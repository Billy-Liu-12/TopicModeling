Hybrid Index for Metric Space Databases
Mauricio Marin1 , Veronica Gil-Costa2 , and Roberto Uribe3
2

1
Yahoo! Research, Santiago, Chile
DCC, Universidad Nacional de San Luis, Argentina
3
DCC, Universidad de Magallanes, Chile
mmarin@yahoo-inc.com

Abstract. We present an index data structure for metric-space
databases. The proposed method has the advantage of allowing an eﬃcient use of secondary memory. In the case of index entirely loaded in
main memory our strategy achieves competitive performance. Our experimental study shows that the proposed index outperforms other strategies known to be eﬃcient in practice. A valuable feature of the proposal
is that the index can be dynamically updated once constructed.

1

Introduction

Searching in metric spaces is a very active research ﬁeld since it oﬀers eﬃcient
methods for indexing and searching by similarity in non-structured domains. For
example, multimedia databases manage objects without any kind of structure
like images, audio clips or ﬁngerprints. Retrieving the most similar ﬁngerprint
to a given one is a typical example of similarity search. The problem of text
retrieval is present in systems that range from a simple text editor to big search
engines. In this context we can be interested in retrieving words similar to a
given one to correct edition errors, or documents similar to a given query. We
can ﬁnd more examples in areas such as computational biology (retrieval of DNA
or protein sequences) or pattern recognition (where a pattern can be classiﬁed
from other previously classiﬁed patterns).
Similarity search can be trivially implemented comparing the query with all
the objects of the collection. However, the high computational cost of the distance function, and the high number of times it has to be evaluated, makes
similarity search very ineﬃcient with this approach. This has motivated the
development of indexing and search methods in metric spaces that make this
operation more eﬃcient trying to reduce the number of evaluations of the distance function. This can be achieved storing in the index information that, given
a query, can be used to discard a signiﬁcant amount of objects from the data
collection without comparing them with the query.
Although reducing the number of evaluations of the distance function is the
main goal of indexing algorithms, there are other important features. Some methods can only work with discrete distance functions while others admit continuous distances too. Some methods are static, since the data collection cannot grow
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 327–336, 2008.
c Springer-Verlag Berlin Heidelberg 2008

328

M. Marin, V. Gil-Costa, and R. Uribe

once the index has been built. Dynamic methods support insertions in an initially empty collection. Another important factor is the possibility of eﬃciently
storing these structures in secondary memory.
Search methods in metric spaces can be grouped in two classes [2]: pivotbased and clustering-based search methods. A pivot-based strategy selects some
objects as pivots from the collection and then computes the distance between
the pivots and the objects of the database and use this information to group
related objects. This method selects a subset of objects from the collection as
pivots, and the index is built computing and storing the distances from each
of them to the objects of the database. During the search, this information is
used to discard objects from the result without comparing them with the query.
Clustering techniques partition the collection of data into groups called clusters
such that similar entries fall into the same group. Thus, the space is divided into
zones as compact as possible, usually in a recursive fashion, and this technique
stores a representative point (“center”) for each zone plus a few extra data that
permit quickly discarding the zone at query time. In the search, complete regions
are discarded from the result based on the distance from their center to the query.
In this paper we propose a combination of two existing methods (Sec. 2). The
ﬁrst method is used as it is proposed by their authors whereas the second one has
been highly optimized by us to deal with secondary memory eﬃciently and very
importantly to reduce the running time by increasing the ability of the strategy
to quickly discard objects that cannot be part of the solution to a given query
(Sec. 3). We present a complete evaluation of the performance of the proposed
strategy in Sec. 4 which shows that our strategy consistently outperforms all
others in practice. Sec. 5 presents concluding remarks.

2

Metric Spaces and Indexing Strategies

A metric space (X, d) is composed of an universe of valid objects X and a distance
function d : X × X → R+ deﬁned among them. The distance function determines
the similarity between two given objects. The goal is, given a set of objects
and a query, to retrieve all objects close enough to the query. This function
holds several properties: strictly positiveness (d(x, y) > 0 and if d(x, y) = 0
then x = y), symmetry (d(x, y) = d(y, x)), and the triangle inequality (d(x, z) ≤
d(x, y)+d(y, z)). The ﬁnite subset U ⊂ X with size n = |U|, is called the database
and represents the collection of objects.
A k-dimensional vector space is a particular case of metric space in which
every object is represented by a vector of k real coordinates. The deﬁnition of the
distance function depends on the type of the objects we are managing. In a vector
space, d could be a distance function of the family Ls (x, y) = i<=i<=k (|xi −
yi |s )1/s . For example s = 2 yields Euclidean distance, that is the number of
insertions, deletions or modiﬁcations to make two words equal.
There are three main queries of interest,
– range search: that retrieves all the objects u ∈ U within a radius r of the
query q, that is: (q, r)d = {u ∈ U/d(q, u) ≤ r};

Hybrid Index for Metric Space Databases

329

– nearest neighbor search: that retrieves the most similar object to the query
q, that is N N (q) = {u ∈ U/∀v ∈ U, d(q, u) ≤ d(q, v)};
– k-nearest neighbors search: a generalization of the nearest neighbor search,
retrieving the set kN N (q) ⊆ U such that |kN N (q)| = k and ∀u ∈ kN N (q),
v ∈ U − kN N (q), d(q, u) ≤ d(q, v).
We focus on range queries since nearest neighbor queries can be rewritten
as range queries in an optimal way [2]. In the following we describe the data
structures we combine to produce our metric-space index.
2.1

List of Clusters (LC)

This strategy [1] builds the index by choosing a set of centers c ∈ U with radius
rc where each center maintains a bucket that keep all objects that are within
the extension of the ball (c, rc ). Each bucket contains the k objects that are
the closet ones to the respective center c. Thus the radius rc is the maximum
distance between the center c and the k-nearest neighbor.
The buckets are ﬁlled as the centers are created and thereby a given element
a located in the intersection of two or more center balls is assigned to the ﬁrst
center. The ﬁrst center is randomly chosen from the set of objects. The next are
selected so that they maximize the sum of the distances to all previous centers.
A range query q with radius r is solved by scanning in order of creation the
centers. At each center we compute d(q, c) and in the case that d(q, c) ≤ rc all
objects in the bucket associated with c are compared against the query. Also if
the query ball (q, r) is totally contained in the center ball (c, rc ), there is no need
to consider others centers.
2.2

Sparse Spatial Selection (SSS)

During construction, this pivot-based strategy selects some objects as pivots
from the collection and then computes the distance between the pivots and the
objects of the database [4]. The result is a table of distances where columns are
the pivots and rows the objects. Each cell in the table contains the distance
between the object and the respective pivot. These distances are used to solve
queries as follows. For a range query (q, r) the distances between the query and
all pivots are computed. The objects x from the collection that do not hold the
condition |d(pi , x) − d(pi , q)| ≤ r for all pivots pi can be immediately discarded
due to the triangle inequality. The objects that pass this test are considered as
potential members of the ﬁnal set of objects that form part of the solution for the
query and therefore they are directly compared against the query by applying
the condition d(x, q) ≤ r. The gain in performance comes from the fact that it
is much cheaper to eﬀect the calculations for discarding objects using the table
than computing the distance between the candidate objects and the query.
A key issue for eﬃciency is the method employed to calculate the pivots,
which must be eﬀective enough to drastically reduce total number of distance
computations between the objects and the query. To select the pivots set, let

330

M. Marin, V. Gil-Costa, and R. Uribe

(X, d) be a metric space, U ⊂ X an object collection, and M the maximum
distance between any pair of objects, M = max{d(x, y)/x, y ∈ X}. The set of
pivots contains initially only the ﬁrst object of the collection. Then, for each
element xi ∈ U, xi is chosen as a new pivot if its distance to every pivot in the
current set of pivots is equal or greater than α M , being α a constant parameter.
Therefore, an object in the collection becomes a new pivot if it is located at more
than a fraction of the maximum distance with respect to all the current pivots.
2.3

LC-SSS Combination (Hybrid)

We propose a combination between the List of Clusters (LC) and Sparse Spatial
Selection (SSS) indexing strategies. In this case we both compute the LC centers
and SSS pivots independently. We form the clusters of LC and within each cluster
we build a SSS table using the global pivots and organization of columns and
rows described above. We emphasize on global SSS pivots because intuition tells
that in each cluster of LC one should calculate pivots with the objects located
in the respective cluster. However, we have found that the quality of SSS pivots
degrades signiﬁcantly when they are restricted to a subset of the database, and
also the total number of them tends to be unnecessarily large. We call this
strategy hybrid.

3

Optimizing Running Time and Secondary Memory

Our contribution to increasing the performance of the SSS index is as follows.
During construction of the table of distances we compute the cumulative sum
of the distances among all objects and the respective pivots. We then sort the
pivots by these values in increasing order and deﬁne the ﬁnal order of pivots
as follows. Assume that the sorted sequence of pivots is p1 , p2 , ...., pn . Our
ﬁrst pivot is p1 , the second is pn , the third p2 , the fourth pn−1 and so on. We
also keep the rows in the table sorted by the values of the ﬁrst pivot so that
upon reception of a range query q with radius r we can quickly (binary search)
determine between what rows are located the objects that can be selected as
candidates to be part of the answer. This because objects oi being part of the
answer can only be located between the rows that satisﬁes d(p1 , oi ) ≥ d(q, p1 )−r
and d(p1 , oi ) ≤ d(q, p1 ) + r.
In practice, during query processing and after the two binary searches on
the ﬁrst column of the table, we can take advantage of the column x rows organization of the table of distances by ﬁrst performing a few, say v, vertical
wise applications of the triangular inequality on the objects located in the rows
delimited by the results of the binary searches, followed by horizontal wise applications of the triangular inequality to discard as soon as possible all objects that
are not potential candidates to be part of the query answer. See Fig. 1 which
shows the case of two queries being processed concurrently.
For secondary memory the combination of these strategies have the advantage
of increasing the locality of accesses to disk and the processor can keep in main

Hybrid Index for Metric Space Databases

331

P1 Pn P2 Pn−1 P3 Pn−2 ......................................Pk
11111
00000
00000
11111
00000
00000
11111
queries: Q1 11111
00000
11111
00000
11111
00000
11111
00000
11111
00000
11111
00000
11111

111111111111111
000000000000000
000000000Candidate
000000000000000111111111
111111111111111
111111111
000000000 Objetcs

00000
11111
11111
00000
00000
11111
00000
11111

1111111111
0000000000
000000000000000
111111111111111
0000000000
1111111111
000000000000000
111111111111111

00000
Q2 11111
00000
11111

Vertical
Processing

Horizontal Processing

Fig. 1. Optimization to the SSS distance table

2
3
3
4

4
12
9
11

2
5
7
3

11
12
11
3

3
13
15
5
44

2
4
4
8

4
11
1
14

2
3
6
8

11
3
3
11

3
5
6
2
44

4
4
5
6

1
5
12
11

6
1
6
10

3
7
10
9

6
22
14
9
88

8
8
9
9

1
4
8
5

2
7
11
7

3
4
13
9

4
7
1
8
88

6
7
7
7

2
7
6
9

2
4
8
11

12
8
8
6

12
17
18
19
132

3
3
5
6

12
9
12
11

5
7
6
10

12
11
10
9

13
15
14
9
132

8
8
8
9

14
1
4
8

11
3
4
13

2
4
7
1
176

6
9
11
12

2
9
6
2

2
1
11
10

12
6
9
3

12
11
16
10
176

9
9
9
10

5
9
4
13

7
1
9
12

9
6
4
7

8
11
23
20
220

4
7
7
7

5
7
6
9

1
4
8
11

7
8
8
6

22
17
18
19
220

11
12
12

6
2
13

11
10
12

9
3
9

16
10
21

9
10
12

4
13
13

9
12
12

4
7
9

23
20
21

8
2
7
11

264

264

(a)

(b)

Fig. 2. Storing the distance table in blocks composed of a ﬁxed number of disk pages

memory the ﬁrst v columns of the table. In the experiments performed in this
paper we observed that with v = n/4 we achieved competitive running times.
In the following we describe two feasible physical organizations of the index
on disk pages. The description is illustrated in Fig. 2 which presents two cases

332

M. Marin, V. Gil-Costa, and R. Uribe

for the distribution of a distance table with 23 objects and 4 pivots. The table is
partitioned in 5 blocks. The ﬁrst 4 columns contains the distances from objects to
the 4 pivots and the last column contains the respective object ID associated with
each row. The cell located at the bottom-right indicates the physical address of
the disk page containing the next table block. Each block is stored in contiguous
disk pages. We assume that the main memory is large enough to store two
blocks. Fig. 2.a represents a case in which all objects 1 ... 23 are available at
construction time and Fig. 2.b a case in which objects are arriving one by one
to the index and every time a block is ﬁlled up a new one is started. The ﬁrst
case requires a external memory sorting by the ﬁrst pivot. In the latter case the
ﬁrst column is kept sorted every two blocks since we are assuming that they
both ﬁt into main memory. Thus external sorting is not required. In the next
section we show that both strategies achieve a very similar performance which
indicates that the scheme supports eﬃciently further updates once the index has
been constructed from an initial set of objects.
In Fig. 2.a and 2.b, the grey cells represent the cases in which the triangular
inequality gives a positive match for a range query q with d(q, pi ) = {6, 8, 3, 7}
for pivots pi and radius r = 3. We assume that the query is solved by performing
one vertical operation followed a horizontal operation for each row selected for
the ﬁrst pivot. In fact, as the ﬁrst pivot is sorted by distance it is only necessary
to perform two binary searches to detect the ﬁrst row with value d(q, p1 ) − r = 3
and the last row with value d(q, p1 ) + r = 9. Then the sequence of horizontal
applications of the triangular inequality determines that the objects 22, 17 and 11
are candidates which must be directly compared against the query object. Notice
that a second vertical operation would have reduced signiﬁcantly the number of
horizontal operations (which is a tradeoﬀ that depends on the application).

4

Experiments

The performance of Hybrid Index was tested with several collections of data.
First, we used a collection of 100, 000 vectors of dimension 10, synthetically
generated with Gaussian distribution. The Euclidean distance was used as the
distance function when working with this collection. We also worked with a
collection of 86, 061 words taken from the Spanish dictionary, and using the edit
distance as the distance function. The algorithm was compared with other wellknown clustering-based indexing methods: M-Tree [6], GNAT [8], EGNAT [7],
Spatial Approximation Trees (SAT) [3]. We also included in the comparison the
LC [1] and SSS [4] strategies, and a recent version of the SSS called the SSSTree
[5] which uses a tree structure in which the SSS pivots are used to recursively
divide the space.
4.1

Cost of Secondary Memory Access

In the left part of table 1 we show for the Spanish dictionary data set the total
number of blocks and objects per block for cases in which we limit the total

Hybrid Index for Metric Space Databases

333

number of pivots to 4, 8, 12, 16 and 20. The ﬁrst three columns show the disk
activity when constructing the index with the 90% of the data set by using the
strategy despicted in Fig. 2.a. The last column shows the case when the same
data is indexed on-line by using the strategy of Fig. 2.b. In this case no reads
of blocks are eﬀected and blocks are written to disk as soon as they become
full during the insertion of objects. In the ﬁrst case reads and seeks have to be
performed in order to perform the sorting by the ﬁrst column and move whole
rows among blocks. However, the actual diﬀerence in running time between the
two alternatives is negligible, presumebly because of disk-cache eﬀects.
Table 1. Disk activity for index construction
Pivots Blocks Objects
4
378
204
8
686
113
12
994
78
16
1291
60
20
1614
48

Writes
399
721
1030
1342
1676

Seeks
761
1373
1989
2583
3229

Reads Writes
780
380
1408
688
2025
996
2634 1293
3291 1616

The next 10% of the data set is used to perform range queries with radio 1, 2,
3 and 4. The Fig. 3.a and 3.b show the total number of block reads performed
during the processing of queries for the two methods of index construction. The
diﬀerences in disk ativity are irrelavant showing that both approaches achieve
similar performance. However, for large radious 4 the on-line creation of the
index tends to generate more activity because large radio tend to generate a
large number of candidate objects which are expected to be evenly distributed
onto all blocks.
4.2

Calls to the Distance Evaluation Function

Computing the distance between two complex objects is known to be very expensive in terms of running time in metric-space databases. This produces an
implementation independent base upon which comparing diﬀerent strategies. In
the following we review previous studies on comparison of a number of metricspace index and then we compare the best performers with our proposal.
Fig. 4 and 5 show results for diﬀerent data structures proposed so far. The
Hybrid strategy achieves the best performance in terms of this metric though
very similar to the LC strategy.
4.3

Comparing Running Times

In Fig. 6 we present results for running times with the diﬀerent strategies. The
proposed Hybrid achieves the best performance for most cases. Notice that structures such as the SAT achieves better performance than ours for range queries
with large radio. The results suggests that SAT performs signiﬁcantly better for
large r. However, for these radio almost all objects are part of the solution to

334

M. Marin, V. Gil-Costa, and R. Uribe
Cost Average Search (n=86061 spanish words)

Cost Average Search (n=86061 spanish words)
2500

Pivots: 4
Pivots: 8
Pivots: 12
Pivots: 16
Pivots: 20

2000

Number of Access to Disk

Number of Access to Disk

2500

1500

1000

500

0

1

2

3

4

Pivots: 4
Pivots: 8
Pivots: 12
Pivots: 16
Pivots: 20

2000

1500

1000

500

0

1

2

Search Range

3

4

Search Range

(a)

(b)

Fig. 3. Disk seeks and their respective block read for during range queries

Evaluations of the distance function

70000

Hyb
SSS
LC
SAT
EGNAT
SSSTree
M-Tree
EGNAT

60000
50000
40000
30000
20000
10000
1

1.5

2

2.5
Query range

3

3.5

4

Fig. 4. Number of calls to the distance evaluation function per query for diﬀerent
metric-space index data structures. Results for the Spanish dictionary data set.

Evaluations of the distance function

90000
80000
70000
60000

Hyb
LC
SSS
SAT
M-Tree
GNAT
EGNAT
SSSTree

50000
40000
30000
20000
0.01

0.1

1

Query range

Fig. 5. Number of calls to the distance evaluation function per query for diﬀerent
metric-space index data structures. Results for the Gaussian vector space.

500
480
460
440
420
400
380
360
340
320
300

900

SSS
LC
SAT
Hyb

335

Hyb
SSS
LC
SAT

800
Running Time (Secs)

Running Time (Secs)

Hybrid Index for Metric Space Databases

700
600
500
400
300
200

1

2

3

4

1

2

Query range

3

Query range

(a)

(b)

Fig. 6. Total running times for processing 10,000 queries with the Spanish dictionary
(left) and a Gauss vector data set (right)

1000
Total

Running Time (Secs)

800

600

Distance
Evaluation

400
Triangle
Inequality

200

0
0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9
alpha

Fig. 7. Running time for the three main components in the execution of the Hybrid

the query and we do not see a practical use of queries like this ones in actual
applications.
Finally Fig. 7 shows results for the cummulative running time involved in
accessing the distance table and executing the distance evaluation function for
diﬀerent values of the parameter α, namely diﬀerent number of pivots. The
results show a tradeoﬀ between both costs with optimum in α = 0.7.

5

Conclusions

We hace presented a simple but very eﬃcient strategy to solve queries in
metric-space databases. Our strategy achieves best performance than most other
strategies. However, it is not able to outperform in a signiﬁcant manner to a tree

336

M. Marin, V. Gil-Costa, and R. Uribe

based structure called SSSTree which is in fact based on a strategy quite similar
to ours. However, our strategy has clear advantages with respect to secondary
management, total memory used by the index. Also the organization of the index
in terms of a table with columns and rows allows it to exploit in an optimal way
the parallelism available in the new computer architectures based on multi-cores
devised to support multi-threading by hardware. We are currently evaluating the
gain in performance in this architectures by solving queries using the standard
openMP.
Acknowledgments. This work has been partially funded by FONDECYT
project 1060776, UMAG PR-F1-002IC-06, and UNSL PICT 2002-11-12600.

References
1. Ch´
avez, E., Navarro, G.: A compact space decomposition for eﬀective metric indexing. Pattern Recognition Letters 26(9), 1363–1376 (2005)
2. Ch´
avez, E., Navarro, G., Baeza-Yates, R., Marroquyn, J.L.: Searching in metric
spaces. ACM Computing Surveys 3(33), 273–321 (2001)
3. Navarro, G.: Searching in metric spaces by spatial approximation. The Very Large
Databases Journal (VLDBJ) 711(1) (2002)
4. Brisaboa, N., Pedreira, O.: Spatial selection of sparse pivots for similarity search in
metric spaces. In: van Leeuwen, J., Italiano, G.F., van der Hoek, W., Meinel, C.,
Sack, H., Pl´
aˇsil, F. (eds.) SOFSEM 2007. LNCS, vol. 4362, pp. 434–445. Springer,
Heidelberg (2007)
5. Brisaboa, N., Pedreira, O., Seco, D., Solar, R., Uribe, R.: Clustering-based similarity
search in metric spaces with sparse spatial centers. In: Geﬀert, V., et al. (eds.)
SOFSEM 2008. LNCS, vol. 4910, pp. 186–197. Springer, Heidelberg (2008)
6. Ciaccia, P., Patella, M., Zezula, P.: M-tree: An eﬃcient access method for similarity
search in metric spaces. In: Proceedings of the 23rd International Conference on
Very Large Data Bases (VLDB 1997), pp. 426–435 (1997)
7. Uribe, R., Navarro, G., Barrientos, R., Marin, M.: An index data structure for
searching in metric space databases. In: Alexandrov, V.N., van Albada, G.D., Sloot,
P.M.A., Dongarra, J. (eds.) ICCS 2006. LNCS, vol. 3991, pp. 611–617. Springer,
Heidelberg (2006)
8. Brin, S.: Near neighbor search in large metric spaces. In: 21st conference on Very
Large Databases (1995)

