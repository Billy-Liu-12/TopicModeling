Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1631–1639

International Conference on Computational Science, ICCS 2011

Non-functional Aspects of Information Integration and Research
for the Web Science
Iv´an Ruiz-Rubea , Juan Manuel Doderoa,∗, John Stoitsisb
a Superior
b Greek

School of Engineering, University of C´adiz, C/ Chile 1, 11002 C´adiz, Spain
Research & Technology Network, 56 Mesogion Av., 11527 Athens, Greece

Abstract
Web Science is emerging as an interdisciplinary ﬁeld that views the Web as a relevant source of information
to be analysed for diverse scientiﬁc purposes. Semantic and linked data techniques and standards have been used
to integrate existing Web information developing e-research eﬀorts. Web applications and sources have to publish
enriched information and data models, which are then matched and aligned. Some aspects of this integration are
related with the evolutionary tracking, trustiness and plurality of the information available for e-science research.
These aspects need to be modeled independently of the information and data sources of the research discipline. Here
we provide an integrative ontology that enables to model such non-functional, informational aspects, to integrate
information sources from enriched linked data applications. Finally we describe an application case of information
research in the e-culture ﬁeld.
Keywords: web science, information integration, semantic web, linked data, humanities, ontologies

1. Introduction
The large amount of information existing in the Web has made it the main information, communication and
research media around the globe. New ways of doing e-science and e-research on the Web have emerged and evolved
[1]. The Web information is shaped by early hypertext-based information, as well as extended semantic information
[2] and more recent linked data [3]. There are needs and large initiatives to enable large-scale coordination and
resource sharing eﬀorts on such large amounts of enriched information [4]. For that aim, Web Science is emerging
as an interdisciplinary ﬁeld that views the Web as a source of information to be analysed with a relevance in diverse
sciences. Interdisciplinary e-science research must be endowed with adequate conceptualizations for information
integration [5], especially for research in social sciences and humanities [6]. This work deals with a number of
integration issues related with e-research in the Web. A linked data integration solution is described and then assessed
by means of a web-based querying application that operates on a number of web applications holding semantically
enriched cultural information. The rest of this paper is structured as follows: Section 2 describes some aspects
of e-research in the Web and related information integration issues; section 3 explains our solution to information
∗ Corresponding

author
Email addresses: ivan.ruiz@uca.es (Iv´an Ruiz-Rube), juanma.dodero@uca.es (Juan Manuel Dodero), stoitsis@ieee.org (John
Stoitsis)

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.176

1632

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

integration in the Web for e-research purposes; the solution is analysed by the case study evaluation of section 4,
ﬁnishing with some conclusions and future lines of research in section 5.
2. Web Science and Information Integration
The Web Science aims at analysing how web information structures can serve the representational requirements
to produce designs and design principles governing such decentralised structures [7]. Web Science is a merge of
the synthetic and analytic scientiﬁc paradigms [8], in the sense that human interactions need to be designed (i.e.
engineered) for the Web, but also be analysed and understood. The ﬁnal aim is to exploit web resources for the
needs of a particular discipline, such as commerce, learning, entertainment, politics and almost anywhere in which
communication serves a purpose [9]. The synthetic face of the Web has to do with engineering of formalisms and
algorithms to support the desired behavior of the rich web-based content repositories. Graph-like languages and
knowledge formalisms such as RDF(S), OWL and ontologies have been recurrently used to represent and synthesize
the Web structure since the inception of the Semantic Web.
There is an important cost for Web engineers to synthesize, integrate and re-design the web structure, in order to
allow users to explore the constantly evolving linked path of Web structures and services [10]. A major issue has to do
with information integration, which is usually tackled by software and knowledge engineering eﬀorts in a systematic,
but still costly manner. The question is which informational requirement do users have when exploiting that huge
information network for a given scientiﬁc discipline? If the Web consists of a great number of sources that evolve, do
answers to user queries have to be always the same? What if informational statements or sources that might contradict
one another emerge? These issues are especially relevant, though not exclusive, for e-research in Social Sciences and
Humanities, in which incurred incompleteness and undecidability of inquiries are unavoidable [11].
2.1. Non-functional aspects of e-research in the Web
e-Science refers to the large scale science that is increasingly carried out through distributed collaboration on the
Web. Such eﬀorts require access to large data collections and large scale computing resources to the individual user
scientists [12]. This issue is not restricted to the physical and natural sciences, but the humanities and social sciences
have been also aﬀected [6]. Current conceptions of e-science are rooted in computer science, meaning that most escience initiatives aim at constructing a computational infrastructure to support scientiﬁc research in the Web [13]. It is
argued that social science and humanities cannot perform their research without adequate conceptualizations and tools
that handle ontological plurality and contexts, provide argumentation and question corpora management systems, as
well as support adequate representational expressivity [11]. In the Semantic Web, these conceptualizations are usually
explicited by means of ontologies [14], which have been applied to represent knowledge of the Humanities ﬁeld by
means of ontological annotations.
Nevertheless, contents of the Web often evolve over time. After they have been created, they change, evolve or
even be removed with time. It is usual that existing concept annotations cease to be valid, for instance, by a mistake
or by a newly discovered fact that was not taken earlier into account. This is especially unavoidable for research in
social sciences and the humanities.
Another issue occurs when two or more authorized researchers want to annotate the same concept but have contradictory opinions. The issue is usually tackled by a review process before publication, carried out by speciﬁc domain
knowledge experts. This is not always desirable in all sciences though. In the humanities there might be a need to
maintain diﬀerent, even contradictory, ontological annotations on the same content, according to diﬀerent theories,
models or thoughts of renowned researchers. That requires maintaining and tracking a quite plural ontological versioning system. One way to implement ontological plurality is by supporting contexts, both for ontology building and
for reasoning [15]. In terms of reasoning, contexts provide a way of compartmentalizing mutually contradictory information without inferring a contradiction. Using computational reasoners to solve these contradictions is presently
undecidable. If every text reﬂects the underlying mental ontology of its author(s), then it is a duty of researchers
to attempt to reconstruct the text in terms of that ontology. Instead, an enhanced inquiry system in the Web might
enrich answers by describing the plural possibilities of assertions and enabling to explore them to show and restrict
the possible answers.
The third aspect we have to deal with is trustiness. In the scope of the Web, trust and trustworthiness requires
maintaining causal links between information and providers [16, 17], so that a degree of conﬁdence can be assigned

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

1633

and acknowledged for each information source. Diﬀerent trustworthiness can be linked to researchers, but also to
diﬀerent categories of applications. For instance, we might assume that researchers with brilliant scholar r´esum´es are
more trusty, or that blog publications are probably less reliable than journals stored in a digital library.
Our work deals with information integration issues on the Web that should consider the information evolution,
plurality of information and trustiness of information sources. We call this type of issues as non-functional aspects
of Web information integration, in the sense that they are accompanying properties of the main, functional aim of
information of e-research in the Web.
2.2. Information integration and linked data
There are two strategies for information integration, namely Enterprise Information Integration (EII) and Extraction, Transformation and Loading (ETL). The former is characterized by an architecture based on a global schema
and a set of sources. The sources contain the actual data, while the global schema provides a reconciled, integrated
and virtual view of the underlying source [18]. The latter approach, usual in data warehousing systems, does not use
a virtual view, but a distributed information repository, which stores data as extracted and transformed from external
sources [19].
Regardless of the selected strategy, all information integration solutions require a number of wrappers (to extract
or publish data from speciﬁc applications), integration processes (to transform and route data messages), information
containers (logical views in the case of EII, or data warehouses for ETL) and query interfaces.
Emergent initiatives such as the Semantic Web or Linked Data have been used for information integration. They
enable to exchange, collect and query data. The aim of semantic and linked data technologies is to describe and publish
the information of web contents in a structured manner that can be easily processed by software programs [3]. These
techniques can be used to integrate information from diﬀerent sources and obtain added value features. A fundamental task is to generate the schema of the logical view or the data warehouse to be used. If semantic web ontologies
are used as a formalism to represent the information, the generation of the integration schema is known as ontology
matching [20]. Ontology matching aims to ﬁnd relationships or correspondences between concepts of diﬀerent ontologies. There are several dimensions of research in semantic integration, as stated in [21, 22], namely: mapping,
discovery, declarative formal representations of mappings (alignments) and reasoning with mappings. However, the
non-functional aspects of web information integrationare not considered often. These aspects need to be modeled
independently of the information schema and data sources of the research discipline.
3. Web information integration solution
Our proposal consists of a general framework for the development of integration solutions that support e-science
researchers in the inquiry of facts described in diﬀerent web sources. Researchers can build queries on data merged
from diﬀerent data sources (e.g. wikis, blogs, digital libraries, etc.) taking into account the non-functional aspects
described in the previous section. This framework comprises an integration ontology, the use of RDF as data exchange
mechanism and a queries pretreatment process. The approach can be applied for both strategies of information integration.
3.1. Integration Ontology
Figure 1 presents an Web resources integration ontology1 that enables to model the described non-functional
aspects in order to query for data sources from a number of available web applications. It comprises the following
elements:
WebContent is an abstraction that represents any linked content published on the Web that feeds the global view
or warehouse data. The information is formed by statements or subject-predicate-object triples. WebContent is an
RDF-compliant metadata container that provides the ability to view an information source at the level of its relevant
semantic concepts and also supports information inquiries that are independent of the structure or location of the
data source. Similar to version control and workﬂow properties in a Content Management System (CMS), each
1 Available

in http://ecultura.uca.es/linkedData/app/WebIntegrationOntology.owl

1634

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

Figure 1: Web Integration Ontology

WebContent has a unique identiﬁer, a publication date, a version number and a state (i.e. an enumerated value among
DRAFT, PUBLISHED and REMOVED).
The WebSource concept represents the identity of a particular website such as Wikipedia, a news portal, a blog
site, a thematic library, etc. A property has been added that models the trustiness of the website.
ConﬁdenceAgent is the concept that represents the person, group or organization that publishes the information
on the web. This is a specialization of the Agent class on the FOAF2 ontology. In addition, a property that depicts the
known conﬁdence level about the web content author has been added to the ontology.
Regarding trustiness, a question arises about how trustinessLevel of a WebSource or conﬁdenceLevel of a ConﬁdenceAgent can be assigned. Although they are far from the aims of this work, various possibilities arise. On one
hand, if this is done manually, it implies pre-processing annotations to set the trustiness of the websites and the conﬁdence of the authors. The questions are now who would undertake this and if we can trust in that work. On the other
hand, if the assignment is automatic, measurement algorithms can be used to analyze the impact, the reputation or the
veracity of web sites, for instance, using the popular algorithm PageRank by Google [23]. With respect to the level
of conﬁdence on the authors, a possible choice is to use their scientiﬁc productivity metrics (e.g. by calculating the
h-index via citations in Google Scholar), but this presents a major threat because of the problems already described in
[24].
3.2. Linked data exchange and querying
Wrappers or data extractors are often ad-hoc for the speciﬁc applications that are integrated. Such wrappers are
designed to publish data according to a particular scheme. The use of semantic technologies implies having to export
data from applications in RDF format, either using RDF/SQL semantic-relational mappers, RDFa harvesters, or other
mechanisms.
The main aim of data integration is to have a query interface, which works on a ETL repository or EII virtual view
of data, as appropriate. In our framework, we propose an SPARQL extended querying interface, which enables to
issue web queries concerned with the non-functional aspects described above, namely information evolution, plurality
of information elements, and trustiness of the information sources.
The RDF reiﬁcation allows to to link authorship, provenance and versioning to the domain information published,
according to the integration ontology described above. However, queries on domain ontologies, which a priori are
2 http://www.foaf-project.org/

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

1635

simple, can become very complex, generating large amounts of SPARQL code, to meet the requirements of ontology
integration. To approach this problem, we make a query pre-processing, which allows the user to abstract from
aspects of the reiﬁcation of the SPARQL queries, focusing only on the research queries that are needed to issue. Preprocessing is responsible for expanding the queries entered by the user. Furthermore, the SPARQL queries expanded
by this process oﬀer diﬀerent versions of the results, depending on the source and the author. Optionally, the user can
ﬁlter information according to speciﬁed levels of trustiness and conﬁdence. Thus, it oﬀers to the researcher a simple
and impartial way to ﬁnd information.
4. Case Study
Our general framework for the development of integration solutions has been evaluated and set up in the context
of the eCultura project[25], which aims at creating a semantic platform for the preservation and exploitation of eculture contents. This platform is based on the integration of information ETL strategy. From a number of semantic
applications built on MediaWiki3 and WordPress4 , the platform feeds a shared repository of linked metadata. After introducing the platform, a proof of concept is presented to clarify the non-functional aspects of information integration
and research described above.
4.1. e-Culture integration platform
With the aim of sharing the information stored in instances of MediaWiki and WordPress, we develop some extensions to provide linked data capabilities to the e-culture platform tools, namely LinkedWiki and LinkedBlog. In
the case of LinkedBlog [26], we developed a WordPress extension plug-in to visually annotate blog posts according
to a certain ontological model accessible through an SPARQL endpoint. This plug-in is based in the RDFa speciﬁcation transparently to the end user. In the case of LinkedWiki, we built a software tool that automatically generates
forms and wiki articles based on structured templates for existing classes and individuals, respectively. Likewise, this
software uses an ontological model accessible through an SPARQL endpoint.
We have created semantic wrappers to extract, transform and load data from the linked blog posts and wiki articles
into the metadata repository. The wrapper developed for LinkedBlog is responsible for extracting RDF statements
from RDFa content; meanwhile the LinkedWiki wrapper is responsible for deriving RDF code from wiki articles. Both
wrappers transform the RDF statements, reifying and contextualizing them, in order to comply with the integration
ontology proposed in this paper. The information is loaded into a metadata repository based on the Jena5 framework
and the domain ontologies used in the context of the e-culture project, namely: FOAF, Music Ontology6 and the
CIDOC CRM7 . With this aim, we use SPARQL/Update, an update language for RDF.
Finally, we propose the query web interface, capable of processing the non-functional aspects. The interface uses
the services oﬀered by Joseki, an HTTP SPARQL query engine for Jena stores. The query results are enriched with
information about the source, author and date of publication. We can see it in the screenshot shown in Figure 2.
4.2. Proof of Concept
Here we will illustrate a particular e-research scenario in the Humanities, consisting of questionable information
about a ﬂamenco musical artist and how researchers can easily discover dissents and then obtain their own conclusions.
The problem8 describes the diﬀerent opinions about the birth of the ancient ﬂamenco singer known as Silverio
Franconetti. In a given annotated post in the LinkedBlog, Jos´e Blas Vega, who is a leading researchers in ﬂamenco,
states that Franconetti Silverio was born in 1831. Listing 1 shows the HTML-embedded RDFa code for this statement.
3 http://www.mediawiki.org/
4 http://wordpress.org/
5 http://openjena.org/
6 http://musicontology.com/
7 http://www.cidoc-crm.org/
8 http://es.wikipedia.org/wiki/Silverio

Franconetti

1636

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

Figure 2: Query Interface

Listing 1: RDFa generated code example from a blog post
<span about= ” h t t p : / / p u r l . org / o n t o l o g y /mo/ S i l v e r i o F r a n c o n e t t i t y p e o f = ” h t t p : / / p u r l . org / o n t o l o g y /mo/ S o l o M u s i c A r t i s t ” >
S i l v e r i o F r a n c o n e t t i , a l s o known s i m p l y as S i l v e r i o was a s i n g e r and t h e l e a d i n g f i g u r e o f t h e p e r i o d i n flamenco
h i s t o r y known as The Golden Age . S i l v e r i o F r a n c o n e t t i was born i n S e v i l l e on <span
r e l = ” h t t p : / / xmlns . com / f o a f / 0 . 1 / b i r t h d a y ” c o n t e n t = ” 1831 −06 −10 ” >10 June 1831 < /span > . As a s i n g e r , S i l v e r i o was deeply
i n f l u e n c e d by E l F i l l o , from whom he l e a r n t most o f h i s r e p e r t o i r e . . . < / span >

On the other hand, Daniel Pineda Novo, another leading ﬂamenco researcher, aﬃrms in a LinkedWiki article that
Silverio was born in 1823. We see it in the article excerpt from listing 2, described by a structured template.
Listing 2: Structured information excerpt from a wiki article
{ { Anotations
| individualCategory=MusicArtist
| o n t o l o g y A s s o c i a t e d = h t t p : / / p u r l . org / o n t o l o g y /mo/
}}
{ { Agent
| familyName= S i l v e r i o F r a n c o n e t t i
| gender=male
| b i r t h d a y =1823 −10 −06
}}
{{ MusicArtist }}

Once the above data are stored in the metadata repository, if a researcher needs to know the birth date of Silverio,
he/she would create a query as the following:
Listing 3: SPARQL query (with brief explanations) based on the FOAF ontology
PREFIX f o a f : < h t t p : / / xmlns . com / f o a f / 0 . 1 / >
SELECT ? B i r t h d a y
WHERE {
# Main graph p a t t e r n u s i n g an o u t p u t v a r i a b l e
? a r t i s t f o a f : age ? B i r t h d a y
# A u x i l i a r y graph p a t t e r n
? a r t i s t f o a f : name ? a r t i s t N a m e
# R e s t r i c t i o n expression
FILTER regex ( ? artistName , ” S i l v e r i o F r a n c o n e t t i ” , ” i ” ) }

In addition, the user can set the non-functional parameters that restrict the selection, for example, to those contents
that are not outdated (in a published state) with conﬁdence level of 0.8 and trustiness level of 0.75. The query of
listing 3, together with the set parameters of non-functional aspects, are submitted from the visual interface and will
be intercepted by the SPARQL query expansion process. This process will automatically include the author, web

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

1637

source and date of publication into the query results. In addition, new graph patterns are generated that consider the
RDF statements reiﬁcation, the state of contents and the set levels of trustiness and conﬁdence, as shown in listing 4.
Listing 4: SPARQL expanded query concerned about non-functional aspects
SELECT ? B i r t h d a y ? P u b l i s h e r ?Source ?DateTime
WHERE {
# Required query expansion t o c o n s i d e r t h e r e i f i c a t i o n on main graph p a t t e r n
? statement1 r d f : s u b j e c t
?artist
.
? statement1 r d f : p r e d i c a t e f o a f : age .
? statement1 r d f : o b j e c t
?Birthday .
# Required query expansion t o c o n s i d e r t h e r e i f i c a t i o n on a u x i l i a r y graph p a t t e r n
? statement2 r d f : s u b j e c t
?artist
.
? statement2 r d f : p r e d i c a t e f o a f : name .
? statement2 r d f : o b j e c t
?artistName .
# R e s t r i c t i o n expression
FILTER regex ( ? artistName , ” S i l v e r i o F r a n c o n e t t i ” , ” i ” ) .
# R e t r i e v a l o f t h e a u t h o r and p u b l i c a t i o n source f o r t h e main graph p a t t e r n
?webContent1 wio : hasStatements
? statement1 .
?webContent1 wio : publishedBy
?webauthor1 .
?webContent1 wio : p u b l i s h e d I n
?websource1 .
# Checking t h e t r u s t i n e s s and c o n f i d e n c e r e q u i r e m e n t s f o r t h e main graph p a t t e r n
?webContent1 wio : s t a t u s
” PUBLISHED ” .
?websource1
wio : t r u s t i n e s s L e v e l
?trustiness1 .
FILTER ( ? t r u s t i n e s s 1 > 0 . 7 5 )
?webauthor1
wio : c o n f i d e n c e L e v e l
? c on f id e nc e 1 .
FILTER ( ? c o n f i d e n c e 1 > 0 . 8 )
# R e t r i e v a l o f t h e p u b l i s h e r , web source and p u b l i c a t i o n date
?webauthor1
f o a f : name
?Publisher .
?websource1
wio : nameWebSource
?Source .
?webContent1 wio : p u b l i c a t i o n D a t e T i m e
?DateTime .
# R e t r i e v a l o f t h e a u t h o r and p u b l i c a t i o n source c o r r e s p o n d i n g t o t h e a u x i l i a r y graph p a t t e r n
?webContent2 wio : hasStatements
? statement2 .
?webContent2 wio : publishedBy
?webauthor2 .
?webContent2 wio : p u b l i s h e d I n
?websource2 .

}

# Checking t h e t r u s t i n e s s and c o n f i d e n c e r e q u i r e m e n t s f o r t h e a u x i l i a r y graph p a t t e r n
?webContent2 wio : s t a t u s
” PUBLISHED ” .
?websource2
wio : t r u s t i n e s s L e v e l
?trustiness2 .
FILTER ( ? t r u s t i n e s s 2 > 0 . 7 5 )
?webauthor2
wio : c o n f i d e n c e L e v e l
? c on f id e nc e 2 .
FILTER ( ? c o n f i d e n c e 2 > 0 . 8 )

The system answers with the results shown in Table 1. Here we can see how diﬀerent people have published
contradictory data about the same fact into diﬀerent websites. At this point, the researcher would have to manually
discern, according to his own knowledge, what is the correct birth date. Taking into account the non-functional aspects
in the query, the system has facilitated to the user the task of ﬁnding out that information in multiple web sources.
Birthday
1831-06-10
1823-10-06

Publisher
Jos´e Blas Vega
Daniel Pineda Novo

Source
http://ecultura.org/linkedBlog
http://ecultura.org/linkedWiki

DateTime
2009-03-09T10:30:00
2011-12-10T10:30:00

Table 1: Query results

The main beneﬁts of this system are, ﬁrst, to have a central access point from which to inquiry information
published from heterogeneous web sites and by diﬀerent authors (i.e. plurality of the information); and second,
to discover and discard outdated information (i.e. evolutionary tracking) and/or coming from a dubious origin (i.e.
trustiness).

1638

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

5. Conclusions
Web Science has emerged as a new ﬁeld that views the Web as a source of information with a relevance for
e-research in diverse, interdisciplinary sciences. In this work we have presented a general framework for the development of information integration solutions on the Web, taking into account non-functional aspects such as evolutionary
tracking, trustiness and plurality of information available for a given discipline. This framework comprises of an integration ontology, the use of RDF as data exchange mechanism and a query expansion process capable of intercepting
and enriching SPARQL queries with provenance information, authorship and time.
We have presented a case study of the framework for the construction of an integration solution based on an
ETL approach. We discussed the procedures for the extracting, processing, loading and querying data. We have also
exempliﬁed the situation caused when diﬀerent web sources describe controversial information and how the developed
solution can help to discover these.
Our proposal aims to support researchers, as far as possible, searching information on the Web and discovering
controversies on facts published as web contents. However, the proposal is not intended to resolve these discrepancies,
but to provide information in a simple and clear way as gathered from several integrated web sources. A possible way
of extending the work is to investigate how semantic reasoners (e.g. Pellet) can help us make decisions to resolve
any ambiguities. Another way of extending this research would be exploring possible applications of the case-based
reasoning paradigm, as in [27]. This approach lies in solving problems by ﬁnding similar past cases, and reusing them
in new situations. The idea would be that our system resolves ambiguities about facts described in the web, based on
decisions on discrepancies taken previously by the researchers.
There is a relevant issue that has not been considered in the scope of our work. First, we admit that the intellectual
author of a particular information is not necessarily the person who publishes it in the web. Another essential issue to
tackle in the future can be to apply an eﬀective procedure to set the trustiness and conﬁdence levels on web sites and
authors. Altough these issues are out of the scope of the integration problem described in this paper, they represent a
threat to the validity of our approach in an actual e-research environment.
Acknowledgments
This work has been partly sponsored by grants from the eCultura project (TSI-020501-2008-53) of the Spanish
Ministry of Industry, Tourism and Trade and the ASCETA project (P09-TIC-5230) of the Andalusian Government.
References
[1] W. Hall, D. De Roure, N. Shadbolt, The evolution of the Web and implications for eResearch., Philosophical transactions. Series A, Mathematical, physical, and engineering sciences 367 (1890) (2009) 991–1001.
[2] T. Berners-Lee, J. Hendler, O. Lassila, The Semantic Web, Scientiﬁc American (2001) 35–43.
[3] C. Bizer, T. Heath, T. Berners-Lee, Linked data-the story so far, International Journal on Semantic Web and Information Systems 5 (3) (2009)
1–22.
[4] T. Hey, A. E. Trefethen, The UK e-Science Core Programme and the Grid, Future Generation Computer Systems 18 (8) (2002) 1017–1031.
doi:10.1016/S0167-739X(02)00082-1.
[5] N. Shadbolt, W. Hall, T. Berners-Lee, The Semantic Web Revisited, IEEE Intelligent Systems may/june (2006) 96–101.
[6] R. Schroeder, J. Fry, Social Science Approaches to e-Science: Framing an Agenda, Journal of Computer-Mediated Communication 12 (2)
(2007) 563–582.
[7] T. Berners-Lee, W. Hall, J. Hendler, N. Shadbolt, D. J. Weitzner, Computer science. Creating a science of the Web., Science (New York, N.Y.)
313 (5788) (2006) 769–71.
[8] T. Berners-Lee, D. J. Weitzner, W. Hall, K. O’Hara, N. Shadbolt, J. a. Hendler, A Framework for Web Science, Foundations and Trends in
Web Science 1 (1) (2006) 1–130.
[9] D. L. Hoﬀman, T. P. Novak, A. Venkatesh, Has the Internet become indispensable?, Communications of the ACM 47 (7) (2004) 37–42.
[10] J. L. Herlocker, J. a. Konstan, L. G. Terveen, J. T. Riedl, Evaluating collaborative ﬁltering recommender systems, ACM Transactions on
Information Systems 22 (1) (2004) 5–53.
[11] R. C. Kahlert, D. Austin, Ontologies: A Wish List for the Humanities, Proc. of CaSTA’06 2.
[12] N. W. Jankowski, Exploring e-Science: An Introduction, Journal of Computer-Mediated Communication 12 (2) (2007) 549–562.
[13] P. Wouters, B. A, Imagining e-Science beyond computation, Idea Group, 2006, Ch. III, pp. 48–70.
[14] T. R. Gruber, A translation approach to portable ontology speciﬁcations, Knowledge Acquisition 5 (1993) 199–220.
[15] R. Guha, R. Mccool, R. Fikes, Contexts for the Semantic Web, in: The Semantic Web - ISWC, 2004, pp. 32–46.
[16] J. Golbeck, Trust on the world wide web: a survey, Found. Trends Web Sci. 1 (2006) 131–197.
[17] K. O’Hara, W. Hall, Trust on the Web : Some Web Science Research Challenges (2008).

Iván Ruiz-Rube et al. / Procedia Computer Science 4 (2011) 1631–1639

1639

[18] M. Lenzerini, Data integration: A theoretical perspective, in: Proceedings of the twenty-ﬁrst ACM SIGMOD-SIGACT-SIGART symposium
on Principles of database systems, ACM, 2002, pp. 233–246.
[19] R. Kimball, J. Caserta, I. Books24x7, The data warehouse ETL toolkit: practical techniques for extracting, cleaning, conforming, and
delivering data, Wiley, 2004.
[20] J. Euzenat, P. Shvaiko, Ontology matching, Springer-Verlag New York Inc, 2007.
[21] H. Wache, T. Voegele, U. Visser, H. Stuckenschmidt, G. Schuster, H. Neumann, S. Hubner, Ontology-based integration of information-a
survey of existing approaches, in: IJCAI-01 workshop: ontologies and information sharing, Vol. 2001, Citeseer, 2001, pp. 108–117.
[22] N. Noy, Semantic integration: a survey of ontology-based approaches, ACM Sigmod Record 33 (4) (2004) 65–70.
[23] L. Page, S. Brin, R. Motwani, T. Winograd, The pagerank citation ranking: Bringing order to the web, Tech. rep., Stanford Digital Library
(1998).
[24] P. Jacs´o, The pros and cons of computing the h-index using Google Scholar, Online information review 32 (3) (2008) 437–452.
[25] C. Cornejo, I. Ruiz-Rube, J. Dodero, eCultura, a Semantically-Enriched Web-Based Approach to Manage Cultural Contents, in: Proceedings
of the 10th International Conference on Information Reuse and Integration, 2010, pp. 126–131.
[26] I. Ruiz-Rube, C. Cornejo, J. Dodero, V. Garca, Development Issues on Linked Data Weblog Enrichment, Metadata and Semantic Research
(2010) 235–246.
[27] C. Baccigalupo, E. Plaza, A case-based song scheduler for group customised radio, in: Proceedings of the 7th international conference
on Case-Based Reasoning: Case-Based Reasoning Research and Development, ICCBR ’07, Springer-Verlag, Berlin, Heidelberg, 2007, pp.
433–448.

