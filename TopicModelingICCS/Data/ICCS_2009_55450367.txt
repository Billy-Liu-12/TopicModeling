Design and Implementation of a Scalable General High
Performance Remote Sensing Satellite
Ground Processing System on Performance and Function
Jingshan Li and Dingsheng Liu
Center for Earth Observation and Digital Earth, Chinese Academy of Sciences,
No.45, Bei San Huan Xi Road, Beijing, China
{jsli,dsliu}@ceode.ac.cn

Abstract. This paper discusses design and implementation of a scalable high
performance remote sensing satellite ground processing system using a variety
of advanced hardware and software application technology on performance and
function. These advanced technologies include the network, parallel file system,
parallel programming, job schedule, workflow management, design patterns,etc, which make performance and function of remote sensing satellite
ground processing system scalable enough to fully meet the high performance
processing requirement of multi-satellite, multi-tasking, massive remote sensing
satellite data. The "beijing-1" satellite remote sensing ground processing system
is introduced as an instance.
Keywords: parallel computing, remote sensing, data processing system, clusters computing, scalable.

1 Introduction
With development of the remote sensing mini-satellites, mini-satellites constellation,
as well as the high-performance parallel computing technology, the remote sensing
satellite ground processing system faces to the demand of multi-platform, multitasking, high performance data processing. Remote sensing is characterized by a need
to perform computationally intensive operations on large data sets. Full-scene image
processing requires operating on tens of millions of image data points per scene.
The cluster of PC server has grown from a curiosity to become the norm for much of
the world's computing [1],[5],[6].Integrating parallel computer programs into a framework that can be easily used by applied scientists is a challenging problem. Such a
framework has to enable simplified access to computationally complex operations and
high performance technologies, as well as providing a means for defining the appropriate data sets for the operation request. It still can be inadequate for a lack of suitable
software, suitable hardware and total integrate processing system [2], [3],[4].
The scalable General HIgh Performance remote sensing satellite ground Processing
System (GHIPS) is researched. The advanced high performance computing technology, advanced software design, a combination of parallel storage technologies, parallel computing, task scheduling technology, process management technology, design
G. Allen et al. (Eds.): ICCS 2009, Part II, LNCS 5545, pp. 367–374, 2009.
© Springer-Verlag Berlin Heidelberg 2009

368

J. Li and D. Liu

methods, web service technology are used in this system, which makes performance
and function to achieve a high degree to meet the requirement of satellite ground data
processing system.
We describe our GHIPS design on performance and function in section 2 and
GHIPS implementation case, the "beijing-1" satellite remote sensing ground processing system, in section 3.We discuss conclusion in section 4.

2 GHIPS Design on Performance and Function
GHIPS, developed at the Center for Earth Observation and Digital Earth, Chinese
Academy of Sciences, is a high performance computing middleware that supports the
development and execution of generic remote sensing satellite ground processing
system applications over a collection of hardware and software resources. The system
is client-server architecture. The client submitted to the task of processing through the
web service protocol to server end, and server end finished product processing with
high performance.
This paper focuses on the server-side design of the system. The key issue of remote
sensing satellite ground processing system on performance and function is researched.
As shown in Figure 1, the server end system is divided into five layers, namely the
hardware layer, system support layer, data processing layer, tasks scheduling layer
and user composition layer. The first two layers make system scalable on performance
and the other three layers make system scalable on function. The methods of making
system scalable on performance and function are discussed below.

Fig. 1. GHIPS Server End Architecture

2.1 Hardware Layer
The hardware layer provides hardware support, including commercial off-the-shelf
systems such as PC server cluster, Storage Area Network (SAN) / Network Attached
Storage (NAS) storage systems, Gigabit Ethernet or Infiniband network systems.
All three modes use traditional network storage technologies: direct attached storage (DAS), which is attached to a single server; NAS, a server dedicated to file sharing; and SAN, networks of shared storage devices. NAS can offer low cost massive

Design and Implementation of a Scalable General High Performance

369

storage, and SAN can offers both high performance network storage and secure data
sharing across platforms.
The InfiniBand is a switched fabric communications link primarily used in highperformance computing. Its features include quality of service and failover, and it is
designed to be scalable. The InfiniBand architecture specification defines a connection between processor nodes and high performance I/O nodes such as storage devices. The InfiniBand can offer high-bandwidth, low-latency communication among
cluster. The InfiniBand standard supports single data rate (SDR), double data rate
(DDR), and quad data rate (QDR),which provides bandwidth equal to 10Gbps,
20Gbps,and 40Gbps, respectively.
The commercial off-the-shelf computing hardware is a cost-effective way of exploiting in remote sensing applications. The above high performance hardwares have
standard interface and make system scalable on performance of computing, storage
and network. On this hardware layer, users can deployment commercial off-the-shelf
software without worrying about any further change of hardware.
2.2 System Support Layer
The remote sensing data processing is a complex computing intensive, data intensive
and network intensive applications and different functions of computing, storage and
network access performance requirements may differ from each other.
The system support layer provides software support environment, includes parallel storage software, such as Stornext, PVFS, Luster file system, parallel computing
software, such as MPI, OpenMP, PVM, network load balance software, such as
LVS, BigIP. This layer can integrate and make full use of computing, storage, and
network access software and resource. The orthogonal design of the system of parallel computing, parallel storage, the parallel network load make the system performance, network performance, storage performance to be scalable independent,
and to be optimized data processing performance on the three dimensions. The
optimized method of three dimensions is showed in Figure 2.This layer shields the
complexity of using of parallel software, and users can design and implement their
data processing application without worrying about any further change of parallel
system support software, and can gain the better performance of new system software and hardware automatically.
2.3 Data Processing Layer
The data processing layer makes use of advanced software design patterns. In software engineering, a design pattern is a general reusable solution to a commonly occurring problem in software design. A design pattern is not a finished design that can
be transformed directly into code. It is a description or template for how to solve a
problem that can be used in many different situations. Object-oriented design patterns
typically show relationships and interactions between classes or objects, without
specifying the final application classes or objects that are involved.

370

J. Li and D. Liu

Fig. 2. Scalable on Performance

A software design pattern, the abstract factory Pattern provides a way to encapsulate
a group of individual factories that have a common theme. In normal usage, the client
software would create a concrete implementation of the abstract factory and then use
the generic interfaces to create the concrete objects that are part of the theme. The
client does not know (or care) about which concrete objects it gets from each of these
internal factories since it uses only the generic interfaces of their products. This pattern
separates the details of implementation of a set of objects from its general usage.
The template design pattern is perhaps one of the most widely used and useful design patterns. It is used to set up the outline or skeleton of an algorithm, leaving the
details to specific implementations later. This way, subclasses can override parts of
the algorithm without changing its overall structure. This is particularly useful for
separating the variant and the invariant behavior, minimizing the amount of code to
be written. The invariant behavior is placed in the abstract class (template) and then
any subclasses that inherit it can override the abstract methods and implement the
specifics needed in that context.
Using design pattern, data processing layer design a variety of abstract function interface for a variety of satellite sensors using abstract factory design pattern and
common logical thread of public functions using template method design pattern. The
various processing algorithms of satellite sensors can be added through inherit, which
ensure scalability of satellite sensors data processing algorithms. The scalable data
processing layer architecture showed as class diagram is illustrated in Figure 3, for
examples of data processing of "beijing-1" satellite and " CBERS " satellite.
2.4 Task Scheduling Layer
A cluster system has driven the need for new job scheduling system in the computational science realm. A job scheduling system is used for both serial and parallel job
control.

Design and Implementation of a Scalable General High Performance

Fig. 3. Scalable Data Processing Layer Architecture and Class Diagram

Fig. 4. Tasks Scheduling System

371

372

J. Li and D. Liu

A workflow is a depiction of a sequence of operations, declared as work of a person, work of a simple or complex mechanism, work of a group of persons, work of an
organization of staff, or machines. Workflow software can provide end users with an
easier way to orchestrate or describe complex processing.
The tasks scheduling layer integrate job scheduling and workflow management
system to achieve the work load balancing process and the ability to compose complex job workflow. The tasks scheduling layer can assign any data processing job on
the whole cluster with help of system support software. The tasks schedule is illustrated in Figure 4.
2.5 User Composition Layer
The user composition layer provides users with kind interface to compose process,
users can compose a variety of complex processing, such as data processing, archiving, production, distribution and other functions, as shown in Figure 5.

Fig. 5. User Composition Data Processing Task

2.6 Scalable on Performance and Function
The hardware layer and system support layer achieve on demand scalability on system performance. The using of high performance commercial off-the-shelf computing
hardware and orthogonal design of the system of parallel computing, parallel storage,
and the parallel network load make the system performance, network performance,
storage performance to be scalable independent, and to be optimized data processing
performance on the three dimensions.
The data processing layer, task scheduling layer and user composition layer
achieve on demand scalability on system function, that not only to increase the number of new satellite remote sensing data processing algorithms and functions, but also

Design and Implementation of a Scalable General High Performance

373

bring out a variety of composition of the basic processing functions. Users can customize remote sensing data processing to meet user custom needs of data processing.
The system has a completely open platform due to the use of a variety of commercial off-the-shelf advanced high performance computing technology and advanced
software design technology. Users can facilitate the balanced expansion of the system
of processing, storage and network capacity to improve the performance of the process and load their own business functions of a new satellite remote sensing data by
inserting the appropriate data processing module based on certain rules to extend
system processing function without modifying the system hardware and software.

3 GHIPS Implementation Case
Based on above research, The new version of “Beijing-1” remote sensing satellite
ground processing system is implemented on GHIPS, which make use of NAS storage
systems, Gigabit Ethernet, and computing servers hardwares, PVFS2,Parallel Virtual
File System Version 2,MPICH2,an implementation of the Message-Passing Interface,
openPBS, open source version of the Portable Batch System, OSworkflow, a pure
Java open-source workflow engine for technical users, and JAVA RMI, Remote
Method Invocation.
The system include system geometric correction, geometric correction based on
control point and Digital Elevation Model (DEM), and other functions more than a
dozen modules of serial and parallel processing, more than 30 kinds of business of
composition of modules, and more business can be composed in accordance with the
requirements of users.
The cluster consists of 16 SMP PC computing nodes connected by 24 port gigabit
Ethernet switch. The computing node has two Intel Xeon 2.4GHz CPU and 1G Bytes
local memory. The eight nodes are used for new version based on GHIPS; the other
eight nodes are used for previous version of “Beijing-1” remote sensing satellite
ground processing system.
The test data processing includes raw data management, band registration, MTF
correction. The system shows about 20% performance improvement over the previous
version with using the local file system and custom scheduling system on the same
hardware. The test data and result are showed in table 1.
Table 1. New version based on GHIPS versus previous version

Dataset Name

Data Row Number

time-consuming(second)
New version

dmc+4bj1L104081701
60041_160155_0
dmc+4bj1L104081880
32203_032703_0
dmc+4bj1L104081880
32203_032703_0
dmc+4bj1L104081910
20724_020844_0

Previous version

5000~14983

777

851

10000~19983

711

896

50000~59983

718

931

1~9984

654

903

374

J. Li and D. Liu

4 Conclusions
As many remote sensing satellite ground processing applications for computing have
high demand for processing powers, it is critical to have a platform that readily supply
such computing powers with the ease of use.
In this paper we propose the architecture of GHIPS. With using of a variety of commercial off-the-shelf advanced high performance computing technology and advanced
software design technology, users can facilitate the balanced expansion of the system of
processing, storage and network capacity to improve the performance of the process and
load their own business functions of a new satellite remote sensing data by inserting the
appropriate data processing module based on certain rules to extend system processing
function without modifying the system hardware and software.
Future work is divided between application issues and infrastructure issues. The
application issues include the integration new satellite remote sensing data processing
and basic algorithms. The infrastructure issues are studying how parallelization at
various hardware and software levels can be used for maximization of performance
and researching corresponding algorithms parallel model.

References
1. Chao-Tung, Y., Chih-Li, C., Chi-Chu, H., Frank, W.: Using a BEOWULF cluster for a remote sensing application. In: Proceedings of the 22nd Asian Conference on Remote Sensing, Singapore, pp. 233–238 (2001)
2. Li, G., Liu, D.: Key Technologies Research on Building a Cluster-Based Parallel Computing System for Remote Sensing. In: International Conference on Computational Science,
vol. (3), pp. 484–491 (2005)
3. Zhang, W., Liu, D., Li, G., Zhang, W.: Special Task Scheduling and Control of Cluster Parallel Computing for High-Performance Ground Processing System. In: Alexandrov, V.N.,
van Albada, G.D., Sloot, P.M.A., Dongarra, J. (eds.) ICCS 2006. LNCS, vol. 3993, pp. 17–
23. Springer, Heidelberg (2006)
4. Hawick, K.A., Maciunas, K.J., Vaughan, F.A.: DISCWorld: A Distributed Information Systems Control System for High Performance Computing Resources. DHPC Technical Report
DHPC-014, Department of Computer Science, University of Adelaide (1997)
5. Yang, C.T.: Using a Beowulf Cluster for a Remote Sensing Application. In: Proceedings of
the Asian Conference on Remote Sensing (ACRS), Singapore (2001)
6. Sterling, T.L., Salmon, J., Backer, D.J., Savarese, D.F.: How to Build a Beowulf: A Guide
to the Implementation and Application of PC Clusters 2nd Printing. MIT Press, Cambridge
(1999)

