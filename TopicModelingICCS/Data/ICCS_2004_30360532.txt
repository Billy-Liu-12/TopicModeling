Query Execution Algorithm in Web
Environment with Limited Availability of
Statistics
Juliusz Jezierski and Tadeusz Morzy
Poznan University of Technology
Piotrowo 3a, 60-965 Poznan, Poland
{jjezierski, tmorzy}@cs.put.poznan.pl

Abstract. Traditional static cost-based query optimization approach
uses data statistics to evaluate costs of potential query execution plans
for a given query. Unfortunately, this approach cannot be directly applied
to Web environment due to limited availability of statistics and unpredictable delays in access to data sources. To cope with lack or limited
availability of statistics we propose a novel competitive query execution
strategy. The basic idea is to initiate simultaneously several equivalent
query execution plans and measure dynamically their progress. Processing of the most promising plan is continued, whereas processing of remaining plans is stopped. We also present in the paper results of performance evaluation of the proposed strategy.

1

Introduction

There is increasing interest in query optimization and execution strategies for
Web environment that can cope with two speciﬁc properties of this environment:
lack or limited availability of data statistics and unpredictable delays in access to
data sources. Typically, in Web environment query processing parameters may
change signiﬁcantly over time or they may be simply not available to query engines. Web sites that disseminate data in Web environment in the form of ﬁles,
dynamically generated documents and data streams usually do not allow access
to internal data statistics. The second speciﬁc property of Web environment is
unexpected delay phenomenon in access to external data sources. Such delays
may cause signiﬁcant increase of system response time. They appear due to variable load of network devices resulting from a varying activity of users, and also,
due to breakdowns. As a result, traditional static optimization and execution
techniques cannot be directly applied to Web environment.
In the paper, we present the novel competition strategy of query execution
in Web environment that solves or reduces limitations of previous solutions (e.g.
[1,2,3,4]). Our approach consists in simultaneous execution of a set of alternative
query execution plans for a given query. The system monitors execution of these
plans, and the most attractive plans are promoted, while execution of the most
expensive plans is canceled. Final query result is delivered to the user by the
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3036, pp. 532–536, 2004.
c Springer-Verlag Berlin Heidelberg 2004

Query Execution Algorithm in Web Environment

533

plan that has won the competition according to rules deﬁned by the strategy
implementation.

2

Competition Strategy of Query Execution

In traditional database systems query speciﬁed by user is transferred to the query
optimizer, which chooses optimal query execution plan (QEP) during query compilation. The query optimization process depends on: (1) a cost function used to
evaluate the cost of a query, (2) the search space of all possible QEPs for a given
query, and (3) a search strategy used to penetrate the search space of QEPs.
Final QEP generated by the query optimizer is static and it does not change
during its execution.
Our query execution strategy is based on the idea that the query optimization process should be continuous and interactive, which means that the search
space of QEPs should be also analyzed during query execution. Query optimizer
improves the initial QEP by taking into account data statistics gathered during query execution. Formally, the competition strategy of query execution can
be deﬁned as a triple: CSQE = {PGR, CC FR}, where: PGR - rules of plan
generation, CC - competition criteria, FR - feedback rules.
PGR denotes a set of rules used to generate QEPs participating in the competition. The important issue is the proper selection of initial QEPs. On the
one hand, in order to reduce the overhead related to simultaneous processing
of many QEPs, it is necessary to restrict the number of initiated plans. On the
other hand, if the number of initiated plans is too small, then, the adaptation to
changing conditions of runtime environment is automatically restricted. CC denotes competition criterion used to evaluate attractiveness of diﬀerent QEPs (i.e.
response time, evaluation cost). Proper deﬁnition of CC allows to limit overhead
related to simultaneous processing of many plans by pruning ineﬀective QEPs.
FR denotes a set of rules that control the competition process (e.g., start new
plans). FR allows to adapt query execution process accordingly to changes of
runtime environment parameters, e.g., delays in access to data sources.
The competition strategy has an ”open” character and it can be implemented
in many diﬀerent ways. To illustrate the approach, we implemented greedy algorithm (abbreviated as GA), which implements our strategy. We assume no
availability of statistics. All necessary data are dynamically established or estimated during query execution.

3

Experimental Evaluation

To demonstrate the practical relevance and universality of our strategy, we compare it with simple ”brute force” strategy (abbreviated as BFS), which generate
all possible query execution plans for a given query, and to comparison we have
taken into account the average value of their results. We considered two basic
performance evaluation criteria: system response time and utilized CPU time.
Two main goals of experiments were: analysis of the impact of transfer rates

534

J. Jezierski and T. Morzy

and initial delays on performance evaluation criteria. Arbitrary, three transfer
rates were assumed for experiments: 20Kbytes/s (slow), 200Kbytes/s (normal)
and 2Mbytes/s (fast). The algorithm was implemented in Java 1.4 and experiments were computed on PC Intel 1000Mhz, 512MB RAM under control of MS
Windows 2000. We analyzed the cycle SQL query Q1 given below:
select * from A, B, C where A.b=B.a and B.c=C.b (Q1)

The aim of the ﬁrst series of experiments was comparison of our strategy with
BFS in case where costs of potential query execution plans signiﬁcantly diﬀer
from each other. Thus, we generated data with large range of values of join
selectivity coeﬃcients: sel(A✶B)=2∗10−3 , sel(A✶C)=2∗10−4 and sel(B✶C)=2∗
10−5 . The volumes of the sources we assumed as follows: A–800KB(5∗103 tuples),
B–1500KB(104 tuples), C–2000KB(2 ∗ 104 tuples).

GA 2Mbs

BFS 2MBS

GA 200Kbs

GA 2Mbs

BFS 200Kbs

35

18

30

16

GA 200Kbs

GA 20Kbs

BFS

14
12
CPU [s]

elapsed [s]

25
20
15

10
8
6

10

4

5

2
0

0
0

2

4

6
8
10
delay of source C [s]

12

14

0

16

2

4

6
8
10
delay of source C [s]

12

14

16

Fig. 1. Elapsed time of Q1 execution ver- Fig. 2. Utilized CPU time of Q1 execution
sus initial delay of source C
versus initial delay of source C

2

2

C

2

1

1
B

A

Fig. 3. QEP1 of Q1

A

1
C

B

Fig. 4. QEP2 of Q1

A

B

C

Fig. 5. QEP3 of Q1

Figure 1 presents the system response time for the query Q1 versus initial
delay of the source C and diﬀerent values of the transfer rate. The cost ranking
of QEP for Q1 is the following (from cheapest to the most expensive): 1. QEP1,
2. QEP2, 3. QEP3 (Fig. 3, 4, and 5). Most attractive plans require access to
source C in the ﬁrst step. For 2Mbytes/s transfer rate, we observe that the
algorithm switches from QEP1 to QEP2 for 8 seconds delay. This switch appears
when delay in access to source C is so long that execution of the subplan 1
of QEP3 is ﬁnished before the algorithm collects statistically reliable samples
from executions of subplan 1 of QEP2 and subplan 1 of QEP3. From the ﬁgure
follows, that the GA outperforms BFS strategy before switch from QEP1 to
QEP3 occurred, and longer response time after the switch. For 200Kbytes/s
transfer rate, response time provided by the algorithm is always better than

Query Execution Algorithm in Web Environment

535

response time provided by BFS. For 20Kbytes/s transfer rate, we do not observe
any switch. QEP1 always wins the competition. Moreover, for the whole range
of delays for the source C, the GA outperforms BFS. However, for readability of
Fig.1, we omit in the ﬁgure the results for 20Kbytes/s transfer rate.
Figure 2 presents utilized CPU time (i.e. overhead) versus initial delay of
source C and diﬀerent values of the transfer rate. The overhead depends on delay in access to most attractive sources. Increasing delay in data transfer from
the source C delays a moment of competition termination, and, thus, extends
also execution time of QEPs, belonging to a competition group, and CPU consumption. The largest overhead is observed for 2Mbytes/s transfer rate, while the
smallest one is observed for 20Kbytes/s transfer rate. This phenomenon can be
explained as follows: for a given delay of source C, in case of higher transfer rate,
a large part of unattractive subplans (i.e. subplan 1 of QEP3) will be executed
until the competition process stops their processing. In case of lower transfer
rate, unattractive subplans consume less CPU since the algorithm cancels their
processing ”earlier”. Notice that for 2Mbytes/s and 200Kbytes/s transfer rates,
if delay of the source C is rather small, i.e. does not exceed several seconds,
GA is cheaper than the BFS. For 20kbytes/s transfer rate, GA is several times
cheaper than the BFS.
We also performed a series of experiments, which tested diﬀerent transfer
rates for other data sources. If attractive data sources transfer data with higher
rate than other sources, then the competition overhead decreases. We also tested
the performance of the GA with the 5-way join query (Q2). In this case, the GA
produced query result few times faster than the BFS. It can be explained as
follows: the query Q2 is more complex than Q1, and, therefore, a set of QEPs
for Q2 is much larger than that of Q1. Therefore, an average cost of these
plans taken into account in the comparison, is relatively large, whereas the GA
generated nearly optimal QEP.

4

Summary

In this paper, we proposed novel strategy of dynamic query optimization and execution in Web environment, which cope with limited availability of data statistics
and unexpected delay in access to data sources. We evaluated our strategy by a
set of experiments for diﬀerent transfer rates and diﬀerent delay scenario, and
proved its feasibility. As the experiments show, our strategy is especially appropriate for small and medium transfer rates (20Kbytes/s and 200Kbytes/s). The
strategy is eﬃcient also for large transfer rate (2Mbytes/s) and relatively small
delays (several seconds) in access to attractive sources. The algorithm prefers
bushy QEPs, which, when compared to linear QEPs produced by traditional
static cost-based optimization algorithms provide usually better response times.

536

J. Jezierski and T. Morzy

References
1. Urhan, T., Franklin, M.J., Amsaleg, L.: Cost based query scrambling for initial
delays. In: Proc. ACM SIGMOD Conf., June 2-4, 1998, Seattle, USA, 130–141
2. Kabra, N., DeWitt, D.J.: Eﬃcient mid-query re-optimization of sub-optimal query
execution plans. In: Proc. ACM SIGMOD Conf., June 2-4, 1998, Seattle, USA,
ACM Press (1998) 106–117
3. Avnur, R., Hellerstein, J.M.: Eddies: Continuously adaptive query processing. In:
Proc. ACM SIGMOD Conf., May 16-18, 2000, Dallas, USA, 261–272
4. Viglas, S., Naughton, J.F., Burger, J.: Maximizing the output rate of multi-way
join queries over streaming information sources. In: Proc. VLDB Conf., September
9-12, 2003, Berlin, Germany, Morgan Kaufmann (2003) 285–296

