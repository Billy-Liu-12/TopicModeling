A New Data Compression Technique for Event
Based Program Traces
Andreas Kn¨
upfer
Center for High Performance Computing
Dresden University of Technology, Germany
knuepfer@zhr.tu-dresden.de

Abstract. The paper presents an innovative solution to the problem
of the very huge data sets that are regularly produced by performance
tracing techniques – especially on HPC programs. It designs an adapted
data compression scheme that takes advantage of regularities frequently
found in program traces. Algorithms to reveal repetition patterns in a
programs call structure and run time behavior are discussed in detail,
solutions to some problems arising on practical application are addressed
as well. Two examples demonstrate the capabilities of the approach and
document its behavior. Finally, some thoughts are given regarding how
the patterns revealed in the process of data compression may assist the
automatic analysis of traces.

1

Introduction

While tracing is a well established method of program performance analysis,
there is one critical part regularly encountered: the amounts of data generated.
Of course, this problem is already addressed by instrumentation procedures.
Furthermore, trace libraries do pay close attention on eﬃcient encoding of trace
data. In any case fact is that trace data sets grow bigger and bigger. On the
one hand, this is caused by faster processors that produce more trace events
per time. On the other hand, the amount of trace data is multiplied by the
number of processes that work together to solve a problem. Especially in the High
Performance Computing (HPC) ﬁeld the trend to massive parallel computation
causes immense trace data sizes.
At the same time the extractable information of a trace does not necessarily
increase along with its size. So the question arises what the actual information
is inside a trace. The answer to that question is tricky. But it is easy to see
what non-information is included: ever repeating sequences produced by program
loops over some essential parts of a program.
Such regularities are exploited to construct a data compression method specially suited for program traces. Of course, general data compression methods are
being utilized for program traces, e.g. gzip and others, but compression ratios1
for traces achieved by them grow rarely over a factor of ﬁve to ten.
1

Compression ratio is deﬁned as K := original Size / compressed Size.

P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2659, pp. 956–965, 2003.
c Springer-Verlag Berlin Heidelberg 2003

A New Data Compression Technique for Event Based Program Traces

957

The new approach was motivated by the work [2,3,4] about analysis and
visualization of very large and highly parallel program traces of the local research
group – especially in conjunction with the adaption of VAMPIR towards the
ASCI project.

2

Construction of Meta-events

The given approach notices only events that denote function calls (enter events)
or function returns (leave events) and ignores any other events like sending and
receiving messages. Furthermore, the method takes only the current thread of a
parallel program into account – thus for now it can be assumed that it has to
deal with sequential programs only.

2.1

Model

By the restriction to enter and leave events – the most common classes of events
in general – additional properties are assured: Following the procedural programming paradigm for every enter event e there is exactly one associated leave
event l. This relation is denoted as e ∼ l. Given that the relation < expresses
the order of events in terms of time, for two pairs of associated events e ∼ l and
f ∼ g the equivalence
e<f <l⇔e<g<l

(1)

is implied. This is called the stack property since it is caused by the LIFO scheme
of the function calls. Now meta-events are deﬁned as follows:
Deﬁnition 1. A collection of n ∈ N consecutive events m := {e0 , e1 , ...en−1 } is
called a meta-event of order n if the implication ei ∈ m ⇒ ∃∗ ej ∈ m : ei ∼ ej is
satisﬁed for every i, 0 ≤ i < n.
With this deﬁnition in mind it is easy to put up the three rules for constructing
meta-events – see also Fig. 1:
1. The pair of an enter event e and a leave event l ∼ e immediately following
makes up a meta-event of order 2.
2. A meta-event m of order n, an enter event e immediately before m and a
leave event l ∼ e immediately following m make up a meta-event m of order
n + 2.
3. Two meta-events m and m of order n and n make up a new meta-event of
order n + n if there are no events or meta-events between both.

958

A. Kn¨
upfer

Fig. 1. Transformation from events to meta-events

2.2

Implementation

The ﬁrst step for an application of the above scheme is to reveal the association
∼ between the single events. In fact, it is suﬃcient to be able to refer to the
enter event e ∼ l that is associated with any given leave event l. This can be
achieved very easily by extending the call stack representation of a trace library.
The second step is the application of the three construction rules for metaevents to the trace buﬀer – this works quite straight forward and it is done best
by in-place substitution. The transformation algorithm has to traverse the event
records in the order of creation and has to act only on leave records. For every
possible situation exactly one of the three construction rules can be applied,
compare Fig. 1:
1. If the current leave record references to the previous record as its associated
one, then apply construction rule (1) – compare Fig. 1, (enter C, leave C).
2. If between the current leave record and its associated enter record there is
exactly one meta-event record, apply construction rule (2) – compare Fig. 1,
(enter B, call E, leave B). Note that by that time all leave records prior to
the current one have already been processed.
3. If there are l ≥ 2 meta-events between associated events, apply construction
rule (3) exactly l−1 times – compare Fig. 1, (enter B, call C, call D, leave B).
After that branch 2) will be applicable.
Out of practical considerations it is suggested that the algorithm shall raise
the order of the created meta-events only up to a certain order N but not further.
This implies that the sequence of events is transformed into a sequence of events
and meta-events but in general not meta-events only!

A New Data Compression Technique for Event Based Program Traces

2.3

959

Naming

It is customary in tracing to refer to functions by tokens. A token is an integer
number that can be stored with a ﬁxed amount of bits. There is a bijective
relation between the function set and the tokens set.
This naming scheme can be extended to meta-events as well, it might even
share the same token set. The deﬁnition of a meta-event token must take the
way of construction (rule 1, 2, 3) into account and the thereby referenced other
events/meta-events resp. their tokens.

3

Extending Meta-events to Event-Patterns

Up to now the algorithm recognizes repetitions in a function call structure. In a
second stage similarities in terms of execution times are to be detected: that is
a meta-event that appears multiple times with “similar” vectors of timestamps.
3.1

Comparison of Timestamp Vectors

The timestamp vector of a meta-event of order n is the vector
(t0 , t1 , ...tn−1 ) ∈ Rn+ , ti ≤ ti+1 ∀i ∈ [0, n − 2]

(2)

of dimension n that simply contains the timestamps of the atomic events. In
order to reveal similarity2 it is convenient to transform a timestamp vector into
the equivalent representation of a time diﬀerences vector together with the very
ﬁrst time stamp value t0 :
(t0 ; d0 , d1 , ...dn−2 ) ∈ R+ × Rn−1
+ , di := ti+1 − ti ≥ 0 ∀i ∈ [0, n − 2].

(3)

Now it is very simple to recognize two time diﬀerences vectors d := (d0 , ...dn−2 )
and e := (e0 , ...en−2 ) as similar if all the corresponding vector components are
similar. This can be tested by an absolute measure ai := |di − ei | or by a relative
measure ri := |1 − deii |. The measure for the whole vectors is taken as maximum
over all components mabs := max0≤i<n−1 (ai ) and mrel := max0≤i<n−1 (ri ). The
suggestion is to combine the two ways of measuring: the two vectors are rated
similar :⇔ mabs ≤ Tabs ∨ mrel ≤ Trel

(4)

with two thresholds Tabs and Trel .
3.2

Event-Patterns

Where a meta-event represents several successive atomic events an event-pattern
also respects the time behavior of the underlying part of a program.
2

Testing for equality would be to strict.

960

A. Kn¨
upfer

Deﬁnition 2. An event-pattern is deﬁned as a 4-tuple of a meta-event of order
n, a time diﬀerences vector (the representative vector) of dimension n − 1 and
the the absolute and relative thresholds tabs ≤ Tabs and trel ≤ Trel for time
diﬀerences vectors.
The transformation of meta-events into event-patterns is performed subsequent
to the transformation of events into meta-events, i.e. it is only performed for the
meta-events of maximal order. For each of the maximum-order meta-events the
according time diﬀerences vector is compared with the representative vectors of
all (so far deﬁned) event-patterns based on the same meta-event. If similar eventpatterns are found choose the best ﬁt, otherwise deﬁne a new event-pattern with
the given time diﬀerences vector as the new representative vector.
3.3

Over-All Data Compression Ratio

In order to estimate the over-all data compression ratio trace data sizes are to be
compared: First there is always a (relative small) number of general deﬁnition
records that shall be ignored here: lD := 0 bytes. For classic enter or leave events
there is a ﬁxed amount of lE := 18 bytes storage space required3 . So the total
size for a trace ﬁle with e events results in
L0 := ld + lE · e bytes.

(5)

An event-pattern is stored with lP := 30 bytes regardless of its order n. For every
event-pattern a deﬁnition record is required that needs lEP := 26 + 8 · n bytes.
That event-pattern references a tree of meta-event deﬁnitions. A single metaevent deﬁnition record requires lM E := 23 bytes. The number of meta-event
deﬁnitions k depends on the order n of the meta-event that forms the root of
the tree and is
k :=

(log2 n) − 1 ≈ log2 n
minimum
.
n−1≈n
maximum/average

(6)

The total trace ﬁle size of a new-style trace ﬁle is then
L1 := ld + lM E · k + lEP + lP ·

e
.
n

(7)

With the sizes L0 (e) and L1 (e, n) the compression ratio achieved by the data
compression approach can be predicted as
K :=

L0
lE · e
=
L1
lM E · k + lEP + lP ·

e
n

,

(8)

see Fig. 2. For arbitrary high number of events and k = const that results in
K :=
3

lE
3
L0
−→
· n = · n (e → ∞, n = const),
lP
5
L1

All record sizes refer to the VTF3 binary trace ﬁle format [16].

(9)

A New Data Compression Technique for Event Based Program Traces
200

200

3/5*n
avg/max
min

150

150

100

100

50

50

0

961

3/5*n
avg/max
min

0
1 64128

256

512
order n, e= 100000

1024

0

20000

40000

60000

80000

100000

#events e, n= 128

Fig. 2. Impact of the event count e and the maximum order n on the compression
ratio K. This shows idealistic behavior for a single repeated event-pattern

see Fig. 2b. The inﬂuence of n (Fig. 2a) is more interesting: it occurs that K
grows with n up to a certain level. For higher values of n and e = const the
compression ratio declines. The optimal n grows with the number of events e.
Thus K can be increased arbitrary by increasing n as long as e is big enough!

4

Further Details

There are two issues that are necessary to analyze at this stage. Both deal with
problems that arise only in certain situations but which can destroy the usability
of the whole approach, if not handled adequately.
4.1

Correction Pairs

The ﬁrst problem is related to the limited regularity of execution times: Even
if a program shows the most regular execution times there is always a source
of irregularity present: the operating systems task scheduler. Without special
precautions the algorithm would produce a set of event-patterns for an over and
over repeated meta-event: one event-pattern shows the undisturbed execution
of the meta-event, all the others have one or more components of the time
diﬀerences vector inﬂuenced by the disturber. The data compression algorithm
works nevertheless but suﬀers a higher deﬁnition overhead.
The solution to this problem is quite simple since a disturbed time diﬀerences
vector does not diﬀer much from the undisturbed version but in one (or few)
components: the solution is to store only index and values of the disturbed
components (called a correction pair) and refer to an existing event-pattern for
all remaining ones.
4.2

Name Spaces

The second problem for general usability is connected with parallel programs.
Unlike the classic approach tokens for meta-events and event-patterns must be

962

A. Kn¨
upfer

supplied dynamically – it is impossible to provide a token for every possible
meta-event. This means tokens have to be generated on demand. It is most
undesirable to synchronize token generation among multiple processes so every
process will create an own local set of tokens and in general these local sets will
be incompatible with each other.
This can be corrected easily by a simple token translation: After all local
tokens are known global tokens can be deﬁned, then all occurrences of local
tokens are replaced by their global counterparts in a post-processing step4 . This
little extra eﬀort prepares the compression algorithm to deal with non-sequential
programs.

5

Examples

Now, two examples are presented in order to show the real world behavior of
the algorithm. The examples shall address very regular and very irregular cases.
For both the well known quick sort algorithm is utilized.
For the very regular case quick sort is called for sorting a rather small array
as the body of a large loop, where the data to be sorted is always identical. This
example can be understood as a general loop with anything in the body, where
’anything’ is the same for all iterations. Figure 3 shows the compression ratios
achieved for the regular example: K goes up to 45 where actually 4.5 MB trace
data is reduced to 100 KB! The charts compare nicely to the theoretical result
shown in Fig. 2. This plot is less smoothly because here the the given value for
N is an upper bound and not necessarily reached.
The second example uses quick sort to have a very large array of random
data sorted once. This produces a huge and complex recursive call structure.
Such a behavior might arise and is a rather bad case but after all there is still

50

50

e=130002

45

N=50
N=150
N=250

45

40

40

35

35

30

30

25

25

20

20

15

15

10

10
5

5

0

0
0

50

100

150
200
max. order N

250

300

350

0

20000 40000 60000 80000 100000 120000
#events e

Fig. 3. Regular example: Inﬂuence of maximum order N and event count e on K
4

This can be combined with the merging of multiple process traces.

A New Data Compression Technique for Event Based Program Traces
8

8

e=147693

7

7

6

6

5

5

4

4

3

3

2

2

1

1

0

963

N=10
N=20
N=60

0
0

20

40

60

80

100

0

20000

max. order N

40000

60000

80000 100000 120000

#events e

Fig. 4. Irregular example: Inﬂuence of maximum order N and event count e on K
1

N=50
N=150
N=250
N=0

0.8

1

0.6

0.6

0.4

0.4

0.2

0.2

0

N=10
N=20
N=60
N=0

0.8

0
0

20000 40000 60000 80000 100000 120000
#events e

0

20000 40000 60000 80000 100000 120000
#events e

Fig. 5. Run times of regular and irregular experiments as measured on a PC AMD
Athlon 1.4 GHz, disk writing performance ≈ 20 MB/s

some kind of regularity left5 . In Fig. 4 the charts of K depending on N and e are
given for the irregular case. Of course, the result is not as good as in Fig. 3 but
it reveals the ability of the algorithm to cope well with non-regular situations!
And most important there are never values of K < 1.0!
The run time consumed by the trace data compression algorithm might not
be as important if it is performed post mortem. But the following ﬁgures shall
proof that the algorithm can be used at trace time as well, i.e. trace data is
compressed on-the-ﬂy, no intermediate non-compressed output is generated at
all. In Fig. 5a the run time durations are given for the experiments shown in
Fig. 3a, Fig. 5b resp. for all experiments of Fig. 4a. The case N = 0 which means
classical tracing without any compression is shown for comparison.
Obviously, the compression algorithm does not necessarily suﬀer a penalty
for the increased computational eﬀort. In fact, in the actual test cases it is faster
than the classic tracing most of the time! This can be explained by the smaller
amount of data to be written to disk after on-the-ﬂy compression. Since this
eﬀect is heavily dependent on processor speed and disk I/O performance neither
5

The worst case would be something like choosing the next function to call at random
which is assumed to never ever happen in real life.

964

A. Kn¨
upfer

classic tracing nor the version with on-the-ﬂy compression can be said to be
faster than the other in general.

6

Future Plans

Current work in connection with meta-events and event-patterns is focused on
the analysis part of the performance investigation process. This is supposed to
transfer the advantage of much smaller trace ﬁles to the tools that read and
handle the data as well as to introduce the option to deal with meta-events and
event-patterns directly.
So far there has only been discussion about compression but not about the
decompression. Though, with a basic understanding of the compression scheme
the according decompression is simple and works for every meta-event/eventpattern by itself. This is especially useful when accessing portions of a trace. A
most elegant way to examine a compressed trace ﬁle would be to extract only
the (few) event-patters that relate to the trace portion of interest! Thus the
compression provides not only an advantage in terms of storage space but also
in terms of access speed and response time during user interaction.
Another very interesting approach is using meta-events like more abstract
functions, i.e. do not use functions as smallest entities but meta-events of certain
(variable) sizes. This provides additional abstraction layers for trace analysis
where so far there are merely two: statistics and fully detailed reproduction.

7

Related Work

Everything that is presented here is covered much more comprehensively in
the German language diploma thesis [9]. There connections are drawn to string
pattern matching [1,6,10,12], information encoding and general data compression
algorithms [5,11,15] especially the Lempel-Ziv family.
Furthermore, for requirements and demands of trace analysis software tools
[7,8,13,17,18] are referenced.
[14] presents another very interesting data compression scheme for parallel
program traces that is more or less orthogonal to the one presented here.

References
1. Jun-ichi Aoe. Computer Algorithms: String Pattern Matching Strategies. IEEE
Computer Society Press, Los Alamitos, 1994.
2. H. Brunst, H.-Ch. Hoppe, and W.E. Nagel. Group Based Performance Analysis
for Multithreaded SMP Cluster Applications. In Proceedings of Euro-Par2001,
Manchester, UK, volume 2150 of LNCS, page 148ﬀ. Springer-Verlag Berlin Heidelberg New York, August 2001.
3. H. Brunst, H.-Ch. Hoppe, W.E. Nagel, and M. Winkler. Performance Otimization
for Large Scale Computing: The Scalable VAMPIR Approach. In Proceedings of
ICCS2001, San Francisco, USA, volume 2074 of LNCS, page 751ﬀ. Springer-Verlag
Berlin Heidelberg New York, May 2001.

A New Data Compression Technique for Event Based Program Traces

965

4. H. Brunst, W.E. Nagel, and S. Seidl. Performance Tuning on Parallel Systems: All
Problems Solved? In Proceedings of PARA2000 - Workshop on Applied Parallel
Computing, volume 1947 of LNCS, pages 279–287. Springer-Verlag Berlin Heidelberg New York, June 2000.
5. T.H. Cormen, C.E. Leiserson, and R. L. Rivest. Introduction to Algorithms. MIT
Press, 1990.
6. G. Davies and S. Bowsher. Algorithms for Pattern Matching. Software - Practice
and Experience, June 1986.
7. R. Jain. The Art of Computer Systems Performance Analysis. John Wiley & Sons,
Inc., 1991.
8. R. Klar et al. Messung und Modellierung paralleler und verteilter Rechnersysteme.
B.G.Teubner, Stuttgart, 1995.
9. A. Knuepfer. Analyse von Programmspuren: Entwurf und Implementierung eines
eﬃzienten Algorithmus zur Datenreduktion. Technical Report ZHR-R-0202, Zentrum f¨
ur Hochleistungsrechnen, TU-Dresden, June 2002.
10. D.E. Knuth. The Art of Computer Programming: Fundamendal Algorithms, volume 1. Addison Wesley Longman, zweite edition, 1997.
11. D.E. Knuth. The Art of Computer Programming: Sorting and Searching, volume 3.
Addison Wesley Longman, zweite edition, 1998.
12. D.E. Knuth, J.H. Morris, and V.R. Pratt. Fast Pattern Matching in Strings. SIAM
Journal of Computing, 06 1977.
13. B. Mohr. Ereignisbasierte Rechneranalysesysteme zur Bewertung paralleler und
verteilter Systeme. VDI Verlag, 1992.
14. O.Y. Nickolayev, P.C. Roth, and D.A. Reed. Real-time statistical clustering for
event trace reduction. The International Journal of Supercomputer Applications
and High Performance Computing, 11(2):144–159, Summer 1997.
15. R. Sedgewick. Algorithmen. Addison Wesley, 1991.
16. S. Seidl. VTF3 - A Fast Vampir Trace File Low-Level Library. personal communications, May 2002.
17. F. Wolf. EARL – Eine programmierbare Umgebung zur Bewertung paralleler
Prozesse auf Message-Passing-Systemen. Technical report, Forschungszentrum
¨
J¨
ulich GmbH, June 1998. JUL-3551.
18. F. Wolf and B. Mohr. Automatic Performance Analysis of SMP Cluster Applications. Technical report, Forschungszentrum J¨
ulich GmbH, August 2001. FZJZAM-IB-2001-05.

