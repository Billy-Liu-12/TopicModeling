Procedia Computer Science
Volume 80, 2016, Pages 428–438
ICCS 2016. The International Conference on Computational
Science

D-STHARk: Evaluating Dynamic Scheduling of Tasks in
Hybrid Simulated Architectures∗
S´avyo Toledo1 , Danilo Melo1 , Guilherme Andrade2 , Fernando Mour˜ao1
, Aniket Chakrabarti3 , Renato Ferreira2 , Srinivasan Parthasarathy3 , and
Leonardo Rocha1
1

Universidade Federal de S˜
ao Jo˜
ao del Rei, S˜
ao Jo˜
ao del Rei, Minas Gerais, Brasil
{danilo,savyo,fhmourao,lcrocha}@ufsj.edu.br
2
Universidade Federal de Minas Gerais, Belo Horizonte, Minas Gerais, Brasil
{gnandrade,renato}@dcc.ufmg,br
3
Dept. of Computer Science and Engineering, The Ohio-State University
chakrabarti.14@osu.edu,srini@cse.ohio-state.edu

Abstract
The emergence of applications that demand to handle eﬃciently growing amounts of data
has stimulated the development of new computing architectures with several Processing Units
(PUs), such as CPUs core, graphics processing units (GPUs) and Intel Xeon Phi (MIC). Aiming
to better exploit these architectures, recent works focus on proposing novel runtime environments that oﬀer a variety of methods for scheduling tasks dynamically on diﬀerent PUs. A main
limitation of such proposals refers to the constrained system conﬁgurations, usually adopted
to tune and test the proposals, since setting more complete and diversiﬁed evaluation environments is costly. In this context, we present D-STHARk, a GUI tool for evaluating Dynamic
Scheduling of Tasks in Hybrid Simulated ARchitectures. D-STHARk provides a complete
simulated execution environment that allows evaluating dynamic scheduling strategies on simulated applications and hybrid architectures. We evaluate our tool by simulating the dynamic
scheduling strategies presented in [3], using the same architecture and application. D-STHARk
was able to achieve the same conclusions originally reported by the authors. Moreover, we performed an experiment varying the number of coprocessors, which was not previously veriﬁed
due to lack of real architectures, showing that we may reduce the energy consumption, while
keeping the same performance.
Keywords: Dynamic Scheduling, Hybrid Simulated Architectures

∗ This

428

work was partially supported by CNPq, CAPES, Fapemig, and INWEB.
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.395

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

1

Savyo

Introduction

Currently, a new era is characterized by the massive data generation and the development of
new technologies. The continuous data growth, associated with more sophisticated processing
in diﬀerent areas of knowledge, has been pushing for signiﬁcant advances in computing architectures, reﬂecting in more eﬃcient storage systems, as well as the use of diﬀerent types of
processing units (PUs), in the so-called hybrid systems. An example of these new architectures
are computers with multiple processors (multicore architecture) and diﬀerent coprocessors. Two
of the most popular coprocessors are the graphics processing units (GPUs) [12] and Intel Xeon
Phi (MIC) [13]. These coprocessors have emerged as alternative architectures as the golden
standard of frequency scaling broke down in the ﬁrst decade of the century. They consist of
massively parallel architectures privileging ALU operations over I/O and control ﬂow operations. The end result is that coprocessors may yield very high compute density if certain criteria
are matched to the application and its data.
Therefore, it is becoming essential for applications from diﬀerent domains to be able to
explore all available PUs in a coordinated and eﬃcient way, while taking full advantage of their
processing capabilities. Several runtime environments have been proposed in the literature
aiming to make the use of diﬀerent PUs transparent to developers [7, 6]. Among the main
methods provided by these environments, we highlight task schedulers, which are responsible
for adequately distributing various tasks that compose an application to the available PUs. The
task schedulers can be: (1) static [2], on which the characteristics of the tasks are evaluated
along with the capabilities of diﬀerent PUs in a preprocessing stage, using global information of
the application; and (2) dynamic [4], on which this evaluation is done at runtime, considering
a limited view of the execution of entire application and thus a more challenging scenario.
From many proposed dynamic schedulers in the literature, most of them are evaluated in restricted real system conﬁgurations, composed of reduced number of PUs (e.g., some CPU cores,
one or two GPUs and/or one or two MICs) due to high costs associate with creating more
complete evaluation environments. For example, the price of an Intel R Xeon PhiTM 7120P
Henhexaconta-Core Socket PCI Express x16 Coprocessor, 1.24 GHz is almost $5,000. As a
consequence, the conclusions achieved by evaluating the scalability of these proposals might
be limited. Moreover, the performance of these strategies in hybrid architectures composed by
many PUs is unknown. In this context, a simulating environment on which it is possible to
conﬁgure diﬀerent hybrid architectures, composed by an unlimited number of diﬀerent PUs, in
order to evaluate dynamic scheduling strategies, becomes an important contribution and it is,
therefore, the focus of this work.
More speciﬁcally, in this paper, we present D-STHARk, a GUI tool for evaluating Dynamic
Scheduling of Tasks in Hybrid Simulated ARchitectures. The goal of this tool is to provide a
complete simulated execution environment that allows evaluating dynamic scheduling strategies
on simulated applications. Furthermore, D-STHARk allows users to simulate hybrid architectures, varying the types and number of PUs (CPUs, GPUs and MICs) and to create tasks,
from diﬀerent applications, with diﬀerent characteristics (i.e., relative performance, task dependencies, volume of data to be manipulated, among others.). Our tool provides the diﬀerent
dynamic scheduling strategies presented by [4, 3]. Moreover, it is possible to insert other new
strategies through an API.
We describe D-STHARk through its three main parts. In Section 3.1 we detail the simulated
execution environment and its components. In the Section 3.2 we explain how the previous described components interact with each other in a simulation process. Finally, in Section 3.3,
we show the main elements of the API that allows users to implement, insert and evaluate new
429

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

Savyo

dynamic scheduling strategies. We validate our tool by simulating the execution of pathology
image analysis application, used to investigate brain cancer morphology [3]. In this analysis,
we adopted diﬀerent dynamic scheduling strategies, presented in [4], varying the architecture
setup. We show that D-STHARk was able to present the same results found in the original
paper. Moreover, we present some new analysis of the scheduling strategies using diﬀerent architecture conﬁgurations, evincing the usefulness of D-STHARk in providing broader analyses.

2

Related Work

The eﬃcient use of hybrid systems equipped with CPUs and accelerators is a challenging problem, requiring the implementation of application codes optimized for multiple processors and
scheduling of work among heterogeneous devices. Recently, a number of compiler techniques
[16], domain-speciﬁc libraries [9], and, mainly, runtime systems [15, 17, 5, 10, 16] have been
proposed to reduce the programming eﬀort involved in porting applications to these systems.
Execution on distributed CPU-GPU-MIC platforms has been the target of several projects [5,
10, 16, 14]. Ravi et al. [16] developed a compiler based translation of generalized reductions
to CPU-GPU systems. In [10], the authors proposed OmpSs, a parallel programming model
for dataﬂow applications that allows parallelizing codes via compiler from user annotated code.
Augonnet et. al. [5] developed StarPU, a runtime environment that expresses computations as
a Directed Acyclic Graph (DAG). Similarly, XKaapi is another runtime environment that supports cooperative execution on CPU-GPU-MIC, machines using a multi-versioning scheme in
which operations may have multiple implementations targeting diﬀerent computing devices [14].
Recent eﬀorts on runtime environments have given particular attention to exploiting the
so-called dynamic schedulers, which distribute on runtime tasks of a given application among
the diﬀerent PUs available. Basically, these schedulers perform a runtime evaluation of the
characteristics of each task and PU. Then, based on that evaluation, they determine the most
appropriate PU to execute each task. The challenge, in this case, is how to maximize parallelization opportunities based on only a local and limited knowledge of the task set that compose
an application. Schedulers should prevent events that compromise the proper distribution of
tasks, such as overload of a PU, choice of PUs not suitable to perform a given task, and even
excessive data transfer among non-shared memories of distinct PUs. There are several proposals of dynamic schedulers in the literature [8, 18, 4]. A main limitation of such proposals,
however, refers to the constrained system conﬁgurations usually adopted to tune and test the
proposed environments. Most of them are evaluated considering only a particular architecture,
since setting more complete and diversiﬁed evaluation environments is costly.
In this paper propose D-STHARk, a GUI tool for evaluating dynamic scheduling strategies
simulating diﬀerent hybrid architectures. D-STHARk allows users to simulate the execution
of applications, contrasting the eﬀects of diﬀerent dynamic scheduling strategies on distinct
architecture conﬁgurations. To the best of our knowledge, our approach is the ﬁrst simulating
environment focused on the evaluation of dynamic scheduling of tasks proposed in the literature.

3

D-STHARk

In this section, we present D-STHARk, the GUI tool proposed for evaluating Dynamic
Scheduling of Tasks in Hybrid Simulated ARchitectures1 . We divide the description of our
tool into three parts. First, we present its main components. Then, we describe how these
1 D-STHARk

430

is available at https://github.com/SavyoToledo/D-STHARk

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

Savyo

components work and interact with eah other to execute a simulation. Finally, we present the
dynamic scheduler API that allows users to deﬁne distinct scheduling strategies.

3.1

D-STHARk Components

Basically, D-STHARk is composed of four main components: (1) environment conﬁguration;
(2) task creation; (3) scheduling strategy deﬁnition; (4) experimental execution and evaluation.
Using these components, users can adjust the simulation according to their goal, evaluating
each particular scenario close to its real conditions.
1. Environment Conﬁguration. D-STHARk allows users to create hybrid architecture
using three types of Processing Units (PUs): CPU, GPU and MIC. Each one of these PUs
may be instantiated many times. For example, we may create an environment with 6 CPUs, 2
GPUs and 2 MICs. Moreover, for each coprocessor (i.e., GPU and MIC) it is possible to deﬁne
the bus bandwidth, which corresponds to the amount of data that can be transfered between
the coprocessor and CPU in a given time unit. This conﬁguration makes the simulations even
closer to real heterogeneous scenarios. Further, users may store each conﬁguration into a ﬁle.
2. Task Creation. D-STHARk represents each simulated application as a set of distinct
tasks and dependencies among them. In turn, each task is deﬁned through three main characteristics: (1) task type, (2) error rate and (3) workload size. There exists a high variability
on the speedups achieved by the same PU as diﬀerent operations are considered. Moreover,
the relative performance among PUs varies according to the operation executed. Consequently,
diﬀerent PUs are more eﬃcient for particular types of operations. Therefore, (1) Task Type
represents the behavior that a group of similar tasks usually exhibits w.r.t. execution time
in each type of PU. All tasks belong to the same type will have a speciﬁc execution time in
each PU, informed by the user. However, in order to allow a simulation closer to real scenario,
users can deﬁne the (2) Error Rate, an interval (i.e., minimum and maximum error value) that
corresponds to how much the execution times of a task are expected to vary. After deﬁning
these two characteristics, the next step is to create the tasks properly. D-STHARk allows users
to insert all the tasks that compose the main application to be simulated, where each task
must belong to one of the aforementioned task types. According to the task type and the error
rate, a random time is deﬁned for each task for diﬀerent PUs. Finally, the third characteristic
required by D-STHARk is the (3) Wokload Size in MB. This characteristic is relevant, since
many scheduling strategies consider the data size and the number of operations to be executed
on each PU in order to estimate the communication cost. For simplicity, we assume that the
transfer cost varies linearly with the data size. In order to identify each task created, users can
assign a unique ID to each task on D-STHARk. Using these IDs, users may deﬁne dependencies
among distinct tasks that compose an application, such as in real scenarios. For instance, a
dependence of a task t1 to a task t2 means that t2 must be executed before t1. Again, users
may store all these conﬁgurations into an output ﬁle.
3. Scheduling Strategy Deﬁnition. In this step, users select the dynamic scheduling
strategies to be evaluated. Currently, D-STHARk has four strategies implemented: (1) FCFS
(First Come First Served), a common strategy based on a global queue; (2) HEFT (Heterogeneous Earliest Finish Time); (3) HEFT-DA (Heterogeneous Earliest Finish Time Data-Aware);
and (4) SEQ (Sequencial), a straightforward serialization of all tasks to be executed. While
the ﬁrst three strategies were extensively evaluated in [3], the last one serves as a baseline
to contrast the performance of diﬀerent scheduling strategies. Moreover, D-STHARk allows
users to load and evaluate their own schedulers, as further explained in Section 3.3. Finally,
we highlight that users can select diﬀerent schedulers to compose a single simulation. In this
431

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

Savyo

case, D-STHARk executes individually each selected scheduler, allowing users to compare the
performance achieved by each one.
4. Experimental Execution and Evaluation. In this step, users can review and conﬁrm all setup conﬁgurations. After conﬁrming, D-STHARk starts performing the simulation.
The proposed tool also allows deﬁning how many times each simulation will be executed. The
results are reported as the average of these executions and the standard deviation is also presented. During the simulation execution, D-STHARk exhibits a log visualization, detailing the
simulated application and showing which task is being executed by each PU at each moment.
This log visualization can be used to debug the schedulers, verifying if they are working as
expected. At the end of the simulation, D-STHARk presents detailed results for each simulated
scheduler, which may be exported to an output ﬁle. More speciﬁcally, it shows (1) Speedup
achieved; (2) Histogram with the task distribution among PUs, assigned by each scheduler; and
(3) Graphics showing the percentage of processing performed by each PU.

Figure 1: Execution Process of Simulations

3.2

Execution Process of Simulations

Once deﬁned or loaded all required conﬁgurations, D-STHARk is ready to execute the simulation. For this purpose, D-STHARk creates a distinct thread2 , named Worker Thread, to
simulate each PU. Moreover, a main thread is instantiated and it is responsible for reading
the task conﬁgurations (GetTask routine) and submit the task for execution (SubmitTask routine). Finally, the main thread creates a queue for each Worker Thread that will be managed
according to the dynamic scheduling strategy deﬁned in the conﬁguration process.
Meanwhile, the task management is executed concurrently with the task execution, such as
on real dynamic scheduling environments. After receiving a task to run, each Worker Thread
veriﬁes the task dependencies. If the task has dependencies, it is inserted in the Stuck Task
List, which stores all tasks that do not have all dependencies solved. Otherwise, it is sent to
2 We

432

implemented threads using the standard pThread library.

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

Savyo

the method PushTask that inserts the task into one of the tasks queues, according to the
scheduler policy deﬁnition.
When a speciﬁc Worker Thread becomes idle, it fetches a new task to be executed using the
method PopTask, deﬁned according to each dynamic scheduling strategy. As aforementioned,
each task has a speciﬁc execution time deﬁned for each PU. Thus, the Worker Thread calls
a sleep method during the execution time corresponding to the PU that it is simulating. In
addition, another sleep call is made when the execution is simulating a coprocessor. This second sleep call simulates the data transferring time from the CPU memory to the coprocessor
memory. As the user has indicated previously the bus bandwidth, as well as the workload size,
the Worker Thread can calculate how long to sleep for simulating this communication cost.
For instance, the PCI-EXPRESS 16x bus features a 4GB transfer speed per second. Hence,
for each MegaByte of the task data, we perform a sleep of 0.000244141s, getting closer to real
conditions of execution. Finalizing the execution process, the Worker Thread veriﬁes the
Stuck Task List and removes all dependencies associated with the task just executed. Then,
the main thread starts to fetch tasks from Stuck Task List, since all of them, at this point,
will have all their dependencies solved. By this way, we guarantee that tasks will be executed
in the correct order. Figure 1 illustrates the above described process.

3.3

Dynamic Scheduler API

As aforementioned, D-STHARk allows users to include their own scheduling strategies. For this
purpose, our tool oﬀers an API specifying a guideline to be followed in order to make these new
strategies compatible to the system.
Basically, all new schedulers must be implemented in C language. These implementations
may use diﬀerent routines and ﬁle names, which must be loaded into D-STHARk through
the GUI available. However, the source code must have a ﬁle named scheduler.c, with four
mandatory routines:
1. InitializeScheduler: it is responsible to initiate the scheduler’s components. This
routine also creates the task queues, associating them with the deﬁned PUs.
2. PushTask: deﬁnes which strategy will be used to schedule task among PU queues.
3. PopTask: this routine is called by each Worker Thread, whenever it is idle, and
deﬁnes the next task to be executed in the thread.
4. DestroyScheduler: it is responsible to ﬁnalize the scheduler. In this routine the ﬁnal
procedures must deallocate the memory used by the scheduler.

4

Experimental Evaluation

In this section, we present the experiments performed to evaluate D-STHARk. These experiments consist of simulating the same scenario originally presented in [3], on which the authors
evaluated diﬀerent dynamic scheduling strategies for a real application [11]. Our evaluations
contrast the simulated results against the original ones, considering both execution times and
distribution of tasks among PUs. Moreover, we extended these analyses by simulating the use
of more coprocessors than originally reported due to lack of real architectures.
433

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

4.1
4.1.1

Savyo

Simulation Setup
Simulated Application

In our experiments, we simulated an application related to studies of brain cancer [11], which
intends to ﬁnd better tumor classiﬁcations using high resolution Whole Tissue Slide Images
(WSIs). This application partitions each WSI into multiple image tiles that can be independently analyzed. There are many phases of this image analysis, but the time demanding phases
are segmentation and features computation ones. Hence, these two phases have been the focus
of execution optimizations in large-scale hybrid machines [3]. Each image tile is submitted to
diﬀerent operations, forming a dataﬂow graph, such as shown in Figure 2).

Figure 2: Application Dataﬂow
In D-STHARk, we instantiated a distinct task type for each operation, represented as
colored rectangles in the dataﬂow. The relative performance (i.e. speciﬁc times) for each PU
on each task type was deﬁned based on the values originally reported in [19]. In order to ﬁt
the original experiments, we considered the error rate as zero. Observe that processing several
image tiles is an embarrassingly parallel problem, since each image tile determines a diﬀerent
dataﬂow. Thus, we instantiated an individual task for each diﬀerent operation applied on each
diﬀerent image tile. Moreover, we inserted the dependencies among tasks, such as exhibited
in the dataﬂow, to simulate the correct execution order for each pair . Aiming to depict the
above process, we consider only the operations Morph.Open and Recon.Nuclei applied to two
image tiles. First, we create two types of task, T ype1 (i.e., Morph.Open) and T ype2 (i.e., Recon.Nuclei ). Then, D-STHARk automatically determines the execution times in the PUs for
each task type, based on the conﬁgurations previously deﬁned by the user. Later, we instantiate
the tasks related to each image tile: (a) t1 of T ype1 for the ﬁrst tile; (b) t2 of T ype2 for the
ﬁrst tile; (c) t3 of T ype1 for the second tile; and (d) t4 of T ype2 for the second tile. Finally,
we add the dependencies from t2 to t1 and from t4 to t3, ensuring the correct execution order.
We experimentally provide simulations with 800 image tiles, which generates 10,400 ﬁnegrained tasks for execution. Moreover, based on descriptions in [3], the authors reported that
each tile presents a resolution of 4Kx4K pixels. Considering a 256 color representation, each
image tile has a size of 15.25M B. Consequently, we deﬁned 15.25M B as the data workload
that each instantiated task needs to handle.
4.1.2

Simulated Schedulers

As the above discussed application characteristics induce quite similar behaviors on two strategies (i.e., HEFT-DA and HEFT), we restricted our analyses to two strategies evaluated in [3]:
• FCFS: it is a simple scheduling strategy based on a global queue. When a Worker
Thread is idle, it fetches the ﬁrst task on the queue head.
434

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

Savyo

• HEFT: it maintains a task queue for each PU. The task distribution across the PUs is
deﬁned according to their processing capabilities. More speciﬁcally, the scheduler maintains a history of the execution times and thereby assigns a task to a speciﬁc PU that
minimizes Equation 1.
(1)
minP i (Avail(P i) + EstP i (T ))
P i is the PU being evaluated; Avail(P i) represents the amount of time that P i takes to
process all tasks assigned to it; and EstP i denotes the estimated time that P i takes to
run a speciﬁc task T .
4.1.3

Simulated Architectures

Basically, our analyses consider three distinct hybrid architectures, originally evaluated in [3]:
(1) CPU-GPU - 15 CPU cores and 1 GPU; (2) CPU-MIC - 15 CPU cores and 1 MIC; and
(3) CPU-GPU-MIC - 14 CPU cores , 1 GPU, and 1 MIC. Thus, we evaluate the previously
mentioned scheduling strategies on each of these architectures. Further, we consider other conﬁgurations of PUs in order to evaluate scenarios with more coprocessors than originally reported
by [3], evincing the usefulness of D-STHARk in providing broader analyses. We set the bus
bandwidth as 4GB, like one PCI-EXPRESS 16x used in original experiments.

4.2

Analysis of Results

We evaluated D-STHARk considering three issues. First, we analyzed how similar are the distribution of tasks, deﬁned by each scheduler strategy on the simulated architecture, with the
distributions observed in a real architecture. Second, we investigated how close are the execution times of our simulations to those times measured in a real architecture. For these two
issues, we consider the CPU-GPU-MIC architecture, such as evaluated in [3]. We highlight
that, through these two issues, we intend to evaluate whether these simulated results are close
to those achieved using actual architectures, demonstrating the eﬀectiveness of D-STHARk.
Finally, the third issue concerns about extending the original evaluation to other types of architectures, in order to achieve broader conclusions.
4.2.1

Distribution of Tasks

In [3], the authors evaluated the impact of the number of distinct image tiles concurrently
processed by each Worker Thread. They concluded that the overall performance may be improved using high levels of concurrence (i.e., 55 image tiles). In our analyses, the simulated
schedulers worked without limitations on this number as well, presenting some of the results
found by the authors. Figure 3 presents D-STHARk’s results. First, we observe that FCFS
scheduling to PUs is nearly the same for all operations. Hence, we found FCFS is not able to
take full advantage on the performance variability among operations. On the other hand, we
may notice that HEFT has prioritized the use of CPU cores for most tasks, regardless of the
performance/speedup of the other PUs. As presented in [19], some operations (e.g., PreWaterShad, ReconNuclei and RBC ), with high computational costs, may decrease the execution
time using coprocessors. Indeed, HEFT was able to better assign tasks to processing unit that
minimize its execution time, exhibiting the smallest execution times. Further explanations of
these decisions and their consequences are better discussed in [3].
435

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

(a) FCFS

Savyo

(b) HEFT

Figure 3: Proﬁle of task assignment to devices for each of the tasks executed in our application.
4.2.2

Execution Times

The execution times of the schedulers are presented in Figure 4 (a) and (b), corresponding to
simulated and real results, respectively. Once more, the results achieved using D-STHARk are
quite similar to those achieved using a real architecture, on which FCFS attains the worst performance among all conﬁgurations. As reported in [3], it is also important to highlight that the use
of GPU always leads to good performance. For instance, the best CPU-GPU execution time is
about 1.26× faster than the best CPU-MIC execution time. This result motivates us to perform
the next described experiments in order to demonstrate the wider applicability of our tool.

(a) Simulated Execution

(b) Real Execution

Figure 4: Performance of schedulers in cooperative executions using diﬀerent types of processors.

4.2.3

Increasing Coprocessors

Despite some outcomes achieved by the authors on [3] indicating that, for the evaluated application, increasing the number of processors could improve the system performance, it was not
veriﬁed due to the lack of real architectures. In this section, we provide this analysis by conﬁguring diﬀerent architectures in D-STHARk. Speciﬁcally, using just the dynamic scheduling
strategy HEFT, we decrease the number of CPU cores and increase the number of coprocessors
coordinately. Our goal is to show that a small increasing on the number of coprocessors may
produce the same performance using less CPU cores.
Table 1 presents the execution times reported by D-STHARk on diﬀerent conﬁgurations,
on which the ﬁrst one is related to the CPU-GPU-MIC architecture. As we can note, by
increasing just one coprocessor MIC it is possible to remove 2 CPU cores. Similarly, by in436

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures
Processors Conﬁguration
14 CPUs + 1 GPU +1 MIC
11 CPUs + 1 GPU + 2 MIC
9 CPUs + 2 GPU + 1 MIC
4 CPUs + 2 GPU + 2 MIC

Savyo

HEFT Scheduler time (s)
305.892
309.537
301.079
302.646

Table 1: Simulating diﬀerent architectures, varying the number of coprocessors.
creasing one GPU it is possible to remove 4 CPU cores, both without degrading the system
performance. These results are consistent with those expected in [3], showing that we may reduce the energy consumption (reducing CPU cores and increasing coprocessors), while keeping
the same performance [1].

5

Conclusions and Future Work

In this paper, we present D-STHARk, a GUI tool for evaluating Dynamic Scheduling of Tasks
in Hybrid Simulated ARchitectures. By this tool, it is possible to evaluate new proposals of
dynamic scheduling strategies, simulating applications with distinct characteristics (task dependences, manipulating data etc. ) in diﬀerent hybrid architectures (CPUs, GPUs and MICs).
We evaluated our tool by simulating some of the dynamic scheduling strategies presented in [3],
adopting the same application related to studies of brain cancer [11] and an architecture with
14 CPU cores, 1 MIC and 1 GPU. The results and conclusions achieved with D-STHARk were
the same as originally reported, showing the eﬀectiveness of our proposal. Moreover, we performed an experiment in which we varied the number of coprocessors (MIC and GPU), which
was not previously veriﬁed due to lack of a real architecture, showing that we may reduce the
energy consumption, while keeping the same performance [1]. As future work, we will extend
D-STHARk to simulate inner buses, in order to consider contentions related to increasing the
number of processing units. Moreover, we intend to include new scheduling strategies and allow
the insertion of more complex tasks, with ﬁner-grained details.

References
[1] Reducing the Energy Consumption of Embedded Systems by Integrating General Purpose GPUs.
Technical reports in computer science. TU, Department of Computer Science, 2010.
[2] D.I. George Amalarethinam and G.J. Joyce Mary. Article: A new dag based dynamic task scheduling algorithm (dytas) for multiprocessor systems. IJCA 2011.
[3] Guilherme Andrade, Renato Ferreira, George Teodoro, Leonardo C. da Rocha, Joel H. Saltz, and
Tahsin M. Kur¸c. Eﬃcient execution of microscopy image analysis on cpu, gpu, and MIC equipped
cluster systems. In 26th IEEE SBAC-PAD 2014, Paris, France.
[4] Guilherme Andrade, Gabriel Ramos, Daniel Madeira, Rafael Sachetto, Esteban Clua, Renato
Ferreira, and Leonardo Rocha. Eﬃcient dynamic scheduling of heterogeneous applications in
hybrid architectures. In Proceedings of ACM SAC ’2014, pages 866–871.
[5] C´edric Augonnet, Samuel Thibault, and Raymond Namyst. StarPU: a Runtime System for
Scheduling Tasks over Accelerator-Based Multicore Machines. Technical report, 2010.
[6] Cedric Augonnet, Samuel Thibault, Raymond Namyst, and Maik Nijhuis. Exploiting theCell/BE
architecture with the StarPU uniﬁed runtime system. July 2009.
[7] Cedric Augonnet, Samuel Thibault, Raymond Namyst, and PierreAndre Wacrenier. Starpu: A
uniﬁed platform for task scheduling on heterogeneous multicore architectures. Concurrency and
Computation: Practice and Experience and Special Issue: Euro Par 2009.

437

D-STHARk: Evaluating Dynamic Scheduling of Tasks in Hybrid Simulated Architectures

Savyo

[8] Robert D. Blumofe and Charles E. Leiserson. Scheduling multithreaded computations by work
stealing. J. ACM, 1999.
[9] G. Bradski. The OpenCV Library. Dr. Dobb’s Journal of Software Tools, 2000.
[10] J. Bueno, J. Planas, A. Duran, R.M. Badia, X. Martorell, E. Ayguade, and J. Labarta. In 2012
IEEE 26th Int. Parallel Distributed Processing Symp. (IPDPS).
[11] Lee Cooper, Jun Kong, David Gutman, Fusheng Wang, and et al. An integrative approach for in
silico glioma research. IEEE Trans Biomed Eng., 57(10):2617–2621, 2010.
[12] Massimiliano Fatica and David Luebke. High performance computing with CUDA. Supercomputing 2007 tutorial. In Supercomputing 2007 tutorial notes, November 2007.
[13] James Jeﬀers and James Reinders. Intel Xeon Phi Coprocessor High Performance Programming.
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1st edition, 2013.
[14] Jo˜
ao V. F. Lima, Fran¸cois Broquedis, Thierry Gautier, and Bruno Raﬃn. Preliminary experiments
with xkaapi on intel xeon phi coprocessor. In 25th IEEE SBAC-PAD, pages 105–112, 2013.
[15] Michael D. Linderman, Jamison D. Collins, Hong Wang, and Teresa H. Meng. Merge: a programming model for heterogeneous multi-core systems. SIGPLAN Not., 43(3):287–296, 2008.
[16] V.T. Ravi, W. Ma, D. Chiu, and G. Agrawal. Compiler and runtime support for enabling generalized reduction computations on heterogeneous parallel conﬁgurations. In ACM Supercomp.
2014.
[17] Christopher J. Rossbach, Jon Currey, Mark Silberstein, Baishakhi Ray, and Emmett Witchel.
PTask: operating system abstractions to manage GPUs as compute devices. In ACM SOSP, 2011.
[18] Warren Smith, Valerie Taylor, and Ian Foster. Using run-time predictions to estimate queue
wait times and improve scheduler performance. In Scheduling Strategies for Parallel Processing.
Springer-Verlag, 1999.
[19] George Teodoro, Tahsin Kurc, Jun Kong, Lee Cooper, and Joel Saltz. Comparative Performance
Analysis of Intel Xeon Phi, GPU, and CPU: A Case Study from Microscopy Image Analysis. In
IPDPS, 2014.

438

