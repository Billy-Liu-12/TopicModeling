Agent-Based Model and Computing
Environment Facilitating the Development of
Distributed Computational Intelligence Systems
Aleksander Byrski and Marek Kisiel-Dorohinicki
AGH University of Science and Technology, Krak´
ow, Poland
{olekb,doroh}@agh.edu.pl

Abstract. In the paper a simple formalism is proposed to describe the
hierarchy of multi-agent systems, which is particularly suitable for the
design of a certain class of distributed computational intelligence systems. The mapping between the formalism and the existing computing
environment AgE is also sketched out.

1

Introduction

Realization of multi-agent systems is usually performed utilizing in parallel: a
dedicated formalism for describing its structure and behavior, and then generalpurpose design and implementation methods, such as UML and object-oriented
programming to achieve a functional system [1]. Of course using general-purpose
design and implementation methods has an unquestionable drawback, which is the
need to establish a mapping between the model and its implementation each time
a new class of systems (or even a novel approach to modeling) is considered. Obviously dedicated implementation tools help to understand the designed system
faster and allow to extend its features easier. There exist some frameworks, which
facilitate the construction of agent systems, such as Jade, Aglets, or Grasshopper [2]. Other approaches concentrate on speciﬁc aspects of agent systems, like
AgentSpeak language for describing BDI agent behavior together with its implementation based on Jason and Moise+ facilitate constructing agents interacting
in some organizational structure [3,4]. However, it is obvious that such frameworks
are not equally useful for implementing all kinds of multi-agent systems.
Our interests focus on a speciﬁc class of agent systems, which use computational intelligence paradigms — particularly hybrid techniques based on the
concept of decentralized evolutionary computation [5]. Several variants of these
techniques were considered for diﬀerent goals and problems (e.g. global, multimodal and multi-criteria optimization), and a variety of systems were developed
using general-purpose tools. Both the realized systems and proposed models
proved useful for the analysis of these techniques — in testing their eﬃciency for
diﬀerent kinds of problems or exploring their asymptotic behavior [6]. However,
still a complete methodology which would bring together the model and its implementation is lacking. Thus in this paper a simple formalism is proposed to
describe the particular class of computing multi-agent systems, which is suitable
G. Allen et al. (Eds.): ICCS 2009, Part II, LNCS 5545, pp. 865–874, 2009.
c Springer-Verlag Berlin Heidelberg 2009

866

A. Byrski and M. Kisiel-Dorohinicki

for their realization. It is aimed to describe the structure and behavior of the
system, yet it does not provide the means for its more sophisticated analysis.
A mapping is established between the proposed formalism and an existing computing environment, which was successfully used in the implementation of the
above mentioned decentralized evolutionary computation systems.
The paper begins with the presentation of a formalism which allows for describing the structure and behavior of computing agent-based systems. The
model of an evolutionary multi-agent system is given as an illustration in the
next section. Finally the mapping between the model and the computing environment AgE is shown and some conclusions are drawn.

2

Structure and Behavior of a Computing MAS

Obviously a multi-agent system consists of autonomous agents. Thus the proposed model deﬁnes MAS as a set of agents, but also a set of actions to be executed by the agents, and the environment represented by some common data,
which may acquired by the agents:
AS

as = Ag, Act, qr1 , . . . , qrm

(1)

where:
Ag ⊂ AG is the set of agents of as,
Act ⊂ ACT describes actions that may be performed by the agents of as,
qri ∈ QRi , i = 1, . . . , m denote queries providing data (knowledge) available for
all agents in the environment.
An agent ag may be described as the following tuple:
AG

ag = id, tp, dat1 , . . . , datn

(2)

where:
id ∈ ID is a unique identiﬁer of an agent1 ,
tp ∈ T P denotes the type of an agent, depending on its type, an agent is equipped
with speciﬁc data and may perform speciﬁc actions,
dati ∈ DATi , i = 1, . . . , n represents problem-dependent data (knowledge) gathered by an agent (solutions, resources, outcomes of the observations etc.)
An agent may provide an environment for a group of other agents, which by
themselves constitute a multi-agent system, which is essentially diﬀerent then
the one of the “parent” agent. These nested (multi-agent) subsystems introduce a
tree-like structure, which will be further referred as physical hierarchy of agents.
In fact, the agents of diﬀerent subsystems form a structure, which is rather a
1

For each element of the model its domain, which is a ﬁnite set of possible values, is
denoted by the same symbolic name in upper case, e.g. ID is the set of all possible
agent identiﬁers.

Agent-Based Model and Computing Environment

867

collection of trees (a forest), which may be perceived as a single tree with a
virtual root node. Inner nodes of this structure may be perceived as aggregates
of other agents, but of course it is only a simpliﬁcation, since these sub-agents
constitute a complete multi-agent system according to (1). Particular types of
agents are often present at particular levels of physical hierarchy – the structure
of allowed agent types in the physical hierarchy is called a logical hierarchy.
To identify an agent which provides the environment for a particular multiagent system a mapping is introduced:
γ : AS → AG ∪ {∅}

(3)

If a certain agent ag ∈ Ag in as = Ag, Act provides the environment for
as∗ = Ag ∗ , Act∗ the mapping will give γ(as∗ ) = ag, and this agent will be
called an aggregate for as∗ . For a multi-agent system at the top of the physical
hierarchy γ(as) = ∅, since there is no real agent providing an environment for
this system (symbol ∅ may be perceived as denoting a virtual root node of the
hierarchy).
Let us introduce subsumption relation in the set of types T P , which is used
to state whether one type is the specialization of another:
” ” ⊂ TP × TP

(4)

Relation deﬁnes a partial order in T P (it is reﬂexive, transitive, antisymmetric). Since the type of an agent determines its features, it is assumed that an
agent with a more speciﬁc type is able to provide all data and perform all actions of an agent with a more general type, yet of course the realization of the
descendant may be diﬀerent than the parent.
Further deliberations are impossible without giving even the approximation
of the system state space:
X = 2AS
AS = 2AG × 2ACT

(5)
(6)

Actual state space will be constrained by the existence of agent types, and the
logical hierarchy of particular system, yet the precise description of the state of
the whole system is beyond the scope of this paper.
Agents may perform actions in order to change the state of the system. An
action is deﬁned as the following tuple:
ACT

act = tp, pre, post

(7)

where:
tp ∈ T P denotes the type of agents allowed to execute the action (only agents of
the type tp and descendant types – according to ” ” relation – may perform
the action),
pre ∈ X is the state of the system which allows for performing action act,
post ∈ X × X the relation between the state of the system before and after
performing action act,

868

A. Byrski and M. Kisiel-Dorohinicki

This tuple may be perceived as so-called Hoare’s triple (precondition, operation,
postcondition) used e.g. for contract deﬁnition in component-based software (see
[7]). The descendant types (according to relation) must hold the preconditions
and postconditions of the parents, yet they may extend these conditions by
adding new alternatives in preconditions and conjunctions in postconditions.
When mentioned conditions are met, the descendant types are fully substitutable
for parent types (in the means of contract substitutability [8]).
The following function family is used by an agent of type tp to choose the
action to be executed:
(8)
{ω tp : X → M(ACT )}
The choice of the action is thus based on the current state of the system and is
deﬁned in stochastic terms2 . Usually only small part of the system state will be
taken into consideration (e.g. the agent’s data or it’s aggregate’s data). Function
ω allows an agent to choose only the actions with compatible (the same or
descendant) type:
∀ag ∈ AG : ag = id, tp1 , dat1 , . . . , datn , ∀act ∈ ACT : act = tp2 , pre, post
ω tp (x)(act) > 0 ⇐⇒ tp1

tp2

(9)

thus introducing a new type of agents requires adding new function for choosing
the actions.
To recapitulate, the relations among agents in the whole system may be described using two distinct hierarchies: physical hierarchy (aggregate agents provide an environment for nested multi-agent (sub)systems) and type hierarchy
(each agent is assigned a type, which may be a specialization of another type).

3

Modeling Evolutionary Multi-Agent Systems

The idea of EMAS (Evolutionary Multi-Agent System) was proposed as a particular technique of decentralized evolutionary computation [9,5]. A variety of
applications of this paradigm were considered from typical optimization problems to hybrid computational intelligence systems [10].
The system consists of individual agents decomposed into several subpopulations (demes). Agents contain (partial) solutions of the given optimization
problem. They also contain a non-renewable resource called life energy, which is
the base of a distributed selection process. Agents exchange their energy based
on the ﬁtness value of their solutions. These which gather more energy have
greater chances for reproducing, and those with low energy have greater chances
of dying. This energy-based selection is used instead of classical global selection mechanisms, because of the assumed autonomy of agents. Agents may also
migrate to another subpopulation if they have enough energy.
To facilitate the realization of EMAS, two types of agents are used:
T P = {ind, isl}
2

M(A) denotes the space of probabilistic measures over the measurable set A.

(10)

Agent-Based Model and Computing Environment

869

where ind denotes the type of an individual agent (as described above), and
isl — of an aggregate agent, which introduced to manage subpopulations of
individual agents (plays a role of an evolutionary island).
Consequently at the top of the physical structure of EMAS there is a system
of evolutionary islands:
as = Ag, ∅

γ(as) = ∅

(11)

where:
Ag

ag = id, isl, N b

(12)

and N b ⊂ Ag is the set of neighboring evolutionary islands, which is used to
deﬁne the topology of migration.
Every evolutionary island ag provides an environment for the population of
individual agents:
∀ag ∈ Ag ∃as∗ = Ag ∗ , {migr, get, repr, die}, f indAg, f indLoc :
ag = γ(as∗ ) (13)
and an individual agent is deﬁned as:
Ag ∗

ag ∗ = id, ind, sol, en

(14)

where:
sol ∈ SOL is the solution of the problem (usually for optimization problems
SOL ⊂ Rn , n ∈ N),
en ∈ R+ is the amount of energy gathered by the individual,
f indAg : AG → M(AG) is the query that allows to choose the neighboring individual agent (another agent present in the same system),
f indLoc : AG → M(AG) is the query that allows to choose the neighboring
island (using N b ⊂ Ag).
The set of actions available for individual agents contains:
–
–
–
–

migr – migration of an agent from one to another subpopulation,
get – transfer of a portion of energy from one to another agent,
repr – creation of a new agent by two parents,
die – removing of an agent from the system.

Agents use following function to choose the action they intend to perform:
ω ind : X → U({migr, get, repr, die})

(15)

where U(·) stands for a uniform random distribution.
Action of energy transfer get performed by ag1∗ = id1 , ind, sol1 , en1 ∈ Ag ∗ ,
which meets ag2∗ = f indAg(ag1∗ ) = id2 , ind, sol2 , en2 ∈ Ag ∗ (randomly chosen
with uniform distribution from its neighbors) may be deﬁned in the following
way:
Act get = ind, pre, post
(16)

870

A. Byrski and M. Kisiel-Dorohinicki

where:

pre = #Ag ∗ > 1
post = (ϕ(sol1 ) < ϕ(sol2 ) ⇒ en1 = en1 + eget ∧ en2 = en2 − eget )
∨ (ϕ(sol1 ) > ϕ(sol2 ) ⇒ en1 = en1 − eget ∧ en2 = en2 + eget )

where: ϕ : SOL → R is the ﬁtness function used for the evaluation of solutions,
the precise deﬁnition of this function is problem-dependent. en1 denotes the value
of en1 after performing the action3 , A(B) denotes the result of the random choice
of the value from the set B with distribution A.
This action may be performed by an individual agent, which has at least one
neighbor (agent in the same MAS subsystem). Depending on the quality of its
solution, a part of energy is transferred from the worse to the better agent.
Action of reproduction repr performed by ag1∗ = id1 , ind, sol1 , en1 ∈ Ag ∗ ,
which meets ag2∗ = id2 , ind, sol2 , en2 ∈ Ag ∗ (randomly chosen with uniform
distribution from its neighbors) and produces the oﬀspring agent ag3∗ = id3 , ind,
sol3 , en3 ∈ Ag ∗ may be deﬁned in the following way:
Act
where:

repr = ind, pre, post

(17)

pre = #Ag ∗ > 1

post = en1 > erepr ∧ en2 > erepr ⇒ Ag ∗ = Ag ∗ ∪ {ag3∗ }
1
1
∧ en3 = e0 ∧ en1 = en1 − e0 ∧ en2 = en2 − e0 ∧ sol3 = χ(sol1 , sol2 )
2
2
where: χ : SOL × SOL → M(SOL) is a variation operator (recombination and
mutation), its precise deﬁnition is problem-dependent.
This action may be performed by an individual agent with at least one neighbor, both with suﬃcient energy. They create a new agent based on their solutions.
Action of death die performed by ag ∗ = id, ind, sol, en ∈ Ag ∗ may be deﬁned
in the following way:
Act die = ind, pre, post
(18)
where:
pre = (en = 0)
post = (Ag ∗ = Ag ∗ \ {ag ∗ })
This action may be performed by an individual agent which energy level falls to
zero. This agent is removed from the system.
Action of migration migr performed by ag ∗ = id, ind, sol, en ∈ Ag1∗ :
∃ as∗1 = Ag1∗ , Act∗1 ∧ γ(as∗1 ) = ag1 which migrates from ag1 = id1 , isl, N b1
3

Here and later the symbol a will denote the value of a after performing the action
(usually a is used in precondition and a only in postcondition). This is similar to
old operator used in contract speciﬁcation in Eiﬀel programming language [8].

Agent-Based Model and Computing Environment

871

to ag2 = f indLoc(ag1 ) = id2 , isl, N b2 : ∃ as∗2 = Ag2∗ , Act∗2 ∧ γ(as∗2 ) = ag2
(ag2 is randomly chosen from all neighbors of ag1 with uniform distribution).
Act

migr = ind, pre, post

(19)

where:
pre = ag2 ∈ N b1
post = en1 > emigr ⇒ Ag1∗ = Ag1∗ \ {ag1∗ } ∧ Ag2∗ = Ag2∗ ∪ {ag1∗ }
This action may be performed by an individual agent, located in the system with
at least two evolutionary islands. The agent with suﬃcient energy emigr leaves
one island and moves to another.

4

AgE Computing Environment

The model presented constitutes a base for the design of the core structure of
distributed computing environment AgE4 , developed as an open-source project
at Intelligent Information Systems Group of AGH University of Science and
Technology. The name reminds that it was primarily dedicated to agent-based
evolutionary techniques (AgE = Agent Evolution), but now it grew up into a
general-purpose platform facilitating the implementation of a variety of (not
necessarily but most suitably) agent-based simulation and computing systems.
Mainstream implementation is realized in Java and follows component approach,
which allows for ﬂexible (re)conﬁguration of the system to meet the requirements
of particular problems and solving techniques.

Fig. 1. Properties of objects in AgE computing core

Essential implementation entities that form the computing core of AgE (mainly
agents) are realized so as they may be described in terms of properties. A property is a feature of an object, which may be referenced at runtime by its name
4

http://age.iisg.agh.edu.pl/

872

A. Byrski and M. Kisiel-Dorohinicki

— to be read, written or even monitored. This functionality is represented by
IPropertyContainer interface and may be easily achieved extending an abstract class ClassPropertyContainer (Fig. 1), which provides instrumentation
allowing to treat appropriately annotated methods (serving as getters or setters)
or ﬁelds of a class as its properties.
According to the deﬁnition of an agent (2) properties allow for ﬂexible access to agents’ data dati , which facilitates the realization of observation of single agents. It is always possible because a fundamental interface representing
an agent IAgent extends IPropertyContainer. Basic agent implementation
AbstractAgent extends ClassPropertyContainer to gain this functionality
without any additional eﬀort. Also the identiﬁcation of an agent, which is realized in the form of a unique agent address (AgentAddress class), is provided as
a property.

Fig. 2. Diﬀerent kinds of agent implementations in AgE computing core

Fig. 2 shows diﬀerent kinds of agent implementations – most notably those,
which allow for parallel execution (IThreadAgent), as well as those which work
semi-parallelly based on the concept of event-driven simulation (ISimpleAgent)
and thus allow for more eﬃcient realization of agent interactions. A speciﬁc interface (IAggregate) implies an agent which serves as an environment for the nested
multi-agent subsystem. Since IAggregate extends IAgent, the implementation of
a tree-like structure of agents introduced in (1) simply follows composite pattern.
The environment for descendant agents is available via dedicated interface
IAgentEnvironment (see Fig. 3), which provides identiﬁcation and both synchronous (queries) and asynchronous (messages) communication facilities.
Queries may concern the state of the system an agent is a part of (realized
by IQueryable interface) and the state of the “parent” agent’s system (query
Parent() operation). In case of event-driven execution (as implemented by
SimpleAgent class) the environment (ISimpleAgentEnvironment) also provides
the mechanism supporting actions (as realized by SimpleAggregate class).
Agents of the top-level multi-agent system (considering the described hierarchy nested subsystems) play special role in the organization of the platform
— they work in parallel and may be distributed over the network. They may

Agent-Based Model and Computing Environment

873

Fig. 3. Environments available in AgE computing core

be understood as roots of local computing environments, because all the agents
in one branch of the hierarchy must be executed on one node (a single JVM
in Java implementation) — thus they are marked by IWorkplace interface extending IThreadAgent and IAggregate. Obviously there is no special agent
providing their environment, but rather there is some infrastructure available
via IWorkplaceEnvironment, which provides identiﬁcation and communication
in the possibly distributed way.

5

Conclusions

In the paper a simple formal model of a computing multi-agent system was proposed and used to describe a speciﬁc computational intelligence system — an
evolutionary multi-agent system. The proposed formalism is solely used for design, and that is why such details as the precise deﬁnition of the system state
space or state transition functions were not taken into consideration. Since several existing EMAS implementations are based on AgE framework, the mapping
between the proposed model and this framework was also shown in the course
of the paper.
Further research should allow to extend the model to cover other computation
intelligence techniques based on agent paradigm, such as iEMAS (immunological evolutionary multi-agent system) [11] or HGS (hierarchical genetic search)
[12]. Also the mapping between the proposed formalism and existing models describing these techniques will be provided. Because the implementation of AgE
framework continues, the formalism will surely be updated in the near future.

References
1. Booch, G., Rumbaugh, J., Jacobson, I.: The Uniﬁed Modeling Language User
Guide. Addison-Wesley, Reading (1998)
2. Trillo, R., Ilarri, S., Mena, E.: Comparison and performance evaluation of mobile
agent platforms. In: ICAS 2007: Proceedings of the Third International Conference
on Autonomic and Autonomous Systems, Washington, DC, USA. IEEE Computer
Society, Los Alamitos (2007)

874

A. Byrski and M. Kisiel-Dorohinicki

3. Bordini, R., H¨
ubner, J., Wooldridge, M.: Programming Multi-Agent Systems in
AgentSpeak Using Jason. John Wiley & Sons, Ltd., Chichester (2007)
4. H¨
ubner, J.F., Sichman, J.S., Boissier, O.: Developing organised multiagent systems
using the moise+ model: programming issues at the system and agent levels. Int.
J. Agent-Oriented Softw. Eng. 1(3/4), 370–395 (2007)
5. Kisiel-Dorohinicki, M.: Agent-oriented model of simulated evolution. In: Grosky,
W.I., Plasil, F. (eds.) SOFSEM 2002. LNCS, vol. 2540, pp. 253–261. Springer,
Heidelberg (2002)
6. Byrski, A., Schaefer, R.: Immunological mechanism for asynchronous evolutionary computation boosting. In: ICMAM 2008: European workshop on Intelligent
Computational Methods and Applied Mathematics: an international forum for researches, teachers and students, Cracow, Poland (2008)
7. Szyperski, C.: Component Software: Beyond Object-Oriented Programming.
Addison-Wesley Longman Publishing Co., Inc., Boston (2002)
8. Meyer, B.: Object-Oriented Software Construction. Prentice Hall PTR, Englewood
Cliﬀs (2000)
9. Cetnarowicz, K., Kisiel-Dorohinicki, M., Nawarecki, E.: The application of evolution process in multi-agent world (MAW) to the prediction system. In: Tokoro, M.
(ed.) Proc. of the 2nd Int. Conf. on Multi-Agent Systems (ICMAS 1996). AAAI
Press, Menlo Park (1996)
10. Byrski, A., Kisiel-Dorohinicki, M., Nawarecki, E.: Agent-based evolution of neural
network architecture. In: Hamza, M. (ed.) Proc. of the IASTED Int. Symp.: Applied
Informatics. IASTED/ACTA Press (2002)
11. Byrski, A., Kisiel-Dorohinicki, M.: Immunological selection mechanism in agentbased evolutionary computation. In: Klopotek, M.A., Wierzchon, S.T., Trojanowski, K. (eds.) Intelligent Information Processing and Web Mining: proceedings of the international IIS: IIPWM 2005 conference, Gdansk, Poland. Advances
in Soft Computing, pp. 411–415. Springer, Heidelberg (2005)
12. Schaefer, R., Kolodziej, J.: Genetic search reinforced by the population hierarchy.
Foundations of Genetic Algorithms 7 (2003)

