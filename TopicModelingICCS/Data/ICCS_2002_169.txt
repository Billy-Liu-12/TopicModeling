A survey of the latest Levinson-type algorithms
for Toeplitz systems
A. Melman
Department of Mathematics and Computer Science
St. Mary’s College
Moraga, CA 94575, USA
melman@stmarys-ca.edu

Abstract. We present a survey of Levinson-type methods for the solution of strongly nonsingular symmetric Toeplitz systems. In particular, we include the latest methods based on the even-odd properties of
Toeplitz matrices. We describe the main idea behind these methods and
then list the different algorithms with their complexities.

1

Introduction

This work concerns Toeplitz matrices, the study of which continues to be of
interest, due to their occurrence in a host of applications, in engineering (signal and image processing), numerical analysis and elsewhere. The most common
problems involving these matrices are the computation of some or all of their
eigenvalues and the solution of systems of linear equations that have such matrices as their coefficient matrix. A good overview of the many areas in which
Toeplitz problems are encountered can be found in [4].
Eigenvalue problems appear in certain signal processing problems such as
harmonic retrieval (see, e.g., [20]) and were considered, among others, in [7], and
[21]. There is a wide range of applications of linear systems with a Toeplitz coefficient matrix: the computation of Padé approximations is but one example. In
signal processing, such systems are ubiquitous, most notably in linear prediction
(see, e.g., [16]). There exists a vast body of literature on Toeplitz matrices of
which it would be impossible to give a complete list. Let us just mention that
many early general results can be found in [14].
Symmetric Toeplitz matrices exhibit an even-odd structure which manifests
itself most clearly in their eigenvalues, of which there are two types: even and
odd, belonging to even and odd eigenvectors, respectively. As we will show, this
even-odd structure can be applied to linear systems as well. It is a remarkable
fact that, even today, this structure has not been fully exploited in Levinson-type
algorithms for symmetric positive-definite Toeplitz systems and it is this issue
that will be addressed here. We will give a survey of all Levinson-like algorithms
with their respective complexities, including some very recent ones.
In section 2, we present some basic definitions and results, and then, in
Section 3, examine linear systems. In section 4 we explain how the even-odd

2

A. Melman

structure can be applied to the solution of linear systems and list the different
Levinson-type algorithms with their complexities.

2

The even-odd structure of Toeplitz matrices

A matrix T ∈ IR(n,n) is said to be Toeplitz if its elements Tij satisfy Tij = ti−j
for some vector t = (t0 , . . . , tn−1 )T ∈ IRn , so that


t0 t−1 ... t1−n

. 
 t1 t0 . . . .. 
 .
T =

 . . .
.. .. t 
 ..
−1
tn−1 ... t1 t0
Toeplitz matrices are persymmetric, i.e., they are symmetric about their southwestnortheast diagonal. For such a matrix T , this is the same as requiring that
JT T J = T , where J is a matrix with ones on its southwest-northeast diagonal
and zeros everywhere else (the exchange matrix). It is easy to see that the inverse
of a persymmetric matrix is also persymmetric.
Matrices, which are both symmetric and persymmetric (of which symmetric
Toeplitz matrices are a special case) have an interesting even-odd structure,
which reveals itself most particularly in their spectra. Drawing on the results in
[2], it was shown in [5] that, given a real symmetric and persymmetric matrix of
order n, there exists an orthonormal basis for IRn , composed of n − bn/2c even
and bn/2c odd eigenvectors of that matrix. Here, bαc denotes the integral part
of α, an even vector v satisfies Jv = v, and an odd one satisfies Jw = −w.
(The identity and exchange matrices are denoted by I and J, respectively,
throughout this paper, without specifically indicating their dimensions, which
are assumed to be clear from the context.)
This even-odd structure, which, at least for the spectrum, has been known
for some time (see, e.g., [8]), has nevertheless not been fully exploited for the
solution of some common Toeplitz matrix problems, until fairly recently.
Let us now examine the even-odd structure as it relates to the solution of
Toeplitz systems.

3

Linear systems

A problem in signal processing, linear prediction (see, e.g., [16]), gives rise to the
Yule-Walker equations. This is a positive-definite Toeplitz system of the form
T x = −(t1 , ..., tn )T , where the right-hand side is very closely related to the first
column (or row) of T .
There are several classes of methods for solving this system: so-called fast
methods, with a complexity of O(n2 ) flops (for an overview, we refer to [12])
and superfast methods (see, e.g., [1],[3]), which are based on the Fast Fourier
Transform and have a complexity of O(n log2 n) flops. (Following [12], we define

Levinson-type algorithms for Toeplitz systems

3

a flop, or floating-point operation, as an addition, subtraction, multiplication,
or division.) However, for matrix dimensions of up to several hundreds, the fast
methods need fewer operations, and it is on those methods that we want to
concentrate, at least initially.
Probably the most well-known in this class of methods are Durbin’s method
([11]), which solves the Yule-Walker equations in 2n2 +O(n) flops and Levinson’s
algorithm ([15]), which solves T x = b, for an arbitrary right-hand side b, in
4n2 + O(n) flops. Both methods are recursive in nature and both construct a
solution from the top down, by progressively increasing the dimension of the
subsystems. In the course of Levinson’s algorithm, the Yule-Walker equations
are solved “in parallel” using Durbin’s algorithm, since it needs the intermediate
solutions at each step. For a good overview and full details of these algorithms,
we once again refer to [12].
In both Durbin’s and Levinson’s algorithms, it is assumed that the matrix
T is strongly nonsingular, i.e., that all its principal submatrices are nonsingular
(as is the case for a positive-definite matrix.)
Durbin’s algorithm was improved by Delsarte and Genin in [9], by proposing
the “split Levinson” method for the Yule-Walker system, exhibiting a complexity
of 23 n2 + O(n) flops. An algorithm for a system with arbitrary right-hand side,
proposed by the same authors in [10], improved upon Levinson’s algorithm by
achieving a complexity of 3n2 + O(n) flops.
The aforementioned algorithms still do not take full advantage of the evenodd structure. The next section describes algorithms that make better use of
it.

4

Even-odd algorithms

In this section, we give an outline of the way the even-odd structure can be more
fully expoited to improve both the complexity and parallelism of Levinson-type
methods. We assume the same assumptions on the matrix T as in Levinson’s
algorithm, i.e., strong nonsingularity. First, we write the right-hand side vector
b as the sum of its even and odd parts: b = be + bo , where
1
1
be = (b + Jb) and bo = (b − Jb).
2
2
Clearly, Jbe = be and Jbo = −bo . We then solve the system T x = b, by solving
the two systems T xe = be and T xo = bo . Because of the persymmetry of T , we
have that Jxe = xe and Jxo = −xo . The solution is then given by x = xe + xo .
To see what a basic step for such an algorithm looks like, let us assume that
the dimension of T is even and that T is normalized with t0 = 1. We concentrate
on the even solution: its odd counterpart is obtained analogously. Using the same
partition as in [17], the basic recursion step is given by the following:
At step

k
2

+ 1: (k = 2, 4, ..., n2 ):

Given:

Tk y = −t
,
Tk xe = be
t = (t1 , ..., tk )T , be = (ben − k +1 , ..., ben2 , ben2 , ..., b n − k +1 )T ,
2

2

2

2

4

A. Melman

compute u and α from:

   e

bn−k
α
1
t T tk+1
2
2


 t
Tk
Jt   u  =  be  ,
α
ben − k
tk+1 (Jt) T 1
2

2

where
u = Tk−1 (be − α(t + Jt)) = xe + α(y + Jy)
and:
α=

ben − k − t T xe
2

2

1 + tk+1 + tT (y + Jy)

·

For more details we refer to [18].
This method constructs a solution from the middle of the solution vector out,
rather than in the top-down approach of Levinson’s algorithm. When the dimension of the matrix
picture for the progression of

 the
 following
 thisgives
 is even,
•
•

•

  • • •
the solution:  ••  →  ••  →  ••  →  •• 
  • • •
•
•

•
•
•

whereas for Levinson’s algorithm,

•
•

•

•

,

•
•
•
•

•
•
•
•
•

         
we have:   →   →   →   →   →
         

•
•

...

 •• 
→  
 •• 

.

•
•

What are the advantages of this approach? First of all, just like Levinson’s
algorithm, it needs the intermediate solutions of the Yule-Walker equations.
However, contrary to that algorithm, we only need roughly half of them, as our
algorithm takes steps of two, rather than one. This means that in this case, the
basic requirement, in theory, is that only about half of the principal submatrices
of T be nonsingular, rather than all of them, as is required by Levinson’s algorithm. Another advantage is the increased parallelism: the even and odd parts
can be computed separately, if the computer architecture allows it.
Since all of the Levinson-type algorithms for solving a system with arbitrary
right-hand side need the solutions to the Yule-Walker equations, the algorithm
used for these equations has a significant influence on the overall complexity.
Here are the different algorithms with their complexities:
Levinson’s Algorithm: this is the classical Levinson algorithm for arbitrary
right-hand side with a complexity of 4n2 + O(n) flops.
Split Levinson Algorithm: this is the method from [9], which achieves a
complexity of 3n2 + O(n) flops.
Even-Odd Levinson Algorithm: this is the method explained in this section, where the Yule-Walker equations are computed with Durbin’s algorithm
(see [18].) The complexity of this algorithm is 3.5n2 + O(n) flops.
Even-Odd Split Levinson Algorithm: this is the Even-Odd Levinson
algorithm, where the Yule-Walker equations are solved using the “Split Levinson
Algorithm” from [9]. Its complexity is 2.5n2 + O(n) flops.

Levinson-type algorithms for Toeplitz systems

5

Two-Step Even-Odd Split Levinson Algorithm: this is the Even-Odd
Split Levinson algorithm from [19], where the Yule-Walker equations are solved
using a two-step method. Its complexity is 2.375n2 + O(n) flops, making it
the fastest polynomial-time algorithm for symmetric positive-definite Toeplitz
systems.
In addition to the improved complexity, all of the “Even-Odd” algorithms
just mentioned, which are all quite recent developments, are speeded up if two
independent processors are available. This is not the case for the Levinson and
Split Levinson methods, which cannot take advantage of this.

References
1. Ammar, G.S. and Gragg, W.B. (1987): The generalized Schur algorithm for the
superfast solution of Toeplitz systems. In Rational Approximations and its Applications in Mathematics and Physics, J. Gilewicz, M. Pindor and W. Siemaszko,
eds., Lecture Notes in Mathematics 1237, Berlin, pp. 315–330.
2. Andrew, A.L. (1973): Eigenvectors of certain matrices. Linear Algebra Appl., 7, pp.
151–162.
3. Bitmead, R.R. and Anderson, B.D.O. (1980): Asymptotically fast solution of
Toeplitz and related systems of linear equations. Linear Algebra Appl., 34, pp.
103–116.
4. Bunch, J.R. (1985): Stability of methods for solving Toeplitz systems of equations.
SIAM J. Sci. Stat. Comput., 6, pp. 349–364.
5. Cantoni, A. and Butler, F. (1976): Eigenvalues and eigenvectors of symmetric centrosymmetric matrices. Linear Algebra Appl., 13, pp. 275-288.
6. Chan, T.F., Hansen, P.C. (1992): A look-ahead Levinson algorithm for indefinite
Toeplitz systems. SIAM J. Matrix Anal. Appl., 13, , No.2, pp. 490–506.
7. Cybenko, G. and Van Loan, C.(1986): Computing the minimum eigenvalue of a
symmetric positive definite Toeplitz matrix. SIAM J. Sci. Stat. Comput., 7, No.1,
pp. 123–131.
8. Delsarte, P. and Genin, Y (1983): Spectral properties of finite Toeplitz matrices.
In Mathematical Theory of Networks and Systems, Proc. MTNS-83 International
Symposium, Beer-Sheva, Israel, pp. 194–213.
9. Delsarte, P. and Genin, Y. (1986): The split Levinson algorithm. IEEE Trans.
Acoust. Speech, Signal Processing, ASSP-34, pp. 470–478.
10. Delsarte, P. and Genin, Y. (1989): An extension of the split Levinson algorithm
and its relatives to the joint process estimation problem. IEEE Trans. Inf. Theory,
35, No. 2, pp. 482–485.
11. Durbin, J. (1960): The fitting of time series model. Rev. Inst. Int. Stat., 28, pp.
233–243.
12. Golub, G. and Van Loan, C. (1989): Matrix Computations. The Johns Hopkins
University Press, Baltimore and London.
13. Gover, M.J.C. and Barnett, S. (1985): Inversion of Toeplitz matrices which are not
strongly nonsingular. IMA J. Numer. Anal., 5, pp. 101–110.
14. Grenander, U. and Szegö, G. (1958): Toeplitz Forms and Their Applications. University of California Press, Berkeley, CA.
15. Levinson, N. (1947): The Wiener RMS (root mean square) error criterion in filter
design and prediction. J. Math. Phys., 25, pp. 261–278.

6

A. Melman

16. Makhoul, J. (1975): Linear prediction: A tutorial review. Proc. IEEE, 63, pp.
561–580.
17. Melman, A. (1998): Spectral functions for real symmetric Toeplitz matrices. J.
Comp. Appl. Math, 98, pp. 233-243.
18. Melman, A. (1999): A symmetric algorithm for Toeplitz systems. Linear Algebra
and its Applications, 301, pp. 145-152.
19. Melman, A. (2001): A two-step even-odd split Levinson algorithm for Toeplitz
systems. Linear Algebra and its Applications, 338, pp. 219-137.
20. Pisarenko, V.F. (1973): The retrieval of harmonics from a covariance function.
Geophys. J. Royal Astron. Soc., 33, pp. 347–366.
21. Trench, W.F. (1989): Numerical solution of the eigenvalue problem for Hermitian
Toeplitz matrices. SIAM J. Matrix Anal. Appl., Vol.10, No.2, pp. 135–146.

