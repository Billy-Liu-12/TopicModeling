Approximate B-Spline Surface Based on
RBF Neural Networks
Xumin Liu1,2, Houkuan Huang1, and Weixiang Xu3
1

School of Computer and Information Technology, Beijing Jiaotong University, 100044
2
School of Information Engineering, Capital Normal University, Beijing 100037
3
School of Traffic and Transportation, Beijing Jiaotong University, 100044
liuxmxxxy@263.net

Abstract. Surface reconstruction is a key technology in geometric reverse engineering. In order to get the geometric model of object we need a large number
of metrical points to construct the surface. According to the strong points of
RBF network such as robust, rehabilitating ability and approximating ability to
any nonlinear function in arbitrary precision, we presented a new method to reconstruct B-spline surface by using RBF. Simulation experiments were made
based on the theoretical analysis. The result indicated that this model could not
only efficiently approximate incomplete surface with noise, automatically delete and repair the input wrong points through self-learning, but has a rapid
learning speed, which improves the reconstructing efficiency and precision of
dilapidation incomplete surface. The surface obtained by this model has a good
smooth character.

1 Introduction
Reverse Engineering (RE), which means the designing of products is based on practicality instead of conception, has recently become a researching hotspot in the field of
CAD/CAM. It’s widely applied in the industrial formative field, which relates to freeform surface, such as aviation, automobile and shipping, etc. Based on the attainable
object model, RE can be used for the construction of the design model. Using the
adjustment and modification of character parameter of the reconstructed model, the
result is to approach or modify the object model, so that it can meet many kinds of
requirements. After the data attained from scanning and measure is processed, surface
reconstruction become a key technology of RE. It denotes the surface of the measured
object in the form of some piecewise smooth, and unites continued global continuous
surfaces at definite range of error through some scatter data points acquired by
measure.
As geometrical scanning machines are more widely used, the number and complexity of scanned objects increase. It is inevitable to attain 3D model with noise when
scanned by the scanning machine. Therefore, it is important to remove the noise data
out of all the data points and meanwhile keep the original shape of the object. With
the development of Artificial Neural Networks (ANN) theory, neural networks surface reconstruction method is brought forward by a great deal of home and broad
literatures. They put forward scatter data points surface modeling method from a new
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3514, pp. 995 – 1002, 2005.
© Springer-Verlag Berlin Heidelberg 2005

996

X. Liu, H. Huang, and W. Xu

point of view. ANN is a large-scale, distributing and parallel non-linear information
processing system. It has powerful learning capability. It can learn and gain knowledge from samples. If we use the powerful non-linear approach ability of ANN to
start measured scatter data points surface modeling, the result model will not only
have higher approach precision, but also be somewhat antinoise capability.
There is primary research in the surface reconstruction in intelligent ways, such as
the reconstruction for partial disrepaired surface by improved BP neural networks.
Presently, the ANN aimed to modeling often adopts three layered feedforward networks as its network topology structure, and adopts algorithm of Back-Propagation
[1] as its learning algorithm. Because the algorithm uses negative gradient descent
algorithm to guide the search optimize process of weight and threshold of network, it
has some disadvantages such as making search optimize process get into local minimum and slow convergence speed, etc. Although Simulated-Annealing method can
overcome the BP algorithm’s shortcoming of local optimize [2], it is at the price of
sacrificing convergence speed, so its application has some limits. The Genetic Algorithms neural network has the specialty of search traverse [3]. It is based on search
optimize chromosome by evolution of population, so it has some discomfort when
modeling.
The Radial Basis Function (RBF) adopted in this paper is better than the above
networks no matter it is approaching ability, classifying ability, convergence speed, or
search traversal. So it is applied widely.
This paper put forward the reconstruction method of surface , which come from the
standard geometrical description model of industrial product. The method combines
with the advantages of Neural Network surface reconstruction, such as precision, high
efficiency, and anti-noise. It aims at requirement of the crust surface reconstruction in
industrial product. The paper adopts RBF network to pre-fit scatter measure data
points from B-spline surface. We use RBF network to obtain the mapping relationship
of the surface and store this relationship in the weight and threshold. This mold of
holographic memory has strong capacity of fault-tolerant and association, so it won’t
bias the output because of the break of a few neuron or slight lack of input data, hence
it has a strong robust. Better precision of reconstruction can be obtained by using the
nonlinear approaching ability of the RBF network to construct unorganized points.

2 RBF Neural Network
RBF neural network (RBFNN) is a kind of efficient Multi-Layer forward network
after Multi-Layer Perceptions (MLP) in recent years. It is a partially approaching
network, which originates from Radius Basis Function method of multivariable interpolation in numerical analysis. The basic structure includes input layer, hidden layer
and output layer, all of which has different functions. The input layer is composed of
some source point (perceptive unit) , which connect the network with the outside
environment. The function of the hidden layer is to transits between input space and
hidden space. In most cases, hidden space has a higher dimension. The output layer,
which is linear, has the function of providing echoing for the stimulated mold (information) of the function and the input layer. It has been proved that a RBF neural network can approach any non-linear function at any precision, and it has the ability of

Approximate B-Spline Surface Based on RBF Neural Networks

997

optimizing functional approach ability[4], in case of the concealed nodes are adequate, and the studying is sufficient.
2.1 RBF Neural Network Structure and Learning Way
RBF neural network is a kind of network of three layers feedforward. The number of
each layer’s node respectively is p, n, m. It’s structure is showed in Fig.1.
C1 δ1

x1

y1(X)

K

…

…

…

Cj δj

xi

K

yk(X)

wij

…

…

…

Cn δn

xp

ym (X)

K
hidden layer

input layer

output layer

Fig. 1. Construction of RBF neural network

The weight from input layer to concealed layer is fixed in 1. Only the weight
wkj(j=1,2,…,n; k=1,2,…,m) coming from concealed layer to output layer can be adjusted.
The concealed layer output function (namely Kernel Function) is often defined as
Gaussian Kernel Function. It produces a localized response to input prompting. This
character makes Gaussian concealed layer have a clustering impact on input sample.
The nodes concealed represent the class numbers of clustering. The center of concealed layer is the agglomerate center point of this kind. The Kernel Function’s form
is usual as follows:

φ j ( X ) = exp[−

X −Cj
2δ 2j

2

]

( j = 1,2,L, n)

(1)

In the expression (1), Φj(X) is the output of jth node in concealed layer.
X=( x1,x2,...,xp )T is network input vector, where║*║represents Euclidean normal data.
Let X-Cj=(X-Cj)T(X-Cj); Cj be the center vector of jth Gaussian unit in concealed
layer; δj be radius. From formula (1), we can see that: The function transform is from
input layer to output layer. The output of concealed layer nodes ranges from 0 to 1,
and the input sample is closer to the center of the nodes, the output value is larger.
RBF neural network’s output is the linear combination of concealed nodes output.
The output form is represented as follows:

998

X. Liu, H. Huang, and W. Xu
n

y k = ∑ wkj φ j ( X )

(k = 1,2,L , m)

j =1

(2)

The formula (2) is written in the form of matrix.
Y = Wφ

(3)
T

In the formula (3), W=(w1,w2,…,wq,…,wm)
is the weight matrix
(wq=(wq1,wq2,…,wqn)) between concealed layer to output layer. Φ=(Φ1,Φ2,…,Φn)T is
the output matrix of the concealed.
RBF neural network do its training by supervisory learning method. For a neural
network which has certain type and the number of Kernel Function, in order to make
it rightly perform the expected data processing, two parameters are needed to be ensured: one is Kernel Function’s center which is located at the input sample data space,
the other is the weight vector aggregation from concealed layer to output layer. So the
learning process of a RBF neural network includes two phases:
The first stage is to decide the Gaussian Kernel Function’s center Cj and radius δj of
each node of concealed layer, according to all the input samples.
The second stage is to seek the output layer’s weight Wi after deciding concealed
layer’s parameters, and according to the sample, adopt error revise learning algorithm,
for instance least square method and gradient descent method.
At present, as for the first phase there are training methods such as clustering
method based on k-means value [5], Kohonen clustering method [6], Orthogonal least
squares learning algorithm [7], gradient descent method [8], and for each class sample
covariance’s Gram-Schmidt Orthogonal method [9] etc. The training method in the
second phase is mainly least gradient descent method [8], which is used to seek the
target function. Recently, Kaminski has put forward the standard of Kernel Function
Gram-Schmidt Orthogonal training method [10].
RBF neural network can make certain the Gaussian Kernel Function’s parameters
Cj and δj by means of Clustering algorithms. The most simple and effective way is Kmeans [11] method. The detailed steps are as follows:
1) Initialize all the clustering center Cj. The number of the center is usually equal to
the number of concealed layer’s nodes n.
2) Classify all the input samples X according to the closest center Cj, from criterion
(4), classify the sample as class i; G is the sum of sample.
X g − C i = min X g − C i

( g = 1,2, L , G )

(4)

3) Calculate the mean of each kind of samples.
E (C j ) =

1
Nj

Nj

∑X
i =1

i

(5)

Nj is the number of sample of each class. We substitute E(Cj) for Cj;
4) Repeat the process (2), (3), until E(Cj)-C inclines to zero, and confirm Cj as the
center of hidden layer activation function.

Approximate B-Spline Surface Based on RBF Neural Networks

999

5) Each kind of radius can be defined as the average distance from the training
sample, which belongs to this class, to the clustering center. For Gaussian RadiusBasis-Function, usually δj can simply have the value of 1.
2.2 Use RBF Network to Do Pre-fit Scatter Measure Data Points
Every point of the free-form surface of the three-dimensional space can be described
by the mapping relation z=f(x,y). So the essential of using RBF neural network to prefit scatter measure data points is a optimize process of neural network parameter for
precisely mapping the antetype surface S. Firstly, input the data of measure points into
RBF neural network. Then the neural network begins to learn from the known information. When the error between the neural network output and the real value is less
than the fixed maximal error, the training of neural network is finished. The prefitting to archetypal surface is achieved by RBF neural network.

3 The Transform to B-Spline Surface
These are the most widely used class of approximating splines. B-splines have two
advantages: (1) the degree of a B-splines polynomial can be set independently of the
number of control points (with certain limitations), and (2) B-splines allow local control over the shape of a spline curve or surface.
We can obtain a vector point function over a B-spline surface using the Cartesian
product of B-spline basis functions. The Bicubic B-spline surface’s mathematic description is as follows:
m+2 n+2

S (u , v ) = ∑ ∑ d st B s ,3 (u , v ) ⋅ Bt , 3 (u , v )

(6)

s =1 t =1

Formula (6) satisfy S(ui,vj)=Pij(i=1,2,…,m; j=1,2,…,n), where dst (s=1,2,…, m+2;
t=1,2,…,n+2) is the control vertexes of B-spline surface. Bs,3(u, v) and Bt,3(u, v) are
Bicubic B-spline basis function.
Append with standardized condition, the basic function of cubic B-spline curve can
be written as
B3,3 (u ) = 1/6 ⋅ u 3
B2,3 (u ) = 1/6 ⋅ (1 + 3u + 3u 2 − 3u 3 )
B1,3 (u ) = 1/6 ⋅ (4 − 6u 2 + 3u 3 )

(7)

B0,3 (u ) = 1/6 ⋅ (1 − 3u + 3u − u )
2

3

Where u is a parameter variable between two controlling vertexe (0≤u≤1).
Suppose the known data points mesh is Pij (namely the standard mesh defined by
data point set Pij, i=1,2,...,m; j=1,2,...,n), m and n are the u orientation and v orientation of the number of data points. Now reverse seeks the Bicubic B-spine surface.
B-spline interpolation includes two steps. Firstly, calculate every control polygon’s
vertex according to the data points at the direction of u (or v). Then calculate the
polygon mesh at the direction of v (or u) according to the obtained polygon vertex.

1000

X. Liu, H. Huang, and W. Xu

Finally, the B-spline surface defined by the mesh can interpolate the original data
points Pij. The essential of resolving is seeking the control vertex mesh dst of the target
B-spline surface.
The main steps of the transformation from RBF neural network mapping model
z=f(x,y) to B-spline surface representation are as follows[11].
1) Picking up boundary points concentrated from antetype surface S, and then fit
into four boundary B-spline curve C1,C2,C3,C4 according to the measured object’s
specific geometrical character. Using bilinear interpolation method to gain the boundary interpolation B-spline surface as the basis surface Sb.
2) Doing uniform parameter segmentation to the basis surface Sb. We get the mesh
data point set of the parameter region.
D={(ui,vj):i=1,2,…,m; j=1,2,…,n}
Seek the mesh data point set D’s mapping in the XYZ space.
D'={(x(u,v),y(u,v),z(u,v))}
Map the D' to the XOY projection surface to project, get the basic interpolation
mesh.
D”={(x(u,v),y(u,v))}. The result is show as Fig. 2.

Z

Sb

C2

C1

C3

C3

D'

X

y

D"

Fig. 2. The formation of basic interpolation mesh

3) Input each node of basic interpolation mesh D” into the trained perfectly RBF
neural network at measure data points pre-fitting stage. Then get the standard mesh
topology point set of surface S.
P={(x,y,z):((x,y)∈D” ,z=f(x,y))}
Among above formula, z=f(x,y) if output information of RBF neural network.
4) Following standard mesh topology point set P to interpolation B-spline surface,
we can achieve antetype surface’s transformation from RBF neural network mapping
model z=f(x,y) to B-spline surface representation.
5) If the reverse resolution precision does not meet the requirement, we regard interpolation B-spline surface as new basis surface Sb, and return to 2). Then we start the
next turn calculation for interpolation.

Approximate B-Spline Surface Based on RBF Neural Networks

1001

4 Simulation Experiment
Experiment of fitting B-splines surface by RBF network.
The control vertex coordinates of input as follow:
d11= (10,150); d12=(40,150); d13=(50,60); d14=(80,130);
d21=(20,150); d22=(60,130); d23=(80,110); d24=(120,170);
d31=(40,250); d32=(70,200); d33=(120,150); d34=(150,250);
d41=(60,200); d42=(90,150); d43=(130,100); d44=(150,200);
In experiment, B-Splines surface is drawn according to control vertexes firstly.
Then noise is added, that range of noise is 0.5. The data with noise is training set. The
step is 0.01.
Control point coordinates are network inputs. Data points produced by B-splines
surface are expected output. We train the noise data by the above RBF and reconstruct
the surface by using the original data set, noise contaminated data set and data set
obtained by the trained RBF. The simulation result is depicted as fig. 3.

(a) Surface obtained original data set

(c) Noise is added in x coordinate

(b) Noise is added in x and y coordinate

(d) Surface obtained by the data set after fitting

Fig. 3. B-splines surface by RBF network fitting noise

1002

X. Liu, H. Huang, and W. Xu

The experiment result denotes that the fitting precision of RBF is quite good and
the training speed of network is fast. The quality and quantity of training sample influence directly the fitting precision and training speed. The less the training sample’s
variance, the higher is the convergence precision and the convergence speed.

5 Conclusions
This paper presented a RBF model to reconstruct surface according to the characteristics of RBF such as good approximating ability, good generalizability, fast convergence speed and strong robust ability. Theoretic analysis and experiment result both
denote that by this model, we can construct very smooth surface and raise the efficiency and precision of reconstructing dilapidation incomplete surface. This paper
gives a new method of surface modeling with dense and messy data set in a new
viewpoint.

Acknowledgements
This paper is supported by Beijing Educational Committee under Grant No.
KM200410028013

References
1. Bian Zhaoqi, Zhang Xuegong, Pattern Recognition Principles, Tsinghua University Press,
(2000). (in Chinese)
2. Wang Kai, Zhang Caiming, “Neural Network Method to Reconstruct the Freeform Surface”, Journal of Computer-Aided Design & Computer Graphics, Vol. 10, No. 3, (1998)
193-199. (in Chinese)
3. Gao hongfeng et al. “Neural Network Trained with Genetic Algorithms and Its Application
for Non-Linear System Identification”, Journal of Luoyang Institute of Technology, Vol.
19, No. 1, (1998) 74-77. (in Chinese)
4. Chen S, Cowan C F N, Grant P M, “Orthogonal least squares learning algorithm for radial
basis function network”, IEEE Trans on Neural Net works, No. 2,( 1991)904-910.
5. Bezdek J C, Pattern recognition with fuzzy objective function algorithm, New York: Plenum (1981).
6. Kohonen T, Self-organization and associative memory, Berlin, Germany Springer Velag
(1989).
7. Chen S et al, “Orthogonal least squares learning algorithm for radial basis function network”, IEEE Trans on Neural Networks, Vol. 2, No. 2, (1991) 302-309.
8. Tarassenko B et al, “Supervised and unsupervised learning in radial basis function classifiers”, Vision Image Signal Processing, Vol. 141, No. 4, (1994) 210-216.
9. Musavi M F et al, “On the training of radial basis function neural networks “, Neural Networks, Vol. 5, No. 3, (1992) 595-603.
10. Kaminski W et al, “Kernel orthonormalization in radial basis function neural networks”,
IEEE Trans on Neural Networks, Vol. 8, No. 5, (1997) 1177-1183.
11. Zhou Jinyu, Xie Liyang, “B-spline Surface Reconstruction Based on RBFNN Pre fitting”,
Journal of Northeastern University, Vol. 24, No. 6, (2003)556-559. (in Chinese)

