Procedia Computer Science
Volume 80, 2016, Pages 1968–1977
ICCS 2016. The International Conference on Computational
Science

Teaching computational modeling in the data science era
Philippe J. Giabbanelli, PhD1 and Vijay K. Mago, PhD2
1
2

Department of Computer Science, Northern Illinois University, DeKalb IL, USA
giabba@cs.niu.edu
Department of Computer Science, Lakehead University, Thunder Bay ON, Canada
vmago@lakeheadu.ca

Abstract
Integrating data and models is an important and still challenging goal in science. Computational
modeling has been taught for decades and regularly revised, for example in the 2000s where it
became more inclusive of data mining. As we are now in the ‘data science’ era, we have the
occasion (and often the incentive) to teach in an integrative manner computational modeling and
data science. In this paper, we reviewed the content of courses and programs on computational
modeling and/or data science. From this review and our teaching experience, we formed a set
of design principles for an integrative course. We independently implemented these principles
in two public research universities, in Canada and the US, for a course targeting graduate
students and upper-division undergraduates. We discuss and contrast these implementations,
and suggest ways in which the teaching of computational science can continue to be revised
going forward.
Keywords: Course content; Data analytics; Simulations

1

Introduction

In the context of computer science, ‘modeling’ is used to cover a variety of ﬁelds ranging from
developing UML models in software engineering to entity-relationship modeling in databases.
In the ﬁeld of modeling and simulation, modeling is the process of identifying the common
properties of closely related phenomena or entities and then using these to produce a useful
characterization. Speciﬁcally, in computational modeling this utility is expressed in the form of
models that can run as a software program on a computer [11]. Computational modeling has
been taught for several decades: for example, the well-known PhD in Computational Sciences
and Informatics at George Mason University was created in 1992 [3]. The ways in which
computational modeling needs to be taught changes with societal demands and innovations.
In the early 2000s, data mining was increasingly combined with computational modeling, for
example in the Computational and Statistical Learning PhD introduced at Carnegie Mellon
University in 2001 [1]. Since the late 2000s, a shift has operated toward ‘data science’.
1968

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.517

Teaching computational modeling in the data science era

Giabbanelli and Mago

The growing societal needs for trained data scientists have been emphasized by several large
bodies. Several reports funded by the National Science Foundation touched on this issue [6, 16],
and its director went on to state (emphasis added) [15]:
“American scientists must rise to the challenges and seize the opportunities aﬀorded
by this new, data-driven revolution. The work we do today will lay the groundwork
for new enterprises and fortify the foundations for U.S. competitiveness for decades
to come.”
Similarly, the Department of Defense has expressed that data scientists are the most in
demand job for the military, while the National Institutes of Health is heavily committed to
supporting initiatives in data science. By 2012, these calls were echoed by changes in curricula
and research: almost two hundred universities had data science degrees in some form [4],
and the revised Computing Classiﬁcation System of the ACM included 109 concepts with the
word ‘data’ [1]. Not only are the main funding bodies and institutions promoting more data
science degrees and curricula, but students are actively seeking them as well. For example, the
online Johns Hopkins Data Science Specialization enrolled 1.76 million students within a year1 .
Consequently, a new transformation of computational modeling programs is in place that seeks
greater synergies with data science topics. A symbol of this shift is the fact that the PhD in
Computational Sciences and Informatics at George Mason University is now delivered by the
Department of Computational and Data Sciences.
In this paper, we detail the design of a modelling and simulation course targetting upperdivision undergraduates and graduate students. Our focus is to update our course content to
include more data science topics. The course was independently designed by the two authors,
who were strategic hires in data science at two diﬀerent North American universities, thus allowing to compare design and experiences. In Section 2 we review how courses and programs at a
variety of institutions have addressed computational modeling and/or data science. In Section 3
we introduce the two designs chosen for our course. As for many data science programs [1, 2, 3],
we found that having a project was essential. A discussion on how such projects were set-up
and managed, as well as selected examples, are given in Section 4. Finally, we discuss the next
update of course material going forward in Section 5 and oﬀer concluding remarks.

2

Content of modeling & data science courses/programs

2.1

Modeling and simulation

Generic modeling and simulation courses typically include the modeling process, and techniques
for continuous (system dynamics, systems of diﬀerential equations) or discrete models (cellular
automata, agent-based models). Additional topics range from hybrid models to experimental
design or large-scale simulations. The lists of topics for three courses are provided in Table 1.
The ﬁrst two courses are two instances of a graduate-level course that we collegially taught
at Simon Fraser University, Canada [12], and that inﬂuenced the design of the two versions
presented in section 3. For comparison, the last course is an undergraduate course oﬀered at
Woﬀord College, whose description is part of the ACM Computer Science Curricula 2013 [19].

1 http://simplystatistics.org/2015/02/05/johns-hopkins-data-science-specialization-top-performers/

1969

Teaching computational modeling in the data science era

Giabbanelli and Mago

Table 1: Content for three courses on modelling and simulation
MATH800 (Fall’08)
MATH800 (Fall’11)
COSC/MATH 201 (Fall’11)
Modeling process
Modelling social networks
Topological data analysis
High-performance computing
Spatial analysis in criminology
Computational error
Crime modelling
Fuzzy cognitive maps
Simulation techniques
Issues of data manipulation
Health promotion in prisons
Empirical models
Cellular automata
Computational criminology
Monte Carlo simulations
Complex networks
Stat. model for homelessness
Interactive visualization
Urban dynamics
Complex systems and obesity
Agent-based modeling
Operation research
System dynamics
Queuing theory
Queuing theory

2.2

Data science

The data science courses currently oﬀered can vary greatly in content. Chatﬁeld and colleagues
stated that “despite the recent sensational declaration of a data scientist as ‘the sexiest job of the
21st century’, however, there is a lack of published rigorous studies of what a data scientist is,
and what job skills this hottest job title may require” [4]. The ambiguity in terms of required
skills is reﬂected in the heterogeneity of course materials. Varvel and colleagues surveyed
data science courses and divided them into four categories based on the extent to which they
contained data science topics. The categories go from ‘data-centric’ (exclusive focus; 8% of
courses) to ‘data-inclusive’ (devoted segments; 11% of courses), ‘digital’ (some highly relevant
topics; 27% of courses), and traditional (54%) [20]. There are thus data science courses that
are simply a rebranding of existing ones, and others that were speciﬁcally developed. Examples
of the latter can be found as part of the Data Science undergraduate program oﬀered at the
College of Charleston [1]. Three courses are unique to the program: an introductory course
including knowledge discovery, analysis of large datasets, and inductive data-driven modeling; a
dataset organization course touching on databases, data cleaning and wrangling; and a project
course that applies the techniques to speciﬁc ﬁelds such as psychology. Several of these themes
have been incorporated in the new design of our courses.

2.3

Integrated computational modeling and data science

There is a widespread misconception that computational modeling is not part of data science,
despite data science being a (large) umbrella term. A review of 6 academic and 18 industry
deﬁnitions of a data scientist only mentioned modeling in 1 deﬁnition, as part of ‘statistical and
modeling expertise’ [4]. However, modeling is particularly important, as explained in a recent
article by Cleveland [5]:
“The data analyst faces two critical tasks [...] (1) speciﬁcation - the building
of a model for the data and (2) estimation and distribution. [...] A vast array
of methods exist for estimation and distribution, but far less eﬀort has gone into
methods for model building. [...] Often, the model building phase is the salient
part of the analysis, and the estimation and distribution phase is straightforward.
1970

Teaching computational modeling in the data science era

Giabbanelli and Mago

Model building is complex because it requires combining information from exploring
the data and information from sources external to the data such as subject matter
theory and other sets of data.”
Teaching such model building skills is thus essential. To illustrate that point, imagine that
a data scientist is meeting with a decision-maker to discuss ﬁndings regarding the data. The
decision-maker may not only be interested in the properties of the data at present: there is
likely to be questions about how data came to be the way it is, or what interventions can change
the situation going forward. Answering such questions requires models to generate theories,
or conduct what-if analyses. That is, the toolbox of a data scientist should not be limited to
regression analysis and data mining but should also include discrete and continuous models.
Critically, modeling should not be seen as an advanced/optional course for data scientists or
a separate track within a larger program. Rather, the two need to be integrated, and that
is commonly not the case [3]. In the words of Finkelstein, “what is surprising is that science
largely looks at data and models separately, and as a result we miss the principal challenge
– the articulation of modelling and experimentation” [14]. There have been plans to develop
curriculum integrating computational modeling and data science. For example, Embry-Riddle
Aeronautical University planned to add a data science track to its computational program [17].
The program in Computational and Data Sciences at George Mason University is built on that
integration. Of the 6 required computational and data sciences core courses, 2 are modeling and
simulations courses, and 1 is an introductory course covering scientiﬁc discovery via simulations
and data analysis [3]. The balance of content in this program has inspired the design of our
course.

3
3.1

Our course designs
Design principles

The context for the course development is as follows. The two authors have a background
in computational modeling and simulation. In Fall 2015, they were part of strategic hires in
data science in the computer science departments of two public research universities: Lakehead
University (‘LU’) in Ontario, Canada, and Northern Illinois University (‘NIU’) in Illinois, USA.
The two departments deliver master degrees but not PhD. In both cases, no classes were
currently taught in modeling and simulation. However, classes touching on data science were
introduced at the same time as we delivered the course. At LU, the class on big data was
taught in parallel, while at NIU classes on data visualization and information retrieval were
taught in the same semester. We thus had to develop a course on computational modeling and
data science that would be directly accessible upon admission to the program, while minimizing
partial overlaps with other courses (whose content was in a state of ﬂux). While we did not
expect a qualiﬁed teaching assistant to be available for such new courses, this did not aﬀect our
design principles.
The course was independently designed for LU and NIU with a set of shared principles,
emanating from our experience in delivering MATH800 in Fall 2011 (Table 1) and from the
review conducted in the previous section:
1971

Teaching computational modeling in the data science era

Giabbanelli and Mago

Design principles for a course on computational modeling and data science
(1) Students should ﬁrst be provided an overview of the ﬁeld (in line with Table 1). Then,
the course should include at least 3 modeling techniques, exposing students to both
individual-level models and aggregate models.
(2) Students should be familiarized with one programming environment for modeling and
one programming environment for data analytics. These environments should use the
object-oriented and imperative paradigms that students are most familiar with. Since
no prior exposure to either data science or simulation is assumed, the introduction to
these environments will have to start from basic syntax.
(3) Students should be actively engaged in interdisciplinary projects, as is generally the
case in computational and/or data science programs [3, 17, 1] and as we previously
recommended [9, 10].
(4) Students should be exposed to seminal and recent research papers on modeling and
data science. Students should critically evaluate these papers to ﬁnd shortcomings,
and form teams to provide solutions combining data science and modeling.

3.2

Implementation

At LU, the modeling class was taught in Fall 2015 to 3 graduate students and 4 undergraduates.
The course content is summarized in Table 2 over 9 modules. Structural-equation modeling
was an optional module, which was also taught. The design principles were implemented as
follows:
(1) Three modeling techniques are used: 1 individual-level technique (Cellular Automata)
and 2 aggregate techniques (Compartmental Models, and Fuzzy Cognitive Maps). These
three techniques were selected or extensive research experience by the instructor [18, 13].
(2) Students were introduced to R and Matlab. Since fuzzy logic was an important modeling
tool in the course, Matlab was chosen as it provides a fuzzy toolbox. R was selected as it
is commonly used for data analytics (alongside Python).
(3) Students worked in 3 teams of 2 and 1 ‘team’ of 1 on projects. They were pointed to data
repositories in week 1 and asked at the same time to provide a survey of the literature
(via google scholar) on a problem of their choice. Their survey was discussed in class,
following by discussions about the model and ﬁnally using the data.
(4) All students read 13 research papers, which were debated in class. In addition, teams
performed of varying amount of readings for the speciﬁc needs of their project. A LaTeX
report summarized each project.
At NIU, the modeling class was designed for Spring 2016, with an enrollment of approximately 30 students, equally composed of upper-division undergraduates and graduate students.
The course content is summarized in Table 3 over 9 modules; experimental design is an optional
theme. The design principles were implemented as follows::
(1) Three modeling techniques are used: 2 individual-level technique (Networks, Agent-Based
Modeling) and 1 aggregate techniques (System Dynamics). These three techniques were
selected because they were the ones taught at the Institutes of Systems Sciences and
Health (ISSH), and the author has conducted research in all three [7, 8].
(2) Students used Java through AnyLogic for simulation design, and Python for data analytics. This was motivated by having publicly available teaching all three techniques in
AnyLogic (by Prof. Nathaniel Osgood).
1972

Teaching computational modeling in the data science era

Module
1
2
3
4
5
6
7
8
9

Giabbanelli and Mago

Table 2: Course content for the LU implementation
Theme
Name
Principles of modeling and simulation
Programming with MATLAB
Programming
Programming with R
Data science
Data preprocessing
Cellular automata
Compartmental models
Modeling techniques Fuzzy Logic
Fuzzy Cognitive Maps
Adaptive Neuro Fuzzy Inference System

Table 3: Course content for the NIU implementation
Name
Content
Overview of modeling
and data science
Abstracting a problem
Basics of abstraction
Implementation in AnyLogic
Principles of Compartmental Models
Basic models
The SIR model
Modeling
infectious
What makes a good model
diseases
Mathematical notation
What is a network
Finding important elements
Network concepts
Modeling processes on networks
Network properties
Modeling with net- Implementing a network model with
works
AnyLogic
What is an ABM
Agent-based models
Implementing ABMs with AnyLogic
Understanding
the Data Mining in Python
Data science data for/from models
Initializing from ind. distributions
Using data to populate Initializing from individual cases
Validating at the aggregate level
and validate models
Cleaning data
Data cleaning and wrangling in Python
Building Selenium scripts
Web crawlers
Acquiring data
Collection on humans and ethics

Module Theme
1
2

3

4
5
6
6

7
8
9

(3) Students are expected to work in teams of 5 on projects designed by the course instructor.
For each project, students will be pointed to speciﬁc datasets and start with a literature
review.
(4) Students will be given 8 readings consisting of 2 (undergraduates) to 4 (graduates) papers.
To ensure that students do read the papers, they answer questions on each reading in class
on quizzes worth 40% of their total grade. Students will deliver projects in LaTeX.
1973

Teaching computational modeling in the data science era

4
4.1

Giabbanelli and Mago

Course projects
Project design

The data science and/or computational modeling programs that we surveyed often require that
students take courses in another discipline and do a project/capstone. For example, at the
College of Charleston, data science students learned about molecular biology or psychology;
doing a data science capstone was a core course [1]. Similarly, at George Mason University,
students had concentration areas in physics, chemistry, and biology; their research project
was optional [3]. Since we developed a course rather than a program, our research projects
required a minimal exposure to another ﬁeld. As both authors have ample experience in health
informatics, projects were mostly geared toward the health sciences.
At LU, students were asked to present a research proposal consisting of: an objective, a
discussion of recent research and identiﬁcation of a knowledge gap, links to dataset (if required),
and a potential conference/journal (to identify the intended readership). At NIU, projects were
designed for the students, who instead started by a literature review. For all projects, using
real data was mandatory. Indeed, “engaging students by using real data to address scientiﬁc
questions in formal education settings is known to be an eﬀective instructional approach” [2]
and data science topics easily lend themselves to it.

4.2

Projects

There were four LU projects. One individual projected was a software benchmarking, while the
others were performed in teams with the following subjects, techniques, and datasets:
• A study of cancer using structural equation modeling and fuzzy cognitive maps, based on
the P53 Mutant Dataset from the University of California at Irvine (Figure 1(a)).
• An examination of nutritional status in the US based on fuzzy inference systems, using
the National Health and Nutrition Examination Survey (NHANES) data.
• A predictive model of cardiovascular diseases using structural equation modeling and fuzzy
cognitive maps, using the Canadian Community Health Survey (CCHS) (Figure 1(b)).
The six NIU projects varied from reviews to pilot projects on new topics or follow-up of previously developed models. It was decided that, to emphasize that students were dealing with
real-world data, they should have access as much as possible to those directly involved with the
data. Local non-governmental organizations were thus approached for the 3 months preceding
the start of classes, with the oﬀer to share their data and expertise in return for help with
making sense of the data. One organization accepted to partner, provided their anonymized
individual-level data with explanations, and agreed to regularly meet with students who would
take on the project. Similarly, researchers in other ﬁelds were approached and one accepted to
discuss with students the results on their data analysis on gerontology data.

5

Discussion and conclusion

Data and models should be looked at together [14]. Revising a course on computational modeling and simulation during the data science era provides a much needed incentive to work
toward that integration. In this paper, we introduced our design principles for a course on
computational modeling and data science, and discussed two independent implementations of
these principles at two public research universities. Since both implementations had to combine data science and modeling topics, it was expected that neither would be classiﬁed as only
1974

Teaching computational modeling in the data science era

Giabbanelli and Mago

Figure 1: Two models developed in the LU projects. A fuzzy cognitive map (FCM) was built
to model the transcriptional activity (i.e., active/inactive) of the tumor protein p53 based on
the DNA mutations in the Mutant Dataset from the University of California at Irvine (a). A
structural equation model (SEM) was built to relate the risk of cardiovascular disease (noted
RCVD) to variables from the Canadian Community Health Survey, such as self-perceived health
or having high blood pressure (b).

data-science (i.e., having only data science topics) or traditional (i.e., without any data science
topic). Based on the categories deﬁned by Varvel and colleagues [20], we found that one class
was in the data-inclusive category, as it devoted segments of the course to data science topics,
while the other was in the digital category, as some data science topics were found but not
clustered. The digital class was taught concurrently (by the same instructor) to a class on big
data also taken by 3 of the 7 students. Thus, in each of the 3 teams of the digital class, the
instructor ensured that there was one student also taking the big data class. This conferred each
team with additional data science skills that thus did not need to be taught again. In contrast,
the data-inclusive class aimed at being more self-contained. In the future, we plan to create
specializations in data science that include pre-requisites such that all students taking the class
would already have been familiarized with a programming environment for data analytics (R
or Python).
Another signiﬁcant diﬀerence was on the way in which students performed their interdisciplinary projects and readings. In one case (LU implementation), students had to propose a
project and readings were discussed in class. In the other case (NIU implementation), students
selected from projects that were already designed, and ﬁlled in a quiz to demonstrate that they
performed the readings. We believe that the two implementations are equivalent in terms of
instructor eﬀort (i.e., it takes as long to iterate project design than to grade reading tests).
Consequently, the drivers between these diﬀerences were most related to pedagogical preferences (e.g., being more or less directive) and class size: a smaller class size was deemed more
conducive to debating and advising on student-led projects, while a larger class size led to more
teaching and standardized options. Our research suggests that the former approach, which
customizes the learning experience based on students’ interests, can be more eﬀective [10, 12].
In order to deliver it eﬀectively, we recommend a class size between 10 and 12 students, equally
divided as undergraduates and graduate students. When the class is taught for the second
1975

Teaching computational modeling in the data science era

Giabbanelli and Mago

time and qualiﬁed teaching assistants start being available, the enrollment may be reasonably
increased.
In our projects, students generally have to ﬁnd datasets either as the primary object of
study or to complement data that is already provided to them. They are pointed to sources
such as HealthData.gov, physionet.org, or the UK Data Service. While identifying or navigating
repositories is relatively straightforward, ﬁnding datasets useful for modeling purposes is much
harder. We believe that there is a tendency to capture all quantiﬁable information, archive
it with little data quality assurance, and leave it to the data analyst ‘as is’. This can be
particularly problematic for students who can be tempted to download and use any dataset
matching the right keywords, spend a lot of time on cleaning it, and then (possibly) realize that
it has little value. A student reported that it was ‘painful’ to ﬁnd the right dataset, as it took
10 to 15 hours. To ensure some standards in the data, we recommended to only use repositories
from governments or public agencies, and that datasets were previously used for publications
in reputable journals.
Early feedback from the completed class suggests that students appreciated having few
lectures on programming or data cleaning, and more time to discuss readings and their projects.
At the same time, doing the research for a project that required both modeling and data science
skills took much more work than they anticipated when they signed for the course. A potential
solution would be to spread the content of the course over two courses, but we would advocate
against splitting the course into data analytics on the one side and modeling on the other as it
would run contrary to integrating these synergistic topics.

6

Acknowledgments

PJG wishes to thank the Department of Computer Science and the College of Liberal Arts and
Sciences at Northern Illinois University for research support. VKM is grateful to the feedback
provided by the students.

References
[1] P. Anderson, J. Bowring, R. McCauley, G. Pothering, and C. Starr. An undergraduate degree in
data science: curriculum and a decade of implementation experience. SIGCSE, pages 145–150,
2014.
[2] K. Borne, S. Jacoby, K. Carney, A. Connolly, dT Eastman, M. Raddick, J. Tyson,
and J. Wallin.
The revolution in astronomy education: data science for the masses.
http://arxiv.org/abs/0909.3895.
[3] K. Borne, J. Wallin, and R. Weigel. The new computational and data sciences undergraduate
program at george mason university. In G. Allen, J. Nabrzyski, E. Seidel, G. van Albada, J. Dongarra, and P. Sloot, editors, Computational Science - ICCS 2009, volume 5545 of Lecture Notes in
Computer Science, pages 74–83. Springer Berlin Heidelberg, 2009.
[4] A. Chatﬁeld, V. Shlemoon, W. Redublado, and F. Rahman. Data scientists as game changers in
big data environments. Proc. of the 25th Australasian Conference on Information System, 2014.
[5] W. Cleveland. Data science: an action plan for expanding the technical areas of the ﬁeld of
statistics. Statistical Analysis and Data Mining, 7:414–417, 2014.
[6] Computing Research Association. Cyberinfrastructure for education and learning for the future:
a vision and research agenda, 2005. http://archive.cra.org/reports/cyberinfrastructure.pdf.

1976

Teaching computational modeling in the data science era

Giabbanelli and Mago

[7] P. Giabbanelli. A novel framework for complex networks and chronic diseases. In R. Menezes,
A. Evsukoﬀ, and M. C. Gonzlez, editors, Complex Networks, volume 424 of Studies in Computational Intelligence, pages 207–215. Springer Berlin Heidelberg, 2013.
[8] P. Giabbanelli, T. Torsney-Weird, and D. Finegood. Building a system dynamics model of individual energy balance related behaviour. Canadian Journal of Diabetes, 35(2):201, 2011.
[9] P. J. Giabbanelli. Why having in-person lectures when e-learning and podcasts are available? In
Proc. of the 14th Western Canadian Conference on Computing Education, WCCCE ’09, pages
42–44. ACM, 2009.
[10] P. J. Giabbanelli. Ingredients for student-centered learning in undergraduate computing science
courses. In Proc. of the Seventeenth Western Canadian Conference on Computing Education,
WCCCE ’12, pages 7–11. ACM, 2012.
[11] P. J. Giabbanelli and P. J. Jackson. Using visual analytics to support the integration of expert
knowledge in the design of medical models and simulations. Procedia Computer Science, 51:755 –
764, 2015. International Conference On Computational Science (ICCS).
[12] P. J. Giabbanelli, A. A. Reid, and V. Dabbaghian. Interdisciplinary teaching and learning in
computing science: Three years of experience in the mocssy program. In Proc. of the Seventeenth
Western Canadian Conference on Computing Education, WCCCE ’12, pages 47–51. ACM, 2012.
[13] V. K. Mago, R. Mehta, R. Woolrych, and E. I. Papageorgiou. Supporting meningitis diagnosis
amongst infants and children through the use of fuzzy cognitive mapping. BMC Medical Informatics and Decision Making, 12(1):1–12, 2012.
[14] Microsoft Corporation. Towards 2020 science, 2006.
[15] National Science Foundation (NSF). NSF leads federal eﬀorts in big data, 2012.
[16] NSF.
Cyberinfrastructure
vision
for
21st
century
discovery,
2007.
http://www.nsf.gov/pubs/2007/nsf0728/.
[17] J. Raghavan and H. Liu. An innovative undergraduate computational mathematics curriculum
for engineering students seeking dual majors. Proc. of the 2010 Annual Conference & Exposition,
2010.
[18] E. Rana, P. J. Giabbanelli, N. H. Balabhadrapathruni, X. Li, and V. K. Mago. Exploring the
relationship between adherence to treatment and viral load through a new discrete simulation
model of hiv infectivity. In Proc. of the 3rd ACM SIGSIM Conference on Principles of Advanced
Discrete Simulation, SIGSIM PADS ’15, pages 145–156. ACM, 2015.
[19] A. Shiﬂet. Cosc/math 201: Modeling and simulation for the sciences. pages 258–261, 2013.
[20] V. Varvel, E. Bammerlin, and C. Palmer. Education for data professionals: a study of current
courses and programs. iConference, pages 527–529, 2012.

1977

