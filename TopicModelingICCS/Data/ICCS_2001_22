Scalable Large Scale Process Modeling and
Simulations in Liquid Composite Molding
Ram Mohan� , Dale Shires, and Andrew Mark
U. S. Army Research Laboratory †
High Performance Computing Division
Aberdeen Proving Ground, MD 21005

Abstract. Various composite structural conﬁgurations are increasingly
manufactured using liquid composite molding processes. These processes
provide unitized structures with repeatability and excellent dimensional
tolerances. The new generation of materials and processes, however, pose
signiﬁcant challenges in aﬀordable development and process optimization. Process modeling and simulations, based on physical models, play
a signiﬁcant role in understanding the process behavior and allow for
optimizing the process variants in a virtual environment. Large scale
composite structures require scalable process modeling and simulation
software. An overview of various key issues for such scalable software developments are presented. Several items, including our experiences with
the numerical techniques and algorithms for the solution of the representative physical models, are discussed. We also investigate and brieﬂy
discuss the various parallel programming models and software development complexities to achieve good performance. In this context, iterative
solution techniques for large scale systems, based on a domain decomposition of the problem domain and non-invasive techniques to boost performance of scalable software, are discussed. Preliminary results of the
performance of simulations in liquid composite molding are presented.
The discussions presented, though in direct reference to scalable process modeling and simulations in liquid composite molding, are directly
applicable to any unstructured ﬁnite element computations.

1

Introduction

Polymer composite materials have become the material of choice in various new
aerospace, marine, and dual-use military and commercial applications. This is
due to the high strength-to-weight ratio of these materials. However, manufacture of structural composite materials poses signiﬁcant problems. These composite materials are made of a ﬁber matrix and are consolidated together by a polymeric resin. The strength of these composite materials is due to the directional
†

This research was made possible by a grant of computer time and resources by the Department
of Defense High Performance Computing Modernization Program.

�

Guest Researcher

V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2073, pp. 1199–1208, 2001.
c Springer-Verlag Berlin Heidelberg 2001
�

1200

R. Mohan, D. Shires, and A. Mark

orientation of the individual fabric layers. Manufacturing techniques should ideally preserve this ﬁber orientation during processing for each of the repeated
composite structural parts. Processes like prepreg and hand layup maintain the
high quality of the layer orientations and good bonding between the individual layers. However, these tend to be highly time consuming and labor intensive. New processing methodologies based on liquid molding of composites have
evolved over the past decade to provide a production oriented methodology for
structural composite conﬁgurations. The process allows for repeated production
of net-shape composite structures that maintain and preserve the desired ﬁber
orientation in a production environment. One particular type of liquid composite
molding is resin transfer molding (RTM) and its related variants. The process
involves only a few steps. The ﬁrst step involves construction of a tool or mold
cavity that could be either one- or two-sided. This is followed by setting up
a dry ﬁber preform with multiple individual layers of woven fabrics (normally
stitched together) and preforming the dry fabric into a net-shape of the composite structural part conﬁguration. The net-shaped composite structural part
conﬁguration is placed inside the mold cavity conforming to the tool surface.
The polymeric resin is then injected into the mold cavity where it inﬁltrates
and impregnates the dry ﬁber preform, thus consolidating into the net-shaped
structural composite part conﬁguration after curing and consolidation.
The challenges facing the new generation of material processes for producing
these composite structures are how these processes and materials can be cost
eﬀectively developed and optimized for various processing conditions. The mold
tooling costs in liquid molding applications are high and it is essential to develop
optimal processing conditions. Physical process modeling and simulations enable
understanding the physical behavior and optimizing the process variables in a
virtual environment. The strength of the liquid molding processes such as RTM
and its variants is in their ability to manufacture unitized, net-shape, large scale
composite conﬁgurations. The physical and geometric complexity necessitate a
need for scalable simulation software for the process modeling and simulations.
Physical process modeling and simulations begin with the understanding
and description of the underlying physical phenomena by means of mathematical model equations representing the various conservation laws, and, appropriate
material constitutive relations. The model equations are then discretized by numerical methods such as the ﬁnite element method. Computational algorithms
play a critical role in obtaining physically and numerically accurate solutions for
large scale problems. In particular, in scalable computational analysis, it is critical and important to employ optimal computational methodologies. This is in
addition to having optimal data structures, data and processor layout, and communication strategies for scalable high performance computing architectures. A
purely ﬁnite element based methodology [1,2,3] for modeling and analyzing the
pressure driven transient ﬂow through porous ﬁber media is brieﬂy described.
The development of large scale, parallel scalable software involves a clear
trade-oﬀ between the amount of work and the information the developer has to
perform and provide, and the amount of eﬀort the compiler has to expend to

Scalable Large Scale Process Modeling and Simulations

1201

generate the optimal scalable parallel software code. This depends mainly on
parallel programming paradigms. Programming paradigms based on high level
parallel languages (High Performance Fortran (HPF), CM-Fortran[4] in CM-5
systems) and parallelizing compilers permit a data parallel mode of computing
with no user deﬁned explicit communication across multiple processors. Another parallel programming paradigm involves explicit message passing across
the multiple processors. With the development and maturation of the message
passing standards from the early 1990s, this approach has gained wider usage
for scalable parallel software development. Various issues of the message passing interface (MPI) parallel software developments are discussed and presented.
Illustrative examples demonstrating the computational time speed up for multiprocessor runs are presented. Preliminary results comparing the execution times
between the HPF and MPI parallel paradigms are provided in the context of
these simulations.

2

Process Modeling of Resin Impregnation

The resin impregnation process in liquid molding processes such as RTM involves the ﬂow of a polymeric resin through a ﬁber network until the network is
completely ﬁlled. The macroscopic ﬂow of the resin through the complex ﬁber
medium is usually treated as a pressure driven ﬂow through a porous media
and is characterized by Darcy’s law. Darcy’s law relates the macroscopic ﬂow
velocity ﬁeld to the pressure gradient through ﬂuid viscosity and ﬁber preform
permeability as
K
� P,
(1)
u=
µ
where u is the velocity ﬁeld, µ is the ﬂuid viscosity, and P is the pressure.
Permeability K is a measure of the resistance a ﬂuid experiences when ﬂowing
through a porous medium and is an important material characteristic in the
process ﬂow impregnation simulations. Physically, resin impregnation and ﬂow
permeating through a porous media is a free surface moving boundary value
problem whereby the ﬁeld equations and the free surface have to be solved and
tracked. In the liquid composite molding processes such as RTM, the primary
interest is in the temporal progression of the resin inside a complex mold cavity
representing the net-shape composite structural part. Eulerian ﬁxed-mesh approaches are employed for numerical ﬁnite element computations of the complex
diverging/merging ﬂow front progressions.
2.1

Numerical Methodologies

Computational methodologies employed in process ﬂow modeling simulations
for solving the pressure ﬁeld and the free surface include (1) an explicit ﬁnite
element-control volume method and (2) the pure ﬁnite element method originally
developed by Mohan et al. [1,2,3].

1202

R. Mohan, D. Shires, and A. Mark

In the ﬁnite element-control volume technique [5,6,7], the transient resin impregnation problem is treated as a quasi-steady-state problem solving for the
quasi-steady incompressible continuity equation. This leads to stringent numerical restrictions based upon the Courant stability conditions. The time step increments are highly restricted across each of the quasi-steady steps ensuring the
numerical stability of the quasi-steady approximations based on the Courant
stability conditions. Such restrictions increase the number of quasi-steady state
steps needed for the analysis. The power of high performance computing lies
in its ability to enable practical large scale simulations in a reasonable time.
For large scale problem sizes and computational domains, the quasi-steady time
increment sizes are extremely small compared to the resolution needed in the
application. This makes it impossible to complete large scale simulations, even
on scalable high performance computing platforms in any reasonable time. These
diﬃculties are overcome by the pure ﬁnite element methodology [1,2,3] brieﬂy
described next.
The pure ﬁnite element methodology is based on the transient mass conservation law modeling the resin mass balance inside a mold cavity involving the
state variable Ψ (0 ≤ Ψ ≤ 1), where Ψ = 0 represents the unimpregnated regions
of the dry ﬁber preform, and Ψ = 1 represents the completely impregnated regions of the dry ﬁber preform. The velocity ﬁeld is modeled with Darcy’s law.
The governing transient equation is represented by
�
�
K
∂Ψ
=�·
�P ,
(2)
∂t
µ
where µ is the resin viscosity and K is the permeability tensor of the ﬁber
preform. For thin preforms (2.5 D physics) with variations in the in-plane velocity
ﬁelds, the permeability tensor K is a matrix of order two; for thick preforms,
the permeability tensor is a matrix of order three. Based on a Galerkin-weighted
residual formulation, and, introducing ﬁnite element approximations for both
the state variable Ψ (Ni Ψi ) and the pressure ﬁeld P (Ni Pi ), where Ni is the ﬁnite
element shape function that depends on the element type employed; Pi , Ψi are
the nodal values, leads to a discretized system of equations given by
�
�
(3)
C Ψ n+1 − Ψ n + Δt [K] P = Δtq.
In equation 3, C is the mass matrix representing the pore volume, [K] is the
stiﬀness matrix associated with the pressure ﬁeld, Δt is the time step size for
the transient problem, and q is the force vector representing the injection conditions. The pure ﬁnite element methodology solves for the ﬁll factor and the
pressure ﬁeld associated with the ﬁnite element nodes in an iterative manner
until complete mass conservation is achieved at each time step.
The pure ﬁnite element methodology brieﬂy described here does not involve
the restrictions of the time step increments seen in the explicit ﬁnite elementcontrol volume method for this free surface ﬂow problem and is second-order
accurate in time. Rather, it computes the position of the ﬂow front at each of

Scalable Large Scale Process Modeling and Simulations

1203

the discrete time steps that are selected by the analyst. This leads to signiﬁcant
reductions in the computing time required to complete the execution of process
modeling and simulations. These reductions are quite dramatic in the case of
large-scale computational models for composite structural conﬁgurations. This
methodology is proven to provide a more physically accurate, computationally
faster, and algorithmically better solution strategies for the ﬁnite element modeling of the resin impregnation in liquid composite molding processes [1,2,3]. The
computational advantage demonstrated by the method in comparison to the ﬁnite element-control volume technique for liquid resin impregnation composite
molding simulations is solely due to the computational methodology and the
algorithmic solution strategy. The computational eﬀectiveness of the strategy is
independent of the computational platform. Large-scale process modeling and
simulations that were impossible earlier are now possible.
When the thermal and curing eﬀects are considered during the resin impregnation process, the governing model equations based on a volume-averaged
energy balance is given by
ρCp

∂ T̂
ˆ
+ ρf Cpf û · �T̂ = � · KT � T̂ + φĠ.
∂t

(4)

The subscript f denotes the liquid phase, φ is the porosity of the ﬁber medium,
and ρ and cp are the average density and speciﬁc heat, respectively. The curing
reaction based on species balance can be written as
φ

∂ α̂
+ û · �α̂ = φRˆα .
∂t

(5)

In most cases, the impregnation phase is completed before the initiation of thermal and cure reactions. The equations are presented here for illustration and the
present scalable developments focus only on the resin impregnation phase.

3

Scalable Parallel Software Paradigms

The development of parallel software involves various levels of eﬀort based on
the programming paradigms employed. There is a clear correlation between the
work that the parallel software developer has to perform and the performance
of a parallel code. The paradigms based on parallelizing compilers leave the full
responsibility of extracting the parallelism to the compilers and tend to perform poorly, though a minimal level of eﬀort is needed from the developer. At
the intermediate level are the parallel languages in the form of HPF, where the
developer and the compiler/runtime system share the responsibility of extracting the parallelism. This is based on Fortran directives that allow the developer to express the parallelism (normally data parallel mode in ﬁnite element
computations) and control the data locality at a very high level. The developerdeﬁned data layout is then utilized in a compiler which generates the low-level
details, including the required communications. At the highest level of developer responsibility are explicitly-parallel formulations, such as MPI. Here, the

1204

R. Mohan, D. Shires, and A. Mark

developer has to explicitly code all the parallelism, synchronization, and masking based on the analysis schemes and interprocedural data requirements. In
the MPI based paradigms, parallelism is obtained through a single-program,
multiple-data (SPMD) programming model. This is achieved using appropriate decomposition of the computational domain into multiple domains assigned
to various processors. Speciﬁc interprocessor and required processor masking is
speciﬁed by the developer with explicit MPI communication and synchronization
calls. Both HPF- and MPI- based scalable parallel software have been developed.
An illustrative preliminary comparison of total execution times, excluding input
and output operations, is presented next.
3.1

HPF and MPI Comparisons

Illustrative analysis resulting from the scalable software developments is shown
in ﬁgure 1. A domain decomposed partition for MPI-based scalable simulations

(a) Partitioned Domain for
MPI

(b) Temporal resin progression contours

Fig. 1. Scalable process modeling and simulations of a complex structure

is shown in ﬁgure 1(a). The nonoverlapping ﬁnite element mesh decompositions
have been obtained using the graph partitioning software Metis and/or ParMetis
[8]. The temporal resin progression contours, based on representative injection
conditions for a large, complex aerospace composite structural conﬁguration, are
shown in Figure 1(b).
The total execution times for complete analysis based on two ﬁnite element
mesh conﬁgurations are shown in ﬁgure 2. The timing comparisons are based on
a Cray T3E-1200 system. We chose this system since the HPF compiler employed
(Portland Group PGHPF 3.0) was more heavily optimized for this architecture
[9]. A preconditioned conjugate gradient iterative solver is employed to solve the
linear system of equations. The HPF implementation of the iterative solver is
based on a element-by-element formulation where the residuals are determined
at the element level before they are assembled to the global level. The MPI implementation is based on a sub-domain assembled (no communication involved
within a processor) sparse implementation and is discussed further in the next
section. It is clearly seen from ﬁgure 2, that the execution time for the HPF

Scalable Large Scale Process Modeling and Simulations

1205

(a) Conﬁguration 1
(b) Conﬁguration 2
Fig. 2. Total execution time comparison of HPF and MPI scalable software

version of scalable software is higher compared to the MPI solver. This illustrates that signiﬁcantly better performance can be obtained with MPI-based
paradigms that require a full developer involvement. However, new approaches
to boost performance of data parallel approaches for unstructured mesh problems are coming to fruition. For example, the new PGHPF 3.2 compiler supports asymmetric block data distribution, and the Japan Association for HPF
has proposed techniques to reuse communication schedules inside of gather-type
operations. Further studies on the computation, communication costs, memory
usage, and linear system solver performance are currently in progress.

4

Linear System Solver with MPI

The process modeling and simulations in liquid composite molding involve the
solution of a linear system of equations of the form Ax = b, based on a sparse,
symmetric positive deﬁnite matrix. An iterative conjugate gradient algorithm,
based on the developments [11] for multiple instruction, multiple data (MIMD)
computers, is employed. A similar procedure has been followed and extended
to include diagonal preconditioners [10]. The assembled and distributed vector
forms are employed. Assembled forms are denoted by (ˆ·) [12]. The iterative
procedure is thus
SD
– {xSD
} = {bSD }
0 } = 0, {r0
– Do i = 0, 1, . . . . . . until convergence

ρSD =

1. If i = 0 Go
� To Step
� 5
2. {uSD } = ASD {pSD }

β SD = {pSD }T {uSD }
σSD = β SD /γ
1
3. MPI ALLREDUCE α
= Σσ SD

4.

� SD � � SD �
� �
x
= x
+ α pSD
� SD � � SD �
� SD �
r

=

r

−α

SB
5. SEND
{r N B }
� SD �{r �};SDRECEIVE
�
r̂
= r
+ Σ{r N B }

�

r̂ SD

�T �

r SD

�

6. MPI ALLREDUCE γnew = ΣρSD
7. If (i
� = 0) Go �to Step 9
< � STOP
8. If γnew
γ

�

�

pSD =
9.
10. γ = γnew

�

r̂ SD

�

+

γnew
γ

�

pSD

�

u

The method is demanding in terms of both communication and computations
and is called repeatedly during the analysis runs.
One of the major steps in the previous iterative procedure is matrix-vector
multiplication. The sparse matrix is repeatedly multiplied by a vector. The cache
performance of SAXPY with the matrix A in sparse format depends on the ﬁnite
element connectivity. Performance gains are possible by noninvasive techniques

1206

R. Mohan, D. Shires, and A. Mark

that actually modify the data sets without aﬀecting the physics behind the
simulation. The techniques presented next are apropos for reduced instruction
set (RISC) based computers currently in use.
Most RISC-based processors utilize various levels (at least two) of cache to
overcome the CPU/memory system performance gap [13]. A poorly structured
connectivity of an unstructured ﬁnite element mesh can lead to poor cache aﬃnity. The sparse matrix A is in a compressed row format, and the node-based
computations are based on element connectivity. For instance, matrix-vector
multiplication with an element composed of nodes numbered 3, 100, and 200
will require a load of data from the node-based vector vec at addresses &vec[3],
&vec[100], and &vec[200]. A load of data for vec[3] will likely load data into
cache for entries vec[4] and vec[5], but hardly data for nodes 100 and 200. A
node renumbering that will improve the proximity of node numbers will also
improve the cache eﬃciency. Various techniques are available to renumber the
meshes to promote cache eﬃciency [14]. Reordering ﬁnite element nodes based
on the Reverse Cuthill McKee (RCM) scheme [15] signiﬁcantly improved the
closeness of the data for the matrix-vector multiplications. Figure 3(a) shows
the distribution of non-zero entries of a matrix A before reordering, and ﬁgure
3(b) shows the distribution of entries after reordering. The closeness of the non-

(a) Before reordering

(b) After reordering

Fig. 3. Distribution of non-zero entries in a ﬁnite element sparse matrix A

zero entries after reordering permits loading of all required nodal vectors into the
cache. This is important in the case of high performance computing systems with
small cache sizes for combined data and instruction. For example, the Cray T3E
processors only contain 8KB of primary cache and 96KB of secondary cache. An
RCM processed ﬁnite element mesh executed roughly 10% faster on the Cray
T3E than an unprocessed mesh. However, on machines with a large cache, such
as the SGI Origin 3800 with an 8MB secondary cache, the wall clock time is
unaﬀected. A detailed analysis of the underlying memory system, however, did
show dramatic improvements in cache performance with reduced cache misses
and improved memory performance. It is surmised that the large cache, coupled with optimizations such as software and hardware prefetching, mitigated

Scalable Large Scale Process Modeling and Simulations

1207

wall clock improvements. Further detailed analysis is currently being conducted.
Similar approaches improve the data locality in HPF implementations [16].

5

Scalable Simulations

The total execution times based on scalable multiprocessor MPI simulation runs
for two diﬀerent mesh conﬁgurations are shown in ﬁgure 4. These runs represent
diﬀerent processing conditions for the composite structural conﬁguration shown
in ﬁgure 1(a). The results imply a good scalability and portability of the scalable

Fig. 4. Execution time and speedup from scalable MPI simulations

software, and demonstrate the scalable process modeling and simulation capability to perform realistic simulations in a reasonable time. Large-scale process
modeling simulations are now routinely possible for complex composite structural conﬁgurations manufactured by liquid molding processes such as RTM and
its variants. Further performance studies are currently in progress.

6

Concluding Remarks

Modeling and simulation, coupled with scalable high performance computing,
can play a signiﬁcant role in various new composite manufacturing applications.
These techniques, available because of new numerical approaches such as the
pure ﬁnite element method and large scale parallel computing assets, reduce
the risks associated with manufacturing large, geometrically complex composite
structural components. The impacts are wide ranging, and applicable to numerous military and commercial uses.
This paper has demonstrated how various parallel methodologies can be applied to complex engineering problems. High level approaches to parallelism,
such as data parallelism through HPF, are applicable to this class of problem.
These approaches continue to mature through more robust compilers and an enhanced standard. Large scale industrial applications may beneﬁt more from an
explicitly parallel approach found in message passing, where the MPI libraries
are providing fast solutions to grand-scale problems on numerous parallel architectures.

1208

R. Mohan, D. Shires, and A. Mark

References

[1] R. V. Mohan, N. D. Ngo, and K. K. Tamma. On a Pure Finite-Element-Based
Methodology for Resin Transfer Mold Filling Simulations. Polymer Engineering
and Science, Vol. 39, no.1, January 1999.
[2] R. V. Mohan, N. D. Ngo, K. K. Tamma, and K. D. Fickie. A Finite Element
Based Methodology for Resin Transfer Mold Filling Simulations. In R. W. Lewis
and P. Durbetaki, editors, Numerical Methods for Thermal Problems, Vol. IX, pp.
1287–1310, Atlanta, GA, July 1995. Pineridge Press.
[3] R. V. Mohan, N. D. Ngo, K. K. Tamma, and D. R. Shires. Three-Dimensional
Resin Transfer Molding: Isothermal Process Modeling and Implicit Tracking of
Moving Fronts for Thick, Geometrically Complex Composite Manufacturing Applications - Part 2. Numerical Heat Transfer-Part A, Applications, Vol. 35, no. 8,
1999.
[4] R. V. Mohan, D. R. Shires, A. Mark, and K. K. Tamma. Advanced Manufacturing of Large Scale Composite Structures : Process Modeling, Manufacturing
Simulations and Massively Parallel Computing Platforms. Journal of Advances
in Engineering Software, Vol. 29, no. (3-6), pp. 249–264, 1998.
[5] C. A. Fracchia, J. Castro, and C. L. Tucker. A Finite Element/Control Volume
simulation of Resin Transfer Mold Filling. In Proc. of the American Society For
Composites, 4th technical conference, pages 157–166, Lancaster, PA, 1989.
[6] M. V. Bruschke and S. G. Advani. A Finite Element/Control Volume Approach
to Mold Filling in Anisotropic Porous Media. Polymer Composites, Vol. 11, no. 6,
pp. 398–405, 1990.
[7] F. Trouchu, R. Gauvin, and D. M. Gao. Numerical Analysis of the Resin Transfer
Molding Process by the Finite Element Method. Advances in Polymer Technology,
12(4):329–342, 1993.
[8] George Karypis and Vipin Kumar. METIS: A Software Package for Partitioning
Unstructured Graphs, Partitioning Meshes, and Computing Fill-Reducing Orderings of Sparse Matrices. University of Minnesota and the Army HPC Research
Center, 1997.
[9] Portland Group, Major Shared Resource Center Symposium Series, U. S. Army
Research Laboratory, 2000.
[10] R. Kanapady. Parallel Implementation of Large Scale Finite Element Computations on a Multiprocessor Machine: Applications to Process Modeling and Manufacturing of Composites. Masters Thesis, 1998. University of Minnesota.
[11] K. H. Law. A Parallel Finite Element Solution Method. Computers & Structures,
Vol. 23, no. 6, pp. 845–858, 1985.
[12] D. R. Shires, R. V. Mohan, and A. Mark A Study of Parallel Software Development with HPF and MPI for Composite Process Modeling Simulations DOD
Users Group Conference, Albuquerque, NM, 2000.
[13] T. Chilimbi, M. Hill, and J. Larus. Making Pointer-Based Data Structures Cache
Conscious. Computer , vol. 33, no. 12, pp. 67–74, 2000.
[14] G. Kumfert and A. Pothen. Two Improved Algorithms for Envelope and Wavefront Reduction. BIT , Vol. 37, no. 3, pp. 559–590, 1997.
[15] E. Cuthill and J. McKee. Reducing the Bandwidth of Sparse Symmetric Matrices.
24th National Conference. Association for Computing Machinery, pp. 157–172,
1969.
[16] D. R. Shires, R. V. Mohan, and A. Mark. Improving Data Locality and Expanding
the Use of HPF in Parallel FEM Implementations. International Conference on
Parallel and Distributed Processing Techniques and Applications, LasVegas, NV,
2000.

