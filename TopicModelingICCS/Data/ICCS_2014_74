Procedia Computer Science
Volume 29, 2014, Pages 546–556
ICCS 2014. 14th International Conference on Computational Science

Workflow as a Service in the Cloud:
Architecture and Scheduling Algorithms
Jianwu Wang1, Prakashan Korambath2, Ilkay Altintas 1,
Jim Davis3 , Daniel Crawl1
1

2

San Diego Supercomputer Center, UCSD, La Jolla, CA, U.S.A.
Institute for Digital Research and Education, UCLA, Los Angeles, CA, U.S.A.
3
University of California, Los Angeles, Los Angeles, CA, U.S.A.
{jianwu,altintas,crawl}@sdsc.edu, ppk@ucla.edu, jdavis@oit.ucla.edu

Abstract
With more and more workflow systems adopting cloud as their execution environment, it becomes
increasingly challenging on how to efficiently manage various workflows, v irtual machines (VMs) and
workflow execution on VM instances. To make the system scalable and easy-to-extend, we design a
Workflow as a Service (WFaaS) architecture with independent services. A core part of the architecture
is how to efficiently respond continuous workflo w requests from users and schedule their executions
in the cloud. Based on different targets, we p ropose four heuristic workflo w scheduling algorith ms for
the WFaaS architecture, and analy ze the differences and best usages of the algorith ms in terms of
performance, cost and the price/performance ratio via experimental studies.
Keywords: Workflow, Cloud, Workflow as a Service (WFaaS) architecture, workflow scheduling algorithms

1 Introduction
The Smart Manufacturing Leadership Coalit ion (SM LC) 1 is a project to build Smart
Manufacturing (SM) systems that integrate manufacturing intelligence in real t ime cross an entire
production operation including supply chain that are rare in large co mpanies, and virtually nonexistent in small and med iu m size organizations. Even though the sensor, signal and response
technologies have become very reliab le and advanced, the imp lementation of data -driven
manufacturing intelligence and adoption of real time performance-modeling management in achieving
good operating performance across mu ltip le units within the production line of an ent ire factory has

1

546

https://smartmanufacturingcoalition.org/

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.049

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

been lagging behind. Implementation of dynamic real t ime mon itoring, analysis and modeling is
essential to the development of a sophisticated smart manufacturing intelligence.
Workflow and cloud co mputing are two main co mponents developed in the system to date. SM LC
considers workflo w as an essential technique in the implementation of automation, and dynamic
decision-making process through contextualization and analysis of real t ime data. Due to the capability
to build flexib le and co mplicated applications, each user application service is exp ressed in a
workflow. The cloud platform is intended for elastic scalability and reduces cost of deploying SM
services by providing guaranteed compute and data storage resources to complete jobs in real time.
Following service models of cloud co mputing, we think Workflow as a Service (WFaaS) is a good
service model on top of other cloud services to support workflow publishing, query and execution [1].
WFaaS provides a way to compose multip le software packages/services based on a certain logic
within a workflow service. It facilitates a service and management environ ment for flexib le
application integration via workflows. Ut ilizing other cloud services, such as IaaS and DaaS, WFaaS
needs to get proper data, software packages, and VMs for its execution.
The contributions of this paper are three-fold. First, we refine our conceptual WFaaS arch itecture
by defining its services in order to make it scalable and easy -to-extend. Second, we propose four
heuristic workflow scheduling algorith ms for efficient wo rkflo w execution in the cloud for the WFaaS
architecture. Third, we verify and compare the algorithms through simulated experiments.

2 Architecture for Workflow-as-a-Service in the Cloud
2.1 Role Separation for Virtual Machine and Workflow Management
A workflow co mposes many computing steps that need to run with third -party packages, which
brings challenges on VM management. Workflo ws in the cloud run on VM instances (VMIs) that are
instantiated fro m proper VMs. We can have many independent VMIs fro m one single VM. For
example, one of our SM wo rkflo ws includes two tasks calling Octave or Mat lab software package and
a third task invoking Fluent CFD package. To execute such a wo rkflo w on one VMI, we can either
install all needed packages during workflo w execution on the VM I or have one or more VMs ready to
be deployed with preinstalled package(s). The packages, e.g., Matlab and Octave, may have varying
disk space and memory requirements. If we install all the packages needed for a workflo w in one VM I
beforehand or during runtime, the VMI could beco me very b ig and need a lot of resource. For
example, one package needs at least 10 GB of disk space and 1 GB of memo ry, and another one needs
20 GB disk and 500 M B memory. To have a VMI with both packages, we need at least 30 GB d isk
and 1 GB memory. This all-in-one approach also causes VM management difficult ies in the cloud. If
there are many workflows with various third-party package requirements, the VM could be extremely
big if we have a single large VM with all packages installed. It is also hard to manage VM if we have
a VM per workflow because the VM number grows along with workflo w nu mber. Moreover, VM and
workflow are tightly coupled in the approach since VM creation depends on workflows.

Figure 1. Independent role assignment for VM and workflow management.

547

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

Often the VM ad min istrator and workflow co mposer are not going to be the same person, so it is
better if these two roles are loosely coupled and work more independent ly, as shown in Fig. 1. Ideally,
VM ad ministrator does not need to know what the current and future workflo w requests are. She only
builds VMs based on commonly used packages in the domain and makes them available for the
community. For the wo rkflo w co mpos er, she normally works with application users and designs
workflows according to their requirements. Therefore her main job should be expressing workflo w
logic, not where and when each workflow task should run. Each co mposed workflo w is published as a
service. Users will find needed workflow fro m published workflo w services and submit service
execution requests. VM information and how to run workflows on VMIs are hidden fro m users. To
support such loose coupling and automatic execution, we need a co mponent, called Workflow
Scheduler in Fig. 1, to find proper VMs and allocate VMIs for each workflow execution.

2.2 Services in WFaaS Architecture
Our WFaaS architecture is shown in Fig. 2. Following a service -oriented arch itecture approach,
all components in our architecture are REST services, wh ich are exp lained below. The first two
services compose the workflow scheduler in Fig. 1.
VM
management
service

Cloud storage
service
request VMIs

WF input and
output transfer

...
continually
coming WF
requests

WF
WF request
request
management
update WF
list
service
request list
Workflow Scheduler

manage VMIs

WF and IO
data transfer

WF
schedule
service

...
run WF on
scheduled
VMI

run tasks on
scheduled
VMI

VMIs for Workflow
System

...
VMIs for
Package A

...
VMIs for
Package B

Figure 2. An architecture for Workflow-as-a-Service in the cloud.
Workflow request management service accepts user requests to run a certain workflo w along
with input data. This service supports asynchronous requests so that users can submit new requests
without wait ing for the co mpletion of existing ones. Users can use this service to check the status of
each workflow request and get outputs once the workflow execution is complete.
Workflow schedule service schedules workflo ws and tasks in the workflows to proper VMIs.
Since the whole a rchitecture calls for continuous user workflow requests, this service has to be able to
schedule workflows/tasks independently without the knowledge of future workflow requests.
Cloud storage service is a scalable redundant storage service found in many existing cloud
environments, such as Amazon S3 2 or OpenStack Object Storage (Swift) 3 . In our architecture, we will
use it to store workflow specification, user inputs and outputs.
VM management service is a scalable virtual co mputing service also found in many cloud
environments, such as Amazon EC2 4 or OpenStack Co mpute (Nova) 5 . We will use it to manage VMs
and VMIs to execute workflows.

2
3
4
5

548

http://aws.amazon.com/s3/
http://swift.openstack.org
http://aws.amazon.com/ec2/
http://nova.openstack.org

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

Following the modularity and separation-of-concerns principle , we t reat VM management and
workflow management separately in our architecture. To keep each VM simp le, we limit available
packages for each VM. In this paper, we assume one VM only has one package. Workflow co mposer
does not need to be aware of availab le VM information. When composing a new workflo w, she just
specifies the package information for each task. Du ring execution time, workflow schedule service
will find the proper VM for each task and schedule VMI for the tasks. It makes the architecture easy to
extend for new VMs and workflows.
This architecture also supports scalable workflo w execution by allocating separate VM Is for
different workflow requests. Some workflow systems [11], like Kepler [12], can handle simultaneous
workflow executions at the same time by a single engine. This single engine approach, however, will
become a bottleneck when workflo w requests grow. Further, exception fro m one workflow execution
might cause the workflo w engine stop working for other workflow executions. To avoid single points
of failure and resource competition among multip le workflo w executions, we only allo w workflo w
engines to handle one workflow execution at any time. When a new workflow request is scheduled, it
either is allocated on a new VMI or waits until one of the current VMI becomes idle.

3 Workflow Scheduling in the Cloud
Generally, workflow scheduling in a d istributed environment is an NP -hard problem. Th is work
targets random workflow requests over time, so it must schedule workflow execution without any
knowledge of the future requests. In this section, we will present different heuristic algorith ms to
schedule workflow requests and analyze their features.
Our algorith ms have the following assumptions/limitations. First, they only process workflo ws
that can be described in d irected acyclic graphs (DA G). Second, we assume the task execution t ime is
known beforehand since this informat ion can be generated via performance prediction [3]. Third, we
do not consider the overhead and cost of VMI instantiation and data transfer among tasks.

3.1 VMI Sharing among Workflow Tasks
Our algorith ms target VM I sharing among workflow tasks during workflow executions in the
cloud in order to save monetary cost without affecting much performance. Studies show that virtual
resource cost can be reduced greatly if mu ltiple requests share VMIs [2]. In cloud environ ments, costs
are normally calculated by VM I uptime hours (a.k.a. instance hour), not the real usage time period.
For examp le, suppose two tasks need 10 and 30 minutes for their executions, respectively. Due to
dependency constraints, the second task cannot start until the first one fin ishes. Instead of allocating
one VMI for each task, both tasks can be allocated to the same VM I to save cost and still have the
same performance. Workflows have a lot of task dependencies like this examp le, so we could
potentially reduce a lot of resource cost if we take into account the dependencies in scheduling. In th is
paper, we do not consider resource sharing by running multip le tasks simultaneously on the same VM I
since it is difficult to know how the execution time of each task will change in this situation.
Fig. 3 illustrates such an examp le with two workflo w executions, where each task is marked with
its earliest start time, execution time and requested VM ID. Because the two workflows are sub mitted
at different times and there are dependencies among tasks, some task executions could be shared on
the same VM I. The schedule result 1 and 2 show two task execution p lans. The first one does not have
VM I sharing among workflows, whereas the second one has. The two results have the same execution
times for the workflows, but the second one can save half the cost. The reason is that the instance hour
is four for the first schedule result and two for the second one. We note that each workflow also costs
VM I in our architecture, wh ich is not depicted in this figure. In this paper, we only consider VM I

549

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

sharing for tasks, not workflo ws. So each workflow execution will have its own VMI and the VMI is
stopped once the workflow execution is done.

Figure 3: A VMI sharing example among workflow tasks.

3.2 Workflow Scheduling Process
Once a wo rkflo w execution is requested, the schedule service must find VMI allocations for the
workflow and its tasks. Fig. 4 depicts the basic logic of workflow request management service and
workflow schedule service that is the same for our algorith ms. The management service is invoked
when a new workflo w execution is requested. It updates the workflow list and invokes the schedule
service if the workflow request is the only one in the list. If the list has other workflow requests, the
workflow schedule service is already running and will track list changes during its execution.
The workflow schedule service gets the latest workflow request list an d schedules them on proper
VM Is. It first goes through the workflow list and get the list of their tasks. During this process, we can
get the earliest start time for each task by considering workflo w submission time, workflo w
dependencies and task execution time. Because the earliest start time tells when a task can be allocated
on a VM I, we also call it ready time . Then the service sorts the task list based their ready times. Next ,
it gets the first task from the task list and the workflow for the task. If the wo rkflo w has not been
scheduled, it instantiates a new VMI for the wo rkflo w. Then it schedules the task on a VM I. The VM I
could be a new one, or one already started when scheduling previous tasks. When a task is scheduled,
its real start time might be later than its ready time. If so, its downstream tasks need to be updated
based on the real start time. A task is removed fro m the task list once it is scheduled, and a workflo w
request is removed from the workflo w request list once it no longer has any p ending tasks. The VM I
for the workflow will also stop once all its task finish. The service keeps checking latest workflo w
request list and their task list until all workflows and tasks are scheduled.

550

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

Figure 4: Flow chart for workflow management service and workflow schedule service.

3.3 Heuristic Task Scheduling Algorithms
A good heuristic scheduling needs to make proper decisions based on available information.
Three main decisions need to be made fo r workflo w scheduling in the cloud: 1) when to start a new
VMI? 2) when to stop a running VMI? and 3) how to allocate a task to a proper VMI?
To boost sharing without adding cost, the best time to stop an existing VM I is when its uptime
value (by minutes) is a mult iple of 60. If a VM I waits for a shorter time than it, the cost is the same
and it loses chances for sharing. If a VMI is id le and waits for a longer time than it, both cost and
process time are no better than those of starting a new VMI. So we have a separate monitoring process
for each running VM I. It checks the status of the VM I every 60 minutes after the VMI is instantiated,
and stop the VMI if it is idle.
Following the same structure in Fig. 4, the differences of our algorith ms lie in the task schedule
step (highlighted in Fig. 4) in the workflo w schedule service. Monetary cost and process time are two
main criteria for workflow scheduling in the cloud. Besides these two criteria, we will also check
price/performance rat ios (PPR), wh ich reflects a mo re co mbined result of cost and process time.
Performance is normally measured by speed or throughput. Since process time has inverse relationship
with speed/throughput, we use the product of process time and cost for the PPR value . The smaller a
PPR value is, the better the result is.

551

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

Tables 1 through 4 present different task scheduling algorith ms. Most of them take two inputs.
The first is the task to be scheduled. The second, called activeVMIList, is the list of VMIs that have the
requested package and are up currently. This list shows existing VMIs that could be reused for the
task.
Table 1: Task schedule algorithm with static maximal VMI number.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.

staticTaskS chedule(task, activeVMIList, maxVMINum)
search activeVMIList and get the vmi with the earliest stopTime;
if (vmi.stopTime > task.readyTime) //vmi is busy at task ready time
if (activeVMIList.size() < maxVMINum) //we still can create new VMI
schedule task on a new vmi (newVMI) and set newVMI.startTime = currentTime and
newVMI.stopTime = (currentTime + task.exeTime);
else //reuse the vmi for the task
schedule task on vmi after its current running task and set vmi.stopTime = (vmi.stopTime +
task.exeTime);
end if-else starting from line 3
else //reuse the vmi for the task
schedule task on vmi when the task is ready and set vmi.stopTime = (task.readyTime + task.exeTime);
end if-else starting from line 2

Table 1 shows a static task schedule algorithm by setting the maximal active VMI threshold
(maxVMINu m in the input) for each VM type. In line 1, it finds the VM I fro m activeVM IList whose
stop time is the earliest. We note this value only describes the current temporary setting. Once a new
task is allocated here, this value will increase accordingly. When the function approaches line 4,
because the current active VMI nu mber is still less than the threshold, it instantiates a new VMI for the
task. Otherwise, it allocates the task on the VMI (line 6 and 9) and the VM I is reused for the task after
existing tasks on the VMI fin ish. If the threshold number is one for each VM type, we can achieve
minimal cost because it utilizes all possible sharable chances.
Table 2: Task schedule algorithm for shortest process time.
dynamicTaskS chedule (task, activeVMIList)
search activeVMIList and get the vmi with the earliest stopTime;
if (vmi.stopTime > task.readyTime) //vmi is busy at task ready time
schedule task on a new vmi (newVMI) and set newVMI.startTime = currentTime and
newVMI.stopTime = (currentTime + task.exeTime);
4. else //reuse the vmi for the task
5.
schedule task on vmi and set vmi.stopTime = (vmi.stopTime + task.exeTime);
6. end if-else starting from line 3
1.
2.
3.

Table 2 shows a dynamic task schedule algorith m by starting each task instantly . In this
algorith m, an existing VMI is reused only if it is id le at the task’s ready time (line 5). Otherwise, a
new VM I is instantiated for the task. Since each task does not wait fo r other tasks to fin ish, it can start
at its earliest start time and the algorithm can achieve shortest process time for all workflows.
Table 3: Adaptive task schedule algorithm.
1.
2.
3.
4.
5.
6.
7.
8.

adaptiveTaskS chedule(task, activeVMIList, taskList, historyTaskList, thresholdRatio)
get taskNum from taskList or historyTaskList within one hour interval relative to task’s ready time;
vmiNum = thresholdRatio × taskNum; // threshold ratio could be any real number in (0, 1]
if (vmiNum > currentUpVMINum) //we should have more vmi
schedule the task on a new vmi (newVMI) and set newVMI.startTime = currentTime and
newVMI.stopTime = (currentTime + task.exeTime);
else //find a vmi from active VMI list and reuse it for the task
get vmi from activeVMIList with the earliest stopTime;
schedule the task on vmi and set vmi.stopTime = (task.readyTime > vmi.stopTime) ? (vmi.readyTime +
task.exeTime) : (vmi.stopTime + task.exeTime);
end if-else starting from line 3

Table 3 shows a task schedule algorithm that allocates VMI adaptively based on the schedule
history or future task informat ion. In line 1, it first checks task number for a certain t ime interval based

552

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

on the task to be scheduled. We can use the time interval for the past hour or the next hour, both
relative to the task’s ready time. The algorith m counts the tasks in task list or task history list that have
the same requested package and their ready times fall into the interval. Then line 2 calculates needed
VM I number based on the task number and pre-defined threshold ratio. For example, a threshold ratio
0.5 means having one VMI for every two tasks. By co mparing the needed VMI nu mber and current
running VMI nu mber (line 3), it knows whether it should start a new VMI. If no new VM I should be
started, the task will be allocated at the VMI whose stop time is the earliest (line 7). In summary, it
utilizes informat ion of existing task allocations or tasks to be scheduled in order to adjust VM I nu mber
for the current task.
Table 4: Greedy task schedule algorithm.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.

greedyTaskS chedule(task, activeVMIList)
minPPRValue = 0
for each vmi in activeVMIList
calculate pprValue if the task is allocated on the vmi;
if (minPPRValue == 0 || pprValue < minPPRValue)
minPPRValue = pprValue; selectedVMI = vmi;
end if starting from line 4
end for starting from line 2
calculate pprValue if the task is allocated on a new vmi (newVMI);
if (minPPRValue == 0 || pprValue < minPPRValue)
selectedVMI = newVMI; // select the new vmi for the task
stop if starting from line 9
schedule task on selectedVMI and set selectedVMI.stopTime = (task.readyTime > selectedVMI.stopTime)
? (task.readyTime + task.exeTime) : (selectedVMI.stopTime + task.exeTime);

Table 4 shows a task schedule algorith m that tries to have the best PPR for the task to be
scheduled. Fro m line 1 to line 6, it calculates the PPR values for each VM I in act iveVMIList if the
task is allocated on the VMI and finds the VMI with min imal PPR value. Fro m line 8 to line 11, it
calculates the PPR value if the task is allocated on a new VMI and compares it with the above min imal
PPR value. By this approach, this algorith m can find the VM I with the best PPR value and allocate the
task on it. Like other greedy algorith ms, this algorith m cannot guarantee the results are optimal
globally even with the best VMI selection for each task.

4 Experiments
To verify and compare the capabilit ies of the algorith ms in Section 3, we experiment with 100
randomly generated workflow requests in a simu lated environ ment. The 100 requests are fro m 10
workflows with random submission times. Each workflow has five to seven tasks with some
dependencies among them. Each task also has its execution time and required software package name.
In the experiments, the same wo rkflo w requests are used for the four algorith ms with different
configurations. We imp lement the simu lated environment and the algorith ms in Java and all the tests
are done on a Mac desktop. No physical VMs are involved in the experiments.
As mentioned in Section 3, we focus on three criteria: process time, monetary cost and PPR. We
want to have a good overall result, not for each workflow request. So we record the average workflo w
process makespan, total monetary cost, and their product for the workflow requests. We include VMI
usage for both tasks and workflows when the monetary cost is calculated.

553

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

Figure 5: Workflow static schedule results with different maximal VMI numbers.
Our first experiment tests the static schedule algorith m with different maximal VMI nu mber
configurations. The results are shown in Fig. 5 where normalized values of process time, monetary
cost or PPR are on Y-axis and maximal VMI nu mber is on X-axis. Since we only want to know their
differences, each value in the figure is the quotient of dividing its real value by the minimal value of
all configurations. In other words, the values on Y-axis are normalized with respect to the lowest
value. So if the value is 1, it means that algorith m can get the min i mal result for the criterion. The
figure shows different curves in three value ranges. When the maximal VMI nu mber increases from 10
to 40, the values for all three criteria decrease. When the number increases from 40 to 60, process time
values still decrease but the other two values slightly increase. When it increases fro m 60 to 80, all
three values do not change anymore. The reason for the cost decrease from 10 to 40 is that more VM I
number means faster workflow execut ion, which reduces the cost for workflow VMI usage. Fro m the
experiment, we conclude that: 1) the performance of a WFaaS system will be better when we increase
usable VMIs and will reach a point where adding more VM Is will not make it better; 2) adding more
VM Is does not always mean mo re cost for a WFaaS system; 3) we could find a VMI nu mber
configure for the best PPR. We p lan to work on how to find the number for the best PPR automat ically
in the future.

Figure 6: Workflow schedule results with different algorithms.
The second experiment co mpares the four algorithms in Section 3, and the results are illustrated in
Fig. 6. The maxVM INu m value is one for the static schedule and thresholdRatio value is 0.5 for
adaptive schedule. For adaptive schedule, we test it with the task informat ion in both the last hour
(backward) and the next hour (forward). Like the first experiment, only normalized values are shown
here. The figure verifies our assertion that static schedule algorith m can achieve minimal cost and
dynamic schedule algorith m can achieve min imal process time. Fo r PPR, the adaptive schedule
algorith m with future task information gets the min imal value in the experiments. We also find that the
last four algorith ms can get similar PPR results. Our tests with more sets of workflow requests show
the adaptive schedule algorithm with future task information is not always the best in terms of PPR.

554

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

5 Related Work
With the popularity of the cloud and workflow systems, several architectures have been proposed
to support workflo w execution in the cloud [4-6]. Zhao et al. study how to deploy different layers of a
workflow management system in the cloud [4]. Liu et al. design a peer-to-peer based cloud workflo w
architecture for managing large scale workflow applicat ions in [5]. Pathirage et al. propose WFaaS to
host workflo w in the cloud and an architecture for mult iple tenants (users) to share a single application
instance securely [6]. Besides the support of workflow execution in the cloud with good scalability
like these studies, our architecture further focuses on how to manage VM and VMI for workflo w
execution in the cloud, which are not well studied in existing work. We think it will beco me
increasingly challenging as more VMs and workflows are added in a WFaaS system. By separating
VM and workflow management, our architecture is more modular and easy -to-extend.
In recent years, workflo w scheduling in the c loud has become a hot research topic and many
algorith ms have been proposed. As surveyed in [7], these algorith ms differ in schedule target,
schedule approach and applicable scenarios. We mainly co mpare our work with algorith ms that also
support multip le/continuous workflo w executions in the cloud. Xu et al. propose an algorithm to
schedule multip le workflows with mu ltip le Quality of Serv ice (QoS) constraints in the cloud, which
results a service list for the workflows [8]. The algorith m in [9] takes a set of workflows as input and
generates the schedule that is executable on IaaS system and meets user QoS requirements. These two
algorith ms must have all the workflows ready before scheduling, whereas our work deals with
continuous workflow requests. The most related work is [10], wh ich proposes an auto -scaling
algorith m to finish workflo ws by user specified deadlines with cost-efficiency in the cloud. Like our
work, VMI sharing among tasks is also allo wed in this algorith m to save cost. A difference is that this
algorith m on ly allow VMI sharing for tasks of the same workflow, but our algorithms support VM I
sharing among tasks no matter they are in the same workflow or not, which has potential for more
VM I sharing and better cost reduction. Another difference is that algorith m target. The target in [10] is
to meet each workflow’s deadline, whereas our targets include execution time, cost and PPR.

6 Conclusions and Future Work
Workflow and cloud become increasingly popular in cyberinfrastructure projects. Workflow has
capability to build flexib le and co mp licated application and cloud platform is suitable for providing
scalable and economic services. By clearly defining independent services, our WFaaS architecture
makes it easy to manage increasing wo rkflo ws and VMs. Based on the architecture, we also present
four heuristic workflow schedule algorith ms for efficient workflo w execution in the cloud. We
compare the algorithms in experiments in terms of p rocess time, monetary cost and price/performance
ratio. We find that an algorithm with proper configuration could red uce both cost and PPR without
affecting much performance. Although originated fro m SM, our work can also be used in other
domains.
For future work, we first plan to improve our algorithms to support mo re co mplicated workflo w
logics, such as loop and condition. Then we will extend the Kepler workflow system to support the
algorithms in physical cloud environments with real world applications in SM and bioinformatics.

7 Acknowledgements
This work is supported by DOE grant DE-EE0005763 : “Industrial Scale Demonstration of Smart
Manufacturing Achieving Transformational Energy Productivity Gains” , NSF grant DBI-1062565:

555

Workﬂow as a Service in the Cloud

J.Wang, P. Korambath, I. Altintas, J. Davis and D. Crawl

“bioKepler: A Co mprehensive Bio informat ics Scientific Workflo w Module for Distributed Analysis
of Large-Scale Biological Data”, and NSF grant 1331615: “WIFIRE: A Scalable Data-Driven
Monitoring, Dynamic Prediction and Resilience Cyberinfrastructure for Wildfires ”.

References
[1] P. Korambath, J. Wang, A. Ku mar, L. Hochstein, B. Schott, R. Graybill, M. Baldea, J. Davis.
"Deploying Kepler Workflows as Services on a Cloud Infrastructure for Smart Manufacturing",
Accepted by the Second International Workshop on Advances in the Kepler Scientific Workflo w
System and Its Applications, at International Conference on Computational Science (ICCS 2014).
[2] S. Niu, J. Zhai, X. Ma, X. Tang, W. Chen. "Cost-effective cloud HPC resource provisioning by
building semi-elastic virtual clusters", In Proceedings of SC13: International Conference for High
Performance Computing, Networking, Storage and Analysis, Article No. 56. ACM, 2013.
[3] L. Carrington, A. Snavely, N. Wolter. "A performance prediction framework for scientific
applications", Future Generation Computer Systems, 22(3) (2006): 336-346.
[4] Y. Zhao, X. Fei, I. Raicu, S. Lu . "Opportunities and Challenges in Running Scientific Workflo ws
on the Cloud", In Proceedings of IEEE International Conference on Cyber -enabled distributed
computing and knowledge discovery (CyberC), pp. 455-462, 2011.
[5] X. Liu, D. Yuan, G. Zhang, J. Chen, Y. Yang. "SwinDeW -C: a peer-to-peer based cloud
workflow system", In Handbook of Cloud Computing, pp. 309-332. Springer US, 2010.
[6] M. Pathirage, S. Perera, I. Ku mara, and S. Weerawarana. "A mult i-tenant architecture for business
process executions", In Proceedings 2011 IEEE International Conference on Web Services
(ICWS), pp. 121-128, 2011.
[7] A. Bala and I. Chana. "A survey of various workflow scheduling algorith ms in cloud
environment", In IJCA Proceedings on 2nd National Conference on Information and
Communication Technology NCICT, New York, USA. 2011.
[8] M. Xu, L. Cui, H. Wang, Y. Bi. "A mult iple QoS constrained scheduling strategy of multip le
workflows for cloud computing", In Proceedings of IEEE International Sy mposiu m on Parallel
and Distributed Processing with Applications (ISPA -09), pp. 629-634, 2009.
[9] P. Varalakshmi, A. Ramaswamy , A. Balasubramanian, P. Vijayku mar. "An optimal wo rkflo w
based scheduling and resource allocation in cloud", In Advances in Co mputing and
Communications, pp. 411-420. Springer Berlin Heidelberg, 2011.
[10] M. Mao and M. Hu mphrey. "Auto-scaling to minimize cost and meet application deadlines in
cloud workflows", In Proceedings of SC11: International Conference for High Performance
Computing, Networking, Storage and Analysis, Article No. 49, 2011.
[11] I. J. Taylor, E. Deelman, D. B. Gannon, M. Shields (Eds.), Workflows for e -Science: Scientific
Workflows for Grids, Springer, 2007.
[12] B. Ludaescher, I. A ltintas, C. Berkley, D. Higgins, E. Jaeger-Frank, M . Jones, E. A. Lee, J. Tao,
Y. Zhao, "Scientific workflow management and the Kepler system", Concurrency and
Computation: Practice & Experience, 18 (10) (2006) pp. 1039-1065.

556

