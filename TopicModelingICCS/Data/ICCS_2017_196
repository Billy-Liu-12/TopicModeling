Available online at www.sciencedirect.com

This
This
This
This
This

ScienceDirect

space is reserved for the Procedia header,
space is reserved for the Procedia header,
space
reserved
for the
header,
ProcediaisComputer
Science
108CProcedia
(2017) 586–595
space is reserved for the Procedia header,
space is reserved for the Procedia header,

do
do
do
do
do

not
not
not
not
not

use
use
use
use
use

it
it
it
it
it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland
On the Use of a GPU-Accelerated
Mobile Device Processor

On
On
On
On

the
the
the
the

Use
Use
Use
Use

of
aa GPU-Accelerated
Mobile
Device
Processor
of
GPU-Accelerated
Mobile
Device
Processor
for
Sound
Source
Localization
of
a
GPU-Accelerated
Mobile
Device
Processor
of for
a GPU-Accelerated
Mobile
Device
Processor
Sound
Source
Localization
for
Sound
Source
Localization
1
for
Sound
Localization
Jose A. Belloch1∗
, Jose
M. BadiaSource
, Francisco
D. Igual22 , Maximo Cobos33 , and
for
Sound
Source
Localization
1
1 2 , Maximo Cobos3 , and
Jose A. Belloch1∗
,
Jose
M.
Badia
,
Francisco
D. Igual
1∗
1

Quintana-Ortı́
Jose A. Belloch1∗, Jose M.Enrique
Badia1 ,S.Francisco
D. Igual
Cobos3 , and
1 2 ,, Maximo
Jose A. Belloch1∗, Jose M.Enrique
Badia1 ,S.Francisco
D. Igual
Cobos3 , and
Quintana-Ortı́
1 2 , Maximo
Badia
,
Francisco
D.
Igual
Maximo
Cobos , Spain
and
Enrique
S.
Quintana-Ortı́
1Jose A. Belloch , Jose M.
1Jaume I, 12071–Castellón,
Depto. de Ingenierı́a y Ciencia
de
Computadores,
Universitat
Enrique S. Quintana-Ortı́1
1
Enrique
S.
Quintana-Ortı́
y Ciencia de Computadores,
Universitat
Jaume I, 12071–Castellón, Spain
jbelloch@uji.es,
badia@uji.es,
quintana@uji.es
1 Depto. de Ingenierı́a

2
1
1
2
2
2
2

Depto.
Depto.
Depto.
Depto.
Depto.
Depto.
Depto.3
3
3
3
3

de Ingenierı́a y Ciencia de Computadores, Universitat Jaume I, 12071–Castellón, Spain
badia@uji.es,
quintana@uji.es
de Arquitectura
de Computadores
y Automática,
Universidad
de Madrid,
Ingenierı́ajbelloch@uji.es,
y Ciencia
de Computadores,
Universitat
Jaume I,Complutense
12071–Castellón,
Spain
badia@uji.es,
quintana@uji.es
de Arquitectura
Ingenierı́ajbelloch@uji.es,
y Ciencia
de Computadores,
Universitat
Jaume I,Complutense
12071–Castellón,
Spain
de
de Computadores
y Automática,
Universidad
de Madrid,
28040–Madrid,
Spain
jbelloch@uji.es,
badia@uji.es,
quintana@uji.es
de Arquitectura
de Computadores
y Automática,
Universidad Complutense de Madrid,
jbelloch@uji.es,
badia@uji.es,
quintana@uji.es
28040–Madrid,
Spain
figual@pdi.ucm.es
de Arquitectura
de Computadores
y Automática,
Universidad Complutense de Madrid,
28040–Madrid,
Spain Universidad Complutense de Madrid,
de
Arquitectura
de Department,
Computadores
y Automática,
figual@pdi.ucm.es
Computer
Science
Universitat
de València, 46100–Valencia, Spain
28040–Madrid,
Spain
figual@pdi.ucm.es
28040–Madrid,
Computer Science Department,
Universitat Spain
de València, 46100–Valencia, Spain
maximo.cobos@uv.es
figual@pdi.ucm.es
Computer Science Department,
Universitat de València, 46100–Valencia, Spain
figual@pdi.ucm.es
maximo.cobos@uv.es
Computer Science Department,
Universitat de València, 46100–Valencia, Spain
maximo.cobos@uv.es
Computer Science Department,
Universitat de València, 46100–Valencia, Spain
maximo.cobos@uv.es
maximo.cobos@uv.es

Abstract
Abstract
The growing interest to incorporate new features into mobile devices has increased the numAbstract
growing
interestapplications
to incorporate
new features
into mobile
devices
increased
the numAbstract
ber The
of signal
processing
running
over processors
designed
forhas
mobile
computing.
A
The
growing
interest to incorporate
new features
into mobile
devices
has
increased
the numAbstract
ber
of
signal
processing
applications
running
over
processors
designed
for
mobile
computing.
A
The
growing
interest
to
incorporate
new
features
into
mobile
devices
has
increased
theapplinumchallenging
signal
processing
field
is
acoustic
source
localization,
which
is
attractive
for
ber The
of signal
processing
applications
running
over processors
designed
forhas
mobile
computing.
A
growing
interest
to incorporate
new features
into
mobile
devices
increased
theapplinumchallenging
signal
processing
field
is
acoustic
source
localization,
which
is
attractive
for
ber
of
signal
processing
applications
running
over
processors
designed
for
mobile
computing.
A
cations
suchsignal
as automatic
camera
human-machine
interfaces,
videoforgaming
challenging
processing
field issteering
acousticsystems,
source
localization,
which
ismobile
attractive
appliber
of
signal
processing
applications
running
over
processors
designed
for
computing.
A
cations
such
as automatic
camera
systems,
human-machine
interfaces,
video
gaming
challenging
signal
processing
field
issteering
acoustic
source localization,
which
is attractive
forcontain
applior
audio
surveillance.
In
this
context,
the
emergence
of
systems-on-chip
(SoC)
that
cations
suchsignal
as automatic
camera
steering
systems,
human-machine
interfaces,
videoforgaming
challenging
processing
field
is
acoustic
source
localization,
which
is
attractive
applior
audiosuch
surveillance.
In this
the
emergence
of systems-on-chip
that contain
cations
as automatic
camera
steering
systems,
interfaces,
video
gaming
a
small
graphics
accelerator
(orcontext,
GPU),
contributes
ahuman-machine
notable
increment
of(SoC)
the computational
or
audiosuch
surveillance.
In this
context,
the
emergence
of systems-on-chip
(SoC)
that contain
cations
as automatic
camera
steering
systems,
interfaces,
video
gaming
a
accelerator
(orcontext,
GPU),
contributes
ahuman-machine
notable
increment
of(SoC)
the computational
orsmall
audiographics
surveillance.
In
this
the
emergence
of systems-on-chip
thatsystems.
contain
capacity
while
partially
retaining
the
appealing
low-power
consumption
of
embedded
a
small
graphics
accelerator
(orcontext,
GPU), the
contributes
a notable
increment of(SoC)
the computational
or
audio
surveillance.
In
this
emergence
of
systems-on-chip
that
contain
capacity
while
retaining
the
appealing
low-power
consumption
of
systems.
a small
graphics
accelerator
(or
GPU),
contributes
a5422
notable
increment
of embedded
the
computational
This
is the
case,partially
for
example,
of the
Samsung
Exynos
SoC
that includes
a Mali-T628
MP6
capacity
while
partially
retaining
the
appealing
low-power
consumption
of
systems.
a
small
graphics
accelerator
(or
GPU),
contributes
a5422
notable
increment
of embedded
the
computational
This
isThis
the
case,
for
example,
ofOpenCL-based
the
Samsung
Exynos
SoC
that
includes
a sound
Mali-T628
MP6
capacity
while
partially
retaining
the
appealing
low-power
consumption
of
embedded
systems.
GPU.
work
evaluates
an
implementation
of
a
method
for
source
loThis
is the
case,partially
for example,
of the
Samsung
Exynos
5422 SoC
that includes
a Mali-T628
MP6
capacity
while
retaining
the
appealing
low-power
consumption
of for
embedded
systems.
GPU.
work for
evaluates
anofOpenCL-based
implementation
ofthat
a method
source
loThis isThis
the
case,
example,
the
Samsung
Exynos
5422 SoC
includes
a sound
Mali-T628
MP6
calization,
namely,
the
Steered-Response
Power
with
Phase
Transform
(SRP-PHAT)
algorithm,
GPU.
work for
evaluates
anofOpenCL-based
implementation
ofthat
a method
fora sound
source
loThis
isThis
the namely,
case,
example,
the Samsung
Exynos
5422 SoC
includes
Mali-T628
MP6
calization,
the
Steered-Response
Power
withproposed
Phase
Transform
(SRP-PHAT)
algorithm,
GPU.
This
work
evaluates
anresults
OpenCL-based
implementation
of a method
for sound
source
loon
GPUs
of
this
type.
The
show
that
the
implementation,
given
the
audio
calization,
namely,
the
Steered-Response
Power
with
Phase
Transform
(SRP-PHAT)
algorithm,
GPU.
Thisof
work
evaluates
OpenCL-based
of a method
for sound
source
loon
GPUs
this to
type.
Theanaudio
results
showPower
thatimplementation
the
proposed
implementation,
given
the
audio
calization,
namely,
the
Steered-Response
with
Phase
Transform
(SRP-PHAT)
algorithm,
samples,
is
able
perform
localization
in
real
time
with
high-resolution
spatial
grids
on
GPUs of
this type.
The results showPower
that the
proposed
implementation,
given algorithm,
the audio
calization,
namely,
the
Steered-Response
with
Phase
Transform
(SRP-PHAT)
samples,
isofable
to
perform
in real
time with
high-resolution
spatial
grids
on GPUs
this
type.
The audio
resultslocalization
show that the
proposed
implementation,
given
the audio
using
up to
12
microphones.
samples,
isofable
to
perform
in real
time with
high-resolution
spatial
grids
on
GPUs
this
type.
The audio
resultslocalization
show that the
proposed
implementation,
given
the audio
using
up to
12
microphones.
samples,
is able
to
perform
audio
localization
in real
time with
high-resolution
spatial
grids
using
up
to
12
microphones.
Keywords:
Embedded
systems,
Sound localization
source
Microphonespatial
arrays grids
samples,
isAuthors.
able
to
perform
audio
in realAudio
time processing,
with high-resolution
©
2017 up
Theto
Published
by Elsevier
B.V. localization,
using
12
microphones.
Keywords:
Embedded
systems,
Sound
source
localization,
Audio processing,
Microphone
arraysScience
Peer-review
under
of the
scientific
committee
of the International
Conference
on Computational
using
up to
12 responsibility
microphones.
Keywords:
Embedded
systems, Sound source localization, Audio processing, Microphone arrays
Keywords: Embedded systems, Sound source localization, Audio processing, Microphone arrays
Keywords: Embedded systems, Sound source localization, Audio processing, Microphone arrays

1 Introduction
1
Introduction
1
Introduction
The
functionalities
of mobile devices are rapidly growing thanks to the increasing number of
1
Introduction
1
Introduction
The
of mobile devices
rapidly growing
thanks toincluded
the increasing
number
of
signalfunctionalities
processing applications
that areare
implemented
on processors
in current
mobile
The functionalities of mobile devices are rapidly growing thanks to the increasing number of
signal
processing
applications
thatinclude
areare
implemented
on processors
in
current
mobile
The
functionalities
of mobile
devices
rapidly
growing
thanks
increasing
number
of
devices.
Representative
examples
those
applications
relatedtoincluded
tothe
smart
audio
processing.
signal
processing
applications
that areare
implemented
on processors
included
in
current
mobile
The
of mobile
devices
rapidly
growing
thanks
increasing
number
of
devices.
Representative
examples
those
applications
relatedtoincluded
tothe
smart
audio
processing.
signalfunctionalities
processing
applications
thatinclude
are implemented
on processors
in
current
mobile
devices.
Representative
examples
include
those applications
related included
to smart in
audio
processing.
signal
processing
applications
that
are
implemented
on
processors
current
mobile
devices.
Representative examples include those applications related to smart audio processing.
∗ Corresponding
author examples include those applications related to smart audio processing.
devices.
Representative
∗ Corresponding
∗ Corresponding
∗ Corresponding
∗ Corresponding

author
author
author
author

1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.037

1
1
1
1
1

	

SRP-PHAT implementation forJose
a mobile
device
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595

Belloch et al.

In this context, implementations for high-performance spatial audio [5] and multichannel filtering [4] have been previously proposed, showing the capabilities of current parallel processors
for dealing with complex signal processing applications.
One of the challenging applications that has not been investigated is the localization of
sound sources on low-power processors of this type. This application is used in a wide range of
areas such as acoustic-based surveillance, gaming and virtual reality. However, implementing
this application requires an efficient exploitation of the computational resources of a mobile
processor. This is not a straightforward task, since high computational resources are usually
needed to attain accurate results.
The SRP-PHAT method [11] exhibits a massive fine-grain parallelism, i.e., the same operations are performed over different sets of data. Usually, these different data sets correspond to
the audio samples of the different audio channels involved in the system. Basically, the SRPPHAT algorithm evaluates a functional over a fine spatial grid and accepts its maximum value
as the most likely source position. An iterative search strategy has been previously proposed in
order to reduce the processing limitations [15], but this approach prevents a proper exploitation
of the fine-grain inherent parallelism of the SRP-PHAT.
The Exynos 5422 system-on-chip (SoC) is an implementation of the ARM big.LITTLE
architecture [1] present in multiple mobile devices and development boards, such as the Samsung
Galaxy S5 (SM-G900H) and the Odroid boards XU3/XU3-Lite/XU4, respectively. It is a
highly efficient architecture in terms of energy consumption, and still exhibits decent floatingpoint processing capabilities. The SoC is composed by a quad-core ARM Cortex-A15, a quadcore ARM Cortex-A7, and an ARM Mali-T628 MP6 GPU including from one to eight shader
cores. A GPU can be viewed as a Single Instruction Multiple Data architecture (SIMD),
i.e., a processor in which a single flow of instructions is executed on different data sets [12].
Since the SRP-PHAT algorithm presents a fine-grain data parallelism, the Mali GPU of the
Exynos is an appealing target architecture. To this end, we use an OpenCL (Open Computing
Language) [17, 13] framework that enables general-purpose parallel programming across CPUs,
GPUs and other kind of processors.
OpenCL consists of an API (Application Programming Interface) for coordinating parallel
computation across different devices on a heterogeneous platform; and a cross-platform C-like
programming language to program each device. Different vendors provide specific compilers
to extract high performance from their architectures. This provides a high level of versatility
since an OpenCL-based implementation can be ported and run in a large number of different
processors. Nowadays, there exist plenty of CUDA-based implementations in the field of audio
signal processing [16, 6, 7], even approaching sound source localization algorithms [8, 9], which
are constrained to use an NVIDIA platform. In this paper, we address the OpenCL implementation of the SRP-PHAT algorithm on a Mali GPU in order to assess the capabilities of this
mobile processor for a sound source localization application with varying grid sizes and number of microphones. We analyze also different OpenCL-based strategies for efficient resource
management with the objective of increasing the computational performance. To complete the
analysis, we show performances on some state-of-the-art general-purpose GPU devices. The
main novel contributions of this paper are the following:
• We introduce a portable OpenCL implementation of the method which widens the range
of platforms that could be addressed with previous CUDA implementations [8, 9].
• We describe several implementations of some of the kernels applying different optimization
strategies related with the granularity of the computations, the work-group size or the
benefits obtained from precomputing some of the values.
2

587

588	

SRP-PHAT implementation forJose
a mobile
device
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595

Belloch et al.

• We demonstrate the feasibility of using our algorithm to perform audio localization in
real time using up to 12 microphones on a low-cost and low-power platform that can be
found in current mobile devices.
The paper is structured as follows. Section 2 briefly describes the basic sequential SRPPHAT localization algorithm and analyzes its computational cost. Section 3 highlights important features of the OpenCL framework. Section 4 describes the OpenCL-based implementation,
details programming techniques in order to improve performance, and obtains the computational performance of the sound source localization system. Finally, Section 5 provides a few
concluding remarks.

2

The SRP-PHAT Algorithm

Consider the output from a microphone l, ml (t), in a system composed of S microphones. Then,
the SRP at the spatial point x = [x, y, z]T for a time frame n of length T is defined as
Pn (x) ≡



(n+1)T

nT


2
S




wl ml (t − τ (x, l)) dt,




(1)

l=1

where wl is a weight and τ (x, l) is the direct time of travel from location x to microphone l.
DiBiase [11] showed that the SRP can be computed by summing the GCCs for all possible pairs
of the set of microphones. In particular, the GCC for a microphone pair (k, l) is computed as
 ∞
Φkl (ω)Mk (ω)Ml∗ (ω)ejωτ dω,
(2)
Rmk ml (τ ) =
−∞

where τ is the time lag, ∗ denotes complex conjugation, Ml (ω) is the Fourier transform of the
microphone signal ml (t), and Φkl (ω) is a combined weighting function in the frequency domain.
The Phase Transform (PHAT) [14] has been demonstrated to be a suitable GCC weighting for
time delay estimation in reverberant environments:
Φkl (ω) ≡

1
.
|Mk (ω)Ml∗ (ω)|

(3)

Taking into account the symmetries involved in the computation of Eq. (1) and removing
some fixed energy terms [11], the part of Pn (x) that changes with x is isolated as
Pn (x) =

S
S



Rmk ml (τkl (x)) ,

(4)

k=1 l=k+1

where τkl (x) is the Inter-Microphone Time-Delay Function (IMTDF). This function is very
important, since it represents the theoretical direct path delay for the microphone pair (k, l)
resulting from a point source located at x. The IMTDF is mathematically expressed as [10]
τkl (x) =

x − xk  − x − xl 
,
c

(5)

where c is the speed of sound, and xk and xl are the microphone location vectors.
3

SRP-PHAT implementation forJose
a mobile
device
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595

3m

Mic 2

2

Belloch et al.

S = 48

Intersecting Half-Hyperboloids for a Point-Source

y [m]

	

1
0

Mic 1

Mic 3

-1

6m
-4

-3

-2

-1

0

1

2

3

4

5

x [m]

4m

Figure 1: (a) Intersecting half-hyperboloids for M = 3 microphones. Each half-hyperboloid
corresponds to a TDOA peak in the GCC. (b) Microphone set-up for 48 microphones.

In summary, the SRP-PHAT algorithm consists in evaluating the functional Pn (x) on a fine
grid G with the aim of finding the point-source location xs that provides the maximum value:
x̂s = arg max Pn (x).
x∈G

(6)

Figure 1(a) shows schematically the intuition behind SRP-PHAT localization. In this figure,
an anechoic environment is assumed so that the GCC for each microphone pair is a delta function
located at the real TDOA (Time Difference of Arrival). Each TDOA defines a half-hyperboloid
of potential source locations. The intersection resulting from all the half-hyperboloids matches
the point of the grid having the greatest accumulated value.

2.1

Sequential Implementation

The SRP-PHAT algorithm is usually implemented on a 3D spatial grid with three different
resolutions: rx , ry and rz . Taking a shoe-box-shaped room as a model room with dimensions
l
l
lx × ly × lz , the size of the grid is ν = Px × Py × Pz , where Px = rlxx , Py = ryy , Py = ryy .
The real-time implementation of the SRP-PHAT algorithm works with sample buffers of size
L. The main steps carried out by the algorithm together with their computational cost are:
1. For each of the S microphones we weight the L samples of all input buffers by a Hamming
window vector. This involves SL multiplications, that is, SL floating point operations
(flops).
2. For each of the S microphones we perform an L-FFT resulting in S vectors, each containing L frequency bins. The computation of S FFTs, requires 5SL log2 L flops that result
from L2 log2 L complex multiplications and L log2 L complex additions.
3. The GCC matrix of size Q × L is computed, where Q = S(S − 1)/2 represents the
number of microphone pairs. For each pair of microphones j, the element GCC[i, j] is
obtained by combining the ith frequency bin of both microphones. The complex value of
the first bin is conjugated and multiplied by the value of the second. The matrix stores
the complex phase resulting from those multiplications.
A complex multiplication for L points, resulting in 6L flops (4 real multiplications and
2 real additions). This is done for Q microphone pairs, resulting in a cost of 6QL flops.
The computation of the phase of the complex element involves 5L operations. Thus, this
requires 5QL additional flops.
4

589

590	

SRP-PHAT implementation forJose
a mobile
device
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595

Belloch et al.

4. Q inverse L-FFT are then carried out with the rows of matrix GCC. After this processing, the matrix GCC stores the temporal values (time delays). In step 1, this requires
5QL log2 L operations.
5. A tridimensional SRP matrix is computed. Its dimensions are given by the number of
points of the grid G(ν). Each element of this matrix stores the value Pn (x) of one spatial
point x (see Eq. 4). Each element of the matrix is computed by accumulating Q GCC
values, one per row of the matrix. The selected column in each row depends on the
IMTDF (see Eq. 5), i.e, from point x to the pair of microphones associated to the row.
The values of the inter-microphone time-delays are independent of the values of the audio
samples. Therefore, as we will show in section 4, we have tested the possibility of reducing
the cost of processing the audio frames by precomputing those values and storing them
in a four-dimensional matrix. Each element IMTDF[i, j, k, l] contains the time-delay
from the point of the grid G with coordinates {i, j, k} to the lth pair of microphones.
6. Finally, the algorithm computes the position of the maximum SRP value, which represents
the estimated sound source location.
Steps 5 and 6 require to evaluate the following parameters for each point of the grid:
• S Euclidean distances, xk , requiring 3 multiplications, 9 additions and 1 square root.
• Q TDOAs, requiring 2 flops (1 subtraction and 1 division by c) per microphone pair: 2Q
operations.
• The SRP requires truncating the TDOA values to the closest sample according to the
system sampling frequency, multiplying the cross-power spectrum to obtain the phase
transform for each microphone pair and adding up all the GCC values: 3Q flops.
As a result, the cost of the SRP-PHAT is given by:




S + S2
5S(S − 1)
11S 2 − 9S
Cost =
5L log2 L +
L + ν 13S +
flops,
2
2
2

(7)

where ν is the total number of functional evaluations. In the conventional full grid-search
procedure, ν equals the total number of points of the grid G.

3

OpenCL features

An OpenCL platform is a set of potentially heterogeneous computing devices (GPUs, CPUs,
etc.). Each device consists of different compute units (CU) containing multiple processing
elements (PE). In the OpenCL programming model, data-parallelism is exploited by dividing
the computation into multiple work-items that can run the same code in parallel on different
processing elements over different data. The code executed by each work-item is included in
kernels that are submitted by the host to the devices.
Regarding the OpenCL memory model, the memory is divided into four distinct regions:
global to each device, constant, local to each work-group and private to each work-item. Depending on the CPU or GPU device, the distinct memory regions of the model may be mapped
to different hardware memories of the device. The use of faster memory in the kernels may
drastically improve its performance. We should also have into account the cost of transferring
5

	

SRP-PHAT implementation for
a mobile
device
Jose
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595

Belloch et al.

information from the host CPU to the GPU device and the cost of copying information among
different memory regions.
The clFFT [2] library provides an efficient OpenCL implementation of the FFTs. This
library improves the efficiency of its routines by allowing the user to process many transforms
in batches, trying to send and process as much data as possible in a single transform call.
Table 1 shows the main features of the three experimental platforms used in our experiments.
We have selected a Mali-T628 device to show the feasibility of performing source localization
in real time on low-cost GPUs that can be found in mobile phones. We have also selected
two more powerful NVIDIA devices that use two different GPU architectures, namely a Kepler
architecture in the case of the Tesla K20c and the most recent Pascal architecture in the case of
the Tesla GTX1080. We do not intend to compare the performance of the three architectures,
but to show the portability of the developed algorithm to different types of GPUs and to
compare the effect of some optimizations on different platforms. Obviously the GTX1080 can
be hundreds of times faster that the Mali GPU.
Table 1: Main OpenCL features of the experimental platforms.

Vendor
Max compute units
Max clock frequency (MHz)
Max constant buffer size
Max mem alloc size
Global memory size
Global memory cache size
Global memory line cache size
Local memory size
Max work item sizes

4

Mali-T628
ARM
4
600
64 kB
497 MB 658 kB
1 GB 966 MB 584 kB
128 kB
64
32 kB
(256, 256, 256)

Tesla K20c
NVIDIA
13
705
64 kB
1 GB 161 MB 528 kB
4 GB 646 MB 64 kB
208 kB
128
48 kB
(1024, 1204, 64)

Tesla GTX1080
NVIDIA
20
1771
64 kB
1 GB 1004 MB 368 kB
7 GB 945 MB 448 kB
320 kB
128
48 kB
(1024, 1024, 64)

Implementation and Evaluation

The six main steps of the algorithm described in section 2.1 must be executed sequentially
as each step requires results from the previous one. However, the computations on some of
them are embarrassingly-parallel and all of them offer fair opportunities for exploiting finegrain data-parallelism. Our parallel algorithm using OpenCL implements efficient kernels for
each step.
Before starting the execution of the first kernel we transfer from the CPU host to a GPU
device, a buffer with SL samples corresponding to the S input buffers that contains the audio
samples captured by the microphones. We also transfer to the GPU the positions of the S
microphones and a vector with the Hamming window to be used by the first kernel.
Firstly, we use the kernel kIMTDF to precompute in parallel the inter-microphone time-delays.
This kernel uses a global 3D workspace of dimension Px × Py × Pz . Every work-item computes
the time-delays from one point of the grid to the Q pairs of microphones. We store consecutively
in memory the distances from every pair of microphones to every point of the grid, so that we
get a coalesced access to the global memory when the work-items store the results. In order
to reduce the cost of the kernel, each work-item first computes the time-delay from its point
to the S microphones, and stores the results in a vector on its private memory. Then it can
efficiently access this vector to compute the inter-microphone time-delays from the point to all
pairs of microphones. The main problem of this kernel is the size of the IMTDF matrix. For
6

591

592	

SRP-PHAT implementation for
a mobile
device
Jose
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595

Belloch et al.

example, in a shoe-box-shaped room with dimensions 4 × 6 × 3 m, using a resolution of 0.01 m
on each dimension, and 24 microphones, we need more than 37 GBytes of global memory to
store all the time-delays.
Kernel kHamming uses a global work space of size L. The ith work-item uses a Hamming
window to weight the ith element of the input buffers corresponding to all the S microphones.
Alternatively we could weight in parallel the values for every sample, thus launching SL parallel
work-items. However, our experiments show that increasing the granularity of the computations
of every work-item is more efficient than launching more work-items with fewer operations.
A Forward version of the complex discrete 1D FFT implementation included in library
clFFT is used to perform a batch of S parallel transformations of size L.
Kernel kGCC also uses a global work space of size L. Each work-item can compute in parallel
one of the columns of the matrix GCC. As in the case of kHamming, we could have launched
LQ work-items, each dealing with only one element of the matrix. However running work-items
with a larger number of operations provides higher performance.
A Backward version of the complex discrete 1D FFT implementation included in the clFFT
library is then used to perform a batch of parallel transformations of size L with each of the Q
rows of matrix GCC.
Kernel kSRP pre computes in parallel the SRP values of all points of the grid. This kernel uses a one dimensional global workspace of size Px × Py × Pz . Each work-item uses the
precomputed time-delays from its grid point to every pair of microphones to perform a sum
reduction of the corresponding elements of matrix GCC. If the device does not have enough
global memory to store the precomputed time-delays, we can use a version kSRP pairs of the
kernel that computes them for every audio frame processing. In this case the kernel uses a 3D
workspace with the dimensions of the grid, so that every work-item can compute the position
of its grid point. We can obtain another version of this kernel, kSRP priv, if we use the same
technique that with kernel kIMTDF, i.e., we first precompute and store in private memory the
time-delays from the grid point to every microphone.
Figure 2 (a) shows the time required to compute matrix SRP with the different versions of
the kernel kSRP using 24 microphones. These results were obtained with a resolution of 0.005 m
on the GTX1080 and K20c, and with a resolution of 0.01 m using the Mali GPU (see Table 1).
The bars of the figure show the ratio with respect to the fastest version of the kernel, which
depends on the computation rate and memory bandwidth of the platform. The best results
in the K20c and Mali platforms were obtained accessing to the precomputed IMTDF values
in global memory to build the SRP matrix. However, for the GTX1080 GPU, it is faster to
compute the time-delays to all pair of microphones. Note that it is even faster recomputing the
time-delay to the second microphone of each pair (pairs) than accessing it in private memory
(pri). These results correspond to the best work-group size. This parameter depends on the
experimental platform and is not always that selected automatically by the OpenCL routines.
In the case of the kernel kSRP pre the best results were obtained in both platforms with a 1D
work-group of size 256. In the two other variants of the kernel, the best results in the Mali
platform were obtained with a 3D work-group of size (8,4,2), while in the K20c were obtained
with a size (16,8,4).
Kernels kMaxV and kMaxC use a modified version of the two-phases parallel reduction described in [17] to obtain the maximum value stored in matrix SRP. During the first phase, we
perform several sequential iterations with the first kernel reducing the size of the global work
space. On each iteration different work-groups copy part of the SRP elements from global to
local memory, and then the work-items of each work-group use a tree schema to compute the
local maximum of its elements. We then launch kernel kMaxC to obtain the global maximum
7

Jose
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595
SRP-PHAT implementation for
a mobile
device
3

80

pre
pairs
pri

2.5

70
60

2

Time (ms)

Time ratio wrt fastest version

	

1.5
1

50

Belloch et al.

kHam
FFT
kGCC
BFFT
kSRP
Pmax

40
30
20

0.5
0

10
GTX1080

K20c

Mali-T628

(a) Experimental platforms

0

6 & 0.1

6 & 0.01

12 & 0.1

12 & 0.01

(b) Number of Microphones & Resolution

Figure 2: (a) Time ratio with respect to the fastest version in order to compute matrix SRP
with the different versions of the kernel kSRP and using 24 microphones and sample buffers
of size L = 4096. (b) Time employed for each kernel considering 6 and 12 microphones with
resolutions of 0.1 m and 0.001 m on the Mali GPU.

from the previously reduced local maxima.
Finally, kernel kPosMax obtains the position of the global maximum previously reduced.
This kernel uses a 1D global workspace of size ν. The position of the maximum in the grid can
be obtained from the global index of the work-item storing the maximum SRP value.

4.1

Real-time Performance

To analyze the real-time performance, we consider an audio interface that captures the signals
of the microphones using an ASIO (Audio Stream Input/Ouput) driver to communicate with
the CPU, providing L = 4096 samples per microphone every 92.86 ms for a sample frequency
of 44.1 kHz. Therefore, real-time conditions are achieved as long as the processing of the input
buffers is completed before that time, i.e. tp < 92.86ms (tp : Processing time).
We generated a set of acoustic simulations using the image-source method [3] with shoebox-shaped room with dimensions 4×6×3 meters. The setup consists of S = {6, 12, 24, 36, 48}
microphones located on the walls of the room on four different planes (z = {0.6, 1.2, 1.8, 2.4})
following hexagon-like shapes. Different grid resolutions were used for dimensions x and y, but
for dimension z we always used the resolution given by the four planes of the microphones, see
Figure 1(b).
Table 2 reports the time tp that is required to process the input buffers of the microphones.
The Mali platform is able to carry out the processing in real time up to 12 microphones and with
a resolution of r = 0.05 m. The executions that fit inside the real-time conditions are highlighted
in boldface. This result suits perfectly for a camera steering application in a conference room.
Note that results tagged as NO in the table correspond to executions that could not be obtained
with a precomputed matrix IMTDF due to the memory capacity of the platform.
The behavior of the OpenCL algorithm can be better understood if we analyze the cost of its
main steps (see Fig. 2 (b)). The most expensive step of the algorithm for small resolutions is the
computation of matrix SRP using kernel kSRP. Its cost together with that of the computation
of the maximum value and its position depend on the grid resolution. While the cost of the
remaining steps only depends on the size of the frame, L, and the number of microphones, S.
We can not obviate the non-negligible cost of performing the backward FFT.
8

593

594	

Jose
A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595
SRP-PHAT implementation for
a mobile
device

Belloch et al.

Table 2: Computational Time in milliseconds for the SRP-PHAT algorithm on the Mali GPU.

Microphones
6
12
24
36
48

0.5
14.17
40.26
145.35
254.58
558.38

0.1
14.47
41.13
152.29
276.76
627.69

Resolution
0.05
15.33
45.24
177.33
346.53
824.12

0.01
43.48
134.91
494.56
971.67
NO

0.005
171.96
510.16
NO
NO
NO

Finally, we remark that our OpenCL algorithm is totally portable to other GPU devices.
Table 3 shows the processing time that is required on the Tesla GTX1080 GPU for a high
number of microphones and resolutions. Results were obtained with the best version of the
kernel kSRP. Using GPUs of this kind, we can achieve real-time conditions in systems composed
of 96 microphones using a resolution of 0.05 m.
Table 3: Processing time in a Tesla GTX1080 GPU using high number of microphones and a
high spatial resolution.
#Mic
Res
Time

5

0.1
1.00

24
0.05
1.07

0.005
11.79

0.1
3.14

48
0.05
3.78

0.005
50.06

0.1
11.78

96
0.05
14.32

0.005
371.06

Conclusion

The development of numerous signal processing applications in mobile devices is gaining momentum. In this paper, we have exposed how a low-cost mobile GPU can be used to develop
a sound source localization system. We have described an OpenCL-based implementation in
detail taking into account different programming strategies to improve performance.
The results show that the mobile GPU Mali-T628, present in the Samsung Galaxy 5 mobile
device, is able to handle a sound source localization system made up of 12 microphones using a
spatial resolution of r = 0.05 m in a shoe-box-shaped room with dimensions 4×6×3 m. From
the application’s point of view, these results show that processors included in current mobile
devices are able to manage complex signal processing such as automatic camera steering or
audio-based surveillance, when the number of required microphones is moderate.
Future work will aim to offer a deeper analysis considering aspects such as energy consumption. This will allow us to gain a better understanding of the temporary and energetic
dependence of the system.
Finally, the presented implementation has been developed using the OpenCL standard,
so that this work may be representative of the power of state-of-the-art devices regarding
portability and scalability issues.
9

	

A. Belloch
et al.processor
/ Procedia Computer Science 108C (2017) 586–595
SRP-PHAT implementation forJose
a mobile
device

Belloch et al.

Acknoledgements
This work has been supported by the postdoctoral fellowship from Generalitat Valenciana
APOSTD/2016/069, the Spanish Government through TIN2014-53495-R, TIN2015-65277-R
and BIA2016-76957-C3-1-R, and the University project UJI-B2016-20.

References
[1] ARM NEON. http://www.arm.com/. (accessed 2016 July 27).
[2] OpenCL fast fourier transforms. http://clmathlibraries.github.io/clFFT. (accessed 2017 January).
[3] J. B. Allen and D. A. Berkley. Image method for efficiently simulating small-room acoustics. J.
Acoust. Soc. Am., 65(4):943–950, 1979.
[4] J. A. Belloch, F. J. Alventosa, P. Alonso, E. S. Quintana-Ortı́, and A. M. Vidal. Accelerating multichannel filtering of audio signal on ARM processors. Journal of Supercomputing, 73(1):203–214,
2017.
[5] J. A. Belloch, A. Gonzalez, F. D. Igual, R. Mayo, and E. S. Quintana-Ortı́. Vectorization of
binaural sound virtualization on the ARM cortex-A15 architecture. In Proc. 23rd European Signal
Processing conference, (EUSIPCO), Nize, France, September 2015.
[6] J. A. Belloch, A. Gonzalez, F. J. Martı́nez-Zaldı́var, and A. M. Vidal. Real-time massive convolution for audio applications on GPU. Journal of Supercomputing, 58(3):449–457, December
2011.
[7] J. A. Belloch, A. Gonzalez, E. S. Quintana-Ortı́, M. Ferrer, and V. Välimäki. GPU-based dynamic
wave field synthesis using fractional delay filters and room compensation. IEEE/ACM Trans.
Audio Speech Lang. Process., 25(2):435–447, Feb 2017.
[8] J. A. Belloch, A. Gonzalez, A. M. Vidal, and M. Cobos. Real-time sound source localization on
graphics processing units. Procedia Computer Science, 18(0):2549 – 2552, 2013. 2013 International
Conference on Computational Science.
[9] J. A. Belloch, A. Gonzalez, A. M. Vidal, and M. Cobos. On the performance of multi-gpu-based
expert systems for acoustic localization involving massive microphone arrays. Expert Syst. Appl.,
42(13):5607–5620, 2015.
[10] M. Cobos, A. Marti, and J. J. Lopez. A modified SRP-PHAT functional for robust real-time sound
source localization with scalable spatial sampling. IEEE Signal Processing Letters, 18(1):71–74,
January 2011.
[11] J. H. DiBiase. A high accuracy, low-latency technique for talker localization in reverberant environments using microphone arrays. PhD thesis, Brown University, Providence, RI, May 2000.
[12] M.J. Flynn. Some computer organizations and their effectiveness. IEEE Transactions on Computers, 21:948–960, 1972.
[13] Benedict R. Gaster, Lee W. Howes, David R. Kaeli, Perhaad Mistry, and Dana Schaa. Heterogeneous Computing with OpenCL - Revised OpenCL 1.2 Edition. Morgan Kaufmann, 2013.
[14] C. H. Knapp and G. C. Carter. The generalized correlation method for estimation of time delay.
Transactions on Acoustics, Speech and Signal Processing, ASSP-24:320–327, 1976.
[15] A. Marti, M. Cobos, J. J. Lopez, and J. Escolano. A Steered response power iterative method
for high-accuracy acoustic source localization. The Journal of the Acoustical society of America,
134(4):2627–2630, October 2013.
[16] L. Savioja, V. Välimäki, and J. O. Smith. Audio signal processing using graphics processing units.
J. Audio Eng. Soc., 59(1–2):3–19, Jan.-Feb. 2011.
[17] M. Scarpino. OpenCL in Action: How to Accelerate Graphics and Computation. Manning, 2012.

10

595

