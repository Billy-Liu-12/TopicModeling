Procedia Computer Science
Volume 80, 2016, Pages 2098–2106
ICCS 2016. The International Conference on Computational
Science

Workflow scheduling algorithms for hard-deadline
constrained cloud environments
Alexander A. Visheratin, Mikhail Melnik,
Denis Nasonov
ITMO University, Saint-Petersburg, Russia.
alexvish91@gmail.com, mihail.melnik.ifmo@gmail.com, denis.nasonov@gmail.com

Abstract
Cloud computational platforms today are very promising for execution of scientific applications since
they provide ready to go infrastructure for almost any task. However, complex tasks, which contain a
large number of interconnected applications, which are usually called workflows, require efficient tasks
scheduling in order to satisfy user defined QoS, like cost or execution time (makespan). When QoS has
some restrictions – limited cost or deadline – scheduling becomes even more complicated. In this paper
we propose heuristic algorithm for scheduling workflows in hard-deadline constrained clouds –
Levelwise Deadline Distributed Linewise Scheduling (LDD-LS) – which, in combination with
implementation of IC-PCP algorithm, is used for initialization of proposed metaheuristic algorithm –
Cloud Deadline Coevolutional Genetic Algorithm (CDCGA). Experiments show high efficiency of
CDCGA, which makes it potentially applicable for scheduling in cloud environments.
Keywords: Hard-deadline, IaaS, cloud environment, workflow, scheduling.

1 Introduction
Nowadays cloud-based computational platforms like Amazon EC2 or Microsoft Azure became very
widespread. They utilize Infrastructure-as-a-Service (IaaS) model of providing resources to users with
on-demand resources provision according to a pay-as-you-go model. In contrast to clusters and Grids,
where users usually have limited resources and sometimes cannot obtain required QoS (best-effort
quality of service), clouds provide the ability to adjust resources capacity according to the changing
requirements of the application by extending existing or creating new resources. Because of that for the
efficient resources utilization in potentially infinite resources pool proper mechanisms of scheduling
tasks of composite application (workflow) onto resources is required. In some cases we also have to
consider proper resources utilization not only from the point of QoS, but from the point of user defined
restrictions, like budget limits or workflow deadlines. In this case we have a problem of hard-constrained
multi-objective scheduling.

2098

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.529

Workﬂow scheduling algorithms ...

Alexander A Visheratin et al.

Workflow scheduling is a well-known NP-complete problem [10] and there are two main groups of
algorithms used for solving this problem. The first group is heuristic algorithms. One of the most popular
algorithms in this group is heterogeneous earliest finish time (HEFT) algorithm [15] because it provides
short computation time and very efficient solutions. In this work we developed another heuristic
algorithm called Levelwise deadline distributed linewise scheduling (LDD-LS), which is aimed
specifically on hard-deadline constrained cloud scheduling. The second group is metaheuristic
algorithms. Algorithms of this group usually require more time for execution, than heuristics, but can
find much better solutions due to searching through a solution space instead of using predefined
algorithm. The most popular algorithms in this area are genetic algorithm (GA), particle swarm
optimization (PSO) and ant-colony optimization (ACO) [16]. In this work we improved earlier
developed coevolutional genetic algorithm (CGA) for hard deadline cases in cloud environments.

2 Related works
Due to intensive development of cloud-based computational environments, big number of articles is
related to applications execution scheduling in clouds. Unlike deadline-constrained scheduling in Grids
[5], for clouds we have potentially unlimited number of resources, but we have to pay for their usage.
Thus we have more complex problem of multiobjective optimization, where not only execution time,
but also resources cost must be considered. Authors of [6] present metaheuristic algorithm for costefficient scheduling of long-running applications in cloud environments. Besides cost optimization,
Frincu et al. took into account workload balancing between resources, which is also very challenging
problem. While the paper aim different set of characteristics for optimization, in our work we also used
the basic concept of equal workload distribution between computational resources. Coevolution genetic
algorithm was proposed in [7] for multiple workflows with hard-deadlines, however, this work does not
consider the cost optimization. Authors of [8] make use of multiobjective optimization theory [9] in
order to obtain the best solutions within user-defined constraints. Application of general purpose
methods for scheduling problem allows Fard et al. efficiently work with very complex cases of fourobjective optimization and outperform algorithms under comparison in bi-criteria cases. However,
authors show that in some cases time complexity of proposed approach can rise up to ܱሺ݉ ‫݊ ڄ‬ଷ ሻ, where
݉ is number of resources and ݊ is number of tasks, which makes it quite difficult to apply this algorithm
for very big workflows. In addition, authors do not consider cloud environments with unlimited
resources in the article except for computational cost criterion description. The low-time complexity
heuristic algorithm is proposed by Arabnejad et al. [12] In this work, budget and deadline are considered
only as constraints, whereas in our work, the budget is a criterion for the optimization. In [11] authors
extend ordinal optimization approach to meet specific cloud-based applications constraints like
execution cost and makespan. Zhang et al. [10] perform extensive experimental evaluation of proposed
algorithm and show significant performance and quality increase compared to Monte Carlo and Blind
Pick methods. One significant drawback of this article regarding our case is that it does not take into
account workflow deadlines, which is crucial for us.

3 Problem statement
3.1 Scientific workflows
A scientific workflow is commonly represented as a directed acyclic graph (DAG) in a form ܹ ൌ
ሺܶǡ ‫ܦ‬ሻ, where ‫ݐ‬௜ ‫ܶ א‬ǡ ͳ ൑ ݅ ൑ ܰ is a workflow task with specified execution time and ݀௜ǡ௝ ‫ܦ א‬ǡ ͳ ൑ ݅ ൑

2099

Workﬂow scheduling algorithms ...

Alexander A Visheratin et al.

ܰǡ ͳ ൑ ݆ ൑ ܰǡ ݅ ് ݆ is a dependency (usually data dependency) between tasks [1]. These dependencies
show that child tasks cannot start before all parent tasks finish.
Nowadays a lot of very complex scientific problems are being solved with high performance
composite applications, which make use of described approach. One of the most illustrative examples
is a CyberShake workflow, which is used by the Southern California Earthquake Center (SCEC) [2] to
characterize earthquake hazards with the Probabilistic Seismic Hazard Analysis. Authors of [3] show
that original CyberShake consists of 815823 execution tasks, reads 217 Tb of data and writes 920 Gb.
Structure of the workflow is presented on Fig. 1. It is worth mentioning that there are much more tasks
of type 2 and 4, up to 404864 of each type, which means that this type of workflows requires a high
level of parallelization and can make an extensive usage of distributed environments, like clouds. At the
same time heavy data transfer with a limited network bandwidth means that proper scheduling is very
important to minimize sending data between computational nodes by mapping tasks, which work with
the same data to one node.

Figure 1 – Structure of CyberShake scientific workflow
In our work we used 5 types of synthetic workflows, which replicate real scientific applications:
Montage (astronomy), CyberShake (earthquake science), SIPHT (biology), Inspiral (gravitational
physics) and Epigenomics (biology) [4]. These workflows provide information about structure of the
application, dependencies between tasks, data used for tasks execution and average execution time on
benchmarking workstation. Bharathi et al. have developed workflows generator, which allows to create
synthetic workflows of different sizes but still following general structure of the application, thus
making possible to investigate scheduling algorithms on various workload.

3.2 Cloud environment
In our cloud environment model resources provider offers a set of services – types of virtual
machines with different characteristics and prices – that users can lease for some time, and they have to
pay only for the time they used these resources. Very important feature of cloud environments is that
users are charged not for exact time of resources usage, but for time periods, no matter what fraction of
them they have used. Cloud providers utilize different time periods, the most widely used is 1 hour. We
took Amazon EC2 services and pricing model as an example – Amazon provides a wide variety of
resources with different computational powers to fit all their customers’ needs. Offered resources’
characteristics as well as prices change from the lowest to the highest at a pitch of about 2 times – from
small instances with 1 core and 0.5 Gb of memory to high-performance resources with 40 cores and 160
Gb of memory. In our model we also assume that computational resources are located in the same
homogeneous network, so bandwidth between them is equal and high.
Taking this into account the goal of scheduling algorithms in described conditions is minimizing the
cost of resources utilization while finishing workflow execution within specified deadlines.

2100

Workﬂow scheduling algorithms ...

Alexander A Visheratin et al.

4 Proposed solution
4.1 Used notions
In this section we describe notions used in algorithms descriptions to make them easier to understand.
Resource provider offers a set of services ܵ. When algorithm creates instance of some service ‫ݏ‬, it is
instantiated into resource ‫ݎ‬, which becomes part of a resources set ܴ. Every resource has its start time
ܵܶ௥ and runtime ܴܶ௥ . Network bandwidth between resources is denoted as ‫ݓܤ‬. Tasks have two sets of
files – input data ‫ܦܫ‬௧ , which they receive from parent tasks or external sources (in case of first tasks),
and output data ܱ‫ܦ‬௧ , which they transfer to child tasks. Task execution on some resource has a number
of important metrics – start time ܵܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ , transfer time ܶܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ execution time ‫ܶܧ‬ሺ‫ݐ‬ǡ ‫ݎ‬ሻ and
completion time ‫ܶܥ‬ሺ‫ݐ‬ǡ ‫ݎ‬ሻ. ܵܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ is calculated as:
ܵܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ ൌ ሺ  ൫‫ܶܥ‬ሺܲ௜௧ ǡ ܴሾܲ௜௧ ሿሻ൯ ǡ ܴܶ௥ ሻ ൅ ܶܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ
ଵஸ௜ஸே

where ܲ௜௧ is i-th parent of the task, ܰ is the number of parent tasks and ܴሾܲ௜௧ ሿ is a resource, on which
௧
ܲ௜ was mapped. ܶܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ is calculated using following equation:
σ௜ୀଵǤǤே ܱ‫ܦ‬௉೟ ǡ ‫ܲ׊‬௜௧ ǣ ܴሾܲ௜௧ ሿ ് ‫ݎ‬
೔
ܶܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ ൌ
‫ݓܤ‬
where ܰ is the number of parent tasks. ‫ܶܧ‬ሺ‫ݐ‬ǡ ‫ݎ‬ሻ is calculated as:
‫ܥ‬௕
௧
‫ܶܧ‬ሺ‫ݐ‬ǡ ‫ݎ‬ሻ ൌ ܶ௥௨௡
‫ڄ‬
‫ܥ‬௥
௧
where ܶ௥௨௡
is task runtime taken from workflow description, ‫ܥ‬௥ is relative computational power of
௧
was
resource ‫ ݎ‬and ‫ܥ‬௕ is a relative computational power of benchmarking machine, where ܶ௥௨௡
Τ
obtained. ‫ܥ‬௕ ‫ܥ‬௥ shows how much less time we need to execute task on current resource in comparison
with benchmarking workstation. ‫ܶܥ‬ሺ‫ݐ‬ǡ ‫ݎ‬ሻ can be found using formula:
‫ܶܥ‬ሺ‫ݐ‬ǡ ‫ݎ‬ሻ ൌ ܵܶሺ‫ݐ‬ǡ ‫ݎ‬ሻ ൅ ‫ܶܧ‬ሺ‫ݐ‬ǡ ‫ݎ‬ሻ

4.2 LDD-LS description
LDD-LS algorithm is deadline-constrained adaptation of LEFT (Linewise Earliest Finish Time)
heuristic algorithm. The execution process of LEFT consists of following steps: (1) break workflow into
lines – paths from the task of the first level to the task of the last level through only one child on each
௟
; (3) map the first task of the first
level; (2) order lines according to their relative computing times ܶ௖௢௠௣
line to resource providing the earliest finish time; (4) remove mapped task from all lines; (5) repeat steps
2-4 until all tasks are mapped.

Figure 2 – Workflow linewise representation (a) and LDD-LS scheduling schema (b)
LDD-LS uses the basic concept of making lines for the workflow, but makes a number of
adjustments for better compliance with deadline-constrained scheduling in cloud environment. On the
first step of execution process algorithm creates lines of the workflow tasks (example can be found at
௟
௟
for each line. ܶ௖௢௠௣
is calculated as the sum of
Fig 1a) and calculates relative computing time ܶ௖௢௠௣

2101

Workﬂow scheduling algorithms ...

Alexander A Visheratin et al.

௧
௧
௧
execution times ܶ௖௢௠௣
of all tasks in the line. ܶ௖௢௠௣
consists of task runtime ܶ௥௨௡
and total input data
௧
transfer time ܶௗ௔௧௔ . During estimation process we do not know, on what resource the task will be
௧
from workflow description and assume, that all input data will be
executed, so we use relative ܶ௥௨௡
transferred through the network. On the next step total deadline is distributed across levels of the
௧
between its tasks –
workflow in following way – for each level we find the maximum runtime ܶ௥௨௡
௟௘௩௘௟
ܶ௜
– and divide it to the sum of maximum runtimes for all levels:

‫ܦ‬௜௟௘௩௘௟ ൌ

ܶ௜௟௘௩௘௟
σ௜ୀଵǤǤே ܶ௜௟௘௩௘௟

where ‫ܦ‬௜௟௘௩௘௟ is level’s deadline partition in total workflow deadline and ܰ is the number of layers
in workflow.
After that algorithm begins mapping tasks to resources, which is very similar to tasks mapping in
LEFT. The only difference is appropriate resource selection process – instead of selecting resource
providing the earliest completion time, which in cloud environments in most cases would be the most
powerful and expensive resource, LDD-LS tries to achieve equal resources utilization with respect to
levels’ deadline and tasks part in these deadlines. For this purpose, on individual task mapping step
algorithm calculates fraction of the task in deadline of the level:
‫ܦ‬௞௧ ൌ

௧
ܶ௥௨௡

ܶ௜௟௘௩௘௟

And then searches for the resource, where execution time of the task will take the fraction of time
period closest to ‫ܦ‬௞௧ and task completion time does not exceed deadline of the level:
‫ܶܧ‬ሺ‫ݐ‬ǡ ܴ௝ ሻ
‫ܶܥ ר‬ሺ‫ݐ‬ǡ ܴ௝ ሻ ൑ ‫ܦ‬௜௟௘௩௘௟ ή ‫ܦ‬
ଵஸ௝ஸெ ܲ ή ‫ܦ‬௞௧

‫ ݎ‬ൌ 

where ‫ ܦ‬is total workflow deadline. At first algorithm tries to find suitable resource in ܴ, and if there
are no appropriate resources, algorithm instantiates one from ܵ.

4.3 CDCGA description
Implemented algorithm represents a coevolution genetic algorithm and contains two different
heterogeneous populations. An individual from the first population contains ordered list of tasks’
identifiers in conjunction with indexes of computational resources on which these tasks will be executed.
An individual from the second population contains the ordered list of computational powers of
computational resources, that define the number and powers of computational resources in the
environment. Thus, individuals from each population are only a part of a full solution, and the full
solution is composed by a pair of individuals from each population. At the initialization step, these two
populations are generated randomly. In addition, both IC-PCP and LDD-LS solutions are divided into
respective parts and added to randomly generated populations. Further, mutation, crossover and
selection operators are applied to populations at each algorithm’s iteration. Examples of individuals’
representations are presented on the figure 3.

2102

Workﬂow scheduling algorithms ...

a)

Alexander A Visheratin et al.

Individual from the mapping population

b) Individual from the resource population

Figure 3 – Individuals representation
Since, coevolution genetic algorithm contains two heterogeneous populations, mutation and
crossover operators are different for these populations. Mutation operator is represented as a variation
of individuals’ parameters. For individuals from the first population, mutation can be provided either by
replacing index of computational resource for the task, or by swap the ordering of two randomly chosen
tasks in the ordered list. For individuals from the second population, mutation is performed by the one
of three operators: add new resource, delete random resource from the ordered list of computational
powers, change resource’s power of the randomly chosen resource.
The next crossover operator chooses two parent individuals, and generates a new child individual,
which contains parts from both parents. For the first population, two-point crossover is chosen. The
child inherits left and right parts from the first parent, and the middle from the rest tasks of the second
parent. For the second populations one-point crossover is implemented. This point is chosen randomly
in range from 0 to maximum list size of both parents. The child inherits left part from the first parent,
and right part from the second parent. All children are added into populations.
Before the selection phase, all solutions in both populations must be evaluated. Since the fitness
function can be applied only to a full solution, coevolution genetic algorithm includes the one additional
merging stage. During the merging, each individual from the one population is combined with several
individuals from the another population and the additional pair with the another part from the best
solution, which is kept separately from populations. After the merging step, fitness function can be
applied to all combined pairs. Each individual receives the best fitness value from all pairs with this
individual. In the case, when a better solution is found, it replaces the old best solution. After the fitness
evaluation phase, the standard roulette wheel is applied as a selection operator for each population
separately. The scheme of the algorithm is shown on the figure 4. The advantages of using
coevolutionary scheme can be found in [13].

Figure 4 – CDCGA scheme
The criterion of the algorithm is minimizing the cost of resources utilization while finishing
workflow execution within specified deadlines. The solution pair contains the part with the description

2103

Workﬂow scheduling algorithms ...

Alexander A Visheratin et al.

of the computational environment, and the part with tasks’ mapping and ordering. According to these
parts, the result schedule can be constructed. Firstly, the total cost of the resources utilization is
evaluated. Secondly, the makespan (total execution time) of obtained schedule is compared to
established deadline. If the makespan exceeds the deadline, an additional penalty is added to the cost of
resources utilization. This penalty depends on difference between makespan and deadline, and
multiplied on the certain penalty coefficient. Thus, this fitness function tends to reduce the cost of
resources and meet deadlines.
The terminate condition of the algorithm is the established number of iterations.

5 Experiments
5.1 Competitive algorithm
To investigate how applicable are developed algorithms for the stated problem, we checked them
against the algorithm, which solves the same task of hard-deadline constrained scheduling in cloud
environments. It is called IaaS Cloud Partial Critical Paths (IC-PCP) and it was introduced along with
its modification IC-PCPD2 by Abrishami et al. in [14]. The main optimization target of the algorithm is
total computation cost while making workflow to finish within defined deadline. IC-PCP starts creating
schedule from the dummy node in the end of workflow. The process consists of two main parts – parents
assigning and path assigning. On the parents assigning step for each task it creates a critical path, which
contains critical parents – unassigned parent tasks having the latest data arriving time. After critical path
initialization, algorithm assigns all its tasks to the cheapest resources satisfying tasks’ latest finish times.
Then it tries to create next critical path for the task. Algorithm works until all tasks are assigned to
resources. In their article authors also proposed another version of PCP algorithm – IC-PCPD2 – which
uses deadline distribution with per task assigning, but, since experiments show better performance of
IC-PCP, we decided to compete with it.

5.2 Experimental setup
In our experiments we define only one IaaS provider, which utilizes functional schema close to
Amazon EC2 – time periods of 1 hour and vast variety of services with different relative computational
powers: ܲ ൌ ሾͲǤͲ͹ͷǡ ͲǤͳͷǡ ͲǤ͵ǡ ͲǤ͸ǡ ͳǤʹǡ ʹǤͷǡ ͷǡ ͳͲǡ ʹͲǡ ͶͲሿ. In order to provide a wide range of services
without need to use very small numbers, we assign computational power of the benchmarking
workstation equals to 20. In our experimental simulation environment this value is called Ideal Flops.
Services costs also follow Amazon’s rule – resources that are two times more powerful cost twice more.
Network bandwidth between resources is homogeneous and equals to 20 Mb/sec.
Another very important parameter for experiments is a workflow deadline. For deadline calculating
we followed the same concept that authors of [14] used for IC-PCP – define some ideal deadline and
multiply it by the coefficient. However, after analysis of target workflows, especially CyberShake,
which has enormous amounts of data, it was found out that we cannot discard data transfer for ideal
deadline. Because of that ideal deadline is calculated according to the formula:
‫ܦ‬௜ௗ௘௔௟ ൌ ෍ ൫ܶ௝௥ ൯ ൅ ሺܶ௝௧ ሻ
௜ୀଵǤǤே

where ܰ is a number of levels, ܶ௝௥ is task runtime on the fastest resource, ܶ௝௧ is task total transfer
time, ͳ ൑ ݆ ൑ ‫ ܯ‬, ‫ ܯ‬is a number of tasks on the level. For calculating actual deadline for every
experiment, ‫ܦ‬௜ௗ௘௔௟ was multiplied by deadline coefficient ܿௗ with values in range ሾʹǤ Ǥͷሿ and step 0.5.

2104

Workﬂow scheduling algorithms ...

Alexander A Visheratin et al.

5.3 Results
Experimental results are presented on Fig. 4. It is clear that CDCGA highly outperforms both
heuristics in all cases. We can see that for Sipht workflow profit in not very big and this is related to its
specific structure, where a big number of tasks on one level are related to one task on the next level,
thus making this part of workflow hard to parallelize efficiently. In addition, it should be mentioned that
LDD-LS provides worse results than IC-PCP in all cases for Epigenomics workflow. Such results
outcome from pipelined sequences of tasks in this workflow, which form a number of loosely coupled
lines on the lines making steps.

Figure 5 – Experimental results for different deadline coefficients

6 Conclusion
In this article we investigated the applicability of developed heuristic and metaheuristic algorithms
for scheduling scientific workflows in heterogeneous cloud-based computational environment. In our
work we considered the main features of IaaS providers, like wide variety of offered computational
services and pay-as-you-go price model with time periods of charge. Experimental results show high
efficiency of proposed CDCGA algorithm in comparison with proposed heuristic algorithm LDD-LS
and implementation of IC-PCP algorithm. In the future works we plan to improve heuristic algorithm
used for CDCGA initialization in order to provide very good solution in the beginning.
This paper is financially supported by Ministry of Education and Science of the Russian Federation,
Agreement #14.587.21.0024 (18.11.2015), RFMEFI58715X0024.

References
1.
2.

Sinnen, O. (2007). Task scheduling for parallel systems. Wiley-Interscience, 108.
SCEC Project, "Southern California Earthquake Center," http://www.scec.org/

2105

Workﬂow scheduling algorithms ...

3.
4.
5.
6.

7.

8.

9.
10.
11.
12.

13.

14.

15.
16.

2106

Alexander A Visheratin et al.

Juve, Gideon, et al. "Characterizing and profiling scientific workflows." Future Generation
Computer Systems 29.3 (2013): 682-692.
Bharathi, Shishir, et al. "Characterization of scientific workflows." Workflows in Support of
Large-Scale Science, 2008. WORKS 2008. Third Workshop on. IEEE, 2008.
Sakellariou, Rizos, et al. "Scheduling workflows with budget constraints." Integrated research
in GRID computing. Springer US, 2007. 189-202.
Frincu, Marc E., and Ciprian Craciun. "Multi-objective meta-heuristics for scheduling
applications with high availability requirements and cost constraints in multi-cloud
environments." Utility and Cloud Computing (UCC), 2011 Fourth IEEE International
Conference on. IEEE, 2011.
Visheratin, A., Melnik, M., Butakov, N., & Nasonov, D. (2015). Hard-deadline Constrained
Workflows Scheduling Using Metaheuristic Algorithms. Procedia Computer Science, 66, 506514.
Fard, Hamid Mohammadi, et al. "A multi-objective approach for workflow scheduling in
heterogeneous environments." Proceedings of the 2012 12th IEEE/ACM International
Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012). IEEE Computer Society,
2012.
Marler, R. Timothy, and Jasbir S. Arora. "Survey of multi-objective optimization methods for
engineering." Structural and multidisciplinary optimization 26.6 (2004): 369-395.
Zhang, Fan, et al. "Multi-objective scheduling of many tasks in cloud platforms." Future
Generation Computer Systems 37 (2014): 309-320.
Ibarra, Oscar H., and Chul E. Kim. "Heuristic algorithms for scheduling independent tasks on
nonidentical processors." Journal of the ACM (JACM) 24.2 (1977): 280-289.
Arabnejad, H., Barbosa, J. G., & Prodan, R. (2016). Low-time complexity budget–deadline
constrained workflow scheduling on heterogeneous resources. Future Generation Computer
Systems, 55, 29-40.
Butakov, N., & Nasonov, D. (2014, October). Co-evolutional genetic algorithm for workflow
scheduling in heterogeneous distributed environment. In Application of Information and
Communication Technologies (AICT), 2014 IEEE 8th International Conference, 1-5.
Abrishami, Saeid, Mahmoud Naghibzadeh, and Dick HJ Epema. "Deadline-constrained
workflow scheduling algorithms for Infrastructure as a Service Clouds." Future Generation
Computer Systems 29.1 (2013): 158-169.
Arabnejad, H. (2013). List Based Task Scheduling Algorithms on Heterogeneous Systems-An
overview.
Yu, J. R. (2008). Workflow scheduling algorithms for grid computing. Metaheuristics for
scheduling in distributed computing environments, 173-214.

