Procedia Computer
Science
ProcediaComputer
Computer Science
Procedia
Science001 (2010)
(2012)1–9
2609–2617

www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Selection methods for interactive creation and
management of objects in 3D immersive environments
Andrew Dunka,∗, Adrian Haﬀegeea , Vassil Alexandrova
a Centre

for Advanced Computing and Emerging Technologies, University of Reading

Abstract
This paper provides details on the the importance and requirements of multiple selection methods, and the creation
and management of interactive objects within immersive CAVE like virtual reality systems. Various methods of
selection and interactive model creation are explored, as well as the design and implementation of an application able
to create interactive objects from within an immersive virtual environment in real-time. Some initial limitations of
the research and potential improvements are documented in this paper. Finally, two case studies are presented that
demonstrate the additional functionality and interaction gained within an immersive virtual environment from the
research. Being able to create and manage interactive objects from within an immersive environment starts to bridge
the gap between an immersive 3D visualisation. and an interactive, and productive environment.

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝

Keywords: Selection Methods, Interaction, Object Creation, Virtual Reality

1. Introduction
This paper provides details on the creation and management of interactive objects within immersive CAVE[1] like
virtual reality systems, and speciﬁes the requirement of multiple selection methods for this process.
Immersive virtual reality applications are increasing in size and complexity. The virtual environments and associated data being visualised are more detailed, and include a growing number of objects. In order to interact with these
objects, a selection needs to be created, allowing the application to recognise the user’s intentions. There are already
multiple methods for selecting single objects within a 3D environment, but few are able to select multiple objects
simultaneously. Individual selections can be collected together, creating a list of selected objects, but larger selections
become time consuming and tedious. As virtual environments become larger and more complex, the need to create
parallel interactions is becoming more predominant.
The growing requirements for virtual environments also put additional strain on creating interactive content. There
is not only a desire to make more of the environment interactive, but also increase its functionality. Each object that is
required to have some method of interaction needs to be explicitly programmed or conﬁgured. A generalised approach
to object interactions solves this problem, but it also reduces the quality of an application by either limiting an object’s
∗

Email address: a.dunk@reading.ac.uk (Andrew Dunk)
URL: http://www.acet.reading.ac.uk (Andrew Dunk)

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.294

2610

et al.V./Alexandrov
Procedia Computer
(2012) 00
2609–2617
A. Dunk,A.
A.Dunk
Haﬀegee,
/ Procedia Science
Computer1 Science
(2010) 1–9

2

interactions, or giving objects interactions that are not necessary. Content creation also requires more specialised
understanding of the application and the creation of 3D models. Take the following as an example:
A user wants to employ a 3D model of a chess board and its pieces within an immersive virtual environment, with
the intent of playing a game of chess. If the model was loaded into a virtual environment as is, there would be no
interaction as the model is static; it would not be possible to play. The application needs to know some logic about
the possible interactions and which parts of the model are associated with those interactions. A simple speciﬁcation
could include:
• Knowledge of each of the chess pieces and board loaded from the model ﬁle.
• Each of the pieces is able to be picked up separately.
• When the board is moved all the pieces should move accordingly.
Existing methods for adding this functionality to an application are available[2]. Commonly model interaction is
loaded by reading meta-data either embedded into the model during its creation or via additional ﬁles. The application
then searches for this information when the model is loaded. This method has some major drawbacks; you must have
control over the creation of the models to include any required meta-data, the application requires speciﬁc knowledge
about the model it is loading to know what to search for, and the model ﬁles, or application, need to be edited to
change any of the interactions stored.
A desired result would be to create interactive objects from 3D models, in real time, from within the virtual
environment. It would then be possible for a user to download a model of a chess board and its pieces from a free
on-line model database and then load the model into the virtual environment, select all the pieces with a multiple
object selection tool, and add properties stating that the pieces can be picked up and moved.
The user would not need any programming or 3D modeling knowledge and could create an interactive virtual
environment with little eﬀort. It would be possible to edit more detailed settings of the chess set, changing the colour,
texture, and physics of the pieces, or swap individual chess pieces out for other models as the user desires.
The remainder of this paper describes the background into some of the main methods of selection, giving brief
summaries of their abilities and limitations; the ability to create interactive objects from a selection, from within
the virtual environment; two case studies generated from this research; using multiple selection tools and interactive
object creation; and ﬁnally, some conclusions are drawn and future work is documented.
2. Related Work
2.1. Selection Methods
Methods of selection are highly important for interactions within a virtual environment. From studying desktop
applications, selections can occur before or after the initiation of an operation or interaction. Either a selection is made
and the objects are moved, or the request to move is called followed by a selection to indicate which objects should
be moved. The latter is more commonly found where the user decides that the operation is to be repeated on multiple
separate selections, meaning the user does not need to restate the operation each time.
Selections also have the ability to be modiﬁed, either by editing the selection area, or having the ability to ‘add to’,
‘subtract from’, or ‘inverse’ a current selection. There are also many methods for creating the selection; from a single
click on the object with the input device; a click and drag to create a selection area, selection based on property masks
i.e. colour, lasso selections which allow a more diverse selection area; plus many others. Most selection methods
have implementations in 3D, though single object selection methods have been used and tested more extensively than
multiple object selection methods.
A basic 3D position technique uses a 3D cursor position equivalent to the position of the 3D input device. This
technique resembles the actions related to a desktop mouse with an additional dimension. This type of method
is only feasible for selection within the user’s reach, unless other techniques are incorporated such as the Go-Go
technique[3], which enables a scaled extension of the user’s reach within the environment. Methods such as the ray
pointer[4] overcome the issues of selecting objects out of a user’s reach, though accuracy decreases with distance, the
selection cone [5], and selection shadow cone [6] improve on the ray’s accuracy. Techniques such as WIM[7] and

A. Dunk
et al. / Procedia
Computer
Science
1 (2012)
2609–2617
A. Dunk,
A. Haﬀegee,
V. Alexandrov
/ Procedia
Computer
Science
00 (2010) 1–9

2611
3

put-that-there[8] oﬀer novel methods of selecting objects, but still rely on the basic 3D position or ray techniques.
Although any of these methods can be repeated multiple times to form a multiple selection, none are natively able to
simultaneously select multiple objects in a controlled way.
Brush-style selection methods actively select objects as the selector is passed over, or come into contact with
objects in the environment; this style of selection can still use any of the methods mentioned above, but reduces the
need to speciﬁcally select each item. These methods allow for a multiple selection but require the user to pass over
every object in the selection area, meaning the entire selection is still not created simultaneously.
3D Multiple object selection methods are capable of selecting a group of objects in a single operation. Here, they
are separated into two main methods of approach; either a ﬁnite selection volume, or an occlusion plane style selection.
Finite volumes represent a 3D selection cube or other volumetric geometry, depending on the implementation, only
the objects totally engulfed within the selection volume are selected, or additionally any objects that collide with the
selection volume are also included in the selection.
An occlusion plane style selection designates values for two of the three axis of a 3D selection box, while the third
extends to inﬁnity. Another description of this is the selection consists of all items that the user can see when they look
through a window. The selection area is commonly orientated to the user’s view, but can be made orthogonally[9].
Selections can include all objects within the selection area, only objects which are visible in the selection area, or
objects at a speciﬁc depth in the selection area.
2.2. Interactive Object Creation
There are many 3D modeling packages available for desktop systems; Blender[10] and MilkShape[11] are two
examples. These applications allow the creation of 3D models from basic meshes, through to advanced rigging,
texturing, and animations. Modelling applications speciﬁcally for virtual reality systems also exist, like MEW[12], a
3D modelling workbench, and 3D Palette[13], a virtual tablet based modeling environment, but these applications do
not allow the creation of interactive objects.
Other developments such as VR-WISE[14] and Petri Net Script (PNS)[15] are able to generate interactive environments and behaviours through scripts and desktop GUI. There are also many editors for game level design, which
introduce interaction into the game via various types of triggers. Triggers can be drawn visually in the editor and
converted to logic within the game, GtkRadiant is one such example[16]. These applications allow the creation of
interactive objects and environments, but are still designed for editing on desktop systems.
Active Worlds[17] and Second Life[18] are also desktop applications, but have the ability to create interactive
objects from within their virtual environments; additional scripts can be written for more complex interactions between
the objects, the environment, and avatars within their worlds. Though the above have some extensive abilities to create
content, interactions, and behaviours, none can be used for creating interactive content from within an immersive
virtual environment such as a CAVE in real time.
3. Design and Implementation
The proposed application for immersive real-time interactive object creation involves two main areas; the initial
selection methods that allow the user to select multiple areas of a static model, and the operation to then create an
interactive object from that selection. A number of considered methods for selection and possible interactions that
could then be applied to the created objects are presented here. Finally, a small subset of these options are chosen to be
developed for initial testing, giving some understanding into the requirements and feasibility of creating an immersive
virtual reality system that would give any user the ability to create and edit interactive content from within a virtual
environment in real time.
3.1. Selection Methods
Previous research from Lucas et. al. [19] concluded that multiple object selection methods can improve eﬃciency
in selection tasks where the improvement is related to the number of objects in the selection. Smaller selections do
not beneﬁt from the ability to select multiple items, a single object selection method was more appropriate as they
tended to have a higher accuracy. These ﬁnding suggest that two selection methods are required for a more eﬃcient
work ﬂow. One single, and one multiple selection method, that are able to cooperatively edit a single selection list.

2612

et al.V./Alexandrov
Procedia Computer
(2012) 00
2609–2617
A. Dunk,A.
A.Dunk
Haﬀegee,
/ Procedia Science
Computer1 Science
(2010) 1–9

4

It is also important to be able to not only select small objects within the local vicinity of the user, but also much
larger objects, and objects that are out of the user’s reach. From these requirements and the abilities of the selection
methods described in Section 2.1 the following selection methods where drawn for varying scenarios.
Single / Multi selection
Large objects
Small objects

Object In Reach
3D position / 3D position brush
3D position / Selection box

Object In Distance
Ray / Perspective occlusion culling or Navigation
Ray (Cone Selection more accuracy) /
Perspective occlusion culling or Navigation

Table 1: Selection Methods for Varying Scenarios

Navigation in this table means the user will move closer to the object, implying an alternate selection method can
then be used. With each of the selection methods it should be possible to create a new selection, add to a current
selection, or remove from a current selection. The ability to invert the selection based on all objects, and based on
another selection of objects can be achieved with a combination of simpler selections, and are therefore not a primary
concern.
This research is initially focusing in the selection of objects that are in arms reach, as navigation in the environment
is possible. In the future, extensions to the functionality of the selection methods will be included, giving them the
ability to select objects at further distances. Initially a position, brush, and selection cube technique have been chosen
for implementation.
3D Position Selection Implementation – has a direct relationship to the position of the user’s hand within the
virtual environment. The position of the selector is indicated by a sphere within the environment, and uses collision
detection with all other objects in the scene. The user must press and release a button on the input device once a
collision is made to indicate that the object is to be considered in the selection. An additional button will remove a
collided object from the selection list.
3D Position Brush Implementation – has the same functionality as the 3D position selection implementation,
with the exception that the device buttons can be held down to invoke any object collision to be considered for the
selection.
Selection Cube Implementation – uses a click and drag metaphor to create a selection cube within the environment, see Figure 1. The selection cube is drawn as a wire frame for easy viewing of the volume and any engulfed
objects. An arrow is used to more precisely indicate the starting point and orientation of the selection area, after which
the user views the selection cube for the remainder of the selection process. On release of the button the selection
cube vanishes, any objects fully surrounded by the selection cube will be added to the selection list. As the objects
selected need to be fully surrounded, the orientation of the selection cube is very important see Section 4.3.
A further two options allow any selected items to be cleared, or all items to be selected, no matter which selection
method is used.
3.2. Interactive Object Creation
The VieGen framework[20] has an implementation based on the idea of sceneObjects. A sceneObject represents a single entity within the virtual environment. These sceneObjects have a set of basic interactive capabilities
that can be applied or changed. Some of their properties include the ability to pick up the object, if the object should
return to its starting position when dropped or remain in its new location, and the object’s scale, orientation, and
translation properties. By creating sceneObjects from the selection, some initial interactions can be set and used
instantly.
When creating a sceneObject from a loaded static model, a number of steps are required. The selected region
of the model needs to be found, along with positional and material information. The selection and associated information need to be duplicated and used to create a sceneObject. The new sceneObject needs to be positioned, and
orientated to the location of the initial selection. Finally the static section of the loaded model needs to be removed.
As multiple objects can be selected, there needs to be the ability to either create a single sceneObject from
the selection, or multiple sceneObjects, one for each part of the selection list. This poses a signiﬁcant problem,
knowing which parts of a selection count as individual objects within the selection list. This has been solved with the

A. Dunk
et al. / Procedia
Computer
Science
1 (2012)
2609–2617
A. Dunk,
A. Haﬀegee,
V. Alexandrov
/ Procedia
Computer
Science
00 (2010) 1–9

2613
5

Figure 1: A selection cube as it is dragged to the correct size

use of a further two diﬀerent types of selection, see Section 4.2, which can be used with each of the selection methods
mentioned above.
Additional interactions related to editing the environment include, being able to set the visibility of objects, duplicate objects, delete objects, change the object’s appearance via editing associated materials and exporting the
selections to ﬁle for use in other environments. Object visibility poses the problem of ﬁnding an object once it has
been made invisible. This can be resolved by having the ability to override the visibility settings of all the objects,
or being able to view a list of invisible objects within the environment and change visibility settings from there. For
this initial research, the ability to create sceneObjects from a selection is key, as this allows many instantaneous
interaction capabilities. The deletion of objects becomes a simple task once the selection is removed from the initial
loaded model. The duplication of objects is also a trivial task once an initial object is created from the selection,
though the further manipulation of the duplicated objects to a new location is not a key area of this work.
4. Preliminary Review and Design Enhancements
During the initial stages of development, various design problems needed to be explored and improved. This
section describes some of the issues and any resulting outcomes.
4.1. Selection Feedback
The ability to select objects in itself is invaluable, unless the user is able to verify that a selection has been created,
and in the case of a multiple selection, that all desired objects are selected. For this, a method of highlighting an
object has been created. A highlighted object uses a multiple pass rendering technique to superimpose the object’s
wire frame mesh on top of the object with a high contrast colour, see Figure 2. This is achieved by editing the object’s
material properties and adding an additional multi-pass material to the object for the duration that it is highlighted.
This extra material information is able to be skipped when creating an initial sceneObject, or when duplicating a
selection, so new objects do not have the appearance of being highlighted unintentionally. It is also possible to view
a text list with all the selection information.
4.2. The Diﬀerence Between Object and Mesh Selections
A deﬁnition needs to be created for two separate types of selection; these are, mesh selection and object selection. An object selection is used for selecting items within the environment that are already sceneObjects, so that
object properties can be conﬁgured. A mesh selection refers to the selection of part of a model for creation into a
sceneObject.

2614

et al.V./Alexandrov
Procedia Computer
(2012) 00
2609–2617
A. Dunk,A.
A.Dunk
Haﬀegee,
/ Procedia Science
Computer1 Science
(2010) 1–9

6

Figure 2: A Highlighted Object

A model ﬁle can consist of many separated meshes, if the model is well designed, each mesh in the model
represents a particular section or item within the model, this is not always the case however. Currently, the mesh
selection method only supports the ability to select whole meshes from within a model ﬁle, therefore only clean
model ﬁles are currently supported. When creating a object selection, it is not possible to select individual meshes. If
a mesh selection is created, it is only possible to select individual meshes from a model.
4.3. Selection Cube Revision
The initial design of the selection cube was created without orientation information. The assumption was made
to reduce the complication of the selection process. This method worked with initial tests of the selection cube
without complaint, the test environment consisted of rectangular objects, at right angles to the selection cube. As
soon as a complex scene was introduced the selection cube began to fail. Multiple attempts were needed to create a
desired selection correctly, and it became diﬃcult to accurately judge the needed size of a selection box to fully engulf
irregularly shaped objects, or objects at diﬀerent orientations.
Orientation was added to the selection cube method by using the initial rotations of the input device as the starting
orientation of the selection cube. This position is then ﬁxed for the remainder of the selection so that the size of the
selection cube can be changed with ease.
Another proposed implementation is a three click method, whereby the x, y, and z values of the selection cube are
deﬁned separately. This would be achieved by ﬁrst creating a line, expanding this to a plane, and ﬁnally extruding the
plane to a cube. This would enable correct size and orientation of the selection cube with the drawback of needing
multiple button presses.
5. Case Studies
From the developments in this research, two case studies have been created to demonstrate some of the new
interactions capable within the immersive environment. The ﬁrst case study demonstrates the ability to create objects

A. Dunk
et al. / Procedia
Computer
Science
1 (2012)
2609–2617
A. Dunk,
A. Haﬀegee,
V. Alexandrov
/ Procedia
Computer
Science
00 (2010) 1–9

2615
7

from mesh selections of a loaded clean model ﬁle. This case study demonstrates the desired result from the example
described in the introduction of this paper.
The second case study is a simple 3D drawing application, which demonstrates the ability to change object properties in the environment, as well as deleting and duplicating object selections.
Interactive Models:
With this application it is possible to load a clean 3D model ﬁle, see section 4.2 and create an interactive environment from it. The sequence of images presented in Figure 3 shows a loaded model of a coﬀee shop. The user is
able to select meshes from the model and create interactive objects from them, all from within the environment, and
in real-time. The images demonstrate the ability to use the selection box to select a stool that has been created from
multiple meshes, then create a sceneObject from this selection, and ﬁnally maneuver the new sceneObject within
the environment.
The user is able to set new sceneObjects to remain at a desired location or return back to their original location
within the environment.

Figure 3: Creating an interactive object from a selection

2616

et al.V./Alexandrov
Procedia Computer
(2012) 00
2609–2617
A. Dunk,A.
A.Dunk
Haﬀegee,
/ Procedia Science
Computer1 Science
(2010) 1–9

8

3D Drawing Application:
With this application the user is able to draw 3D images by creating spherical objects within the environment at
the location of the 3D input device. It is then possible to select any number of these points and change their colour
using a 3D colour picker. The selected objects can also be deleted from the environment.
The drawing features can be used within any loaded environment, making it possible to draw annotations into
an environment, Figure 4 shows a user adding a rout on a map hanging on the wall of a coﬀee shop model, and
highlighting a section of the rout in a diﬀerent colour, using the multiple selection technique.

Figure 4: An annotated map, and demonstration of changing colour properties

6. Conclusions
This paper began by showing the importance of multiple object selection, and content creation and management
for immersive virtual reality systems. It then proceeded to review various methods for single and multiple object
selection, mentioning key points about each method, as well as some of the current methods of model creation and
interactive object creation. The design and implementation of an application to be able to create interactive objects
from within an immersive virtual environment in real-time was created, with the emphasis on selection methods
and creation of basic interactive objects. A suggested set of selection methods are developed based on object size,
distance, and number of objects being selected. Multiple selection methods are suggested, rather than attempting
to ﬁt one selection method to all foreseeable circumstances. After initial developments, a review of the work was
documented with limitations of the design and remedies to those problems. Finally, two case studies are presented
that demonstrate the additional functionality and interaction gained within an immersive virtual environment.
From this initial research we have learnt that multiple selection methods are required within an interactive immersive application. That orientation is an important part of multiple object selection, and that further research into
methods for easier orientated selection is required. It has also been noted that a distinction needs to be made between
diﬀerent types of selection within an environment, i.e. object selection and mesh selection.
Being able to create basic interactive objects from within the immersive environment starts to bridge the gap from
being an immersive 3D visualisation, to an immersive, interactive, and productive environment that is able to be used
by the masses, not just by virtual reality experts. It is possible for a user to load a clean 3D mesh model downloaded
from the internet into the application, and extend the model’s functionality, and interaction capabilities, without the
need of 3D modeling, programming, or scripting knowledge.
This initial research has generated further research avenues and developments. Currently, it is not possible to save
the interactive changes made in a loaded environment, this functionality needs to be incorporated. The ability to select
partial sections of a mesh would give the application the ability to create objects from any loaded 3D ﬁle, even if
the model had badly organised mesh data. Further research into orientated 3D selections needs to be investigated to
see if it is possible to improve the eﬃciency of multiple object selections. There is already work being carried out to

A. Dunk
et al. / Procedia
Computer
Science
1 (2012)
2609–2617
A. Dunk,
A. Haﬀegee,
V. Alexandrov
/ Procedia
Computer
Science
00 (2010) 1–9

2617
9

add functionality to the selection cube that will enable the user to further adjust the size, shape, and orientation of the
selection. Selections can also be improved with an investigation into the ability of intelligently suggesting or choosing
an appropriate selection method for the user depending on a predicted attempt of a group of objects.
Finally, the further development of interactions available for the user to apply to objects within the environment
is important in keeping the application up-to-date. Some suggested additions include logical operations, triggers,
sensors, physics, and an in environment visual editor for complex object interactivity.
References
[1] C. Cruz-Neira, D. Sandin, T. DeFanti, Surround-screen projection-based virtual reality: the design and implementation of the CAVE, in:
Proceedings of the 20th annual conference on Computer graphics and interactive techniques, ACM, 1993, p. 142.
[2] Dassault Systems, 3DVIA Virtools. Accessed 07/03/2010.
URL http://www.3ds.com/products/3dvia/3dvia-virtools/welcome/
[3] I. Poupyrev, M. Billinghurst, S. Weghorst, The Go-Go Interaction Technique: Non-linear Mapping for Direct Manipulation in VR, in: ACM
Symposium on User Interface Software and Technology, ACM Press, 1996, pp. 79–80.
[4] M. Billinghurst, I. Poupyrev, T. Ichikawa, S. Weghorst, Egocentric Object Manipulation in Virtual Environments: Empirical Evaluation of
Interaction Techniques, Computer Graphics Forum 17 (3) (1998) 41–52. doi:10.1111/1467-8659.00252.
[5] F. Steinicke, T. Ropinski, K. Hinrichs, Object Selection in Virtual Environments With an Improved Virtual Pointer Metaphor, in: Proceedings
of the International Conference on Computer Vision and Graphics ICCVG, SpringerLink, Warsaw, 2004, pp. 320—-326.
[6] A. Steed, C. Parker, 3D Selection Strategies for Head Tracked and Non-Head Tracked Operation of Spatially Immersive Displays, in: 8th
International Immer- sive Projection Technology Workshop., London, UK, 2004, pp. 1–8.
[7] R. Stoakley, M. Conway, R. Pausch, Virtual reality on a WIM: Interactive worlds in miniature, in: Proceedings of the SIGCHI conference on
Human factors in computing systems, Vol. 95, ACM Press/Addison-Wesley Publishing Co. New York, NY, USA, Virginia, 1995, p. 265272.
[8] R. A. Bolt, ”Put-that-there”: Voice and gesture at the graphics interface, in: SIGGRAPH ’80: Proceedings of the 7th annual conference on
Computer graphics and interactive techniques, ACM Press, Seattle, Washington, United States, 1980, pp. 262–270. doi:800250.807503.
[9] J. D. Mulder, Menu Selection in Desktop Virtual Reality, in: J. Zara, J. Sloup (Eds.), Central European Multimedia and Virtual Reality
Conference, Amsterdam, the Netherlands, 2005.
[10] Blender Foundation, Blender. Accessed 15/01/2010.
URL http://www.blender.org
[11] M. Ciragan, MilkShape 3D. Accessed 15/01/2010.
URL http://chumbalum.swissquake.ch/
[12] G. H. Bendels, F. Kahlesz, R. Klein, Towards the next generation of 3D content creation, Proceedings of the working conference on Advanced
visual interfaces - AVI ’04 (2004) 283doi:10.1145/989863.989912.
[13] M. Billinghurst, S. Baldis, L. Matheson, M. Philips, 3D palette: a virtual reality content creation tool, in: Proceedings of the ACM symposium
on Virtual reality software and technology, no. Figure 1, ACM New York, NY, USA, 1997, p. 155156.
[14] O. De Troyer, F. Kleinermann, B. Pellens, W. Bille, Conceptual modeling for virtual reality, in: Tutorials, posters, panels and industrial
contributions at the 26th international conference on Conceptual modeling-Volume 83, Vol. 83, Australian Computer Society, Inc., 2007, p.
318.
[15] L. Blackwell, B. von Konsky, M. Robey, Petri net script: a visual language for describing action, behaviour and plot, Australian Computer
Science Communications 23 (1).
[16] Id Software, GtkRadiant. Accessed 15/10/2010.
URL http://www.qeradiant.com/cgi-bin/trac.cgi
[17] Active Worlds Inc., Active Worlds. Accessed 15/01/2010.
URL http://www.activeworlds.com/
[18] Linden Research, Second Life. Accessed 15/01/2010.
URL http://secondlife.com/
[19] D. A. Bowman, J. F. Lucas, J. Chen, C. A. Wingrave, Design and Evaluation of 3D Multiple Object Selection Techniques, in: Proc. of the
ACM I3D, ACM Press, Seattle, Washington, USA, 2005.
[20] A. Haﬀegee, VieGen: An Accessible Toolset for the Conﬁguration and Control of Virtual Environments (2008).

