A Semantic-Oriented Platform for Performance
Monitoring of Distributed Java Applications
Wlodzimierz Funika, Piotr Godowski, and Piotr P¸egiel
Institute of Computer Science, AGH, al. Mickiewicza 30, 30-059 Krak´
ow, Poland
funika@agh.edu.pl, {flash,pegiel}@student.agh.edu.pl
Phone: (+48 12) 617 44 66; Fax: (+48 12) 633 80 54

Abstract. In this paper we present an approach to semantic performance analysis in on–line monitoring systems. We have designed a novel
monitoring system which uses ontological description for all concepts exploited in the distributed systems monitoring. We introduce a complete
implementation of a robust system with semantics, which is not biased to
any kind of the underlying “physical” monitoring system, giving the end
user the power of intelligent monitoring features like automatic metrics
selection and collaborative work.

1

Introduction

The design of a distributed application is in many cases a challenge to the developer ([1,2,3,4]). On the one hand, there are the limitations and performance
issues of distributed programming platforms. So one of the most important tasks
is to increase the performance and reliability of distributed applications. On the
other hand, the developer must assure that the application manages and uses distributed resources eﬃciently. Therefore, understanding application’s behaviour
through performance analysis and visualization is crucial. It is especially true
now, when many distributed systems exploit the SOAP protocol, where functionality of the program is implemented as Web Services. The monitoring of
data ﬂow between components could be very helpful for the user to discover
performance problems with a system.
The biggest problem when using performance tools (especially, these working
“on-line”) is their complexity. Thus many users beneﬁt from often less complex
but easier to use tools. So a very important task is to ease user’s interactions
with the monitoring system, moreover, to turn these interactions into a kind of
collaboration activities with the system, which involve other users. Certainly,
“simple” should not imply “limited functionality” related to performance evaluation. Nowadays, more and more developed software use software agents which
guide the user step-by-step. Such agents usually use a semantic description of
software’s features and through the analysis of user’s behaviour provide suggestions what to do to achieve a desired result.
A similar approach can be used in tools used for performance monitoring in the
distributed environment. The ﬁrst steps have been done (AutoPilot, PerfOnto),
M. Bubak et al. (Eds.): ICCS 2008, Part III, LNCS 5103, pp. 233–242, 2008.
c Springer-Verlag Berlin Heidelberg 2008

234

W. Funika, P. Godowski, and P. P¸egiel

but their authors aimed at developing their own architecture for semantic description (mostly based on feedback from metrics) from scratch, omitting the already
existing solutions (like OWL/RDF). The Semantic Web paradigm has introduced
the concept of semantic description of resources (OWL/RDF, DAML) and services (mostly Web Services – OWL-S, DAML-S). We can leverage from existing
standards to develop a performance monitoring tool using some knowledge which
describes performance metrics, and this is the primary goal of our paper.
The rest of this paper is organized as follows: Section 2 discusses a motivation
and system use cases. Related work is discussed in Section 3, in Section 4 we
present our proposed ontology and system architecture for on-line monitoring
system with semantics, followed by Summary and Future work in Section 5.

2

System Use Cases

In this paper we are presenting a semantic-oriented monitoring infrastructure
called SemMon. The architecture of the tool ﬁts into the OMIS model [10] and is
capable to co-operate with available monitoring systems (like J-OCM[8], JMX1 ).
The complexity and heterogeneity of the technologies necessitates to introduce
semantics into the distributed computing monitoring because; the large amount
of hardware, software and network environments makes monitoring a challenging task. Semantics enables the system to automatically process data without
supervision or customized processing for speciﬁc areas, enables ”understanding”
what is really monitored, which in turn reduces the time the user spends on
manually searching for issues and shortens the system learning curve. Having
a semantic description and taxonomy of the monitored elements and their contexts, the system is ”smart” enough to guide its user throughout the whole
monitoring/analysis process. The user can focus on its main task: to ﬁnd performance issues within limited time, based on the system guidance coming from
historic analysis and being able to add their own measurements when needed.
Semantics in the monitoring architecture should exploit as much as possible
from existing solutions, libraries and tools, with special attention paid to Open
Source software and solutions developed in European projects (like GOM [9]
developed in the K-Wf Grid project [7]). The following general use cases show
the usability of the designed system.
The user should be able to:
– monitor the performance of a Java application running under control of a
physical monitoring system
– use the system in an automatic way with a set of metrics which are meaningful
for the user and a desired result
– get information about metrics that should be called in a next step.
The system administrator should be able to:
– create, destroy, and insert a semantic description of available metrics and
elements of the monitored system
1

Stands for Java Management Extensions.

A Semantic-Oriented Platform

235

– provide new metrics in a physical monitoring system, and describe them in
semantic way
– manage historical performance data.
The work should be based on a portable (preferably XML) client–server protocol
both for sending and receiving requests about semantic descriptions. Developing
a system as a Web Service (with semantic description provided) leads to a universal solution, which ﬁts into the Semantic Web paradigm. The developed system
should be designed in such a way that it should work with any existing “native”
grid-enabled monitoring system. The system should be able to integrate with
existing ontologies describing resources and performance measurements which
should be a great beneﬁt for system administrators. The designed system should
be able to be extended with sensors and metrics strongly related to the structure
of the monitored application to point the actual and the most accurate source
of the data.

3

Related Work

In this section we will concentrate on those available monitoring systems where
semantics or ﬂexible monitoring architecture are introduced.
Gemini [5] is a Grid monitoring framework that fulﬁlls a gap between resources
monitoring components and monitoring services clients. It performs measurements using a set of loadable modules called sensors which retrieve monitoring
data on its own or by using external applications for this purpose. Although the
Gemini framework is powerful in its ﬂexibility of adding new sensors, it does not
use any kind of semantics for selecting performance metrics to run and analyse
or for providing any guidance to the user.
Autopilot [11] has been developed within the Grid Application Development
Software (GrADS) Project [6] and is responsible for adaptive control of distributed applications. Autopilot’s architecture comprises performance sensors
and a decision control unit using fuzzy logic to analyse received data from sensors and preparing messages to actuators. Autopilot is the very ﬁrst example of
exploiting some kind of semantics usage, or rather fuzzy logic usage to help with
monitoring and adaptation actions.
PerfOnto [12] is a new approach to performance analysis, data sharing and
tools integration in Grids that is based on ontology. PerfOnto is an OWL ontology describing experiment-related and resource-related concepts. The experiment-related concept describes experiments and their associated performance data
on applications. The prototype PerfOnto system is able to search data in an ontological (i.e. using a knowledge base) manner, e.g. to ﬁnd a code region executed
on a particular node with a metric exceeding a threshold value, thus giving a
hint to the site scheduler to migrate a job to another node. PerfOnto gives a rich
description of performance data, but does not provide any automation for using
it. Whereas using much of PerfOnto’s taxonomy and retaining the main idea of
describing resources in form of ontology, we were able to signiﬁcantly extend it
and provide adaptation algorithms.

236

4

W. Funika, P. Godowski, and P. P¸egiel

Overview of the SemMon System

The visualization of monitoring data in a “user friendly” form is one of the
most key features provided by any performance monitoring system. Due to the
great amount of gathered information, proper presentation and interpretation of
observation results becomes a very complicated task. So steering the visualization
of monitoring data involving making decisions what, when, in what form, under
which circumstances should be presented to the user is a challenge.
A high level architecture overview of SemMon is introduced in Fig. 1.

Ontology Subsystem
Core Subsystem
Ontology storage
(Resource description,
Metrics description)
monitoring information over
physical monitoring system,
control information
Monitoring core computer/cluster

Metrics results database

computers/nodes
with monitoring agents
Computers with monitoring GUI tool
(GUI Subsystem)

Fig. 1. System architecture as distributed environment. Monitoring core computers
include Core Subsystem and Ontology Subsystem.

The heart of the model are computers that provide a primary system functionality like processing an ontology with Resource Capabilities and Metrics or
storing monitoring data.
To support knowledge persistency a database is required. This functionality is
implemented in the Ontology subsystem. Another part of this node is support for
a “physical” monitoring system. This subsystem has to provide a functionality
for registering monitoring agents as well as for processing monitoring data.
The second part of the system contains computers with monitoring agents.
Agents expose monitored resources to our monitoring system. All of them will
register to the Core subsystem, afterwards Core is able to introspect possible
resources that are exposed. Agents are programs on the nodes/computers that
access the “physical” monitoring system, e.g. JMX, JOCM.
The last part of the system are GUI clients connected to the Core subsystem.
GUI is an environment for collaborative work – the users share metric ranks
between diﬀerent GUI instances in order to help other users in proper decision
making. In the following we focus on a description of the components of the
SemMon monitoring system.

A Semantic-Oriented Platform

4.1

237

Ontology Subsystem

The Ontology subsystem is the heart of the whole system. The key aspect to
understand here is the ontology term. An ontology is an explicit speciﬁcation of a
conceptualization. In such an ontology, deﬁnitions associate the names of entities
(e.g., classes, relations, functions, or other objects) with a human readable text
describing what the names are meant to denote, and formal axioms that constrain the interpretation and well formed use of these terms, formally speciﬁed
with the OWL language. The Ontology Web Language (OWL) is intended to be
used when the information needs to be processed in an automatic way by applications, as opposed to situations where the content only needs to be presented to
humans. OWL has powerful facilities for expressing meaning and semantics and
thus OWL goes beyond all other similar languages in its capability to represent
a machine interpretable content on the Web.
The Ontology subsystem contains methods for parsing, automatic interpretation, searching, creating, and, ﬁnally, saving and sharing ontology data. The
Ontology subsystem brings a unique feature to the designed system: the capability of interpreting what is monitored both for system users and (what is even
more important) for the system itself. Using the knowledge deployed in the underlying ontology data, the system is aware what is monitored and what should
be monitored in a next step within the monitored application’s lifetime. Every
single type of resource accessible to the monitoring system is described in the
OWL ontology and reﬂects a natural computing resources hierarchy. Part of the
description or even the whole of it can be updated.
Resources in question are: Resource classes (like Node, CPU, JVM), Resource
instances (i.e. OWL instances of resources available in the underlying monitoring system, like CPU i386 node2 cluster1) and the measurable attributes for
the resource instances. Each Resource class deﬁnes which measurable attributes
are available for its instances. A measurable attribute, called in this paper ResourceCapability, might be both an atomic attribute (like LoadAvg1Min) or an
OWL superclass for a set of ResourceCapabilities. This way a natural hierarchy
of capabilities can be constructed. A special property hasResourceCapability
is a glue between Resources and ResourceCapabilities. Any type of Resource can
contain any number of Resource Capabilities. Fig. 2 shows the Resources ontology class hierarchy while Fig. 3 presents a fragment of the ResourceCapabilities
ontology class hierarchy.
An ontology describes metric concepts like the OWL classes or individuals describing metrics available to be executed by the user. Metrics ontology reﬂects the
metrics hierarchy (i.e. from the most generic metric to the most speciﬁc one) in
order to provide a rich description for ontology reasoners. Metrics can be simple,
i.e. the metric is able to measure only one attribute or custom, which means that
the metric can be applied to as many capabilities as required and it is even possible
to provide custom implementations for metrics (user-deﬁned metrics).
A metrics ontology is designed from a ﬂat list of all available metrics to be
considered by the monitoring system. However, having only a ﬂat list without
a hierarchy (specialization) introduced, it is impossible to provide any powerful

238

W. Funika, P. Godowski, and P. P¸egiel
ThirdPartSoftware

Software

ClassLoader

JVM

Thread

OperatingSystem
Class

Cluster
Resource

NetworkInterface
Node
CPU

Hardware

Memory

Storage

HardDisk

Fig. 2. Resources ontology diagram

CPUUsageCapability

CPUCapability

MemoryCapability

HardwareCapability

AvailableVirtualMemory
Capability

StorageCapability
LoadCapability

ResourceCapability

NodeCapability

NetworkingCapability
ThreadCapability

SoftwareCapability
OperatingSystemCapability

JVMCapability

UptimeCapability

Fig. 3. ResourceCapabilities ontology diagram

reasoning process. This is because no ”generic-speciﬁc” or ”is related to” relationships are provided. Looking at a ﬂat list of all possible metrics, the next
step is to ﬁnd out which of them are generic and which are speciﬁc. Such relationships can be expressed in an ontology as the rdfs:subClassOf property.
A sample superclass metric might be SoftwareMetric with its speciﬁc subclass
JVMThreadCPUTimeMetric. As a result, metrics form a tree which can be used
for a reasoning process.
A special metric property monitors is a glue between the Metrics ontology
and the Resources and ResourcesCapabilities ontology. Property monitors has
a domain in the AbstractMetric class (and its subclasses) and a range in the
ResourceCapability classes. Because the cardinality of this property is not limited, any type of AbstractMetric is able to monitor any number of capabilities.
This means that the total number of measurements available in the system does
not equal to the number of subclasses and individuals of the AbstractMetric

A Semantic-Oriented Platform

239

class, but is a sum of cardinalities of monitors properties in the metrics ontology. Metric property hasCustomImplementationClass is used to inform the
system that the metric is a custom metric, i.e. has its own implementation. This
property points to the fully qualiﬁed Java class name implementing the Custom
Metric interface. Custom Metric has its own implementation rules that is exactly
returned as a measurement process, which is explained as follows. Since Custom
Metric can access the Core public API, and the Resources registry, it can request
any number of capabilities’ values from the underlying monitoring system. The
only contract that Custom Metric must meet is to return a single number each
time it is requested for.
It should be noted that the described Ontology subsystem should be able to
coexist with any already existing ontology for resources description and matching.
4.2

Core Subsystem

The Core subsystem is responsible for connecting to the underlying monitoring system’s initialization (using its protocol adapter mechanism), deploying,
initializing and executing metrics (including user-deﬁned metrics), providing an
interface to the Ontology subsystem and last but not least, exposing a public
(remote) interface for GUI clients to connect to. Core also manages GUI clients
subscribed to the list of connected resources, running metrics, running metric
values and alarms (i.e. conditional action metrics notiﬁcations). The Core subsystem comprises three components – Adapter, Resource Registry, and Remote
interface for GUI. The Adapter component follows the commonly used Adapter
structural design pattern and is used for “translation” of all Core requests into
the requests speciﬁc to the underlying monitoring system (JMX, J-OCM, OCMG, etc.). Due to the major diﬀerences and interface incompatibilities of a wide
range of monitoring systems available on the market, a common interface called
Protocol Adapter is designed. Resource Registry is a service that leverages both
Core and Protocol Adapter. Resource Registry holds (with Protocol Adapter)
all the resource instances found as visible in the underlying monitoring system
and maps them into Core identiﬁers. Protocol Adapter resolves incompatibility
issues between diﬀerent physical monitoring systems. User-deﬁned metrics have
full access to the public Core API. Therefore a user-deﬁned metric (implementing the Custom Metric interface) can introspect Resource Registry and with
a Protocol Adapter implementation is capable to send a speciﬁc query to the
underlying monitoring system. This feature is useful when the underlying monitoring system has some speciﬁc features, not covered by the generic Protocol
Adapter interface.
Remote interface for GUI allows remote GUI clients to connect to SemMon
to enable collaborative work and provides:
– notiﬁcations for: newly attached and detached monitoring systems, started
and stopped measurements on the Core subsystem, and, ﬁnally, notiﬁcations
for measurement values
– interface for alarms – Alarms are conditional action metric notiﬁcations.
When some action metric is running on the Core subsystem and its value ex-

240

W. Funika, P. Godowski, and P. P¸egiel

ceeds a declared threshold action value, all the unconditional action metrics
that are declared in the underlying ontology are sent as notiﬁcations to all
the subscribed GUI users. The user is enabled to take an action to resolve
the alarm (e.g. to start a new metric from within a list of metrics suggested
by the system).
4.3

Sample Use of SemMon

The below real-life example shows a few of the key SemMon features. A SemMon
system user is monitoring a complex distributed application with critical problems relating to unstable memory usage over the application life time occurring
only on a single node of the cluster. The monitored application is a WebServiceenabled Java server, deployed across a cluster of processing nodes placed behind
a restrictive ﬁrewall with a load balancer. The usual behaviour on the correctly
deployed system in question is to consume 50% of the CPU time for each node
and create no more than 100 threads per JVM instance.

Fig. 4. Sample analysis with SemMon

At ﬁrst, the user decides to monitor a CPU usage on the heaviest loaded
node (see step 1 in Fig. 4). When a CPU burst lasts for at least 3 minutes,
SemMon deducts from the metrics ontology a ”critical” situation, and calculates
the next most probable metric to start. Since CPU load is semantically connected
with the number of JVM live threads, the adequate metric is suggested and
the user follows this guidance (2 ). Again, the number of threads is irrationally
high (over 200 threads), so a new alarm is raised and SemMon ”reasons” that
since the CPU load and number of threads were already monitored, it would
be reasonable to monitor memory usage (3 ). Since the memory usage is at 80%
level of the available virtual memory, a new alarm is raised. This moment is the
key in the described monitoring scenario: since the observed CPU load, memory
usage, and JVM threads count are extremely high, the algorithm selects the
Network Bandwidth metric to run (4 ). A motivation for doing this is that this
metric had been frequently selected by other system users in the past and it is
semantically connected with memory usage, CPU load, and JVM threads (there

A Semantic-Oriented Platform

241

is a possibility that application threads are processing data incoming from the
network). SemMon has calculated the best matching metric and the user is able
to see that almost the whole available network bandwidth is consumed by the
incoming traﬃc. This suggests that either the cluster system is overloaded (which
is not the case since we observe high load only on the certain node), or the load
balancer is broken. The user checks the network bandwidth on the rest of the
cluster nodes and does not observe any signiﬁcant incoming traﬃc. This leads
to the conclusion that the problem lies not in the monitored application, but in
the load balancing component (5 ).
Please note that the path followed by the user comprises both hardware (low
level) and software (high level) metrics. It shows how ﬂexible a reasoning process
might be when the knowledge stored in SemMon holds possibly a full description
of the environment. It is also possible to track down performance issues not only
in the monitored application, but also in its environment.

5

Summary and Future Work

The main objective of this paper was to present the design and implementation of
a robust and ﬂexible semantics-oriented monitoring system, SemMon. It seems to
be one of the ﬁrst complete approaches to the joint “worlds” of on-line distributed
monitoring and Semantic Web.
The SemMon system extensively uses ontology for semantic description of
all concepts used in. It is as much ﬂexible as it can be, starting from picking
up automatic ontology changes, through automatic metric selection assistance,
collaborative users’ knowledge leveraging, user-deﬁned metrics, ﬁnally, to the
extensible and clear visualisation options.
There are still places for improvements. There is a unresolved problem with
performing part of the computations on the clients to improve system scalability
by reducing the size of performance data sent to a central database. An important
task is to explore algorithms for reasoning in the ontology frameworks. Although
there are some improvements in the query algorithms, they are just based on
additional caching layer rather than optimizing algorithms.
Acknowledgements. The research is partially supported by the EU IST 0004265
CoreGRID and 031857 int.eu.grid projects with the related SPUB-M grant.

References
1. Gerndt, M., Wism¨
uller, R., Balaton, Z., Gomb´
as, G., Kacsuk, P., N´emeth, Zs.,
Podhorszki, N., Truong, H.-L., Fahringer, T., Bubak, M., Laure, E., Margalef, T.:
Performance Tools for the Grid: State of the Art and Future. APART-2 Working Group, Research Report Series, Lehrstuhl f¨
ur Rechnertechnik und Rechnerorganisation (LRR-TUM) Technische Universit¨
at Muenchen, vol. 30. Shaker Verlag
(2004) ISBN 3-8322-2413-0
2. Podhorszki, N., Kacsuk, P.: Presentation and Analysis of Grid Performance Data.
In: Kosch, H., B¨
osz¨
orm´enyi, L., Hellwagner, H. (eds.) Euro-Par 2003. LNCS,
vol. 2790, pp. 119–126. Springer, Heidelberg (2003)

242

W. Funika, P. Godowski, and P. P¸egiel

3. Reed, D.A., Ribler, R.L.: Performance Analysis and Visualization. In: Foster, I.,
Kesselman, C. (eds.) Computational Grids: State of the Art and Future Directions
in High-Performance Distributed Computing, pp. 367–393. Morgan-Kaufman Publishers, San Francisco (1998)
4. Wism¨
uller, R., Bubak, M., Funika, W.: High-level application-speciﬁc performance
analysis using the G-PM tool. Future Generation Comp. Syst. 24(2), 121–132
(2008)
5. Balis, B., Bubak, M., Labno, B.: GEMINI: Generic Monitoring Infrastructure for
Grid Resources and Applications. In: Bubak, M., Unger, S. (eds.). Proc. Cracow
Grid Workshop 2006. The Knowledge-based Workﬂow System for Grid Applications, pp. 60–73. ACC Cyfronet AGH, Poland (2007)
6. Berman, F., Chien, A., Cooper, K., Dongarra, J., Foster, I., Johnsson, L., Gannon,
D., Kennedy, K., Kesselman, C., Reed, D., Torczon, L., Wolski, R.: The GrAds
project: Software support for high-level grid application development. Technical
Report Rice COMPTR00-355, Rice University (2000)
7. Bubak, M., Fahringer, T., Hluchy, L., Hoheisel, A., Kitowski, J., Unger, S., Viano,
G., Votis, K., K-WfGrid Consortium: K-Wf Grid Knowledge based Workﬂow system for Grid Applications. In: Proc. Cracow Grid Workshop 2004, p.39. ACC
CYFRONET AGH, Poland (2005) ISBN 83-915141-4-5
8. Funika, W., Bubak, M., Sm¸etek, M., Wism¨
uller, R.: An OMIS-based Approach to
Monitoring Distributed Java Applications. In: Kwong, Y.C. (ed.) Annual Review
of Scalable Computing, ch.1, vol. 6, pp. 1–29. World Scientiﬁc Publishing Co. and
Singapore University Press, Singapore (2004)
9. Krawczyk, K., Slota, R., Majewska, M., Kryza, B., Kitowski, J.: Grid Organization Memory for Knowledge Management for Grid Environment. In: Proc. Cracow
Grid Workshop 2004, pp.109-115. ACC CYFRONET AGH, Krakow, Poland (2005)
ISBN 83-915141-4-5
10. Ludwig, T., Wism¨
uller, R., Sunderam, V., Bode, A.: OMIS – On-line Monitoring
Interface Speciﬁcation (Version 2.0). LRR-TUM Research Report Series, vol. 9.
Shaker Verlag, Aachen (1997)
11. Ribler, R.L., Vetter, J.S., Simitci, H., Reed, D.A.: Autopilot: Adaptive Control
of Distributed Applications. In: Proc. 7th IEEE High-Performance Distributed
Computing Conference (1998)
12. Truong, H.-L., Dustdar, S., Fahringer, T.: Performance metrics and ontologies for
Grid workﬂows. Future Generation Comp. Syst. 23(6), 760–772 (2007)

