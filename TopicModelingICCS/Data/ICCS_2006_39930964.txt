Workﬂow Deployment in ICENI II
A. Stephen McGough, William Lee, and John Darlington
London e-Science Centre
Department of Computing
Imperial College London, London
{asm, wwhl, jd}@doc.ic.ac.uk

Abstract. The Imperial College e-Science Networked Infrastructure
(ICENI) has been developed by the London e-Science Centre for over
four years. ICENI has prototyped many novel ideas for providing an end
to end Grid middleware. This has included: service-oriented architecture,
component programming model, retaining and using meta-data collected
throughout the life-cycle of an application, and scheduling algorithms
which are aware of workﬂow and performance data. In this paper we
describe the workﬂow pipeline and deployment process of ICENI II. This
allows the user to specify their workﬂow at an abstract level which is fed
through the pipeline in order to successfully deploy it over the Grid. The
tool sets, which make up the stages of the ICENI II pipeline, are designed
to be composable in an `
a-la-carte fashion. Thus allowing Grid developers
to select only those components which are relevant for their work. When
these tool sets are composed together they form the higher level services
required to make the Grid useful to the end user.

1

Introduction

The ICENI (Imperial College e-Science Networked Infrastructure) [8, 3] has been
developed as a service–oriented architecture for (workﬂow) component composition. Our focus in ICENI has three major elements: prototyping the services
and their interfaces necessary to build a service–oriented middleware; developing
an augmented component programming model for authoring reusable Grid applications; to explore the meta-data needed to enable eﬀective machine-assisted
and automated decision-making; and the development of higher level services
required to make Grid infrastructure usable. ICENI II is a re-working of the
original ICENI concepts using the newly evolving commodity tools, standards
and services. Allowing us to re-focus on the higher level services required to make
the Grid useful to the scientist. In this paper we present the workﬂow pipeline
and deployment service for ICENI II focusing on the core services that can be
composed to enable a (workﬂow) component programming paradigm.
In ICENI an application is a composition of components and services deﬁned
using a workﬂow language. A component is an indivisible unit of execution in
which all the contextual, functional and behavioral aspects are made explicit.
While multiple components might exhibit the same functional interface, they can
be independently implemented yielding diﬀerent behavior [10]. Furthermore, a
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part III, LNCS 3993, pp. 964–971, 2006.
c Springer-Verlag Berlin Heidelberg 2006

Workﬂow Deployment in ICENI II

965

component is an abstract entity that awaits composition by application authors
and subsequent deployment into an execution environment.
A deployed component is referred to as a service. A service is a realised manifestation of the states and functions provided by the underlying resource and
the component implementation. The deﬁnition does not mandate a particular
component implementation architecture. The current ICENI II implementation
requires the use of an interoperable set of protocols (e.g. SOAP) and data model
(e.g. WSDL, XSD Schema) as the common denominator. We envisage the protocol details are suﬃciently abstract from the component and application authors.
This allows applications to be composed with both abstract components that
need to be provisioned and anchored services that exist irrespective of the lifetime of the application. It is the role of the workﬂow pipeline to realise an application by performing component implementation selection, resource allocation,
deployment and orchestration. Further information on the ICENI component
model can be found in [8, 9].

2

Architecture

Figure 1 illustrates the workﬂow pipeline for ICENI II. Within this design we
have determined three main stages within an application’s life-cycle:
Speciﬁcation of the application to be executed. At this stage the workﬂow may
be abstract in nature - the code that will be used to implement the tasks and the

Specification
Specification
End-users
End-users

Developers
Developers and
and Deployers
Deployers

High-level Abstract Workflow + QoS
Preferences + Security Constraints

Realisation
Oon

Functional Description + Performance
Annotation + Availability

Syntactic
Syntactic and
and Semantic
Semantic Validation
Validation

Static
Static Workflow
Workflow Optimisation
Optimisation

Performance Data

Performance
Performance Repository
Repository
Performance
Profiles

Equivalent Workflow
Candidates

P2P / UDDI

Discovery
Discovery

Component and
Resource
Availability

Dynamic
Dynamic Optimisation
Optimisation and
and Scheduling
Scheduling
Concrete Workflow + QoS constraints + Security
constraints

Service
Service

Service
Service

Component
Component
Component
Component
Component
Component

Service
Service

Virtualised
Virtualised Component
Component Container
Container
Execution
Execution Environment
Environment

op
po Re
rt ac
fa un ts t
ilu iti o
re es
s an
d

de
pl
oy
m
oen
or
t
di
ex nat
ch es
an m
ge es
sa
ge
En
M vir
on on
m
ito
rin en
g t
C

rr
an
ge
s

A

Execution
Execution

M
ak
es

re
se
rv
at

io
n

Workflow
Workflow Orchestration
Orchestration and
and Re-optimisation
Re-optimisation

Component Packaging and
Deployment

Fig. 1. The Design Diagram for ICENI II

966

A.S. McGough, W. Lee, and J. Darlington

resources on which they run are not yet deﬁned. The translation of an application
scientist’s ideas into these workﬂows is a complex task. It cannot be assumed that
the application scientist will be an expert with workﬂow languages, we therefore
see the need to develop application speciﬁc interfaces which allow the scientist to
describe their problem in their own space - translating this down into a workﬂow.
This is an area of active research. We are working with the bio-informatics
community within the e-Protein project [13]. The Taverna project [21] is a good
example of this process.
Realisation of the workﬂow. The workﬂow needs to be made concrete before
it can be executed. This process involves determining the appropriate resources
and software (component implementations) dependencies for the workﬂow to
operate. The Realisation stage of the life-cycle is discussed further in Section 3.
Execution of the workﬂow. In this stage the concrete workﬂow is enacted on
the deﬁned set of resources. Implementations will be made active on resources
at the appropriate point in time. If however the workﬂow does not proceed as
planned then the realisation stage can be re-entered so that the workﬂow may be
altered in light of the changes. It is also possible to re-enter the realisation stage
in cases where parts of the original workﬂow couldn’t be made concrete at the
original pass or when new opportunities become available; such as availability of
new resources. Further details of the Execution stage are given in Section 4.
Once a workﬂow enters the realisation stage an Application Service will be
designated to represent the running application. It acts as a central point where
the user can ﬁnd out about the state or inﬂuence the progress of the application.

3

Realisation of Workﬂows

The Realisation stage selects the best use of anchored services or resources and
component implementations available on the Grid in an attempt to match the
criteria speciﬁed by the application scientist. Most often this will be in terms of
time constraints that the scientist may have. Although, other constraints may be
used (or combined) such as cost of resources, reliability of execution or the level
of trust required from the used resources and components. This is often referred
to as a Quality of Service (QoS) Document. This stage will take the abstract
workﬂow and resolve it into a concrete workﬂow in which implementations and
resources will have been determined.
The Realisation stage can be decomposed into several complementary services with most being optional. The only non-optional element, referred to as
the Resolver, matches abstract components with anchored services or implementations and resources. Pluggable optimisers can be used to improve the performance of the workﬂows or matching of QoS requirements. Detailed in the following subsections are the pluggable elements that we have deﬁned so far [11].
Syntactic and Semantic validation. On entering the Realisation stage the
workﬂow is checked for syntactic and semantic validity. The ﬁrst step in checking
syntactic correctness ensures that all required inter-component connections have

Workﬂow Deployment in ICENI II

967

been made, i.e. all ports that must be connected are, otherwise the workﬂow will
be unsuccessful at a later stage. The second step is to verify that the data to be
exchanged through each of these connections is a valid transaction.
The workﬂow may now be checked for semantic validation. Scientiﬁc knowledge about what action a component performs, and what the meaning of its
inputs and outputs, can be used to determine if the connection of two components makes sense. For example it may be syntactically correct to feed a matrix
into a ﬁnite diﬀerence solver, though if this matrix is a diagonal solution to a
set of linear equations this makes little semantic sense. If a workﬂow fails at a
syntactic or semantic level then it is returned to the speciﬁcation stage.
Static Workﬂow Optimisation. The Workﬂow Static Optimisation Service
is responsible for manipulation of the workﬂow. Using static information about
the components and their composition this service generates a new workﬂow
which is expected to execute more eﬃciently than the original. This is achieved
through such steps as re-ordering of the components to improve eﬃciency; inserting additional components to allow particular implementations to communicate
with each other; substitution of semantically equivalent workﬂow sections; pruning of redundant components from composed workﬂows; and the substitution of
alternative implementations of components. It should be noted that the Workﬂow Static Optimisation Service does not consider the dynamic load on system’s
within the Grid.
Pruning of Resource Space. Once the workﬂow has been optimised it is now
essential to reduce the set of resources that will be considered. This is achieved
by looking at the slowly changing resource information such as authorization to
use a resource; hardware / software requirements; problem speciﬁc requirements
such as long execution time with no option to checkpoint; and sensibility of
selection.
Workﬂow-aware, performance-guided scheduling. The aim of most schedulers is to map the abstract workﬂow to a combination of resources and implementations that is both eﬃcient in terms of execution time of the workﬂow and
in terms of the time to generate the concrete workﬂow. Components need not
all be deployed at the same time: just in time scheduling of components and
the use of advanced reservations help to make more optimal use of the available
resources for both the current and other users.
Schedulers need to be designed to be workﬂow aware. A number of workﬂow
aware schedulers have been prototyped in ICENI [12] and we are now developing
new workﬂow aware performance guided schedulers using constraint equations
solved using Mixed Integer Linear Programming [15]. Thus the scheduling of
components depends not only on the performance of a component on a given
resource, but also on the eﬀect this will have on the other components in the
workﬂow. Described below are the general steps taken to evaluate a suitable
mapping of components onto resources.
The scheduler can speculatively match implementations with resources. The
scheduler can then interrogate performance information in order to obtain estimates on the execution times for these implementation / resource combinations

968

A.S. McGough, W. Lee, and J. Darlington

along with any implications for the overall workﬂow. With this information and
information gathered from the resources that have been discovered, the scheduler
can determine an appropriate mapping of the components over the resources.

4

Execution of a Workﬂow

Due to the uncertainties of resource and network availability in a dynamic system such as the Grid, it is necessary to support advanced reservations to provide
QoS guarantees. Reservations may be made on computational resources, storage
resources, instruments or the underlying fabric of the Internet such as network
links. The reservations may be made for exclusive use of the entity or, in some
cases, some pre-agreed portion of it. This can be realised through the introduction of market forces into the Grid [6].
The execution environment represents the virtualisation of the resource that
manages the life-cycle of the parts of an application (see Figure 2). The execution environment encapsulates the facilities available to the software component,
such as inter-component communication, logging, monitoring, failure recovery,
checkpointing and migration. These facilities are exposed to the software component through a set of abstract APIs. These abstractions allow the execution
environments managing the parts of an application to co-operate and co-ordinate
their runtime capabilities, such as network transport, co-location and shared ﬁle
system. Software engineers developing the components are insulated from the
implementation choice made by the optimisation stage by following the software
patterns oﬀered by the APIs. This is analogous to the MPI[5] abstraction for
message-passing in parallel applications.
The software component instantiated in the execution environment is referred
to as a service. We adopt Web Services as one view of the running software
component. It is an ideal way for services on diﬀerent physical resources to
communicate with each other in an interoperable manner. The elements in the
execution environment will be discussed in more detail.
Component

Workflow Pipeline

transfers

deploys

monitors

Deployment Service
Instantiates
Inter-service
communication abstraction

Prepares
Service

Service

Service Container
Virtualised Operating System
Operating System
Hardware

Fig. 2. Execution Environment and Multi-level Virtualisation

Workﬂow Deployment in ICENI II

4.1

969

Component Deployment

A deployment service is the gateway to a computational resource. It is responsible for facilitating the provisioning and instantiation of a component assigned
to a particular resource. Firstly, the deployment service prepares the execution
environment. This might involve the preparation of a component container in a
cluster resource. Recent advances in virtualisation technologies [1, 20] oﬀer operating system-level virtualisation. Within the virtualised operating system, a
component container provides the higher-level abstraction to the software component on top of the operating system facilities. The compartment model oﬀers
attractive features such as security and fault isolation. Multi-level virtualisation
allows runtime facilities to be ﬂexibly conﬁgured depending on the deployment
requests [16]. Although virtualisation provides a sandbox environment for a component to execute seemingly exclusively, the cost in instantiating the container
on-demand [7] may be too high for short-running components. Predictive instantiation might alleviate the setup cost by allocating resources in advance.
Once an execution environment is available, the deployment service will facilitate the provision of the software component onto the resource. This might
involve the staging of software packages and their dependencies available remotely into the system. In order for this architecture to succeed across the Grid,
a standardised interface for deployment and a language for software requirement
description is essential. It reduces the need for users and software agents to understand a large number of description languages and deployment mechanisms
to exploit a variety of Grid resources.
GridSAM [4] is a job submission and monitoring Web Service developed
through collaboration with the OMII [14]. GridSAM allows the deployment of
legacy code through a standard interface and is seen as one of the ﬁrst toolkit
items within ICENI II.
4.2

Checkpointing and Migration

Checkpointing is a technique for preserving the state of a process in order to
reconstruct it at a later date. It is a crucial element for providing fault-recovery
from a saved state. In scientiﬁc applications checkpointing provides a means for
long-running simulations to be restarted at a previously examined parameter
space [2]. This is also an important means for migrating the state of a process to
another execution environment. This is often triggered by a re-scheduling decision as in some distributed resource managers. Many checkpointing and migration systems exist including OpenMosix [18], OpenSSI [19], and Kerrighed [17].
Migration might occur as a result of a recovery operation after a host failure. Alternatively migration may be as the result of a desire to exploit new
possibilities within the Grid, such as a new resource becoming available.
It is worth pointing out that not all components can be checkpointed. Techniques to checkpoint components are outlined below. The generality of the approaches increases from one to the next. Checkpointing and migration schemes
can be classiﬁed into three broad categories. Application-level checkpointing

970

A.S. McGough, W. Lee, and J. Darlington

might be initiated by the application itself through a checkpointing and migration API. This provides ﬁne-grain control to the developer to save the states
of the application at a critical moment of the execution, however it requires
existing applications to be modiﬁed to take advantage of the functionality. Existing executables could also be made checkpointable by linking to checkpoint
libraries that capture running stack, heap and program counter information in
order to reconstruct the process remotely. This solution produces a checkpoint
image that is rarely portable and complete because network sockets or ﬁle handles are inherently diﬃcult to reconstruct. System level checkpointing provided
by many virtual machine technologies allows the whole virtualised environment
to be checkpointed. This provides a generic solution for most cases but the coarse
nature means the checkpoint image would be very large.
In cases where the services within the workﬂow are capable of being checkpointed and migrated, the application co-ordinator in the workﬂow pipeline may
re-schedule the service state to a suitable resource in order to respect the stated
quality constraints. This might involve re-scheduling other services to diﬀerent
resources to achieve an optimal schedule. The stored checkpoints of services
are transferred to the suitable resources through the deployment service and
restarted in a reinstated execution environment. A component might receive
messages during the time elapsed between its failure and restart. Such events
are taken care of by the messaging abstraction in the initiating execution environment. The execution environment reports any anomalies like resource overloading or network failure to the application co-ordinator which in turn might
trigger the migration process.

5

Conclusion

In this paper we have outlined a set of high level tool sets for the manipulation of
workﬂows. When composed together these tool sets form the stages of a workﬂow
pipeline which take a users abstract workﬂow through to deployment on Grid
resources.
We are now developing some of these higher level services on top of GridSAM for job deployment and monitoring. Along with developments in the other
services for optimising workﬂows across multiple resources.
Wherever possible, and appropriate, ICENI II is being developed using existing standards. To this end ICENI II will be developed as a set of Web Services
and using up and coming standards such as BPEL4WS and JSDL.

References
1. P. Barman, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R. Neugebauer,
I. Pratt, and A. Warﬁeld. Xen and the art of virtualization. In SOSP 2003,
September 2003.
2. J. Chin, J. Harting, S. Jha, P.V. Coveney, A. R. Porter, and S. M. Pickles. Steering in computational science: mesoscale modelling and simulation. Contemporary
Physics, 44:417–434, 2003.

Workﬂow Deployment in ICENI II

971

3. N. Furmento, A. Mayer, S. McGough, S. Newhouse, T. Field, and J. Darlington. ICENI: Optimisation of Component Applications within a Grid Environment.
Journal of Parallel Computing, 28(12):1753–1772, 2002.
4. Grid
Submission
and
Monitoring
service
(GridSAM).
http://www.lesc.imperial.ac.uk/gridsam.
5. W. Gropp, E. Lusk, N. Doss, and A. Skjellum. A high-performance, portable implementation of the MPI message passing interface standard. Parallel Computing,
22(6):789–828, September 1996.
6. Jeremy Cohen and John Darlington and William Lee. Payment and Negotiation
for the Next Generation Grid and Web. In UK e-Science All Hands Meeting,
Nottingham, UK, sep 2005.
7. K. Keahey, K. Doering, and I. Foster. From Sandbox to Playground: Dynamic
Virtual Environments in the Grid. In 5th IEEE/ACM International Workshop on
Grid Computing, November 2004.
8. A. Mayer, S. McGough, N. Furmento, J. Cohen, M. Gulamali, L. Young, A. Afzal,
S. Newhouse, and J. Darlington. Component Models and Systems for Grid Applications, volume 1 of CoreGRID series, chapter ICENI: An Integrated Grid Middleware to Support e-Science, pages 109–124. Springer, June 2004.
9. A. Mayer, S. McGough, N. Furmento, W. Lee, S. Newhouse, and J. Darlington.
ICENI Dataﬂow and Workﬂow: Composition and Scheduling in Space and Time.
In UK e-Science All Hands Meeting, pages 627–634, Nottingham, UK, September
2003. ISBN 1-904425-11-9.
10. A. Mayer, S. McGough, M. Gulamali, L. Young, J. Stanton, S. Newhouse, and
J. Darlington. Meaning and Behaviour in Grid Oriented Components. In 3rd
International Workshop on Grid Computing, Grid 2002, volume 2536 of Lecture
Notes in Computer Science, Baltimore, USA, November 2002.
11. A.Stephen McGough, Jeremy Cohen, John Darlington, Eleftheria Katsiri, William
Lee, Soﬁa Panagiotidi, and Yash Patel. An End-to-end Workﬂow Pipeline for
Large-scale Grid Computing. Journal of Grid Computing, pages 1–23, February
2006.
12. S. McGough, L. Young, A. Afzal, S. Newhouse, and J. Darlington. Workﬂow Enactment in ICENI. In UK e-Science All Hands Meeting, pages 894–900, Nottingham,
UK, sep 2004.
13. A. O’Brien, S.J. Newhouse, and J. Darlington. Mapping of scientiﬁc workﬂow
within the e-protein project to distributed resources. In Proceedings of the UK
e-Science All Hands Meeting 2004, Nottingham, September 2004.
14. Open Middleware Infrastructure Institute (OMII). http://www.omii.ac.uk/.
15. Yash Patel, A. Stephen McGough, and John Darlington.
16. E. Smith and P. Anderson. Dynamic Reconﬁguration for Grid Fabrics. In 5th
IEEE/ACM International Workshop on Grid Computing, November 2004.
17. The Kerrighed project. http://www.kerrighed.org/.
18. The open Mosix project. http://openmosix.sourceforge.net/.
19. The open SSI project. http://openssi.org/index.shtml.
20. User Mode Linux. http://user-mode-linux.sourceforge.net/.
21. The Taverna Project Website. http://taverna.sourceforge.net/.

