Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1516–1525

International Conference on Computational Science, ICCS 2010

Data exchange algorithm and software design of KAKUSHIN
coupler Jcup
Takashi Arakawaa,1,∗, Hiromasa Yoshimurab , Fuyuki Saitoc , Koji Ogochic
a Reseach

Organization for Information Science and Technology
b Meteorological Research Institute
c Japan Agency for Marine-Earth Science and Technology

Abstract
A coupler development program is on going as a part of Innovative Program of Climate Change projection for the
21st century (KAKUSHIN Program). The coupler is called Jcup. Basic functions of coupler are data exchange between models that have various grid systems and data conversion (interpolation) calculation. Among these functions,
this article focuses on data exchange. Especially, multi-component coupling case that two or more models exist in
single execution unit is regarded as the most important topic. What kind of coupling patterns are possible and how
such a coupling patterns are realized on multi-component coupling is discussed in this article.
Keywords: coupler, climate modeling, multi-component, data exchange

1. Introduction
Climate simulation model is one of the largest-scale simulation models in various scientific and technological
fields that requires state-of-the-art computational resources.
For example, NCAR CCSM (Community Climate System Model) code consists of more than 350000 lines. On
the other hand, five appliations presented in Table.1 chosen to compare the performance of leading supercomputing
platforms have lines from 3000 to 84000[1].

Table 1: Overview of scientific applications used for peta-scale performance evaluation

Name
GTC
Cactus
ELBD
PARATEC
HyperCLaw

∗ Email

Lines
5000
84000
3000
50000
69000

Discipline
Magnetic Fusion
Astrophysics
Fluid Dynamics
Materials Science
Gas Dynamics

Methods
Particle in Cell, Vlasov-Poisson
Einstein Theory of GR, ADM-BSSN
Lattice-Boltzmann, Navier-Stokes
Density Functional Theory, FFT
Hyperbolic, High-order Godunov

address: arakawa@tokyo.rist.or.jp(Takashi Arakawa)
author

1 Corresponding

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.164

Structure
Particle/Grid
Grid
Grid/Lattice
Fourier/Grid
Grid AMR

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

1517

The reason why the program size of climate model has come to be so large comes from complexity of climate
system. In general, atmosphere, ocean, land and sea ice are typical processes included in a climate model, of course
it depends on the spatial and temporal scale and/or accuracy the model must represent. In addition, these physical
processes are composed of various sub-processes such as precipitation process and radiation process etc. Land biota
process must be included in the model, furthermore, to calculate the concentration change of human born green house
gases which play an important role on climate change prediction.
The history of climate model development is that of taking more various processes into the calculation with more
accurate expression.
Recently, these models including such a diverse processes are called Earth System Model (ESM). But in this
article, the word• •climate model • •is used for all of these models and some other terms are defined as follows.
• Process: An individual physical phenomenon included in a climate model
• Component: A program unit corresponding to the process
• Task: A set of component executed as a single executable
A process can include some sub-processes and a sub-process can include some sub-sub-processes. Therefore,
what program unit is regarded as a component is arbitrary and changeable according to code structure and/or focused
phenomena
The solution of climate simulation can be obtained by time integration of equations under an appropriate initial
condition. During the time integration, information exchange (data exchange) is required because each physical
process is essentially interactive. On the other hand, each model component has its own grid space and time step
corresponding to the process the component expresses. For example, typical resolution of the ocean model is finner
than the resolution of atmospheric model because typical vortex scale in the ocean is about 1/10 compared with that
in the atmosphere. Therefore, it is necessary to give an appropriate interpolation calculation that compensates for the
diﬀerence of grid system and/or satisfies quantitative consistency to the inter-process data exchange during the time
integration.
Moreover, the model might have its own program structure because it is often developed by researchers and/or
research laboratories in each field individually.
For these reasons, the calculation that compensates the diﬀerence of spatial and temporal resolution, grid system
and program structure is indispensable for information exchange between components. It is improper (in view of
development eﬃciency or interface uniformity) that an individual researcher implements the program used for the
information exchange, and thus, developing the proprietary software and coupling every components through this
software should be preferable. The software that carries out such a function is called a coupler. From the viewpoint mentioned above, several coupler development projects are on going, such as CCSM (Community Climate
System Model) Coupler of NCAR[2], ESMF (Earth System Modeling Framework) project[3] in USA and PRISM
(Programme for Integrated Earth System Modeling) project[4][5] in EU.
In Japan, Scup has been developed by JMA/MRI and applied to JMA/MRI ESM[6], and, another new coupler
development program is on going as a part of Innovative Program of Climate Change projection for the 21st century
(KAKUSHIN program) launched in 2007. The purpose of this program is to develop a more general and standard
coupler based upon experience of development and an architecture of Scup. This coupler is called Jcup. The feature of
Jcup and its performance on atmosphere-ocean coupling are reported in [7]. In that study, elapse time for interpolation
calculation using Jcup was shortened to negligible level compared with original interpolation code (Table.2). And in
the reference [8], performance evaluation of atmosphere-aerosol model coupling have been reported.
In this article, algorithm and implementation of data exchange process especially multi-component data exchange
case will be discussed.

Table 2: Elapse time for interpolation (sec)

original
coupler
Atm. • •Ocean Ocean • •Atm. Atm. • •Ocean Ocean • •Atm.
49.49
23.34
0.683
0.067

1518

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

2. Desing concept of Jcup
2.1. Execution pattern of a coupler
The execution of a coupler has two patterns.
1. A coupler is executed as an independent task
2. A coupler is executed as a part of model task
The advantage of first pattern is flexibility of data exchange between components. When a coupler task is independent, the coupler task can probe the data exchange request from components at any time. So, each component can
send data exchange request to the coupler and exchange data at an arbitrary timing. On the other hand, first pattern
has a disadvantage of low execution eﬃciency. Though the function of a coupler is data exchange and interpolation,
the amount of operation for interpolation is generally smaller than that for physical process calculation, and, when
the coupler task is independent from model task, the coupler will spend the most of execution time for waiting for
requests of data exchange from model tasks.
The advantage and disadvantage of second pattern is reverse to first pattern. With second pattern, a coupler component is included in the task in which the physical process components are executed, therefore, without load-imbalance,
large decrease of execution eﬃciency is avoidable. On the other hand, synchronization is necessary between send component and receive component when data is transmitted. Scup and Jcup employed second execution pattern because
of the high execution eﬃciency. The theme of this article is to discuss what design is eﬀective for multi-component
data exchange and how the coupler program was implemented under the condition of this execution pattern.
2.2. Communication pattern for data exchange
Simplicity, flexibility and eﬃciency are general benchmarks for software development. In the case of a coupler,
simplicity of the interface and flexibility in use are important because there is less calculation in a coupler that influences on eﬃciency. In this section, simplicity and flexibility of data exchange program are discussed. Hereinafter,
following two preconditions are set for discussion.
1. Only MPI is used for data exchange
2. MPI is limited to MPI-1 level, and the remote memory access of MPI-2 is not used
To discuss the design and the implementation of data exchange program, the function necessary for data exchange
is considered step-by-step from destination to source.
• Data Acquisition
A component uses a coupler because its calculation needs data calculated by another component. Therefore,
acquisition of data from another component is the most basic, indispensable function of a coupler. Data acquisition should be possible at an arbitrary point in the program because the place where acquired data is used for
is variant according to the calculation algorithm and program structure of an individual component.
• Data conversion
To match the grid shape, the number of grid points and the unit system etc. to the destination component, data
conversion calculation is needed. The conversion calculation algorithm is diﬀerent depending on the physical
processes and/or required accuracy.
• Data redistribution
It is a precondition for the system design that both source component and destination component are parallelized
by domain decomposition. It is general that the domain decomposition pattern and decomposed domain position
is diﬀerent between source and destination component, so redistribution of data is necessary for the conversion
calculation.
• Data provision
An algorithm and a program structure of each component are not be able to be generalized. Therefore, both
variable name and position in the program must be specified explicitly to identify the data required by other
components.

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

1519

Among these four step operations, data conversion and data redistribution can be processed in the coupler only.
On the other hand, data provision and data acquisition process cannot be hidden in the coupler and some operation
(subroutine call) is necessary in the component code. So, user interface subroutines must be provided at least for these
two processes. Hereafter, these two processes are written as• •data put • ,• •data get • ,•and the interface subroutines
correspond to the operation are written as• •Put data • •and• •Get data • .•
Following two information must be included in interface subroutines Put data and Get data.
• Time of the data
Data put and get are usually performed in a time integration loop, and ΔT of the individual component is
diﬀerent each other. Therefore, when getting data, destination component should clarify what time of the data
of source component is required and, when putting data, source component should clarify the time of the data.
• Name of the data
It is necessary to specify the name of the variable when the data is received and is used in the destination
component, and similarly, the variable name of the data sent in the source component should be specified.
From these conditions, arguments of interface subroutines• •Put data • •and• •Get data • •are as follows.
Put data(time, variable identifier (e.g. variable name), variable)
Get data(time, source component identifier (e.g. component name), source variable identifier, variable)
Among the arguments of Get data, source component identifier and source variable identifier are • •hard-wired • •
informations to the source component, and so, it is unsuitable to write such information directly in the code of destination component from the viewpoint of keeping independence of the component. From this reason, it is better
that only a destination variable identifier is used for Get data argument instead of source component identifier and
source variable identifier and that the coupler searches the source component and the source variable from the destination variable identifier. The relation between source component/variable and destination variable is given from
configuration file. After this modification, the arguments of Put data and Get data are as follow.
Put data(time, source variable identifier, variable)
Get data(time, destination variable identifier, variable)
The argument • •time • •is discussed next. For discussing time setting, it is necessary to consider the following
three aspects.
1. Current time is not change during one time step integration.
2. Put data and Get data can be called two or more times in the time integration loop for two or more variables.
3. Put data and Get data can be called at arbitrary point of the time integration loop.
From these aspects, it is redundant that every Set data and Get data has time information and it is reasonable way
for time setting that a special purpose subroutine (Set time) is made and called at an appropriate place (ordinary at the
beginning of time integration loop).
Based upon this consideration, interface routines of a coupler related to data exchange become as follows.
Set time(current time, ΔT)
Put data(source variable identifier, variable)
Get data(destination variable identifier, variable)
3. Data exchange
3.1. Single component data exchange
Before discussing multi-component data exchange, single component data exchange is discussed.
The simplest way of data exchange by using MPI is point-to-point communication using MPI send and MPI recv
like procedures. Both MPI send in source component and MPI recv in destination component must correspond to each
other, because this type of communication is one-to-one. Meanwhile, as mentioned before, Put data and Get data are

1520

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

premised to be called at arbitrary point in the time integration loop, one-to-one correspondence cannot be assumed.
Therefore, among the interface subroutines, only Set time can call MPI data exchange subroutines such as MPI send
or MPI recv
Data flow from Put data to Get data is as following Figure.1. The data put to the coupler from Component A is
kept in a data buﬀer in the coupler. This data is drawn from the buﬀer and sent to receive component when subroutine
Set time is called. Received data is, after interpolation calculation, kept in a receive buﬀer, and when subroutine
Get data is called, drawn from the buﬀer and passed to the destination component B.

Figure 1: Data flow from Component A to Component B. A red arrow means data transition by MPI.

There are two pattern of data exchange as shown in Figure.2. One is a pattern that two components are executed
concurrently, ant the other is in serial. Figure.2 shows the case that coupling time interval is T , ΔT of Component A is
T/2, ΔT of Component B is T/3. In the case of concurrent execution, data put at T n − T/2 step by Component A is get
at T n step by Component B and data put at T n − T/3 step by component B is gotten at T n step by Component A. In the
case of serial execution, data put at T n − T/3 step by Component B is gotten at T n step by Component A in the same
way of left figure, in contrast, the data get at T n step by Component B is put at T n+1 − T/2 step of Component A. These
execution patterns are controlled by configuration tag ”time lag” in a configuration file as the same as Scup doing.
The destination component gets data at T n − ΔT step when time lag = -1 or at T n+1 − ΔT step when time lag = 1. By
combining time lag setting, specification of two data exchange patterns becomes possible. It should be emphasized
that the concept and categorization of time lag is based upon the design of Scup and that the originality belongs to
Scup developers.

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

1521

Comp.A

Comp.B

Figure 2: Data exchange patterns in single component exchange. The left panel shows the parallel execution case and the right panel shows the
serial execution case.

3.2. Multi-component data exchange
Similar to the single component case, data exchange of multi-component case is performed in the subroutine
Set time. However, diﬀerent from single component case, subroutine Set time must be called by every component
individually because each component has its own ΔT and current time.
In the following section, two cases of multi-component data exchange will be discussed. The one is the case that
each component is included in diﬀerent task (inter-task data exchange) and the other is the case that all components
are included in the same task (intra-task data exchange)
3.2.1. Inter-task data exchange
Figure.3 represents an example of inter-task data exchange. In this figure, two components Atm, Land and Ocn,
Ice are included in Task A and Task B respectively. Subroutine Set time is indicated by yellow rectangles and the
figure represents that each component sets its own time individually. If all of each component tries to exchange data
with all other components, these tasks will come to a deadlock. Because the component Atm must wait for data
from the component Ice, and Ocn must wait for data from Land. This problem arises from the regulation that data
exchange of each component is performed when the subroutine Set time of each component is called. Therefore, such
a situation can be avoided by changing the regulation. This regulation can be defined as follows.
• All the data that should be exchanged at the time T e are exchanged when the subroutine Set time is called at
first.

Task A

Task B

do t1 = 1, N1

do t3 = 1, N1

Atm step

Ocn step

do t2 = 1, N2

do t4 = 1, N2

Land step
end do
end do

Ice step
end do
end do

Figure 3: Inter-task data exchange deadlock occurred. The yellow rectangles show the calls of subroutine Set time.

1522

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

3.2.2. Intra-task data exchange
Data exchange pattern when two components are in the same task can be classified into three types as follows.
1. Two components are nested and each component gets T n − ΔT step data
2. Two components are nested, Get data and Put data are called alternately by outer component and inner component.
3. Two components run in serial.
These patterns are represented in the upper panel, the middle panel and the lower panel of Figure.4 respectively.
Comparing this exchange pattern with inter-task data exchange pattern represented in Figure.2, the upper panel of
Figure.2 corresponds to the left panel and the lower panel corresponds to the right panel respectively.

Figure 4: Data exchange pattern of multi-component execution. The blue rectangles show outer components. The green rectangles show inner
components.

The pattern represented by the middle panel of Figure.4 can be expressed as Figure.5 in the case of inter-task
exchange. As shown in the figure, data is transfered at Put data and Get data without time lag. New time lag setting
corresponds to this exchange pattern is introduced as time lag = 0. Three types of data exchange shown in Figure.4
can be performed seamlessly by these time lag settings without concerning whether components are in the same task
or not.

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

1523

Figure 5: Immediate data exchange pattern of multi-component execution

In the case of non-time lag data exchange, data send and data receive must be performed at the time when Put data
and Get data are called. When the source component and the destination component are in diﬀerent tasks, data
exchange can be easily realized by using MPI subroutines (MPI send and MPI recv) in Put data and Get data respectively. There can be such a situation that data transmission using MPI is required even when both components
are in the same task as shown in the middle panel of Figure.4. Because it can be happen that two components have
diﬀerent grid systems and the destination component might need data that belongs to another processor of the source
component. Then, data flow is as shown in Figure.6. Data is substituted to the buﬀer in Put data. In Get data, 1) data
is drawn from the buﬀer, 2) exchanged by MPI, 3) interpolation calculation performed and 4) the result is passed to
the model.

Figure 6: Data flow of immediate data exchange. A red arrow means data transition by MPI.

3.3. Test coupling
Multi-component coupling is examined by using test models. As listed in Table.3, three tasks, A, B and C are used.
Task A includes component Atm and Lnd, task B includes component Ocn and Ice. Task C has single component
Chm. Communication interval and data exchange type discussed in section3 are listed in Table.4. Data exchange
diagram of this configuration is shown in Figure.7. Atm↔Lnd and Ocn↔Ice are Intra-task communications specified
by italic font in Table.4 and others are Inter-task communications. The type of data exchange is that Ocn↔Ice
is immediate data exchange• •Atm↔Chm is serial data exchange• •others are parallel (concurrent) data exchange.
Though the components Chm and Atm are drown continuously in time in Figure.7, both are waiting for data sent by

1524

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

other component because two components communicate in serial. The coupling was tested several times with diﬀerent
decomposition pattern because three tasks (and components in the task) are parallelized by domain decomposition.
As a result of test coupling, valid data was obtained without depending on the domain decomposition pattern and
it was confirmed that the coupler worked definitely.

Table 3: Tasks and components used for coupling test

Task
A
B
C

Component
Atm
Lnd
Ocn
Ice
Chm

ΔT
60
30
180
30
120

Table 4: Configuration for data exchange test. Italic font means intra-task communication.

Components
Atm ↔ Chm
Atm ↔ Ocn
Atm ↔ Ice
Atm ↔ Lnd
Lnd ↔ Ice
Ocn ↔ Lnd
Ocn ↔ Ice

Exchange type
serial
parallel
parallel
parallel
parallel
parallel
immediate

Interval
120
180
60
60
60
180
180

Figure 7: Data exchange diagram of test models coupling. The dotted lines show Intra-task communications.

Takashi Arakawa et al. / Procedia Computer Science 4 (2011) 1516–1525

1525

4. Concluding remarks
A coupler that can couple some components seamlessly without concerning whether components are in the same
task or not is developed. Current design assumes that a component is • •local • ,•the component is included in single
task only. But now, the computation such that the result is analyzed with all processors concurrently after a diﬀerent
component is executed in a diﬀerent task as shown in Figure.8 has been performed by climate research community.
Next development step is to extend Jcup to be able to carry out coupled computation under the condition that• •local • •
components and• •global • •components are mixed.

Chem N

Chem 3

Chem 2

Chem 1

ᮦᮦᮦᮦ

Analysis
Chem N

Chem 3

Chem 2

Chem 1

ᮦᮦᮦᮦ

Analysis
Figure 8: Example of global component coupling

Acknowledgement
This study was supported by Innovative Program of Climate Change projection for the 21st century, MEXT, Japan.
Reference
[1] J. Shalf, L. Oliker, M. Lijewski, S. Kamil, J. Carter, A. Canning, Petascale Computing, Chapman & Hall/CRC, 2008, Ch. Performance
Characteristics of Potential Petascale Scientific Applications, pp. 1–28.
[2] J. P. Drake, P. W. Jones, G. R. Carr, Overview of the software design of the community climate system model, International Journal of High
Performance Computing Applications, 19 (2005) 177–186.
[3] C. Hill, C. DeLuca, V. Balaji, M. Suarez, A. DaSilva, ESMFJointSpecificationTeam, The architecture of the earth system modeling framework,
Comp in Science and Engineering 6 (2004) 12–28.
[4] S. Valcke, E. Guilyardi, C. Larsson, Prism and enes: A european approach to earth system modelling, Concurrency Computat: Pract Exper 18
(2006) 231–245.
[5] R. Redler, S. Valcke, H. Ritzdorf, Oasis4 - a coupling software for next generation earth system modelling, Geoscientific Model Development
Discussions 2 (2009) 797–843.
[6] H. Yoshimura, S. Yukimoto, Development of a simple coupler (scup) for earth system modeling, Pap Met Geophys 59 (2008) 19–29.
[7] T. Arakawa, H. Yoshimura, Performance evaluation of a coupling software for climate models (in japanese), Jurnal of Information Processing
Society of Japan 2 (2009) 95–110.
[8] T. Arakawa, H. Yoshimura, Coupling of physical processes and its performance evaluation in climate model miroc (in japanese), Transactions
of JSCES 2010 (2010) No.20100006.

