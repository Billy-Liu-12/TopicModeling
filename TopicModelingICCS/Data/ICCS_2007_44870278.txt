An Eﬃcient Quantum-Behaved Particle Swarm
Optimization for Multiprocessor Scheduling
Xiaohong Kong1,2 , Jun Sun1 , Bin Ye1 , and Wenbo Xu1
1

School of Information Technology, Southern Yangtze University,
Wuxi 214122, China
nancykong@hist.edu.cn, sunjun wx@hotmail.com, xwb@sytu.edu.cn
2
Henan Institute Of Science and Technology,
Xinxiang, Henan 453003, China

Abstract. Quantum-behaved particle swarm optimization (QPSO) is
employed to deal with multiprocessor scheduling problem (MSP), which
speeds the convergence and has few parameters to control. We combine
the QPSO search technique with list scheduling to improve the solution
quality in short time. At the same time, we produce the solution based
on the problem-space heuristic. Several benchmark instances are tested
and the experiment results demonstrate much advantage of QPSO to
some other heuristics in search ability and performance.

1

Introduction

Multiprocessor scheduling problem (MSP) is popularly modeled by a weighted
directed acyclic graph (DAG) or micro-dataﬂow graph, and the objective of
MSP is minimizing the parallel completion time or schedule length by properly assigning the nodes of the graph to the processors without violating the
precedence constraints. Generally, the multiprocessor scheduling problem is NPhard[1] except for some cases for which an optimal solution can be obtained in
polynomial time. In the past decades, a myriad of heuristic algorithms have been
investigated[2][3][4][5][6][7][8][9], but the results are constrained by eﬃciency and
complexity. In this paper, the multiprocessor scheduling problem is tackled by
establishing the priority list of tasks utilizing the Quantum-Behaved Particle
Swarm Optimization (QPSO).
A directed acyclic weighted task graph (DAG) is deﬁned by a collection
G = {V, E, C, W },where V = (nj ; j = 1 : v) is the set of task nodes and E
is the set of communication edges. The weight c(ni , nj ) ∈ C corresponds to the
communication cost incurred while the task ni and nj are scheduled, which is
zero if both nodes are assigned on the same processor. The weight w(ni ) ∈ W is
the execution cost of node ni ∈ V . The edge e(i, j) = (ni , nj ) ∈ E represents the
partial order between tasks ni and nj . The target system is commonly assumed
to consist of p processors connected by an interconnection network based on a
certain topology in which a message is transmitted through bidirectional links
with the same speed.
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 278–285, 2007.
c Springer-Verlag Berlin Heidelberg 2007

An Eﬃcient QPSO for Multiprocessor Scheduling

2
2.1

279

Quantum-Behaved Particle Swarm Optimization
The Standard PSO

Particle Swarm Optimization (PSO)[10][11][12], originally proposed by Kennedy
and Eberhart in 1995, is a novel evolutionary algorithm and a swarm intelligence
computation technique. In PSO system, a particle or an individual depicted by
its position vector X and its velocity vector V , is a candidate solution to the
problem. To solve an optimal problem,a population of initialized solutions search
through a multidimensional solution space, and each member continually adjusts
its position and velocity learning its own experience and the experience of other
members. Considering D(d = 1 : D) dimensions as an example, the particles are
manipulated according to the following formula [10][11]:
Vi,d = Vid + c1 ∗ r1 ∗ (Pid − Xid ) + c2 ∗ r2 ∗ (Pgd − Xid )

(1)

Xid = Xid + Vid

(2)

Where c1 and c2 are learning factors, r1 ,r2 are random number uniformly distributed in the range [0, 1]. In equation(1),the vector Pi is the best position (the
position giving the best evaluate value) of particle i , vector Pg is the position
of the best particle among all the particles in the population.
2.2

Quantum-Behaved PSO

In 2004, J. Sun et al. proposed a Delta potential well model of PSO in quantum
time-space framework[13][14]. With the quantum particles,the exact values of
X and V cannot be determined simultaneously, and the quantum state of a
particle is described by wavefunction |ψ(X, t)|. In Quantum-Behaved Particle
Swarm Optimization (QPSO), the particle can only learn the probability of its
2
appearance in position X from probability density function |ψ(X, t)| , the form
of which depends on the potential ﬁeld the particle lies in. The updates of the
particles are accomplished according to the following iterative equations[13][14]:
X(t + 1) = P ± β ∗ |mbest − X(t)| ∗ ln(1/u)
mbest =

1
M

M

Pi = (
i=1

1
M

M

Pi1 ,
i=1

1
M

M

Pi2 , · · · ,
i=1

1
M

P = ϕ ∗ Pid + (1 − ϕ) ∗ Pgd , ϕ = rand()

(3)
M

Pid )

(4)

i=1

(5)

mbest(Mean Best Position) is the mean value of all particles’ best positions Pi , ϕ
and u are a random number distributed uniformly on [0,1] respectively; The only
parameter in QPSO algorithm is β , called Contraction-Expansion Coeﬃcient.
As a new method, QPSO has its advantages such as simple concept, immediate
accessibility for practical applications, simple structure, ease of use, speed to
get the solutions, and robustness, and parallel direct search method. QPSO has
successful application in optimization problem[13][14].

280

3

X. Kong et al.

Multiprocessor Scheduling Based on QPSO

Since 1995, Particle Swarm Optimization has been reported in literature to solve
a range of optimization problem[15][16][17], and scheduling is the new ﬁeld of
PSO algorithm in discrete space. In general, there are two forms of solution representations, namely permutation-based representation and priority-based representation[17][18].
3.1

Particle-Based Solution Representation

For the priority-based form, every dimension d(d = 1 : D) represents the task
index number, and the corresponding value of each element in the vector X
means the priority a node is scheduled to start. We assign a higher priority to
a task with a smaller element value, i.e. each task is scheduled in ascending
order of each element value [18]. Fig.1 illustrates the priority-based solution
representation of target individual with ﬁve dimensions: the 4th element is the
smallest, so the task 4 is scheduled ﬁrstly, and so on.
Priorities vector
Task index
Scheduling list

1.3
1
4

4.5
2
1

3.7
3
5

0.6
4
3

2.3
5
2

Fig. 1. Priority-based solution representation

3.2

Permutation-Based Representation

For the permutation-based form, every dimension d(d = 1 : D) in the vector
means the order or sequence the node is scheduled, and the corresponding value
of each element means a node index number.Used to stand for the index number
of a task, the parameter of each element in the particle represented permutation
should be an integer limited to [1, D]. For example, a permutation of 5 tasks for
a scheduling can be represented as the particle in Fig. 2.
Priorities vector
scheduling sequence
Scheduling list

4
1
4

1
2
1

5
3
5

3
4
3

2
5
2

Fig. 2. Permutation-based solution representation

3.3

QPSO for Multiprocessor Scheduling

When designing the QPSO algorithm, we combine the priority-based QPSO
with list scheduling. The proposed QPSO approach are adopted searching for
optimal combination of the priority values. A ready list preserves the ready tasks
whose parent has ﬁnished. The highest-priority ready task is removed from the
ready list and selected for scheduling during the ﬁrst step. Next, the task list is

An Eﬃcient QPSO for Multiprocessor Scheduling

281

dispatched to processors using the earliest start time rule and satisfy precedence
constraints. In case the earliest time of a task on two machines is the same,
the algorithm breaks the tie by matching and scheduling the task to the ﬁrst
machine in the sequence. Finally, updating the ready task list, until all tasks are
scheduled.
In addition, an initial population is a key factor for the solution quality so we
produce an eﬃcient initial set based on speciﬁc problem. b level and t level are
two general attributes in DAG graph. b level is total cost(including execution
cost and communication cost)from the bottom node to speciﬁed node and t level
is total cost from top node to speciﬁed node[9]. As described above, the ith
element of particle represents priority of a task ni , and the X0i of ﬁrst particle
X0 is a set to the b level of a task ni . Every dimension of the rest of the initial
population is generated by a random perturbation of the values of the ﬁrst
particle as follows:
Xji = X0i + unif orm(t level/2, −t level/2)

(6)

Where X0i is the priority of task ni in the ﬁrst particle,i = (1; · · · ; D);j =
(1; · · · ; N pop − 1); unif orm(t level/2, −t level/2) is a random number generated uniformly between t level/2 and −t level/2. This strategy has a good performance in the PSGA [19]. On the basis of above, the population evolves to
search the optimal solution. After every iteration, we limit the position value
range to interval [b level + t level, b level]. Here, each dimension has a diﬀerent priority value for each task in diﬀerent particles, so each particle guides
the heuristic to generate a diﬀerent schedule in this case. The Proposed QPSO
algorithm for multiprocessor scheduling is depicted in Fig .3.
Initialize the population
Do {
N gen ++
For i=1 to Npop(the particle population number)
β linearly decreases
Find out the mbest of the swarm
Obtain the update priority according to euqation(3)(4)(5)
Find possible permutation
End for
Re-evaluate the Pi and the Pg
While (the termination criterion is not met or generation ¡ Ngen(the generation number)
Output results

Fig. 3. QPSO algorithm for MSP

4

Experimental Results

Firstly, we execute the QPSO and some other list scheduling to a set of random
graphs with diﬀerent parameter, including CCR, density ρ, task number n and
machine number p. Some classical algorithms including HLFET [2], ISH [3], MCP

282

X. Kong et al.

[4], ETF [5] and DLS [6] are also implemented. CCR is deﬁned to be the ration of
the mean communication to the mean computation which represents the weight
of the communication to the whole computation[9]. Edge density ρ is deﬁned as
the number of edges divided by the number of edges of a completely connected
graph with the same number of nodes [20]. There, CCR ∈ {0.1, 0.5, 1.0, 5.0, 10}
n ∈ {20, 40, 60, 80, 100}
p ∈ {2, 4}
ρ ∈ {20, 40, 50, 60, 80}
For every combination (CCR, n, p, ρ),there are 5 graphs, amount to 5(CCR) ×
6(n) × 2(p) × 5(ρ) × 5(graphs) = 1500(graphs) =1500(graphs). In order to evaluate the performance, we normalize the actual scheduling length according to
the following formula(7)[8][9]:
N SL =

SL
w(ni )

(7)

i∈CP

w(ni ) is the sum of computation time of all the CP nodes.
i∈CP

First, we select the graphs (n = 100) with diﬀerent density to investigate the
QPSO and other algorithms. The performance of QPSO algorithm is computed
after 10 runs (5CCR × 5graphs), and the results are depicted in Fig.4. In our algorithm, the parameter β is set changing from 1.2 to 0.5[13][14], which decreased
linearly. From the Fig.4, an apparent conclusion is that more improvement is
achieved for sparse-task graphs, while little enhancement in solution quality is
observed for dense ones. It appears that dense graphs spent more time waiting
for predecessor tasks to complete their execution and transferring data between
related tasks scheduled on diﬀerent processors.
At the same time, we test the performance of graphs with diﬀerent tasks. The
results are depicted in Fig.5. With more tasks, the QPSO has always the comparable performance among these algorithms, which is due to global search ability

QPSO
DLS
ISH
HLFET
MCP
ETF

2.2

the averge NSL

2
1.8
1.6
1.4
1.2
0

20

40
task density

60

80

Fig. 4. The NSL of QPSO and a few algorithms to n=100 with diﬀerent density (p = 2,
N pon = 20, N gen = 30)

An Eﬃcient QPSO for Multiprocessor Scheduling

283

of the QPSO to ﬁnd near-optimal task list and the scalability. It appears that
graphs with increasing tasks spent more time waiting for predecessor tasks to
complete their execution and transferring data between related tasks scheduled
on diﬀerent processors.
2
QPSO
DLS
ISH
HLFET
MCP
ETF

the averge NSL

1.9

1.8

1.7

1.6

1.5
20

40

60
task density

80

100

Fig. 5. The NSL of QPSO and a few algorithms diﬀerent tasks number (p = 4, N pon =
20, N gen = 30)

Finally, benchmark instances from website (http://www.mi.sanu.ac.yu/ tanjad), and the results of a few algorithms, including algorithms CPES, LPTES,
DC, LPTDC, LBMC, PPS are downloaded to test the algorithm. These algorithms are adjusted from other algorithms by T. Davidovic et al [20]. We select
the t200 − 80 instances and investigate how the number of processors aﬀects
the scheduling results. The mean results of QPSO after 10 runs and other algorithms (download from http://www.mi.sanu.ac.yu/ tanjad) are listed as Table.1
and Table.2.
From the above results, in most cases QPSO attains better results than the
other algorithms whether p = 2 or p = 4, but with the increasing of machines,
Table 1. The comparison of results between QPSO and other algorithms to t200-80
instances (p = 2)
instance
t200-80-1
t200-80-2
t200-80-3
t200-80-4
t200-80-5
t200-80-6

CPES
3420
5353
3232
3586
1968
2498

LPTES
3433
5535
3244
3618
1979
2522

DC LPTDC LBMC PPS QPSO
3464 3454
4526 3687 3351
5630 5600
7146 5977 5359
3363 3365
4125 3441 3226
3804 3864
4754 3990 3580
2057 2069
2783 2151 1934
2525 2549
3396 2807 2485

284

X. Kong et al.

Table 2. The comparison of results between QPSO and other algorithms to t200-80
problem (p = 4)
instance
t200-80-1
t200-80-2
t200-80-3
t200-80-4
t200-80-5
t200-80-6

CPES
3414
5345
3232
3586
1968
2489

LPTES
3427
5475
3244
3618
1979
2522

DC LPTDC LBMC PPS QPSO
3464 3453
5245 3875 3343
5630 5581
7583 6225 5332
3363 3365
4276 3413 3226
3800 3684
4791 4040 3568
2057 2069
3065 2705 1934
2525 2549
3850 2995 2478

a little improvement is obtained. We analyze the reason behind the results:
with more machines, more communications among machines are involved, the
scheduling length is not proportional to machines.

5

Summary

As to be seen from the previous results of the performance-testing experiment,
the performance of the Quantum Particle Swarm Optimization method in coping
with scheduling problems is better than some classical algorithms in most cases.
Our future work will focus on hybrid strategies of the QPSO algorithm with
other optimization algorithms.

References
1. M.R. Garey, D.S. Johnson: Computers and Intractability: A Guide to the Theory
of NP-Completeness. W. H. Freeman and Company (1979)
2. T. L. Adam, K. M. Chandy, J. Dickson: A comparison of list scheduling for parallel
processing systems. Communication of the ACM 17 (1974) 685-690
3. B. Kruatrachue and T. G. Lewis: Duplication scheduling heuristic (DSH): A new
precedence task scheduler for parallel processor systems. Technical Report, Oregon
State University, Corvallis, OR 97331, (1987)
4. M.-Y. Wu, D. D. Gajski: Hypercool: a Programming Aid for Message-passing Systems. IEEE Trans. Parallel Distrib. Systems 1 (1990) 330-343
5. J. J. Hwang, Y. C. Chow, F. D. Anger, C. Y. Lee: Scheduling Precedence Graphs in
Systems with Interprocessor Communication Times. SIAM Journal on Computing
18 (1989) 244-257
6. G. C. Sih, E. A. Lee: A Compile-time Scheduling Heuristic for Interconnectionconstrained Heterogeneous Processor Architectures. IEEE Transactions Parallel
and Distrib. Systems 4 (1993) 175-187
7. T. Yang, A. Gerasoulis: DSC: Scheduling Parallel Tasks on an Unbounded Number
of processors. IEEE Transactions on Parallel and Distributed Systems 5 (1994)
951-967
8. Y.K. Kwok, I. Ahmad: A Static Scheduling Algorithm Using Dynamic Critical
Path for Assigning Parallel Algorithms onto Multiprocessors. Proceedings of the
1994 International Conference on Parallel Processing (ICPP’94) 2 (1994) 155-159

An Eﬃcient QPSO for Multiprocessor Scheduling

285

9. Y.K Kwok, I.Ahmad: Benchmarking and Comparison of the Task Graph Scheduling Algorithms. Journal of Parallel and Distributed Computing 59 (1999) 381-422
10. J. Kennedy, R.c. Eberhart: Particle Swarm Optimization. Proc. IEEE Conf. On
Neural Network IV (1995)1942-1948
11. R.C.Eberhart,J. Kennedy : A New Optimizer Using Particles Swarm Theory. Proc.
Sixth Intemational Symposium on Micro Machine and Human Science (1995) 39-43
12. Y. Shi, R.C. Eberhart: Empirical Study of Particle Swarm Optimization. Proc.
Congress on Evolutionary Computation (1999) 1945-1950.
13. J.Sun, B.Feng,W.B. Xu: Particle Swarm Optimization with Particles Having Quantum Behavior. Proc. 2004 Congress on Evolutionary Computation (2004) 325-331
14. J. Sun, W.B. Xu: A Global Search Strategy of Quantum-Behaved Particle Swarm
Optimization. 2004 IEEE Conference on Cybernetics and Intelligent Systems
(2004) 111-116
15. F. van den Bergh, A.P Engelbrecht: Cooperative Learning in Neural Networks using
Particle Swarm Optimizers. South African Computer Journal 26 (2000) 84-90
16. S. C.Esquivel, C. A.Coello: On the Use of Particle Swarm Optimization with Multimodal Functions. Proceedings of IEEE Congress on Evolutionary Computation
2003 (CEC 2003) 1130-1136
17. H. Zhang, X.D.Li, H.Li, F.L. Huang: Particle Swarm Optimization-based Schemes
for Resource-constrained Project Scheduling. Automation in Construction 14
(2005) 393-404
18. M.F.Tasgetiren, Y.C. Liang, M.Sevkli, G. Gencyilmaz: Diﬀerential Evolution Algorithm for Permutation Flowshop Sequencing Problem with Makespan Criterion.
4th Inter-national Symposium on Intelligent Manufacturing Systems (IMS 2004)
19. M. K. Dhodhi, Imtiaz Ahmad, A.Yatama,Ishfaq Ahmad: An Integrated Technique
for Task Matching and Scheduling onto Distributed Heterogeneous Computing
Systems. Journal of Parallel and Distributed Computing 62 (2002) 1338-1361
20. T. Davidovic, T. G. Crainic: Benchmark-problem Instances for Static Scheduling
of Task Graphs with Communication Delays on Homogeneous Multiprocessor Systems. Computers and Operations Research 33 (2006) 2155-2177

