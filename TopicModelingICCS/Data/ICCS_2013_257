Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 1999 – 2007

2013 In
nternational Coonference on Computationa
C
al Science

Dynam
mic Data Driven Applicati
A
ions Systtem conccept for
Inforrmation Fusion
F
b
Erik Blaascha*, Gunaa Seetharam
mana, Kitt Reinhardt
R
a

b

Air Force Reseaarch Laboratory (A
AFRL/RIEA), 525 Brooks Rd., Romee, NY 13441, USA
A
Air Force Researcch Laboratory (AFRL/RY), 2241 Avvionics Cir., WPAF
FB, OH 45433, US
SA

Abstrract
W present a fram
We
mework of Inforrmation Fusion (IF)
(
using the Dynamic
D
Data Driven
D
Applicatioons Systems (DD
DDAS)
conceept. Existing litterature at the intersection off these two toppics supports environmental
e
m
modeling
(e.g., terrain
underrstanding) for coontext enhanced
d applications. Taking
T
advantagee of sensor moddels, statistical methods,
m
and sittuationspeciffic spatio-temporal fusion produ
ucts derived from
m wide area senssor networks, DD
DDAS demonstrrates robust mullti-scale
and multi-resolution
m
g
geographical
terrrain computationns. We highlightt the complemenntary nature of thhese seemingly parallel
approaches and proppose a more inttegrated analytical framework in the context of a cooperativve multimodal sensing
appliccation. In particuular, we use a Wide-Area
W
Motionn Imagery (WAM
MI) application to draw parallelss and contrasts between
b
IF andd DDDAS systeems that warrants an integrated perspective.
p
Thiss elementary woork is aimed at trriggering a sequuence of
deepeer insightful reseearch towards exploiting
e
sparseely sampled pieecewise dense WAMI
W
measurem
ments – an application
wheree the challengess of big-data wiith regards to mathematical
m
fussion relationshipps and high-perfformance compuutations
remain significant annd will persist. Dynamic data-ddriven adaptive computations are
a required to effectively hanndle the
challeenges with expponentially increeasing data vollume for advannced informatioon fusion systeems solutions such
s
as
simulttaneous target trracking and iden
ntification.
© 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Publisshed by Elsevierr B.V.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational
Selectiion and/or peer-revview under respon
nsibility of the orgaanizers of the 20133 International Coonference on Compputational Science
Science
Keywoords: Information Fusion; DDDAS; Cooperaive Sensinng; Wide-Area Mootion Imagery; tarrget tracking; situaation awareness

1. Inttroduction to DDDAS for In
nformation Fu
usion
DD
DDAS is a cooncept where measurementss form a symbbiotic feedbackk control for applications with
w
or
withoout simulation augmentation [1, 2, 3]. As a control system
m, DDDAS dynnamically usess collected dataa to (1)

* Corresponding
C
authhor. Tel.: +1-315-330-2395.
E-m
mail address: erikk.blasch@rl.af.mil..

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.369

2000

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

guide the measurement process and (2) choose among processing methods over a trade space of two or more
interdependent factors. An application operating on sensed data can be thought of as an information fusion
system made popular in the 1980s from the development of the Kalman Filter in the 1960s [4]. Information
fusion, like DDDAS, seeks to reduce uncertainty through filtering past data, estimating current states, and
predicting future needs such as that of simultaneously tracking and identifying a target [5, 6]. Using the
DDDAS concept, current trends include information management, large volume data processing, and system
software over an enterprise for real-world complex systems design [7]. DDDAS as a concept, supports the
advanced systems-level processing needed for complex information fusion systems.
DDDAS since its inception has been applied to numerous areas where complex real-world conditions are not
predetermined by the initialization parameters and initial static data [8, 9, 10]. Three common areas include
environmental modeling, situation awareness, and systems-level applications. DDDAS environmental modeling
includes oceans [11] and wild fires [12, 13]. Other examples include social services such as transportation
[14], emergency medical response [15], and waste distribution [16]. Combining the above applications in a
complex system could facilitate accurate weather prediction for emergency response as demonstrated by the
Engineering Research Center for Collaborative Adaptive Sensing of the Atmosphere (CASA) formed by the
National Science Foundation [17]. These applications for environmental assessment have similar goals of
information fusion stochastic modeling for uncertainty assessment [18]. Even diverse applications such as
cyber situational awareness have been a forum for DDDAS [19] and IF. These applications are similar to data
registration and terrain environmental modeling frequent in the information fusion literature.
With these developments in DDDAS, further research continued to explore these areas while more broadly
applying the DDDAS concept to different applications. Hurricane modeling for weather and climate prediction
[20] and emergency response [21] cross research in information fusion where different events are modeled for
situational awareness. For example, not only sensor data from the weather, but also multi-modal imagery [22].
Multi-modal imagery can be used for information fusion object tracking, classification, and identification that
supports situation assessment, awareness, and understanding.
Enhancements were made to increase the fidelity of DDDAS modeling and simulation for forest fires [23],
civil infrastructure, and traffic management [24]. Systems-level concepts were demonstrated for manufacturing
[25] and supply chain modeling [26]. Finally, by understanding the system level situation, one can predict the
threat and trust in an system [27]. Consistent DDDAS applications in the last decade are tied to systems-level
environmental modeling. Areas of water ecology and infiltration [28, 29, 30] are important for society (e.g.,
health), the military (e.g., protection), and systems response (e.g. logistics). DDDAS continues to be a method
for a modeling a top international health concern of surface water [31] and ground water infiltration [32]. Based
on these developments and successes of DDDAS for environmental and systems-level complex modeling, its
merits consideration in information fusion.
The rationale and potential benefits of DDDAS can enhance information fusion (IF) processes. DDDAS
processes can be driven by batch-level statistical analysis would amortize the temporal variations of observed
wide-sense stationary processes into power-spectral densities or probabilistic networks. DDDAS control
effectively steers computations over a current measurements based on associations extracted from the previous
ones. Such methods are used in practice to effectively allocate computational resources by matching the
expected entropies of localized information content as a function of the multidimensional space that the
observations span. For example, in atmospheric modeling over vast areas, turbulent flows would require high
resolution over small regions, and laminar-flow dominated regions will accept coarser computations without a
noticeable degradation or artifacts. Then, the IF challenge is how to let the data dictate a dynamic assessment of
an effective processing of the observed data. While many classic works have been published on multi-grid
techniques based on batch-mode and model-driven decomposition strategies, the data-driven dynamic
partitioning strategies remain a topic of intense interest in many applications. For example, the diversity of
hard (i.e., physics based video) and soft (i.e., human based text) data may be dynamically available for IF. A

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

2001

human must effortlessly use in such hard-soft data instances that do not always lend themselves for direct
representation by computers. Capturing feature-rich associations are critical to impact overall result, which
need to be represented in a manner that can be easily integrated to steer and catalyze essential inferences.
In this paper, we will consider a spatio-temporal information relations, commonly used in computer vision,
to forecast the wide-area motion image analysis as a DDDAS problem. The diverse applications of DDDAS
show promise, such that insights can be cooperatively gained from merging the benefits of DDDAS and
information fusion such as sensor fusion, social and behavioral modeling, cognitive measurements, and mission
awareness. For example, a merging of data mining [33] as an information fusion technique with that of
DDDAS information management [34] are current trends. Applications include complex systems that are
sometimes difficult to model; however with increased multi-modal sensing, big data cloud techniques, and
enterprise architectures, DDDAS paves the way for information fusion systems management.
Section 2 overviews information fusion cast in terms of DDDAS. Section 3 presents an example of WAMI
integrated multi-modal sensing, processing, and exploitation. Section 4 concludes the paper as a way ahead for
continued exploration of merging DDDAS and information fusion techniques.
2. Information Fusion
Information fusion has been applied to many applications. One commonly accepted model is the Data
Fusion Information Group (DFIG) model [35] (shown in Figure 1) originally developed for military systems,
but adopted by the International Society of Information Fusion (www.isif.org) as a common processing
framework. The levels (L) determine the processing in the system such as L0 data registration, L1 object
tracking and identification assessment [5], L2 situation awareness [36, 37] and L3 impact assessment [38]. The
complementary control levels are: L4 sensor management, L5 user refinement [39], and L6 mission
management. Together, these levels of processing could be represented in an DDDAS framework.

Fig. 1. Data Fusion Information Group Model (L = Level)

2.1. Information fusion as a systems application
As data and sensors measurements become more available, it is important that the models and system
software be scalable, agile, and provide data relevance to user queries. User refinement [40] includes focusing
on the interaction of an operator with a system to achieve mission needs. For example, choosing the correct
sensor mode requires the modeling and adaptation of the systems to deliver the correct information in response
to a query. When the user requests objects information (L1) within a situation (L2); environmental
considerations need to be accounted for such as the time of operation (e.g., day or night), weather conditions
(e.g., clouds), and geographical information (e.g., terrain). By correctly modeling the environmental situation,

2002

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

the correct multimodal visual or infrared sensor (L4) can deliver the optimal response. Inherent in this example
is the fact that DDDAS solutions are needed for accurate environmental modeling to achieve desired objectives
and data-driven dynamic partitioning strategies. To achieve the desired results requires advances in enterprise
architectures (shown in Figure 2) that we contend is afforded by advancements in DDDAS.

Fig. 2. Information Fusion in the Enterprise.

As the information fusion system composes an enterprise, the software needs to be able to provide dynamic
responses. Examples includes tasking sensors on mission platforms [41] for resource coordination. DDDAS is a
control architecture which supports data fusion, performance prediction, and sensor management for target
tracking, recognition, and identification [42]. Accurate statistical modeling of the sensors and the environment
support that objectives are met in a timely and effective manner. One recent example of both information
fusion solutions and DDDAS applications is mission coordination and cooperative sensing for unmanned aerial
vehicles (UAVs) [43]. Also, UAVs can be coordinated with sensors on the ground [44] that require terrain
modeling. Together, DDDAS environmental modeling of the weather for the UAVs and the terrain information
for the ground sensors would aid in the analysis of the complete system.
2.2. DDDAS mapped to the information fusion processing levels
Using our multimodal cooperative sensing example, we are interested in simultaneous target tracking and
identification (STID). Multi-modal measurements could be from infrared, visual, and/or wide-area motion
imagery (WAMI). One recent complex challenge is large data wide-area motion imagery (WAMI) [45]. WAMI
processing with information management supports moving intelligence [46]. Complications of real-time
WAMI sensor processing include a low frame rates [47] and mappings to geospatial intelligence systems [48]
such as environmental (e..g., terrain modeling). Together, DDDAS and IF support enhanced situation
awareness [49] for cooperative control of multimodal sensors as depicted in Figure 3.

Fig. 3. Wide Area Motion Imagery (WAMI) data.

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

Accurate statistical modeling is needed of the environment, sensor, and target data to support the
mathematical algorithms as shown in Table 1. Note that identification includes composing object recognition
and kinematic data for threat assessment of friend, foe, and neutral (FFN) affiliation.
Table 1. Information Fusion Processing Levels as DDDAS measurement, models, and mathematical solutions
Info Fusion / DDDAS Application

Measurement

Model

Algorithm

Level 0 – Data Registration

Pixels

Terrain

Scale-Invariant Feature Transform (SIFT)

Level 1 – Object Assessment

Kinematic/Features

Kinematic/Target

Kalman Filter (KF), Joint-Belief Data
Association Filter (JBDAF)

Level 2 – Situation Assessment

Object Groups

Behavioral

Social Network Analysis (SNA)

Level 3 – Impact Assessment

Threat (FFN)

Intent/Allegiance

(Bomb) Damage Assessment (BDA)

Level 4 – Sensor Management

Look angles

Camera

Affine Transformation

Level 5 – User Refinement

Head-mounted display

Cognitive

Eye Tracker, Fitts’ Law

Level 6 – Mission Management

Objectives

Goal-driven

Reinforcement Learning (RL)

.
3. Application – Interactive Multi-Modal Sensing Processing and Exploitation
There are many attributes which compose an IF system of which we are interested in an integrated
multimodal sensing, processing, and exploitation (IMMSPE) technique. DDDAS is based on applications
modeling, mathematics, and systems software all of which are needed for cooperative sensing. For multimodal
cooperative sensing, there are many issues from which theoretical modeling supports simulations and
measurements. First, with the large amount of motion imagery (i.e., big data problem), there is a need for
cooperative sensing for real-time applications. Second, for meeting user demands, there is a need for
multimodal analysis (i.e., Data to Decision problem). Figure 4 presents our DDDAS architecture that maps to
the information fusion processing levels for Senor, User, and Mission (SUM) management.

Fig. 4. DDDAS Application of Multimodal Cooperative Sensing

On the top in Figure 4, theory aids in supporting tracking and identifying objects for sensor data
management. On the bottom, real-time measurements aid system software and sensor collections for mission

2003

2004

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

management. In the middle, the cooperation of data (including environment, target, and sensor models)
coordinates different multimodal imagery collections for user refinement of data products. For mathematical,
simulation, and software applications, there is a focus on multiscale multimodal approaches. Here multimodal
includes [from left to right] (1) multi-cognition of different users, (2) multi-location of UAVs and ground
platforms collecting full-motion video, and (3) multi-frequency sensors such as WAMI, Infrared, and Visual
imagery. Future considerations include multi-intelligence data (multi-INT) to complement the imagery
(IMINT) such as overhead geographical (GEOINT) terrain and weather modeling. Using this framework for
our DDDAS application, we next briefly describe the mathematical modeling, statistical analysis, and the
systems software for dynamic imagery-based edge detection of static objects.
3.1. WAMI Object Edge Detector (WOED)
Edge detection is one of most fundamental operations in image analysis. In it is simplest form, it detects the
presence of spatial discontinuity. A rich set of operators exist in standard textbooks, to detect, filter, extract and
group edge segments representing lines, contours etc, but data-driven dynamic partitioning strategies are
needed. Suffice it to say that these filters are estimating the existence of an edge from an image data which
include artefacts introduced in the imaging process. The filter results contain latent uncertainties left
unmitigated by these unconstrained optimal estimators. It is worth noting that edges in this context would
originate due to roads, lane-markings, lamp-posts, bill-boards, and buildings in urban imagery shown in Figure
5. Information fusion of contextual knowledge such as geographic directions of a road-segment, or orientation
of a building can thus be used to select among the filters. A class of operators based on Gabor filters extract
edges in an evidence accumulation/validation mode. Such operators select a specific filter from a bank of
filters, each tuned to be highly sensitive to discontinuities along preferred orientation. A more nuanced view
would seek the dynamic range of the a priori orientations including representations to steer these edge
detectors. For example, we define an attractor point as a unique point on the 2D image characterized by the
context-based 3-D direction cosine of the line, perspective imaging geometry, and the exact senor location and
orientation [50].

Fig. 5. WAMI Edge Detection, contextual information such as location, height, and orientation of buildings and
roads can be fused into quantifiable information once the camera position is known.

Image registration is another fundamental operator in image analysis that aligns two or more images in a
information processing task. The simplest manifest is made of two time-separated images of a dynamic scene,
or two stereo images of a static scene observed from distinct relative-directions. Then, by definition, image
registration seeks a one-to-one non-bijective mapping made of maximal (size) simply-connected sets of pixels

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

between the images. When the 3D features underlying such a patch represent a planar surface, the spatial
relation between corresponding connected sets can be characterized as an affine mapping (or homography) for
orthographic and perspective imaging applications [51, 52]. Contextual information such as height, location
and orientation of buildings can be suitably captured and exploited as a priori information to facilitate the
image registration. Registration is a fundamental and essential step to consolidate spatial information across
multiple views, or temporal information across video image sequences. Using both edge detectors and
registration techniques for stochastically varying image collections, DDDAS can support context-based image
retrieval over systems-level analysis and modelling.
3.2. WAMI Context-Based Image Retrieval
In complex scenarios, made up of more than one surface, as is the case for even a vast ground with one
building, each image will be comprised of at least two distinct patches, or four patches, in general. Contrary to
the common view, registration between a pair of WAMI images of a single building in fact involves at least
two distinct homographies and at most four distinct homographies. The challenge is to segment the images,
establish region correspondence, and estimate [51] homographies. Therein lies a data driven portioning of the
data-space, to get past the Rubicon of registration, so that higher-level inferences can be derived. Additionally,
when three or more landmarks are identified [53] in the observed image, the net information can be captured
constrain or mitigate uncertainties in camera orientation measurements as well as the camera-location [54].
For edge detection in the forward direction, there are an infinite number of possibilities, so we are not able
to comprehensively evaluate. However, for the asymmetric case, we can rule out the possibilities through
contextual analysis (e.g. pixel uncertainties due to weather contaminants) to determine the edges. With
advanced DDDAS (modelling) and information fusion (registration), the exploitation of the imagery can
support activity analysis. For example, a car moving on a road gives both the change detection for the car and a
cue as to the road location. The goal of combing DDDAS with information fusion is to use the WAMI camera
model and terrain models (even simulated) from which to quickly extract edges in an image form dynamic
scenes. Using the combined DDDAS-IF methodology, object detection would be quicker that a brute force
method in analysis that is supported by context models, simulations, and mathematical software optimization.
4. Conclusions
Future trends for both DDDAS and information fusion include big data, multi-modal sensing, information
management, and cloud computing. In this paper, we have shown a need for the synergistic developments in
DDDAS and information fusion for Wide-Area Motion Imagery modeling. The benefits so DDDAS inspired
modeling and applications software development complement multimodal cooperative sensing through
environmental modeling. We are exploring DDDAS for a variety of multimodal and multiscale imagery
analysis such as that of airborne multi-intelligence sensing as well as ground based visual [55, 56] and
TeraHertz [57, 58] imagery sensing and advanced image processing in a cloud environment [59].
Acknowledgements
The authors appreciate the discussions and motivation of advancements from DDDAS towards information
fusion solutions from Dr. Frederica Darema. This work was supported by the United States Air Force and thus
free of copyright of the publisher. The views and conclusions contained herein are those of the authors and
should not be interpreted as necessarily representing the official policies or endorsements, either expressed or
implied, of the Air Force.

2005

2006

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]
[24]
[25]
[26]
[27]
[28]

[29]

http://www.dddas.org/
DDDAS Workshop Groups. 2000. Creating a dynamic and symbiotic coupling of application/simulations with
measurements/experiments. NSF DDDAS 2000 Workshop. Available via http://www.nsf.gov/cise/cns/dddas/ [accessed Jan 2013].
Darema, F., 2005. “Grid Computing and Beyond: The Context of Dynamic Data Driven Applications Systems,” Proceedings IEEE,
93(3), p. 692-697.
Waltz, E., Llinas J., Multisensor Data Fusion, Artech House, 1990.
Blasch, E. P., Hong, L., 1998.“Simultaneous Identification and Track Fusion,” IEEE Conf. on Dec. Control.
Blasch, E., Derivation of A Belief Filter for High Range Resolution Radar Simultaneous Target Tracking and Identification, Ph.D.
Dissertation, Wright State University, 1999.
E. Blasch, E. Bosse, and D. A. Lambert, 2012. High-Level Information Fusion Management and Systems Design, Artech House.
Knight, D., 2003. “Data driven design optimization methodology—a dynamic data driven application system,” New York: Springer
Verlag; pp. 329–336.
Darema, F., 2004. “Dynamic Data Driven Applications Systems: A New Paradigm for Application Simulations and Measurements.
Computational Science.” ICCS 2004, Lecture Notes in Computer Science series, 3038, 662–669.
Darema, F., 2005. “Dynamic data driven applications systems: New capabilities for application simulations and measurements,”
Lecture Notes in Computer Science 3515, p. 610–615, 2005.
Patrikalakis, N.M., McCarthy, J. J., Robinson, A. R., et al., 2004. “Towards a Dynamic Data Driven System For Rapid Adaptive
Interdisciplinary Ocean Forecasting,”F. Darema (ed.), Dynamic Data Driven Applications Systems, Kluwer Academic Pub., p. 1-16.
Chen M., et al., 2004.“Dynamic data driven wildfire modeling,” F. Darema (ed.) Dynamic Data Driven Applications Systems. Kluwer
Acadmec Publishers.
Chen M., et al., 2005.“Towards a Dynamic Data Driven Application System for Wildfire Simulation. In V.S. Sunderam et al. (eds.)
Computational Science, Proc. Int’l Conf. on Computational Science (ICCS), Lecture Notes in Computer Science. 3515, p. 632-639.
Fujimoto R. M., Guensler, R. Hunter, M. et. al, 2004.“Dynamic data driven application simulation of surface transportation systems,”
ICCS 2004, Part III, LNCS 3993:425-432. Berlin: Springer-Verlag.
Gaynor M., Seltzer M., Moulton, S., Freedman, J., 2005. “A dynamic, data-driven, decision support system for emergency medical
services,” In Proc. of the Int’l Conf. on Computational Science (ICCS), LNCS 3515, Springer-Verlag, Berlin, p. 703–711.
Parashar, M., Matossian, V., Klie, H., et. al., 2006.“Towards Dynamic Data-Driven Management of the Ruby Golch Waste
Repository,” In Proc. of the Int’l Conf. on Computational Science (ICCS).
Brotzge, J., Droegemeier, K. K., McLaughlin, D. J., 2006. “Collaborative adaptive sensing of the atmosphere (CASA): new radar
system for improving analysis and forecasting of surface weather conditions,” J Transp Res Board, p. 145–151.
Douglas, C. C., Efendiev, Y., Ewing, R., Ginting, V., and Lazarov, R., 2006. “Dynamic Data Driven Simulations in Stochastic
Environments,” Computing, 77(4):321–333.
Mahinthakumar, K., von Laszewski, G., Ranjithan, R., et. al, 2006. “An adaptive cyberinfrastructure for threat management in urban
water distribution systems,” Int’l Conf. on Computational Science (ICCS), LNCS 3993, p. 401–408.
Allen, G., 2007, “Building a Dynamic Data Driven Application System for Hurricane Forecasting,” Int’l Conf. on Computational
Science (ICCS), LNCS, vol. 4487, p. 1034–1041. Springer, Heidelberg.
Madey, G., Barabási, A. L., Chawla, N., Gonzalez, M.., 2007. “Enhanced situational awareness: Application of DDDAS concepts to
emergency and disaster management,” Int’l Conf. on Computational Science (ICCS).
Ononye, A.E., Vodacek, A., and Saber, E., 2007. “Automated extraction of fire line parameters from multispectral infrared images,
Remote Sensing of Environment 108:179-188.
Denham, M., Cortes, A., Margalef, T., Luque, E., 2008. “Applying a Dynamic Data Driven Genetic Algorithm to Improve Forest Fire
Spread Prediction,” M. Bubak et al. (Eds.): ICCS 2008, LNCS 5103, pp. 36–45, Springer-Verlag Berlin Heidelberg.
Huang, Y., and A. Verbraeck, 2009. “A Dynamic Data-Driven Approach For Rail Transport System Simulation,” In Proc. IEEE
Winter Simulation Conference, 2553–2562.
Douglas, C., L.Deng, Efendiev, Y., et al., 2010. “Advantagesof multiscale detection of defective pills during manufacturing,”
HPCA2010, LNCS, vol. 5938, pp. 8-16. Springer-Verlag Berlin Heidelberg.
Celik, N., Lee, S., Vasudevan, K., Son, Y., 2010. DDDAS-based multi-fidelity simulation frameworkfor supply chain systems, IIE
Transaction, 42/5:325-341.
Onolaja, O., Bahsoon, R., Theodoropoulos, G., 2010. “Conceptual framework for dynamic trust monitoring and prediction,” Procedia
Computer Science 1(1), 1241– 1250.
Stonestrom, D.A., Blasch, K.W., 2003. “Determining temperature and thermal properties for heat-based studies ofsurface-water
ground-water interactions,” In Heat as a Tool for Studying the Movement of Ground Water Near Streams, ed. D.A. Stonestrom and J.
Constantz, 73–80. USGS Circular 1260. Reston, Virginia: USGS.
Blasch, K., Ferre, P., Hoffmann, J., Fleming, J. 2006, “Relative contributions of transient and steady-state infiltration fluxes during
ephemeral streamflows,” Water Resour. Res., 42, W08405, doi:10.1029/ 2005WR004049.

Erik Blasch et al. / Procedia Computer Science 18 (2013) 1999 – 2007

2007

[30] Blasch, K., Constantz, J., and Stonestrom, D. A., 2007. “Thermal methods for investigation ground-water recharge,” U.S. Geol. Surv.
Prof. Pap., 1703, 353– 376.
[31] Ouyang, Y., Luo, S. M., Cui, L. H., et al., 2011, “Estimation of real-time N load in surface water using dynamic data-driven
application system,”Ecological Engineering, Elsevier.
[32] Yu, H., Douglas, C. C., Ogden, F. L., 2012. “A new Application of Dynamic Data Drive System in the Talbot-Ogden model for
Groundwater Infiltration,” Procedia Computer Science, Elsevier.
[33] Waltz, E. L. 1998. “Information understanding: integrating data fusion and data mining processes,” Int. Symp on Circuits and
Systems, Vol. 6.
[34] Metzler, J. M., Linderman, M., H., Seversky, L. M., 2009. “N-CET: Network-Centric Exploitation and Tracking,” IEEE Military
Communication (MILCOM) conference.
[35] Blasch, E., Plano, S., 2005. “DFIG Level 5 (User Refinement) issues supporting Situational Assessment Reasoning,” Int. Conf. on
Info Fusion,
[36] Salerno, J., Blasch, E., Hinman, M., Boulware, D., 2005. “Evaluating algorithmic techniques in supporting situation awareness,”
Proc. of SPIE, Vol. 5813.
[37] Blasch, E., Kadar, I., Salerno, J., Kokar, M. M., Das, S., et. al., 2006. “Issues and Challenges in Situation Assessment (Level 2
Fusion),” J. of Adv. in Information Fusion, Vol. 1, No. 2, pp. 122 - 139, Dec.
[38] Shen, D., Chen, G., Blasch, E., and Tadda, G., 2007. “Adaptive Markov Game Theoretic Data Fusion Approach for Cyber Network
Defense,” IEEE Military Communications Conf (MILCOM), Oct.
[39] Blasch, E., 2006. “Level 5 (User Refinement) issues supporting Information Fusion Management” Int. Conf. on Info Fusion.
[40] E. Blasch, et al., 2002. “JDL Level 5 Fusion model ‘user refinement’ issues and applications in group Tracking,” Proc. SPIE, 4729.
[41] Blasch, E., Kadar, I., Hintz, K., et. al., 2008. “Resource Management Coordination with Level 2/3 Fusion Issues and
Challenges,”IEEE Aero. and Elect. Sys. Mag., Vol. 23, No. 3, pp. 32-46, Mar.
[42] Blasch, E., Moses, R., Castanon, D., Willsky, A., Hero, A., 2008. “Integrated Fusion, Performance prediction, and sensor
management for Automatic Target recognition,” Int. Conf. on Info Fusion.
[43] Shen, D., Chen, G., Cruz, J., Blasch, E., 2008. “A game Theoretic Data Fusion Aided Path Planning Approach for Cooperative UAV
Control,” IEEE Aerospace Conf.
[44] Srivasta, A., Wen, Y., Hendrick, E., et. al, 2011, “Information Fusion for Object & Situation Assessment in Sensor Networks,” IEEE
American Control Conf.
[45] Mendoza-Schrock, O, Patrick, J. A., Blasch, E., 2009. ”Video Image Registration Evaluation for a Layered Sensing Environment,”
Proc. IEEE Nat. Aerospace Electronics Conf (NAECON).
[46] Blasch, E., Russell, S., G. Seetharaman, G., 2011. “Joint Data Management for MOVINT Data-to-Decision Making,” Int. Conf. on
Info Fusion.
[47] Ling, H., Wu, Y., Blasch, E., Chen, G., Bai, L., 2011. “Evaluation of Visual Tracking in Extremely Low Frame Rate Wide Area
Motion Imagery,” Int. Conf. on Info Fusion.
[48] Blasch, E., Deignan, P. B. Jr, Dockstader, S. L., et al., 2011. “Contemporary Concerns in Geographical/Geospatial Information
Systems (GIS) Processing,” Proc. IEEE Nat. Aerospace Elec. Conf. (NAECON).
[49] Blasch, E., Seetharaman, G. Palaniappan, K., Ling, H., G. Chen, G., 2012. “Wide-Area Motion Imagery (WAMI) Exploitation Tools
for Enhanced Situation Awareness,” IEEE Applied Imagery Pattern Recognition Workshop.
[50] Seetharaman, G., Bao, H., Shivram, G., 1995. “Calibration of Camera Parameters Using Vanishing Points: Stereo Vision Systems,”
Journal of Franklin Institute, Issue: 331-B, Vol. 5, pp. 555-585, September.
[51] Chou, E. C., Iyengar, S. S., Seetharaman, G., Holyer, R., Lybanon, M., 1998. “Velocity Vectors for Features of Sequential
Oceanographic Images,” IEEE Trans. on Geo-science And Remote Sensing, Vol. 36, No. 3, pp. 985-998, May.
[52] Seetharaman, G., 1994. “Image Sequence Analysis: Three Dimensional Perception of Dynamic Scenes," in Handbook of Computer
Vision and Image Processing, Vol. 2, (Ed.) Tzay Y. Young, Chapter 10, pp. 361-403, Academic Press, San Diego, 1994.
[53] Jhanwar, N., Chaudhuri, S., Seetharaman, G., Zavidovique, B., 2004. “Content Based Image Retrieval Using Motif Co-occurrence
Matrix,” Journal of Image and Vision Computing, Vol. 22, No.14, pp. 1211-1220, Dec.
[54] Seetharaman., G., Le, H., 2006. “Video Assisted GPS for Visual Terrain Navigation using Landmarks," International Journal of
Distributed Sensor Networks, Vol. 2, No. 2, pp. 103-119.
[55] Liu, Z., Blasch, E., Xue, Z., Langaniere, R., Wu, W., 2012. “Objective Assessment of Multiresolution Image Fusion Algorithms for
Context Enhancement in Night Vision: A Comparative Survey,” IEEE Trans. Pattern Analysis and Machine Intel., 34(1):94-109.
[56] Zheng, Y., Dong, W., Blasch, E. 2012. “Qualitative and quantitative comparisons of multispectral night vision colorization
techniques,” Optical Engineering, Vol. 51, Issues 8, Aug.
[57] Blasch, E., Liu, Z., Petkie, D.., Ewing, R., Pomrenke, G., and Reinhardt, K., 2012. “Image Fusion of the Terahertz-Visual NAECON
Grand Challenge Data,” IEEE Nat. Aerospace and Elect. Conf (NAECON).
[58] Gao, J. Chen, Q. Blasch, E., 2012. ”Image denoising in the presence of non-Gaussian power-law noise,” IEEE Nat Aero Conf.
[59] Blasch, E., Chen, Y., Chen, G., Shen, D., Kohler, R., 2013. “Information Fusion in a Cloud-Enabled Environment,” in Choi, B-Y.,
Han, K., Song, S., (Eds.), High Performance Semantic Cloud Auditing, Springer Publishing.

