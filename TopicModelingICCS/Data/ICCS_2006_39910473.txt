Score Evaluation Within the Extended
Square-Root Information Filter
Maria V. Kulikova1 and Innokenti V. Semoushin2
1

2

School of Computational and Applied Mathematics,
University of the Witwatersrand, Private Bag 3, Wits 2050,
Johannesburg, South Africa
mkulikova@cam.wits.ac.za
Ulyanovsk State University, 42 Leo Tolstoy Str., 432970 Ulyanovsk, Russia
i.semushin@ulsu.ru
http://staff.ulsu.ru/semoushin/

Abstract. A newly developed algorithm for evaluating the Log Likelihood Gradient (score) of linear discrete-time dynamic systems is presented, based on the extended Square-Root Information Filter (eSRIF).
The new result can be used for eﬃcient calculations in gradient-search
algorithms for maximum likelihood estimation of the unknown system
parameters. The theoretical results are given with the examples showing the superior perfomance of this computational approach over the
conventional one.

1

Introduction

Consider the discrete-time linear dynamic stochastic system
xt+1 = Ft xt + Gt wt ,
t = 0, 1, . . . , N
t = 1, 2, . . . , N
zt = Ht xt + vt ,

(1)
(2)

with the system state xt ∈ IRn , the state disturbance wt ∈ IRq , the observed
vector zt ∈ IRm , and the measurement error vt ∈ IRm , such that the initial state
x0 and each wt , vt of {wt : t = 0, 1, . . .}, {vt : t = 1, 2, . . .} are taken from
mutually independent Gaussian distributions with the following expectations:
⎧⎡
⎧⎡ ⎤⎫ ⎡ ⎤
⎤⎡
⎤T ⎫ ⎡
⎤
⎪
P0 0 0
x¯0
(x0 − x
¯0 )
¯0 ) ⎪
⎨ (x0 − x
⎬
⎨ x0 ⎬
⎦⎣
⎦
wt
wt
= ⎣ 0 Qt 0 ⎦
E ⎣ wt ⎦ = ⎣ 0 ⎦ , E ⎣
⎪
⎭
⎪
⎩
⎩
⎭
0
0 0 Rt
vt
vt
vt
and E wt wtT = 0, E vt vtT = 0 if t = t . Assume the system is parameterized
by a vector θ ∈ IRp of unknown system parameters. This means that all the above
characteristics, namely Ft , Gt , Ht , x¯0 , P0 ≥ 0, Qt ≥ 0 and Rt > 0, can depend
upon θ (the corresponding notations Ft (θ), Gt (θ) and so on, are suppressed for
the sake of simplicity).
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 473–481, 2006.
c Springer-Verlag Berlin Heidelberg 2006

474

M.V. Kulikova and I.V. Semoushin

Models like (1), (2), together with the associated Kalman ﬁlter, have been
intensively used in many application ﬁelds such as control, communications, and
signal/image processing. To apply the Kalman ﬁlter/smoother in the case of
parametric uncertainty, it is necessary to identify the model, i. e., to estimate
the unknown system parameters (or directly the Kalman ﬁlter/smoother parameters) from the available measurements Z1t = (z1 , z2 , . . . , zt ), t = 1, 2, . . . , N .
A very general and well known approach to parameter estimation is the maximum likelihood (ML) principle. The ML method for estimating θ requires the
maximization of the Log Likelihood Function (LLF) Lθ Z1N , which is the logarithm of the joint probability density of z1 , z2 , . . . , zN , with respect to θ. It
incorporates various gradient-search optimization algorithms. In this context, it
is very important to ﬁnd a means for eﬃcient computation of Log Likelihood
Gradient (LLG) known as the “score”.
The ﬁrst solutions to the problem [1, 2] obtained by the direct diﬀerentiating
the Kalman ﬁltering equations are time consuming as they require the computation of p vector ﬁlter sensitivity equations and p matrix Riccati-type sensitivity
equations, both run recursively in the forward time direction. An alternative approach was developed by Yared [3] who assumed a steady-state Kalman ﬁlter
and used an adjoint ﬁlter, resulting in one additional backward pass in time. It
works faster than the forward “diﬀerentiated” ﬁlter although at the expence of
increased storage requirements. Wilson and Kumar simpliﬁed Yared’s results [4]
by moving from derivatives of Kalman variables to those of the original system
matrices. They reduced the problem to solving a time-invariant matrix equation,
an algebraic Riccati equation, a time-invariant Kalman ﬁlter equation, and the
backward adjopint ﬁlter equation.
Segal and Weinstein developed LLG formulas for both the discrete and continuous-time systems [5, 6] using Fisher’s identity and employing the Kalman
smoother. Their approach enables to compute not only the LLG, but (approximately) the log-likelihood Hessian and the Fisher information matrix of θ as well.
The continuous-time formula in [5] uses the Itˆ
o integral, which cannot be instrumented. For continuous-time case, Leland developed the improved formulas for
the LLG [7, 8] free of this limitation.
Despite this remarkable success it is useful to develop alternative algorithms.
The most important reason is that the previously mentioned methods suﬀer from
some limitations mainly stemming from the use of the conventional Kalman ﬁlter
(KF) implementation. This implementation — in terms of covariance matrices —
is particularly sensitive to roundoﬀ errors [12]. As a consequence, any method for
evaluating the log-likelihood gradient based on the conventional KF implementation, inherits this drawback and so cannot be considered as numerically stable.
The alternative solutions to evaluate the LLG can be found in alternative KF
implementation methods developed for dealing with the problem of numerical
instability in many papers, for example [9, 10, 11], and described in [12].
In this paper we derive a new algorithm for evaluating the LLG based upon the
extended Square-Root Information Filter (eSRIF) recently proposed in [11]. Unlike the Conventional Kalman ﬁlter (CKF), the eSRIF avoids numerical

Score Evaluation Within the Extended Square-Root Information Filter

475

instabilities arising from roundoﬀ errors and has also the added feature of being
better suited to parallel and to very large scale integration (VLSI) implementations (see [11]). Thus, inheriting these advantages, we expect our method to
outperform the conventional KF mechanization for accuracy. These expectations
will be veriﬁed by two examples of ill-conditioned problems.
The paper is organized as follows. In Section 2 we present a new algorithm
for evaluating the LLG based upon the eSRIF. The comparison of the developed
algorithm and the conventional approach in terms of sensitivity to roundoﬀ errors
is given in Section 3. Section 4 presents some numerical results and ﬁnally,
Section 5 concludes the paper.

2

Log Likelihood Gradient Evaluation

The Log Likelihood Function (LLF) of system (1), (2) is given by
Lθ Z1N = −

1
2

N

t=1

m
−1
ln(2π) + ln(det(Re,t )) + eTt Re,t
et
2
def

where Z1N = (z1 , z2 , . . . zN ) is N -step measurement history, et = zt − Ht xˆt is
def

the zero-mean innovation sequence whose covariance is determined as Re,t =
E et eTt = Ht Pt HtT + Rt . The matrix Pt is the error covariance matrix of the
time updated estimate x
ˆt of the state vector generated by the Kalman ﬁlter.
Let lθ (zt ) denote the negative LLF for the t-th measurement zt in system (1),
def

(2), given measurement history Z1t−1 = {z1 , z2 , . . . , zt−1 }, then
lθ (zt ) =

1
2

m
−1
ln(2π) + ln(det(Re,t )) + eTt Re,t
et .
2

(3)
T /2

1/2

From (3) one can easily obtain the expression for the LLG. Let Re,t = Re,t Re,t
1/2

where Re,t is a square-root factor of the matrix Re,t and e¯t are the normalized
−T /2

1/2

innovations, i. e. e¯t = Re,t et . Taking into account that the matrix Re,t is
triangular, we can write down the expression
⎤
⎡
1/2
∂ Re,t
∂
1/2
−1/2
⎦.
ln(det(Re,t )) = tr ⎣Re,t
∂θi
∂θi

(4)

Hence,
⎡
∂l(zt )
−1/2
= tr ⎣Re,t
∂θi

1/2

∂ Re,t
∂θi

as it follows directly from (3) and (4).

⎤
et
⎦ + e¯Tt ∂¯
,
∂θi

i = 1, 2, . . . , p

(5)

476

M.V. Kulikova and I.V. Semoushin

According to the goal pursued by this research and stated in Section 1, we
consider the eSRIF presented in [11]. For convenience, we reformulate it in the
−T /2
−T /2
−T /2
following form: given P0
and P0
xˆ0 = P0
x
¯0 ; calculate
⎡
⎢
Ot ⎢
⎣

−T /2

Rt

0
0

−T /2

−Rt

−T /2

Pt

−T /2

Ht Ft−1 Rt

Ht Ft−1 Gt Qt

−T /2

Ft−1

−Pt

0

T /2

Ft−1 Gt Qt

T /2

−T /2

−Rt

−T /2

Pt

Iq
⎡

−T /2

Re,t

zt

⎤

⎥
x
ˆt ⎥
⎦

0
0

0

−¯
et

⎤

⎥
⎢
−T /2
−T /2
−T /2
=⎢
ˆt+1 ⎥
⎦
⎣ −Pt+1 Kp,t Pt+1 0 Pt+1 x
∗

∗

∗

(6)

∗

where Ot is any orthogonal transformation such that the matrix on the right1/2
hand side of formula (6) is block lower triangular. The matrix Pt is a squareT /2 1/2
1/2
root factor of Pt , i. e. Pt = Pt Pt , Pt
is upper triangular. Similarly, we
T /2 1/2
T /2 1/2
T /2 1/2
T /2 1/2
deﬁne Pt+1 = Pt+1 Pt+1 , Rt = Rt Rt , Qt = Qt Qt and Re,t = Re,t Re,t .
For convenience we shall also write AT /2 = (A1/2 )T , A−1/2 = (A1/2 )−1 and
−1
A−T /2 = (A−1/2 )T . Additionally, Kp,t = Ft Pt HtT Re,t
.
It is easy to see that the LLG (5) in terms of eSRIF (6) is given by
⎤
⎡
−1/2
∂ Re,t
∂¯
et
∂l(zt )
1/2
⎦ +¯
eTt
= − tr ⎣Re,t
,
∂θi
∂θi
∂θi

i = 1, 2, . . . , p .

(7)

To establish our algorithm for eﬃcient evaluation of LLG (7) we prove the
following result.
Lemma 1. Let
QA = L

(8)

where Q is any orthogonal transformation such that the matrix on the righthand side of formula (8) is lower triangular and A is a nonsingular matrix. If
the elements of A are diﬀerentiable functions of a parameter θ then the upper
triangular matrix U in
Qθ QT = U T − U

(9)

is, in fact, the upper triangular part of the matrix QAθ L−1 .
Having applied Lemma 1 to eSRIF (6), we obtain the following algorithm for
computing LLG (7).

Score Evaluation Within the Extended Square-Root Information Filter

477

Algorithm LLG-eSRIF
I. For each θi , i = 1, 2, . . . , p, calculate
⎡
∂
∂
∂
−T /2
(1)
(2)
St
St
⎢ ∂θi Rt
∂θ
∂θ
i
i
⎢
⎢
∂
∂
Ot ⎢
(4)
(5)
St
St
0
⎢
∂θi
∂θi
⎣
0

0

∂
(3)
St
∂θi
∂
(6)
St
∂θi
0

0

⎤

⎡
⎤
⎥
Xi Yi Mi Li
⎥
⎥ ⎢
⎥
⎥ = ⎣ Ni Vi Wi Ki ⎦
⎥
⎦
∗ ∗ ∗ ∗

where Ot is the same orthogonal transformation as in (6) and
(1)

St

(4)

St

−T /2

= −Rt

−T /2

= Pt

−T /2

Ht Ft−1 , St
Ft−1 ,

(2)

= Rt

(5)

= −Pt

St

Ht Ft−1 Gt Qt

T /2

−T /2

Ft−1 Gt Qt

T /2

−T /2

(3)

= −Rt

, St

(6)

, St

−T /2

= Pt

zt ,

x
ˆt .

II. For each θi , i = 1, 2, . . . , p, compute the matrix
⎡
Ji = ⎣

Xi Yi Mi

⎤

⎡

−T /2

Re,t

0

⎢
−T /2
⎦ ⎢ −P −T /2 K
p,t Pt+1
t+1
Ni Vi Wi ⎣
∗
∗

0

⎤−1

⎥
0⎥
⎦

.

∗

III. For each θi , i = 1, 2, . . . , p, we split the matrices Ji obtained at Step II as
follows:
m+n+q

Ji =

L i + Di + Ui

∗∗∗

m+n

m+n

where Li , Di and Ui are the strictly lower triangular, diagonal and strictly
upper triangular parts of matrix Ji , respectively.
IV. For each θi , i = 1, 2, . . . , p, compute the following quantities:
⎡
⎤
−T /2
∂Re,t
0
⎢
⎥
−T /2
Re,t
0
⎢
⎥
∂θi
⎢
⎥ = L i + Di + U T
i
⎢
⎥
−T /2
−T /2
−T /2
⎣ ∂ P˜t+1 Kp,t ∂ P˜ −T /2 ⎦
−P˜t+1 Kp,t P˜t+1
t+1
−
∂θi
∂θi
−T /2

∂Re,t
∂¯
et
=
∂θi
∂θi

T /2

− Xi Re,t e¯t + Yi Ft x
ˆt − Li ,

⎤
⎡
−T /2
(6)
−T /2
∂ P˜t+1 Kp,t
∂St+1
∂ P˜t+1
T /2
=⎣
+ Ni ⎦ Re,t e¯t +
− Vi Ft x
ˆt + Ki .
∂θi
∂θi
∂θi

478

M.V. Kulikova and I.V. Semoushin

Table 1. Comparison of Rounded Solutions to Problem 1 evaluated at the point θ = 1
Filter
Implementation

Solution
Exact Answer
¾
¬

(P1 )θ ¬θ=1 =

“diﬀerentiated”
Conventional
Covariance Filter
 

“diﬀerentiated”
Conventional
Information Filter
Algorithm
eSRIF

LLG-

¡ ¬
¬
P1−1 θ ¬
θ=1

−1/2
P1

¬
¬
¬

θ θ=1

2

Rounded Answer

e
0
1 + e2
0
1
¾

= −

1 + e2
0
e2
0
1

¾

1
= −
2

¿

√

¬

00

r

(P1 )θ ¬θ=1 =
¿

1 + e2
0
e
0
1

¡ ¬
r
¬
P1−1 θ ¬
=
θ=1

 

¿
−1/2
P1

01
¾

−

¬
r
¬
=
¬
θ θ=1

1
0
e2
01
¾

1
−
2

¿

1
0
e
0 1

¿

V. Finally, compute the LLG according to (7).
Remark 1. Since, the matrices in (7) are triangular, only the diagonal elements
−1/2

of

1/2
Re,t

need to be computed. Hence, the Algorithm LLG-eSRIF
∂θi
allows the m × m-matrix inversion of Re,t to be avoided in the evaluation of
LLG.

3

and

∂ Re,t

Ill-Conditioned Example Problems and Comparison

To illustrate and compare the performance of the presented Algorithm LLGeSRIF and the conventional approach, i.e. a straightforward diﬀerentiation of
the KF (“diﬀerentiated” KF), two simple test problems have been constructed.
Problem 1. Given:
P0 =

θ0
, H = 1, 0 , R = e2 θ
0θ

and F = I2 , Q = 0, G = 0, 0

T

where θ is an unknown parameter, I2 is an identity 2 × 2 matrix, 0 < e << 1;
r
to simulate roundoﬀ we assume e + 1 = 1 but e2 + 1 = 1.
Calculate: (P1 )θ at the point θ = 1.
For the θ = 1, this example illustrates the initialization problems that result
when Ht Pt HtT + Rt is rounded to Ht Pt HtT (see, for example, [9]). The exact
r
answer and the rounded answer, using e2 + 1 = 1 in all calculations, are given
for the “diﬀerentiated” CKF, “diﬀerentiated” Conventional Information ﬁlter
(CIF) and the new Algorithm LLG-eSRIF developed in this paper (see Table 1).

Score Evaluation Within the Extended Square-Root Information Filter

479

Table 2. Comparison of Rounded Solutions to Problem 2 evaluated at the point θ = 1
Filter
Implement.

Solution
Exact Answer
¬

(P1 )θ ¬θ=1 =

“diﬀ.”
CKF

 

P1−1

“diﬀ.”
CIF

¡ ¬
¬
¬
θ θ=1

1
2 + e2

1 + e2

1
e2

1 + e2

= −

¾Ö

Algorithm
LLGeSRIF

−1/2

P1

¬
¬
¬

θ θ=1

= −

1
2

−1

1

Rounded Answer
−1
1+e

¬

1
1+e

 

P1−1

2

2 + e2
1
√
1 + e2 e 1 + e2
√
1 + e2
0
e

r

(P1 )θ ¬θ=1 =

2

¡ ¬
r
¬
=
¬
θ θ=1

¿

1 −1

1
2

−1
−

¾√
r

=−

1
2

2
0

1
e2

1
11
11
1
e
1
e

¿

It can be seen that all algorithms except the “diﬀerentiated” CKF give the
nonsingular result. A singular answer will lead to a zero gain if a second measurement of the same type is processed.
Problem 2. Given: same as Problem 1, but H = 1, 1 .
Find: (P1 )θ at the point θ = 1.
The exact solution and the rounded one for Problem 2 are summarized in Table 2.
With this more general type of ill-conditioning, only Algorithm LLG-eSRIF gives
a nonsingular result.

4

Numerical Results

To substantiate the above theoretical result experimentally, we consider the example taken from [10]. Our simulation experiments are broken down into the
following steps. Step 1 is planned to compute the negative LLF; in so doing, we
compare our simulation results with those produced by the Conventional Information Filter (CIF). Step 2 is intended to compute the LLG; in this case, we
compare the result generated by the Algorithm LLG-eSRIF with those produced
by the “diﬀerentiated” CIF.
Example 1. Let the test system (1), (2) be deﬁned as follows:
xt+1 =

1 Δt
0
wt ,
xt +
1
0 e−Δt/τ
zt = 1 0 xt + vt

where τ is a parameter which needs to be estimated.

480

M.V. Kulikova and I.V. Semoushin

500

0.5

498

Gradient of Log Likelihood Function

negatrive Log Likelihood Function

0

496

494

492

490

CIF
eSRIF
(15, 487.62)
(15, 487.62)

488

486

5

10

15

20

25
tau (sec.)

30

35

40

45

−0.5

−1

−1.5

−2

"differentiated" CIF
Algorithm LLG−eSRIF
(15, −0.0045553)
(15, −0.0045553)
5

10

15

20

25
tau (sec.)

30

35

40

45

Fig. 1. The negative LLF and LLG calculated by the Conventional Information Filter, the extended Square-Root Information Filter, the “diﬀerentiated” Conventional
Information Filter and Algorithm LLG-eSRIF, respectively.

The results of Step 1 and Step 2 are shown in Fig. 1. For the test problem,
τ ∗ = 15 was chosen as the true value of parameter τ . As can be seen, all two
algorithms for evaluatinf the LLG produce exactly the same result and give the
same zero point. Besides, it is readily seen that the estimate τˆmin minimizing
the negative LLF coincides with the estimate τˆgrad at which the LLG is zero.
Moreover, all estimates ﬁt the true value of parameter τ , i.e. τ ∗ = 15.

5

Conclusion

In this paper, the new algorithm for evaluating the Log Likelihood Gradient
(score) of linear discrete-time dynamic systems has been developed. The necessary theory has been given and substantiated by the computational experiments.
Two ill-conditioned example problems have been constructed to show the superior perfomance of the Algorithm LLG-eSRIF over the conventional approach.

References
1. G. C. Goodwin and R. L. Payne, Dynamic System Identiﬁcation: Experiment Design and Data Analysis. New York: Academic, 1977.
2. R. L. Goodrich and P. E. Caines, Linear System Identiﬁcation from Non-stationary
Cross-sectional Data, IEEE Trans. Automat. Contr., vol. AC-24, pp. 403–411, June
1979.
3. K. I. Yared, On Maximum Likelihood Identiﬁcation of Linear State Space models,
Mass. Inst. Technol., Cambridge, MA, Rep. LIDS-TH-920, 1979.
4. D. A. Wilson and A. Kumar, Derivative Computations for the Log Likelihood
Function, IEEE Trans. Automat. Contr., vol. AC-27, pp. 230–232, Feb. 1982.
5. M. Segal and E. Weinstein, A New Method for Evaluating the Log-Likelihood
Gradient (Score) of Linear Dynamic Systems, IEEE Trans. Automat. Contr., vol.
AC-33, pp. 763–766, Aug. 1988.

Score Evaluation Within the Extended Square-Root Information Filter

481

6. M. Segal and E. Weinstein, A New Method for Evaluating the Log-Likelihood
Gradient, the Hessian, and the Fischer Information Matrix for Linear Dynamic
Systems, IEEE Trans. Automat. Contr., vol. AC-35, pp. 682–687, May 1989.
7. R. P. Leland, A New Formula for the Log-Likelihood Gradient for Continuous-Time
Stochastic Systems, IEEE Trans. Automat. Contr., vol. AC-40, pp. 1295–1300, July
1995.
8. R. P. Leland, An Improved Log-Likelihood Gradient for Continuous-Time Stochastic Systems with Deterministic Input, IEEE Trans. Automat. Contr., vol. AC-41,
pp. 1207–1210, Aug. 1996.
9. P.G. Kaminski, A.E. Bryson, S.F. Schmidt, Discrete Square Root Filtering: A
survey of Current Techniques. IEEE Trans. on Aut. Cont. V. AC-16.(6), P. 727–
735, 1971.
10. G.J. Bierman, M.R. Belzer, J.S. Vandergraft, D.W. Porter, Maximum likelihood
estimation using square root information ﬁlters. IEEE Trans. on Autom. Contr.
35(12), P. 1293–1298, 1990.
11. P. Park, T. Kailath, New square-root algorithms for Kalman ﬁltering. IEEE Trans.
on Autom. Contr. 40(5), P. 895–899, 1995.
12. M.S. Grewal, A.P. Andrews, Kalman Filtering: Theory and Practice. Prentice-Hall,
Englewood Cliﬀs, New Jersey, 2001.

