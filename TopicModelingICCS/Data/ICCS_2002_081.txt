A Correction Method for Parallel Loop Execution
Volodymyr Beletskyy
Faculty of Computer Science, Technical University of Szczecin, Zolnierska 49 st.,
71-210 Szczecin, Poland,
Bielecki@man.szczecin.pl

Abstract: A new method of parallel loop execution is presented. Firstly, all
the loop iterations are executed in parallel. Then, the ends of pairs of dependent
iterations are re-executed. The method requires no conversion of a source loop
into an equivalent serial-parallel loop, involving iteration indices to be
converted into new ones, that appears to be a typical requirement in the most
known loop paralleling approaches such as unimodular and nonunimodular
linear transformation methods. Possibilities of serial and parallel correction
processes are discussed. Experimental results are considered. As follows from
experiments, applying the method can be reasonable for the loops with a small
fraction of dependent iterations.

1. Introduction and related work
Since parallel and distributed computing have become increasingly popular, it is
significant to develop such compilers that would automatically translate serial
programs into effective parallel code. Such code can be run on several processors of a
parallel computer or on several nodes of a distributed system.
The effective parallel code implies: the possibility to use the large number of
processors ( nodes of a distributed system) as well as minimization of processes
synchronization and the number of messages.
Numerous methods of loop paralleling have been proposed[1]. However, research
in this field is still carried out as the problem of loop paralleling appears extremely
complicated.
A new method of parallel loop execution proposed in this paper aims at
maximizing the number of iterations that can be processed in parallel for the loops
containing the small fraction of dependent iterations. No loop transformations need.
First, all the iterations are executed in parallel. Next, dependent iterations need to be
corrected. The method requires no conversion of a source loop into an equivalent
serial-parallel loop, involving the source iteration indices to be converted into new
ones, that appears to be a typical requirement in the most known loop paralleling
methods such as unimodular and nonunimodular linear transformation approaches[25].
The method is different from the speculative parallel execution[6] in the following:
1) dependence analysis is fulfilled before loop execution; 2) if cross-iteration
dependencies exist, then only the iterations that are the ends of pairs of dependent
iterations are re-executed.

The main objective of the paper is to present a concept of the correction method,
possibilities of its implementation and experimental results.

2. Analysis of Data Dependence
Analysis of data dependencies is considered in lots of papers[7-9]. Below, we
reproduce known knowledge that is necessary to explain a concept of the correction
method.
Consider the following generic nested loop
for
I1 = L1 , U1
for
I 2 = L 2 ( I1 ), U 2 ( I1 )
…
for
I n = L n ( I1 ,…, I n −1 ), U n ( I1 ,…, I n −1 )
H( I1 ,…, I n )
end for
…
end for
end for.
Where I1 ,…, I n are the iteration indices; Li and U i - the lower and upper loop
bounds that are linear functions of the iteration indices I1 ,…, I i −1 , implicitly a stride
of one is assumed; H is the body of the nested loop. I = ( I1 ,…, I n )• is called the
iteration vector.
Definition 1. The set I⊆ Zn such that
I ={ i1 ,…, i n ) | L1 ≤ i1 ≤ U1 ,…, L n ( i1 ,…, i n −1 )≤ i n ≤ U n ( i1 ,…, i n −1 },
is an iteration space.
Individual iterations are denoted by tuples of iteration indices.
The dependence relation between two statements constrains the order in which the
statements may be executed. There are four types of data dependencies: flow, anti,
output, and input dependence. The only true dependence is flow dependence. The
other dependencies are the result of reusing the same location of memory and are
hence called pseudo dependencies. They can be eliminated by renaming variables as
well as by the techniques presented in[6,10,11]. From now on, we suppose that the
loop has only cross-iteration flow dependencies. Additionally, we suppose that the
loop body has no statements of the form: x=…x…
We often need to know all the pairs of iterations that are dependent and the precise
relationship between them, such as the dependence distance vector.
Definition 2. (Dependence Distance Vector) For a pair of iterations i = ( i1 ,…, i n )
and j = ( j1 ,…, j n ) such that j is flow dependent on i , the vector j - i = ( j1 - i1 ,…,
j n – i n )• is called the dependence distance vector.
From now on, we write “dependence vector” instead of “dependence distance
vector”.

3

To find dependence vectors, equations should be built for each pair of the same
named variables ID ( A1 I + B1 ), ID ( A 2 I + B 2 ) that are located in the loop body on
both hands of assignment statements - the right and the left- or on the left sides
only, where A1 , A 2 are matrices; B1 , B 2 are vectors.
The equations mentioned above can be written as follows:
A1 *i - A 2 *j = B 2 - B1 ,
K = j - i,
K  0.

The solution of
form[12]:

(1)

equations (1) , if it exists, can be presented in the following

K = t 11 * V1 + t 12 * V 2 + ... + t 1r * V r + V0 ,
i = t 21 * W1 + t 22 * W 2 + ... + t 2s * W s + W 0 ,
where: V0 , V1 , ..., V r , W 0 , W1 , ..., W s are vectors of dimension n with
constant elements; t lq , t 2 p , q = 1, 2, ..., r; p=1,2,...,s are free variables, values of
which are arbitrary integer numbers, 0 ≤ r, s ≤ n; to find the boundaries of t lq , t 2 p ,
the loop limits should be took into consideration.
Vector i describes all the iterations that form the beginnings of pairs of dependent
iterations, while vector j =i + K describes the ends of those. For a pair of dependent
iterations, a beginning is the iteration that is lexically less. To obtain correct results,
all the dependent iterations have to be executed in lexicographical order.
Let us consider the example :
for i1 = 1, N
for i 2 = 1, N
a ( i1 , i 2 ) = a ( i1 - 1, i 2 - 1) .
Equations (1) for the loop above is as follows:

i1 - j1 = -1,
i 2 - j 2 = -1.

The solution of these equations is: K = (2, 1)•, i = t 1 (1, 0)• + t 2 (0, 1)•, where
t 1 , t 2 are free variables. For the vector j we have
j= i + K = t 1 (1, 0)• + t 2 (0, 1)• + (2, 1)•.
To find the limits of t 1 and t 2 , we build inequalities
(1,1)• ≤ j ≤ (N, N)• or
(1,1)• ≤ t 1 (1, 0)• + t 2 (0, 1)• + (2, 1)• ≤ (N, N)•.
From (2) we have

(2)

1 ≤ t 1 ≤ N-2,
1 ≤ t 2 ≤ N-1 .
The iterations, forming the beginnings of dependent pairs of iterations, are as
follows: (1,1), (1,2), ..., (1,N), (2,1), (2,2), ..., (2,N), ..., (N,1), (N,2), ..., (N,N), i.e the
beginnings of dependent iterations belong to the entire iteration space I.

3. Correction Method
The correction method comprises the two steps described below.
1. All the iterations of a loop are executed in parallel, applying only the old values
of variables (the values before execution of iterations).
2. Given vectors i and K, dependent iterations are determined and the correction of
results for these dependent iterations is executed. The correction means a
procedure of repeating the execution of the ends of all the pairs of dependent
iterations in lexicographical order with regard to new values of variables.
The correction can be executed in various ways:
serially
or parallel,
synchronously or asynchronously, statically or dynamically.
The serial correction means that only one processor fulfils the correction.
The parallel one implies that two or more processors execute the correction
simultaneously.
For the synchronous correction at first, a graph representing all the dependent
iterations is built. Next, the correction for the iterations of the first layer of the graph
is fulfilled, then the correction is executed for the iterations of the second layer and
so on, i.e. consecutive layers are scanned serially while the iterations within each
layer are corrected in parallel. If we can correct the iterations represented by the
graph independently, i.e. without waiting for the finish of the execution of a
particular layer of iterations, then we have the asynchronous correction.
The correction method is considered static if finding dependent iterations and
planning the iterations applied for the correction take place before loop execution,
else the method is considered as dynamic.
Let us consider the following loop:
for i = 3,6
a (i) = a (i - 3) + 1;
and suppose the values of vector elements before loop execution are: a(m) =0,
m=1,2,...,6.
When this loop is executed serially, the following values are obtained: a (3) = 1,
a(4) = 1, a (5) = 1, a (6) = 2.
Now, let us, the correction method is to be applied. After the first step(parallel
execution of all the iterations) we have: a (3) = 1, a (4) = 1, a (5) = 1, and a (6) = 1.
Vectors K and i for the loop considered are as follows: K = 3, i = t 1 +2, 1 ≤ t 1 ≤4.
Here, we have the only pair of dependent iterations with its beginning in iteration 3

5

and its end in iteration 6 (j = i + K = 3 + 3 = 6). It means a single correction is only
required: the result of iteration 6 is calculated using the new value of iteration 3:
A (6) = a (3) + 1 = 1 + 1 = 2.
The results obtained are the same as those obtained at serial loop execution.

4. Serial Correction
Procedures of the serial correction may be built in different manners. When a
loop yields the only pair of vectors i,K, a possible procedure is as follows. From
equations (1), the vectors i, K are found. By means of vector j=i+K, a serial loop is
built that executes the correction. The loop is constructed in such a way that the
iterations yielded with vector j are increased in lexicographical order. The loop,
carrying out the correction, has to execute all iterations yielded with vector j, j∈I.
Let us consider the example:
for i = 1, N
a (6i - 7) = a (2i + 5);
The solution of equations (1) for the loop above is as follows:
i = t*(1) +3,
K = t*(2),
j = i + K = t* (1) + t* (2) + 3,
where: 1 ≤t ≤ N/3 -3.
In this case, the correction loop is as follows:

for t = 1, N/3 - 3
i = t + 2t + 3;
a (6i - 7) = a (2I + 5);
or

t = 1;
while (i = 3t + 3 ≤ N)
a (6i - 7) = a (2i + 5);
t = t + 1;
The example above shows that the correction is required only for every third
iteration and applying the correction method might be advantageous.

5. Parallel Correction
Let us now consider the case when the loop 1) yields many dependence vectors
K1 , K 2 , ..., K n but elements of them are constant; 2) { i1 }=…={ in }= I, i.e. each
iteration is a beginning of a pair of dependent iterations.
To implement parallel dynamic correction in such a case, the following approach
can be applied.
Among the vectors K i , i = 1, ..., n, only such vectors are selected and marked as
T1 , T 2 , ..., T m , m ≤ n that satisfy the condition:
T1

≠ ( t 1 , t 2 ,..., t n )• + t n +1 * K i , T1 ≠ K i , i=1,2,...,n; l=1,2,...,m.

(3)

Where
t 1 , t 2 ,..., t n , t n +1 are free variables, values of which are arbitrary integer
numbers.
All the ends of dependent iterations yielded with vectors K j ≠ T1 , l =1,2,...,m will
be held with a vector T1 satisfied (3) as well since the end of a pair of dependent
iterations (( t 1 , t 2 ,..., t n ), (( t 1 , t 2 ,..., t n )+ K j )) will be reached after t n +1 steps of the
correction procedure started in iteration ( t 1 , t 2 ,..., t n ) with the vector T1 . To execute
dependent iterations in lexicographical order, vectors K j ≠ T1 must be skipped.
Let us consider the following example :

for i = 1, N
a (i) = a (i - 2) + a (i – 3);
Here, dependence vectors are: K1 = 2, K 2 = 3 . Only K1 is the independent vector
since it forms all the ends of dependent iterations as the vector K 2 does, however,
with more number of steps.
Next, all iterations of { J1 } are determined, i.e. the ones to start the correction with.
The set { J1 } contains iterations of layer 1, i.e. the iterations for which the correction
should be executed firstly. The set { J1 } can be described as follows:
{ J1 }={({ I01 + T1 } ∪ { I02 + T 2 } ∪ ... ∪{ I0 n + T n })∩I },
where: I01 , l=1,2,…,n are sets of all iterations that are the beginnings of pairs of
dependent iterations defined with the dependence vector T1 but they are not the ends
of any pair of dependent iterations; { I01 + T1 } means that to each tuple of the set
{ I01 } the tuple T1 is added; ∪, ∩ are the union and intersection sets operations.
The set { I0l } is computed as { I0l } = I ∩ { J 01 }, where J 01 = i0l + K l is the solution
of equations (1) built for a particular dependence l=1,2,...n and defining all the ends
of pairs of dependent iterations.
It should be mentioned here that the sets ( I0l + T1 ), l = 1, 2, ..., m, contain only
single representatives of identical elements. The correction is executed in parallel for
all iterations, belonging to { J1 }.
Farther, we select all the iterations of layer 2 as follows:

7

{ J 2 }={({ J1 + T1 } ∪ { J1 + T 2 } ∪ ... ∪{ J1 + T n })∩I },
All the iterations are executed in parallel for layer 2 and the procedure as above is
repeated for next layer and so on.
The correction procedure above can be described as follows:

{ J1 }={({ I01 + T1 }∪{ I02 + T 2 }∪ ... ∪{ I0 n + T n })∩I }
i=1;
WHILE{ J i }≠nil
PAR L ∈ { J i }
{loop body (L);}
i=i+1;
{ J i } = {({ Ji−1 + T1 } ∪ { Ji−1 + T 2 }∪ ... ∪{ Ji−1 + T n })∩I},
where: the instruction WHILE { J i } ≠ nil means that as long as the set { J i } contains
elements, the loop is executed; PAR L ∈ { J i } means that each iteration L belonging
to the set { J i } can be executed in parallel.
The above loop is only the description of the parallel computation possibility
(pseudo code) but not any explicit programming language code.
The procedure above finds all the ends of dependent iterations. It is clear that
iterations of each layer are independent, while for dependent iterations on consecutive
layers i and i+1, the iterations on layer i are lexicographically less than those on
layer i+1. Since layers are scanned serially at the correction, it is clear that dependent
iterations are executed in lexicographical order. It proves the correctness of the
proposed approach.
Let us consider the loop:
for i1 = 1, N
for i 2 =1, N
a ( i1 , i 2 )=a ( i1 , i 2 –1) + a ( i1 –1, i 2 ) + a ( i1 –1, i 2 –1).
The dependence vectors for the loop above are of the following form: K1 = (0, 1)•,
K 2 = (1, 0)•, K 3 = (1, 1)•. Only vectors K1 and K 2 should be chosen for the
correction since vector K 3 can be written as K 3 = (1, 0)• + K1 . The set { I01 }
equals to the set { I02 } and equals {(1,1)}. The set{{ I01 + T1 } = {(1,2)} and the set
{ I02 + T 2 }={(2,1)}.
The loop applied to execute the correction is as follows:
( J1 } = {(1,2)}∪ {(2,1)}={(1,2), (2,1)}
i=1;
WHILE { J i } ∈ I

PAR L ∈ { J i }
a( i1 , i 2 ) = a( i1 , i 2 -1)+a( i1 -1, i 2 )+ a( i1 -1, i 2 -1);
i=i+1;

{ J i } = {({ Ji−1 +(0,1)}∪{ Ji−1 + (1,0)})∩I }.
The number of correction layers for the loop in the last example equals to 2N - 2. For
N=3, the iterations to be corrected on each layer are as follows:
1. { J1 } = {(1,2), (2,1)}
2. { J 2 } ={ J1 +(0,1)} ∪ { J1 + (1,0)} = {(1,2) +(0,1), (2,1)+ (0,1)}∪{(1,2) +(1,0),
(2,1)+(1,0)} = {(1,3), (2,2)} ∪{(2,2), (3,1)}={(1,3),(2,2),(3,1)}
3. { J3 } ={ J 2 +(0,1)} ∪ { J 2 + (1,0)} = {(1,3) +(0,1), (2,2)+ (0,1),
(3,1)+(0,1)}∪{(1,3) +(1,0), (2,2)+(1,0), (3,1)+(1,0)} = {(1,4), (2,3), (3,2)}
∪{(2,3), ((3,2), (4,1)}={(1,4), (2,3) ,(3,2), (4,1)}.
The set iterations to be corrected on the third layer equals { J3 }∩I = {(2,3), (3,2)}
4. { J 4 } ={ J3 +(0,1)} ∪ { J3 + (1,0)} = {(2,3) +(0,1), (3,2)+ (0,1)}∪{(2,3) +(1,0),
(3,2)+(1,0)} = {(2,4), (3,3)} ∪{(3,3), (4,2)}={(2,4), (3,3), (4,2)}.
The set iterations to be corrected on the fourth layer equals { J 4 }∩I ={(3,3)}

6. Experiments
To evaluate the efficiency of the correction method, several experiments on
Power Challenge supercomputer with three working processors were performed.
The following C loop

For (a1=1;a1<=100;a1++)
{

(3)

T[10*a1] = f(T[a1], t);
T[11*a1] = f(T[a1], t);
T[13*a1] = f(T[a1], t);
}
was executed with different implementations of the correction method, where
f(T[a1], t) is a function with two parameters T[al] and t. The parameter t defines the
time of the execution of each iteration.
The following algorithm for the static serial correction was applied.
Step 1. (Data preparing) For each pair of vectors i, K compute dependent iterations
and insert them in lexicographical order in a container.
Step2. (Correction of the ends of dependent iterations) Execute each iteration from
the container in lexicographic order.
Figure 1 illustrates how speedup depends on the run time of one iteration at the
execution of loop (4) with the algorithm above.

9

6SHHGXS
















7LPHRIRQHLWHUDWLRQPV

Fig.1. Speedup dependence on the run time of one iteration at the execution of loop
(4): 10.000 iterations, 2,6% dependent iterations.
The dynamic correction was implemented in accordance with the approach
presented in Section 5. Figure 2 shows how speedup depends on the run time of one
iteration at applying the dynamic serial and parallel corrections at the execution of
loop(4).The continuos and discontinuous lines in Figure 2 show speedups at the
serial and parallel corrections, correspondingly.



























7LPHRIRQHLWHUDWLRQPV

























VSHHGXS




Fig.2. Speedup dependence on the run time of one iteration at the execution of loop
(4) with the dynamic serial and parallel corrections: 100 iterations, 26% dependent
iterations.
On the base of analysis of the results received, the following conclusions can be
made:
1. As the run time of one iteration increases, speedup increases as well;
2. As the percent of dependent iterations decreases, speedup increases;
3. As the number of loop iterations grows, the speedup grows as well.
It may be expected that if the run time of one iteration is large enough and the
percent of dependent iterations is small, applying the correction method can be
reasonably.

7. Conclusion
The concept of the correction method, enabling the parallel loop execution was
presented. The method involves two steps: the first step provides the parallel
execution of all the iterations of a loop while the other step fulfils the correction of the
ends of pairs of dependent loop iterations.
Further research on the correction method needs. The main work to be done is as
follows: determining a scope of effective applying the method; developing
algorithms of the method implementation for different approaches: static/dynamic,
serial/parallel, synchronous/asynchronous; comparing the correction method with
other known loop paralleling techniques; combining the correction method with other
loop paralleling approaches; program implementation of different techniques of the
method; examination of the method by means of standard benchmarks and different
general-purpose applications.

8. References
1. Bacon, D., Graham S., Sharp O.: Compiler transformation for high – performance
computing. Computing Surveys, 26 (4) (December, 1994) 345-420
2. Lim A.W., Lam S.: Maximizing parallelism and minimizing synchronization with affine
transformations. Parallel Computing, 24(3-4) (May, 1998) 445-475
3. Huang C.H., Sadayappan P.: Communication –free hyperplane partitioning of nested loops.
Journal of Parallel and Distributed Computing, 19(2) (October, 1993) 90-102
4. Wolfe M.: High Performance Compilers for Parallel Computing. Addison-Wesley
Publishing Company (1995)
5. Ramanujam J.: Non-singular transformations of nested loops. In Supercomputing 92 (1992)
214-223
6. Rauchwerger L., Padua D.: The privatizing doall test: A run-time technique for doall
loop identification and array privatization. In Proc. Of the 1994 International Conf. On
Supercomputing (July, 1994) 33-43
7. Banerjee U.: Dependence Analysis for Supercomputing. Kluwer Academic Publishers
(1988)
8. Li Z., Yew P., Zhu C.: An efficient data dependence analysis for parallelizing compilers.
IEEE trans. Parallel Distributed Systems, 1(1) (1990) 26-34
9. Wolfe M. Tseng Chau-Wen: The power test for data dependence. IEEE Trans. Parallel
Distributed Systems, 3(5) (1992) 591-601
10. Feautrier P.: Array expansion. Conference proceedings on International conference on
supercomputing, , ACM (1988) 429-441
11. Brandes T.: The Importance of Direct Dependencies for Automatic Parallelization.
Conference proceedings on International conference on supercomputing, ACM (1988) 407417
12. Gregory R.I., Krishnamurthy E.V.: Methods and Applications of Error-Free Computation.
Springer-Verlag (1984)

