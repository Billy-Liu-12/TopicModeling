Multiple Criteria Mathematical Programming
and Data Mining
Yong Shi1,2, Rong Liu1,3, Nian Yan2, and Zhenxing Chen2
1

Research Center on Fictitious Economy and Data Sciences, Chinese Academy of Sciences
100080 Beijing, China
2
College of Information Science and Technology, University of Nebraska at Omaha
Omaha NE 68182, USA
3
School of Mathematical Science, Graduate University of Chinese Academy of Sciences
100049 Beijing, China
liu.rong@163.com, yshi@gucas.ac.cn,
{nyan,zchen}@mail.unomaha.edu

Abstract. Recently, researchers have extensively applied quadratic programming into classification, known as V. Vapnik’s Support Vector Machine, as
well as various applications. However, using optimization techniques to deal
with data separation and data analysis goes back to more than forty years ago.
Since 1998, the authors and their colleagues extended such a research idea into
classification via multiple criteria linear programming (MCLP) and multiple
criteria quadratic programming (MQLP). The purpose of the paper is to share
our research results and promote the research interests in the community of
computational sciences. These methods are different from statistics, decision
tree induction, and neural networks. In this paper, starting from the basics of
Multiple Criteria Linear Programming (MCLP), we further discuss penalized
MCLP Multiple Criteria Quadratic Programming (MCQP), Multiple Criteria
Fuzzy Linear Programming, Multi-Group Multiple Criteria Mathematical
Programming, as well as regression method by Multiple Criteria Linear Programming. A brief summary of applications of Multiple Criteria Mathematical
Programming is also provided.
Keywords: Multi-criteria programming, MCLP, MCQP, data mining, classification, regression, fuzzy programming.

1 Introduction
Recently, researchers have extensively applied quadratic programming into classification, known as V. Vapnik’s Support Vector Machine [1], as well as various applications. However, using optimization techniques to deal with data separation and data
analysis goes back to more than forty years ago. In 1960’s, O.L. Mangasarian’s group
formulated linear programming as a large margin classifier [2]. Later in 1970’s, A.
Charnes and W.W. Cooper initiated Data Envelopment Analysis where a fractional
programming is used to evaluate decision making units, which is economic representative data in a given training dataset [3]. From 1980’s to 1990’s, F. Glover proposed
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 7–17, 2008.
© Springer-Verlag Berlin Heidelberg 2008

8

Y. Shi et al.

a number of linear programming models to solve discriminant problems with a small
sample size of data [4]. Then, since 1998, the authors and their colleagues extended
such a research idea into classification via multiple criteria linear programming
(MCLP) and multiple criteria quadratic programming (MQLP). These methods are
different from statistics, decision tree induction, and neural networks. The purpose of
the paper is to share our research results and promote the research interests in the
community of computational sciences.
The data mining task which will be investigated in this paper is the classification
or the so-called discriminate analysis in statistical inference. The purpose of classification is to separate data according to some criteria. There are two commonly
used criteria among them. The first one is the overlapping degree with respect to the
discriminate boundary. The lower of this degree the better the classification is.
Another one is the distance from a point to the discriminate boundary. The larger
the sum of these distances the better the classification is. Accordingly, the objective
of a classification is to minimize the sum of the overlapping degree and maximize
the sum of the distances [4]. Note that these two criteria can not be optimized simultaneously because they are contradictory to each other. Fortunately, the multicriteria mathematical programming can be used to overcome this kind of problems
in a systematical way.
It has been thirty years since the first appearance of the multi-criteria linear programming. During these years, the multi-criteria programming has been not only
improved in theoretical foundations but also applied successfully in real world problems. The data mining is such an area where the multi-criteria program has achieved a
great deal. Initialed by Shi et al. [5], the model and ideal of multi-criteria programming have been widely adopted by the researches for classification, regression, etc.
To handle the unbalanced training set problem, Li et al. [6] proposed the penalized
multi-criteria linear programming method. He et al. [7] introduced the fuzzy approach
in the multi-criteria programming to address the uncertainty in criteria of data separation. Using a different norm to measure the overlapping degree and distance, Kou [8]
presented the Multiple Criteria Quadratic Programming for data mining. Kou et al. [9]
proposed Multi-Group Multiple Criteria Mathematical Programming aimed to handle
the multi-group classification. To extend the application of multi-criteria programming, Zhang et al. [10] developed a regressing method based on this technique. Some
important characteristics of these variations of the multi-criteria data mining technique are summarized in Table 1.
In respect of the abundance of the variations of multiple criteria mathematical programming and the diversity of applications, a comprehensive review of related methods would benefit the research in data mining. In this paper, several multi-criteria
linear programming methods in data mining are reviewed and analyzed. The remaining part of the paper is organized as follows. First, we present the basics of Multiple
Criteria Linear Programming (MCLP) (Section 2). Since the training set could be
unbalanced, penalized MCLP method has been proposed to deal with this problem
(Section 3). Furthermore, in order to achieve better classification performance and
stability, Multiple Criteria Quadratic Programming (MCQP) has been developed
(Section 4). Instead of identifying a compromise solution for the separation of data in
MCLP, an alternative Multiple Criteria Fuzzy Linear Programming approach has
also been studied (Section 5). In addition, two-group Multiple Criteria Mathematical

Multiple Criteria Mathematical Programming and Data Mining

9

Table 1. Some Important Characteristics of MCLP (M.1) Variations

MCQP
FMCLP
Multi-group
MCLP
MCLP Reg.

√
√
√
√
√
√
√

√
√

√

√
√
√

√
√
√

√
√

√
√

√

Regression

M.2
M.3
M.5
M.6
M.7
M.9
M.10
M.11

Classification

Multi-group
classification
Unbalance
Constraints
Soft
Constraints
Hard
Constraints
Non-Linear
Objective
Linear
Objective

MCLP
PMCLP

√
√
√
√
√
√
√
√

Programming has been extended to Multi-Group Multiple Criteria Mathematical Programming (Section 6). We also review how to apply MCLP to regression problem
(Section 7). A brief summary of applications of multiple criteria mathematical programming is provided in Section 8. We conclude the paper in Section 9.

2 Multiple Criteria Linear Programming (MCLP)
In linear discriminate analysis, the data separation can be achieved by two opposite
objectives. The first one is to maximize the minimum distances of observations from
the critical value. The second objective separates the observations by minimizing the
sum of the deviations (the overlapping) among the observations [4]. However, it is
theoretically impossible to optimize MMD and MSD simultaneously, the best tradeoff
of two measurements is difficult to find. This shortcoming has been coped with by the
technique of multiple criteria linear programming (MCLP) [5, 11, 12]. The first
MCLP model can be described as follows:
n

∑α

Min

i

i =1
n

Max

∑β
i =1

S. T .

(Model 1)

i

(x i , w ) = b + yi (α i − β i ),

i = 1, K , n

α, β ≥ 0
Here,

αi

is the overlapping and

(x i , w ) = b

βi

the distance from the training sample

x i to the

yi ∈ {1,−1} denotes the label
of x i and n is the number of samples. The weights vector w and the bias b are the
discriminator

(classification boundary).

10

Y. Shi et al.

Fig. 1. The two criteria of classification

unknown variables to be optimized for the two objectives. A visual description of this
model is shown in Fig. 1.
Model 1 is formulized as Multiple Criteria Linear Programming which is difficult
to optimize. In order to facilitate the computation, the compromise solution approach
[5, 13] can be employed to reform the above model so that we can systematically
identify the best trade-off between -Σαi and Σβi for an optimal solution. The “ideal
value” of -Σαi and Σβi are assumed to be α* > 0 and β* > 0 respectively. Then, if Σαi > α*, we define the regret measure as -dα+ = Σαi + α*; otherwise, it is 0. If Σiαi < α*, the regret measure is defined as dα - = α* + Σαi; otherwise, it is 0. Thus, we
have (i) α* + Σαi = dα - – dα +, (ii) |α* + Σαi | = dα - + dα +, and (iii) dα- , dα + ≥ 0.
Similarly, we derive β* – Σβi = dβ - – dβ+, |β* – Σβi | = dβ - + dβ+, and dβ - , dβ+ ≥ 0.
The two-class MCLP model has been gradually evolved as Model 2:

Min d α+ + d α− + d β+ + d β−
n

S. T .

α ∗ + ∑ α i = d α− − d α+
i =1
n

β − ∑ β i = d β− − d β+
∗

(Model 2)

i =1

(xi , w ) = b + yi (α i − βi ),

i = 1,K, n

α, β ≥ 0, d α+ ,d α− ,d β+ ,d β− ≥ 0
Here α* and β* are given, w and b are unrestricted. The geometric meaning of the
model is shown as in Fig. 2.
In order to calculate a large data set, the Linux-based MCLP classification algorithm was developed to implement the above Model 2 (Kou and Shi, 2002).

Multiple Criteria Mathematical Programming and Data Mining

11

Fig. 2. Model 2 and Model 7 formulations

3 Penalized MCLP
Usually, the sample sizes of different groups vary; namely, the training set is unbalanced. To handle this problem with the MCLP model, Li et al. [6] proposed the following penalized MCLP method (Model 3) for credit scoring.

Min d α+ + d α− + d β+ + d β−
S. T .

α∗ + p ×

n2
α i + ∑ α i = d α− − d α+
∑
n1 i∈B
i∈G

β∗ − p×

n2
βi = d β− − d β+
∑ βi − ∑
n1 i∈B
i∈G

(xi , w ) = b + α i − βi ,
(xi , w ) = b − α i + βi ,

(Model 3)

xi ∈ B
xi ∈ G

α, β ≥ 0, d α+ ,d α− ,d β+ ,d β− ≥ 0
Here, “Bad” and “Good” denote different groups,

n1 and n2 are the number of

p ≥ 1 is the penalized parameter.
In this model the distance is balanced on the two sides of b with the parameter n1 / n2 , even there are less “Bad” records on the left of the credit score boundary b . The value of p enhances the effect of “Bad” distance and penalizes much
samples corresponding to the two groups, and

more if we wish more “Bad” records on the left of the boundary.

12

Y. Shi et al.

If n1 = n2 ,

p =1, the model above degenerates to the original MCLP model (Model
1). If n1 < n2 , then exist p ≥ 1 to make “Bad” catching rate of PMCLP higher than
that of MCLP with the same n1 , n2 .

4 Multiple Criteria Quadratic Programming (MCQP)
Based on MCLP, the Multiple Criteria Quadratic Programming is later developed to
achieve better classification performance and stability. The overlapping and distance
are respectively represented by the nonlinear functions f (α ) and g ( β ) . Given
weights

ωα

and ωβ , let

f (α ) =|| α ||p and g ( β ) =|| β ||p , the two criteria basic

Model 1 can be converted into a single criterion general non-linear classification
model (Model 4):

Min ωα || α ||p −ωβ || β ||p
S.T .

(xi , w ) = b + yi (αi − βi ),

i = 1,K, n

(Model 4)

α, β ≥ 0
On the basis of Model 4, non-linear classification models with any norm can be defined theoretically. Let
m

m

i =1

i =1

f (α ) = α T Hα = ∑ α i2 and f ( β ) = β T Qβ = ∑ β i2
where H and Q are predefined as identity matrices. We add the term

1
|| w ||22 into
2

the objective function and formulate a simple quadratic programming with 2-norm as
in Model 5:
n
n
1
|| w ||22 +ωα ∑ αi2 − ωβ ∑ β i2
2
i =1
i =1
S . T . (x i , w ) = b + yi (αi − β i ), i = 1,K, n

Min

(Model 5)

α, β ≥ 0
In order to reduce the number of variables involved in our model and thus simplify
computation. Let ηi = α i − β i . According to our definition, ηi = α i for all misclassified records and

ηi = − β i

for all correctly separated records. To obtain strong

convexity to the objection function, we add

ωb
2

b2 to Model 5’s objective function.

The weight Wb is an arbitrary positive number and ωb

<< ωβ . Model 6 becomes [8]:

Multiple Criteria Mathematical Programming and Data Mining
n
W
ω n
1
|| w ||22 + α ∑ηi2 + ωβ ∑ηi + b b2
2
2 i =1
2
i =1
S . T . (xi , w ) = b + yiηi , i = 1, K, n

13

Min

(Model 6)

η≥0
5 Multiple Criteria Fuzzy Linear Programming
Instead of identifying a compromise solution for the separation of data in MCLP, the
fuzzy approach classifies the data by seeking a fuzzy (satisfying) solution obtained
from a fuzzy linear program (FLP) [7]. Let y1L be MSD and y 2U be MMD, then one
can assume that the value of Maximize Σαi to be

y1U and that of Minimize Σαi to

be y 2 L . The classification problem is equivalent to the following fuzzy linear program (Model 7):

Min ξ
S.T .

ξ≤

∑α

ξ≤

∑β

i

− y1L

y1U − y1L
i

− y2 L

(Model 7)

y2U − y2 L

(x i , w ) = b + yi (αi − βi ),

i = 1,K, n

α, β ≥ 0
Note that Model 7 will produce a value of

ξ

with 0 ≤ ξ

< 1 . To avoid the trivial

solution, one can set up 0 ≤ ε < ξ , for a given ε . Therefore, seeking Maximum ξ
in the FLP approach becomes the standard of determining the classifications between
Good and Bad records in the database. A graphical illustration of this approach can be
seen from Fig. 2, any point of hyper plane 0 < ξ < 1 over the shadow area represents the possible determination of classifications by the FLP method.

6 Multi-group Multiple Criteria Mathematical Programming
The above models are concerned with two groups’ case. Now suppose we have k
groups, G1, G2,…, Gk, are predefined. Gi ∩ G j = Φ, i ≠ j ,1 ≤ i, j ≤ k and

xi ∈ {G1 ∪ G2 ∪ ... ∪ Gk } . A series of boundary scalars b1<b2<…<bk-1, can be
set to separate these k groups. The boundary bj is used to separate Gj and Gj+1.

14

Y. Shi et al.

Let w =

( w1 ,..., wm )T ∈ R m be a vector of real number to be determined. Thus, we

can establish the following linear inequations [14; 8]:
(xi, w) < b1,

∀xi ∈ G1;

(1)

bj-1 ≤ (xi, w) < bj,

∀xi ∈ Gj;

(2)

(xi, w)≥ bk-1,

∀xi ∈ Gk;

(3)

2 ≤ j ≤ k-1, 1≤ i ≤ n.
A mathematical function f can be used to describe the summation of total overlapping while another mathematical function g represents the aggregation of all distances. The final classification accuracies of this multi-group classification problem
depend on simultaneously minimize f and maximize g . Thus, a generalized bicriteria programming method for classification can be formulated as Model 8:

Min

f

Max
S. T .

g
(1), (2), and (3)

(Model

8)

Furthermore, to transform the bi-criteria problems of the generalized model into a
single-criterion problem, weights ωα > 0 and ωζ > 0 are introduced for

f (α ) and g (ζ ) , respectively. The values of ωα and ωζ can be pre-defined in the
process of identifying the optimal solution. As a result, the generalized model can be
converted into a single-criterion mathematical programming model as Model 9:
k

n

Min ωα ¦¦ α i , j
j =1 i =1

S. T .

p

n
§
− ωζ ¨ ¦ ¦ ζ i , j
¨ j =1orj = k i =1
©

(x i , w ) = b j + α i , j − ζ i , j , 1 ≤
(x i , w ) = b j −1 + α i , j −1 − ζ i , j −1 ,

k −1 n

p

− ¦¦
j = 2 i =1

b j − b j −1
2

·
− ζ i, j ¸
¸
p ¹

j ≤ k −1

(4)

2≤ j≤k

(5)

ζ i , j −1 ≤ b j − b j −1 2 ≤ j ≤ k

(6)

ζ i , j ≤ b j +1 − b j 1 ≤ j ≤ k − 1

(7)

Here xi is given, w and bj are unrestricted, and

α i, j , ζ i , j ≥ 0 , 1 ≤ i ≤ n.

(6) and (7) are defined as such due to the fact that the distances from any correctly
classified data (x i ∈ G j , 2 ≤ j ≤ k − 1 ) to two adjunct boundaries bj-1 and bj must
be less than bj - bj-1 . A better separation of two adjunct groups may be achieved by
the following constraints which have stronger limitation on ζ i :
j

Multiple Criteria Mathematical Programming and Data Mining

ζ i, j ≤ (bj

- bj-1 )/2+ε, 2 ≤

ζ i, j ≤ (bj+1

- bj )/2+ε, 1 ≤

15

j≤k

(8)

j ≤ k −1

(9)

ε ∈ ℜ+

is a small positive real number.
Let p = 2, then objective function in Model 1 can now be a quadratic objective and
we have Model 10 as shown below:
k −1 n b − b
n
k
n
⎛
j −1
Min ωα ∑∑ α i , j − ωζ ⎜ ∑ ∑ ζ i , j − ∑∑ j
− ζ i, j
p
p
⎜ j =1orj = k i =1
2
j = 2 i =1
j =1 i =1
⎝
S. T . (4), (5), (8), and (9)

Note that the constant

(

b j − b j −1

2

⎞
⎟
⎟
p⎠

) 2 is omitted from the Model 6 without any ef-

fect to the solution.

7 Regression Method by Multiple Criteria Linear Programming
MCLP can also be applied to regression problem. The data set of the regression problem is T = {( x1 , y1 ), ( x2 , y 2 ), K , ( xn , yn )} , where
T

T

T

xi ∈ R m is the input variable,

yi ∈ R is the output variable, which can be any real number. Define the G and B as
+

−

“Good” and “Bad”, respectively, then the D MCLP and D MCLP data sets for MCLP
regression model are constructed. With these data sets, MCLP regression model can
be written as Model 11 [10]:
n

Min

∑ (α
i =1

S. T .

i

− α i ') − Max

n

∑ (β
i =1

i

− β i ')

xi1w1 + L + xim wm + ( y1 + ε )wm +1 = b − α1 + β1
L
xn1w1 + L + xnm wm + ( yn + ε )wm +1 = b − α n + β n

for all ∈ G

L
xn1w1 + L + xnm wm + ( yn − ε )wm +1 = b + α n '− β n '

for all ∈ B

xi1w1 + L + xim wm + ( y1 − ε )wm +1 = b + α1 '− β1 '

α , α ' , β, β ' ≥ 0
Aggregation of Good samples:
+

D MCLP = {((x i , y i + ε ) , +1) , i = 1, L , l }
T

T

16

Y. Shi et al.

Aggregation of Bad samples:
−

D MCLP = {((x i , y i − ε ) , −1) , i = 1, L , l }
T

T

8 Applications
The multi-criteria data mining techniques reviewed above have yielded fruitful results
in diverse applications. Kou [8] applied the Multiple Criteria Quadratic Programming
to credit card risk analysis and obtained comparable results with some sophisticated
methods. Classification of HIV-1 mediated neuronal dendritic and synaptic damage is
another successful example of the multi-criteria data mining techniques [15]. Kou et
al. [16] introduced this technique to network surveillance and intrusion detection
system. This approach has also been applied to predict firm bankruptcies [17, 18].
Zhang et al. [19] employed the both Multiple-Criteria Linear and Quadratic Programming in VIP e-Mail behavior analysis. In addition to these applications, some of
the models mentioned above have played important roles in building the national
credit scoring system in China as well as an insurance fraud detection system in USA,
in witch tera-bytes of data have been handled for business intelligence.

9 Conclusions
This paper has reviewed various multi-criteria programming data mining models.
These methods are different from statistics, decision tree induction, and neural networks. We have discussed 11 models related to basic Multiple Criteria Linear Programming (MCLP), MCLP Multiple Criteria Quadratic Programming (MCQP), Multiple Criteria
Fuzzy Linear Programming, Multi-Group Multiple Criteria Mathematical Programming, as
well as regression method by Multiple Criteria Linear Programming. These models have

been successfully applied in many real-life applications, such as credit assessment
management, information intrusion, bio-informatics, etc. The purpose of the paper is
to share the research results and promote research interests in the international community of computational sciences.
Acknowledgments. This work was partially supported by National Natural Science
Foundation of China (Grant No. 70621001, 70531040, 70501030, 10601064), National Natural Science Foundation of Beijing (Grant No. 9073020), 973 Project of
Chinese Ministry of Science and Technology (Grant No. 2004CB720103), and BHP
Billiton Cooperation of Australia.

References
1. Cortes, C., Vapnik, V.: Support-vector Network. Machine Learning 20, 273–279 (1995)
2. Mangasarian, O.L.: Linear and Nonlinear Separation of Patterns by Linear Programming.
Operations Research 13, 444–452 (1965)
3. Charnes, A., Cooper, W.W., Rhodes, E.: Measuring the Efficiency of Decision-making
Units. European Journal of Operations Research 3(4), 339 (1979)

Multiple Criteria Mathematical Programming and Data Mining

17

4. Freed, N., Glover, F.: Simple but Powerful Goal Programming Models for Discriminant
Problems. European Journal of Operational Research 7, 44–60 (1981)
5. Shi, Y., Wise, M., Luo, M., Lin, Y.: Data Mining in Credit Card Portfolio Management: A
Multiple Criteria Decision Making Approach. In: Proceedings of International Conference
on Multiple Criteria Decision Making, Ankara, Turkey (2000)
6. Li, A.H., Shi, Y., He, J.: MCLP-based Methods for Improving “Bad” Catching Rate in
Credit Cardholder Behavior Analysis. Applied Soft Computing 8(3), 1259–1265 (2008)
7. He, J., Liu, X., Shi, Y., Xu, W., Yan, N.: Classifications of Credit Cardholder Behavior by
using Fuzzy Linear Programming. International Journal Of Information Technology And
Decision Making 3(4), 633–650 (2004)
8. Kou, G.: Multi-Class Multi-Criteria Mathematical Programming and its Applications in
Large Scale Data Mining Problems, PhD Dissertation, University of Nebraska Omaha
(2006)
9. Kou, G., Liu, X., Peng, Y., Shi, Y., Wise, M., Xu, W.: Multiple Criteria Linear Programming to Data Mining: Models, Algorithm Designs and Software Developments. Optimization Methods and Software 18, 453–473 (2003)
10. Zhang, D.L., Tian, Y.J., Shi, Y.: A Regression Method by Multiple Criteria Linear Programming. In: 19th International Conference on Multiple Criteria Decision Making (2008)
11. Shi, Y.: Multiple Criteria and Multiple Constraint Level Linear Programming: Concepts.
World Scientific Publishing Co., Singapore (2001)
12. Shi, Y., Peng, Y., Xu, W., Tang, X.: Data Mining Via Multiple Criteria Linear Programming: Applications in Credit Card Portfolio Management. International Journal of Information Technology and Decision Making 1, 131–151 (2002)
13. Shi, Y., Yu, P.L.: Goal Setting and Compromise Solutions. In: Karpak, B., Zionts, S. (eds.)
Multiple Criteria Decision Making and Risk Analysis Using Microcomputers, pp. 165–
204. Springer, Berlin (1989)
14. Kou, G., Peng, Y., Shi, Y., Wise, M., Xu, W.: Discovering Credit Cardholders Behavior
by Multiple Criteria Linear Programming. Annals of Operations Research 135(1), 261–274
(2005)
15. Zheng, J., Zhuang, W., Yan, N., Kou, G., Peng, H., McNally, C., Erichsen, D., Cheloha,
A., Herek, S., Shi, C., Shi, Y.: Classification of HIV-1 Mediated Neuronal Dendritic and
Synaptic Damage Using Multiple Criteria Linear Programming. Neuroinformatics 2, 303–
326 (2003)
16. Kou, G., Peng, Y., Yan, N., Shi, Y., Chen, Z., Zhu, Q., Huff, J., McCartney, S.: Network
Intrusion Detection by Using Multiple-Criteria Linear Programming. In: Chen, J. (ed.)
Proceedings of 2004 International Conference on Service Systems and Service Management, Beijing, China, July 19-21, pp. 806–809 (2004)
17. Kwak, W., Shi, Y., Cheh, J.J.: Firm Bankruptcy Prediction Using Multiple Criteria Linear
Programming Data Mining Approach. Advances in Financial Planning and Fore-casting 2,
27–49 (2006)
18. Kwak, W., Shi, Y., Eldridge, S., Kou, G.: Bankruptcy prediction for Japanese firms: using
Multiple Criteria Linear Programming data mining approach. International Journal of
Business Intelligence and Data Mining 1(4), 401–416 (2006)
19. Zhang, P., Zhang, J.L., Shi, Y.: A New Multi-Criteria Quadratic-Programming Linear
Classification Model for VIP E-Mail Analysis. In: Shi, Y., van Albada, G.D., Dongarra, J.,
Sloot, P.M.A. (eds.) ICCS 2007. LNCS, vol. 4488, pp. 499–502. Springer, Heidelberg
(2007)

