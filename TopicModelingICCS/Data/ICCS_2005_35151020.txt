Highly Scalable Algorithms for
Robust String Barcoding
andoiu2 , and A.A. Shvartsman2
B. DasGupta1 , K.M. Konwar2 , I.I. M˘
1

2

Department of Computer Science, University of Illinois at Chicago,
Chicago, IL 60607-7053
dasgupta@cs.uic.edu
Computer Science and Engineering Department, University of Connecticut,
371 Fairfield Rd., Storrs, CT 06269-2155
{kishori, ion, aas}@cse.uconn.edu

Abstract. String barcoding is a recently introduced technique for genomicbased identification of microorganisms. In this paper we describe the engineering of highly scalable algorithms for robust string barcoding. Our
methods enable distinguisher selection based on whole genomic sequences
of hundreds of microorganisms of up to bacterial size on a well-equipped
workstation, and can be easily parallelized to further extend the applicability range to thousands of bacterial size genomes. Experimental
results on both randomly generated and NCBI genomic data show that
whole-genome based selection results in a number of distinguishers nearly
matching the information theoretic lower bounds for the problem.

1

Introduction

String barcoding is a recently introduced technique for genomic-based identiﬁcation of microorganisms such as viruses or bacteria. The basic barcoding problem
[14] is formulated as follows: given the genomic sequences g1 , . . . gn of n microorganisms, ﬁnd a minimum number of strings t1 , . . . , tk distinguishing these
genomic sequences, i.e., having the property that, for every gi = gj , there exists
a string tl which is a substring of gi or gj , but not of both. A closely related
formulation was independently proposed in [3], where it is assumed that it is
possible to detect not just the presence or absence of a distinguisher ti , but also
the number of repetitions of ti as a substring, up to a threshold of R > 0. The
formulation in [14], which we adopt in this paper, corresponds to R = 1.
Identiﬁcation is performed by spotting or synthesizing on a microarray the
Watson-Crick complements of the distinguisher strings t1 , . . . , tk , and then hybridizing to the array the ﬂuorescently labeled DNA extracted from the unknown
microorganism. Under the assumption of perfect hybridization stringency, the
hybridization pattern can be viewed as a string of k zeros and ones, referred to as
the barcode of the microorganism. By construction, the barcodes corresponding
The work of BD was supported in part by NSF grants CCR-0206795, CCR-0208749
and NSF CAREER grant IIS-0346973. The work of KMK and AAS was supported
in part by NSF ITR grant 0121277. The work of IIM was supported in part by a
“Large Grant” from the University of Connecticut’s Research Foundation.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 1020–1028, 2005.
c Springer-Verlag Berlin Heidelberg 2005

Highly Scalable Algorithms for Robust String Barcoding

1021

to the n microorganisms are distinct, and thus the barcode uniquely identiﬁes
any one of them. To improve identiﬁcation robustness, one may also require redundant distinguishability (i.e., at least m diﬀerent distinguishers for every pair
of microorganisms, where m > 1 is some ﬁxed constant) and impose a lower
bound on the edit distance between any pair of selected distinguishers [14].
The algorithms previously proposed for string barcoding are based on integer
programming [14], and on Lagrangian relaxation and simulated annealing [3].
Unfortunately, the run-time of these algorithms does not scale well with the
number of microorganisms and the length of the genomic sequences, e.g., the
largest instance sizes reported in [14] have a total genomic sequence length of
around 100,000 bases.
In this paper we describe the engineering of highly scalable algorithms for
robust string barcoding. Our methods enable distinguisher selection based on
whole genomic sequences of hundreds of microorganisms of up to bacterial size
on a well-equipped workstation, and can be easily parallelized to further extend
the applicability range to thousands of bacterial size genomes. Whole-genome
based selection is beneﬁcial in at least two signiﬁcant ways. First, it simpliﬁes
assay design since the DNA of the unknown pathogen can be ampliﬁed using
inexpensive general-purpose whole-genome ampliﬁcation methods such as specialized forms of degenerate primer multiplex PCR [5] or multiple displacement
ampliﬁcation [9]. Second, whole-genome based selection results in a reduced number of distinguishers, often very close to the information theoretic lower bound
of log2 n .
Our algorithms are based on a simple greedy selection strategy – in every
iteration we pick a substring that distinguishes the largest number of not-yetdistinguished pairs of genomic sequences. This selection strategy is an embodiment of the greedy setcover algorithm (see, e.g., [16]) for a problem instance
with O(n2 ) elements corresponding to the pairs of sequences. Hence, by a classical result of [6, 11, 13], our algorithm guarantees an approximation factor of
2 ln n for the barcoding problem. Very recently, Berman et al. [1] have shown
that no approximation algorithm can guarantee a factor of (1 − ) ln n unless
N P = DT IM E(nlog log n ), and also proposed an information content greedy
heuristic achieving an approximation factor of 1 + ln n. Experimental results
given in Section 4 show that our setcover greedy algorithm produces solutions of
virtually identical quality to those obtained by the information content heuristic.
The setcover greedy algorithm is extremely versatile, and can be easily extended to handle redundancy and minimum edit distance constraints, as well
as other biochemical constraints on individual distinguisher sequences. Furthermore, unlike the information content heuristic of [1], the greedy setcover algorithm can also take into account genomic sequence uncertainties expressed in the
form of degenerate bases. Although degenerate bases are ubiquitous in genomic
databases, previous works have not recognized the need to properly handle them.
For example, experiments in [14] have implicitly treated degenerate bases in the
input genomic sequences as distinct nucleotides; under this approach a substring
of degenerate nucleotides such as NNNNN, might be erroneously selected as a
distinguisher although it encodes for any possible substring of length 5.
To achieve high scalability, our implementation relies on several techniques.
First, we use an incremental algorithm for quickly generating a representative
set of candidate distinguishers and collecting all their occurrences in the given

1022

B. DasGupta et al.

genomic sequences. To reduce the number of candidates, we avoid generating
any substring that appears in all genomic sequences, which typically eliminates
very short candidates. For each genomic sequence, we also generate only one of
the substrings that appear exclusively in that sequence, this optimization eliminates from consideration most candidate distinguishers above a certain length.
Unlike the suﬃx tree method proposed by Rash and Gusﬁeld [14], our approach
may generate multiple candidates that appear in the same set of k genomic sequences (for 1 < k < n). However, the penalty of having to evaluate redundant
candidates in the candidate selection phase is oﬀset in practice by the faster
candidate generation time. Finally, the eﬃcient implementation of the greedy
selection phase of algorithm combines a partition based method for computing
the coverage gain of candidate distinguishers (this method was ﬁrst proposed in
the context of the information content heuristic in [1]) with a “lazy” strategy
for updating coverage gains.
The rest of the paper is organized as follows. In Section 2 we give formal
problem formulations and review previous work. In Section 3 we describe the
eﬃcient implementation of the setcover greedy algorithm for the basic string
barcoding problem. In Section 4 we give experimental results on complete microbial genomic sequences extracted from NCBI databases [7].
We conclude in Section 5 with directions for further research.

2

Preliminaries and Problem Formulation

Let Σ = {a, c, g, t} be the DNA alphabet, and Σ ∗ be the set of string over Σ.
A degenerate base is a non-empty subset of Σ. We identify degenerate bases
of cardinality 1 with the respective non-degenerate bases. Given a DNA string
x = x1 . . . xk ∈ Σ ∗ and a string of degenerate bases y = y1 . . . yn , n ≥ k, we say
that
– x has a perfect match at position i of y iﬀ yi+j−1 = {xj } for every 1 ≤ j ≤ k,
– x has a perfect mismatch at position i of y iﬀ there exists 1 ≤ j ≤ k such
that {xj } ⊆ yi+j−1 , and
– x has an uncertain match at position i of y iﬀ {xj } ⊆ yi+j−1 for every
1 ≤ j ≤ k, but yi+j−1 = {xj } for at least one j.
String x = x1 . . . xk ∈ Σ ∗ distinguishes two sequences of degenerate bases y and
z iﬀ (a) x has a perfect match at one or more positions of y, and has perfect
mismatches at all positions of z, or, symmetrically, (b) x has a perfect match at
one or more positions of z, and has perfect mismatches at all positions of y. The
robust string barcoding problem with degenerate bases is formulated as follows:
Given sequences of degenerate bases g1 , . . . gn and redundancy threshold m, find
a minimum number of strings t1 , . . . , tk ∈ Σ ∗ such that, for every i = j, there
exist m distinct strings tl distinguishing gi and gj .
It is easy to see that, for m = 1, at least log2 n distinguishers are needed
to distinguish any n genomic sequences. However, achieving this lower bound
requires distinguishers that have perfect matches in nearly half of the sequences.
In practice, additional constraints, such as lower bounds on the length of distinguishers, may result in no string having perfect matches in a large number of

Highly Scalable Algorithms for Robust String Barcoding

1023

sequences, and therefore much more than a logarithmic number of distinguishers. The next theorem establishes, under a simple probabilistic model, that there
is an abundance of distinguishers perfectly matching at least a constant fraction
of the input sequences; see [8] for the proof.
Theorem 1. Consider a randomly generated instance of the string barcoding
problem over a ﬁxed alphabet Σ in which there are n strings, each string s =
s0 s1 . . . s −1 is of length exactly generated independently randomly with P r[si =
a] = 1/|Σ| for any i and any a ∈ Σ. Also assume that is suﬃciently large compared to n. Then, for a random string x ∈ Σ ∗ of length O(log ), the expected
number of the input strings which contain x as a substring is pn for some constant 0 < p < 1.
Previous work. The robust string barcoding problem was introduced (for the
case when genomic sequences contain no degenerate bases) by Rash and Gusﬁeld [14]; they provided some experimental results based on integer programming
methods, and left open the exact complexity and approximability of this problem. The problem without redundancy constraints was independently considered
by Borneman et al. [3], who also considered non-binary distinguishability (based
on detecting the multiplicity of a distinguisher as a substring) and a slightly
more general problem in which the objective is to pick a given number of distinguishers maximizing the number of distinguished pairs. The main motivation
for the formulations in [3] comes from minimizing the number of oligonucleotide
probes needed for analyzing populations of ribosomal RNA gene (rDNA) clones
by hybridization experiments on DNA microarrays. Borneman et al. provided
computational results using Lagrangian relaxation and simulated annealing techniques, and noted that the problem is NP-hard assuming that the lengths of the
sequences in the prespeciﬁed set were unrestricted. Very recently, Berman, DasGupta and Kao [1] considered a general framework for test set problems that
captured the string barcoding problem and its variations; their main contribution
is to establish theoretically matching lower and upper bounds on the worst-case
approximation ratio. Cazalis et al. [4] have independently investigated similar
greedy distinguisher selection strategies for string barcoding. Unlike our work,
the algorithms in [4] consider only a small random subset of the possible distinguishers and also prescribe their length in order to achieve practical running
time.

3

Eﬃcient Implementation of the Greedy Setcover
Algorithm

In this section we present the implementation of the setcover greedy algorithm
in the context of the basic string barcoding problem, i.e., we disregard redundancy constraints and the presence of degenerate bases in the input sequences.
Implementation modiﬁcations needed to handle the robust barcoding problem
in its full generality are discussed in [8].
Our implementation of the setcover greedy algorithm has two main phases: a
candidate generation phase and a candidate selection phase. In the candidate generation phase a representative set of candidate distinguishers is generated from
the given genomic sequences. For each generated candidate, we also compute the

1024

B. DasGupta et al.

Input: Set C of candidate distinguishers
Output: Set D of selected distinguishers
D ← ∅; For every c ∈ C, ∆old (c) ← ∞
Repeat
∆∗ ← 0
For every c ∈ C with ∆old (c) > ∆∗ do // Since ∆(c, D) ≤ ∆old (c), c can be
ignored if ∆old (c) ≤ ∆∗
∆old (c) ← ∆(c, D)
If ∆(c, D) > ∆∗ then ∆∗ ← ∆(c, D); c∗ ← c
If ∆∗ > 0 then D ← D ∪ {c∗ }
While ∆∗ > 0
Fig. 1. The greedy candidate selection algorithm

list of sequences with which the candidate has perfect matches; this information
is needed in the candidate selection phase. To reduce the number of candidates,
we avoid generating any substring that appears in all genomic sequences, which
typically eliminates very short candidates. For each genomic sequence, we also
make sure to generate only one of the substrings that appear exclusively in that
sequence, this optimization eliminates from consideration most candidate distinguishers above a certain length. Unlike the suﬃx tree method proposed by Rash
and Gusﬁeld [14], our approach may generate multiple candidates that appear
in the same set of k genomic sequences (for 1 < k < n). However, the penalty
of having to evaluate redundant candidates in the candidate selection phase is
oﬀset in practice by the faster candidate generation time.
Eﬃcient implementation of the above candidate elimination rules is achieved
by generating candidates in increasing order of length and using exact match
positions for candidates of length l − 1 when generating candidates of length
l. For each position p in the input genomic sequences, we also maintain a ﬂag
to indicate whether or not the algorithm should evaluate candidate substrings
starting at p. The possible values for the ﬂag are TRUE (the substring of current
length starting at p is a possible candidate), FALSE (we have already saved the
substring of current length starting at p as a candidate), or DONE (all candidates
containing as preﬁx the substring of current length starting at p are redundant,
i.e., the position can be skipped for all remaining candidate lengths). Initially
all ﬂags are set to TRUE. The FALSE ﬂags are reset to TRUE whenever we
increment the candidate length, however, we never reset DONE ﬂags. For every
candidate length l, candidate evaluation proceeds sequentially over all positions
of the genomic sequences. Whenever we reach a position p whose ﬂag is set to
TRUE, we use the list of matches for the substring of length l−1 starting at p (or
a linear time string matching algorithm if l is the minimum candidate length) to
determine the list of matches for the substring of length l starting at p, and set
the ﬂag to FALSE for all positions where these matches occur. If the substring
of length l starting at p has matches only within the source sequence, and we
have already generated a “unique” candidate for this sequence, we discard the
candidate and set the ﬂag of p to DONE.
A further speed-up technique is to generate candidate distinguishers from
a strict subset of the input sequences. Although this speed-up can potentially
aﬀect solution quality, the results in Section 4 show that the solution quality

Highly Scalable Algorithms for Robust String Barcoding

1025

loss for whole-genome barcoding is minimal, even when we generate candidates
based on a single input sequence, which corresponds to pre-assigning a barcode
of all 1’s to this sequence.
After the set of candidates is generated we select the ﬁnal set of distinguishers in the greedy phase of the algorithm (Figure 1). We start with an empty set
of distinguishers D. While there are pairs of sequences that are not yet distinguished by D, we loop over all candidates and compute for each candidate c the
number ∆(c, D) of pairs of sequences that are distinguished by c but not by D,
then add the candidate c with largest ∆ value to D. Two sequences s and s are
distinguished by a candidate c iﬀ exactly one of s and s appears in the list Pc of
perfect matches of c, which is available from the candidate generation phase. A
simple method for computing ∆ values is to maintain an n×n symmetric matrix
indicating which of the pairs of sequences are already distinguished, and then
to probe the |Pc | · (n − |Pc |) entries in this matrix corresponding to pairs (s, s )
with s ∈ Pc and s ∈
/ Pc when computing ∆(c, D). A more eﬃcient method is
based on maintaining the partition deﬁned on the set of sequences by D. If the
partition deﬁned by D consists of sets S1 , . . . , Sk , then we can compute ∆(c, D)
in O(k + |Pc |) = O(n) time using the observation that
k

|Si ∩ Pc | · |Si \ Pc |

∆(c, D) =

(1)

i=1

In addition to the fast partition based computation, our implementation of the
greedy selection phase uses a lazy strategy for updating the ∆ values, based on
the observation that they are monotonically non-increasing during the algorithm
(see Figure 1).

4

Experimental Results

We performed experiments on both randomly generated instances and whole microbial genomes extracted from the NCBI databases [7]. Due to space constraints
we report here only results obtained by the setcover greedy algorithm on microbial genomes. Experimental results comparing the setcover greedy algorithm, the
information content heuristic in [1], and a recently proposed multi-step rounding
algorithm for set multicover [2] on large number of random testcases are given
in [8].
The results on the NCBI dataset, which consists of a set of 29 complete microbial genomic sequences extracted from [7], are given in Table 1. Sequence
lengths in the set vary between 490 Kbases and 4.75 Mbases, with an average
length of 2.6 Mbases (over 76 Mbases total). The sequences contain a small
number of degenerate bases, 861 bases in total. Therefore, we cannot use the
partition method for computing the number of sequence pairs distinguished by
a candidate in the greedy selection phase, and we have to use the slower matrix
datastructure. In these experiments we varied the redundancy requirement from
1 to 20. To see the eﬀect of length and edit distance requirements on the number of distinguishers, for each redundancy requirement we computed both an
unconstrained solution, and a solution in which distinguishers must have length
between 15 and 40, and there should be a minimum edit distance of 6 between

1026

B. DasGupta et al.

Table 1. Results on a set of 29 NCBI complete microbial genomes. Candidate generation time is approximately 335 seconds for all combinations of parameters. The
experiments were run on a PowerEdge 2600 Linux server with 4 Gb of RAM and dual
2.8 GHz Intel Xeon CPUs – only one of which is used by our sequential algorithms
Redundancy lmin lmax MinEdit Select time #Distinguishers
1
0 ∞
0
14.2
6.0
1
15 40
6
2.6
8.0
5
0 ∞
0
20.3
21.0
5
15 40
6
8.7
31.0
10
0 ∞
0
22.9
41.0
10
15 40
6
16.4
60.0
20
0 ∞
0
26.8
76.0
20
15 40
6
33.4
123.0

every two selected distinguishers (these values are similar to those used in [14].
In all experiments, we generated candidates based only on the shortest sequence
of 490 Kbases.
Results in Table 1 show that, naturally, meeting higher redundancy constraints requires more distinguishers to be selected. Additional length and edit
distance constraints further increase the number of distinguishers, but the latter is still within reasonable limits. The length constraints reduce the number of
candidates (from 1,775,471 to 122,478), which, for low redundancy values has the
eﬀect of reducing greedy selection time. However, for high redundancy requirements the reduction in number of candidates is oﬀset by the increase in solution
size, and greedy selection becomes more time consuming with length and edit
distance than without (selection time grows roughly linearly with solution size).

5

Conclusions

In this paper we have given highly scalable algorithms for the robust string
barcoding problem, and have shown that distinguisher selection based whole
genomic sequences results in a number of distinguishers nearly matching the
information theoretic lower bounds for the problem.
In ongoing work we are exploring heuristics and approximation algorithms
for several extensions of the string barcoding problem. First, we are considering
the use of probe mixtures as distinguishers. With most microarray technologies
it is feasible to spot/synthesize a mixture of oligonucleotides at any given microarray location. The DNA of a pathogen will hybridize to such a location if
it contains at least one substring which is the Watson-Crick complement of one
of the oligonucleotides in the mixture. Using oligonucleotide mixtures as distinguishers can reduce the number of spots on the array – and therefore barcode
length – closer to the information theoretical lower-bound of log2 n. The reduction promises to be particularly signiﬁcant when reliable hybridization requires
relatively long distinguishers; in these cases even the optimum barcoding length
is far from log2 n [14]. A special case of this approach is the use of degenerate distinguishers similar to the degenerate primers that have been recently employed

Highly Scalable Algorithms for Robust String Barcoding

1027

in multiplex PCR ampliﬁcation [12, 15]. Degenerate distinguishers are particularly attractive for string barcoding since their synthesis cost is nearly identical
to the synthesis cost of a single non-degenerate distinguisher (synthesis requires
the same number of steps, the only diﬀerence is that multiple nucleotides must
be added in some of the synthesis steps).
In many practical pathogen identiﬁcation applications collected biological
samples may contain the DNA of multiple pathogens. This issue is considered
to be particularly signiﬁcant in medical diagnosis applications, see, e.g., [10] for
studies in detecting more than one HPV (human papiloma virus) genotype with
varying rate of multiple HPV infections carried by the same HPV carrier. In
future work we plan to develop extensions of the barcoding technique that can
reliably detect multiple pathogens for a given bound on the number of pathogens
present.

References
1. P. Berman, B. DasGupta, and M.-Y. Kao. Tight approximability results for test
set problems in bioinformatics. In Proc. 9th Scandinavian Workshop on Algorithm
Theory (SWAT), volume 3111 of Lecture Notes in Computer Science, pages 39–50,
Berlin, 2004. Springer-Verlag.
2. P. Berman, B. DasGupta, and E. Sontag. Randomized approximation algorithms
for set multicover problems with applications to reverse engineering of protein
and gene networks. In Proc. 7th International Workshop on Approximation Algorithms for Combinatorial Optimization Problems (APPROX), volume 2748 of
Lecture Notes in Computer Science, pages 39–50, Berlin, 2004. Springer-Verlag
(To appear in Discrete Applied Mathematics.).
3. J. Borneman, M. Chrobak, G.D. Vedova, A. Figueora, and T. Jiang. Probe selection
algorithms with applications in the analysis of microbial communities. Bioinformatics, 1:1–9, 2001.
4. D. Cazalis, T.Milledge, and G. Narasimhan. Probe selection problem: Structure
and algorithms. In Proc. 8th Multi-Conference on Systemics, Cybernetics and
Informatics (SCI 2004), pages 124–129, 2004.
5. V.G. Cheung and S.F. Nelson. Whole genome amplification using a degenerate
oligonucleotide primer allows hundreds of genotypes to be performed on less than
one nanogram of genomic dna. Proc. Natl. Acad. Sci. USA., 93:14676–14679, 1996.
6. V. Chv´
atal. A greedy heuristic for the set covering problem. Math. of Op. Res.,
4:233–235, 1979.
7. NCBI Completed Microbial Genomes. http://www.ncbi.nlm.nih.gov/genomes/microbes/complete.html, 2004.
8. B. DasGupta, K. Konwar, I.I. Mandoiu, and A. Shvartsman. Highly scalable
algorithms for robust string barcoding. ACM Computing Research Repository,
cs.DS/0502065, 2005.
9. F.B. Dean, S. Hosono, L. Fang, X. Wu, A. Fawad Faruqi, P. Bray-Ward, Z. Sun,
Q. Zong, Y. Du, J. Du, M. Driscoll, W. Song, S.F. Kingsmore, M. Egholm, and R.S.
Lasken. Comprehensive human genome amplification using multiple displacement
amplification. Proc. Natl. Acad. Sci. USA., 99:5261–5266, 2002.
10. B. Gharizadeh, M. K¨
aller, P. Nyr´en, A. Andersson, M. Uhl´en, J. Lundeberg, and
A. Ahmadian. Viral and microbial genotyping by a combination of multiplex competitive hybridization and specific extension followed by hybridization to generic
tag arrays. Nucleic Acids Research, 31(22), 2003.
11. D.S. Johnson. Approximation algorithms for combinatorial problems. J. Comput.
Sys. Sci., 9:256–278, 1974.

1028

B. DasGupta et al.

12. C. Linhart and R. Shamir. The degenerate primer design problem. Bioinformatics,
18:S172–S181, 2002.
13. L. Lov´
asz. On the ratio of optimal integral and fractional covers. Discrete Mathematics, 13:383–390, 1975.
14. S. Rash and D. Gusfield. String barcoding: Uncovering optimal virus signatures.
In Proc. 6th Annual International Conference on Computational Biology, pages
254–261, 2002.
15. R. Souvenir, J. Buhler, G. Stormo, and W. Zhang. Selecting degenerate multiplex PCR primers. In Proc. 3rd Intl. Workshop on Algorithms in Bioinformatics
(WABI), pages 512–526, 2003.
16. V.V. Vazirani. Approximation Algorithms. Springer-Verlag, Berlin, 2001.

