Generalized High-Level Synthesis
of Wavelet-Based Digital Systems
via Nonlinear I/O Data Space Transformations
Dongming Peng and Mi Lu
Electrical Engineering Department, Texas A&M University, College Station,
TX77843, USA

1

Introduction

In this paper, we systematically present the high-level architectural synthesis for
general wavelet-based algorithms via a model of I/O data space and the nonlinear transformations of the I/O data space. The parallel architectures synthesized
in this paper are based on the computation model of distributed memory and
distributed control. Several architectural designs have been proposed for the
Discrete Wavelet Transform (DWT) [4]-[11]. None of these architectural designs
for computing the DWT follows a systematic data dependence and localization analysis of general wavelet-based algorithms, and thus they only serve as
particular designs and cannot be extended to other complicated wavelet-based
algorithms such as MultiWavelet Transform (MWT)[1,13,14], Wavelet Packet
Transform (WPT)[2,15] or Spacial-Frequential Quantization (SFQ) [12]. Using
the WPT as a representative example of complex wavelet-based algortihms, this
paper fully describes the theory and methodology used in synthesizing parallel
architectures for general wavelet-based algorithms.

2

I/O Data Space Modeling of Wavelet-Based Algorithms

The basic equation for any discrete wavelet-based algorithms is generally represented by �
(Eq.1)
Xj+1 [t] = k∈L C[k]Xj [M t − k]
where C[k] are taps of a wavelet ﬁlter, Xj and Xj+1 are the sequence of input
data and output data respectively at the (j + 1)th level transform, L is a set
that corresponds to the size of the wavelet ﬁlter, and M is a constant scalar in
the algorithm. Generally, the algorithm is termed as M-ary wavelet transform
for M ≥ 2. There are M wavelet ﬁlters for M-ary wavelet transform. If Xj and
Xj+1 are scalar data and C is scalar-valued taps of the wavelet ﬁlter, the algorithm is a classical scalar wavelet transform; if Xj and Xj+1 are vector-valued
data and C is matrix-valued taps of the multiwavelet ﬁlter, it is an MWT. If t
and k are scalars, the algorithm is a 1-D transform; if t and k are n-D vectors, it
is an n-D transform. Wavelet-based algorithms are multiresolution algorithms,
i.e., the output data at a level of transform can be further transformed at the
next level.
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2073, pp. 884–893, 2001.
c Springer-Verlag Berlin Heidelberg 2001
�

Generalized High-Level Synthesis of Wavelet-Based Digital Systems

885

The following concepts are presented for the analysis in Section 3. Parameter index axis: The parameter index axis of a signal processing algorithm is the
index axis for those data to be broadcasted in the algorithm, i.e., the data used
in most computations but not generated by computations. As parameters of the
computations, the number of them is ﬁxed. Data index: The data index is the
index for the intermediate data, input data, or output data that are generated
and/or used by computations. In signal processing algorithms, the input size
is variable. I/O data space: In an I/O data space the indexed data are only
possibly the input data, output data or intermediate data, and the parameters
of the algorithm are ignored. The intermediate data are viewed as partial inputs
or partial outputs for the intermediate computations. Dependence graph: In
this paper we present the I/O data space based dependence graph, where each
node in the dependence graph corresponds to a data item, and each edge corresponds to a calculation or a dependence relation between the data used in
the calculation and that generated in the calculation. Wavelet-adjacent ﬁeld:
In an I/O data space, a wavelet-adjacent ﬁeld is a small domain made up of a
group of source data items used by a calculation in Eq. (1). Its size is dependent
on the wavelet ﬁlter. Super wavelet-dependence vector: A super wavelet−−→
dependence vector dW b starts from a wavelet-adjacent ﬁeld W and ends at the
resulted data b. Since the source of the “dependence vector” itself is a domain
instead of a single datum, we term such a dependence vector (corresponding to
the calculation in Eq. (1)) a super wavelet-dependence vector. In later analysis
the super wavelet-dependence vectors are generally called dependence vectors
and treated similarly as traditional dependence vectors. The length of a super
−−→
wavelet-dependence vector |dW b | is deﬁned as the Euclidean distance between a
and bc , where a and bc are arithmetic centers of W and b respectively. Regular
dependence graphs: in such dependence graphs the length of each dependence
vector d is a constant value independent of either the input size or the data positions. Pseudo regular dependence graphs: in such dependence graphs the
dependence vectors can be partitioned into a certain number of groups and in
each group the length of dependence vectors is a constant value independent of
either the input size or the data positions.
As examples, a wavelet-adjacent ﬁeld, a super wavelet-dependence vector and
the dependence graph for the algorithm of separable 2-D MWT[13][14] in I/O
data space are shown in Figure 1 based on these concepts.

3

Nonlinear I/O Data Space Transformations for
Regularizing Dependence Graphs

Theorem 3.1: The dependence graphs of wavelet-packet based algorithms (arbitrary expansion of wavelet trees) modeled in I/O data space can always be
merged and regularized to a pseudo regular dependence graphs via appropriate
nonlinear I/O data space transformations.

886

D. Peng and M. Lu
j

target vector

2
1.5

super wavelet dependence vector

1
0.5

wavelet-adjacent field
covering a bunch of vectors

0

Either target vector or each vector in the
wavelet-adjacent field consists of two items
of data at both ends of the vector.

N

n2

N

Dependence Graph
n1

Fig. 1. The wavelet-adjacent eld, super dependence vector and the dependence graph
for 2-D MWT

Proof:
(1) For algorithms of 1-D transforms: There are M wavelet ﬁlters
(f1 , f2 , · · · , fM ) at each level of 1-D M-ary wavelet transform, and each level
of transform can decompose a certain subband into M components in waveletpacket based algorithms. One of the ﬁlters (f1 ) is for generating coarse component, others for detailed components. Assume M functions Fi (x) = M x + i − 1
for i = 1, 2, · · · , M .
�
Suppose that a subband
is calculated in l levels of wavelet-packet based
transform consecutively with wavelet ﬁlters p1 , p2 , · · · , pl , where pu = fi for
u = 1, 2, · · · , l and i is any integer ∈ [1, M ]. Considering that there are many
subbands generated together by l levels of wavelet-packet based transform, and
their corresponding dependence graphs should be merged as well as regularized
to get a whole dependence graph for the algorithm, the nonlinear I/O data
loosing generality, for
space transformation Γ1 is presented as follows. Without
�
the dependence graph corresponding to subband , Γ1 is: j � −→j; t � −→t if
j = 0; t � −→ P1 (P2 (· · · (Pj (t)) · · ·)) otherwise, where Pu = Fi if pu = fi for
u = 1, 2, · · · , j, and j ≤ l, i ∈ [1, M ]. Note that here j corresponds to the level
of transform and can be only integers.
�
�
generated in the algorithm.
Consider another
subband 1 diﬀerent from
�
Suppose that 1 is calculated in l levels consecutively with wavelet ﬁlters
p�1 , p�2 , · · · , p�l , where p�u = fi for u = 1, 2, · · · , l and i is any integer ∈ [1, M ].
�
Since there
�
� exits at least one pu � =pu where u ∈ [1, l], Γ1 maps the data for
and 1 to diﬀerent positions in the I/O data space. In other words, Γ1 can
combine all dependence graphs of the subbands into a single I/O data space
without conﬂicts.
Consider a dependence vector in the I/O data space corresponding to a calculation of Eq.(1) at data position t0 at the (u + 1)th level of transform,
�
Xu+1 [t0 ] = k∈L pu+1 [k]Xu [M t0 − k],
where pu+1 represents the wavelet ﬁlter used at this level. After the mapping of
Γ1 , the calculation changes to

Generalized High-Level Synthesis of Wavelet-Based Digital Systems

887

�
Xu+1 [P1 (P2 (· · · (Pu (Pu+1 (t0 ))) · · ·))] =
k∈L pu+1 [k]Xu [P1 (P2 (· · · (Pu (M t0
−k)) · · ·))],
where Pv = Fi if pv = fi for v = 1, 2, · · · , u + 1, and i ∈ [1, M ]. The dependence vector, starting from the wavelet-adjacent ﬁeld which corresponds
to L and is centered at data Xu [P1 (P2 (· · · (Pu (M t0 )) · · ·))], is targeted to
data Xu+1 [P1 (P2 (· · · (Pu (Pu+1 (t0 ))) · · ·))]. The length of the dependence vector can be resolved by the diﬀerence between their coordinates along index j and t. The diﬀerence along index j is |u + 1 − u| = 1. The diﬀerence along t is |P1 (P2 (· · · (Pu (Pu+1 (t0 ))) · · ·)) − P1 (P2 (· · · (Pu (M t0 )) · · ·))| =
|P1 (P2 (· · · (Pu (M t0 + w)) · · ·)) − P1 (P2 (· · · (Pu (M t0 )) · · ·))|= M u w, where w is
an integer ∈ [1, M − 1]. Here the length of the dependence vector is independent
of t0 ’s value, and the number of transform levels and the number of wavelet ﬁlters
(M ) remain constant in the algorithm. In other words, the lengths of the dependence vectors in the I/O data space after the mapping of Γ1 are bounded and
independent of the data positions and input size. Moreover, the dependence vectors can be partitioned into a ﬁnite number of groups (according to the possible
values of w and u), and the lengths of the dependence vectors in each group are
the same. That is, the dependence graphs for 1-D wavelet-packet based algorithm
are combined and regularized to be a pseudo regular dependence paragraph via
the nonlinear I/O data space transformation Γ1 .
(2) For nonseparable n-D transforms: There are Q = M n diﬀerent wavelet
ﬁlters (f1 , f2 , · · · , fQ ) at each level of n-D M-ary wavelet transform. Assume Q
functions Fi (x) = M x + q, where x and q are n-D vectors. The components of
q are
�qn1 , q2 , · · · , qn , and qv is an integer ∈ [0, M − 1] for v = 1, 2, · · · , n, and
i = u=1 M u qu . So i ∈ [1, Q].
�
Suppose that a subband is calculated in l levels of n-D packet-packet based
transform consecutively with wavelet ﬁlters p1 , p2 , · · · , pl , where pu = fi for u =
1, 2, · · · , l and i ∈ [1, Q]. Without
loosing generality, for the dependence graph
�
corresponding to subband , a nonlinear I/O data space transformation Γ2 is
presented as: j � −→j; t � −→t if j = 0; t � −→P1 (P2 (· · · (Pj (t)) · · ·)) otherwise,
where Pu = Fi if pu = fi for u = 1, 2, · · · , j, and j ≤ l, i ∈ [1, Q]. Note that here
j corresponds to the level of transform and can be only integers, and t represents
n-D vectors.
�
For other subbands diﬀerent from
generated in the algorithm, since there
exits at least�one ﬁlter used in the calculation of l levels of transform diﬀerent
from that of , Γ2 maps the data of them to diﬀerent positions. In other words,
Γ2 can combine all dependence graphs of the subbands into a single I/O data
space without conﬂicts.
Similar to the case (1), a calculation corresponding to the dependence vector
changes to
�
Xu+1 [P1 (P2 (· · · (Pu (Pu+1 (t))) · · ·))]=
k∈L pu+1 [k]Xu [P1 (P2 (· · · (Pu (M t −
k)) · · ·))],
where Pv = Fi if pv = fi for v = 1, 2, · · · , u + 1, and i ∈ [1, Q]. The difference between the coordinates of the source and the target of the dependence vector along index j is |u + 1 − u| = 1. The diﬀerence along t is
P1 (P2 (· · · (Pu (Pu+1 (t))) · · ·)) − P1 (P2 (· · · (Pu (M t)) · · ·)) = P1 (P2 (· · · (Pu (M t +

888

D. Peng and M. Lu

w)) · · ·)) − P1 (P2 (· · · (Pu (M t)) · · ·))= M u w, where w is an n-D vector whose
components are integers ∈ [1, M − 1]. Thus the length of the dependence vector
is independent of t’s value. We have the similar conclusion that the lengths of the
dependence vectors in the I/O data space after the mapping of Γ2 are bounded
and independent of the data positions and input size, and the dependence vectors can be partitioned into a ﬁnite number of groups (according to the possible
values of w and u), and the lengths of the dependence vectors in each group are
the same.
(3) For separable n-D transforms: The n-D separable transforms are calculated separately and consecutively in every dimension. The index j is drawn
in fractional numbers to represent the intermediate calculations in each level
of transform. In the (s + 1)th level (where s is an non-negative integer) of a
separable n-D wavelet transforms, we have (n-1) intermediate I/O data planes
j = s + 1/n, j = s + 2/n, · · ·, j = s + (n − 1)/n between the planes j = s and
j = s + 1. In the calculations for every dimension, there are M wavelet ﬁlters
f1 , f2 , · · · , fM , and a subband may be decomposed into M components on each
dimension. So after each level of transform, a subband can be decomposed into
M n components. In addition, we assume M functions Fv (x) = M x + v − 1 for
v = 1, 2, · · · , M .
�
Suppose that a certain subband
is calculated in l levels of n-D separable
wavelet-packet based transform consecutively with wavelet ﬁlters p1,1 , p1,2 , · · · ,
p1,n , p2,1 , · · · , p2,n , · · · , pl,n , where pu,i = fv for u = 1, 2, · · · , l and i = 1, 2, · · · , n,
and v ∈ [1, M ]. pu,i represents the wavelet ﬁlter used�for the calculation of the uth
level transform on the ith dimension in generating . In order to regularize the
dependence graphs, we present the nonlinear I/O data space transformation Γ 3
as follows. Without
loosing generality, for the dependence graph corresponding
�
to subband , Γ3 is: j � −→ j, ti � −→ ti (i = 1, 2, · · · , n) if j = 0; ti � −→
P1,i (P2,i (· · · (Ps+1,i (ti )) · · ·)) otherwise, with j ∈ [s + i/n, s + 1 + i/n), s being
an integer ∈ [0, l − 1], Pu,i = Fv for pu,i = fv (u = 1, 2, · · · , s + 1; i = 1, 2, · · · , n;
and v ∈ [1, M ]).
�
For other subbands diﬀerent from
generated in the algorithm, since there
exits at least�
one ﬁlter used in the calculation of l levels of transform diﬀerent
from that of , Γ3 maps the data of them to diﬀerent positions.
The calculation of �
wavelet transform for the ith dimension at the (s + 1)th
level�of transform for
� ,
�
ps+1,i [ki ] k ∈L
ps+1,i+1 [ki+1 ] · · · kn ∈Ln ps+1,n [kn ]Xs+(i−1)/n [t1 ,
i+1
i+1
· · · , M ti − ki , M ti+1 − ki+1 , �
· · · , M tn − kn ],
t2 ,�
= k ∈L ps+1,i+1 [ki+1 ] · · · kn ∈Ln ps+1,n [kn ]Xs+i/n [t1 , t2 , · · · ,ti , M ti+1 − ki+1 ,
i+1
i+1
· · · , M tn − kn ],
ki ∈Li

changes
�
� to calculating

�

ps+1,i [ki ] k ∈L
ps+1,i+1 [ki+1 ] · · · kn ∈Ln ps+1,n [kn ]Xs+(i−1)/n [P1,1
i+1
i+1
(P2,1 (· · · (Ps+1,1 (t1 )) · · ·)), P1,2 (P2,2 (· · · (Ps+1,2 (t2 )) · · ·)), · · · , P1,i (P2,i (· · · (Ps,i (M ti −
ki )) · · ·)), P1,i+1 (P2,i+1 (· · · (Ps,i+1 (M ti+1 − ki+1 )) · · ·)), · · · , P1,n (P2,n (· · · (Ps,n (M tn −
)) · · ·))],
kn�
�
ps+1,i+1 [ki+1 ]· · · kn ∈Ln ps+1,n [kn ] Xs+i/n [P1,1 (P2,1 (· · · (Ps+1,1
= k ∈L
i+1
i+1
(t1 ))· · ·)),
P1,2 (P2,2 (· · · (Ps+1,2 (t2 )) · · ·)), · · · ,P1,i (P2,i (· · · (Ps+1,i (ti ))· · ·)), P1,i+1 (P2,i+1 (· · ·
ki ∈Li

Generalized High-Level Synthesis of Wavelet-Based Digital Systems

889

(Ps,i+1 (M ti+1 −ki+1 )) · · ·)),· · · , P1,n (P2,n (· · · (Ps,n (M tn − kn )) · · ·))] after the mapping
of Γ3 , where Pu,i = Fv if pu,i = fv for u = 1, 2, · · · , s + 1; i = 1, 2, · · · , n; and v ∈ [1, M ].

Thus after the transformation Γ3 , the dependence vector, starting from the
wavelet-adjacent ﬁeld which corresponds to Li and is centered at data
Xs+(i−1)/n [P1,1 (P2,1 (· · · (Ps+1,1 (t1 )) · · ·)), P1,2 (P2,2 (· · · (Ps+1,2 (t2 )) · · ·)),
· · · , P1,i (P2,i (· · · (Ps,i (M ti )) · · ·)), P1,i+1 (P2,i+1 (· · · (Ps,i+1 (M ti+1 − ki+1 ))
· · ·)),
· · · , P1,n (P2,n (· · · (Ps,n (M tn − kn )) · · ·))],
is targeted to data
Xs+i/n [P1,1 (P2,1 (· · · (Ps+1,1 (t1 )) · · ·)), P1,2 (P2,2 (· · · (Ps+1,2 (t2 )) · · ·)), · · · , P1,i
(P2,i (· · · (Ps+1,i (ti )) · · ·)), P1,i+1 (P2,i+1 (· · · (Ps,i+1 (M ti+1 − ki+1 )) · · ·)), · · · , P1,n
(P2,n (· · · (Ps,n (M tn − kn )) · · ·))]. The diﬀerence between the coordinates
of the target and the source of the dependence vector along index j is
|(s + i/n) − (s + (i − 1)/n)| = 1/n. The diﬀerence along t is
P1,i (P2,i (· · · (Ps,i (Ps+1,i (ti ))) · · ·)) − P1,i (P2,i (· · · (Ps,i (M ti )) · · ·))
= P1,i (P2,i (· · · (Ps,i (M ti + w)) · · ·)) − P1,i (P2,i (· · · (Ps,i (M ti )) · · ·))= M s w,
where w is an integer ∈ [1, M − 1]. Thus the length of the dependence vector is
independent of t’s value. We have the similar conclusion that the lengths of the
dependence vectors in the I/O data space after the mapping of Γ3 are bounded
and independent of the data positions and the input size, and the dependence
vectors can be partitioned into a ﬁnite number of groups (according to the
possible values of w and s), and the lengths of the dependence vectors in each
group are the same. ✷

4

Design Example: Synthesis of 2-D WPT by Exploiting
Inter-iteration Parallelism

First Level
Row-wise
Transform

Frist Level
Column-wise
Transfrom

Second Level
Row-wise
Transform

LL
L

LHLL
LHL

LH

INPUT

Second Level
Column-wise
Transform

LHLH
LHHL

LHH
LHHH

HL
H

HHLL
HHL

HH
HHH

HHLH
HHHL
HHHH

Fig. 2. An instance of arbitrary wavelet tree expansion in the algorithm of 2-D WPT

The recursive separable 2-D WPT is illustrated in Figure 2 and the equations
are as the followings

890

D. Peng and M. Lu

� �
j,i
C (j+1,4i) [n1 , n2 ] = �
k1
k2 h[k1 ]h[k2 ] × C [2n1 − k1 , 2n2 − k2 ]
�
(j+1,4i+1)
[n1 , n2 ] = �k1 �k2 h[k1 ]g[k2 ] × C j,i [2n1 − k1 , 2n2 − k2 ]
C
(j+1,4i+2)
[n1 , n2 ] = �k1 �k2 g[k1 ]h[k2 ] × C j,i [2n1 − k1 , 2n2 − k2 ]
C
(j+1,4i+3)
[n1 , n2 ] = k1 k2 g[k1 ]g[k2 ] × C j,i [2n1 − k1 , 2n2 − k2 ]
C
(j,i)
th
[n1 ,n2 ] means the datum at the position of nth
where C
1 row, n2 column in
th
the i subband in transform level j, h and g are low- and high-pass wavelet
ﬁlters. C(0,0) is the input image, L0 is the wavelet ﬁlter length, J is the highest
transform level, and N2 is the size of the input image.
In Figure 2, the label for subband C (j,i) generated in the j th (1 ≤ j ≤ J)
level of WPT is given as a combination of H’s and L’s, which represent a binary number if we refer to H as “1” and L as “0”. This binary number is
equal to i. For example, subband C (2,14) is labeled as HHHL in Figure 2,
or “1110” (14 in decimal). Note that some components in a transform level
may not be recursively decomposed in the next level WPT transform. According to Γ3 in Section 3, the nonlinear I/O index space transformation to merge
all dependence graphs for generated subbands (as in Figure 2) is: (1) for the
p1 p2 p3 ......p2m−1 p2m subband in Figure 2 (result of the mth level 2-D WPT),
n1 � −→P2 (P4 (...(P2m (n1 ))...)); n2 � −→P1 (P3 (...(P2m−1 (n2 ))...)); j = m; (2) for
the p1 p2 p3 ......p2m p2m+1 subband in Figure 2 (intermediate result in the (m+1)th
level 2-D WT), n1 � −→P2 (P4 (...(P2m (n1 ))...)); n2 � −→P1 (P3 (...(P2m+1 (n2 ))...));
j = m + 12 , where we assume that function Pk (x) is Low(x) = 2x if pk is “L”; or
Pk (x) is High(x) = 2x + 1 if pk is “H” for k = 0, 1, 2, · · · , 2m. Figure 3 shows
the result of the nonlinear transformation in plane j=2 in the I/O data space.
In this section, we propose the parallel computing of 2-D WPT by exploiting
the inter-iteration parallelism based on the regularized and merged dependence
graphs via this nonlinear I/O data space transformation. The input, pixels of
a 2-D image signal are assumed to be fed to multi-processors in parallel. The
following concepts are adopted in the rest of this section.
Processor assignment: In this paper processor assignment is taken equivalently as I/O data space segmentation, where the I/O data space is segmented
into subspaces, and the computations corresponding to the super dependence
vectors in each segmented subspace are assigned to a processor.
Boundary dependence vectors vs. central dependence vectors: After segmenting the I/O data space, those dependence vectors lying in more than one subspaces of the I/O index space are called boundary dependence vectors, otherwise
central dependence vectors.
Computation scheduling and permissible scheduling: the processor assignment
is accompanied by a computation scheduling scheme, which speciﬁes the order
of the calculations in all the processors. A permissible schedule must satisfy two
conditions: 1) the inherently sequential computations cannot be scheduled to the
same time, i.e., the schedule cannot contradict the dependence graph; 2) no more
than one computations can be performed in a processor at the same time.
Boundary computation: A processor’s boundary computations are those performed in this processor and necessitating that the result of the computations
be sent out to other processors.

Generalized High-Level Synthesis of Wavelet-Based Digital Systems

891

Row-column coordinates for data in different subbands after the nonlinear I/O data space transformation:
LL: (2x,2y)
LHLL: (4x,4y+1)
LHLH: (4x,4y+3)
LHHL: (4x+2,4y+1)
LHHH: (4x+2,4y+3)
HHLL: (4x+1,4y+1)
HHLH: (4x+1,4y+3)
HHHL: (4x+3,4y+1)
HHHH: (4x+3,4y+3)
HL: (2x+1,2y)
where x and y are non-negative integers.

Y
12
11
10

LL

HL

LL

HL

LL

HL

HL

LL

LL

LL

HL

LL

HL

LL

HL

HL

LL

LHLL

7
6
5
4
3
2
1
0

LHLH HHLH LHHH HHHH LHLH HHLH LHHH HHHH LHLH HHLH
LL
LHLL

LL

HHLL LHHL HHHL LHLL HHLL LHHL HHHL LHLL HHLL LHHL
HL

LL

LL

HL
HL

LL

LL

HL

HL

LL

HL

HL
HL
HHLL LHHL HHHL LHLL HHLL LHHL HHHL

LL

HL

LL

LL

HL
HHHL
HL

LHHH HHHH

HL

LL

HL

LHHH HHHH

HL

LL

9
8

LL

LL

HL

LHLH HHLH LHHH HHHH LHLH HHLH LHHH HHHH LHLH HHLH

LL

HL

LHLL HHLL

LHHL HHHL

HL
LL
HL
HL LL
HL
HL
LL
LL
LL
LHLH HHLH LHHH HHHH LHLH HHLH LHHH HHHH LHLH HHLH
HL
LL
HL
HL
HL LL
LL
HL
LL
LL

LHHH HHHH

LHLL HHLL LHHL HHHL LHLL HHLL LHHL HHHL LHLL HHLL

LHHL HHHL

LL

0

HL

LL

HL

LL

HL

1

2

3

4

5

LL

LL

HL

6

7

LL
LL

HL

8

LL

9

HL
HL

HL

10

X
11

Fig. 3. The data redistribution based on the I/O data space transformation for the
2-D WPT algorithm shown as in Figure 2

For brieﬁng communication network and concentrating on the computation
scheduling within processors based on the I/O data space transformation, we
assume mesh-like processor (or PE) array to be used to implement the algorithm.
For the purpose of minimizing data communication intensity, the total number
of boundary dependence vectors is made as small as possible after the I/O data
space segmentation. Thus, we segment the I/O data space in the direction of
most dependence vectors, i.e., along the direction parallel with j axis. The shape
of dependence graphs in each segmented subspace has the similarity as that in the
whole I/O data space, but with diﬀerent boundary dependence vectors generated
in the segmentation. For the purpose of load balance among processors, all the
subspaces are supposed to have the same size after the segmentation. Thus, we
have partitioned the I/O data space into p2 subspaces as in Figure 4, where p2
is the number of parallel processors (or PE’s).
To minimize the data communication intensity or the requirement on the
network bandwidth, the boundary computations in a processor are scheduled
as far away as possible in timing. A simpler explanation for this is that the result of a boundary computation is sent as soon as calculated and it is alright
if the communication is completed before the result of the next boundary computation is generated and sent in the sense that the communication conﬂicts
are avoided. In other words, to maximize the intervals between the boundary
computations, each processor takes turns to execute one boundary computation
and R non-boundary computations which involve boundary dependence vectors
and central dependence vectors respectively, where R is the ratio of the number

892

D. Peng and M. Lu
Solid dependence vectors correspnd to low-pass wavelet filtering
Dotted dependence vectors correspond to high-pass wavelet filtering

j

Dashed lines correspond to the segmentation of the I/O index space
Bold solid lines represent the wavelet-adjacent field

u+1

u+0.5

u

N

n2

N
the merged I/O index spaces and dependence graphs
n1

Fig. 4. The segmentation of I/O data space

of central dependence vectors to the number of boundary dependence vectors in
the processor.

5

Conclusions

This paper has demonstrated that data dependence analysis provides the basis
for the synthesis of parallel architectural solutions for general wavelet-based algorithms and serves as a theoretical foundation for exploiting properties. Extracting the common features of computation locality and multirate signal processing
within the wavelet-based algorithms, this paper contributes to data dependence
and localization analysis based on a new concept — I/O data space analysis
which leads to simpliﬁed structures of dependence graphs, and nonlinear I/O
data space transformations for generalized high-level architectural synthesis of
wavelet-based algorithms.

References
1. M.. Cotronei, L. B. Montefusco and L. Puccio, Multiwavelet analysis and signal
processing, IEEE Transactions on Circuits and Systems II: Analog and Digital
Signal Processing, Vol. 45, Aug. 1998, pp. 970 -987.
2. F. G. Meyer, A. Z. Averbuch and J. O. Stromberg, Fast adaptive wavelet packet
image compression, IEEE Transactions on Image Processing, Vol. 9, May 2000,
pp. 792 -800.
3. J. Fridman and E. S. Manolakos, Discrete wavelet transform: data dependence
analysis and synthesis of distributed memory and control array architectures, IEEE
Transactions on Signal Processing, Vol. 45, May 1997, pp. 1291 -1308.
4. H. Sava, M. Fleury, A. C. Downton and A. F. Clark, Parallel pipeline implementation of wavelet transforms, IEE Proceedings on Vision, Image and Signal
Processing, Vol. 144, Dec. 1997, pp. 355 -360.

Generalized High-Level Synthesis of Wavelet-Based Digital Systems

893

5. K. K. Parhi and T. Nishitani, VLSI architectures for discrete wavelet transforms,
IEEE Transactions on Very Large Scale Integration (VLSI) Systems, Vol. 1, June
1993, pp. 191 -202.
6. A. Grzeszczak, M. K. Mandal and S. Panchanathan, VLSI implementation of
discrete wavelet transform, IEEE Transactions on Very Large Scale Integration
(VLSI) Systems, Vol. 4, Dec. 1996, pp. 421 -433.
7. Seung-Kwon Pack and Lee-Sup Kim, 2D DWT VLSI architecture for wavelet image
processing, Electronics Letters, Vol. 34, March 1998, pp. 537 -538.
8. G. Knowles, VLSI architecture for the discrete wavelet transform, Electronics Letters, Vol. 26, 19 July 1990, pp. 1184 -1185.
9. M. Vishwanath, R. M. Owens and M. J. Irwin, VLSI architectures for the discrete
wavelet transform, IEEE Transactions on Circuits and Systems II: Analog and
Digital Signal Processing, Vol. 42, May 1995, pp. 305 -316.
10. T. C. Denk and K. K. Parhi, VLSI architectures for lattice structure based orthonormal discrete wavelet transforms, IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing, Vol. 44, Feb. 1997, pp. 129 -132.
11. C. Chakrabarti and M. Vishwanath, Eﬃcient realizations of the discrete and continuous wavelet transforms: from single chip implementations to mappings on SIMD
array computers, IEEE Transactions on Signal Processing, Vol. 43, March 1995,
pp. 759 -771.
12. Zixiang Xiong, K. Ramchandran and M.T.Orchard, Wavelet packet image coding
using space-frequency quantization, IEEE Transactions on Image Processing, Vol.
7, June 1998, pp. 892 -898.
13. M. Cotronei, D. Lazzaro, L. B. Montefusco and L. Puccio, Image compression
through embedded multiwavelet transform coding, IEEE Transactions on Image
Processing, Vol. 9, Feb. 2000, pp. 184 -189.
14. Gang Lin and Ze-Min Liu, The application of multiwavelet transform to image
coding, IEEE Transactions on Image Processing, Vol. 9, Feb. 2000, pp. 270 -273.
15. F. Kurth and M. Clausen, Filter bank tree and M-band wavelet packet algorithms
in audio signal processing, IEEE Transactions on Signal Processing, Vol. 47, Feb.
1999, pp. 549 -554.

