On a Family of Cheap Symmetric One-Step
Methods of Order Four
Gennady Yu. Kulikov and Sergey K. Shindin
School of Computational and Applied Mathematics,
University of the Witwatersrand, Private Bag 3, Wits 2050,
Johannesburg, South Africa
gkulikov@cam.wits.ac.za, sshindin@cam.wits.ac.za

Abstract. In the paper we present a new family of one-step methods.
These methods are of the Runge-Kutta type. However, they have only
explicit internal stages that leads to a cheap practical implementation.
On the other hand, the new methods are of classical order 4 and stage
order 2 or 3. They are A-stable and symmetric.

1

Introduction

When solving ordinary diﬀerential equations (ODE’s) of the form
x (t) = g t, x(t) ,

t ∈ [t0 , t0 + T ],

x(t0 ) = x0

(1)

where x(t) ∈ Rn and g : D ⊂ Rn+1 → Rn is a suﬃciently smooth function, any
one-step method reads
xk+1 = xk + τk Φ(tk , xk , tk+1 , xk+1 , τk ),

k = 0, 1, . . . , K − 1,

(2)

where x0 = x0 , τk is a step size and the function Φ(tk , xk , tk+1 , xk+1 , τk ) is referred to as an increment function of method (2). One-step methods (2) possess
many superior practical properties to solve ODE’s (1) of diﬀerent sorts. For instance, they can be A-stable and keep high order convergence rate that is not
possible for multistep methods because of Dahlquist’s second barrier [5]; they
do not have any diﬃculties with a variable step size implementation (see, for
example, [4], [5]); they are also of high importance when applied to Hamiltonian
or reversible equations [6]. Unfortunately, one-step methods have some limitations in the sense of high execution time when solving large-scale ODE’s (1).
Usual representatives of one-step methods (2) are Runge-Kutta formulas, but
only implicit of them are suitable for stiﬀ problems. However, implicit RungeKutta methods of high order are very time-consuming because of the need to
solve in general nonlinear systems of dimension ln where l is the number of stage
The ﬁrst author thanks the National Research Foundation of South Africa for partial
support of his work under grant No. FA2004033000016. The second author thanks
the University of the Witwatersrand, Johannesburg for a Post-Doctoral Fellowship.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 781–785, 2006.
c Springer-Verlag Berlin Heidelberg 2006

782

G.Yu. Kulikov and S.K. Shindin

values at each step of the numerical integration (see [4], [5]). Hopefully, serious
progress was made in this area by Bickart [1] and Butcher [2].
The aim of this paper is to present a cheap family of symmetric A-stable
Runge-Kutta formulas. They are of classical order 4 and of stage order 3.

2

New Family of Symmetric One-Step Methods

Further, we suppose that ODE (1) possesses a unique solution x(t) on the whole
interval [t0 , t0 + T ]. We show how to construct the methods mentioned above.
Let us ﬁx a subinterval [tk , tk+1 ] ⊂ [t0 , t0 + T ] of the length τk ; i.e., τk =
tk+1 − tk , and consider that the exact solution of ODE (1) is known at the point
tk ; i.e., xk = x(tk ). Then, on the one hand, if two additional solutions x(tk + c1 τ )
and x(tk + c2 τ ) evaluated at internal points of the interval [tk , tk+1 ] are known
we will be able to use a two-point quadrature formula of the form
xk+1 = x(tk ) + τk b1 g tk + c1 τk , x(tk + c1 τk ) + τk b2 g tk + c2 τk , x(tk + c2 τk )
in order to ﬁnd an approximation to the exact solution x(tk+1 ).
On the other hand, if the exact solution x(tk+1 ) is considered to be known we
can try to approximate the values xk1 and xk2 of the exact solution evaluated
at the points tk + c1 τk and tk + c2 τk , respectively, by means of explicit formulas
of the following form:
xk1 = a11 x(tk ) + a12 x(tk+1 ) + τk d11 g tk , x(tk ) + d12 g tk+1 , x(tk+1 )

,

xk2 = a21 x(tk ) + a22 x(tk+1 ) + τk d21 g tk , x(tk ) + d22 g tk+1 , x(tk+1 )

.

Thus, our task is to search the highest order one-step methods of the form
x1 = a11 xk + a12 xk+1 + τk d11 g(tk , xk ) + d12 g(tk+1 , xk+1 ) ,

(3a)

x2 = a21 xk + a22 xk+1 + τk d21 g(tk , xk ) + d22 g(tk+1 , xk+1 ) ,

(3b)

xk+1 = xk + τk b1 g(tk + c1 τk , x1 ) + b2 g(tk + c2 τk , x2 )

(3c)

where aij , bi , ci , dij , i, j = 1, 2, are unknown ﬁxed coeﬃcients.
We ﬁrst remark that the Gauss quadrature formula has the highest order 4
among all formulas of the form (3c). Therefore the coeﬃcients
bi , ci are√deter√
mined uniquely and they are: b1 = b2 = 1/2, c1 = (3 − 3)/6, c2 = (3 + 3)/6.
Second, we require the defect (or the local error) of method (3) to be O(τk5 )
for any ODE (1) with a suﬃciently smooth right-hand side. The latter condition
admits the following one-parametric family of the coeﬃcients to provide the
fourth order convergence for method (3):
a12 = 1 − θ,
√
6θ − 2 − 3
,
=
√12
4 + 3 − 6θ
,
=
12

a11 = θ,
d11
d21

a21 = 1 − θ,

(4a)

d12

(4b)

d22

a22 = θ,
√
6θ − 4 − 3
,
=
√12
2 + 3 − 6θ
.
=
12

(4c)

On a Family of Cheap Symmetric One-Step Methods of Order Four

783

Below, we consider that methods (3) are based on the Gauss quadrature
formula of order 4 and their coeﬃcients satisfy conditions (4). So, it is not diﬃcult
to check that all these methods are symmetric. We refer the reader to [4] for the
necessary theory. It is also quite evident that the stability functions of all the
constructed methods are R22 (z), which means the (2, 2)-Pad´e approximation to
the exponential function ez (see, for example, [5]). The latter implies that our
methods are A-stable. Thus, the family of methods (3) can be useful to integrate
both nonstiﬀ and stiﬀ ODE’s (including reversible problems).

3

Practical Implementation

For nonstiﬀ ODE’s, we recommend to use ﬁxed-point iterations with both trivial predictor and nontrivial one. Particulars on implementation of this iteration in iterative Runge-Kutta methods and estimation of a suﬃcient number
for iteration steps to provide the maximum order convergence can be found
in [7].
When solving stiﬀ ODE’s we are constrained with Newton-type iterations
only and have to implement the iteration in the form that does not ruin Astability of the underlying method (see, for example, [3], [5]). From this point
of view, the modiﬁed Newton iteration is a proper one. Unfortunately, the high
execution cost, which is about 4n3 /3 arithmetical operations per evaluation of
the Jacobi matrix and its LU decomposition, makes it pretty unpractical for
large n. Hopefully, the number of operations can be reduced with a factor of
4 by replacement of the full Jacobian of method (3) with a simpliﬁed one, as
follows:
−1
−1
= −xk+1
+x
¯k
(I − τk J/4)2 xk+1 − xk+1

+τk b1 g(tk + c1 τk , xk1−1 ) + b2 g(tk + c2 τk , xk2−1 ) ,

(5)

where = 1, 2, . . . , N and x
¯k is the numerical solution derived by method (3)
def
with N Newton iteration steps per grid point; i.e., x
¯k = xN
k , k = 1, 2, . . . , K.
def

Here, J = ∂x g(tk+1 , x0k+1 ) be the partial derivative of the right-hand side of
ODE (1) with respect to the second variable evaluated at the point (tk+1 , x0k+1 ).
Note that iteration (5) implies a single LU decomposition of the matrix I −
τk J/4 and successive solutions of two linear systems with the same decomposed
coeﬃcient matrix. This feature makes methods (3) comparable to SDIRK, which
are very eﬃcient to solve stiﬀ ODE’s (see [3], [5]).
At the end, we exhibit nice practical properties of iteration (5). First, the
Jacobian replacement made above does not inﬂuence the suﬃcient number of
iteration steps with both trivial predictor and nontrivial one to provide the
fourth order convergence. It follows from Theorem 3 in [8]. Second, iteration
(5) is A-stable. To see this, we apply one step of iteration (5) to the Dahlquist
test equation x = λx where λ is a ﬁxed complex number with a nonpositive real

784

G.Yu. Kulikov and S.K. Shindin

part and consider that x0k+1 = xk . Simple calculations give the stability function
of method (5) in the form R(z) = (1 + z/4)2 /(1 − z/4)2 , which is evidently
A-stable.

4

Numerical Experiments

√
To test our methods, we apply the method (3) when θ = 1/2 + 2 3/9 and with
iteration (5) to the two dimensional Brusselator with diﬀusion and the periodic
boundary conditions (see [5, p. 151–152] for full detail). We take the number of
the grid points in each dimension to be equal 50. It leads to a system of ODE of
dimension 5000. We solve this problem on the interval [0, 6] by the method (3)
and by the Gauss method of order 4 (termed also Hammer and Hollingsworth’s
method). Both methods are based on the same quadrature formula and they are
of the same classical order. However, the stage order of our method is 3 and of
the Gauss one is 2.
We use the same variable step size implementation of these two methods with
modiﬁed Newton iterations and with the same step size selection mechanism
based on the local error estimate evaluated by the Richardson extrapolation.
We apply the modiﬁed Newton iteration in the form of algorithm (5) in method
(3) and do the conventional implementation for the Gauss method. We also want
to emphasize that the correct step size control requires two iteration steps per
grid point in algorithm (5) and three iteration steps in the modiﬁed Newton
iteration applied to the Gauss method (see, for example, [8]). The local error
tolerance is chosen to be 10−01 .
Statistics of both integrations is presented in form of the following table and
clearly displays the better performance of the method (3), at least for this test
problem:
Statistics
execution time (in sec.)
number of rejected steps
number of accepted steps

method (3)
843.985
6
44

Gauss method
2456.656
1
24

References
1. Bickart, T.A.: An eﬃcient solution process for implicit Runge-Kutta methods. SIAM
J. Numer. Anal. 14 (1977) 1022–1027
2. Butcher, J.C.: On the implementation of implicit Runge-Kutta methods. BIT. 16
(1976) 237–240
3. Dekker, K., Verwer, J.G. Stability of Runge-Kutta methods for stiﬀ nonlinear differential equations. North-Holland, Amsterdam, 1984
4. Hairer, E., Nørsett, S.P., Wanner, G.: Solving ordinary diﬀerential equations I: Nonstiﬀ problems. Springer-Verlag, Berlin, 1993
5. Hairer, E., Wanner, G.: Solving ordinary diﬀerential equations II: Stiﬀ and
diﬀerential-algebraic problems. Springer-Verlag, Berlin, 1996
6. Hairer, E., Lubich, C., Wanner, G.: Geometric numerical integration: Structure preserving algorithms for ordinary diﬀerential equations. Springer-Verlag, Berlin, 2002

On a Family of Cheap Symmetric One-Step Methods of Order Four

785

7. Kulikov, G.Yu.: On implicit extrapolation methods for ordinary diﬀerential equations, Russian J. Numer. Anal. Math. Modelling., 17 (2002) No. 1, 41–69
8. Kulikov, G.Yu., Merkulov, A.I.: Asymptotic error estimate of iterative Newton-type
methods and its practical application. In: Antonio Lagana et al (eds.): Computational Science and Its Applications — ICCSA 2004. International Conference, Assisi,
Italy, May 2004. Proceedings, Part III. Lecture Notes in Computer Science. 3045
(2004) 667–675

