Tridiagonalizing Complex Symmetric Matrices
in Waveguide Simulations
W.N. Gansterer1 , H. Schabauer1 , C. Pacher2, and N. Finger2
1

University of Vienna, Research Lab Computational Technologies and Applications
{wilfried.gansterer,hannes.schabauer}@univie.ac.at
2
Austrian Research Centers GmbH - ARC, Smart Systems Division
{christoph.pacher,norman.finger}@arcs.ac.at

Abstract. We discuss a method for solving complex symmetric (nonHermitian) eigenproblems Ax = λBx arising in an application from
optoelectronics, where reduced accuracy requirements provide an opportunity for trading accuracy for performance. In this case, the objective is
to exploit the structural symmetry. Consequently, our focus is on a nonHermitian tridiagonalization process. For solving the resulting complex
symmetric tridiagonal problem, a variant of the Lanczos algorithm is
used. Based on Fortran implementations of these algorithms, we provide
extensive experimental evaluations. Runtimes and numerical accuracy
are compared to the standard routine for non-Hermitian eigenproblems,
LAPACK/zgeev. Although the performance results reveal that more work
is needed in terms of increasing the fraction of Level 3 Blas in our tridiagonalization routine, the numerical accuracy achieved with the nonHermitian tridiagonalization process is very encouraging and indicates
important research directions for this class of eigenproblems.
Keywords: Tridiagonalization, complex symmetric eigenvalue problems,
waveguide simulation, optoelectronic.

1

Introduction

We discuss methods for eﬃciently tridiagonalizing a complex symmetric (nonHermitian) matrix. The term complex matrix is used to denote a matrix which
has at least one element with a nonzero imaginary part.
Tridiagonalization is an important preprocessing step in reduction-based (tridiagonalization-based) methods for computing eigenvalues and eigenvectors of
dense real symmetric or complex Hermitian matrices. In the context considered
here, the underlying complex symmetric eigenvalue problem (EVP) has similar
ˆ B
ˆ ∈ Cn×n
structural, but diﬀerent mathematical properties. Given matrices A,
H
H
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
ˆ
with A = A (but A = A ) and B = B (but B = B ), the objective is to
eﬃciently compute eigenvalues λ and eigenvectors y of the generalized EVP
ˆ = λBy
ˆ .
Ay

(1)

The main challenge is to ﬁnd ways for utilizing the structural symmetry in the
absence of the mathematical properties of Hermitian matrices.
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 945–954, 2008.
c Springer-Verlag Berlin Heidelberg 2008

946

W.N. Gansterer et al.

Although problems of the type (1) do not occur as frequently in practice as
real symmetric or complex Hermitian problems, there are some important applications where they arise (see, for example, [1,2,3]). The eﬀorts summarized in
this paper are motivated by the simulation of guided-wave multi-section devices
in optoelectronics. As described in Section 2, techniques for numerically solving
Maxwell’s equations in this context lead to dense EVPs of the type (1).
Analogously to Hermitian problems, one possible approach for solving probˆ = In . Complex symlem (1) starts with reducing it to standard form where B
metry allows for special techniques in this reduction step which are not discussed
here. After that, a tridiagonalization process is performed on the standard EVP
which results in a similar complex symmetric tridiagonal matrix T . After this
tridiagonalization step, eigenvalues and eigenvectors of T are computed and the
eigenvectors are backtransformed.
In the following, we focus on symmetry-preserving approaches for eﬃciently
tridiagonalizing a complex symmetric matrix. This functionality constitutes a
central step in the solution process outlined above and is one way of exploiting
the available structure. A more detailed discussion of the other steps involved in
solving (1) will be provided in a forthcoming paper.
Mathematically speaking, structural symmetry is not a very distinctive feature of complex matrices, since every matrix A ∈ Cn×n is similar to a complex
symmetric matrix [1]. In contrast to a real symmetric matrix a complex symmetric matrix A is not necessarily diagonalizable. Nevertheless, structural symmetry
is of great interest for the development of space- and time-eﬃcient algorithms.
Obviously, half of the information in a complex symmetric matrix is redundant,
and eﬃcient algorithms should be able to take advantage of this fact in terms
of memory requirements as well as in terms of computational eﬀort. The utilization of this purely structural property in the absence of important mathematical
properties of Hermitian matrices requires a trade-oﬀ in numerical stability. In
order to perform a symmetry preserving similarity transformation, the transformation matrix Q ∈ Cn×n needs to be complex orthogonal (but not unitary), that
is, it has to satisfy Q Q = In .
Related Work. Various non-reduction based methods for solving complex symmetric EVPs have been proposed, for example, based on the Jacobi method [4],
on the Lanczos method [5], or on variants of the Jacobi-Davidson method [6].
For dense matrices, reduction-based methods tend to be more eﬃcient. A modiﬁed conventional Householder-based reduction method has been described in [2].
The tridiagonalization of a dense complex symmetric matrix has also been investigated in [3]. In [2], the resulting tridiagonal complex symmetric problem is
solved using a modiﬁed QR algorithm. Other related approaches for computing
eigenvalues of a complex symmetric tridiagonal matrix were discussed in [7,8].
Synopsis. In Section 2 of this paper, the motivating application from optoelectronics is summarized. In Section 3, the tridiagonalization method investigated
in this paper is discussed in detail, and Section 4 contains experimental results.
Conclusions and future work are summarized in Section 5.

Tridiagonalizing Complex Symmetric Matrices in Waveguide Simulations

2

947

Guided-Wave Multisection Devices

The use of high-index contrast waveguides (WGs) in novel guided-wave devices
for telecom- and sensing applications allows a very versatile tailoring of the ﬂow
of light. However, an eﬃcient design requires the direct numerical solution of
Maxwell’s equations in inhomogeneous media. In many important cases such
devices can be successfully modeled as follows: (i) in the x-direction (direction
of propagation) the material parameters are piecewise constant, (ii) the material
parameters and the optical ﬁelds do not depend on the y-coordinate, and (iii) in
the z-direction the material parameters are allowed to vary arbitrarily. Usually,
the z-dimension is of the order of up to several tens of wavelengths whereas the
device extension into the x-direction is several hundreds of wavelengths.
A powerful numerical method for the solution of Maxwell’s equations in
such WG-based devices is the eigenmode expansion technique (which is often
referred to as mode-matching (MM ) technique) [9,10,11], where the electromagnetic ﬁeld components in each subsection being homogeneous in the x-direction
are represented in terms of a set of local eigenmodes. MM requires a small computational eﬀort compared to other numerical techniques like two-dimensional
ﬁnite-elements or FDTD which can be regarded as “brute-force” methods from
the viewpoint of device physics. However, MM can only be as stable and eﬃcient
as the algorithms used to determine the required set of local WG modes. Due
to the open boundary conditions (see Section 2.1) and materials with complex
dielectric permittivities these local eigenmodes have typically complex eigenvalues which makes their correct classiﬁcation very diﬃcult: numerical instabilities
can arise from an improper truncation of the mode spectrum. In a recently developed variant of the MM technique — the so-called variational mode-matching
(VMM ) [12] — this stability problem is avoided by applying a Galerkin approach
to the local wave equations and taking into account the whole spectrum of the
discretized operators.
2.1

The VMM-Approach

Within the 2D-assumption ∂y (·) = 0, Maxwell’s equations for dielectric materials
characterized by the dielectric permittivity ε(x, z) take the form
∂x a∂x φ + ∂z a∂z φ + k02 bφ = 0 ,

(2)

where φ = Ey , a = 1, b = ε for TE- and φ = Hy , a = 1ε , b = 1 for TMpolarization, respectively; k0 = 2π
λ0 (vacuum wavelength λ0 ).
In the z-direction, the simulation domain is 0 ≤ z ≤ L. To permit an accurate description of radiation ﬁelds, an artiﬁcial absorber (that mimics an open
domain) has to be installed near z = 0 and z = L. For this purpose so-called
perfectly-matched layers (PMLs) are used by employing the complex variable
stretching approach [13], i. e., in the vicinity of the domain boundaries the coorz
dinate z is extended into the complex plane: z → z˜ = z + ı 0 dτ σ(τ ), where σ
is the PML parameter determining the absorption strength. At z = 0 and z = L

948

W.N. Gansterer et al.

Dirichlet- or Neumann boundary conditions (BCs) are set. However, they should
not have a signiﬁcant inﬂuence on the overall optical ﬁeld since the physical BCs
must be given by the PMLs. In the x-direction, the structure is divided into nl
local WGs, which expand over xl−1 ≤ x ≤ xl = xl−1 + dl with 1 ≤ l ≤ nl .
Under the necessary condition that ε does not depend on x Eq. (2) can be
solved inside each local WG l with the separation ansatz
nϕ

φ(l) (x, z˜) =

nϕ
(l)

j=1

(l)

(l)

cjρ αρ,+ eık0 νρ

ϕj (˜
z)

(x−xl−1 )

+ αρ,− e−ık0 νρ
(l)

(l)

(x−xl )

,

(3)

ρ=1

where ρ labels the local waveguide modes. The transverse shape functions ϕj (˜
z)
(the same set is used for all local WGs) must satisfy the outer boundary conditions. Apart from this constraint, the ϕj ’s may be chosen rather freely allowing
for adaptive reﬁnement in z-regions where rapid variations of the ﬁeld are expected. This ansatz reduces the 2D problem to a set of nl 1D problems.
After inserting Eq. (3) into Eq. (2), Galerkin’s method is applied to obtain a
(l)
discretized version of Eq. (2) for each local WG l. Finally, the coeﬃcients αρ,±
are “mode-matched” by imposing the physical boundary conditions at all the
xl -interfaces [12].
2.2

The Complex Symmetric Eigenvalue Problem

For each local WG, the discretized version of Eq. (2) is a generalized EVP of the
form
Acρ = (νρ )2 Bcρ ,
(4)
where we have suppressed the index l for simplicity. Here, the νρ ’s are the
modal refractive indices and the cjρ ’s are the corresponding modal expansion
coeﬃcients occurring in Eq. (3). A is a sum of a mass- and a stiﬀness-matrix,
z (∂z˜ϕm (˜
z ϕm (˜
z )b(˜
z )ϕj (˜
z ) − k12 d˜
z ))a(˜
z )(∂z˜ϕj (˜
z )), whereas B is a
Amj = d˜
0
z ϕm (˜
z )a(˜
z )ϕj (˜
z ).
pure mass-matrix: Bmj = d˜
The generalized EVP (4) has the following properties: (i) A and B are complex symmetric: the complex coordinate z˜ originating from the PMLs (and the
possibly complex material constants a and b) are responsible for the complexvaluedness; (ii) B is indeﬁnite (due to the open boundary conditions represented
by the PMLs and a possibly negative material constant a); (iii) the typical order of the matrices for 2D problems is 100–1000 (depending on the geometry
and the required truncation order of the modal expansion—in 3D models the
order can be much higher); (iv ) the full spectrum of eigenpairs is required; (v )
the required accuracy is of the order 10−8 for the eigenpairs corresponding to
the lowest order WG modes (approx. 10% of the mode spectrum); a somewhat
lower accuracy (approx. 10−6 ) is acceptable for the remainder of the spectrum;
(vi) depending on the WG geometry, some of the eigenvalues (especially those
corresponding to the lowest order WG modes) may almost degenerate.
It is evident that an eﬃcient eigenvalue solver which utilizes the symmetry of
the EVP (4) as well as its special properties is a very important building block
for eﬃcient 2D and 3D optical mode solvers.

Tridiagonalizing Complex Symmetric Matrices in Waveguide Simulations

3

949

Methodology

The standard approach to solving a dense complex symmetric EVP (as available,
for example, in Lapack [14]) is to treat it as a nonsymmetric EVP: the complex
symmetric matrix is reduced to upper Hessenberg form, from which eigenvalues
and eigenvectors are computed using a QR iteration. The main motivation behind investigating tridiagonalization-based approaches as an alternative is the
obvious potential for reducing storage and runtime requirements.
In order to preserve symmetry, complex orthogonal similarity transformations
(COTs) Q are needed which satisfy Q Q = In . In general, Q 2 ≥ 1 and thus
the application of complex orthogonal matrices can increase numerical errors.
3.1

Splitting Methods

The real part R and the imaginary part S of a complex symmetric matrix
A = R + iS are real symmetric matrices. One basic idea, which has been introduced earlier [3], is to separate the tridiagonalization of R from the tridiagonalization of S as much as possible. More speciﬁcally, part of a column of
R can be eliminated using a (real) orthogonal Householder transformation QR .
After that, a (smaller) part of the corresponding column of S can be eliminated
without causing any ﬁll-in in R using another (real) orthogonal Householder
transformation QI . Both of these operations are performed in real arithmetic,
and both transformation matrices have norm one. Eventually, a single nonzero
element below the subdiagonal in S remains to be eliminated. This operation
has to be performed in complex arithmetic, using a 2 × 2 COT, whose norm
cannot be bounded a priori. When the column elimination is ﬁrst performed in
R and then in S, we call the procedure RI variant. Analogously, it is possible to
eliminate ﬁrst in S and then in R. We call this procedure IR variant .
The advantages of splitting methods seem obvious: Most of the computation
can be done in real arithmetic, only one third of the transformations are potentially unstable, and this danger can easily be monitored because of the low
dimensions of the COTs (only order two).
Complex Orthogonal Transformations. The transformation matrix
1
G := √
2
z + s2

zs
−s z

,

z = z1 + iz2 ∈ C, z1 , z2 , s ∈ R ,

(5)

deﬁnes a COT since G G = I2 . Consequently, GAG is a similarity transformation of A. In the RI variant, a COT GRI has to be determined such that
GRI

a + ib
ic

=

d + ie
0

,

where a, b, c, d, e ∈ R and c = 0. Choosing the parameters z = s
s = 0 arbitrary, the COT is given as
GRI =

1
b2 − a2 + c2 − i(2ab)

b − ia c
−c
b − ia

.

b
c

− i ac ,
(6)

950

W.N. Gansterer et al.

In the IR variant, a COT GIR has to be determined such that
a + ib
c

GIR
With z = s

a
c

d + ie
0

.

+ i cb , s = 0 arbitrary, the COT is given as
GIR =

3.2

=

a2

−

b2

1
+ c2 + i(2ab)

a + ib c
−c
a + ib

.

(7)

Numerical Aspects

In a splitting method, the complex orthogonal transformations (5) are the only
non-unitary transformations, all other transformations used have unit norm. If
1 the accuracy of the tridiagonalization process could be inﬂuenced
G 2
negatively. G is a normal matrix, and thus its spectral norm is given by its
largest eigenvalue in modulus:
G

2

=

1+γ
1−γ

1/4

with

γ=

z12

2|z2 s|
.
+ z22 + s2

(8)

If γ approaches one, the accuracy of the tridiagonalization process may deteriorate. For GRI and GIR , respectively, γ in (8) becomes
γRI =

2|ac|
,
a 2 + b 2 + c2

γIR =

2|bc|
.
a 2 + b 2 + c2

We observe that the freedom in choosing the parameter s does not help in controlling the norm of the COT, since γRI and γIR are independent of s. During
the tridiagonalization process, monitoring the norms of the COTs makes it possible to detect potentially large errors. Various strategies have been suggested
to avoid large norms, such as the recovery transformations proposed in [3].
Adaptive Elimination Order. The order of processing R and S can be determined independently in each iteration of the tridiagonalization process. For
both variants, the norm of each COT can be precomputed with only marginal
overhead. Based on this information, the COT with the smaller norm can be selected and the corresponding variant carried out. Obviously, this heuristic choice
is only a local minimization and there is no guarantee that it minimizes the accumulated norm of all COTs in the tridiagonalization process. Comparison to
and combination with recovery transformations are topics of ongoing work.

4

Experimental Evaluation

In our experiments, we used the following routines: zsysta reduces a generalized
ˆ B)
ˆ to a standard EVP (A), and zsyevv solves the standard complex
EVP (A,

Tridiagonalizing Complex Symmetric Matrices in Waveguide Simulations

951

symmetric EVP. The latter consists of a newly implemented RI tridiagonalization
(zsytridi), compev [15] for computing eigenvalues and inverm [15] for computing corresponding eigenvectors of the complex symmetric tridiagonal. zsyevg
tests the accuracy of the tridiagonalization process by ﬁrst calling zsytridi,
followed by a call of LAPACK/zgeev on the resulting tridiagonal matrix.
The codes were run on a Sun Fire v40z with 4 dual-core Opteron 875 CPUs
(2.2 GHz) and 24 GB main memory. Suse Linux Enterprise Server 10, the GNU
Fortran 95 compiler, Lapack version 3.1.1, Goto Blas 1.20, and the AMD
Core Math Library (Acml 4.0.1) were used. We experimented with random test
matrices with elements in [0, 2] as well as with a real application case.
4.1

Numerical Accuracy

Denoting with (λi , xi ) the eigenpairs computed by LAPACK/zgeev, and with
˜i, x
˜i ) the eigenpairs computed by zsyevv, an eigenvalue error E and a residual
(λ
error R have been computed according to
E := max
i

˜ i − λi |
|λ
,
|λi |

R = max
i

˜ i In )˜
||(A − λ
xi ||2
,
||A||2

i ∈ {1, . . . , n} .

Fig. 1 illustrates that the loss of accuracy in the tridiagonalization process itself
is surprisingly low ! Although the total values of E and R of zsyevv increase up
to 10−6 , most of this error is due to the Lanczos variant used for solving the
tridiagonal problem. The error introduced by the RI tridiagonalization is only
about two orders of magnitudes higher than the one of LAPACK/zgeev.
1D Waveguide Problem. The waveguide structure is a Si/SiOx twin waveguide
operated in TM-polarization at a wavelength λ0 = 1.55 μm. The dielectric constants are εSi = 12.96 and εSiOx = 2.25. The core thickness and -separation
are 0.5 μm and 0.25 μm, respectively. The z-extension of the model domain,
terminated by electrically perfectly conducting walls, is 10 μm. The PML-layer
thickness is 1 μm with the PML-parameter σ = 1. As shape functions, localized
linear hat functions and polynomial bubble functions with a degree up to 24
were used.
For reducing the generalized problem (4) to standard form, we computed a
ˆ With ||B
ˆ − F F T ||2 =
generalized (complex) symmetric Cholesky factor F of B.
−16
1.8 · 10 , the accuracy of this factorization is satisfactory for our test case.
The eigenpairs (λi , xi ) of the resulting standard problem computed using Gnu
˜i, x
Octave were compared with the eigenpairs (λ
˜i ) computed by our routine
zsyevv. Backtransformation of the eigenvectors leads to a weighted residual
error
˜i B)˜
ˆ yi ||2
||(Aˆ − λ
max
= 3.8 · 10−14 ,
ˆ
ˆ 2
i=1,...,n
||A||2 ||B||
ˆ 2 = 928, ||B||
ˆ 2 = 2).
which is a very satisfactory accuray (for this test case, ||A||

952

W.N. Gansterer et al.

1e-05
R (zsyevv)
E
R (zsyevg)
R (LAPACK/zgeev)

1e-06
1e-07
1e-08
1e-09
1e-10
1e-11
1e-12
1e-13
1e-14
100

500

1000

2000

3000

4000

Order n of eigenproblem Ax = λx
Fig. 1. Accuracy of zsyevv, LAPACK/zgeev, and zsyevg operating on random matrices

4.2

Runtime Performance

We compared our routine zsyevv to LAPACK/zgeev using two diﬀerent implementations of the Blas. Fig. 2 shows that the current version of zsyevv is faster
than zgeev only if the Acml Blas is used. With the overall faster Goto Blas,
zgeev outperforms our implementation. At ﬁrst sight, this result is disappointing. Despite the exploitation of the structure, the new routine is slower than the
more general routine for nonsymmetric problems for the best Blas available.
A more detailed analysis helps to pinpoint the reason. Table 1 shows the
percentages of the total runtimes which each of the two routines spent in their
diﬀerent parts for the two diﬀerent Blas versions. For our routine zsyevv, the
tridiagonalization part zsytridi clearly dominates the computation time for all
problem sizes and for both Blas versions. This shows that our current code
zsytridi is unable to take advantage of the faster Goto Blas. Three diﬀerent
parts of LAPACK/zgeev have been timed separately: zgehrd reduces the complex matrix A to upper Hessenberg form, zhseqr computes the eigenvalues of
the Hessenberg matrix, and ztrevc computes corresponding eigenvectors. The
runtime for all other code parts of LAPACK/zgeev is summed under “rest”. The
picture here is quite diﬀerent. For the Acml Blas, the operations on the Hessenberg matrix clearly dominate for all problem sizes, whereas for the faster Goto
Blas, the percentages for the three dominating parts become very similar for
large problem sizes.
Summarizing, we observe that our current code cannot utilize a faster Blas.
This is not surprising, since so far it is dominated by Level 2 Blas operations
and more eﬀort is needed to increase the fraction of Level 3 Blas operations.

Tridiagonalizing Complex Symmetric Matrices in Waveguide Simulations

953

10000

Runtime [s]

1000
100
10
zgeev/ACML
zsyevv/ACML
zsyevv/Goto
zgeev/Goto

1
0.1
0.01
100

500

1000

2000

3000

4000

Order n of eigenproblem Ax = λx
Fig. 2. Runtimes of zsyevv and LAPACK/zgeev operating on random matrices
Table 1. Percentages of runtimes spent in parts of zsyevv and LAPACK/zgeev
zsyevv
LAPACK/zgeev
n zsytridi compev inverm zgehrd zhseqr ztrevc
500
87.2
6.5
6.3
8.1
82.6
6.2
Acml 2000
93.9
1.5
4.6
7.2
84.2
6.2
4000
94.5
0.8
4.7
4.4
90.3
3.8

rest
3.1
2.4
1.5

500
Goto 2000
4000

5.9
7.8
9.7

BLAS

5

87.3
92.7
93.7

6.5
1.9
1.0

6.2
5.4
5.3

15.3
22.7
28.6

66.9
50.6
37.8

12.0
18.9
23.9

Conclusions and Future Work

Motivated by application problems arising in optoelectronics, a tridiagonalization process for complex symmetric matrices based on complex orthogonal transformations has been investigated. Compared to the standard Lapack routine for
nonsymmetric eigenproblems, the loss of numerical accuracy caused by the potentially instable tridiagonalization process is surprisingly low in practice. However, partly in contrast to results published earlier [16], the performance beneﬁts
achieved are not yet satisfactory, especially for highly optimized Blas.
The eﬀort summarized here motivates various further research activities.
Methodologically, the performance results indicate the need for blocked approaches. This suggests that non-splitting methods, where A is not split into
real and imaginary part, can be an attractive alternative. For the optoelectronics
problem, the matrices in (4) can be made banded in some situations by choosing
appropriate shape functions. This motivates the investigation of eﬃcient algorithms for generalized banded complex symmetric eigenvalue problems.

954

W.N. Gansterer et al.

References
1. Horn, R.A., Johnson, C.R.: Matrix Analysis. Cambridge University Press, Cambridge (1985)
2. Ohnami, K., Mikami, Y.: Resonance scattering in a two-dimensional non-integrable
system. J. Phys. A 25, 4903–4912 (1992)
3. Bar-On, I., Ryaboy, V.: Fast diagonalization of large and dense complex symmetric matrices, with applications to quantum reaction dynamics. SIAM J. Sci.
Comput. 18, 1412–1435 (1997)
4. Leung, A.Y.T., Liu, Y.F.: A generalized complex symmetric eigensolver. Comput.
and Structures 43, 1183–1186 (1992)
5. Cullum, J.K., Willoughby, R.A.: A practical procedure for computing eigenvalues
of large sparse nonsymmetric matrices. In: Cullum, J.K., Willoughby, R.A. (eds.)
Proceedings of the IBM Europe Institute Workshop on Large Scale Eigenvalue
Problems, pp. 193–223. North-Holland, Amsterdam (1986)
6. Arbenz, P., Hochstenbach, M.E.: A Jacobi–Davidson method for solving complex
symmetric eigenvalue problems. SIAM J. Sci. Comput. 25(5), 1655–1673 (2004)
7. Luk, F., Qiao, S.: Using complex-orthogonal transformations to diagonalize a complex symmetric matrix. In: Luk, F.T. (ed.) Advanced Signal Processing: Algorithms, Architectures, and Implementations VII, Proc. SPIE., vol. 162, pp. 418–425
(1997)
8. Cullum, J.K., Willoughby, R.A.: A QL procedure for computing the eigenvalues of
complex symmetric tridiagonal matrices. SIAM J. Matrix Anal. Appl. 17, 83–109
(1996)
9. Sudbo, A.S.: Film mode matching: A versatile numerical method for vector mode
ﬁeld calculations in dielectric waveguides. Pure and Appl. Optics 2, 211–233 (1993)
10. Franza, O.P., Chew, W.C.: Recursive mode matching method for multiple waveguide junction modeling. IEEE Trans. Microwave Theory Tech. 44, 87–92 (1996)
11. Bienstman, P., Baets, R.: Optical modelling of photonic crystals and VCSELs
using eigenmode expansion and perfectly matched layers. Optical and Quantum
Electronics 33, 327–341 (2001)
12. Finger, N., Pacher, C., Boxleitner, W.: Simulation of Guided-Wave Photonic Devices with Variational Mode-Matching, April 2007. American Institute of Physics
Conference Series, vol. 893, pp. 1493–1494 (2007)
13. Teixeira, F.L., Chew, W.C.: General closed-form PML constitutive tensors to
match arbitrary bianisotropic and dispersive linear media. IEEE Microwave Guided
Wave Lett. 8, 223–225 (1998)
14. Anderson, E., Bai, Z., Bischof, C.H., Blackford, S., Demmel, J.W., Dongarra, J.J.,
Du, C.J., Greenbaum, A., Hammarling, S., McKenney, A., Sorensen, D.C.: Lapack
Users’ Guide, 3rd edn. SIAM Press, Philadelphia (1999)
15. Cullum, J.K., Willoughby, R.A.: Lanczos Algorithms for Large Symmetric Eigenvalue Computations, vol. 1. Theory, vol. 2. Programs, Birkh¨
auser, Boston, MA
(1985)
16. Bar-On, I., Paprzycki, M.: High performance solution of the complex symmetric
eigenproblem. Numerical Algorithms 18, 195–208 (1998)

