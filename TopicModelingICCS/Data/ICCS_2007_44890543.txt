A Model of Facial Expression for 3D Avatar
Zhen Liu
Faculty of Information Science and Technology, Ningbo University,
315211, China
liuzhen@nbu.edu.cn

Abstract. Modeling 3D avatar is very useful in e-learning software, a believable 3D avatar can have complex facial expression, and how to construct complex facial expression is a very interesting topic. The concept of emotion vector
is presented. Emotion state of a 3D avatar can be transformed to an emotion
vector that is calculated by basic emotion vector. The concept of expression
vector is established, expression can be transformed to expression vector that is
calculated by basic expression vector. Emotion mapping is set up from emotion
vector space to expression vector space. A preliminary experiment is carried on
microcomputer.
Keywords: emotion, emotion vector, emotion synthesis.

1 Introduction
Modeling 3D avatar is very useful in e-learning software, a believable 3D avatar can
have complex facial expression, and how to construct complex facial expression is a
very interesting topic.
Parke first presented the research paper on facial animation [1], and there are many
methods of facial animation in now days. The prior research mainly concentrated on
driving some local movements of face effectively, and little on whole movement of
face. For example, the physical model is an effective method of controlling muscle’s
movement on face, the relation between muscle movement and facial expression’s
semantic information is not clear. Some methods emphasized on synthesis of facial
expression by local movement, Ekman first proposed the famous FACS system that
can describe facial expression by Action Units [1], but the method has many limitations for synthesis of complex expression. Noh et al. presented an ingenious technique to clone expression vector from one character to another, the purpose utilizes
existing expression information, but it cannot create new expression [2]. However, the
interpolation technique of facial expression can utilize whole information of the face
effectively [3], it only produces little new expression and lacks the quantitative description of the emotion meaning.
A synthesis model of emotion is presented on basic emotion in this paper, the
model attempts to set up a formal description of complex emotion according to each
intensity of basic emotion.
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 543–546, 2007.
© Springer-Verlag Berlin Heidelberg 2007

544

Z. Liu

2 A Computational Model of Emotion Synthesis
For a certain 3D avatar, BE is a basic emotion class set, BE={be1, …… ,beN}, i ∈ [1,
N], bei is a basic emotion (such as happiness). N is the number of basic emotion class.
EIi(t) is the intensity of bei. EIi(t) ∈ [0, 1], t is time variable. bei is the unit vector of
bei.. For example, be1={1,…,0}, beN={0,…,1}. Let E is emotion state, E is represented emotion vector of E, the projection length of E on bei is EIi(t). E can be represented as formula (1):
N

E=

∑

EIi(t) bei .

(1)

i =1

Let E1 and E2 are two emotion vectors, the synthesis of E1 and E2 is represented as E1
+ E2. There is a formula (2).
N

E1 + E2 =

∑

[EIi1(t) bei1 + EIi2(t) bei2].

(2)

i =1

Let EP is the set of all emotion vectors, if any element of EP satisfies to formula
(1)(2), EP is called emotion vector space, bei is called the basic emotion vector.
A face’s geometry model is described by polygons, the location of any vertex can
be represented as vector vk , k ∈ [0, L], L is the number of all vertex. Let V is a vector
for all vertex, V is called expression vector. V is represented as formula (3).
V =( v1 ,……,vL ) .

(3)

In general, there are some expression vector, pn is the number of expression vector, Vi
is an expression vector, i ∈ [0, pn ], SY is an synthesis function among all Vi, FV is
calculated by formula (4):
(4)

FV = SY (V1,……, Vpn).

In general, EP is emotion vector space, FV is called expression vector space, T is a
emotion function from EP to FV, for any E ∈ EP, T (E) ∈ FV. Let bei is a unit vector, i ∈ [1, N], T (bei ) is called base expression vector. If pn=N, FV is calculated by
formula (5):
FV = SY (T (be1 )1,……, T (beN )).

(5)

In order to simplify the formula (5), let SY is linear function, λ i is the corresponding interpolation function of Vi , the sum of all λ i is equal to 1, let λ i= EIi, FV is
calculated by formula (6):
N

FV =

∑
i =1

( EIi) T (bei ).

(6)

A Model of Facial Expression for 3D Avatar

545

3 A Demo of Complex Facial Expression
A demo of synthesis on expression by formula (6) is realized on pc, the programming
tools are Visual c++ language and Direct3D API. In the demo, only six basic facial
expressions are selected. Six basic facial expressions are shown in Fig.1, some of
synthesis results are shown in Fig. 2. For example, in Fig. 2(1), “1/2 happiness+1/2
sadness” is represented the synthesis of happiness and sadness, each emotion intensify
is equal to 1/2.

Fig. 1. Six basic facial expressions

Fig. 2. (1)1/2happiness+1/2sadness;(2)1/2sadness+1/2anger;(3)1/2surprise+1/2disgust;(4)1/3happiness
+1/3fear+1/3disgust;(5)1/3sadness+1/3disust+1/3anger;(6)1/3happiness+1/3sadness+1/ 3anger

4 Conclusion and Future Work
A model of facial expression for 3D avatar is presented in this paper. The paper improves the interpolation technique of facial expression. The concept of emotion vector
space is introduced, and a basic emotion can be regarded as a unit vector in emotion
vector space. The concept of expression vector space is also introduced, and an expression vector can describe a facial expression. An emotion function can transform a
basic emotion to a base vector in expression vector space. In order to simplify an

546

Z. Liu

emotion function, an expression vector can be described by linear combination of
base vector. A preliminary experiment indicates that basic emotion can produce many
new emotions.

Acknowledgements
The work described in this paper was co-supported by science and technology project
of Zhejiang Province Science Department (grant no: 2006C33046), forepart professional research of ministry of science and technology of the People’s Republic of
China (grant no: 2005cca04400), University Research Project of Zhejiang Province
Education Department (grant no: 20051731).

References
1. Parke, F.I., Waters,K.: computer facial animation, Wellesley, Boston, USA: AK Perters
(1996)
2. Noh, Jun-yong, and Ulrich Neumann. Expression Cloning, In Proceedings of ACM
SIGGRAPH2001 Conference (2001) 277-288
3. Blanz, V., Vetter, T.: A Morphable Model for the Synthesis of 3D Faces, In Proceedings of
ACM SIGGRAPH 99 Conference (1999) 187–194

