A Sparse Parallel Hybrid Monte Carlo
Algorithm for Matrix Computations
Simon Branford, Christian Weihrauch, and Vassil Alexandrov
Advanced Computing and Emerging Technologies Centre,
School of System Engineering,
The University of Reading
Whiteknights, P.O. Box 225
Reading, RG6 6AY, UK
{s.j.branford, c.weihrauch, v.n.alexandrov}@reading.ac.uk

Abstract. In this paper we introduce a new algorithm, based on the successful work of Fathi and Alexandrov, on hybrid Monte Carlo algorithms
for matrix inversion and solving systems of linear algebraic equations.
This algorithm consists of two parts, approximate inversion by Monte
Carlo and iterative reﬁnement using a deterministic method.
Here we present a parallel hybrid Monte Carlo algorithm, which uses
Monte Carlo to generate an approximate inverse and that improves the
accuracy of the inverse with an iterative reﬁnement. The new algorithm
is applied eﬃciently to sparse non-singular matrices. When we are solving
a system of linear algebraic equations, Bx = b, the inverse matrix is used
to compute the solution vector x = B −1 b.
We present results that show the eﬃciency of the parallel hybrid
Monte Carlo algorithm in the case of sparse matrices.
Keywords: Monte Carlo Method, Matrix Inversion, Sparse Matrices.

1

Introduction

The problem of inverting a real n×n matrix (MI) or solving a system of linear algebraic equations (SLAE) is of unquestionable importance in many scientiﬁc and
engineering applications: e.g real-time speech coding, digital signal processing,
communications, stochastic modelling, and many physical problems involving
partial diﬀerential equations. The direct methods of solution require O(n3 ) sequential steps when using the usual elimination or annihilation schemes (e.g.
non-pivoting Gaussian elimination, Gauss-Jordan methods) [10]. Consequently
the computation time for very large problems, or for real-time solution problems,
can be prohibitive and this prevents the use of many established algorithms.
It is known that Monte Carlo methods give statistical estimates for elements
of the inverse matrix, or for components of the solution vector of SLAE, by
performing random sampling of a certain random variable, whose mathematical expectation is the desired solution [11, 13]. We concentrate on Monte Carlo
methods for MI and/or solving SLAE, since, first, only O(N T ) steps are required to ﬁnd an element of the inverse matrix or component of the solution
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3516, pp. 743–751, 2005.
c Springer-Verlag Berlin Heidelberg 2005

744

S. Branford, C. Weihrauch, and V. Alexandrov

vector of SLAE (where N is the number of chains and T is an estimate of the
chain length in the stochastic process, both of which are independent of n, the
size of the matrix) and, second, the sampling process for stochastic methods is
inherently parallel.
Coarse grained Monte Carlo algorithms for MI and SLAE have been proposed by several authors [2, 3, 6, 7, 8, 9]. In this paper we will explore a parallel
sparse algorithm for inverting diagonally dominant matrices. We will show that
this algorithm works eﬀectively and eﬃciently when deployed over multiple processors.
The idea of Monte Carlo for matrix computations is presented in Section 2;
the parallel hybrid algorithm is described in Section 3; in Section 4 we detail how
we implemented the algorithm for sparse matrices; the results of the experimental
runs of this implementation are presented in Section 5; and we conclude the work
in Section 6.

2

Monte Carlo Matrix Computations

Assume that the system of linear algebraic equations (SLAE) is presented in the
form:
Bx = b
(1)
where B is a real square n × n matrix, x = (x1 , x2 , ..., xn )t is a 1 × n solution
vector and b = (b1 , b2 , ..., bn )t .
Assume the general case B > 1. We consider the splitting
ˆ −C
B=B

(2)

ˆ are the same as those of B, and the diagonal
where oﬀ-diagonal elements of B
ˆ are deﬁned as ˆbii = bii + γi ||B||, choosing in most cases γi > 1 for
elements of B
ˆ = B1 − B2 where B1 is the diagonal matrix
i = 1, 2, ..., n. We further consider B
ˆ
ˆ
of B, e.g. (b1 )ii = bii for i = 1, 2, ..., n. As shown in [9] we could transform the
system (1) to
x = Tx + f
(3)
−1
−1
ˆ C and f = B
ˆ b. The multipliers γi are chosen so that, if it
where T = B
is possible, they reduce the norm of T to be less than 1 and thus reducing the
number of Markov chains required to reach a given precision. We consider two
possibilities, ﬁrst, ﬁnding the solution of x = T x + f using Monte Carlo (MC)
ˆ −1 using MC and after that ﬁnding B −1 . Then,
method if T < 1 or ﬁnding B
if required, obtaining the solution vector is x = B −1 b.
Consider ﬁrst the stochastic approach. Assume that T < 1 and that the
system is transformed to its iterative form (3). Consider the Markov chain given
by:
(4)
s0 → s1 → · · · → sk ,
where the si , i = 1, 2, · · · , k, belongs to the state space S = {1, 2, · · · , n}. Then
for α, β ∈ S, p0 (α) = p(s0 = α) is the probability that the Markov chain starts at

A Sparse Parallel Hybrid Monte Carlo Algorithm

745

state α and p(sj+1 = β|sj = α) = pαβ is the transition probability from state α
to state β.The set of all probabilities pαβ deﬁnes a transition probability matrix
P = {pαβ }nα,β=1 [1, 2, 3].
We say that the distribution (p1 , · · · , pn )t is acceptable for a given vector
g, and that the distribution pαβ is acceptable for matrix T , if pα > 0 when
gα = 0, and pα ≥ 0, when gα = 0, and pαβ > 0 when Tαβ = 0, and pαβ ≥ 0
n
when Tαβ = 0 respectively. We assume β=1 pαβ = 1, for all α = 1, 2, · · · , n.
Generally, we deﬁne
Ts s
W0 = 1, Wj = Wj−1 j−1 j
(5)
psj−1 sj
for j = 1, 2, · · · , n.
Consider now the random variable θ[g] =
ing notation for the partial sum:
θi [g] =

g s0
ps0

∞
i=1

Wi fsi . We use the follow-

i

gs 0
ps 0

Wj fsj .

(6)

j=0

Under condition T < 1, the corresponding Neumann series converges for any
given f , and Eθi [g] tends to (g, x) as i → ∞ . Thus, θi [g] can be considered as
an estimate of (g, x) for i suﬃciently large. To ﬁnd an arbitrary component of
the solution, for example, the r th component of x, we should choose, g = e(r) =
(0, ..., 1, 0, ..., 0) such that
r

e(r)α = δrα =
It follows that

1
0

if
r=α
otherwise

(7)

n

e(r)α xα = xr .

(g, x) =

(8)

α=1

The corresponding Monte Carlo method is given by:
ˆ= 1
xr = Θ
N

N

θi [e(r)]s

(9)

s=1

where N is the number of chains and θi [e(r)]s is the approximate value of xr in
the s th chain. It means that using Monte Carlo method, we can estimate only
one, few or all elements of the solution vector. We consider Monte Carlo with
uniform transition probability (UM) pαβ = n1 and almost optimal Monte Carlo
|Tαβ |
method (MAO) with pαβ =
, where α, β = 1, 2, . . . , n. Monte Carlo
n
|T |
β=1

αβ

MI is obtained in a similar way [1].
(−1)
To ﬁnd the inverse M −1 = {mrr }nr,r =1 of some matrix M , we must ﬁrst
compute the elements of matrix A = I − M , where I is the identity matrix.

746

S. Branford, C. Weihrauch, and V. Alexandrov

Clearly, the inverse matrix is given by
M −1 =

∞

Ai

(10)

i=0

which converges if A < 1 .
(−1)
To estimate the element mrr of the inverse matrix M −1 , we let the vector
f be the following unit vector
(11)
fr = e(r )
We then can use the following Monte Carlo method for calculating elements
of the inverse matrix M −1 :
⎡
⎤
N
1
(−1)
⎣
mrr ≈
(12)
Wj ⎦
N s=1
(j|sj =r )

where (j|sj = r ) means that only
Wj =

Ars1 As1 s2 . . . Asj−1 sj
prs1 ps1 s2 . . . psj−1 pj

(13)

for which sj = r are included in the sum (12).
Since Wj is included only into the corresponding sum for r = 1, 2, . . . , n,
then the same set of N chains can be used to compute a single row of the inverse
matrix, which is one of the inherent properties of Monte Carlo making them
suitable for parallelisation.
The probable error of the method, is deﬁned as rN = 0.6745 Dθ/N , where
P {|θ¯ − E(θ)| < rN } ≈ 1/2 ≈ P {|θ¯ − E(θ)| > rN }, if we have N independent
realizations of random variable (r.v.) θ with mathematical expectation Eθ and
average θ¯ [11].
ˆ − C. From this
In the general case, B > 1, we make the initial split B = B
−1
ˆ we
we compute A = B1 B2 , which satisﬁes A < 1 (by careful choice, of B,
make A < 0.5, which gives faster convergence). Then we generate the inverse
ˆ by (12) and from this we recover B −1 , using an iterative process.
of B

3

Hybrid Algorithm for Matrix Inversion

In this paper we consider diagonally dominant matrices, which means that the
ﬁrst split (2) of the input matrix and the recovery process are not required.
Further we consider a hybrid algorithm [8], which uses an iterative reﬁnement
to improve the accuracy of the inverse generated by the Monte Carlo method.
The iterative reﬁnement works on the Monte Carlo generated inverse to improve the accuracy. We set D0 = B −1 , where B −1 is the Monte Carlo generated
inverse. The iterative process is Ri−1 = I − Di−1 B and Di = (I + Ri−1 )Di−1
(for i = 1, 2, . . .), which continues until Ri−1 < γ.

A Sparse Parallel Hybrid Monte Carlo Algorithm

3.1

747

Hybrid Monte Carlo Algorithm

1: Read in matrix B and broadcast to all processes
1 Input matrix B, parameters , δ and γ
2 Broadcast matrix B, and parameters , δ and γ, to all processes
2: Calculate intermediate matrices (B1 , B2 )
1 Split B = B1 − B2 , where B1 = diag(B) and B2 = B1 − B
3: Calculate matrix A and norm
1 Compute the matrix A = B1−1 B2
2 Compute A and the number of Markov Chains N =

0.6745
(1− A )

2

4: Calculate matrix P
1 Compute the probability matrix, P
5: Calculate matrix M , by MC on A and P
1 Broadcast matrices A and P , and parameters , δ and γ
2 For i = procstart to procstop (where procstart and procstop are calculated
to evenly distribute the work between the available processors)
2.1 For j = 1 to N
Markov Chain Monte Carlo Computation
2.1.1 Set W0 = 1, SU M [k] = 0 for k = 1, 2, . . . , n and point = i
2.1.2 Generate a random nextpoint, selected based on the probabilities
in row point
2.1.3 If A[point][nextpoint] = 0 then goto 2.1.2, else continue
A[point][nextpoint]
2.1.4 Compute Wj = Wj−1 P
[point][nextpoint]
2.1.5 Set SU M [nextpoint] = SU M [nexpoint] + Wj
2.1.6 If |Wj | > δ set point = nextpoint and goto 2.1.2
2.2 End of loop j
M [k]
for k = 1, 2, . . . , n
2.3 Then mik = SUN
3 End of loop i
ˆ −1
6: Calculate B
1 Compute the Monte Carlo inverse B −1 = M B1−1
2 The master process collects the parts of B −1 from the slaves
7: Iterative Refinement
1 Broadcast matrix B
2 Set D0 = B −1 and i = 1
2.1 Broadcast matrix Di−1
2.2 Calculate procstart to procstop rows of Ri−1 and Di using the iterative
reﬁnement Ri−1 = I − Di−1 B and Di = (I + Ri−1 )Di−1
2.3 The master process collects the parts of Di from the slaves
2.4 If Ri−1 ≥ γ set i = i + 1 and goto 2.1
8: Save Inverse
1 The inverse is B −1 = Di

748

4

S. Branford, C. Weihrauch, and V. Alexandrov

Implementation

Sparse matrices are common to many scientiﬁc problems. In these a typical MI
or SLAE problem will have a matrix with a handful of non-zero elements in a
row of size in the tens of thousands (or greater). In this work, while considering
sparse matrices, we have used the compressed sparse row (CSR) matrix format.
We implemented the Monte Carlo (Step 5 ) and the iterative reﬁnement (Step
7 ) of the hybrid Monte Carlo method in parallel, since these are the most computationally intensive steps in the algorithm (Section 3.1). The master starts by
computing Step 1 to Step 4 , which is the serial part of the algorithm. For matrix
P only the values array is generated, since the row and the column array are
identical to those for matrix A.
Each processing element (PE), including the master, computes an evenly
distributed part of rows of the solution matrix B −1 , during the Monte Carlo,
Step 5. Therefore the matrices A, P and B1 (which is stored as a vector, since
it is a diagonal matrix) are broadcast to all PE’s. These are used by the PE’s to
compute part of B −1 and then the master collects these matrix parts together.
The master starts the iterative reﬁnement, Step 7 , by sending matrices B and
Di−1 to the slaves. Each PE computes an evenly distributed number of rows of
Ri−1 , and then uses this to compute the corresponding rows of Di . The PE’s also
calculate norm of the part of Ri−1 it has calculated. The master then collects
the parts of Di together and calculates Ri−1 , which it uses to decide if the
result of the reﬁnement stage is accurate enough. If not then another iteration
is performed.

5

Results

For the experiments we generated diagonally dominant banded matrices, with 5
non-zero elements deﬁned on either side of the leading diagonal. The oﬀ-diagonal
elements were generated randomly, with the leading diagonal elements selected
to give A ≈ 0.5.
We used eight Dual Intel R XeonTM 2.8 GHz nodes, each equipped with 512
KB second level cache and 1 GB main memory, and connected via a switched 1
Gbit network. For the experimental runs only one processor per node was used.
LAM-MPI [4, 12] was used for the interprocess communication.
For the calculations ﬂoating point accuracy has been used, since this provides
enough signiﬁcant ﬁgures in the workings to generate an inverse with the required
(10−2 ) accuracy (measured by I −BDi , where Di is the ﬁnal inverse generated
by the parallel hybrid algorithm).
The value for δ, one of the input parameters, was
√ picked to keep T , the
average length of the Markov Chains, about equal to N . This produces good
results from the Monte Carlo calculations [5], without generating non-necessary
elements for the Markov Chain.

A Sparse Parallel Hybrid Monte Carlo Algorithm
5

100
250
500
1000
2000
3000
4000
5000
6000
7000
8000
9000
10000
12500
15000
17500
20000

4.5
4
3.5
Speedup

749

3
2.5
2
1.5
1
1

2

3

4
5
Number of Processors

6

7

8

Fig. 1. Speedup of Parallel Hybrid Monte Carlo

As can be seen in Figure 1, for the majority of the matrix sizes we tested there
is a speedup of 4 to 4.5 when using eight processors. The smaller matrix sizes
(n ≤ 1000) produced worse performance, but in these cases the total running
time was less than a second and this makes the results unreliable.
The eﬃciency of the parallelisation tails oﬀ when using more than four processors. Since the computation time for these problems is small (n = 20000 on
one processor took 31 seconds) the beneﬁts of splitting the work to more than
eight processors will be outweighed by the communication overhead.
Figure 2 shows the percentage of time spent in communication, serial operation and parallel operation when using eight processors for experimental runs
on varying matrix sizes. The results show that the communication overhead decreases as the matrix size increases, with a greater amount of time being spent
in both serial and parallel computations.

1

0.8
Parallel
0.6

0.4

0.2

Communication
Serial

0
2000

4000

6000

8000
10000 12000
Size of Matrix

14000

16000

18000

20000

Fig. 2. Communication and Computation Time on Eight Processors

750

S. Branford, C. Weihrauch, and V. Alexandrov

The communication overhead does not decrease as quickly as could be expected since the amount of calculation, in relation to the communication overhead, does not increase by that much as the matrix size grows. This is because
the matrices used for these experiments contain the same number of non-zero
elements in each row, which means that the sparsity increases linearly with the
dimension of the matrix.

6

Conclusion

We found that our implementation achieves a reasonably good speedup. The
sparse parallel algorithm, described in section 3.1, makes eﬀective use of the available processors to invert the matrix. The communication overhead gets smaller
as the matrix size increases, with a greater percentage of the time being spent
in parallel and serial.
We could improve the eﬃciency by calculating a more accurate inverse, which
would mean more time required for the Monte Carlo or iterative reﬁnement
steps with little increase in the communication needed. Also to be considered is
the eﬀectiveness of the algorithm on larger dimensions and matrices of varying
sparsity.

References
1. V.N. Alexandrov. Eﬃcient Parallel Monte Carlo Methods for Matrix Computation. In Mathematics and Computers in Simulation, number 47, pages 113–122,
Netherlands, 1998. Elsevier.
2. V.N. Alexandrov and A. Karaivanova. Parallel Monte Carlo Algorithms for Sparse
SLAE Using MPI. In LNCS 1697, pages 283–290. Springer, 1999.
3. V.N. Alexandrov, A. Rau-Chaplin, F. Dehne, and K. Taft. Eﬃcient Coarse Grain
Monte Carlo Algorithms for Matrix Computation Using PVM. In LNCS 1497,
pages 323–330. Springer, August 1998.
4. G. Burns, R. Daoud, and J. Vaigl. LAM: An Open Cluster Environment for MPI.
In Proceedings of Supercomputing Symposium, pages 379–386, 1994.
5. I.T. Dimov and V.N. Alexandrov. A New Highly Convergent Monte Carlo Method
for Matrix Computations. In Mathematics and Computers in Simulation, number 47, pages 165–181, Netherlands, 1998. Elsevier.
6. I.T. Dimov, V.N. Alexandrov, and A. Karaivanova. Resolvent Monte Carlo Methods for Linear Algebra Problems. In Mathematics and Computers in Simulation,
number 155, pages 25–36, Netherlands, 2001. Elsevier.
7. I.T. Dimov, T.T. Dimov, and T.V. Gurov. A New Iterative Monte Carlo Approach
for Inverse Matrix Problem, 1998.
8. B. Fathi Vajargah and V.N. Alexandrov. Coarse Grained Parallel Monte Carlo Algorithms for Solving Systems of Linear Equations with Minimum Communication.
In in Proc. of PDPTA, pages 2240–2245, Las Vegas, 2001.
9. B. Fathi Vajargah, B. Liu, and V.N. Alexandrov. Mixed Monte Carlo Parallel
Algorithms for Matrix Computation. In Lecture Notes in Computational Science ICCS 2002, number 2330, pages 609–618, Berlin Heidelberg, 2002. Springer Verlag.

A Sparse Parallel Hybrid Monte Carlo Algorithm

751

10. G.H. Golub and C.F. Van Loan. Matrix Computations. The Johns Hopkins University Press, Baltimore and London, third edition, 1996.
11. I.M. Sobol. Monte Carlo Numerical Methods. Nauka, Moscow, 1973. (in Russian).
12. J.M. Squyres and A. Lumsdaine. A Component Architecture for LAM/MPI. In
Proceedings, 10th European PVM/MPI Users’ Group Meeting, number 2840 in
Lecture Notes in Computer Science, pages 379–387, Venice, Italy, September /
October 2003. Springer-Verlag.
13. J.R. Westlake. A Handbook of Numerical Matrix Inversion and Solution of Linear
Equations. Wiley, New York, 1968.

