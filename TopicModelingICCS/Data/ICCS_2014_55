Procedia Computer Science
Volume 29, 2014, Pages 390–399
ICCS 2014. 14th International Conference on Computational Science

Benchmarking and Data Envelopment Analysis. An
Approach Based on Metaheuristics
Jose J. L´opez-Esp´ın1 , Juan Aparicio1 , Domingo Gim´enez2 , and Jes´
us T. Pastor1
1

Centro de Investigaci´
on Operativa, Miguel Hern´
andez University, Spain
jlopez@umh.es, j.aparicio@umh.es, jtpastor@umh.es
2
Departamento de Inform´
atica y Sistemas, University of Murcia, Spain
domingo@um.es

Abstract
Data Envelopment Analysis (DEA) is a non-parametric technique for estimating technical efﬁciency of a set of units. DEA also provides information on benchmarking. In this paper, we
study DEA models based on closest eﬃcient targets, which are associated with the least distance and allow ineﬃcient units to ﬁnd the easiest way to achieve the eﬃcient frontier. In the
literature these models have been solved through unsatisfactory methods related to combinatorial NP-hard problems. In this paper, the problem is approached by metaheuristic techniques.
Due to the high number of restrictions of the problem, ﬁnding solutions to be used in the
metaheuristic algorithm is a diﬃcult problem. Thus, this paper analyzes and compares some
heuristic algorithms to obtain solutions of the problem. Each restriction determines the design
of these heuristics. Thus, the problem is considered by adding constraints one by one. In this
paper, the problem is presented and studied taking into account 9 of the 14 constraints, and the
solution to this new problem is an upper bound of the optimal value of the original problem.
Keywords: Data Envelopment Analysis, Closest targets, Metaheuristics

1

Introduction

In [15] the two main methodologies for estimating technical eﬃciency are shown. They are
stochastic frontiers, which resort to econometric techniques, and Data Envelopment Analysis (DEA), which involves mathematical programming models. In particular, DEA is a nonparametric technique based on mathematical programming for the evaluation of technical eﬃciency of a set of decision making units (DMUs) that consumes inputs to produce outputs [17].
An advantage of DEA in contrast to stochastic frontiers is that DEA provides simultaneously
both an eﬃciency score and benchmarking information. These two pieces of information are
usually inseparable in DEA. Indeed, the eﬃciency score is obtained from the distance between
the assessed DMU and a point on the frontier of the technology, which serves as eﬃcient target
390

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.035

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

for the evaluated unit. Information on targets can play a relevant role since they indicate keys
for ineﬃcient units to enhance their performance.
Usual DEA models yield eﬃcient targets that are related to the furthest projection to the
assessed unit [5]. Nevertheless, several authors (see, e.g. [5, 28]) argue that the distance to the
eﬃcient projection point should be minimized, instead of maximized, in order to the resulting
targets to be as similar as possible to the observed inputs and outputs of the assessed unit.
The idea behind this is that closest targets suggest directions of improvement for inputs and
outputs that lead to the eﬃciency with less eﬀort than other solutions.
Closest targets are easily attainable and provide the most relevant solution to remove ineﬃciency from the process of production, and additionally their estimation has attracted an
increasing interest of researchers in recent DEA literature. In this respect, see Charnes et
al. [12], Coelli [14], Briec [8], Briec and Lesourd [10], Briec and Lemaire [9], Frei and Harker
´
[19], Cherchye and Van Puyenbroeck [13], Gonz´
alez and Alvarez
[20], Takeda and Nishino [29],
Portela et al. [28], Lozano and Villa [25], Amirteimoori et al. [1], Baek and Lee [6], Pastor and
Aparicio [26], Jahanshahloo et al. [23], Aparicio and Pastor [4], Aparicio and Pastor [2] and
Aparicio and Pastor [3].
Regarding papers that have studied the computational aspects of DEA models related to
the determination of closest targets, we can cite some interesting references: Aparicio et al. [5]
and Jahanshahloo et al. [22, 21, 23, 24]. Some of these approaches are based on Mixed Integer
Linear Programming or Bilevel Linear Pogramming while others are derived from algorithms
that allow the determination of all the facets of a polyhedron. As we will argue in detail in
Section 2, all these approaches present some weaknesses and, as a consequence, currently there
is no approach accepted as the best solution to the problem.
Determining closest targets has been one of the important issues in the recent DEA literature
(see, e.g. Cook and Seiford [16], for a survey on DEA). However, from a computational point
of view, the determination of closest targets is diﬃcult enough and this fact justiﬁes the eﬀort
to apply new methods in order to overcome it.
In this paper, we use several genetic and hybrid metaheuristic algorithms with the aim of
determining closest targets in DEA. In particular, we use the approach introduced by Aparicio
et al. [5], which is based on Mixed Integer Linear Programming, and try to ﬁnd feasible solutions
of the model that these authors introduced by means of metaheuristics. The diﬃculty of the
problem requires us to study the corresponding algorithm by parts, incorporating constraints
while the results are analyzed.
The remainder of the paper is organized as follows: In Section 2, a brief introduction of the
main concepts associated with DEA is presented, and the existing approaches for determining
closest targets are outlined. In Section 3 a genetic algorithm is developed. After that, a random
search is used to improve this algorithm, so obtaining a hybrid metaheuristic. The idea is to
use a random search method in some parts of the genetic algorithm to explore the space of
feasible solutions better. In section 4, the results of some experiments are summarized. Finally,
section 5 concludes the paper and outlines some possible research directions.

2

Data Envelopment Analysis and Closest Targets

Recent years have seen a great variety of applications of DEA for the use in determining the
eﬃciency of many diﬀerent types of entities [17]. DEA models are based on mathematical
programming, whereas stochastic frontiers are based on statistical methods and need the speciﬁcation of a functional form for the production function (such as the Cobb-Douglas form or
the translog). DEA is a non-parametric technique that determines a piece-wise-linear convex
391

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

Figure 1: DEA versus Stochastic frontiers.

technology without specifying a functional form for the production function, constructed such
that no observation of the sample of data lies above it. In Figure 1, we represent a sample of
several DMUs that use one input (X) to produce one output (Y). Each unit is represented by
a point in the ﬁgure. We also show both the Cobb-Douglas function estimated from the data,
if the analyst assumes such functional form, and the piece-wise-linear convex estimation of the
frontier of the technology resorting to DEA.
DEA involves the use of Mathematical Programming to construct the non-parametric piecewise surface over the data. Technical eﬃciency measures associated with the performance of
each unit are then calculated relative to this surface, as a distance to it. Although Farrell
[18] was the ﬁrst to introduce these ideas, the method did not receive wide attention until the
paper by Charnes et al. [11], in which the term data envelopment analysis was coined. Since
then there has been a large number of papers which have extended, adapted and applied this
methodology in the ﬁelds of economics, operations research and management science.
Now, we need to deﬁne some notation. Assume there are data on m inputs and s outputs
for each of n DMUs. For the j-th DMU these are represented by xij ≥ 0, i = 1, . . . , m, and
yrj ≥ 0, r = 1, . . . , s, respectively.
There are a lot of DEA technical eﬃciency measures in the literature. The basic DEA
models are the CCR [11] and the BCC [7]. Both models are based on radial projections to
the production frontier. However, many other approaches give freedom to the projection so
that the ﬁnal eﬃcient targets do not conserve the mix of inputs and outputs. In particular the
Enhanced Russel Graph measure [27] or slacks-based meassure [30] can be calculated for DMU
k, k=1,. . . ,n, as follows:
min
s.t.

1
1− m

1+ 1s

−
s
m
ik
i=1 xik
+
s
s
rk
r=1 yrk

n
j=1 λjk xij
n
j=1 λjk yrj
+
λjk , s−
ik , srk ≥ 0

=
=

xik − s−
ik
yrk + s+
rk

∀i
∀r
∀ i, r
∀j,

(1)

Eq. 1 is a linear fractional program that can be transformed into a linear program by a change
392

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

of variables (see [27]). Speciﬁcally, it is equivalent to the following linear program:
min
s.t.

βk −

1
m

−
m tik
i=1 xik

t+
s
rk
r=1 yrk
n
−βk xik + j=1 αjk xij + t−
ik
n
−βk yrk + j=1 αjk yrj − t+
rk
+
βk , αjk , t−
ik , trk ≥ 0

βk +

1
s

=
=
=

1
0
0

∀i
∀r
∀j, i, r

(2)

The Enhanced Russell Graph measure, deﬁned as the optimal value of Eq. 2, meets a
set of interesting properties from a mathematical and economic point of view. However, it
presents an important drawback. In particular, Eq. 1, or equivalently Eq. 2, yields eﬃcient
targets, points onto the piece-wise frontier, which are far away from the inputs and outputs of
the evaluated DMU k. To illustrate this, note that the targets for this model are deﬁned as
n
n
−
+
j=1 λjk xij = xik − sik for inputs and
j=1 λjk yrj = yrk + srk for outputs and that the slacks,
−
+
sik and srk , appear in the objective function. Consequently, and since we are minimizing, the
model seeks slacks as large as possible and, therefore, Eq. 1 yields the furthest targets for DMU
k with original inputs and outputs (x1k , . . . , xmk , y1k , . . . , ysk ). In order to determine closest
targets instead of furthest targets, it seems enough to change “minimizing” by “maximizing”.
However, it is not true. In this case, we could show that the targets generated by the model
would be not technically eﬃcient but ineﬃcient [5]. And, therefore, they could not serve as
benchmark for the evaluated unit.
This problem was the main reason behind the introduction of diﬀerent approaches to determine closest targets in DEA. A group of the literature [21, 22] focus their work on ﬁnd all the
faces of the polyhedron that deﬁnes a technology estimated by DEA. For example, in Figure
1, we show ﬁve of these faces. The computing time of these algorithms increases signiﬁcantly
as the problem size grows (n+m+s) since this issue is a combinatorial NP-hard problem. A
second group proposes to determine closest targets through Mathematical Programming [5, 24].
In particular, Aparicio et al. [5] introduced the following Mixed Integer Linear Program to solve
the problem for DMU k:
max
s.t.

βk −

−

1
m

−
m tik
i=1 xik

−βk xik +
−βk yrk +
m
i=1 νik xij +

t+
s
rk
r=1 yrk
n
−
j=1 αjk xij + tik
n
+
j=1 αjk yrj − trk
s
r=1 μrk yrj + djk

βk +

αjk

1
s

νik ≥ 1
μrk ≥ 1
djk ≤ M bjk
≤ M (1 − bjk )
bjk = 0, 1
βk ≥ 0
t−
ik ≥ 0
t+
rk ≥ 0
djk ≥ 0
αjk ≥ 0

=
=
=
=

1
0
0
0

(c.1)
(c.2)
(c.3)
(c.4)
(c.5)
(c.6)
(c.7)
(c.8)
(c.9)
(c.10)
∀i (c.11)
∀r (c.12)
∀j (c.13)
∀j (c.14)

∀i
∀r
∀j
∀i
∀r
∀j
∀j

(3)

393

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

As for Eq.3, ﬁrst note that (c.1)-(c.3) are the same constraints than those in Eq. 2, and
it implies that we are considering the same set of feasible points. Note also that the objective
function is maximized in this case instead of minimized. Nevertheless, one drawback of the
approach in Aparicio et al. [5] is that it uses a “big M ” to model the key constraints (c.7) and
(c.8). In particular, it allows linking djk to αjk by means of the binary variable bjk . However,
the value of M may be calculated if and only if we previously calculate all the facets that deﬁne
the technology. Accordingly, this alternative is again associated with a combinatorial NP-hard
problem. In the same manner, Jahanshahloo et al. [24] used a Lineal Bilevel Programming and
a big M to determine closest targets and, therefore, their approach presents the same weakness.
Consequently, from a computational point of view, the determination of closest targets in
DEA has not yet been satisfactorily solved and this fact justiﬁes the eﬀort to apply new methods
in order to solve the problem. In this paper, we apply metaheuristics to approximate Eq.3. In
particular, and since the problem is very complex, in the next section we will ﬁnd valid solutions
of the following problem, where we focus on some constraints of Eq.3, c.1, c.2, c.3, c.8, c.9, c.10,
c.11, c.12 and c.14:
max
s.t.

βk −

1
m

−
m tik
i=1 xik

−βk xik +
−βk yrk +

t+
s
rk
r=1 yrk
n
−
j=1 αjk xij + tik
n
+
j=1 αjk yrj − trk

βk +

1
s

αjk ≤ M (1 − bjk )
bjk = 0, 1
βk ≥ 0
t−
ik ≥ 0
t+
rk ≥ 0
αjk ≥ 0

=
=
=

1
0
0

∀i
∀r
∀j
∀i
∀r
∀j

(c.1)
(c.2)
(c.3)
(c.8)
(c.9)
(c.10)
(c.11)
(c.12)
(c.14)

(4)

It is worth mentioning that the optimal value of Eq.4 is an upper bound of the optimal
value of Eq.3, since Eq.4 uses a subset of constraints of Eq.3.

3

Metaheuristic Methods for Determining Closet Targets

Metaheuristics are proposed here to obtain a satisfactory solution of Eq.4. A population of valid
solutions of Eq.4 is explored. Each solution represents a candidate to be the best model and is
+
+
composed by βk , αjk , t−
ik , trk ∈ R and bjk ∈ {0, 1} being i = 1, ..., m, j = 1, ..., n, r = 1, ..., s.
An evaluation of each solution is calculated by using the objetive function of Eq.4.

3.1

Deﬁning a Valid Solution

A valid solution has to satisfy the constraints in Eq.4. Four methods to generate the initial
population of solutions have been tested. A parameter called M AXGEN is stated to be used
in the random generation of some values. This parameter is higher enough to not aﬀect the
problem. The main characteristics of the four methods are:
−
+
+
• Method 1. The parameters βk ,t−
1k ,...,tmk ,t1k ,...,tsk ,α1k ,...,αnk are generated randomly
between 0 and M AXGEN , and b1k ,...,bnk are generated in 0, 1 randomly.

394

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

• Method 2. The process starts obtaining a random βk between 0 and M AXGEN , and a
set of αjk values using algorithm 1. Next the bjk values are generated considering αjk in
−
order to satisfy c.8. The values t+
rk and tik are deduced from inputs and outputs matrices
and the previously generated βk and αjk using c.2 and c.3. In case of obtaining a valid
solution the algorithm ends, if not, algorithm 2 is used.
m×n

Require: X ∈ R+
, Y ∈ R+
Ensure: α1k , ..., αnk ∈ R+
n

V x , V y ∈ R+ such as Vjx =

s×n

1
m

, DMU k
m

i=1

Xi,j and Vjy =

Sort V x and V y in descending order
n
n
Vjx and Vˆ y = n1
Vjy
Vˆ x = n1
j=1

1
s

s
i=1

Yi,j

j=1

for j := 1, ..., n do
if Vjx < Vˆ x and Vjy >= Vˆ y then
αjk ← 0
else if Vjx >= Vˆ x and Vjy < Vˆ y then
αjk ← Generate 0.5 ≤ αjk ≤ 1 randomly
else if (Vjx ≥ Vˆ x and Vjy ≥ Vˆ y ) or (Vjx < Vˆ x and Vjy < Vˆ y ) then
αjk ← Generate 0 ≤ αjk ≤ 0.25 randomly
end if
end for
Find the minimum αjk and modify its value in order to satisfy Eq. 4
Algorithm 1: Generate alpha
Require: βk ∈ R, q ∈ Z, M axIter ∈ Z
Ensure: A minimal βk for the solution that satisﬁes c.11
d←1
while d ≤ M axIter do
while ∀t−
ik ≥ 0 do
{Decrease βk while still satisﬁes (c.11)}
βk ← βk − dq
Generate t−
ik using c.2
end while
{At this point (c.11) is not satisﬁed. Then increase βk until it is satisﬁed }
repeat
βk ← βk + dq
Generate t−
ik using c.2
≥
0
until ∀t−
ik
d←d+1
end while
Algorithm 2: Adjust βk
Algorithm 2 decreases or increases βk in order to obtain the minimal value that satisﬁes
c.11. Having a lower βk increases the probability of satisfy c.12 because t+
ik are deduced
in c.3.
• Method 3. This method is an extension of method 2 through adding a third adjust process
395

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

−
+
+
for the αjk (algorithm 3). First, obtain βk ,t−
1k ,...,tmk ,t1k ,...,tsk ,α1k ,...,αnk and b1k ,...,bnk
as in Method 2. After that, adjust βk and α1k ,...,αnk using algorithm 3.
m×n

s×n

Require: X ∈ R+
, Y ∈ R+
, q ∈ R, DMU k, M axIter ∈ Z
Ensure: βk and α1k ,...,αnk .
repeat
+
while ∃ 1 ≤ i ≤ n and 1 ≤ r ≤ s such as t−
ik ≤ 0 and trk ≤ 0 and the number of
αjk = 0 > 2 do
+
if ∃t−
ik ≤ 0 and ∀trk ≥ 0 then
Increase βk
end if
+
if ∀t−
ik ≥ 0 and ∃trk ≤ 0 then
Decrease βk
end if
+
if ∃t−
ik ≤ 0 or ∃trk ≤ 0 then
Choose αjk no null randomly and make it equal to zero, decreasing the rest αjk
in p and ﬁnd the minimum αjk and modify its value in order to satisfy Eq. 4
end if
end while
until A valid solution is obtained or Iterations ≥ M axIter or the number of αjk no
null is lower than n-2
Algorithm 3: Adjust βk and α1k ,...,αnk
• Method 4. A genetic algorithm has been used to produce valid solutions of the problem.
The chromosomes are sets of αjk and βk which satisfy c.1, c.2, c.3, c.8, c.9, c.10 and
−
c.14. The evaluation function is the sum of t+
rk and tik , being the solution with the higher
punctuation a better candidate.

4

Experimental Results

Experiments have been carried out in a computer with Itanium-2 dual-core. The code has been
written in C. We used the 11.1 version of Intel compiler and the Intel MKL library, version
10.2.2.025.
Two objectives are pursued, the ﬁrst is to compare the eﬀectiveness of the four methods
proposed, studying the execution cost and the percentage of valid solutions. The second is to
study how the percentage of valid solutions decreases when the size of the problem increases.
Experiments have been carried out 10 times. The average and standard deviation of the
execution time and the percentage of valid solutions found are calculated.
Table 1 shows both the averaged execution time (in seconds) and the averaged percentage of
valid solutions associated with the four aforementioned methods. The corresponding standard
deviations are shown as subscripts. Method 1 works very poorly for all the instances. Method 2
performs better than method 1. However, the averaged percentage of valid solutions decreases
as the problem size increases, reaching a value of zero for the biggest example. The performance
of method 4 is also worse than that of the second method, even with respect to the execution
cost. On the other hand, method 3 is clearly the best approach for determining valid solutions, although the size of the problem adversely aﬀects its eﬀectiveness. Speciﬁcally, Figure 2
illustrates the superiority of the third method compared to the other three possibilities.
396

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

Table 1: Execution cost and percentage of valid solutions when the four methods of initiation
are used, varying the problem size.

m

size
n

s

2
3
4
5
6
10

15
25
30
40
60
100

1
2
2
3
4
10

m

size
n

s

2
3
4
5
6
10

15
25
30
40
60
100

1
2
2
3
4
10

Method 1
time
% val.
0.0030.004
0.0040.004
0.0040.005
0.0040.003
0.0060.000
0.0110.000

0.751.71
0.000.00
0.000.00
0.000.00
0.000.00
0.000.00

Method 3
time
% val.
26.42351.440
6.72216.025
0.2230.584
13.12520.640
2.0661.132
8.4263.235

82.0838.58
90.0530.46
100.000.00
73.9043.40
34.7444.07
32.6541.44

Method 2
time
% val.
0.0080.005
0.0100.006
0.0220.008
0.0190.003
0.0320.001
0.0920.002

50.8341.92
33.5538.24
26.8729.09
13.9023.90
0.030.16
0.000.00

Method 4
time
% val.
17.2443.566
21.2830.801
29.52110.540
18.1871.209
103.6980.185
302.3160.713

10.583.12
0.800.83
1.571,20
0.000.00
0.180.46
0.000.00

Figure 2: A comparison between the percentage of valid solutions obtained with each generation
method.

The problem in method 3 is that the standard deviation is very high in most of the cases,
both in execution cost as in percentage of valid solutions. This means that the variability of
the results could be important and the method has a high dependence on random parameters.
This must be taken into account when method 3 is used and be improved in future works.

5

Conclusions and Future Works

Determining closest eﬃcient targets and their corresponding benchmarking information are
relevant topics in the recent DEA literature. Nevertheless, from a computational point of
397

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

view, it has been usually solved by unsatisfactory approaches associated with a combinatorial
NP-hard problem.
In this paper, a ﬁrst step has been carried out to solve the problem of obtaining valid
solutions for the mathematical programming models based on the determination of closest
targets in DEA. The objective in our work was to approach the optimization problem by
metaheuristic techniques, but due the mathematical diﬃculty of the problem, as a ﬁrst step,
the paper analyzes and compares some heuristic algorithms to obtain valid solutions.
Four diﬀerent methods to generate the initial population of solutions were used and tested
by means of some simulated experiments. The third method, based on three algorithms to yield
the suitable parameters of the problem, clearly presented the best performance.
In this paper, the introduced approach focuses on a model that is an upper bound of
the optimal value of the model that we originally wish to solve. Although the mathematical
complexity of the problem justiﬁes this ﬁrst step, the development of a method considering the
remaining constraints could be a good avenue for further research. Additionally, improving the
method to generate the initial population of solutions and testing diﬀerent heuristics could help
to achieve this speciﬁc objective. It is also in mind a deepest study of the relation between
the diﬀerent initial parameters and the size of the problem with the computing time required
and the eﬀectiveness of the algorithm. Finally, in this paper we studied the problem associated
with the so-called Enhanced Russell Graph measure. Nevertheless, there are a lot of measures
in DEA that can be used for measuring technical eﬃciency by means of closest eﬃcient targets.
Consequently, programming the approach based on metaheuristic algorithms to solve all of
them can be seen as a suitable and interesting future work.

5.1

Acknowledgements

This work was supported by the Spanish MINECO, as well as European Commission FEDER
funds, under grant TIN2012-38341-C04-03. Additionally, J. Aparicio and J. J. L´
opez-Esp´ın are
grateful to the Generalitat Valenciana for supporting this research with grant GV/2013/112.

References
[1] A. Amirteimoori and S. Kordrostami. A euclidean distance-based measure of eﬃciency in data
envelopment analysis. Optimization, 59:985–996, 2010.
[2] J. Aparicio and J. T. Pastor. A well-deﬁned eﬃciency measure for dealing with closest targets in
DEA. Applied Mathematics and Computation, 219:9142–9154, 2013.
[3] J. Aparicio and J. T. Pastor. Closest targets and strong monotonicity on the strongly eﬃcient
frontier in DEA. Omega, 44:51–57, 2014.
[4] J. Aparicio and J. T. Pastor. On how to properly calculate the euclidean distance-based measure
in DEA. Optimization, 63:421–432, 2014.
[5] J. Aparicio, J. L. Ruiz, and I. Sirvent. Closest targets and minimum distance to the Pareto-eﬃcient
frontier in DEA. Journal of Productivity Analysis, 28:209–218, 2007.
[6] C. Baek and J. Lee. The relevance of DEA benchmarking information and the Least-Distance
Measure. Mathematical and Computer Modelling, 49:265–275, 2009.
[7] R. D. Banker, A. Charnes, and W. W. Cooper. Some models for estimating technical and scale
ineﬃciencies in data envelopment analysis. 30:1078–1092, 1984.
[8] W. Briec. H¨
older distance functions and measurement of technical eﬃciency. Journal of Productivity Analysis, 11:111–131, 1998.

398

Data Envelopment Analysis with metaheuristics

L´
opez-Esp´ın, Aparicio, Gim´enez and Pastor

[9] W. Briec and B. Lemaire. Technical eﬃciency and distance to a reverse convex set. European
Journal of Operational Researchs, 114(178–187), 1999.
[10] W. Briec and J. B. Lesourd. Metric distance function and proﬁt: some duality results. Journal of
Optimization Theory and Applications, 101(15–33), 1999.
[11] A. Charnes, W. W. Cooper, and E. Rhodes. Measuring the eﬃciency of decision making units.
European Journal of Operational Research, 2(429–444), 1978.
[12] A. Charnes, J. J. Rousseau, and J. H. Semple. Sensitivity and stability of eﬃciency classiﬁcations
in data envelopment analysis. Journal of Productivity Analysis, 7(2–18), 1996.
[13] L. Cherchye and T. Van Puyenbroeck. A comment on multi-stage DEA methodology. Operations
Research Letters, 28(93–98), 2001.
[14] T. Coelli. A multi-stage methodology for the solution of orientated DEA models. Operations
Research Letters, 23(143–149), 1998.
[15] T. Coelli, D. S. P. Rao, and G. E. Battese. An Introduction to Eﬃciency and Productivity Analysis.
Kluwer Academic Publishers, 1998.
[16] W. D. Cook and L. M. Seiford. Data envelopment analysis (DEA) - Thirty years on. European
Journal of Operational Research, 192(1–17), 2009.
[17] W. W. Cooper, L. M. Seiford, and K. Tone. Data envelopment analysis: a comprehensive text with
models, applications, references and DEA-solver software. Kluwer Academic Publishers, 2000.
[18] M. J. Farrell. The measurement of productive eﬃciency. Journal of the Royal Statistical Society,
120:253–281, 1957.
[19] F. X. Frei and P. T. Harker. Projections onto eﬃcient frontiers: theoretical and computational
extensions to DEA. Journal of Productivity Analysis, 11:275–300, 1999.
´
[20] E. Gonz´
alez and A. Alvarez.
From eﬃciency measurement to eﬃciency improvement: the choice
of a relevant benchmark. European Journal of Operational Research, 133:512–520, 2001.
[21] G. R. Jahanshahloo, F. Hosseinzadeh Lotﬁ, H. Zhiani Rezai, and F. Rezai Balf. Finding strong
deﬁning hyperplanes of production possibility set’. European Journal of Operational Research,
177:42–54, 2007.
[22] G. R. Jahanshahloo, F. Hosseinzadeh Lotﬁ, and M. Zohrehbandian. Finding the piecewise linear
frontier production function in data envelopment analysis. Applied Mathematics and Computation,
163:483–488, 2005.
[23] G. R. Jahanshahloo, J. Vakili, and S. M. Mirdehghan. Using the minimun distance of DMUs from
the frontier of the PPS for evaluating group performance of DMUs in DEA. Asia-Paciﬁc Journal
of Operational Research, 29(2):1250010, 2012.
[24] G. R. Jahanshahloo, J. Vakili, and M. Zarepisheh. A linear bilevel programming problem for
obtaining the closest targets and minimum distance of a unit from the strong eﬃcient frontier.
Asia-Paciﬁc Journal of Operational Research, 29(2):1250011–1–1250011–19, 2012.
[25] S. Lozano and G. Villa. Determining a sequence of targets in DEA. Journal of Operational
Research Society, 56:1439–1447, 2005.
[26] J. T. Pastor and J. Aparicio. The relevance of DEA benchmarking information and the LeastDistance Measure: Comment. Mathematical and Computer Modelling, 52:397–399, 2010.
[27] J. T. Pastor, J. L. Ruiz, and I. Sirvent. An enhanced DEA Russell graph eﬃciency measure.
European Journal of Operational Research, 115:596–607, 1999.
[28] M. C. A. S. Portela, P. C. Borges, and E. Thanassoulis. Finding closest targets in non-oriented
DEA models: The case of convex and non-convex technologies. Journal of Productivity Analysis,
19:251–269, 2003.
[29] A. Takeda and H. Nishino. On measuring the ineﬃciency with the inner-product norm in data
envelopment analysis. European Journal of Operational Research, 133:377–393, 2001.
[30] K. Tone. A slacks-based measure of eﬃciency in data envelopment analysis. European Journal of
Operational Research, 130:498–509, 2001.

399

