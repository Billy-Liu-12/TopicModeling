Constructing a P2P-Based High Performance
Computing Platform*
Hai Jin, Fei Luo, Xiaofei Liao, Qin Zhang, and Hao Zhang
Cluster and Grid Computing Laboratory,
Huazhong University of Science and Technology, Wuhan, 430074, China
{hjin, luofeiren, xfliao, qzhang, haozhang}@hust.edu.cn

Abstract. The construction for a P2P-based high performance computing
platform (P2HP) is presented to address parallel problems in this paper. P2HP
utilizes idle computers in the Internet with great scalability to form an enormous
computing capability for scientific supercomputing and volunteers form
autonomous unstructured P2P network domains. The configuration of P2HP is
easy and a programming model is provided. Its applications involve a large range
of problems, and a benchmark is applied to evaluate its performance.

1 Introduction
Peer-to-Peer (P2P) fashion can construct supercomputers far beyond the power of any
current computing center, which make HPC much less expensive and much more
accessible than clusters [1]. Because P2P addresses failure for dynamics, personal
computers (PCs) in the Internet are suitable to participant into P2P computing. There
are countless PCs which are idle most of time. The collection of them in P2P systems
has potentially enormous computing power.
Currently, most P2P-based computing systems belong to special organizations, and
they are just used to solve one scientific or commercial high throughput problem. The
characteristic of HPC is more instantaneous than that of high throughput computing
(HTC), which makes them more tight constraints in HPC systems than in HTC [2].
A P2P-based HPC platform, P2HP, is depicted to assemble idle Internet resources in
this paper. P2HP is constructed as a 3-layer network architecture, where volunteers
form autonomous unstructured P2P domains. The computing power increases with the
rise of volunteers number. It is easily configured, and the management cost is
distributed into autonomous domains, which brings the advantage that P2HP fits
various environments and users. A one-sided message passing (OMP) [3]
programming model is provided for users, which makes P2HP can work on a variety of
problems, especially infinite workpile applications with deadlines [4].
The rest of the paper is organized as follows. Related works are reviewed in section
2. The system architecture of P2HP is outlined in section 3, and its design issues are
described in section 4. To test its high performance characteristics, sequence alignment
in bioinformatics is applied as a benchmark in section 5. Finally, a conclusion is drawn
in section 6.
*

This paper is supported by National Science Foundation under grant 60433040, China CNGI
project under grant CNGI-04-12-2A and CNGI-04-12-1D.

V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 380 – 387, 2006.
© Springer-Verlag Berlin Heidelberg 2006

Constructing a P2P-Based High Performance Computing Platform

381

2 Related Works
There are many P2P-based computing systems designed to harness idle cycles of
Internet-connected workstations [5], which are also known as “public-resource
computing” or “global computing”, such as SETI@home [6], Folding@home [7],
Prediction@home [8]. Without providing a programming model, they are just used to
solve one scientific or commercial HTC problem. With its OMP programming model,
P2HP can solve a large range of problems.
Furthermore, a number of middleware for public-resource computing have been
provided, such as BOINC [5], OmniRPC [9], and XtremWeb [10]. The clients of these
systems contact directly with the server or through an agent, which is different from the
communication mechanism of P2HP. With autonomous domains, the resource
management of P2HP is decentralized, and most communication between entries exists
in local domains.
OurGrid [11] is a solution of running applications of Bag-of-Tasks. The job
scheduler is based on a provider-consumer algorithm. Different from the OMP
programming model of P2HP, it provides a script-command application programming
model which is limited for applications.

3 System Architecture
P2HP is constructed as a 3-layer network, as well as a pool for accessing data
(Datapool) and a user interface (User), shown in Figure 1. The module User is used to
manage the submission of applications, and Datapool is used to manage the storage of
applications’ related data.

Fig. 1. Architecture of P2HP

The basic components of the 3-layer network are monitors, dispatchers and workers.
The monitoring of the whole system is done by monitors, which are grouped as Monitor
Group (MG). Dispatchers schedule tasks to the workers, and all of the dispatchers are
grouped as Dispatcher Groups (DGs). A dispatcher can choose one or more monitors to
join, and the chosen monitor is then its host monitor. Workers execute subtasks of
applications and each of them is attached to a dispatcher.

382

H. Jin et al.

The parallelism of applications in P2HP is in the application level, and applications
are divided into small tasks. Each task finishes certain computing work for the
application. One of them participates in the control of the tasks’ execution flow, and it
is defined as the main task, while the others are defined as subtasks. Programmed with
OMP, applications are transferred into Datapool, and a project file (JobFile) is
generated, which is submitted to a monitor in the MG. They are then performed through
the scheduling process of P2HP.

4 Design Issues
4.1 Entries of 3-Layer Network
The running of the whole system is controlled by entries of the 3-layer network.
Monitors inquire the information of the actions of participants and the running states of
applications. Dispatchers poll the attached workers to inquire their states, which is
similar to the heartbeat mechanism. The worker accepts their messages and sends back
state information for its available hardware and software resources and executes
dispatched tasks.
A dispatcher with a number of attached workers forms an autonomous domain, and
the dispatcher is the dominator of the domain. Each domain is constructed as an
unstructured P2P network. All the dominators are monitored by the monitor. The
metric with autonomic domains for resource management in the 3-layer network
exploits the scalability of P2HP.
4.2 Data Management
Data is accessed in the Datapool, and all the requested data is transferred by a
transmission protocol and managed by the local storage system.
4.2.1 Storage Management
In the Datapool, the data is accessed in the form of files, and they are assembled in a
directory. The directory management of the Datapool is combined with a lightweighted
database, the Berkeley DB, which is an embedded database. It is used to record and
dynamically update the information of tasks’ states.
Services are provided by the database, and they give universal interfaces to the
Datapool’s requests from clients. With the database turned on, the process of the usage
for these services is passed through applying a service, attaining information and
returning its result.
4.2.2 Data Transmission
The data transmission is implemented as a Fast Data Transfer Protocol (FDTP). It is
based on a network-connected pipe, which consists of a message channel for messages
and a data channel for corresponding data files.
During the transmission, the data files are formatted as an I/O stream, and states are
defined, such as BEGIN_TRANS and FINISH_ONCE for the beginning and finishing
of the process, IDLE for none, SYN_RECEV and SYN_SENT for synchronization of
receiving and sending a message. The transmission process is expressed by a state
transition shown in Figure 2, where the real line represents the server’s state transition,
while the dashed one represents that of the clients.

Constructing a P2P-Based High Performance Computing Platform

383

Fig. 2. State transition during data’s transmission

Both clients and the server start the transmission from the IDLE state, and the
transition of their states will pass through BEGIN_TRANS, EINISH_ONCE, and
IDLE in the end. A file transfer starts with BEGIN_TRNAS, and ends with
FINISH_ONCE. If there are other data files to be transferred, both server and client are
BEGIN_TRANS again and begin to resolve the next data file. If an error occurs, the
transferring fails and both of them are IDLE and prepare next transaction for next
request. The procedure is iterated until all data files have been transferred, or an error
occurs. Each transition will be synchronized with SYN. One of them is the sender,
while the others are the receivers.
4.3 Scheduling
The running of an application is initiated by the main task, which applies subtasks from
the monitor with a program ID and the number of subtasks. The Monitor selects one or
several dispatchers with the lowest load and redirects the JobFile to them. Each of these
dispatchers is assigned part of the project’s subtasks. Then the main task requests those
dispatchers to execute its subtasks.
The dispatcher schedules its workers to execute subtasks. If there are unfinished
subtasks, the dispatcher distributes them to the idle workers. The worker who gets a
task attains the task’s program and related data from the Datapool. Then the worker
performs the execution of subtasks. Finally, the worker returns the result of the subtask
to the Datapool after finishing the execution. After all the subtasks have been finished,
the main task gets their results from the Datapool, and further resolves them to get the
final result.
4.4 Monitoring and Fault Tolerance
To ensure the availability, measures have been taken to trace P2HP’s computing
resources and the running states of applications’ tasks. It is collaborated by monitors
and dispatchers. The monitor is the supervision center of the system.
The monitor and the dispatcher cooperate as follows. In an autonomous domain,
workers are traced by the dispatcher periodically. All the dispatchers are traced by the

384

H. Jin et al.

monitor. The transaction to each entry’s fault is trigged off during the tracing. The load
of the entry with errors will be substituted by another one in its group. This procedure is
controlled by the entry in the top layer of network.
4.5 Software Development Kit
To be adaptive to multiple applications, the OMP programming model has been
provided for users. OMP has been deliberately kept simple with minimum conceptual
overhead. It consists of a communication library (ComLib) and a software development
kit (SDK) for users.
The ComLib is used for the communication between tasks and the Datapool, and it is
packaged based on the system’s data transmission module. The SDK is responsible for
providing application programming interfaces for subtasks (SubAPI) and the main
tasks (MainAPI).
The OMP is a one-sided message passing model. As the shared remote space, the
Datapool will respond to the request messages. When the client that has dispatched
tasks needs the correlative data, it only locally triggers off a message like sending or
receiving, and resolves this message to the Datapool. Then the requested data will be
transferred by the ComLib between the Datapool and the client.

5 Experiment
To evaluate the performance of P2HP, we use a benchmark with speedup of the
parallelized program in P2HP to the original sequential one in a PC. The benchmark is
sequence alignment, which is a basic problem of bioinformatics.
5.1 Methods
The environment of P2HP is conducted in a network with 30 normal PCs. All
computers are connected by a 100Mbps Ethernet switch. The frequencies of CPUs are
from 1GHz to 2.4GHz. The Datapool is installed in a PC, where the Monitor and the
Dispatcher are also configured. Other computers join the platform as workers as
necessary.
CLUSTAL W and its variants are the most common used software packages for
multiple alignments. First, the sequences are aligned by the sequential CLUSTAL W
program in a PC. Then, as presented in [3], the sequential one is parallelized with OMP
and run in P2HP. Assume that the number of sequences for multiple alignments is n,
and the number of pairwise alignments in a subtask is k. Then the number of the whole
pairwise alignments PA and the number of subtasks NS are shown in Formula 1 and 2.
The phylogenetic tree is constructed according to the distance matrix of all the pairwise
alignments, which is used to conduct the order of progressive alignment for multiple
sequences.
n × ( n − 1)
2

(1)

PA
n × ( n − 1)
=
k
2k

(2)

PA =

NS =

Constructing a P2P-Based High Performance Computing Platform

385

5.2 Evaluation
One hundred sequences are selected from NCBI (National Center for Biotechnology
Information) which is one of the sequence databases in the world. The number of each
sequence’s letters is from 957 to 1534. In the CLUSTAL W program, the formation of
phylogenetic tree through pairwise alignments costs about 440s.
In the parallelized execution for pairwise alignments in P2HP, it is assumed that the
time for each pairwise alignment is CP, and the communication time is CM. The time for
disposing of distance matrix is PT, and the execution time TP of the parallelized
CLUSTAL W in P2HP is shown as Formula 3. The execution time TS for the sequential
program is as Formula 4.
The speedup V of the parallelized one in P2HP to the sequential is depicted in
Formula 5. Combined with Formula 1 and 2, V is further represented in Formula 6.
With the number of sequences as a constant, the speedup increases with the decreasing
of k, and the maximum value is attained when k=1.
PA × ( C P + C M )
+ PT
NS

(3)

TS = PA × (CP − E )

(4)

V =

TS
N S × (C P − E )
=
TP C P + C M + N S × PT / PA

(5)

V =

n × ( n − 1)
CP − E
×
C P + C M + PT / 2 k
2k

(6)

6

6

5

5

4

Speedup

Speedup

TP =

3
2
1

4
3
2
1

0

0

0

3

6

9

12

15

18

21

NodesNum

Fig. 3. Speedup with the increase of workers

0

100

200

300

400

500

600

SubTasks

Fig. 4. Speedup with the increase of subtasks

To further verify its performance, we divide the alignments into 98 subtasks and
increase the workers. The time for sequence alignment in P2HP decreases, and the
speedup to the sequential CLUSTAL W increases, shown in Figure 3. If the number of
workers is small, the speedup is less than 1, which means that the parallel execution of
a small quantity of workers can not afford the cost of the communication.

386

H. Jin et al.

Supposed that the number of workers is a constant as 18 and the number of subtasks
is much larger than 18, the speedup to the sequential program is decreasing with the rise
of the subtasks’ number, as shown in Figure 4. It shows that P2HP is more adaptive to
the computation intensive applications.
The experiment demonstrates that P2HP is an efficient and practical distributed HPC
platform, especially to the computation intensive applications. To get the expected
performance of P2HP, the number of subtasks should match that of workers in a limited
environment, and applications should be divided into more subtasks if there are enough
workers in the system.

6 Conclusion
P2HP is constructed as the 3-layer network that consists of monitors, dispatchers and
workers, as well as a user and a Datapool. Based on unstructured P2P, P2HP is scalable
and adaptive to dynamic environments. Augmenting the number of workers, its
computing capability is increasing. With an easy configuration, P2HP is applicable.
Moreover, the benchmark shows that it can provide scalable and enormous power for
HPC applications.

References
[1] G. Bell and J. Gray, “What’s next in high-performance computing”, Communications of
the ACM, 45 (2), pp.91~95, 2002.
[2] R. Raman, M. Livny, and M. Solomon, “Matchmaking: distributed resource management
for high throughput computing”, Proceedings of the Seventh IEEE International
Symposium on High Performance Distribute Computing (HPDC’98), 1998.
[3] H. Jin, F. Luo, Q. Zhang, X. Liao, H. Zhang, “OMP: a one-sided message passing
programming model for P2HP”, Proceedings of the Seventh International Meeting on High
Performance Computing for Computational Science (VECPAR’06), 2006.
[4] V. Lo, D. Zappala, D. Zhou, Y. Liu, and S. Zhao, “Cluster computing on the fly: P2P
scheduling of idle cycles in the Internet”, Proceedings of the 3rd International Workshop
on Peer-to-Peer Systems (IPTPS’04), 2004.
[5] D. P. Anderson, “BOINC: A system for public-resource computing and storage”,
Proceedings of the Fifth IEEE/ACM International Workshop on Grid Computing
(GRID’04), pp.4-10, 2004.
[6] D. P. Anderson, J. Cobb, E. Korpela, M. Lebofsky, and D. Werthimer, “SETI@home: An
experiment in public-resource computing”, Communications of the ACM, 45(11),
pp.56-61, 2002.
[7] V. S. Pande, I. Baker, J. Chapman, S. P. Elmer, S. Khaliq, S. M. Larson, Y. M. Rhee, M. R.
Shirts, C. D. Snow, E. J. Sorin, and B. Zagrovic, “Atomistic Protein Folding Simulations
on the Submillisecond Time Scale Using Worldwide Distributed Computing”,
Biopolymers, Vol.68, pp.91-109, 2003.
[8] M. Taufer, C. An, A. Kerstens, and C. L. Brooks, “Predictor@Home: A ‘protein structure
prediction supercomputer’ based on public-resource computing”, Proceedings of the 19th
IEEE International Parallel and Distributed Processing Symposium (IPDPS’05), 2005.

Constructing a P2P-Based High Performance Computing Platform

387

[9] M. Sato, T. Boku, and D. Takahashi, “OmniRPC: A grid RPC system for parallel
programming in cluster and grid environment”, Proceedings of 3rd International
Symposium on Cluster Computing and the Grid (CCGrid’03), pp.206-213, 2003.
[10] G. Fedak, C. Germain, V. Neri, and F. Cappello, “XtremWeb: A generic global computing
system”, Proceedings of the 1st IEEE/ACM International Symposium on Cluster
Computing and the Grid (CCGrid’01), 2001, pp.582-587, 2001.
[11] N. Andrade, W. Cirne, F. Brasileiro, and P. Roisenberg, “OurGrid: an approach to easily
assemble grids with equitable resource sharing”, Proceedings of the 9th Workshop on Job
Scheduling Strategies for Parallel Processing (JSSPP’03), pp.61-86, 2003.

