A Service-Oriented Framework for Parallel
Medical Image Reconstruction
S. Benkner, A. Dimitrov, G. Engelbrecht, R. Schmidt, and N. Terziev
Institute for Software Science, University of Vienna,
Liechtensteinstrasse 22, A-1090 Vienna, Austria
{sigi,dimitrov,gerry,rainer,terziev}@par.univie.ac.at

Abstract. This paper presents an overview of the eMERGE system, a
service-oriented system for medical image reconstruction on parallel computers. Within the eMERGE system, parallel image reconstruction codes
running on SMP clusters or other parallel machines may be exposed as
Jini services, as Web Services, or as OGSA services and accessed over the
Internet by means of a browser-based GUI. The system provides support
for dynamic service management, service selection and monitoring. We
describe the parallelization of a fully 3D iterative image reconstruction
code using a combination of MPI and OpenMP, discuss the major design
and implementation issues of the various service types supported by our
system, and present experimental results comparing the performance of
RMI-based to SOAP-based image data transfers.

1

Introduction

Novel algorithms enable very accurate 3D reconstruction of medical images from
2D scanner data by considering principal 3D effects of data acquisition. However,
the high computational requirements restrict the deployment of these methods
to dedicated research centers. In order to make advanced image reconstruction
services available to hospitals that have no in-house high performance computing
facilities, we are developing the eMERGE system, a service-oriented framework
that supports near real-time 3D image reconstruction by providing transparent
access to remote parallel computers over the Internet. Our current prototype
consists of a browser-based GUI, a parallel fully 3D image reconstruction code
written in C/MPI/OpenMP, and a framework for dynamic service management,
service selection and monitoring. Parallel image reconstruction codes provided
on PC clusters or other parallel machines may be exposed in our system as Jini
services, as Web Services, or as OGSA-compliant Grid services.
This article is organized as follows: Section 2 provides an overview of the
image reconstruction algorithm and its parallelization. Sections 3 and 4 describe
the main components of the eMERGE system and the different service variants,
This research was partially supported by the Austrian Science Fund as part of the
AURORA project under contract SFB F1102 and by the European Commission as
part of the IST Project GEMSS under contract IST-2001-37153.
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2659, pp. 612−621, 2003.
 Springer-Verlag Berlin Heidelberg 2003

A Service-Oriented Framework for Parallel Medical Image Reconstruction

613

respectively. Performance results of image transfers using different protocols are
presented in Section 5, followed by conclusions and future plans in Section 6.

2

Parallel Fully 3D Image Reconstruction

In emission tomography (e.g. SPECT), the spatial distribution of a radioactive
tracer is reconstructed from projection data. In fully 3D image reconstruction
a solution for the whole image volume X is found simultaneously by using the
whole set of projection values Y . The imaging process is characterized by the
following equation:
Y =AX +E
(1)
The image volume X is represented by means of a vector of size J which stores
the mean activity of each voxel. Vector Y of size I represents the whole set
of projection values, counting the photons detected for each projection value
during the whole acquisition. Element aij of the system matrix A represents
the probability that a photon emitted in voxel j is detected at detector position
i. The system matrix allows a flexible modeling of scanner geometry, detector
efficiency, scatter and attenuation. In typical clinical applications J, the number
of unknowns is 1283 and I, the number of equations is 1282 × 120 assuming 3o
rotational increment over a range of 360o .
The ill-posedness of A and the error term E, in general, allow no exact
solution of Eqn. 1. In our system we utilize an improved variant of the wellknown ML-EM algorithm for emission tomography [12], which is an iterative
method for finding a feasible solution of Eqn. 1. The ML-EM algorithm takes
into account the Poisson statistics of photon emission and detection. During one
(n)
iteration step, the voxel xj of the n-th iteration is updated by
(n+1)

xj

(n)

= xj

yi

aij
i

k

(n)

aik xk

.

(2)

A more detailed description of our reconstruction algorithm, which implicitly
corrects for scatter and attenuation, can be found in [2].
Experiments with a sequential implementation of the image reconstruction
algorithm in C, have shown that the time required for the reconstruction of a
1283 image volume on a single processor workstation can be in the range of
several hours to a few days, depending on the configuration of the algorithm
and the hardware.
2.1

Parallelization for SMP Clusters

In order to allow on-site clinical analysis the reconstruction code has been parallelized. Since our main target platforms are SMP clusters, we adopted a hybrid
parallelization strategy relying on a combination of MPI [7] and OpenMP [11].
Distributed-memory parallelization, based on the single-program multiple-data
(SPMD) paradigm, is achieved by parameterizing the code in such a way that it

614

S. Benkner et al.

can be executed by multiple MPI processes, each computing its own part of the
image volume. This was implemented by strip-mining the outer loop representing the computations defined by Eqn.2 across multiple processes. By utilizing
appropriate OpenMP work sharing constructs, each MPI process employs multiple OpenMP threads. At the end of a full iteration cycle, the voxels updated
by individual MPI processes are transferred to all other processes in a collective
communication phase.
Since most of the elements of the system matrix are zero we utilize the compressed row storage format (CRS) in our implementation. Moreover the symmetries of the system matrix are exploited to further reduce the storage requirements. In order to minimize communication overheads, the system matrix and
some other data structures are allocated on each node.
The parallelized source program is compiled with an OpenMP C compiler
and linked with the MPI library. The resulting program is executed on an SMP
cluster as an MPI program by a set of parallel processes, each usually running
on a separate node of the cluster within its own local address space. Due to the
use of OpenMP, each MPI process employs multiple threads (usually one thread
per processor) which execute concurrently in the shared address space of a node.
The combination of MPI and OpenMP offers greater flexibility with respect
to memory management than an approach based on MPI only. Moreover, due
to the shared memory available within nodes, the number of communications
can be reduced while message sizes can be increased. In a pure MPI implementation of our algorithm, not only more messages but also much more memory is
required. On the other hand, by using OpenMP, certain synchronization overheads are introduced whenever multiple threads update data structures allocated
in the shared memory of a node. Experimental results comparing hybrid-parallel
versions of the reconstruction algorithm to a pure message passing version are
presented next.
2.2

Performance Experiments

We present performance experiments with different versions of the parallel image
reconstruction code on a Beowulf-type PC cluster consisting of 6 nodes connected
by Fast Ethernet. Each node is equipped with 4 Pentium III Xeon processors
(700 MHz) and 4 GB of memory. For the compilation of the MPI/OpenMP
source program the C compiler from Portland Group Inc. was used together
with the mpich library.
In Figure 1 the speed-ups (with respect to the sequential code executed on a
single processor of the cluster) of three different code variants are compared for
an image of size 128x128x128 using data from a clinical standard phantom. A
pure MPI version is compared to hybrid-parallel versions which employed 2 and
4 threads within each MPI process, respectively. The hybrid-parallel versions
have been executed in such a way that each thread is always running on its own
processor. On up to two nodes (8 processors), all three versions yield approximately the same speed-ups. On more than two-nodes, the pure MPI-version

A Service-Oriented Framework for Parallel Medical Image Reconstruction

speed−up

20

615

MPI/OpenMP (2 threads/process)
MPI/OpenMP (4 threads/process)
pure MPI
ideal speedup

15

10

5

0

4

6

8

10

12

16

Number of Processors

20

24

Fig. 1. Experimental comparison of a pure MPI version to hybrid-parallel
MPI/OpenMP versions with 2 and 4 threads per MPI process, respectively.

is outperformed by the MPI/OpenMP versions. One reason for the worse scaling of the pure MPI version is the larger communication overhead (more and
smaller messages), since communication is performed also within nodes. Moreover, the MPI version requires more memory because replicated data structures
are allocated within each process, while in the MPI/OpenMP version all threads
have access to the data allocated within their parent processes. As can be observed from Figure 1, the performance of the MPI/OpenMP version where only
2 threads were generated within each MPI process decreases when more than
one MPI process is run on a node, i.e. if more than 12 processors are used. If
all 24 processors of the cluster are utilized, a significant performance difference
between the pure MPI version and the MPI/OpenMP versions can be seen.
Our reconstruction algorithm has been implemented in such a way that it
is portable across distributed-memory architectures, shared-memory architectures and clusters. A performance evaluation on other parallel computing platforms, including a heterogeneous SMP cluster (2-processor nodes and 4-processor
nodes), an SGI Origin, and an NEC SX-5 multi-node vector supercomputer is
currently under way. In order to efficiently utilize the computing power offered by
vector supercomputers such as the SX-5, modifications of our implementation
will be required for exploiting all three levels of parallelism (i.e. distributedmemory, shared-memory, and vector parallelism).

3

The eMERGE System

Within the eMERGE system, parallel image reconstruction codes running on PC
clusters may be exposed as Jini services, as Web Services, or as OGSA-compliant
Grid services. The eMERGE system provides basic support for automatic service
selection, dynamic service management, and service monitoring. Services may be
accessed via a browser-based graphical user interface either in direct mode, in

616

S. Benkner et al.
Client

Registry Server
Service
Registry

GUI
Service
Connector

Service (SMP Cluster)
Reconstruction
Service

Service
Manager

Service
Executer

Service
Descriptor

Service
Monitor

Reconstruction
Code
C/MPI/OpenMP

Machine
Monitor

Machine
Descriptor

Manager Machine

Fig. 2. Main components of the eMERGE system.

which case a predefined reconstruction service is accessed, or in managed mode,
where a service manager automatically selects from the set of available parallel
machines the one on which the reconstruction job is expected to be completed
within the shortest period of time. The main components of the eMERGE system
are shown in Figure 2.
In a typical use-case scenario, projection data from a CT scanner are loaded
from the client’s local file system and displayed in the GUI. The user selects the
slices to be reconstructed and various other reconstruction parameters. When
the user decides to start the reconstruction process, the raw image and an XML
file, which contains meta data about the image and the reconstruction process,
are transferred over the Internet to a remote parallel machine. On the target
machine, an intermediate Java program handles the transfer of image data, and
initiates the execution of the native image reconstruction code. By monitoring
the reconstruction process, the user is provided with an estimated service completion time and corresponding progress information. After completion of the
reconstruction process, the reconstructed 3D image is transferred back to the
client and displayed in the GUI.
3.1

Reconstruction Services and Server-Side Components

The native image reconstruction code, written in C/MPI/OpenMP, may be installed on PC clusters and other parallel computers and exposed as a service
through an intermediate server-side Java program, called service executor, which
handles the data transfer between clients and services, and the execution of
the reconstruction job on the parallel target machine. The service executor implements the interface ReconstructionService, which contains all methods a
client may invoke on an image reconstruction service. The service executor relies
on a service monitor for monitoring the state of a running service, and a machine
monitor for obtaining an estimate of the available computational power of the
target machine at a certain point in time. For this purpose the machine monitor needs access to the local batch system. Upon start-up, the machine monitor
is configured with an XML machine descriptor, which currently contains the
number of available processors as well as their estimated performance.
In order to support the concurrent execution of multiple reconstruction jobs
on the same target machine, the service executor generates a unique id for each

A Service-Oriented Framework for Parallel Medical Image Reconstruction

617

client, which is passed as an argument to all methods provided by the reconstruction service. As a consequence, a single instance of the service executor can
be accessed by multiple clients at the same time.
3.2

Service Manager and Service Registry

Reconstruction services may be accessed in direct mode or in managed mode. In
direct mode, the client has to know the location of the service. In managed mode,
the client contacts a service manager, which dynamically selects a reconstruction
service to be accessed by the client. Whenever a reconstruction service is added to
the system, the service registers itself in the service registry. Upon an incoming
client request, the service manager selects from the set of registered services
the one that is expected to complete the reconstruction job within the shortest
period of time. For this purpose, the service manager maintains state information
of all registered service machines and chooses the machine that provides the
maximum free computational capacity (currently measured as the accumulated
performance of free processors) at the time a service is requested. Whenever the
number of available free processors on a registered service machine changes, the
service manager receives a corresponding notification from the machine monitor.
After having selected a service, the service manager forwards an appropriate
service proxy to the client which then accesses the chosen service directly.
3.3

User Interface and Client-Side Components

The image reconstruction service system may be accessed via a graphical user
interface that can be provided to end users as a Java applet via a browser. Since
the GUI needs to access the client’s local file system for loading and saving
medical images, we utilize a signed applet which presents a X.509 certificate
upon download to the user for granting the required permissions.
The GUI utilizes a flexible service connector component which is capable of
loading or generating different service proxies in order to access reconstruction
services via RMI or Web Services (JAX-RPC, SOAP) protocols.

4

Service Technologies

Initially, the eMERGE system has been developed based on Jini. Support for
Web Services and OGSA has been added recently and is a major objective of
ongoing work.
4.1

Jini

Within the Jini-based implementation of the eMERGE system, reconstruction
codes installed on parallel computers are exposed as services accessible via the
Java RMI protocol. Using the basic mechanisms of Jini (discovery, join and
lookup), a dynamic federation of multiple image reconstruction services on different parallel hosts may be established. In such a federation of services, at least

618

S. Benkner et al.

one service registry (realized as a Jini lookup service) and one service manager
(realized as a Jini service) must be instantiated. Whenever a reconstruction service is added to the system, the service registers itself with the service registry.
The service manager obtains service proxies of all available reconstruction services from the service registry.
Upon startup of the client GUI, the service connector component discovers
the service registry and obtains a proxy object of the service manager. At the
time a client issues a request for an image reconstruction service, the service
manager selects a suitable image reconstruction service (see below) and returns
the proxy of the corresponding service executor to the client. The client’s service
connector then accesses the image reconstruction service directly. The raw image
data and the XML-based meta-data are transferred over RMI to the target
machine by calling appropriate methods of the service executor. Thereupon,
the service executor launches the parallel reconstruction process on the target
machine, usually utilizing all available free processors.
At the moment our service manager uses a fairly simple strategy for selecting
a reconstruction service: the machine with the maximum available computing
resources, currently measured as the number of free processors times the estimated processor performance in FLOPs, is selected. In order to provide up-todate information about the actual free computational capacity of a machine, the
monitoring component notifies the service manager whenever the number of free
processors changes.
In order to support realistic settings, where server-side machines as well as
clients are behind firewalls, we utilize HTTP tunneling of all RMI calls.
4.2

Web Services

Web Services are rapidly becoming the standard way of performing Enterprise
Application Integration (EAI) within as well as across organizations. Web Services are based on XML vocabularies standardized by the W3C (SOAP, WSDL,
UDDI, etc.) and provide an architecture for exposing applications as services that
are platform and programming language independent. Web services are identified
by an URI, expose their public interfaces and protocol bindings through a Web
Services Description Language (WSDL) document, and are usually accessed via
SOAP over HTTP, even across firewalls.
Our current Web Services implementation of image reconstruction services
supports access in direct mode only. For the development we mainly used the
Java Web Service Developer Pack (JWSDP 1.0 [8]) which provides a framework
for developing and hosting web services based on servlets and Tomcat. Moreover, we have utilized other Web Services frameworks, mainly for the purpose of
performance comparisons, including Glue [5] and Apache Axis [1].
The starting point for realizing image reconstruction services as Web Services
is the Java interface ReconstructionService, which specifies all methods clients
may invoke on a reconstruction service. In order to support access to reconstruction services based on Web Services technologies, a WSDL document that
describes the public interfaces and protocol bindings is required. This WSDL

A Service-Oriented Framework for Parallel Medical Image Reconstruction

619

document has been generated automatically from the Java interface provided
for reconstruction services by using the xrpcc tool of the JWSDP. Besides generating a WSDL document from a Java interface, the xrpcc tool also generates
stubs and ties for marshalling of arguments on the client-side and server-side,
respectively.
On the client-side, we provide an additional service connector for accessing
reconstruction services over JAX-RPC (which is SUN’s implementation of SOAP
RPC). The service connector loads the stub class of the reconstruction service
over HTTP (by means of an URLClassLoader). Upon method invocation, the
stub creates a SOAP request message that is conveyed via HTTP to a servlet
on the server side. The servlet parses the request message, converts arguments
from XML to Java and invokes the corresponding method of the service executor.
The method’s result object is transformed into an appropriate SOAP response
message by the servlet, transferred back to the client, and transformed by the
stub into a Java object.
Compared to a pure Java/RMI communication protocol, SOAP calls imply an
additional overhead for marshalling arguments and for parsing SOAP messages
both on the client side and the server side (see Section 5).
In addition to the stub-based service connector, we have implemented a connector that makes use of the Web Services Invocation Framework (WSIF 2.0 [13])
in order to access reconstruction services independently of the actual implementation and deployment as described in the next section.
4.3

Open Grid Service Architecture

We have implemented a variant of the medical image reconstruction service
according to the Open Grid Service Architecture (OGSA) based on the Open
Grid Service Infrastructure (OGSI) Application Framework (OGSI TP-5 [10]).
An OGSA service is a Web Service that provides standard mechanisms for
creating, naming and discovering services [9]. These mechanisms are realized
by an OGSI container which provides the runtime environment for Grid services. The OGSI container itself makes use of the Tomcat servlet engine and of
Apache Axis. The OGSA specification requires that a compliant Grid service
implements at least the interface (PortType) GridService, which is the base
interface definition in OGSA.
As in the Jini and Web Services implementation, the OGSA implementation of the medical image reconstruction service is based on the Java interface
ReconstructionService from which a WSDL document is generated. In order
to provide an OGSA compliant implementation, our service executor component
extends the class PersistentServiceSkeleton provided by the OGSI application framework implementing the interface (PortType) GridService. Moreover,
a deployment descriptor has to be provided, specifying the URI of the service
and other properties. Upon deployment, the service is automatically registered
in the registry of the OGSI container.
At the current stage of implementation, the OGSA-compliant version of the
service can be used in direct mode only. That is, the client application must

620

S. Benkner et al.

know the service endpoint, which is an URI that designates the WSDL of the
reconstruction service (also referred to as Grid Service Handle (GSH) in OGSA
terminology). In order to access the OGSA service from our GUI, we have implemented a service connector based on the Web Service Invocation Framework
(WSIF 2.0) [13]. Using WSIF, the service connector constructs a SOAP request
based on the grid service reference (GSR) of the reconstruction service (which
is the WSDL document of the service decorated by the container with runtime
specific information) without the need of any OGSA specific classes or stubs.
Another major advantage of WSIF is that besides SOAP other bindings and
transport protocols may be supported (eg. EJB using RMI/IIOP).

5

Experimental Results

In this section we present performance results of image data transfer based on
Java RMI in comparison to various implementations of SOAP (XML-RPC).
SunBlade100 <−> SunFire V880
40

Glue 3.2.3
Axis 1.0
JWSDP 1.0
RMI (with tunneling)

20
15

5 10

25

50

transferred MBs

75

35
30
25

minutes

30
25

40

Glue 3.2.3
Axis 1.0
JWSDP 1.0
RMI

35

20
15

10

10

5

5

100

5 10

25

50

75

minutes

SunBlade100 <−> Cluster Frontend

100

transferred MBs

Fig. 3. Performance of data transfers: RMI vs. different SOAP implementations.

Although in our current reconstruction service the size of medical images
is only approximately 5 MBs, we have measured transfers of up to 100 MBs
on a Fast Ethernet back and forth (ping-pong) between a client and a reconstruction service executor. The client application was executed on a Sun Blade
100 (sparcv9, 502MHz, 640MB RAM). The service executor was hosted on the
front-end PC (dual Pentium II, 400MHz, 1GB total RAM) of our 64 processor SMP cluster (see left hand side of Fig. 3) and on a Sun Fire V880 (four
sparcv9, 750MHz, 8GB RAM), respectively. Apparently for both settings, RMI
data transfers are the fastest, followed by JAX-RPC with JWSDP [8], SOAP
XML-RPC with Axis [1], and finally Glue’s implementation [5] of SOAP-RPC.
Note that in the figure on the left hand side we utilized HTTP tunneling of
RMI calls in order to get access to the cluster frontend across the firewall. The
overhead of SOAP based data transfers compared to RMI is mainly caused by

A Service-Oriented Framework for Parallel Medical Image Reconstruction

621

the generation and parsing of SOAP messages and to a much lesser extent by
the conversion of image data represented as a Java byte array to/from XML.

6

Conclusions

In this paper we gave an overview of a service-oriented system that provides
access to parallel image reconstruction codes on different parallel computers via
the Internet based on RMI and SOAP. We are currently extending our system to
provide support for automatic service selection for the Web Services and OGSAbased service implementations. Moreover our Jini-based service manager is being
extended in order to allow transparent access to a local Jini federation through
Web Services or OGSA protocols similar to the ICENI system [6].
Major directions of future work will include the extension of the service
manager with more sophisticated methods for automatic service selection based
on user-specified criteria, support for authorization and authentication, and for
secure data transfers. Our services will be integrated into a larger Grid-enabled
Medical Simulation System which is currently being developed within the EU
project GEMSS. Within GEMSS, negotiable QoS support for medical services
and security of patient data under the constraints of EU legislation will be of
major importance.

References
1. Apache Axis. http://ws.apache.org/axis
2. W. Backfrieder, S. Benkner, G. Engelbrecht. Web-based parallel ML-EM reconstruction for SPECT on SMP clusters, Proc. METMBS’01, CSREA Press, 2001.
3. I. Foster, C. Kesselman, J. Nick, S. Tuecke. The Physiology of the Grid: An Open
Grid Services Architecture for Distributed Systems Integration, Open Grid Service
Infrastructure WG, Global Grid Forum, June 22, 2002.
4. I. Foster, C. Kesselman, S. Tuecke. The Anatomy of the Grid: Enabling Scalable
Virtual Organizations, International J. Supercomputer Applications, 15(3), 2001.
5. Glue. http://www.themindelectric.com/glue
6. N. Furmento, W. Lee, A. Mayer, S. Newhouse, J. Darlington. ICENI: An Open
Grid Service Architecture Implemented with Jini. Proceedings of the IEEE/ACM
SC2002 Conference, November 2002.
7. Message Passing Interface Forum. MPI: A Message-Passing Interface Standard.
Vers. 1.1, June 1995. MPI-2: Extensions to the Message-Passing Interface, 1997.
8. Java Web Services Developer Pack. http://java.sun.com/webservices
9. S. Tuecke, K. Czajkowski, I. Foster, J. Frey, S. Graham, C. Kesselman. Grid Service
Specification: Open Grid Service Infrastructure WG, GGF, Draft 2, 7/17/2002.
10. T. Sandholm, R. Seed, J. Gawor. OGSI Technology Preview Core - A Grid Service Container Framework, OGSI Technology Preview 5, DRAFT 11/08/2002.
http://www.globus.org/ogsa/releases/TechPreview
11. OpenMP Architecture Review Board. OpenMP C and C++ Application Program
Interface. Version 2.0, March 2002. http://www.openmp.org.
12. L. A. Shepp and Y. Vardi, Maximum likelihood reconstruction for emission tomography. IEEE Trans. Med. Imaging, vol. 1, no. 2, pp. 113-122, 1982.
13. Web Services Invocation Framework. http://ws.apache.org/wsif

