Parallel Algorithms for Dandelion-Like Codes
Saverio Caminiti and Rossella Petreschi
Computer Science Department, Sapienza University of Rome
Via Salaria, 113 - I00198 Rome, Italy
{caminiti,petreschi}@di.uniroma1.it

Abstract. We consider the class of Dandelion-like codes, i.e., a class of
bijective codes for coding labeled trees by means of strings of node labels. In the literature it is possible to ﬁnd optimal sequential algorithms
for codes belonging to this class, but, for the best of our knowledge, no
parallel algorithm is reported. In this paper we present the ﬁrst encoding
and decoding parallel algorithms for Dandelion-like codes. Namely, we design a unique encoding algorithm and a unique decoding algorithm that,
properly parametrized, can be used for all Dandelion-like codes. These algorithms are optimal in the sequential setting. The encoding algorithm
implementation on an EREW PRAM is optimal, while the eﬃcient implementation of the decoding algorithm requires concurrent reading.

1

Introduction

Trees are one of the most studied class of graphs in Computer Science; they are
used in a large variety of domains, including computer networks, computational
biology, databases, pattern recognition, and web mining. In almost all applications, tree nodes and edges are associated with labels, weights, or costs. Examples
range from XML data to tree-based dictionaries (heaps, AVL, RB-trees), from
phylogenetic trees to spanning trees of communication networks, from indexes
to tries (used in compression algorithms). Many are the usual representations
of tree data structures: adjacency matrices, adjacency lists, parent vectors, and
balanced parentheses are just a few examples. An interesting alternative is based
on coding labeled trees by means of strings of node labels.
String-based codes for labeled trees have many practical applications. For
example, they are used in fault dictionary storage [1], distributed spanning tree
maintenance [2], generation of random trees [3], Genetic Algorithms [4]. In this
paper we restrict our attention to bijective string-based codes in which the length
of the string must be equal to n − 2 [5] (n is the number of nodes of the encoded
tree). The ﬁrst bijective string-based coding for trees is due to Pr¨
ufer [6]. since
then, many other bijective codes have been introduced [7,8,9,10,11,12,13,14].
Concerning algorithmic aspects of these codes, there is a wide literature presenting optimal sequential algorithms for encoding and decoding all of them. In particular we refer to [15] for the class of Pr¨
ufer-like codes (the ﬁrst 4 codes in Table 1)
Work partially supported by Sapienza University of Rome under the project “Strutture Dati e Tecniche Algoritmiche Evolute per Modelli di Calcolo Innovativi”.
G. Allen et al. (Eds.): ICCS 2009, Part I, LNCS 5544, pp. 611–620, 2009.
c Springer-Verlag Berlin Heidelberg 2009

612

S. Caminiti and R. Petreschi

Table 1. Costs of known algorithms for bijective string-based codes. Parallel costs are
expressed as the number of processors × maximum execution time.

Pr¨
ufer [6]
2nd Neville [13]
3rd Neville [13]
Stack-Queue [9]
θn [10]
Happy [14]
Dandelion [14]
MHappy [7]
Blob [11,14]
Chen [8]

Sequential
Parallel
Encoding Decoding Encoding Decoding
√
O(n)
O(n)
O(n)
O(n√log n)
√
O(n)
O(n)
O(n log n) O(n√log n)
O(n)
O(n)
O(n)
O(n√log n)
√
O(n)
O(n)
O(n log n) O(n log n)
O(n)
O(n)
unknown unknown
O(n)
O(n)
unknown unknown
O(n)
O(n)
unknown unknown
O(n)
O(n)
unknown unknown
O(n)
O(n)
unknown unknown
O(n)
O(n)
unknown unknown

and to [7] for the other codes. A survey of optimal sequential algorithms can be
found in [16]. Also parallel algorithms have been studied [7,17,18,19], but results
are known only for Pr¨
ufer-like codes. More results related to sequential and parallel algorithms for bijective codes can be found in [20] and are summarized in Table 1.
In this paper we make a further step in understanding the feasibility of encoding and decoding in a parallel setting. We focus on the class of Dandelion-like
codes introduced in [21] and we present eﬃcient parallel algorithms for encoding and decoding all these codes. This class contains the second block of codes
(rows 5 to 8) in Table 1. Dandelion-like codes are especially useful in Genetic
Algorithms (GA) since experimental analysis show that Pr¨
ufer-like codes perform poorly (with respect to GA requirements) [22] while Dandelion-like codes
achieve best results [21]. The techniques we use for Dandelion-like codes can be
also exploited to obtain eﬃcient parallel algorithms for encoding and decoding
the Blob code (rows 5 in Table 1).
The paper is organized as follows: after a few preliminary deﬁnitions, in Sec.3
we recall the Dandelion code, together with examples. In Sec.4 we recall the class
of Dandelion-like codes and introduce an encoding and a decoding algorithm
that, properly parametrized, can be used for all codes in the class. In a sequential
setting these two algorithms run in linear time and are therefore optimal. In
Sec.6 we discuss how to parallelize our algorithms for the PRAM model. For the
encoding algorithm we obtain optimal linear cost implementation on an EREW
PRAM. The decoding algorithm requires O(n log n) cost on a CREW PRAM.

2

Preliminary Definitions

In this section, we introduce some deﬁnitions that will be useful in the rest of
this paper. As usual, the notation [a, b] represents the integer interval from a to
b, both included.
Definition 1. A labeled n-tree is an unrooted tree with n nodes, each with a
distinct label selected in the set [0, n − 1].

Parallel Algorithms for Dandelion-Like Codes

613

Fig. 1. Example of Dandelion encoding algorithm execution

Since in this paper we only deal with labeled trees, we will refer to them simply
as trees. In the following all trees will be regarded as rooted in the ﬁxed node 0
and its edges will be oriented upward from a node to its parent; an example is
depicted in Fig.1a.
Definition 2. Given a function g from the set [0, n] to the set [0, n], the functional digraph G = (V, E) associated with g is a directed graph with V =
{0, . . . , n} and E = {(v, g(v)) for every v ∈ V }.
For this class of graphs the following lemma holds:
Lemma 1. A digraph G = (V, E) is a functional digraph if and only if the
out-degree of each node is equal to 1.
Functional digraphs are easily generalizable for representing functions which are
undeﬁned in some values: if g(x) is not deﬁned, the node x in G does not have
outgoing edges.
As an example consider a rooted tree T and let p[v] be the parent of v for
each v in T . T is the functional digraph associated with the function p.
In the following, when no confusion arise, we will consider vectors as functions
and vice versa. The notation u
v identiﬁes the directed path from node u to
node v; u
u is the degenerate path of length 0. Loops will be considered as
cycles of length 1.

3

The Dandelion Code

We now recall the Dandelion code (originally introduced in [14]) as reinterpreted
in [7] in which a tree T is transformed into a functional digraph Gg . Initially Gg =
T , thus the function g is equivalent to the parent vector of T . The Dandelion
code choose node 1 to play a special role and rearrange all nodes in 1
0 into
cycles; the resulting digraph will correspond to a function g such that g[0] is
undeﬁned and g[1] = 0. Let us detail the rearrangement of nodes in 1
0:
0 and let mi = max{vi , . . . , vm }.
Let 1 = v1 , v2 , . . . , vl = 0 be all nodes in 1
Among them we choose all nodes such that mi = vi (excluding vl ); these nodes

614

S. Caminiti and R. Petreschi

identify a subsequence f1 , f2 , . . . , fk of sequence v1 , v2 , . . . , vl−1 . We assign f0 =
1. As an example consider the tree of 11 nodes, labeled from 0 to 10 in Fig.1a in
which the path 1
0 is (1, 4, 6, 8, 3, 0). We obtain f0 = 1, f1 = 8, f2 = 3. The
algorithm proceeds by set g[fi ] = g[fi−1 ] for each i from k down to 1. During
this process all nodes in the original path between 1 and 0 are partitioned into
several cycles (or loops). At the end the path 1
0 is reduced to a single edge
(1, 0) and the resulting codeword is g[2], g[3], . . . , g[n − 1]. In our example, since
f0 = 1, f1 = 8, and f2 = 3, the algorithm set g[3] ← g[8] = 3, introducing a loop,
and g[8] ← g[1] = 4, introducing a cycle. Fig.1d shows the resulting digraph: the
associated codeword is W = [6, 3, 6, 1, 8, 8, 4, 1, 9].
The procedure can be easily inverted to obtain the tree T corresponding to
any given codeword W = w1 , w2 , . . . , wn−2 . Initially reconstruct the functional
digraph corresponding to g deﬁned as: g[0] is undeﬁned, g[1] = 0, and g[i] =
wi−1 . Then, identify all cycles C1 , C2 , . . . , Ck in Gg . For each cycle Ci , let us
call characteristic its maximum node fi = max{v ∈ Ci }. W.l.o.g. assume that
characteristic nodes are numbered such that f1 > f2 > . . . > fk .
The reconstruction of the original path 1
0 is obtained reinserting all nodes
of each cycle in between 1 and 0. Cycles are selected in descending order with
respect to their characteristic values and, for each i from 0 to k − 1, we set
g[fi ] = g[fi+1 ] (where f0 = 1). At the end we set g[fk ] = 0: Gg is now equal to
the tree T corresponding to the given codeword W .
As an example of decoding consider the codeword W = [6, 3, 6, 1, 8, 8, 4, 1, 9].
It is easy to see that, according with the reconstruction described above, we
initially obtain the functional digraph represented in Fig.1d. This graph has two
cycles: one is a loop on node 3, and one is induced by nodes 6, 8, and 4. Thus
we obtain f0 = 1, f1 = 8, f2 = 3. Then we set g[1] ← g[8] = 4, g[8] ← g[3] = 3,
and g[3] ← 0. Now Gg is exactly the tree represented in Fig.1a.

4

Dandelion-Like Codes

In this section we report the class of Dandelion-like codes introduced in [21]. We
describe them in terms of functional digraphs in the style of [7] and we explicitly
present one optimal encoding and one optimal decoding parametrized algorithms
that can be used for all these codes.
Looking at the Dandelion code presented in Sec.3 it is easy to see that several
details can be changed to originate diﬀerent codes:
1. use minimum instead of maximum to compute fi nodes among those in the
path 1
0 (the characteristic nodes in the decoding procedure);
2. search downward in the path from fi to 1 instead of searching upward in the
path from fi to 0;
3. invert the orientation of all edges in cycles.
A summary of the 23 bijective codes obtained by all possible combinations of the
three changes is reported in the following table – it is to notice that in [21] the
8 bijective codes reported were selected among 16 codes generated considering 4
possible changes of the decoding phase. Codes are numbered according with [21].

Parallel Algorithms for Dandelion-Like Codes

Code max/min up/down edge orientation
C1
max
up
preserve
C2
max
down
invert
C3
max
down
preserve
C4
max
up
invert
C5
min
up
preserve
C6
min
down
invert
C7
min
down
preserve
C8
min
up
invert

615

Code name
Dandelion [14]
Happy [14]
MHappy [7]
θn bijection [10]

Encoding Algorithm. In this section we present an algorithm able to encode
all the 8 Dandelion-like codes. In Program 1 we report only the fragment of
code that transforms a tree into a functional digraph: obtaining the codeword
from the functional digraph and vice versa is straightforward (see Sec.3). The
Dandelion-Like Encoding Algorithm has three parameters:
1. μ ∈ {min, max} speciﬁes whether to search for minimum or maximum values;
2.
∈ {up, down} establishes if the μ values should be searched upward or
downward;
3. invertEdges is a boolean value that discriminates whether the orientation
of cycle edges should be inverted or not.
0, the maximum/
The value μ (v) represents, for each v in the path 1
minimum value above/below node v (including v itself). Thus, depending on
the parameters μ and , the function μ (v) can be one of the followings:
maxup (v) = max{w ∈ v
0}
maxdown (v) = max{w ∈ 1
v}
minup (v) = min{w ∈ v
0}
mindown (v) = min{w ∈ 1
v}
Let us now analyze the algorithm. All values μ (v) can be computed with simple
forward/backward scan of the path 1
0; at the same time all fi are identiﬁed.
This requires O(n) time. In line 4, if = down, the highest node before fi+1
is identiﬁed. Indeed, in this case, fi should form a cycle with all node above it
and below fi+1 . This operation can be performed in linear time traversing the
path 1
0 once again. The same time bound holds for lines 5–6. Line 7 can
eﬃciently be implemented in the following way: each node v in the path 1
0
sets itself as the new parent of its current parent (i.e., p [p[v]] = v) and all values
in p are updated according with the values in p . The overall time complexity of
the Dandelion-Like Encoding Algorithm is linear.
Consider, as an example, the encoding of the tree shown in Fig.1a with all
possible codes. The various codes identify the following nodes in line 2:
C2 , C3 : f1 = 4, f2 = 6, f3 = 8
C1 , C4 : f1 = 8, f2 = 3
C6 , C7 : f1 = 4, f2 = 3
C5 , C8 : f1 = 3
thus introducing the following cycles in the functional digraph Gp :
C2 , C3 : (4), (6), (8, 3)
C1 , C4 : (4, 6, 8), (3)
C6 , C7 : (4, 6, 8), (3)
C5 , C8 : (4, 6, 8, 3)
The resulting codewords are: C1 = [6, 3, 6, 1, 8, 8, 4, 1, 9], C2 = [6, 8, 4, 1,
6, 8, 3, 1, 9], C3 = [6, 8, 4, 1, 6, 8, 3, 1, 9], C4 = [6, 3, 8, 1, 4, 8, 6, 1, 9],

616

S. Caminiti and R. Petreschi

Program 1. Dandelion-Like Encoding Algorithm
Parameters: μ, , invertEdges
Input: a tree T represented by its parent vector p
Output: a functional digraph Gp such that p[0] = undef and p[1] = 0
1. Compute μ (v) for each v in 1
0 excluding 1 and 0
2. Identify all nodes f1 , f2 , . . . , fk such that μ (fi ) = fi
3. f0 = 1; fk+1 = 0
0 : p[v] = fi+1 } ∀ 1 ≤ i ≤ k
4. if
= down then fi = {v ∈ 1
5. for i = k down to 1 do p[fi ] = p[fi−1 ]
6. p[1] = 0
7. if invertEdges then invert all edges in cycles

Program 2. Dandelion-Like Decoding Algorithm
Parameters: μ, , invertEdges
Input: a functional digraph Gp such that p[0] = undef and p[1] = 0
Output: a tree T represented by its parent vector p
1. Find all cycles Ci and their characteristic nodes fi according to μ
2. if (μ = max and = up) or (μ = min and = down) then
3.
Sort {fi } in decreasing order
4. else Sort {fi } in increasing order
5. if invertEdges then invert all edges in cycles
6. f0 = 1; fk+1 = 0
7. if
= down then fi = {v ∈ Ci : p[v] = fi } ∀ 1 ≤ i ≤ k
8. for i = 0 to k − 1 do p[fi ] = p[fi+1 ]
9. p[fk ] = 0

C5 = [6, 4, 6, 1, 8, 8, 3, 1, 9], C6 = [6, 3, 8, 1, 4, 8, 6, 1, 9], C7 = [6, 3, 6, 1, 8,
8, 4, 1, 9], and C8 = [6, 8, 3, 1, 4, 8, 6, 1, 9].
Notice that the 8 codes are all diﬀerent from each other, even thought, on this
small example, diﬀerent codes produce the same codeword.
Decoding Algorithm. We now describe how to invert the transformation: given
a functional digraph we identify its cycles and compute, for each cycle Ci the characteristic node fi according with the function speciﬁed by the parameter μ. Then
all cycles are broken and their nodes are placed in between 1 and 0 in such a way
that the original path 1
0 of the tree is reconstructed. If invertEdges is true
then, before breaking cycles, the edge orientation should be reestablished.
Let us now describe how to reconstruct the correct order among the characteristic nodes. If μ = max and
= up then greater fi must be below any
other characteristic node, thus the fi values must be ordered in decreasing order: f1 > f2 > . . . > fk . On the other hand, if = down then the greater fi
must be placed above any other characteristic node, thus implying an increasing
order: f1 < f2 < . . . < fk . If μ = min the orders are reversed. So, the path 1
0
have to be rebuilt according with the ordering of the fi : 1
f1
...
fk
0.
Finally notice that, if = up then the characteristic node should be above
all nodes of its cycle, otherwise it should be below them. This is all we need to
correctly rebuild the path 1
0 of the original encoded tree.

Parallel Algorithms for Dandelion-Like Codes

617

Program 3. Identiﬁcation of Characteristic Nodes
function Analyze(v)
1. status(v) = inP rocess
2. if status(p[v]) = inP rogress then compute μ value in cycle p[v]
3. else if status(p[v]) = processed then Analyze(p[v])
4. status(v) = processed
main
1. for v = 2 to n − 1 do
2.
if status(v) = processed then Analyze(v)

v

The computation of the reverse function is detailed in Program 2. Line 1 can
be implemented by means of a recursive function that follows the outgoing edge
of each node until it identiﬁes a cycle, then an auxiliary function is used to
compute the min/max value in that cycle (see Program 3). This requires O(n)
time. An integer sorting algorithm can be used to sort the fi values in increasing
or decreasing order and cycles edges can be inverted as described in the analysis
of the encoding algorithm. Line 7 (if required) identiﬁes the only node v in the
cycle of fi such that p[v] = fi , each such node becomes new value for fi : this
require O(n) time. Thus, the overall decoding procedure requires linear time.

5

Parallel Implementation

In this section we present a parallel version of the encoding and decoding algorithms proposed in Sec.4. Our algorithms are described for the theoretical
PRAM model and costs are expressed as the number of processors multiplied by
the maximum time required by a single processor.
We choose the PRAM classical model because we do not need to address any
speciﬁc hardware. In the last decade, PRAM model has been deemed useless
by many researchers because it is too abstract compared with actual parallel
architectures. As noted in the introduction, this trend is changing. At SPAA’07,
Vishkin and Wen reported about the recent advancements achieved at the University of Maryland within the project PRAM-On-Chip [23]. The XMT (eXplicit
Multi-Threading) general-purpose computer architecture is a promising parallel
algorithmic architecture to implement PRAM algorithms. They also developed
a single-instruction multiple-data (SIMD) multi-thread extension of C language
with the intent of providing an easy programing tool to implement PRAM algorithms. It has primitives like: Preﬁx Sum, Join, Fetch and Increment, etc.
Thus we think that PRAM is robust, reasonable, and well studied theoretical
framework for describing high level parallel algorithms.
In the following we will consider PRAM with Exclusive Write (EW) and either
Exclusive Read (ER) or Concurrent Read (CR). Due to the lack of space, we
don’t explicitly recall the well known basic techniques used in this section; we
refer the interested reader to [24].
Parallel Encoding. We now describe how to encode Dandelion-like codes on
an EREW PRAM; the parallel algorithm is detailed in Program 4.

618

S. Caminiti and R. Petreschi

Program 4. Dandelion-Like Parallel Encoding Algorithm
Parameters: μ, , invertEdges
Input: a tree T represented by its parent vector p
Output: a functional digraph Gp such that p[0] is undeﬁned and p[1] = 0
1. Compute min(Tv ) and level(v) for each v ∈ T
2. Create P corresponding to the path 1
0
3. Compute μ (v) for each v ∈ P excluding 1 and 0
4. Identify all nodes f1 , f2 , . . . , fk such that μ (fi ) = fi
5. f0 = 1; fk+1 = 0
6. if
= down then
7.
for i = 1 to k in parallel do fi = pred[fi+1 ]
8. for i = 1 to k in parallel do p[fi ] = p[fi−1 ]
9. p[1] = 0
10. if invertEdges then
11.
for v ∈ P in parallel do p[p[v]] = v

Initially we compute, for each node v, min(Tv ): the minimum value in the
subtree rooted at v. If min(Tv ) = 1 then v is in the path 1
0. This operation
requires O(log n) time with O(n/ log n) processors by using the Rake technique.
With the same bounds we can compute the top-down level of each node (Euler
Tour technique): exploiting this information we are able to create a vector P
containing the sequence of all nodes in the path 1
0.
The function μ (v) can be computed for all nodes in P (with the same time
and processors bounds of the above operations) regarding this path as a tree TP
and computing the max/min value in the subtree of each node. If
= down
then TP have to be rooted in 0, otherwise it must be rooted in 1. To order the
fi values we can use Preﬁx-Sum on vector P assigning 1 to nodes v such that
μ (v) = v and 0 otherwise.
The three cycles of lines 7, 8, and 11 require O(1) with n processors and do
not imply concurrent reading or writing. The value pred[v] (the predecessor of
v in the path 1
0) can be computed in the following way: for each node in
v ∈ P set pred[p[v]] = v. Applying Brent’s Theorem all these operations can be
scheduled on O(n/ log n) processors in O(log n) time. The overall cost is linear
and thus the algorithm is optimal.
Parallel Decoding. The most demanding step in the parallel decoding algorithm
is the computation of characteristic nodes. It can be obtained in O(log n) time with
O(n) processors on a CREW PRAM in a Pointer Jumping like fashion: for each
node we follow the outgoing edge searching for the max/min value in the ascending
path (the parameter μ discriminate whether to search for maximum or minimum
values). After each step we set p[v] = p[p[v]], thus obtaining a single Pointer Jump.
The procedure is detailed in Program 5: the value asc(v) is the min/max value
in the ascending path of v. At each step asc(v) is compared with asc(p[v]) and
eventually updated. Notice that we explicitly ﬂag whether the value asc(v) comes
from v itself or has been encountered in the proper ascending path. At the end of the
log n iterations if asc(v) = v and self(v) is false, we can state that v is the min/max

Parallel Algorithms for Dandelion-Like Codes

619

Program 5. Parallel Identiﬁcation of Characteristic Nodes
1. p[0] = 0
2. for each node v ∈ T in parallel do asc(v) = v; self(v) = true
3. for j = 1 to log n do
4.
for each node v ∈ T in parallel do
5.
if asc(p[v]) = μ{asc(p[v]), asc(v)} then
6.
asc(v) = asc(p[v]); self(v) = false
7.
p[v] = p[p[v]]

Program 6. Dandelion-Like Parallel Decoding Algorithm
Parameters: μ, , invertEdges
Input: a functional digraph Gp such that p[0] is undeﬁned and p[1] = 0
Output: a tree T represented by its parent vector p
1. Identify all characteristic nodes f1 , f2 , . . . , fk according with μ and
2. if invertEdges then
3.
for each v ∈ cycles in parallel do p[p[v]] = v
4. f0 = 1; fk+1 = 0
5. if
= down then
6.
for i = 1 to k in parallel do fi = pred(fi )
7. for i = 0 to k − 1 in parallel do
8. p[fi ] = p[fi+1 ]
9. p[fk ] = 0

node in its cycle. Indeed, a value equal to v has been found in the proper ascending
path of v, this means that there exists a path v
v, i.e., a cycle. Moreover, no
node smaller/greater that v has been encountered in this cycle. All these nodes can
be enumerated with Preﬁx-Sum to generate the (increasing or decreasing) ordered
sequence of the characteristic nodes f1 , f2 , . . . , fk . We assume that a copy of p is
used in Program 5, since the original vector p will be required latter in the decoding.
Once characteristic nodes have been identiﬁed, a further Pointer Jumping
can be used to broadcast a ﬂag in their ascending paths, thus identifying all
nodes belonging to some cycle. The rest of the Decoding Algorithm proceeds as
detailed in Program 6. Namely, all the three cycles of lines 3, 6, and 8 require
O(1) time with n processors, provided that the pred values are computed for all
nodes belonging to any cycle (as described in Parallel Encoding for nodes in P ).

6

Conclusions and Open Problems

Concluding, we want to remark that also for the Blob code [11,14] it is possible
to obtain parallel algorithms with the very same costs of those presented in
this paper. This result can be obtained combining ideas presented in this paper
with the redeﬁnition of the Blob code in terms of transformation of trees in to
functional digraphs given in [7]. With respect to Table 1, it remains an open
problem to study parallel algorithms for the Chen code.

620

S. Caminiti and R. Petreschi

References
1. Boppana, V., Hartanto, I., Fuchs, W.: Full Fault Dictionary Storage Based on
Labeled Tree Encoding. In: IEEE VTS 1996, pp. 174–179 (1996)
2. Garg, V., Agarwal, A.: Distributed Maintenance of a Spanning Tree Using Labeled Tree Encoding. In: Cunha, J.C., Medeiros, P.D. (eds.) Euro-Par 2005. LNCS,
vol. 3648, pp. 606–616. Springer, Heidelberg (2005)
3. Deo, N., Kumar, N., Kumar, V.: Parallel Generation of Random Trees and Connected Graphs. Congr. Num. 130, 7–18 (1998)
4. Reeves, C., Rowe, J.: Genetic Algorithms: A Guide to GA Theory. Springer, Heidelberg (2003)
5. Cayley, A.: A Theorem on Trees. Quart. J. Math. 23, 376–378 (1889)
6. Pr¨
ufer, H.: Neuer Beweis eines Satzes u
¨ber Permutationen. Archiv der Mathematik
und Physik 27, 142–144 (1918)
7. Caminiti, S., Petreschi, R.: String Coding of Trees with Locality and Heritability. In: Wang, L. (ed.) COCOON 2005. LNCS, vol. 3595, pp. 251–262. Springer,
Heidelberg (2005)
8. Chen, W.: A General Bijective Algorithm for Increasing Trees. Syst. Sci. Math.
Sci. 12, 194–203 (1999)
9. Deo, N., Micikeviˇcius, P.: A New Encoding for Labeled Trees Employing a Stack
and a Queue. Bulletin of ICA 34, 77–85 (2002)
¨ Remmel, J.: Bijections for Cayley Trees, Spanning Trees, and Their
10. E˘
gecio˘
glu, O.,
q-Analogues. J. Comb. Th. 42A, 15–30 (1986)
11. Kreweras, G., Moszkowski, P.: Tree codes that preserve increases and degree sequences. J. Disc. Math. 87, 291–296 (1991)
12. Moon, J.: Counting Labeled Trees. William Clowes and Sons, London (1970)
13. Neville, E.: The Codifying of Tree-Structure. In: Proc. of Cambridge Philosophical
Soc., vol. 49, pp. 381–385 (1953)
14. Picciotto, S.: How to Encode a Tree. PhD thesis, U. California, San Diego (1999)
15. Caminiti, S., Finocchi, I., Petreschi, R.: On Coding Labeled Trees. TCS 382, 97–108
(2007)
16. Caminiti, S., Deo, N., Micikeviˇcius, P.: Linear-time Algorithms for Encoding Trees
as Sequences of Node Labels. Congr. Num. 183, 65–75 (2006)
17. Chen, H., Wang, Y.: An Eﬃcient Algorithm for Generating Pr¨
ufer Codes from
Labelled Trees. TCS 33, 97–105 (2000)
18. Deo, N., Micikeviˇcius, P.: Parallel Algorithms for Computing Pr¨
ufer-Like Codes of
Labeled Trees. Technical report, CS-TR-01-06, Department of Computer Science,
University of Central Florida, Orlando (2001)
19. Greenlaw, R., Halld´
orsson, M., Petreschi, R.: On Computing Pr¨
ufer Codes and
Their Corresponding Trees Optimally in Parallel. In: JIM 2000 (2000)
20. Caminiti, S.: On Coding Labeled Trees. PhD thesis, Sapienza U. of Rome (2007)
21. Paulden, T., Smith, D.: Recent advances in the study of the dandelion code, happy
code, and blob code spanning tree representations. In: IEEE CEC 2006, pp. 2111–
2118 (2006)
22. Gottlieb, J., Julstrom, B., Raidl, G., Rothlauf, F.: Pr¨
ufer Numbers: A Poor Representation of Spanning Trees for Evolutionary Search. In: GECCO 2001, pp. 343–350
(2001)
23. Wen, X., Vishkin, U.: PRAM-on-Chip: First Commitment to Silicon. In: ACM
SPAA 2007, pp. 301–302 (2007)
24. J´
aJ´
a, J.: An Introduction to Parallel Algorithms. Addison-Wesley, Reading (1992)

