A Graph Clustering Algorithm Based on Minimum and
Normalized Cut
Jiabing Wang1, Hong Peng1, Jingsong Hu1, and Chuangxin Yang1,2
1

School of Computer Science and Engineering, South China University of Technology
Guangzhou 510641, China
2
Guangdong University of Commerce, Guangzhou 510320, China
{jbwang, mahpeng, cshjs}@scut.edu.cn

Abstract. Clustering is the unsupervised classification of patterns into groups.
In this paper, a clustering algorithm for weighted similarity graph is proposed
based on minimum and normalized cut. The minimum cut is used as the
stopping condition of the recursive algorithm, and the normalized cut is used to
partition a graph into two subgraphs. The algorithm has the advantage of many
existing algorithms: nonparametric clustering method, low polynomial
complexity, and the provable properties. The algorithm is applied to image
segmentation; the provable properties together with experimental results
demonstrate that the algorithm performs well.
Keywords: graph
segmentation.

clustering,

minimum

cut,

normalized

cut,

image

1 Introduction
Clustering is the unsupervised classification of patterns (observations, data items, or
feature vectors) into groups (clusters) [1-2]. It groups a set of data in a way that
maximizes the similarity within clusters and minimizes the similarity between two
different clusters. Due to its wide applicability, the clustering problem has been
addressed in many contexts; this reflects its broad appeal and usefulness as one of the
steps in exploratory data analysis.
In the past decade, one of the most active research areas of data clustering methods
has been spectral graph partition, e.g. [3-7], because of the following advantages:
does not need to give the number of clusters beforehand; low polynomial
computational complexity, etc. In spectral graph partition, the original clustering
problem is first transformed to a graph model; then, the graph is partitioned into
subgraphs using a linear algebraic approach.
Minimum cut in similarity graphs were used by Wu and Leahy [8], Hartuv and
Shamir [9]. The minimum cut often causes an unbalanced partition; it may cut a
portion of a graph with a small number of vertices [3-4]. In the context of graph
clustering, this is, in general, not desirable. To avoid partitioning out a small part of a
graph by using edge-cut alone, many graph partitioning criteria were proposed, such
as ratio cut [10], normalized cut [4], min-max cut [11], etc. Soundararajan and Sarkar
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 497 – 504, 2007.
© Springer-Verlag Berlin Heidelberg 2007

498

J. Wang et al.

[12] have made an in-depth research to evaluate the following partitioning criteria:
minimum cut, average cut, and normalized cut.
Normalized cut proposed by Shi and Malik [4] is a spectral clustering algorithm
and has been successfully applied to many domains [13-18], especially in image
segmentation. However, when applying normalized cut to recursively partitioning
data into clusters, a real number parameter⎯the stopping condition⎯must be given
beforehand [4]. To our knowledge, there are no theoretic results about how to select
the parameter. If the parameter is inappropriate, the clustering result is very bad (see
an example as shown in Fig. 1 and Fig. 2 in section 2).
In this paper, we propose a clustering algorithm based on minimum and
normalized cut. By a novel definition of a cluster for weighted similarity graph, the
algorithm does not need to give the stopping condition beforehand and holds many
good properties: low polynomial complexity, the provable properties, and
automatically determining the number of clusters in the process of clustering.
The rest of the paper is organized as follows. In section 2, we give some basic
definitions, a brief review of normalized cut, and the description of our algorithm. In
section 3, we prove some properties of the algorithm. In section 4, we apply the
algorithm to image segmentation and give some preliminary results. This paper
concludes with some comments.

2 The MAN-C Algorithm
A weighted, undirected graph G = (V, E, W) consists of a set V of vertexes, a set E of
edges, and a weight matrix W. The positive weight wij on an edge connecting two
nodes i and j denotes the similarity between i and j. For a weighted, undirected graph
G, we also use n to denote the number of vertexes of G, m the number of edges of G,
T the sum of weights of all edges of G.
The distance d(u,v) between vertices u and v in G is the minimum length of a path
joining them, if such path exists; otherwise d(u,v) = ∞ (the length of a path is the
number of edges in it). The degree of vertex v in a graph, denoted deg(v), is the
number of edges incident on it.
We say that A and B partition the set V if A ∪ B = V and A ∩ B = ∅. We denote the
partition by the unordered pair (A, B). The cost of a partition for a graph is the sum of
the weights of the edges connecting the two parts cut by the partition, i.e.,

Cut ( A, B) =

∑ wij .

i∈A, j∈B

The graph minimum cut (abbreviated min-cut) problem is to find a partition (A, B)
such that the cost of the partition is minimal, i.e.,
minCut ( A, B ) = min ∑

i∈A, j∈B

wij .

Shi and Malik [4] proposed a normalized similarity criterion to evaluate a partition.
They call this criterion normalized cut:
Ncut =

Cut ( A, B)
Cut ( B, A)
+
.
assoc( A,V ) assoc( B,V )

A Graph Clustering Algorithm Based on Minimum and Normalized Cut

499

where assoc( A,V ) = ∑ i∈A, j∈V wij is the total connection from nodes in A to all the
nodes in the graph, and assoc(B, V) is similarly defined. It is clear that the optimal
partition can be achieved by minimizing Ncut.
The theoretical attraction of the normalized cut lies in its analytical solution. The
near-optimal solution of the normalized cut can be obtained by solving the relaxed
generalized eigensystem. One key advantage of using normalized cut is that a good
approximation to the optimal partition can be computed very efficiently. Let D
represent a diagonal matrix such that Dii = ∑ j∈V wij , i.e., Dii is the sum of the

weights of all the connections to node i. Then, the problem of minimizing Ncut can be
written as the expression (1), which can be reduced to a generalized eigenvalue
system (2) [4].
MinNcut = min
x

xT ( D − W ) x
.
xT Dx

( D − W ) x = λDx .

(1)
(2)

where x represents the eigenvectors, in the real domain, which contain the necessary
segmentation information. The eigenvector with the second smallest eigenvalue,
called Fiedler vector, is often used to indicate the membership of data points in a
subset. Fiedler vector provides the linear search order for the splitting point that can
minimize the Ncut objective.
Just as statements in introduction, when applying normalized cut to recursive
partitioning data into clusters, a parameter⎯the stopping condition⎯must be given
beforehand. If the parameter is inappropriate, the clustering result is very bad. An
example is given in Fig. 1 and Fig. 2 that show clustering results when given different
parameters.
In Fig. 1, the leftmost is the original image, the second one is the clustering result
when given the stopping condition Ncut < 0.25, and the other two images is the

Fig. 1. The leftmost is the original image. The second one is the clustering result when Ncut <
0.25. The other two images is the clustering result when Ncut < 0.5.

Fig. 2. The clustering result when Ncut < 1

500

J. Wang et al.

clustering result when given the stopping condition Ncut < 0.5. Fig. 2 shows the
clustering result when given the stopping condition Ncut < 1. We can see that different
parameters result in different clustering results. Especially, when Ncut < 0.25, the
normalized cut cannot segment the original image. So, selection of the stopping
condition is very important for applying normalized cut to data clustering. However, to
our knowledge, there are no theoretic results on how to select the parameter.
In order to avoid the issue of parameter selection, we give the following definition:
Definition 1. For a graph G = (V, E, W), G is a cluster if and only if min-cut(G) ≥
(nT)/(2m), where n is the number of vertexes of G, m is the number of edges of G, and
T is the sum of weights of all edges of G.

We will see that such a definition of a cluster results in good properties as described
in section 3.
According to the definition 1, we have the clustering algorithm MAN-C (Minimum
And Normalized Cut) as shown in Fig. 3.
Algorithm MAN-C(G)
begin
C ← Min-Cut(G);
if(C < (nTG)/(2mG))
(H, H′) ← Ncut(G);
MAN-C(H);
MAN-C(H′);
else
return G;
end if
end
Fig. 3. The MAN-C algorithm

In Fig. 3, nG is the number of vertexes of G, mG is the number of edges of G, and
TG the sum of weights of all edges of G. The procedure Min-Cut(G) returns the
minimum cut value C, and Ncut(G) returns two subgraphs H and H′ by
implementation of normalized cut. Procedure MAN-C returns a graph in case it
identifies it as a cluster, and subgraphs identified as clusters are returned by lower
levels of the recursion. Single vertices are not considered clusters and are grouped
into a singletons set S. The collection of subgraphs returned when applying MAN-C
on the original graph constitutes the overall solution.
The running time of the MAN-C algorithm is bounded by N ×(2f1(n, m)+f2(n)),
where N is the number of clusters found by MAN-C, f1(n, m) is the time complexity
of computing a minimum cut, and f2(n, m) is the time complexity of computing a
normalized cut in a graph with n vertexes and m edges .
The usual approach to solve the min-cut problem is to use its close relationship to the
maximum flow problem. Nagamochi and Ibaraki [19] published the first deterministic
min-cut algorithm that is not based on a flow algorithm, has the fastest running time of
O(nm), but is rather complicated. Stoer and Wagner [20] published a min-cut algorithm
with the same running time as Nagamochi and Ibaraki’s, but is very simple.

A Graph Clustering Algorithm Based on Minimum and Normalized Cut

501

The normalized cut can be efficiently computed using Lanczos method using the
running time O(kn)+O(kM(n)) [4], where k is the maximum number of matrix-vector
computations required and M(n) is the cost of a matrix-vector computation of Ax,
where A= D-1/2(D-W)D-1/2 (see formula (1)).

3 Properties of MAN-C Algorithm
In this section we prove some properties of the clusters produced by the MAN-C
algorithm. These demonstrate the homogeneity of the solution.
Definition 2. For a graph G = (V, E, W), a vertex x ∈ V, we define the average edge
weight (AEW) as formula (3). That is, the AEW of a vertex x is the average weight of
all edges incident on x.
∑ wxv
v∈V
(3)
ϖx =
deg(x)
Theorem 1. For a cluster G = (V, E, W), the following properties hold:
1. For each pair vertices v1 and v2, if ϖv1 ≤ T/m and ϖv2 ≤ T/m, then the distance
between v1 and v2 is at most two.
2. For each vertex x ∈ V, ϖx > T/(2m).
3. There are O(n2) edges in G.
Proof. Assertion (1) When all edges incident on a vertex are removed, a disconnected
graph results. Therefore the following inequality holds according to the definition 1:

∑ wxv ≥

v∈V

nT
,
2m

for each x ∈ V .

equivalently, deg(x)ϖ x ≥

nT
,
2m

for each x ∈ V ,

i.e.,
deg(x) ≥

nT 1
,
2 mϖx

for each x ∈ V

(4)

So, if ϖv1 ≤ T/m and ϖv2 ≤ T/m, then deg(v1) ≥ n/2, and deg(v2) ≥ n/2. Since deg(v1) +
deg(v2)≥ n, therefore, the distance between v1 and v2 is at most two, as they have a
common neighbor.
Assertion (2) By formula (4), we have:

n
T
.
2deg(x) m
Since deg(x) ≤ n – 1 for each x ∈ V, we have

ϖx ≥

ϖx ≥

n
T
T
>
.
2(n − 1) m 2m

(5)

502

J. Wang et al.

Assertion (3) By formula (4), summing over all vertexes in V we get:

∑ deg(x)ϖ x ≥ n

x∈V

n T n 2T
=
.
2 m 2m

Equivalently,
2T ≥

n 2T
.
2m

That is,
m≥

n2
.
4

(6)

That is, there are O(n2) edges in G.

The provable properties of MAN-C as shown in Theorem 1 are strong indication of
homogeneity. By Theorem 1, the average edge weight of each vertex in a cluster G
must be no less than half of average edge weight of G, and if the average edge weight
of some vertex is small, then it must have more neighbors. Moreover, Theorem 1
shows that each cluster is at least half as dense as a clique, which is another strong
indication of homogeneity.

4 Experimental Results
Image segmentation is a hot topic in image processing. We have applied MAN-C
algorithm to image segmentation. In order to apply the MAN-C to image
segmentation, a similarity graph must be constructed. In our experiments, the
similarity graph is constructed as follows:
1. Construct a weighted graph G by taking each pixel as a node and connecting each
pair of pixels by an edge;
2. For gray image, using just the brightness value of the pixels, we can define the
edge weight connecting the two nodes i and j as formula (7);
3. For color image, using HSV values of the pixels, we can define the edge weight
connecting the two nodes i and j as formula (8).
− ( I (i )− I ( j ))2

wij = e

σI

.

(7)

where I(i) is the intensity value for a pixel i, and σI is a parameter set to 0.1 [4].
−|| F (i )− F ( j )||22

wij = e

σI

(8)

where F(i) = [v, v⋅s⋅sin(h), v⋅s⋅cos(h)](i), and h, s, v are the HSV values [4].
Considering the space limitation, here we give three examples as shown in Fig. 4,
Fig. 5, and Fig. 6. Note that the cluster is drawn using black as background, so the
cluster with background is omitted.

A Graph Clustering Algorithm Based on Minimum and Normalized Cut

503

Fig. 4. The leftmost is original image and other images are clusters produced by MAN-C

Fig. 5. The leftmost is original image and other images are clusters produced by MAN-C

Fig. 6. The leftmost is original image and other images are clusters produced by MAN-C

From the results, we can see that the MAN-C algorithm performs well on all
images.

5 Conclusions
By a novel definition of a cluster, a graph-theoretic clustering algorithm MAN-C is
proposed based on minimum and normalized cut. The minimum cut is used as the
stopping condition of the recursive algorithm, and the normalized cut is used to
partition a graph into two subgraphs. The MAN-C algorithm has the advantage of
many existing algorithm: nonparametric clustering method, low polynomial
complexity, and the provable properties. The provable properties of MAN-C together
with experimental results demonstrated that the MAN-C algorithm performs well.

Acknowledgements
This work was supported by Natural Science Foundation of China under Grant No
60574078, Natural Science Foundation of Guangdong Province under Grant No
06300170 and Natural Science Youth Foundation of South China University of
Technology under Grant No B07-E5050920.

504

J. Wang et al.

References
1. Jain A.K., Murty M.N., Flynn P.J.: Data Clustering: A Review. ACM Computing Surveys,
31 (1999) 264–323.
2. Xu R., Wunsch II D.: Survey of Clustering Algorithms. IEEE Trans. on Neural Networks,
16(3) (2005) 645–678.
3. Kannan R., Vempala S., Vetta A.: On Clusterings: Good, Bad and Spectral. J. ACM, 51(3)
(2004) 497–515.
4. Shi J., Malik J.: Normalized Cuts and Image Segmentation. IEEE Trans. on Pattern
Analysis and Machine Intelligence, 22(8) (2000) 888–905.
5. Qiu H., Hancock E. R. Graph Matching and Clustering Using Spectral Partitions. Pattern
Recognition, 39 (2006) 22–34.
6. Tritchler D., Fallah S., Beyene J.: A Spectral Clustering Method for Microarray Data.
Computational Statistics & Data Analysis, 49 (2005) 63–76.
7. Van Vaerenbergh S., Santamaría I.: A Spectral Clustering Approach to Underdetermined
Postnonlinear Blind Source Separation of Sparse Sources. IEEE Trans. on Neural
Networks, 17(3) (2006) 811–814.
8. Wu Z., Leahy R.: An Optimal Graph Theoretic Approach to Data Clustering: Theory and
Its Application to Image Segmentation, IEEE Trans. on Pattern Analysis and Machine
Intelligence, 15 (11) (1993) 1101–1113.
9. Hartuv E., Shamir R.: A Clustering Algorithm Based on Graph Connectivity. Information
Processing Letters, 76 (2000) 175–181.
10. Hagen L., Kahng, A. B.: New Spectral Methods for Ratio Cut Partitioning and Clustering.
IEEE Trans. on Computer-Aided Design, 11(9) (1992) 1074–1085.
11. Ding H., He X., Zha H., et al: A Min-Max Cut Algorithm for Graph Partitioning and Data
Clustering. In: Proceedings of IEEE 2001 International Conference on Data Mining, IEEE
Computer Society Press, Los Almitos, CA, (2001) 107-114.
12. Soundararajan P., Sarkar S.: An In-Depth Study of Graph Partitioning Measures for
Perceptual Organization. IEEE Trans. on Pattern Analysis and Machine Intelligence, 25(6)
(2003) 642–660.
13. Carballido-Gamio J., Belongie S., Majumdar J. S.: Normalized Cuts in 3-D for Spinal MRI
Segmentation. IEEE Trans. on Medical Imaging, 23(1) (2004) 36–44.
14. Duarte A., Sánchez Á., Fernández F., et al: Improving Image Segmentation Quality
through Effective Region Merging Using a Hierarchical Social Metaheuristic. Pattern
Recognition Letters, 27 (2006) 1239–1251.
15. He X., Zha H., Ding C. H.Q., et al: Web Document Clustering Using Hyperlink Structures.
Computational Statistics & Data Analysis, 41 (2002) 19–45.
16. Li H., Chen W., Shen I-F.: Segmentation of Discrete Vector Fields. IEEE Trans. on
Visualization and Computer Graphics, 12(3) (2006) 289–300.
17. Ngo C., Ma Y., Zhang H.: Video Summarization and Scene Detection by Graph Modeling.
IEEE Trans. on Circuits and Systems for Video Technology, 15(2) (2005) 296–305.
18. Yu Stella X., Shi J.: Segmentation Given Partial Grouping Constraints. IEEE Trans. on
Pattern Analysis and Machine Intelligence, 26(2) (2004) 173–183.
19. Nagamochi H., Ibaraki T.: Computing Edge-Connectivity in Multigraphs and Capacitated
Graphs. SIAM J. Discrete Mathematics, 5 (1992) 54–66.
20. Stoer M., Wagner F.: A Simple Min-Cut Algorithm. J. ACM, 44(4) (1997) 585–591.

