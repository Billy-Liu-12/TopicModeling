Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 697–706

Procedia Computer
Science

Procedia Computer Science 00 (2011) 1–10

International Conference on Computational Science, ICCS 2011
LabWiki : An Executable Paper Platform for Experiment-based Research
Guillaume Jourjona , Thierry Rakotoariveloa , Christoph Dwertmanna , Maximilian Otta
a NICTA,

Australian Technology Park, Eveleigh, NSW, Australia

Abstract
We present the LabWiki , an executable paper platform primarily designed but not limited to networking experimentbased research. The LabWiki leverages the current state of the art tools for the orchestration of experiments in the
networking community and propose a new approach to execute and reproduce experiments. We demonstrate the
usability of the LabWiki through an example at the boundary between network and high performance computing
researches.
Keywords: Network, Scientific Method, Experiment based, OMF
PACS: 84.40.Ua

1. Introduction and Motivation
Many publications in the field of computer networking increasingly contain experimentally-based evaluations of
the proposed systems and algorithms. However, an informal study we conducted on last year’s accepted papers for
one of the leading computer networking conferences indicated problems with 70% of the accepted papers related to
proper description of methodology, experiments, and analysis [1]. While some authors now provide access to the
collected measurements, shortcomings in capturing context and provenance limit their scientific value for evaluating
the published results themselves as well as for further research.
We have developed a comprehensive set of tools for managing large scale experimental facilities, as well as
supporting researchers in conducting experiments on these facilities. The resulting framework, called OMF [2, 3],
is deployed in over 20, primarily wireless and mobile computing focused testbeds around the world and hundreds of
papers have been published containing experiments conducted with our tools.
OMF is heavily focused on supporting repeatable experiments through OEDL[2], a domain-specific language fully
capturing the experiment setup, its orchestration, and all relevant context; as well as a fully integrated instrumentation
and measurement framework which not only eﬃciently collects all the artefacts of an experiment, but maintains full
provenance by linking back to the experiment context.
While OMF supports a very systematic approach to experimental validation, we have seen very few examples
where this follows through into the resulting publications. We have therefore recently embarked on the design and
implementation of a Portal to support an entire investigation based on the hypothetico-deductive model[4] of the
scientific method as shown in Figure 1. In this Figure, we present the diﬀerent components of the portal and their
equivalent in the scientific methods. In this Figure, we noted Ha and H0 the hypotheses and null-hypotheses derived
from the models.
Email addresses: guillaume.jourjon@nicta.com.au (Guillaume Jourjon), thierry.rakotoarivelo@nicta.com.au (Thierry
Rakotoarivelo), christoph.dwertmann@nicta.com.au (Christoph Dwertmann), max.ott@nicta.com.au (Maximilian Ott)

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.073

698 	

Guillaume
et al. / Procedia
Science
(2011) 697–706
G.
Jourjon etJourjon
al. / Procedia
ComputerComputer
Science 00
(2011)41–10
Studied
Phenomenon

Portal
Model 1

...

HA , H0
OEDL
Script

Measurements
database

R
Script

2

Model i
HA , H0

Experiment
Experiment
Experiment

Experiment
Experiment
Experiment

Observations

Analyses
Falsify and/or
reﬁne the
models

Figure 1: The hypothetico-deductive scientific method and its support by the Portal.
The current version allows a researcher to (re)run, track, and record experiments on managed testbeds as well
as manage all resulting artefacts, such as scripts, software versions, and measurement databases. We adopted the
ticketing functionality common to most software development Portals to fully capture each experiment in a single
page with its own unique public URL. A button on the page allows the instantiation of a new experiment with the
same parameters, making it very easy to re-run an experiment. The Portal is independent of any specific testbed
installation and diﬀerent third parties may host Portal instances interfacing with diﬀerent types of testbeds. Its current
implementation is compatible with any testbed running OMF (such as Orbit Lab, NITLab, NICTA Norbit [5, 6, 2]).
In response to this challenge we propose LabWiki which is essentially an extension of our current Portal with a
laboratory notebook like functionality based on the Portal’s wiki capability. This allows the researcher to describe
the problem studied, the models proposed and the hypothesis and anti-hypothesis motivating the design of the various
experiments. Each of the artefacts of an experiment and the experiments themselves are identified by public URLs
which can be linked easily to from any LabWiki page. We further propose to use the R [7] language to analyse any
measurements collected on the Portal. The R scripts are similar to the OEDL scripts mentioned previously and we will
use the existing Portal functionality to archive, run and also re-run analytic tasks the same way we do experiments.
The results, such as graphs or tables, can be embedded directly in a LabWiki page thanks to an extended wiki syntax.
With all this in place, any LabWiki page can become an executable paper. In fact, other LabWiki pages can
be used to capture the resulting review process including the verifying experiments and additional analysis of the
measurements.
This remainder of this paper is as follows. Section 2 presents the general architecture of the Portal and its diﬀerent
features and the components that support researchers in addressing this experimentation issues. Then Section 4 goes
though a study case where we investigate how to use the LabWiki to analyse the impact of the communication between
entities in a P2P computational platform. Section 5 go through the challenge criteria and how our proposed solution
answers them. Finally, Section 6 concludes and gives further research directions.
2. Background
In this section, we present a brief overview of both the testbed management framework OMF [3] and its companion
measurement library OML [8]. In the context of the LabWiki , the measurement library serves two purposes; storage
of user-defined measurements, as explained in the remainder of the section and more importantly the capture of
environment information. This environment data is also made available in the LabWiki and aims at maximising the
reproducibility of experiments.

Guillaume Jourjon et al. / Procedia Computer Science 4 (2011) 697–706
G. Jourjon et al. / Procedia Computer Science 00 (2011) 1–10

699
3

OMF - Experimental facilities (or testbeds) are instrumental for the evaluation of new network technologies. In
many cases, these testbeds are solely built and used for a specific research project, and are often not maintained, reused, or shared. This obviously limits the independent verification of experimental results by the community which
is a cornerstone of the scientific method. Beside access to a facility we also need an unambiguous way to describe an
experiment and all its required resources to enable others to repeat it. To raise to this this challenge, we developed
OMF [2, 3], a suite of management, control, and measurement services and tools for networking testbeds. From an
operator perspective, OMF provides several services to manage, allocate and configure heterogeneous resources within
a testbed. From an experimenter’s perspective, it provides a high level domain-specific language to systematically
describe an experiment (i.e. its used resources, its required measurements, and its task to perform), and a set of
software tools to automatically deploy and orchestrate this experiment on a given testbed.

Figure 2: Overview of OMF architeture from the user’s perspective (source: [2])
Figure 2 shows a simple overview of OMF’s architecture from an experimenter’s point of view. As described
on this figure, the input to the OMF system is an Experiment Description, which is produced by the researcher (i.e.
the user). OMF will then perform all the necessary operations to deploy, configure, and execute the corresponding
experiment. While the experiment is running, various measurements are automatically collected through the use of
the OML measurement library. OMF and OML have been deployed on several heterogeneous testbeds, and have been
used by many researchers worldwide [2].
OML - OML [8] is an instrumentation & measurement framework, which was first developed as a component
of OMF, but is now a stand-alone software which collects and stores any type of measurements from any type of
application. OML has three components that allow the user to automatically generate and store measurement streams.
First, a developer defines Measurement Points (MPs) within their applications or services. At run-time the experimenter can request these MPs to generate Measurement Streams (MSs) which can be further processed (e.g. filtered
or combined), cached, and ultimately streamed towards repositories to be stored in databases for further analysis.
OML has been integrated in many applications, such as traﬃc generators, passive network measurements, GPS
coordinate loggers, and pressure/temperature sensor loggers [9]. We developed a measurement analysis component
as part of the proposed LabWiki , which automatically generates simple graphs from the measurement database of a
given experiment, and allow the import of these measurements into a wiki-based statistical analysis tool.

700 	

Guillaume
et al. / Procedia
Science
(2011) 697–706
G.
Jourjon etJourjon
al. / Procedia
ComputerComputer
Science 00
(2011)41–10

(x1,...,xN)

4

MS1

F1
MP1

F3
(y1,...,yM)

F2

OML
Server

MS2

SQL
Database
Control Node 1

MS3

MP2

F4

MS4

OML
Server

SQL
Database

(z1,...,zP)
Control Node 2
MP3

Application

F5

MS5

liboml2

local
ﬁle

Figure 3: Measurement data path in OML. The application illustrated defines three measurement points, and the user
has configured the library to generate five measurement streams (source: [8])
3. LabWiki Overview
Based on the existing reservation portal of the NICTA testbed [1], we developed LabWiki which allows researchers
to easily apply the hypothetico-deductive approach [4] to their investigations. In addition, LabWiki facilitates the
collaboration between researchers and peer-verification of final results through the use of a fine-grained shareable
wiki pages.
Figure 4 illustrates the workflow of a typical iteration of a research investigation using the proposed LabWiki .
This workflow is following the approach described in Figure 1. It starts with the formulation of a model based on
existing observations or data, and the subsequent derivation of hypotheses from it. LabWiki supports these initial steps
by providing a wiki based space which allows researchers to capture these models and hypotheses, and to potentially
share them with selected collaborators. The researchers would then describe some experiments aiming at confronting
these hypotheses, using the OEDL-based experiment editing interface of LabWiki . These experiments will then be
deployed and performed on OMF-enabled testbed, using both the scheduling mechanisms of the original portal on
which LabWiki is built on and the experiment control features of OMF. At this stage, one of the key contribution of
LabWiki is that in parallel to the experiment-defined measurements, it will also automatically initiate the collection
of additional context relevant measurements on the load and state of the resources being used (e.g. cpu/mem usage of
resource X, channel quality seen by resource Y, etc...). All these measurement collections are done using the OML
software described earlier [8]. Once the experiments are finished, the researchers may use the provided graphical
interface to analyse the resulting collected data. This interface is the other major contribution of LabWiki . It allows
the researchers to edit or load R scripts [7] describing statistical computations to be performed on the collected data.
LabWiki will run these scripts into a R interpreter which has access to the experiment data, and will present the
resulting outputs (e.g. graphs, tables,...) to the researchers.
Finally when the researchers decide to publish their results, LabWiki allows them to selectively mark as public the
relevant parts of their LabWiki investigation. These public parts are accessible to any peers or reviewers and would
in eﬀect embody the executable paper per se, as these third parties would be able to use LabWiki to reproduce the
experiments in similar contexts and verify the published results.
4. Study Case: Eﬀect of Delay on the resolution of the Obstacle Problem
In this section we will present an example of a real research investigation using the LabWiki portal to demonstrate the feasibility of the previously described workflow and the versatility of LabWiki . This example is based on
a problem which is at the border of both networking and high performance computing research. The hypothetical
research project investigates the eﬀect of the communication delay on the performance of the resolution of an obstacle problem [10] deployed over a P2P computing architecture called P2PDC [11]. In this article, we are merely
presenting the methodology of such a study and do not aim at demonstrating any breakthrough research. Therefore
the comprehensive results and analyses related to this study will be presented in a separate paper.

701
5

Guillaume
Jourjon
et al.
/ Procedia
Computer
Science
4 (2011)
697–706
G. Jourjon
et al.
/ Procedia
Computer
Science
00 (2011)
1–10

Exp linked to
reservation

User

N

ideal
topology
required?

Y

Write
model

Y

is
reservation
exist

Make
Reserv
ation

N

Measurement
of topology

Start
ASAP

Topology
met or
timeout

Testbed
Available

Y

N

Model
exists

Reservation
valid?

reservation
validation

Write
Hypo

Y

Y

Y
N

N

Ha and

Start
Experiment

H0?

Y

N

Experiment
successful

N

Y

N

Load single
experiment

Load multiple
experiment
results

Y
Start Statistical
Analysis

Y
Collect
Measur
ement

Save
Hypo

N

H0 rejected/
Ha retained

Write new hypotheses
or model and restart
the process

Y
Y
Describe and
Queue
experiment

need
more
runs
N
Start
Analysis

Write Result
Analysis
Make
result
public

N

Keep result
private

Y
Migration to
public repository

Figure 4: Portal Workflow Diagram (source: [1])
4.1. Model and hypotheses
The discretisation of the obstacle problem leads to the formulation of the following fixed point problem that can
be solved by distributed iterative algorithms:


Find u∗ ∈ V such that
u∗ = F(u∗ )

(1)

where V is an Hilbert space and the mapping F : v → F(v) is a fixed point mapping from V into V.
Many equivalent formulations of this problem can be found in the literature such as the complementary problem,
variational inequality and constrained optimisation problem; the reader if referred to [12, 13] and [14] for more details.
In order to solve the problem (1), we will use the P2PDC architecture [11]. This architecture will use the
Richardson algorithm combined with several classical synchronous schemes of computation like Gauss-Seidel or
asynchronous schemes of computation1 [12].
The P2PDC architecture oﬀers a P2P computational platform that can be deployed over numerous networking
technologies including the Internet Protocol [11]. Therefore, this architecture oﬀers new communication schemes to
perform high performance computing without being tied to a grid architecture over dedicated network.
In the context of the P2PDC deployment over the Internet, we cannot expect the same eﬃciency and on-going
increase of the speedup as we could have in a dedicated grid. Indeed, one could envision that the communication
component of the distributed computation will not be negligible and could result in a loss of eﬃciency when the
ratio time to iterate to the time to communicate reach a certain threshold. Therefore, we hypothesised the following
possible behaviours of the speedup in function of the delay between peers:
1 For

implementation details please refer to [11].

702 	

Guillaume Jourjon et al. / Procedia Computer Science 4 (2011) 697–706
G. Jourjon et al. / Procedia Computer Science 00 (2011) 1–10

6

• Speedup follows log(N) where N is the number of peers,
• Speedup reaches an optimum level,
• Speedup follows K.N where N is the number of peers.
Furthermore, the scheme may not be universal and might depend heavily upon the network impairments. In this
context, we call network impairment the communication delay between peers and the ratio of messages that will be
lost. In the remainder of this section, we will show step by step the configuration and the executions of experiments
to find the correct model according to the network.
4.2. Experiment Description
In order to evaluate the diﬀerent models, we first need to feed the portal with experiment descriptions using the
OEDL scripting language. Listing 1 presents a simplified version of the OEDL script that will be executed on the
testbed. In this script the first five lines represent the parameters the experimenter will be able to tune for every run
of the experiment. As stated in the previous section, we are interested in the eﬀect of the network impairments on the
eﬃciency of the diﬀerent classes of algorithms, therefore we limited the parameters to the delay, the packet loss rate,
the number of peers and the class of algorithms.
# Properties to change during the diﬀerent experiments
defProperty (’ nbPeers’, 2, ”the number of peers involved ”)
defProperty (’ classAlgo ’, ’ asynchrnous’, ”the type of algorithm to use”)
defProperty (’ delay’, ’10ms’, ”the delay between peers ” )
defProperty (’ plr ’, 0.0, ”the packet loss rate between peers ”)
# Coordinator
defGroup(’submitterGroup’, ’ node0’) do | node|
node.addApplication (’ P2PDCAppSubmitter’) do |app|
app. measure(’mp submitter’, : samples => 1)
end
end
# Computing Peers
defGroup(’donorGroup’, ”[[ node1... node#{nbPeers}]]”) do | node|
node.addApplication (’ P2PDCAppDonor’) do |app|
app. measure(’mp worker result ’, : samples => 1)
app. measure(’mp worker diﬀ ’, : samples => 1)
end
end
# Topology
defTopology do | topo|
topo. addNode(”myNode 1”, prop.node1)
topo. addNode(”myNode 2”, prop.node2)
# We describe the characteristics of the links between node 1 and 2
topo. addLink(”myNode 2”,”myNode 1”,:emulationTool => :netem, :asymmetric => true,
: ruleID => 3, : delay => prop.delay, : bw => ’1Mbits’, : bwBuﬀer => 12000,
: bwLimit => 15000, :loss => prop.plr )
topo. addLink(”myNode 1”,”myNode 2”,:emulationTool => :netem, :asymmetric => true,
: ruleID => 3, : delay => prop.delay, : bw => ’1Mbits’, : bwBuﬀer => 12000,
: bwLimit => 15000, :loss => prop.plr )
topo. saveGraphToFile()
end
onEvent(: ALL UP AND INSTALLED) do |event|
group(’ donorGroup’).startApplications
wait 5
group(’ submitterGroup’). startApplications
# Wait for application execution
wait 1200
# Stop the expiriment
Experiment.done
end

Listing 1: Experiment Description Example

Guillaume Jourjon et al. / Procedia Computer Science 4 (2011) 697–706
G. Jourjon et al. / Procedia Computer Science 00 (2011) 1–10

703
7

The remainder of the experiment script describes the diﬀerent components of the experiment. First we select one
of the peers as the coordinator of the computation. This peer ensures that the algorithm finishes correctly. Then we
deploy the computational algorithm to the number of peers previously configured.
Next we configure the network according to the diﬀerent parameters. Without loss of generality, we limit the
topology description to a single pair of peers. In the actual study these impairments will be applied between every
peer in a first time and then on selected peers. In the presented script, we make the management framework to
configure the link between the node 1 and 2 with the configured delay and message loss rate (plr in the listing). Then
we apply the same impairments to the link between 2 and 1.
Once physical and upper level definitions are finished, the user describes the logical and temporal orchestration of
the experiment, which is represented by the last part of the script.
The description of the experiments has been completed using the OEDL scripting language, the user is now able to
schedule the diﬀerent runs. In the context of the presented study, we planned to made the properties vary as described
in the Table 1. These diﬀerent ranges result in the configuration of more than 2000 experiments which would be very
time-consuming without the LabWiki .
Table 1: Ranges for the Experiment Runs
Delay intra-cluster
Delay inter-cluster
Packet Loss Rate intra-cluster
Packet Loss Rate inter-cluster
Class of Algorithm
Number of Peers

Range
[1, 100] ms
[10, 250] ms
[0.0, 0.25]
[0.0, 0.25]
{Synchronous, Asynchronous, Hybrid}
{1, 2, 4, 8, 16, 24, 32, 40}

4.3. Runs and Observations
Using the LabWiki , the user can configure all their experiments using a web interface automatically generated
based on the experiment description presented in Listing 1. The Figure 5 (a) presents the resulting configuration
web page. As specified in the experiment description, the user can configure the network impairments, the resolution
algorithms and the number of peers.
Once the experiment is configured, it is put in a queue as described by the portal workflow and will be automatically run according to either the user’s reservation or the testbed availability. The user can then see the experiment
queue in the Experiments tab of the LabWiki as illustrated in Figure 5 (b). In order to guarantee privacy between
projects, a user can see only the experiments configured for a particular project.
4.4. Analyses
The last step in any research project is the analysis of the measurements. Using the LabWiki , a user can either
download the measurement databases generated by OML and automatically attached to the result page or directly
load and perform analysis of these measurements using the wiki interface. Indeed, as illustrated in Figure 6, we have
enhanced the basic wiki syntax in order to allow the user to load the aforementioned measurement results directly in
the wiki and then use the R language to analyse them.
In the context of the presented study case, as it is not the purpose of this article to present new results in the field
of distributed computing, we present in Figure 6 a hypothetical result of the speedup of one class of algorithm in the
case of a low delay and no packet loss rate.
5. Challenge Criteria
This section addresses the criteria listed in the Challenge brief.

704 	

Guillaume
et al. / Procedia
Science
(2011) 697–706
G.
Jourjon etJourjon
al. / Procedia
ComputerComputer
Science 00
(2011)41–10

(a) The experiment configuration screen.

8

(b) The queue of configured experiments waiting to be started.

Figure 5: Screenshots from the LabWiki interface as seen by researchers.

Figure 6: Result graph generated by LabWiki ’s integrated R module used to analyse the measurements.
5.1. Executability
The Portal stores experiment scripts alongside with any parameters used, and also holds and processes the experiment results and captures all state. Equations, tables, graphs are generated as part of the experiment flow and may be

Guillaume Jourjon et al. / Procedia Computer Science 4 (2011) 697–706
G. Jourjon et al. / Procedia Computer Science 00 (2011) 1–10

705
9

displayed as part of a page in the LabWiki . After the experiment development process is finished, a Portal user may
choose to open up his or her LabWiki permissions to specific reviewers or the general public. The readers can then
review the experiment description and the result set as well as re-run, clone or manipulate the experiments to validate
or extend the result sets inside their own Portal account.
5.2. Short and long-term compatibility
OMF experiments are based on the OEDL Language [2]. Since its introduction in 2002, OEDL is constantly being
extended, but retains backward compatibility given the already large user community. Since experiments described in
OEDL typically do not include any platform or operating system specific commands, and since OMF is written in the
platform-independent Ruby language, we can ensure interoperability of OEDL experiments across a large number of
computer systems.
5.3. Validation
Since the reviewer can access the experiment description, the applications and the experiment results through the
Portal, he or she can easily validate the experiments that have been run and verify the data as well as its analysis that
was produced for the research paper.
5.4. Copyright / Licensing issues
Copyright and licensing are primarily non-technical issues. However, to enforce and implement such policies, the
Portal oﬀers a granular permission system. It allows, for example, the authors to limit the access to their experiment
descriptions and result sets to reviewers only during the review phase, and later open up permissions to the general
public or other user groups after the paper has been accepted or published. Being able to safely publish the data that
accompanies a research paper with just a few mouse clicks encourages authors to do so. Limiting access to closed
user groups can be facilitated to protect intellectual property. We have also recently been evaluating new tools based
on ’diﬀerential privacy’ techniques to allow more open analysis of sensitive data collected from experiments involving
real users which often require ethics board approval.
5.5. Systems
If measurements were conducted on a large scale computer system, where computing resources are limited or
only available to certain users, reviewers and readers still have the opportunity to download a copy of the experiment
description from the Portal and run it on a diﬀerent, more accessible testbed. By adjusting the experiment parameters
(e.g. the number of participating nodes), similar results may be achieved even on smaller testbeds, which in some
cases may be suﬃcient to validate the author’s claims.
One of OMF’s basic principles is repeatability of experiments. If testbed resources are not available to someone
who would like to repeat the experiment, it’s rather a policy issue of the testbed operator than a technical challenge.
5.6. Security considerations
In a testbed running OMF, all code is executed on isolated filesystems or virtual machines. Should malicious code
enter the experiment description and applications, its execution would be limited to the set of nodes in the experiment.
By default, the filesystem image on the nodes is wiped by OMF in between experiment sessions of diﬀerent users.
Code that the user may have entered in the LabWiki is executed in isolated environments (jails), preventing interference with the Portal and the data stored in it.
5.7. Feasibility
Thousands of experiments have been conducted using OMF on more than 20 testbed facilities since 2002, hundreds
of published papers include results gained through OMF managed testbeds. In addition, an early version of the Portal
has been used in an e-learning context at a university in 2010, where students ran 9000 experiments on the IREEL
platform [15] which is layered on top of OML. A paper discussing the outcome of this project and the lessons learned
has been submitted.
The Portal implementation will be completed in early 2011 and will be deployed on a number of sites that already
run OMF testbeds. The Portal itself only needs a web server and security contexts with the associate OMF testbeds.
We aim to give a live demonstration of a full executable paper development cycle using the Portal shortly.

706 	

Guillaume Jourjon et al. / Procedia Computer Science 4 (2011) 697–706
G. Jourjon et al. / Procedia Computer Science 00 (2011) 1–10

10

6. Conclusion
We presented LabWiki , a web portal designed to support the full life-cycle of experiment-based investigations.
It interfaces with OMF, a testbed management as well as experimenter support framework designed with a focus on
experiment repeatability and sound data collection.
The current version of LabWiki already allows an authorised user to re-run experiment and have access to the data
collected for each experiment.
In response to this challenge we propose to extend the Portal’s wiki capability to easily refer to all the relevant
experiments and collected data, as well as integrate powerful analytical capability based on the R environment which
will not only allow the embedding of the resulting graph, but also allow any user, to verify and even extend the
analysis.
We believe that with this extensions, any LabWiki page can become an executable paper fulfilling the criteria
posed in the challenge brief and we are committed to develop these extensions and demonstrate their viability within
the timetable provided.
Acknowledgements
The authors would like to thank The Tung Nguyen and Didier El Baz for letting us use the P2PDC architecture as
an example for the LabWiki . This work was achieved in the context of the NaDa and Onelab2 projects funded by the
E.U. 7th Framework Program, and the GENI (Global Environment for Network Innovations) initiative funded by the
U.S. National Science Foundation.

References
[1] G. Jourjon, T. Rakotoarivelo, M. Ott, A Portal to Support Rigorous Experimental Methodology in Networking Research, in: Proceedings of
TridentCom 2011, 2010.
[2] The OMF Testbed Control, Measurement and Management Framework, at: http://omf.mytestbed.net.
[3] T. Rakotoarivelo, M. Ott, I. Seskar, G. Jourjon, OMF: a control and management framework for networking testbeds, in: SOSP Workshop on
Real Overlays and Distributed Systems (ROADS ’09), Big Sky, USA, 2009, p. 6.
[4] W. Whewell, History Of The Inductive Sciences From The Earliest To The Present Time, Kessinger, 1837.
[5] D. Raychaudhuri, et al., Overview of the ORBIT Radio Grid Testbed for Evaluation of Next-Generation Wireless Network Protocols, in:
proc. IEEE Wireless Communications and Networking Conference (WCNC), 2005.
[6] The NITLab Scheduler, at: http://nitlab.inf.uth.gr/NITlab/.
[7] The R Project for Statistical Computing, at: www.r-project.org/.
[8] J. White, G. Jourjon, T. Rakotoarivelo, M. Ott, Measurement architectures for network experiments with disconnected mobile nodes, in: Proc.
of TridentCom 2010, Vol. 46 of LNICST, Springer-Verlag, Berlin Heidelberg, 2010.
[9] The Orbit Measurment Library, at: http://oml.mytestbed.net.
[10] P. Spit´eri, M. Chau, Parallel asynchronous Richardson method for the solution of obstacle problem, in: Proceedings of the 16th Annual
International Symposium on High Performance Computing Systems and Applications, 2002, pp. 133–138.
[11] T. T. Nguyen, D. El Baz, P. Spiteri, G. Jourjon, M. Chau, High Performance Peer-to-Peer Distributed Computing with Application to Obstacle
Problem, in: Proc. of HotP2P 2010 in conjunction with IPDPS 2010, 2010.
[12] P. Spit´eri, M. Chau, Parallel Asynchronous Richardson Method for the Solution of Obstacle Problem, in: Proc. of the 16th Annual International Symposium on High Performance Computing Systems and Applications, 2002, pp. 133–138.
[13] J.-L. Lions, Quelques M´ethodes de R´esolution des Probl`emes aux Limites non Lin´eaires, Dunod, 1969.
[14] J. C. Miellou, D. El Baz, P. Spit´eri, A new Class of Asynchronous Iterative Methods with Order Intervals, Mathematics Of Computation
67 (221) (1998) 237–255.
[15] G. Jourjon, T. Rakotoarivelo, M. Ott, From Learning to Researching, Ease the Shift through Testbeds, in: Proc. of TridentCom 2010, Vol. 46
of LNICST, Springer-Verlag, Berlin Heidelberg, 2010, pp. 496–505.

