LDMA: Load Balancing Using Decentralized Decision
Making Mobile Agents
M. Aramudhan1 and V. Rhymend Uthariaraj2
1

Research scholar, Dept.of. IT, MIT, Anna University, Chennai-25, Tamilnadu, India
aranagai@yahoo.co.in
2
Professor, Dept.of. IT, MIT, Anna University, Chennai-25, Tamilnadu, India
rhymend@annauniv.edu

Abstract. This paper introduces a new load balancing algorithm, called LDMA
(Load balancing using Decentralized decision making Mobile Agents), which
distributes load among clustered web servers connected in a mesh topology, by
a communications network and compares its performance with other load
balancing algorithm: MALD (Mobile Agent based LoaD balancing).
Architecture is developed for the same and all necessary attributes such as load
deviation, system throughput and response time incurred as a result of the work
are dealt with. In past works, a centralized decision making algorithm was used
for dispatching requests to web servers in the distributed client/server
environment. In the proposed approach, a decentralized decision making
algorithm is used for distributing requests among web servers. The simulator is
developed in C++ and its performance is evaluated. The analysis shows that
LDMA is better than centralized decision making load balancing algorithms.
Keywords: Load balancing, decentralized decision making, mobile agents,
clustered web servers.

1 Introduction
A distributed computer system is a collection of self-sufficient computers located at
diverse or identical sites and associated by a communication network. The
performance of a distributed system is enhanced to an adequate level by distributing
the workload among the servers. Normally, load balancing occurs at the server side
and assists to balance the load in distributed computer system. Winston [1] proved
that the most excellent mechanism for achieving optimal response time is to distribute
the workload equally among the servers. Incoming client requests should be evenly
distributed among the servers to achieve quick response time. Traditional load
balancing approaches on distributed web servers are implemented based on message
passing paradigm. At present, mobile agent technology is used to implement load
balancing on distributed web servers. Mobile agent is defined as a software
component that can move freely from one host to another on a network and transport
its state and code from home host to other host and execute various operations on the
site [6]. The mobile agent based approaches have the merit of high flexibility, low
network traffic and high asynchrony.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 388 – 395, 2006.
© Springer-Verlag Berlin Heidelberg 2006

LDMA: Load Balancing Using Decentralized Decision Making Mobile Agents

389

Distributed web servers deploy in different geographical scopes. They can be
organized into cluster of web servers linked through Local Area Network (LAN), to
provide high processing power and reliability. The servers are heterogeneous in terms
of hardware configuration, operating systems and processing power. Generally, load
balancing on Wide Area Network (WAN) is more time consuming since it involves
the interaction between remote servers for gathering load information, negotiating on
load reallocation and transporting the workload [2]. All approaches in this context so
far has been using only centralized decision making. But, an architecture based purely
on a centralized server is extremely vulnerable to congestion. In addition, it
introduces a single point of failure in the Web system, as stated in [9]. Hence, we
approach the problem in a totally different dimension, by introducing the concept of
“decentralized decision making”. LDMA uses mobile agents for this idea. In LDMA,
there is no collection of load information and request transfer policy between web
servers. Each server processes client requests independently and interact with others
to share the workload.

2 The LDMA Framework
The overall architecture of the LDMA framework is as shown in figure 1. The LDMA
framework defines two worlds, namely: client world and server world. The client
world is an aggregation of all the clients in the physical world, and the server world is
an aggregation of the clustered web servers, which are called replicas. The client
world communicates with the server world via the dispatcher. The queue at the
dispatcher has a finite buffer and a tail drop discard policy. But, unlike the other
approaches, in which the dispatcher re-routes the client requests to corresponding
servers (centralized decision making), the work of the LDMA dispatcher is just to
broadcast client requests to all the replicas. The decision-making for load balancing
among replicas take place only by the interaction of mobile agents between the
replicas. The replicas are inter-connected by mesh topology. Each replica has the
following two modules:
1.
2.

MASM – Mobile Agent Servicing Module
SND – Search aNd Destroy module.

The work of the MASM is to communicate the mobile agents with other replicas to
make them decide which replica may process a request and the work of the SND
module is to search for and delete (remove) a particular request from the replicas
queue. The LDMA framework uses the concept of “ranked web-servers”, i.e., each
replica is statically assigned a rank based on which priority is given for processing a
request.
2.1 LDMA Load Balancing Scheme
Initially, upon the arrival of a client request, the dispatcher broadcasts it to all the
replicas, after assigning a RID (Request ID) to it. The replicas accept the request, but
the request processing does not start immediately. Instead, the request is placed in its

390

M. Aramudhan and V.R. Uthariaraj

Fig. 1. The LDMA Framework

“waiting state”. Each replica sends a mobile agent, with replica’s rank and the RID
just accepted, which we call “RID under siege”. The mobile agents travel to the other
replicas and check the state of the same request in the destination replicas. Then, they
can return back to the source replica with either of the following messages:
1. Accepted: This case occurs when the rank of source replica is less than the rank of
the destination replica, and the RID under siege is in waiting state in the destination
replica. On receiving back this message, the source replica just ignores the accepted
request, and chooses the next request.
2. Deleted: This case occurs,
i. when the rank of source replica is greater than the rank of the destination replica
and the RID under siege is in waiting state in the destination replica, or
ii. irrelevant of the ranks, the RID under siege is in the queue in the destination
replica.
The mobile agent triggers the SND module at the destination replica, which
removes the RID under siege from the destination replica. On receiving back this
message, the source replica starts processing the request.
3. Not Found: A mobile agent returns back to source replica, with this message, when
RID under siege is not found either in its waiting state or even at the queue of the
destination replica. This case occurs when the RID under siege has already been
removed from the destination replica’s queue, by a mobile agent from the other
replica. On receiving back this message, the source replica may choose to ignore or
accept the request, depending on the other mobile agent’s response.

LDMA: Load Balancing Using Decentralized Decision Making Mobile Agents

391

Fig. 2. LDMA Transition Diagram

To retrospect (as shown if figure 2), a replica, on accepting a request, sends mobile
agents to other replicas and waits for the response. It ignores the request, if at least
one of the responses is an “Accepted” message. It starts processing the request
otherwise. Moreover, in case of a packet loss of a mobile agent, a replica waits for a
maximum of twice the RTT (Round Trip Time) of the mobile agent. In case of no
response message, the replica starts processing the request. Also, the dispatcher
assigns RIDs using mod N arithmetic, i.e.,
RID = i mod N, where i = 0, 1, 2, 3…
The RIDs are in increasing order. Hence, the work of SND module at a replica is
easier and it searches for RID under siege from the top (using the sequential search
algorithm), till ith request in the queue, where i is “just greater than” the RID under
siege. After the ith request, the RID under siege cannot be found elsewhere in the
queue (since RIDs are in increasing order), except in the next cycle of RIDs.

3 LDMA Simulation Model
The software simulator was designed in C++ and implemented to model the LDMA
load balancing technique in the distributed web server environment. Workload of a
replica is determined by the number of request processed at each replica. To achieve
best performance results a method applied needs to minimize workload difference
between the replicas. For load balancing algorithm Te and Td are complied. Te is the
elapsed time from the start of the first client call until the entire clients call and Td is
the delay time representing the sum of all the delays associated with the client’s
requests. Simulation parameters governing the generation of client’s events are
summarized below:

392

M. Aramudhan and V.R. Uthariaraj

Load distribution: The load on the server is denoted by the number of requests
processed in the server. The average load distribution deviation over all servers is
calculated to show the effect of load balancing.
System throughput: the overall throughput of the web server cluster, measured in
the number of requests processed per second.
Network traffic: the overall communication overhead in the cluster, measured in
the total number of data (bytes) transferred in the communication.
Table 1. Simulation parameters used

Simulation Parameter

Value

Servers

3

Request/client

1

Data rate (Transmission
speed)
http request file size

10 MBps
<= 2 MB

Propagation Delay

Negligible

Mobile agent RTT

0.5 ms

Processing Delay

Negligible

Graph 1. The LDMA system throughput

LDMA: Load Balancing Using Decentralized Decision Making Mobile Agents

393

Graph 2. System throughput with web server 2,3,4,5

LDMA: Network Traffic (700 Requests)

Network Traffic (in bytes)

18000
16000
14000
12000
10000
8000
6000
4000
2000
0
LDMA2

LDMA3

LDMA4

LDMA5

LDMA (2-5)

Server1
Server2
Server3
Server4
Server5

Graph 3. LDMA Network Traffic

Graph-1 shows the system throughput performance of MALD and LDMA for 700
requests. The LDMA performance is slightly better than MALD. Graph-2 shows the
system throughput of LDMA having different number of servers in cluster. Graph 3
shows the network traffic of LDMA. The overhead of the packet is 50 bytes. The
dispatcher broadcast the incoming requests to all servers. The communication
overhead for totally N servers is as high as O (N2). Network traffic is measured by
the total number of bytes transferred in the communication. The network traffic of
web server cluster having 2 to 5 servers is as shown in Graph-3. In the beginning,
three server's exchanges message for processing the request takes 300 bytes
communication overhead. The next two requests take 200, 100 bytes communication
overhead respectively. The communication overhead of the afterward requests
depends on the previous request processing time.

394

M. Aramudhan and V.R. Uthariaraj
Table 2. Load distribution on three servers

4 Conclusion
LDMA approach to load balancing possesses several advantages. First, decision
making is decentralized and response time improves as the number of replicas
increase. Second, use of mobile agents imposes the merits of high flexibility, low
network traffic and high asynchrony. Third, no replica remains idle at any time while
other replicas are busy processing requests. The requests start processing in the arrival
order. But still, this method has some drawbacks. First, the use of mesh topology to
inter-connect the replicas, limits the scalability of the system to a certain extent. But,
since usually web server clusters in LAN consist of a maximum of only 7 to 8 servers,
the system is considered to be scalable. Second, a failure or fault in the transaction
path of mobile agents between two replicas may result in processing of the same
request by many replicas and hence reduce the throughput of the entire system. But,
this kind of fault is very rare in a LAN environment and is also easy to detect and
repair.

References
1. W. Winston: Optimality of the Shortest Line Discipline. Journal of Applied Probability
(1977) 17-28.
2. Jiannong cao, Yudong Sun, Xianbin Wang and Sajal K. Das :Scalable:Load Balancing on
Distributed Web Servers Using Mobile Agents. Journal of Parallel and Distributed
Computing, Vol.63, Issue 10. (2003) 996-1005.
3. Huamin Chen and Arun Iyengar :A Tiered System for Serving Differentiated Content.
Journal of World Wide Web, Vol.6, Issue 4. (2003) 331-352.
4. Lang fang, Aleksander Slominski and Dennis Gannon: Web Services Security and Load
Balancing in Grid Environment. Proc.of. International Conference on Grid Computing,
Las Vegas, June (2005).

LDMA: Load Balancing Using Decentralized Decision Making Mobile Agents

395

5. Gianfranco ciardo, Almariska and Evgenia smirni: EQUILOAD: a Load Balancing
Policy for Clustered Web Servers. Proc. of Parallel and Distributed systems (2004)14201425.
6. Altec software business unit (2004), “Mobile Agents System for the Interconnection of
Working Groups. Interconnection network vol.5 (2), (2004) 181-191.
7. Foundry Networks, White Paper –Server Load Balancing in Today’s Web-Enabled
Enterprises, (2002).
8. Reinhardtriedl:Workload Modeling for Load Balancing in Distributed DB/DC Transaction
Processing (1999).
9. Marco Conti, Enrico Gregori and Fabio Panzieri :Load Distribution among Replicated
Web Servers: A QoS-based Approach. (1999).
10. Baruch Awerbuch, Mohammad T.Hajiaghayi, Robert D.K leinberg and Tom:Online
Client-Server Load Balancing without Global Information. in proc.of the sixteenth annual
ACM-SIAM symposium on Discrete Algorithms(2005) .
11. Morharchol-Balter, Bianca Schroeder, Nikhil Bansal, and Mukesh Agrawal: Size-Based
Scheduling to Improve Web Performance, in ACM Transactions on Computer Systems,
Vol. 21, No. 2. (2003)
12. Milan E.Soklic: Simulation of Load Balancing Algorithms: A Comparative Study. in
SIGCSE Bulletin vol.34, No.4, Dec. (2002).

