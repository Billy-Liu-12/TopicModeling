Applying Stabilization Techniques to Orthogonal
Gradient Flows
C. Mastroserio1 and T. Politi2
1
2

Dipartimento Interuniversitario di Matematica, Universit`
a di Bari
Via Orabona 4, I-70125 Bari (Italy). carmen@dm.uniba.it
Dipartimento Interuniversitario di Matematica, Politecnico di Bari,
Via Orabona 4, I-70125 Bari (Italy). pptt@dm.uniba.it

Abstract. The solution of ordinary diﬀerential systems on manifolds
could be treated as diﬀerential algebraic equation. In this paper we consider the solution of orthogonal diﬀerential systems deriving from the
application of the gradient ﬂow techniques to minimization problems.
Neglecting the constraints for the solution a diﬀerential system is derived. Hence the problem is modiﬁed introducing a stabilization technique which is a function of the constrain. The advantage of this approach
is that it is possible to apply non conservative numerical methods which
are cheaper. Some numerical examples are shown.

1

Introduction

Many problem of practical interest can be modeled by systems of diﬀerential
equations whose solutions satisfy some invariants, usually deﬁned explicitely by
algebraic constraints. In recent years particular attention has been paid to the
development of numerical methods which approximate the solution of such a
system while preserving the invariant to machine precision. These methods usually need the computational of matrix exponential once (and often repeatedly)
or the solution of linear systems at each time step (see [9,6,8]) and this highly
increases their computational costs.
In this paper we consider a class of diﬀerential systems derived - via a gradient
ﬂow technique - from a constraint minimization problem (on the orthogonal
manifold) of a particular objective function. In this class of problems is not
crucial to preserve the orthogonality of the solution, but the main interest is to
get, as soon as possible, the minimum point.
Hence, we will show how it is possible to solve this diﬀerential system with
invariants applying explicit methods with a splitting technique. To do this, we
review the regularization technique described in [1,2] and applied to the Stiefel
manifold in [4].
In [2] an important diﬀerence between the stabilization and the regularization
techniques for diﬀerential system is pointed out. In regularization methods the
problem is perturbed in order to obtain another system easier to solve. In this
case, the solution we obtain is not the same of the initial system, hence this
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2658, pp. 149–157, 2003.
c Springer-Verlag Berlin Heidelberg 2003

150

C. Mastroserio and T. Politi

implies that the perturbation to introduce must be small. On the other hand, in
the stabilization techniques, the solution of the two systems (the given problem
and the perturbed one) is the same, since the perturbation term vanishes when
a function satisﬁes the constraint. Hence, the perturbation parameter does not
need to be small (or large).
The paper is organized as follows: in Section 2 some stabilization techniques
are recalled, in Section 3 the problem to be solved is stated and a modiﬁed
gradient ﬂow is derived introducing a perturbation term on the minimization
function, in Section 4 a method for the perturbed orthogonal ﬂow is described
and ﬁnally in Section 5 some numerical tests are shown.

2

A Survey on Stabilization Techniques

Let us consider the diﬀerential system
Y (t) = F (t, Y (t)),

(1)

with initial condition Y (0) = Y0 . For sake of simplicity we assume that there is
only a unique function Y (t) satisfying (1). Together with (1) we suppose that
there is an invariant set (or a constraint) deﬁned by an algebraic equation:
H(Y ) = 0

(2)

such that if H(Y0 ) = 0 then H(Y (t)) = 0 for all t > 0. It is not very important to
distinguish between the vector or the matrix case (i.e. Y0 is a square real matrix
and so is Y (t)). The important question is how to design a numerical method
which preserves the properties given by the invariant set or to exploit the information on the solution given by (2) to improve the quality of the approximate
solution in terms, for instance, of stability or of global error. Applications of (1)(2) include some mechanical systems with quadratic constraints, preserving the
orthogonality of a solution matrix and isospectral ﬂows, preserving the set of the
eigenvalues of the initial condition matrix. One of the most popular techniques
for the stabilization of invariants is the one described by Baumgarte [3] applied
to a Diﬀerential Algebraic Equation
y(t)
˙ = F (y) − B(y)x
with invariant

0 = g(y).

Let G = gy (y) be a full rank matrix, the stabilization technique consists in
replacing the invariant with a linear combination of its derivatives
g¨(y) + γ1 g(y)
˙
+ γ2 g(y) = 0
or

g(y)
˙
+ γg(y) = 0.

Applying Stabilization Techniques to Orthogonal Gradient Flows

151

In this case the approach is equivalent to replace the diﬀerential system by
y˙ = F (y) − γB(GB)−1 g(y).
In [2] the following result is proved.
Theorem 1. Consider the diﬀerential system (1) and the invariant deﬁned by
(2) and apply the stabilization
Y (t) = F (Y (t)) − γFY (Y )H(Y )

(3)

where FY = D(HY D)−1 , if there exists a constant γ0 such that
HY (Y )F (Y )

2

≤ γ0 H(Y )

2

for all Y belonging to a neighborhood of the invariant set, then it is asymptotically
stable invariant manifold of (3) for γ > γ0 . In particular if H is an integral
invariant of (1), i.e.
HY (Y )F (Y ) = 0,
∀Y,
then the invariant set is an asymptotically stable invariant manifold of (3) for
any γ > 0.
It should be pointed out that the numerical solution can be now obtained discretizing (3) using also nonstiﬀ integrators. This approach seems to be better
than the Baumgarte and the projected invariants methods.
If we consider the diﬀerential system
Y (t) = F (t, Y )Y,

Y (0) = Y0

(4)

with F (t, Y ) continuous skew-symmetric function for all Y ∈ On (IR) and Y0
orthogonal square matrix of order n, it is well known that the solution Y (t) is
an orthogonal matrix for all t ≥ 0. The system (4) can be considered as a system
on the set of square real matrices with the nonlinear constrain
H(Y ) = Y (t)Y T (t) − In = 0

(5)

where In is the identity matrix of order n. In [4] the following modiﬁed equation
is proposed in order to make the manifold of orthogonal matrices attractive for
the system (4):
Y (t) = F (t, Y )Y − γY (t)P (Y )
(6)
where γ is a real positive number.

3

Gradient Flow Approach for the Regularization

In this section we consider the class of diﬀerential systems on the manifold of
orthogonal matrices and we apply a gradient ﬂow technique in order to minimize
a given matrix function. Consider the isospectral manifold
M (Λ) = {A ∈ IRn×n | A = QT ΛQ, Q ∈ O(n)}

152

C. Mastroserio and T. Politi

where Λ is a given diagonal real matrix and O(n) is the set of n × n orthogonal
matrices. The problem we are interesting in can be formulated as follows:
1 T
Q ΛQ − P (QT ΛQ)
2T
subject to Q Q = I

Minimize

2
F

(7)

where · F denotes the Frobenius norm of a matrix and P (·) is the projection
function. Introducing the Frobenius inner product of two matrices A, B ∈ IRn×n ,
deﬁned by
A, B = trace(AB T ) =

n

aij bij ,
i,j=1

the minimization problem (7) becomes:
1
f (Q), f (Q)
2
subject to g(Q) = 0
Minimize

(8)

where,
f (Q) = QT ΛQ − P (QT ΛQ),

g(Q) = QT Q − I.

Introducing a real nonnegative parameter ε it is possible to transform (8) into
an unconstrained minimization problem:
Minimize

1
ε
f (Q), f (Q) + g(Q), g(Q) .
2
2

ϕ(Q, ε) =

1
[ f (Q), f (Q) + ε g(Q), g(Q) ]
2

Again we put

and compute the Fr´echet derivative of ϕ at Q acting on H:
ϕ (Q, ε)H = f (Q)H, f (Q) + ε g (Q)H, g(Q) =
= H T ΛQ + QT ΛH − P (QT ΛQ)(H T ΛQ + QT ΛH), f (Q) +
+ε H T Q + QT H, g(Q) =
= H T ΛQ + QT ΛH − P (H T ΛQ + QT ΛH), f (Q) +
+ε H T Q + QT H, g(Q) .

(9)

Applying Stabilization Techniques to Orthogonal Gradient Flows

153

Since the projection P (·) is orthogonal to function f (Q), we get
ϕ (Q, ε)H = H T ΛQ + QT ΛH, f (Q) + ε H T Q + QT H, g(Q) =
= H T ΛQ, f (Q) + QT ΛH, f (Q) + ε H T Q, g(Q) +
+ε QT H, g(Q) =
= H, ΛQf (Q)T + H, ΛQf (Q) + ε H, Qg(Q)T + ε H, Qg(Q) =
= H, ΛQf (Q)T + ΛQf (Q) + ε Qg(Q)T + Qg(Q) .
This last equation suggests that the gradient of ϕ at a general matrix H, with
respect to the Frobenius inner product, can be interpreted as the matrix:
ϕ (Q, ε) = ΛQf (Q)T + ΛQf (Q) + ε Qg(Q)T + Qg(Q) =
= ΛQ f (Q)T + f (Q) + εQ g(Q)T + g(Q) =
= ΛQ 2QT ΛQ − 2P (QT ΛQ) + εQ 2QT Q − 2I =
= 2ΛQ QT ΛQ − P (QT ΛQ) + 2εQ(QT Q − I).
The choice of the projection function P (·) leads to diﬀerent classes of problem
on the isospectral manifold M (Λ). It should be observed that the obtained unconstrained diﬀerential systems obtained considering the gradient of function ϕ
can be seen as a stabilized diﬀerential system (it is easy to observe that the last
term is just the stabilized term introduced in the previous section).

4

A Numerical Method for Regularized System

Once the regularization term has been added to the given diﬀerential system
to solve it some numerical aspects are to be taken into account. A possible
technique is the post-stabilization of the numerical solution (see [2]). It consists
in the application of a stabilization step with respect to the manifold at the end of
each time step. In the case of orthogonal diﬀerential systems we can consider the
following method introduced in [2] and used in [4] to solve diﬀerential systems
on the Stiefel manifold in order to compute a subset of Lyapunov exponents
of a dynamical system. First the system (4) (or the system (6) choosing γ =
0) is integrated from tk to tk+1 using an explicit method and obtaining an
approximate solution Y˜k+1 . Then the regularization term
Y (t) = −γY (t)P (Y )

(10)

is integrated using, for instance, forward Euler with the same stepsize h but with
γ chosen so that γh = 12 and taking as approximation at the previous step Y˜k+1 :

154

C. Mastroserio and T. Politi

Yk+1 = Y˜k+1 − γhY˜k+1 P (Y˜k+1 )
and then

(11)

1
Yk+1 = Y˜k+1 In − P (Y˜k+1 ) .
2

This last step can be seen as the application of one step of the Schulz method
to compute the polar decomposition (see [7]).

5

Numerical Tests

Example 1. Let us consider the following gradient ﬂow introduced in [5]. If L
is a real symmetric matrix then the orthogonal ﬂow deﬁned by the diﬀerential
system:
Y (t) = Y [Y T LY, P (Y T LY )],
Y (0) = Y0
(12)
with Y0 a random orthogonal matrix, converges to the eigenvector matrix related
to L. In this case the projection function is
P (X) = diag(X)
while the objective function to minimize is (7). We have solved (12) using the
numerical method introduced in the previous section. Figure 1 shows the orthogonal error of the numerical approximation Yn , given by
En = YnT Yn − I

F

while in Figure 2 are reported the values of objective function. In Figure 3 is
shown the orthogonal error using the numerical method but applying two iterates
of (11). In this case the orthogonal error is smaller but considering the values
of the objective function they are the same shown in Figure 2. In this case it
seems that a better integration in the manifolds does not imply a speeder descent
toward the minimum point of the objective function.
Example 2. Given a real symmetric matrix A we want to ﬁnd a least squares
approximation of A that is still symmetric but has a prescribed set of eigenvalues
{λ1 , . . . , λn }. In this case the orthogonal ﬂow deﬁned by the diﬀerential system:
Y (t) = Y [Y T LY, A],

Y (0) = Y0

(13)

with Y0 a random orthogonal matrix. Figure 1 shows the orthogonal error of the
numerical approximation while in Figure 2 are sketched the values of objective
function.

Applying Stabilization Techniques to Orthogonal Gradient Flows

Orthogonal Error

−4

10

−6

10

−8

||Yk Yk−In||F

10

−10

T

10

−12

10

−14

10

−16

10

0

5

10

15

Time

Fig. 1. Orthogonal error for Example 1.

Objective Function

1

10

0

10

−1

10

−2

10

−3

10

−4

10

−5

10

−6

10

−7

10

0

5

10
Time

Fig. 2. Objective function for Example 1.

15

155

C. Mastroserio and T. Politi

Orthogonal Error

−9

10

−10

10

−11

10

−12

T

||Yk Yk−In||F

10

−13

10

−14

10

−15

10

−16

10

0

5

10

15

Time

Fig. 3. Orthogonal error for Example 1.

Orthogonal Error

−4

10

−6

10

−8

10

||Yk Yk−In||F

−10

10

T

156

−12

10

−14

10

−16

10

0

1

2

3

4
Time

5

6

Fig. 4. Orthogonal errors for Example 2.

7

8

Applying Stabilization Techniques to Orthogonal Gradient Flows

157

Objective Function
7.3

7.2

7.1

7

6.9

6.8

6.7

6.6

0

1

2

3

4
Time

5

6

7

8

Fig. 5. Objective function for Example 2.

References
1. Ascher U.M.; Stabilization of invariants of discretized diﬀerential systems. Numer.
Algorithms 14 (1997) 1–24
2. Ascher U.M., Chin H., Reich S.: Stabilization of DAEs and invariant manifolds.
Numer. Math. 14 (1994) 131–149
3. Baumgarte J.: Stabilization of constraints and integrals of motion in dynamical
systems. Comp. Math. Appl. Mech. Eng. 1 (1972) 1–16
4. Bridges T.J., Reich S.: Computing Lyapunov exponents on a Stiefel manifold. Physica D 156 (2001) 219–238
5. Chu M.T., Driessel K.R.: The projected gradient method for least squares matrix
approximations with spectral constraints. SIAM J. Numer. Anal. 47 (1990) 1050–
1060
6. Diele F., Lopez L., Peluso R.: The Cayley transform in the numerical solution of
unitary diﬀerential systems. Adv. in Comp. Math. 8 (1998) 317–334
7. Higham D.J.: Time-stepping and preserving orthonormality. BIT 37 (1997) 24–36
8. Lopez L., Politi T.: Applications of the Cayley approach in the numerical solution
of matrix diﬀerential systems on quadratic groups. Appl. Num. Math. 36 (2001)
35–55
9. Munthe-Kaas H.: Runge-Kutta methods on Lie groups. BIT 38 (1998) 92–111

