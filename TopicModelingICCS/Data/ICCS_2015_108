Procedia Computer Science
Volume 51, 2015, Pages 2933–2937
ICCS 2015 International Conference On Computational Science

Cloud Technology for Forecasting Accuracy
Evaluation of Extreme Metocean Events
Sergey S. Kosukhin1*, Sergey V. Kovalchuk1, Alexander V. Boukhanovsky1
1

ITMO University, Saint-Petersburg, Russia
skosukhin@gmail.com, sergey.v.kovalchuk@gmail.com, avb_mail@mail.ru

Abstract
The paper describes the approach for ensemble-based simulation within the tasks of extreme metocean
events forecasting as an urgent computing problem. The approach is based on the developed
conceptual basis of data-flow construction for the simulation-based ensemble forecasting. It was used
to develop the architecture for ensemble-based data processing based on cloud computing environment
CLAVIRE with extension for urgent computing resource provisioning and scheduling. Finally the
solution for ensemble water level forecasting in Baltic Sea was developed as a part of St. Petersburg
flood preventing system.
Keywords: ensemble forecasting, cloud computing, flood simulation

1 Introduction
Today the urgent computing (UC) technologies [1] are widely used within solutions for preventing
natural disasters and decision support in extreme conditions. A lot of UC solutions are based on the
simulation of different situation development scenarios. Taking into account the nature of UC, the
computation process often has a hard deadline and strong requirements for the accuracy of its results.
A lot of works are devoted to resource provisioning [2], performance modeling [3] and tasks
scheduling [4] within the scope of urgent computing. The emergence of the cloud computing approach
[5] enabled building a flexible and dynamically manageable cyberinfrastructure which can be used
effectively within UC context [6]. Nevertheless, the UC simulation of different scenarios for the
purpose of decision support often requires a higher level management of the simulation tasks within
complex workflows [7]. The issue is often complicated with the involvement of a wide range of
models with various performance and precision characteristics as well as different ways and
technologies for execution within the distributed or cloud environment. Moreover, the rarity and
extreme nature of the events which are usually simulated within the UC area make it difficult to use
predefined rules and simulation data. As a solution, ensemble-based methods can be used to manage
*

Corresponding author. Tel.: +7-921-639-76-68

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2015.05.483

2933

Cloud Technology for Forecasting Accuracy
Sergey Kosukhin,
Evaluation
Sergey
of Extreme
Kovalchuk
Metocean
and Alexander
Events Boukhanovsky

the accuracy of the simulations. There are different approaches for ensemble-based simulations:
multiple model usage [8], stochastic data manipulation with input and output data [9, 10] etc. In the
case of UC the ensemble-based approach significantly complicates calculation management, thus its
implementation has to be provided with additional ensemble-specific information.
Within this paper an approach for ensemble-based simulation management is presented in the
context of extreme metocean events. They are in demand by UC applications as they are often related
to the natural disasters such as floods [11], hurricanes [12], etc. A variety of existing numerical
models, which have been developed to research and to forecast different hydrological processes, raises
the problem of determining which one is better in relation to a particular application. This refers both
to model's ability to reproduce certain physical phenomena and to its operational characteristics.
Furthermore, the results obtained using hydrological models naturally depend on the sources of initial
and boundary conditions which are calculated on the basis of different atmospheric, water exchange,
wind wave, sea ice and other models each of which introduces an additional uncertainty that has to be
estimated.

2 Concept
The designated simulation management system is expected to perform an automatic intelligent
coupling of models and data sources in order to take into account all elements of a particular
ensemble, especially under the condition when a collection of integrated applied software is regularly
expanded. This can be achieved by providing each piece of applied software with a formal domainoriented description. These descriptions formally specify inputs, outputs and parameters of the
corresponding application in domain terms. First of all, they provide the system with information on
how one model (e.g. hydrodynamic sea model) can be fed with the output of another (e.g. atmospheric
model) in order to construct a data-flow graph. Paths of the graph define basic model pipelines which
produce a particular output. In the presence of objects providing the same type of data there are several
sequences that produce alternative representations of the same physical process as shown in Figure 1.
In cases where several objects of a pipeline expect the same type of input only one of the
corresponding alternative data providers is used for all of them. This is done to preserve the
consistency of the simulations. Additional pipelines are constructed by varying each object's
parameters in the range specified in the description.

Figure 1: Detection of members of water level and currents ensemble:
four basic pipelines (shown in different colors) are expanded by varying hydrodynamic models’ parameters

It is implied that the constructed pipelines are operationally executed by the system upon receipt of
the next portion of input data with concomitant post-processing and analysis. This serves several
purposes. One of them is to produce and disseminate materials which can be useful in preparing

2934

Cloud Technology for Forecasting Accuracy
Sergey Kosukhin,
Evaluation
Sergey
of Extreme
Kovalchuk
Metocean
and Alexander
Events Boukhanovsky

teaching courses on various sea phenomena and their causes. Different interactive visual aids based on
the obtained data can help users to perceive and analyze the results of simulations and observations of
sea state and atmospheric parameters. Another goal is to demonstrate the capabilities of competitive
sea models in operational forecasting. Developers of applied software based on numerical sea models
(i.e. St. Petersburg's Flood Warning System [11]) are able to estimate the performance and the quality
of the available options. An operationally supplemented archive of model products and measurements
opens an opportunity to perform statistical analysis (e.g. for flood risk assessment). Basic tools to
perform corresponding calculation tasks are integrated in the system using the big data approach.
There are several essential requirements that are imposed on the system. The first one is to provide
integration of third-party applications used in the simulations. Models and tools developed by
independent teams implement different interfaces and have different requirements on an operational
environment. Moreover, numerical models usually demand significant computational power and
produce large datasets. All these lead to the necessity to manage heterogeneous high-performance
computing infrastructure. The scalability is another requirement on the system. There should be a
straightforward way to expand the collection of models.

3 Architecture
All the applications can roughly be divided into two groups. The first one is denoted as internal
and includes software that is executed on computing resources managed by the system. Hence,
parameters of those applications can be varied to study their impact on the calculation outcome. In
turn, the applications of the second group are run externally with fixed parameters, and their results are
available only as inputs. A convenient way to solve the problems associated with the heterogeneity of
the internal models' system requirements, and the possible complexity of the concomitant calculations,
is to introduce all the necessary application and auxiliary software as cloud services. In that case, all
the calculation scenarios are sequences of calls to those services, i.e. workflows. This approach is
implemented with the use of the CLAVIRE platform [13]. To unify the invocations of the applications
each of them is provided with a set of basic workflows which are consistent with the corresponding
domain-oriented descriptions. For internal software these workflows contain sequences of calls to
underlying cloud services to produce the declared output including all pre- and post-processing tasks.
In case of external models their workflows only describe steps for downloading and, if necessary,
converting their outputs.

Figure 2: System architecture

2935

Cloud Technology for Forecasting Accuracy
Sergey Kosukhin,
Evaluation
Sergey
of Extreme
Kovalchuk
Metocean
and Alexander
Events Boukhanovsky

The architecture of the system is presented in Figure 2. The implementation of the described
ensemble building approach is represented by the ensemble manager subsystem. Each pipeline
constructed by the ensemble manager is translated to a workflow script which is submitted to the
CLAVIRE kernel. Using the service and resource descriptions, the kernel performs scheduling and
following parallel execution of the target applications. Depending on underlying software and
corresponding application task, the workflow script may contain BigData requests which are
forwarded to the BigData request processor [14]. Further, the tasks are distributed among the storage
agents, which perform the direct local launch of the applications.

4 Case studies
Storm surge floods that regularly happen in the Gulf of Finland are demonstrative examples of
extreme hydrological events. Floods of this type are caused by cyclone activity. When a cyclone
crosses the center of the Baltic Sea its low pressure center sucks up the water and initiates a long
progressive wave which propagates in the Gulf of Finland. Due to the shallowness of the eastern
narrow part of the Gulf the height of the wave increases which leads to the emergence of a flooding
situation in St. Petersburg. The result of the simulation of such situation is presented in Figure 3(a).

Figure 3: (a) Visualization of water level and currents in the Gulf of Finland during the flood; (b) Visualization
of ice fraction field in the Baltic Sea; (c) Ensemble of water level forecasts based on wind stress factor variation

The main source of uncertainty of the hydrodynamic simulations are surface boundary conditions
which are calculated taking into account, among other things, the wind stress factor. An example of
this parameter's variability influence on the quality of the water level forecast is presented in Figure
3(c). The corresponding plots are based on the results of multiple runs of the Baltic Sea Model [15]
provided with HIRLAM [16] meteorological forecast (both integrated as domain-specific objects) and
parameterized with 48 different values of the wind stress factor. It is clear that the optimal wind stress
factor value to obtain the best forecast of the water level is 1.61. It should be noted that the variability
of the parameter can be connected not only with the uncertainty of the meteorological forecast but also
with the characteristics of the underlying surface, for example, its ice fraction. Thus, ice formation
simulations are also performed by the system to build multi-model ensembles. An example of the
corresponding simulations using NEMO ocean engine [17] is presented in Figure 3(b).

2936

Cloud Technology for Forecasting Accuracy
Sergey Kosukhin,
Evaluation
Sergey
of Extreme
Kovalchuk
Metocean
and Alexander
Events Boukhanovsky

5 Conclusions
The approach presented was developed to provide comprehensive support for ensemble-based
simulation of extreme metocean events which can be considered as UC-task. As the ensemble-based
techniques are often related to the computational-intensive and data-intensive tasks the developed
architecture used cloud computing environment extended with additional UC scheduling procedures
[18]. The proposed approach enables development of high-level domain-specific solutions within
different scenarios (simulation-based investigation, urgent-computing decision support, open-access
publication of ensemble simulation, etc.) hiding technological complexity with the use of developed
architecture.
This paper is supported by Russian Scientific Foundation, grant #14-11-00823. The research is
performed in Advanced Computing Lab (ITMO University), which is created in the frame of 220
Decree of Russian Government, contract #11.G34.31.0019.

References
[1] P. Beckman, " Urgent Computing: Exploring Supercomputing’s New Role," CTWatch Quarterly, vol. 4, n. 1, pp. 3-4, 2008.
[2] J. Hedden, J. Insley, T. Leggett, and M.E. Papka, “Experience with Preemption for Urgent Computing,” Urgent Computing
Workshop 2007 [http://spruce.teragrid.org/workshop/talks/Papka.pdf].
[3] N Trebon and P. Beckman, “Empirical-based Probabilistic Upper Bounds for Urgent Computing Applications,” Cluster
Computing, 2008 IEEE International Conference on, pp. 342-347, 2008.
[4] B. Nitzberg, “Job Schedulers, Resource Management, Reservations, and Preemption,” Urgent Computing Workshop 2007
[http://spruce.teragrid.org/workshop/talks/Nitzberg.pdf].
[5] I. Foster, Y. Zhao, I. Raicu, and S. Lu, “Cloud Computing and Grid Computing 360-Degree Compared,” Grid Computing
Environments Workshop, 2008. GCE’08, pp. 1-10, 2008.
[6] S.V. Kovalchuk, P.A. Smirnov, S.V. Maryin, T.N. Tchurov, and V.A. Karbovskiy “Deadline-driven Resource Management
within Urgent Computing Cyberinfrastructure,” Procedia Computer Science, vol. 18, pp. 2203-2212, 2013.
[7] S.V. Ivanov, S.V. Kovalchuk, and A.V. Boukhanovsky, “Workflow-based Collaborative Decision Support for Flood
Management Systems,” Procedia Computer Science, vol. 18, pp. 2213-2222, 2013.
[8] T.N. Krishnamurti, C.M. Kishtawal, Z. Zhang, T. LaRow, D. Bachiochi, E. Williford, S. Gadgil, and S. Surendran,
“Multimodel Ensemble Forecasts for Weather and Seasonal Climate,” J. Climate, vol. 13, n. 23, pp. 4196-4216, 2000.
[9] R. Schefzik, T.L. Thorarinsdottir, and T. Gneiting, “Uncertainty Quantification in Complex Simulation Models Using
Ensemble Copula Coupling,” Statistical Science, vol. 28, n. 4, pp. 616-640, 2013.
[10] Z. Toth, and E. Kalnay, “Ensemble Forecasting at NMC: The Generation of Perturbations,” Bulletin of the American
Meteorological Society, vol. 74, n. 12, pp. 2317-2330, 1993.
[11] S.S. Kosukhin, A.V. Kalyuzhnaya, and D. Nasonov, “Problem Solving Environment for Development and Maintenance of
St. Petersburg‘s Flood Warning System,” Procedia Computer Science, vol. 29, pp. 1667-1676, 2014.
[12] G. Allen, P. Bogden, T. Kosar, A. Kulshrestha, G. Namala, S. Tummala, and E. Seidel, “Cyberinfrastructure for Coastal
Hazard Prediction,” CTWatch Quarterly, vol. 4, n. 1, pp. 17-26, 2008.
[13] K.V. Knyazkov, S.V. Kovalchuk, T.N. Tchurov, S.V. Maryin, and A.V. Boukhanovsky, “CLAVIRE: e-Science
infrastructure for data-driven computing,” Journal of Computational Science, vol. 3, n. 6, pp. 504-510, 2012.
[14] S.V. Kovalchuk, A.V. Zakharchuk, J. Liao, S.V. Ivanov, and A.V. Boukhanovsky, “A Technology for BigData Analysis
Task Description Using Domain-specific Languages,” Procedia Computer Science, vol. 29, pp. 488-498, 2014.
[15] K.A. Klevanny, G.V. Matveyev, N.E. Voltzinger, “An integrated modelling system for coastal area dynamics,”
International Journal for Numerical Methods in Fluids, vol. 19, n. 3, pp. 181-206, 1994.
[16] P. Unden, L. Rontu, H. Jarvinen, P. Lynch, J. Calvo, G. Cats, J. Cuxart, K. Eerola, C. Fortelius, J.A. Garcia-Moya,
C. Jones, G. Lenderlink, A. McDonald, R. McGrath, B. Navascues, N.W. Nielsen, V. Odegaard, E. Rodriguez,
M. Rummukainen, R. Room, K. Sattler, B.H. Sass, H. Savijarvi, B.W. Schreur, R. Sigg, H. The, and A. Tijm, “HIRLAM-5
scientific documentation,” HIRLAM-5 Project, SMHI, S-601 76, Norrköping, Sweden, 2002.
[17] G. Madec, “NEMO ocean engine,” ISSN No 1288-1619, 2012
[http://www.nemo-ocean.eu/content/download/21612/97924/file/NEMO_book_3_4.pdf]
[18] D. Nasonov, and N. Butakov, “Hybrid Scheduling Algorithm in Early Warning Systems,” Procedia Computer Science,
vol. 29, pp. 1677-1687, 2014.

2937

