Problems and Prospects for Quantum Computational
Speed-up
E.V. Krishnamurthy
Computer Sciences Laboratory,
Australian National University, Canberra, ACT 0200, Australia.
abk@discus.anu.edu.au

Abstract. This paper studies the problems involved in the speed-up of the
classical computational algorithms using the quantum computational
paradigm. In particular, we relate the primitive recursive function approach
used in computability theory with the harmonic oscillator basis used in
quantum physics. Also, we raise some basic issues concerning quantum
computational paradigm: these include failures in programmability and
scalability, limitation on the size of the decoherence – free space available and
lack of methods for proving quantum programs correct. In computer science,
time is discrete and has a well-founded structure. But in physics, time is a real
number, continuous and is infinitely divisible; also time can have a fractal
dimension. As a result, the time complexity measures for conventional and
quantum computation are incomparable. Proving properties of programs and
termination rest heavily on the well-founded properties, and the transfinite
induction principle. Hence transfinite induction is not applicable to reason
about quantum programs.

1 Introduction
Quantum theory of computation is an important area of fundamental study linking the
physical quantum theory with the logical theory of computability. From a pragmatic
point of view, we are not even sure whether this study will lead us to the design of a
quantum computer in the near future or almost never! Although, quantum version of
boolean logic circuits [4, 6, 8, 9, 23] have been shown to be feasible, the machine
hierarchy (namely, finite state machines, push-down stack machine and Turing
machine) and the corresponding Chomskian grammatical and linguistic hierarchy
[11,13], their connection to algorithms and related data structures have not been
established in quantum computational logic, leaving a wide gap in understanding. Yet,
some problems have been shown to be amenable for quantum speed-up [4,8,10,23].
These algorithms have been ad hoc discoveries using the principle of quantum
superposition (Schrodinger cat states) and are probabilistic. Based on these, there have
been several claims that quantum speed-up can break the computational intractability,
as well as, the Turing barrier of noncomputability. But so far there has been no
success to prove these claims due to the difficulty in bridging a physical theory with
the logical computability theory. In fact, extending the recursion theory over the
integers to real and complex numbers to include approximate operations that are
typically composition of functions and solutions of differential equations [3] do not
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 779–788, 2003.
© Springer-Verlag Berlin Heidelberg 2003

780

E.V. Krishnamurthy

result in newer complexity classes and so the standard computational complexity
measures remain intact. Yet another obstacle is set by Physics, due to decoherence.
Decoherence prevents coupling with the environment thereby making the quantum
speed up ineffective [2, 10, 23]. Thus this is a challenging area for innovative
experimental and theoretical research seeking answers to many questions.
The purpose of this paper is to explore the reasons as to why the quantum paradigm
is not so easy to extend to all of the classical computational algorithms. Firstly, our
arguments based on quantum field theory (second quantization) leads us to the result
that quantum speed-up can be effective only for the primitive recursive functions (or
the unravelled “for loop” or “count loop” programs), which correspond to the
harmonic oscillator functions, and not for total or partial recursive functions (“general
while loop” programs).This places a severe restriction on the type of algorithms that
can be mapped to gain quantum-speed-up. Secondly, the problem of designing
quantum algorithms through superposition is analogous to designing algorithms based
on the “unrealistic Concurrent-Write- Exclusive Read PRAM” model [14]. That is we
m
need a quantum measurement that can extract all of the 2 values of the component
functions from their superposition pattern. The only way to extract information from
the pattern is through the recognition of joint properties among the values of the
function f(x), for example, the periodicity, using quantum probabilistic means.
However, extracting a definite answer from this pattern is highly problem domain
dependent and is not easy although, Hadamard or Fourier transform and other filtering
or projection techniques are useful for particular problems.
While superposition principle provides space complexity reduction for timeindependent parallel computation, there remains yet another possibility called "Zeno
squeezing", in which an infinite amount of computation can be performed in a finite
time through a time scale change, since time is a real number in Quantum Physics
(See Section 6.5). This aspect remains to be explored in quantum speed-up.
In this paper we consider the following issues:
1.To study why quantum algorithms are hard to design and what are the requirements
for realising such algorithms?
2.What are the current open problems and what are the limitations in our knowledge?
The aforesaid studies lead to the following results:
(i) Errors in encoding and difficulty in Mapping: Quantum computation work with a
continuum of states and use unitary transformation framework over complex numbers
rather than conventional boolean gates. In this sense they are analog;hence inexact and
are subject to operational errors. Therefore, realising an arbitrary unitary operator with
arbitrary precision is not easy. For example, one of the most common quantum gates
rotates a quantum bit by an angle; this can result in error causing operational errors to
propagate [24].
Quantum paradigm requires that the problems are converted into a periodic
superposition of functions. This approach is different from the mapping of processes
to architectures, in the sense, it is a structural transformation of a problem from a
given domain to a non-dissipative quantum dynamical system. Also the absence of
suitable supporting data structures-such as- stack and other data structural mechanisms
required in the design of algorithms are not available.This makes programming
conceptually difficult.
(ii) Failure of Programmability: Quantum nonlocality [10, 17, 21] creates nonanticipated interactions resulting in the failure of a total program.So the software

Problems and Prospects for Quantum Computational Speed-up

781

engineering requirement for modular construction of a whole program from its parts,
or the principle of denotational semantics is violated. Thus programming a quantum
computer through a recursive set-up is not possible.
(iii) Failure of Composition: Conventional programs are built as a composition of
primitive recursive functions over the integers. The quantum programs need to realise
such functions using a composition of the different real or complex functions for each
subprograms. This would result in both operational errors and dissipation leading to
accelerated decoherence. Hence the divide and conquer strategy (or related strategies
used in algorithmic engineering) in which we decompose a problem into subproblems
and composing the results fails [18].
(iv) Failure of Scalabilitty: Scalability is a metric that tells us how the running time to
solve a problem scales or varies with its size. Assume that we use the divide and
conquer strategy. If we partition the problem into N pieces and each such partition is
solved by N different processors simultaneously, and the algorithm is linearly
scalable, we expect that the total problem is solvable in the same time as solving a
single partition plus some overhead for combining the N solutions. Since each such
partition is a different coherent state, their phase coherence is to be preserved before
combining the results in order to avoid an accelerated decoherence. The preservation
of coherence is difficult if the different partitions are not identical as in nontrivial
computations.Hence partitioning a problem and solving is ruled out in quantum
methodology.Hence scalability fails and we need bigger and bigger machines to solve
larger and larger problems.
(v) Quantum Decoherence in while loop: The reason why we cannot use “while loop”
for testing is obvious. Each such test in a loop destroys the coherence. Hence “while
loop” programs are forbidden quantum mechanically. However, the unravelled “for
loop” computations that are primitive recursive are realisable as coherent harmonic
oscillator states. But they cannot be composed due to accelerated decoherence. Some
attempts are under way to prevent accelerated decoherence by choosing decoherencefree space so that phase coherence between such states remains intact.
(vi) Proving Quantum Programs Correct: The structure of time, namely, whether it is
continuous or discrete, plays an important role in reasoning, verification and proving
the correctness of programs. In computer science, time has a discrete well-founded
structure, while in physics, it is well accepted that the structure of time is a real
number and is continuous and is infinitely divisible. In fact time can have a fractal
dimension too. This means the transfinite induction principle is not applicable to
reason about quantum programs. As a result, the time complexity for conventional and
quantum computation are incomparable.
(vii) Curse of dimensionality: We have shown elsewhere [18] that quantum speed-up
cannot obviate the curse of dimensionality encountered in many numerical problems
due to quantum entropy arsing from operational and decoherence errors.
(viii) Zeno-squeezing: Is there a physical possibility of Zeno squeezing of time through
a time-scale change for quantum speed-up? (Section 6.5)

2 Quantum Algorithmic Paradigm
Quantum algorithmic paradigm is the realisation of a physical quantum system whose
dynamical evolution takes the system from one of a set of input states to one of a set

782

E.V. Krishnamurthy

of output states. If we assume that a quantum computer consists of a set of quantum
components and a quantum register, the quantum computation can be viewed as a
process which consists in preparing the input state S(in) and evolving it to an output
state S (out). The output state is a positive map of the input state through a linear
operator transformation that results in a superposition of all m input values into a
single state resulting in a pattern formation (Concurrent Write without any constraint unknown to computer science theory). The quantum measurement is then supposed to
m
extract (or Exclusive Read) of all the 2
values from their joint properties, e.g.
periodicity. It is assumed that such a process preserves quantum coherence in the
register since it is the quantum coherence that provides the required quantum speedup. Thus quantum decoherence should not take place before the reading.

3 Quantum Evolution, Dissipation, and Coherence
In [15, 16] we studied the relationship between the notion of computability and
complexity in computer science, and the notion of integrability in mathematics and
physics to understand the complexity aspects of quantum computing. In [15], using the
Feynman path integral (FPI) approach we showed that a quantum computer behaves
like an analog of an Alternating Turing machine (ATM) exhibiting and-or parallelism
by computing the probability amplitude for the reachability (transitive closure)
between a given initial and the final algorithmic state. We also stated the two
important requirements for the success of quantum evolutionary computation, namely:
1. The evolutionary structure of the exact algorithmic solution of a given mathematical
problem is mappable to the “exact unitary” evolutionary structure of a quantum
dynamical system leading to the exact spectrum, and these two evolutionary structures
have isomorphic histories between the initial, intermediate and final states of the
computation. Any approximation would incur degenerative operational errors.
2. The initial, intermediate and final states of the quantum dynamical system are
coherent states and the evolution of the hamiltonian preserves coherence. In other
words, decoherence does not take place during the progress of computation, and
before the final result is read by an observer. This requirement heavily hinges upon the
theory of quantum measurements.
The requirements 1 and 2 demand that the evolution is nondissipative,Braun [2] and
is also coherence preserving. The requirements, namely, coherence preserving
evolution, as well as nondissipative can be achieved if the quantum dynamical system
belongs to two important group structures, SU(2) and SU(1,1), [1, 16]. Thus to have a
coherence preserving, unitarily evolving, exact quantum computation it is sufficient
that the class of computational problems have models isomorphic to SU(2) or SU(1,1)
group theoretical structures. This class contains instances of periodic problems
mappable to harmonic oscillator, e.g., Shor’s factorization, and instances of problems
mappable to the permutation groups e.g., sorting, Nielsen and Chuang [23]. Note that
for the SU(2), SU(1,1) unitary processes (dealing with photon number measurement)
in a quantum optical system, Ban [1] shows that the entropy decrease of the physical
system is equal to the amount of information extracted from the measurement
outcomes. That is there is no loss of information and the photon number is exactly
obtained. This class of problems corresponds to synchronous coherently evolving non-

Problems and Prospects for Quantum Computational Speed-up

783

interacting parallel streams of computations whose hamiltonians are amenable for
easy composition and analysis using quantum optical devices and molecular spinresonance devices [23]. However, even for such computations the time scale necessary
turns out to be not practical. This is because a million computations are to be carried
–11
out and the final results read-off in a thermal time scale time less than 10
second,
at a very cold temperature as low as 1 degree Kelvin, Landauer [21]. Thus the unitary
quantum dynamical evolution is restricted to solve only problems that can be mapped
on to non-dissipative hamiltonian systems that can evolve without decoherence.

4 Primitive Recursion and Harmonic Oscillator Functions
Two approaches for modelling computability are [11,13,14]:
(i) Turing machine and (ii) Recursive function.
In the last decade the Turing machine model, which is an operational model has
been widely used as the basis for modelling the Quantum mechanical computers, see
Deutsch [4], Hey and Allen [9] to prove the universality of quantum computers. We
may call the Deutsch approach as the first quantisation approach since it is concerned
with the wave aspects of particles (Wavicles) rather than the particle aspect of waves.
Although, the Turing machine approach is equivalent to recursive function approach,
the latter is more suitable than the former for analysis [17]. The QFT approach is
called the second quantisation scheme in Quantum physics.
The quanta of the radiation field corresponds to the non-negative integers and the
harmonic oscillator spectra correspond to the recursive computation- with the
projection, creation and annihilation operators respectively playing the same role as
the Selection, Successor and Predecessor in computability theory. Accordingly this
approach [17] relates the classical computational models and the quantum field
models more directly than the Turing machine approach used earlier [4,9].
If we identify the successor function used in recursive function theory with the
bosonic creation (or construction or raising) operator, and predecessor function with
the bosonic annihilation (destruction or lowering) operator, then we can generate all
the primitive recursive functions (with the quanta as the basic unit of computation)
consisting of the function algebra, consisting of some basic functions and closed under
certain operations:
{ZERO, SUCCESSOR, PREDECESSOR, PROJECTION, COMPOSITION,
PRIMITIVE RECURSION, BOUNDED MINIMALIZATION} [11,13,17] .
Thus, the harmonic oscillator plays the same role in the quantum physics, as the
primitive recursive function generator does in the theory of computation.
The use of harmonic oscillator as the basis, permits us to only compute primitive
recursive functions, but not a total recursive function (such as the Ackerman function)
or partial recursive function (a general “while loop”) [11,13,17].
The precise counting of bosons or phase determination [17,18] provide mutually
exclusive approaches for designing three types of primitive recursive exact digital
Quantum algorithms, see [23]. In quantum computers, a string of bits is stored of a
system equivalent to m 2-level systems (quantum bits or q-bits). The general state is
m
then a superposition of states u(i) where i runs through 0 to 2 – 1 values of a classical
bit string. If the devices are not error-prone and there is no loss of energy, then such a

784

E.V. Krishnamurthy

superposition is identifiable with a primitive recursive computable function,if the
coefficients in the linear combination are exact numbers or exact phases, since the
number-phase relation forbids the exact determination of both [17,18].We can
therefore create a coherent superposition of only phases or amplitudes respectively
creating Schrodinger phase cats or amplitude cats, Braun [2]. To avoid operational
errors, we need to use exact phases as rational numbers using the prime residue or padic rationals [7,12]. No speed-up methods are known for fast quantum computer
arithmetic.
4.1 Decoherence-Free Sub-Space (DFS)
Decoherence is a key ingredient in the transition from quantum to classical mechanics.
It has been shown [2, 21,24] by that in a macroscopic system the decoherence time
scale or the time required for loss of coherence is many orders of magnitude less than
the classical time scale over which probabilities evolve. However, some exceptions
seem possible and one can look for decoherence free subspaces (DFS). Braun [2]
N
shows that if the dimension of the Hilbert space is 2 , and superrdiance is present,
N+1/2
the dimension of the DFS scales as: [2
/ √ π N], for large N. That is a fraction
√2/πN of the Hilbert space can be decoherence free. This means the input and output
domain should remain within the DFS. Obviously, Ackermann function would
outgrow any given DFS super-exponentially.

5 Programmability and Scalability
In programming theory, we define each language construct in terms of certain
mathematical entities (numbers, truth values, functions, operators) that model their
meaning. The total meaning of a program is then reconstructed as a composition of the
meanings of the individual basic constructs; or “a whole “is described in terms of its
“parts”. If the program is recursively defined, its meaning is the input-output function
corresponding to the least or minimal fixed point of a transformation associated with
the program [13, 22]. This ensures that the program has a well-defined functional
relationship between the input and output states and the program halts. This
assumption also holds true in classical mechanics where the real states are always
local and do not contain statistical correlations, among the states of their local
subsystems. However, such an assumption breaks down in quantum systems. The
quantum system can exhibit both kinematic and measurement-induced nonlocality.
The many particle hamiltonian expression one can work out using recursive function
like approach may not obey the basic assumption used in denotational semantics,
namely, a composite system is composed of parts and the state of whole is definable in
terms of the states of its parts. There are quantum correlation between different
subsystems due to the superposition principle. In fact, the whole is more than its parts,
even if we assume there is no interaction among the subsystems. Therefore, we cannot
partition a quantum system into its parts as is done in computer science and synthesize
the system using its parts; this is called non-separability. Hence the structural
programmability, and the scalability of the system is lost.

Problems and Prospects for Quantum Computational Speed-up

785

6 Time, Proof, and Complexity of Quantum Programs
Reasoning about programs (verification, proving correctness and termination) is an
essential requirement in program design. Such schemes are usually based on the
transfinite induction principle that hinges on the theory of nonnegative integers
[19, 20, 22]. Also while reasoning about the complexity of computation, as well as,
time dependent and real time programs, time is represented as a discrete set of points
mappable to the positive integers or to a set of intervals and temporal logic is used
[19]. Such a notion of time satisfies the well-founded relationship to be described in
the next subsection. Proving properties of programs and termination rest heavily on
the well-founded properties, and chain reasoning method.
Despite numerous attempts to revise this concept over many years, it is well
accepted in Physics that time is a real number, continuous and is infinitely divisible.
(In fact, time can have a fractal dimension too). Many of the physical theories rest on
this fundamental assumption. The notion of time complexity in computation depends
on whether the time is continuous or discrete, since this notion distinguishes the
continuous time dynamical evolution (as in analog computation) from the discrete
digital computation. This is because time appears as an intrinsic parameter in the
process of quantum (analog) evolution. For example, under suitable conditions, it may
be possible to use an algebraic transformation or rescaling of the time parameter of a
differential equation to rearrange it so that that the processes which take infinite time
can be executed in a finite time in analog machines. However, analog computing is
not effective in the sense of Church-Turing thesis [3,4,11,13]. Thus the notion of time
complexity is incomparable between the analog and the digital set- up. As an example,
consider the mapping: t := (t-1)/t. This would transform the time parameter from the
range [1, ] to [0,1]. This is called Zeno contraction or squeezing (Section 6.5). Such
types of contractions, dilatations or scale changes abound in Physics. Thus the
computability logic and physics widely differ in defining the structure of time.
6.1 Well-Founded Sets
A binary relation < is well-founded over a class of objects, if it satisfies the nodecreasing condition; that is, there is no infinite sequence of objects decreasing with
respect to that relation. In other words, there are no sequences {x(0), x(1), x(2),
x(3),....} of objects such that: x(0) > x(1) > x(2) > x(3)>... where > is the inverse
binary relation of <. For a detailed study of well founded sets and relations, and
related temporal logic, see Manna and Waldinger [22], Kroger [19]. Formally a wellfounded relation (WFR) is defined over a set of objects (obj) thus: There are no
infinite sequences {t (0),t(1),t(2),...} of objects t(u) such that: for all integers u object
t(u) and for all integers u: t(u) > t (u+1).
A set in which the elements are related through a well-founded relation is called a
well-founded set.
6.2 Properties of Well-Founded Relation (WFR)
Irreflexive: That is there are no objects such that x < x.
Asymmetric: For all object x,y: [If x < y then not ( y < x)] must be valid.

786

E.V. Krishnamurthy

Not necessarily transitive: While WFR may be transitive, it is not necessary.
Minimal Element: If A is any nonempty subset of a wellfounded set, there is an
element in A such that x < y for all y in A. In other words, every nonempty subset of
a wellfounded set contains a minimal element.
In computing logic time is quantized and is a well-founded set satisfying the
properties – irreflexivity and asymmetry. Hence, we have a strong sense that time
starts with a minimal element, the experienced time can be measured by units, and it
has an arrow due to the asymmetry property. In Physics (both classical and quantum),
time is not a well founded set. Time is a computable real number which is infinitely
divisible [25,26]. Also calculus (continuity, differentiability and integrability ) of real
numbers plays a fundamental role in the physics of dynamical systems. Time arrow
has not yet been established and time is symmetric [26].
6.3

Transfinite Induction Principle

An arbitrary well- founded relation over a set of objects (nonnegarive integers, tuples,
trees) gives rise to the “Transfinite Induction Principle” stated below: If for some
property P under every z ε Z , P(z) (i.e. z has the property P ) x can be proved under
the assumption that p(z’) holds for every z’< z then P(z) holds for all z ε Z. This
principle plays a very crucial in the deductive foundations of computer programming
to prove correctness and termination of programs not only over the integers, but also
over other data structures -such as tuples and trees.
6.4

Consequences of Infinite Divisibility of Time

1. Since time is real and not a well-founded set, the transfinite induction principle (that
permits inductive inference) fails. Therefore, quantum programs are not provable for
correctness and termination using the classical generalised induction principle for
nonnegative integers, tuples or trees.
2. Since time is not discrete, it has to be represented as computable real. That is
there exists a computable sequence of rationals which converge effectively to a given
value t. Thus we need to compute “bit by bit” the value of time that converges
effectively within a radius of convergence.
3. Since time is infinitely divisible, the complexity of quantum computing becomes
incomparable to the classical complexity results.
4. The recursive function over integers consists of the function algebra, consisting of
some basic functions and closed under certain operations [3,11,13,17] :
{ZERO, SUCCESSOR, PREDECESSOR, PROJECTION, COMPOSITION,
PRIMITIVE RECURSION, BOUNDED MINIMALIZATION}. This can be
generalised [3]
to the primitive real class with:{ZERO, SUCCESSOR,
PREDECESSOR, PROJECTION, COMPOSITION, INTEGRATION, ZEROFINDING on REAL} permitting us to define periodic functions like Sin, π, e. Also similar
to the case of primitive recursive functions over integers that are not closed under
minimalization, we also have the corresponding situation arising for integration. An
important difference in real recursion is the replacement of primitive recursion by
integration. Thus integrability becomes an important issue in dealing with complexity
aspects over reals and complex numbers [40–43].

Problems and Prospects for Quantum Computational Speed-up

787

5. To reason about quantum programs, we need to develop the theory of recursive
functions over the reals and an associated theory of programmability that can bridge
with the theories of computational complexity, dynamical systems (classical and
quantum), and numerical analysis.
6. Since time is real, we can convert an infinite time computation to a finite time by
using Zeno squeezing oracle to be described in the next subsection. In fact time-line
can be cut through to produce fractal time. This can result in statistically self-similar
evolution [5,25,27,28,29]. In such a case, space and time should be appropriately
defined for evaluating measures of complexity.
6.5

Zeno Squeezing Oracle

Turing defines an oracle [28] thus: An oracle is an agent or a “blackbox”, which upon
being consulted, supplies the true(correct) answers about mathematical or algorithmic
or physical entities. Oracles though unrealizable in any universal computer, are useful
to achieve the limit of an infinite computation. To conceive of such an oracle two time
scales are introduced as below:
(i) an intrinsic time scale of the process of computation which tends to infinity and
(ii) an extrinsic time scale that remains finite for an external observer.
By using two such time scales, it is possible to produce within a finite proper time
an output that would otherwise take an infinite time. This is called Zeno squeezing,
since the infinite intrinsic time is squeezed to a finite extrinsic time limit. For example
consider a time scale t (i) belonging to the set of integers:
t(0) = 0;t(1)=1,....,t(k)= k,,…..
t(i)
Consider a scale T with T(0)= t (0)= 0; T( i > 0) = [ k
-1] /(k-1) with 0 < k< 1.
In the limit when t (i) tends to  WKH SURSHU WLPH 7 N UHPDLQV ILQLWH
A common feature of the Zeno oracle is that the valuation assigned to the intrinsic
time t decreases with its increasing value, reaching a finite extrinsic time limit when
the intrinsic time is infinity. Thus time flow is non-uniform with a higher valuation for
closer events and a lower valuation for events into a far future, much like the visual
valuation of the size of objects as spatial distance varies from near to far. This is
analogous to the non-Archimedian valuation used in p-adic system [7]. Perhaps,
quantum systems may offer the possibility of devising oracles to squeeze time. This
can result in statistically self- similar evolution locally at every point of time and
scaling invariance analogous to Brownian motion and fractional Brownian motion.

7 Concluding Remarks
We explained some important reasons why quantum algorithms are difficult to design
and implement. In particular, we explained the difficulty in seeking an appropriate
structural transformation from a given problem domain to the non-dissipative quantum
domain,failure of programmability and scalability. Since time in Physics is a real
number quantum programs are not provable using transfinite induction principle.

788

E.V. Krishnamurthy

References
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.

Ban, M: Information and entropy in Quantum measurement processes, International J
Theoretical physics, 37 (1998) 2491–2537
Braun,D: Dissipative Quantum chaos and Decoherence,Springer, New York ( 2001)
Campagnolo, M.L.: The Complexity of real recursive functions,in Lecture Notes in
Computer Science, Vol.2509: Springer Verlag , New York (2002) 1–14.
Deutsch,D.: Quantum Theory, the Church Turing principle and the universal quantum
computer, Proc. Roy. soc. London, A 400 (1985) 97–117.
Feder,J: Fractals, Plenum Press, New York,(1988)
Feynman,R: Quantum Mechanical Computers, Foundations of Physics,16 (1986)507–531.
Gregory ,R.T and Krishnamurthy, E.V: Methods and Applications of Error-free
Computation, Springer Verlag, New York ( 1984)
Gruska ,J: Quantum Computing, McGraw Hill, London (1999)
Hey,A.J.C., and. Allen, R.W: Feynman Lectures on Computation, Addison Wesley, New
York, (1996)
Kitaev, A., Yu, Shen, A.H., and Vyalyi, M.N: Classical and Quantum Computation,
American Mathematical Society, New York ( 2002)
Krishnamurthy, E.V.: Introductory Theory of Computer Science, Springer Verlag, New
York, (1984)
Krishnamurthy, E.V.: Error-free Polynomial Matrix Computations, Springer Verlag, New
York, (1985)
Krishnamurthy, E.V.: Parallel Processing, Addison Wesley, Reading, Mass( 1990)
Krishnamurthy E.V.: Complexity Issues in parallel and distributed Computing, Chapter 4,
in Parallel and Distributed Computing Handbook, Ed. A. Zomaya, McGraw Hill, New
York, (1996) 89–146
Krishnamurthy, E.V.: Computational power of quantum machines, quantum grammars, and
feasible computation, International J. Modern Physics. C 9 (1998) 213–241.
Krishnamurthy, E.V: Integrability, Entropy and quantum computation, International J.
Modern Physics. C10(1999) 1205–1228.
Krishnamurthy, E.V and Krishnamurthy, V:, Quantum Field theory and Computational
Paradigms, International J Modern Physics. C12 (2001),1179–1205.
Krishnamurthy, E.V: Mapping, Programmability and Scalability of problems for quantum
speed-up, International J. Modern Physics, in press.
Kroger, F: Temporal Logic of Programs, Springer Verlag, New York (1987)
Lamport, L: Time, Clocks, and the ordering of events in a distributed system, Comm.
ACM,.21 (1978) 558–565.
Landauer, R: Is Quantum mechanics useful? Phil.Trans.Roy.Soc., Lond, A.353 (1995)
367–376
Manna, Z., and Waldinger,R.:The deductive foundations of Computer programming,
Addison Wesley, Reading, (1993)
Nielsen, M.A., and Chuang, I.L.: Quantum Computation and Quantum Information,
Cambridge University Press, Cambridge, (2000)
Niwa, J., Matsumoto. K.,and Imai, H.: General purpose Parallel simulator for Quantum
computing, Lecture Notes in Computer Science, Vol.2509,Springer Verlag, New York,
(2002) 230–251.
Nottale, L.: Fractal Space-Time and Microphysics, World Scientific, Singapore (1993)
Park, D.: Time in Quantum mechanics, in Fundamental questions in quantum mechanics,
Ed. L.M. Roth and A. Inomata, Gordon and Breach Science Publishers, London (1986)
Peitgen, H., Jurgens, H., and Saupe, D.: Fractals for the class room, Part 1, Springer
Verlag, New York, (1991)
Svozil, K.: Randomness & Undecidability in Physics,World Scientific, Singapore(1993)
Wolfram, S.: A New kind of Science, Wolfram Media Inc., Champaign, Ill,( 2002).

