A Generic Framework for Local Search:
Application to the Sudoku Problem
T. Lambert1,2 , E. Monfroy1,3, , and F. Saubion2
1

3

LINA, Universit´e de Nantes, France
Firstname.Name@lina.univ-nantes.fr
2
LERIA, Universit´e d’Angers, France
Firstname.Name@univ-angers.fr
Universidad Santa Mar´ıa, Valpara´ıso, Chile
Firstname.Name@inf.utfsm.cl

Abstract. Constraint Satisfaction Problems (CSP) provide a general
framework for modeling many practical applications. CSPs can be solved
with complete methods or incomplete methods. Although some frameworks
has been designed to formalized constraint propagation, there are only few
studies of theoretical frameworks for local search. In this paper, we are
concerned with the design of a generic framework to model local search
as the computation of a ﬁxed point of functions and to solve the Sudoku
problem. This work allows one to simulate standard strategies used for
local search, and to design easily new strategies in a uniform framework.

1

Introduction

Sudoku literally means single number in Japanese and has reached recently an
international popularity. The success of this great puzzle game probably comes
from the simplicity of its rules : place digits between 1-9 on a 9 × 9 grid such that
each digit appears once in each row, column and each 3x3 sub-grid. This problem
can obviously be considered as a Constraint Satisfaction Problem (CSP), usually
deﬁned by a set of variables associated to domains of possible values and by a
set of constraints.
Local search techniques [1] have been successfully applied to various combinatorial optimization problems (scheduling, timetabling, transportation ...). In the
CSP solving context, local search algorithms are used either as the main resolution technique or in cooperation with other resolution processes (e.g., constraint
propagation) [3, 6]. Unfortunately, the deﬁnitions and the behaviors of these algorithms are often strongly related to speciﬁc implementations and problems.
Usual constraint propagation techniques have already been used to solve Sudoku and in this paper, we are interested in using various local search techniques
to solve this problem. Since we want to test diﬀerent resolution heuristics, our
purpose is to use a generic framework based on basic functions in order to provide uniform framework which help to better understand existing local search
algorithms and to design new ones.
The author has been partially supported by the Chilean National Science Fund
through the project FONDECYT No 1060373.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 641–648, 2006.
c Springer-Verlag Berlin Heidelberg 2006

642

T. Lambert, E. Monfroy, and F. Saubion

In [7] we have extended the mathematical framework of K.R. Apt [2] to take
into account hybridizations of constraint propagation with local search algorithms. The purpose of this paper is to focus on the modeling of basic local
search processes and then to improve this previous work by providing a more
comprehensive deﬁnition to local search algorithms. To obtain a ﬁner deﬁnition
of local search, we propose a speciﬁc computation structure and deﬁne the basic
functions that will be used iteratively on this structure to create a local search
process. Processes are abstracted at the same level by some homogeneous functions called reduction functions. The result of local search is then computed as
a ﬁxed point of this set of functions.
The paper is organized as follows : in Section 2 we recall basic deﬁnitions
related to CSP and local search algorithms. In Section 3 we describe our framework by deﬁning its main components. In Section 4, we provide the operational
semantics as the computation of a ﬁxed point of functions over the ordered
structure, which corresponds to the instantiation of the generic iteration algorithm proposed by K.R. Apt. Popular local search algorithms and strategies are
then designed and applied to solve Sudoku in Section 5 before concluding in
Section 6.

2

Solving CSP with Local Search

A CSP is a tuple (X, D, C) where X = {x1 , · · · , xn } is a set of variables taking
their values in their respective domains D = {D1 , · · · , Dn }. A constraint c ∈ C
is a relation c ⊆ D1 × · · · × Dn . In order to simplify notations, D will also denote
the Cartesian product of Di and C the union of its constraints. A tuple d ∈ D
is a solution of a CSP (X, D, C) if and only if ∀c ∈ C, d ∈ c. In this paper, we
always consider ﬁnite domains.
Given an optimization problem (which can be minimizing the number of violated constraints and thus trying to ﬁnd a solution to the CSP), local search
techniques [1] aim at exploring the search space, moving from a sample to one
of its neighbors. These moves are guided by a ﬁtness function that evaluates the
beneﬁt of such a move in order to reach a local optimum.
For the resolution of a CSP (X, D, C), the search space can be often deﬁned
as the set of possible tuples of D = D1 × · · · × Dn and the neighborhood is a
mapping N : D → 2D . This neighborhood function deﬁnes indeed the possible
moves from a sample of D to one of its neighbors and therefore fully deﬁnes
the exploration landscape. The ﬁtness (or evaluation) function eval is related
to the notion of solution and can be deﬁned as the number of constraints c
that are not satisﬁed by the current sample. The problem to solve is then a
minimization problem. Given a sample d ∈ D, two basic cases can be identiﬁed
in order to continue the exploration of D: intensiﬁcation (choose d ∈ N (d) such
that eval(d ) < eval(d)) and diversiﬁcation(choose any other neighbor d ). Any
local search algorithm is based on the management of these basic heuristics by
introducing speciﬁc control features. Here, we abstract moves and neighborhood
by functions computing over a given ordered structure.

A Generic Framework for Local Search: Application to the Sudoku Problem

3

643

A Computational Framework

In this section, we deﬁne the computation structure we will use to represent local
search states, together with the functions that will be required to model local
search as a ﬁxed point computation.
3.1

The Computation Structure

As we have seen, local search acts usually on a structure which corresponds
to points of the search space. Here, we propose a more general and abstract
deﬁnition based on the notion of sample, already suggested.
Deﬁnition 1 (Sample). Given a CSP (X, D, C), a sample function is a function ε : D → 2D . By extension, ε(D) denotes the set {ε(d)| d ∈ D}.
Generally, ε(d) is restricted to d and ε(D) = D, but it can also be a scatter of
tuples around d, or a box of tuples covering d. Indeed, the search space D is
abstracted by ε(D) to be used by the local search. Note that in any case, ε(D)
is ﬁnite since we consider D to be ﬁnite.
The general process of local search can be abstracted by two stages: generate
the neighborhood of the current sample and move from the current sample to
one of the previously computed neighbor.We deﬁne then a local search path as
a tuple of samples which represents the path already constructed by the local
search process.
Deﬁnition 2 (Local Search Path). A local search path p is a ﬁnite sequence
(s1 , · · · , sn ) such that ∀1 ≤ i ≤ n, si ∈ ε(D).
We denote by Pε(D) the set of all possible local search paths on ε(D). Given a
tuple p = (s1 , · · · , sn ) ∈ ε(D)n , and an element s ∈ ε(D), we denote p = p ⊕ s
the tuple (s1 , · · · , sn , s). To simplify notation, we denote s ∈ p the fact that a
sample s is a component of a path p.
We now deﬁne orderings on this structure. From a practical point of view, a
local search process aims at building a ﬁnite path whose length is either determined by the fact that a solution has been reached or that a maximum number
of iterations have been performed. Therefore, our orderings take into account
these two main aspects of local search.
Deﬁnition 3 (Ordering on paths). Given p =(s1 , · · · , sn ) and p =(s1 , · · · , sm )
two paths of Pε(D) , p p iﬀ sm ∈ Solε(D) or sn ∈ Solε(D) and m ≥ n.
In order to handle simultaneously paths and neighborhoods, we ﬁrst deﬁne the
notion of local search conﬁguration.
Deﬁnition 4 (Local Search Conﬁguration). A local search conﬁguration
Cε(D) is a pair (p, V ) where p = (s1 , · · · , sn ) is a local search path and V ⊆ 2ε(D) .
C is the set of all conﬁgurations. The ordering on path is obviously extended to
conﬁgurations taking into account set inclusion for the neighborhood.

644

3.2

T. Lambert, E. Monfroy, and F. Saubion

Reduction Function Deﬁnitions

Our deﬁnition of reduction functions is based on K.R. Apt´s framework [2].
Deﬁnition 5 (Reduction function on a structure). Given a partial ordering (D, ), a reduction function f is a function from D to D which satisﬁes the
following properties:
– ∀x ∈ D, x f (x) (inﬂationary)
– ∀x, y ∈ D, x y ⇒ f (x) f (y) (monotonic)
As previously described, the basic components to build a single local search path
are move and neighborhood computation.
Deﬁnition 6 (Move Function). A move function is a function μ : C → C
such that μ(p, V ) = (p , ∅) where p = p ⊕ s with s ∈ V if p = p ⊕ s and
s ∈ Solε(D) and V = ∅,p = p otherwise.
Deﬁnition 7 (Neighborhood Function). A neighborhood function is a function ν : C → C with ν(p, V ) = (p, V ∪ V ) such that V ⊆ ε(D) and V ∩ V = ∅.
Move and neighborhood functions are reduction functions.
3.3

Restricting Functions to Match a Practical Framework

As mentioned before, we must remark that stop conditions are always added
in local search algorithms in order to insure termination. These conditions are
basically based on a maximum number of allowed search steps or on a notion of
solution (if this notion is available). In the context of CSP solving, this notion
of solution has been clearly deﬁned and is taken into account in the deﬁnition
of our computation structure. Here the maximum number of operations will
be deﬁned by a maximum number σ of steps in each path (maximal length
of a path). Given a move or neighborhood function f : C → C, we deﬁne its
restriction f σ : C → C as: f σ (p, V ) = f (p, V ) if |p| ≤ σ and f σ (p, V ) = (p, V )
otherwise.
We must insist on the fact that, after these practical restrictions, we only
consider P as the set of all possible local search paths of size σ. Therefore, this
set is ﬁnite and C is also ﬁnite. Note that only the restriction concerning σ is
required to insure ﬁniteness of the structures which is needed to ﬁt the generic
iteration framework (section 4).

4

Local Search as a Fixed Point of Reduction Functions

In our framework, local search will be described as a ﬁxed point computation on
the previously ordered structure.

A Generic Framework for Local Search: Application to the Sudoku Problem

4.1

645

Chaotic Iterations

In [2], K.R. Apt proposed the chaotic iteration framework, a general theoretical
framework for computing limits of iterations of a ﬁnite set of functions over a
partially ordered set. In this paper, we do not recall all the theoretical results
of K.R. Apt, but we just give the GI algorithm for computing ﬁxed point of
functions. Consider a ﬁnite set F of functions, and d an element of a partially
ordered set D.
GI: Generic Iteration Algorithm
d :=⊥;
G := F ;
While G = ∅ do
choose g ∈ G;
G := G − {g};
G := G ∪ update(G, g, d);
d := g(d);
Endwhile
where ⊥ is the least element of the partial ordering (D, ), G is the current set
of functions still to be applied (G ⊆ F ), and for all G, g, d the set of functions
update(G, g, d) from F is such that:
P1 {f ∈ F − G | f (d) = d ∧ f (g(d)) = g(d)} ⊆ update(G, g, d).
P2 g(d) = d implies that update(G, g, d) = ∅.
P3 g(g(d)) = g(d) implies that g ∈ update(G, g, d)
Suppose that all functions in F are reduction functions as deﬁned before
and that (D, ) is ﬁnite (note that ﬁniteness is important as is has already
been mentioned for our structure) then every execution of the GI algorithm
terminates and computes in d the least common ﬁxed point of the functions
from F (see [2]).
We now use the GI algorithm to compute the ﬁxed point of our functions.
The algorithm is thus feed with:
– a set of move and neighborhood functions, that compose the set F ,
– ⊥ = ∅ ∈ Pε(D) to instantiate initial d,
– the ordering that we use is the ordering on Pε(D) .
In our context, the algorithm terminates and computes the least common ﬁxed
point of the functions from F , i.e., the result of the whole local search. Inspired
by [2], the proof partially relies on an invariant ∀f ∈ F − G, f (d) = d of the
“while” loop in the algorithm. This invariant is preserved by our characterization
of the update function. Moreover, since we keep a ﬁnite partial ordering and a set
of monotonic and inﬂationary functions, the results of K.R. Apt can be extended
here.

646

5

T. Lambert, E. Monfroy, and F. Saubion

Solving the Sudoku

As mentioned in the introduction, the Sudoku problem consists in ﬁlling a 9 × 9
grid so that every row, every column, and every 3 × 3 box contains the digits
from 1 to 9. Although Sudoku, when generalized to n2 x n2 grids to be ﬁlled
in by numbers from 1 to n2 is NP-complete, the popular 9 × 9 grid with 3 × 3
regions is not diﬃcult to solve with a simple computer program. Therefore, in
order to increase the diﬃculty, we consider 16 × 16 grids (published under the
name ”super Sudoku”), 25 × 25 and 36 × 36 grids. On this problem, we will show
that our generic framework allows us to easily deﬁne local search algorithms and
to combine and compare them.
5.1

CSP Model

Consider a n2 x n2 problem, an instinctive formalization considers a set of n4
variables whose correspond, to all the cells to ﬁll in. Using this, the set of related
constraints is deﬁned by AllDiﬀ global contraints [8] representing : all digits
appears only once in each row, once in each column and once in each n × n
square the grid has been subdivided.
This model formalizes Sudoku problems in such a way that the CSP to solve
has, for instance, 1296 variables and 108 constraints for the 36 × 36 grid. Usual
approaches consider grids with a subset of cells already ﬁlled in and complete
it (i.e., the real game for players), or aim at generating grids such that only
one solution can be reach. In this paper we consider empty grids and our goal
is to generate full ones. Even if Constraint Programming is useful for small
problems, complete techniques are intractable for bigger instances. Indeed, grids
with already ﬁlled positions (i.e., instantiated variables) are easier and we want to
attack larger and more diﬃcult problem since we consider local search strategies
because of their ability in solving large scale problems.
We consider only grids such that all diﬀerent digits appear once in each n × n
sub-square. This corresponds to enforce some constraints of the problem directly
in the encoding structure and it implies a restriction of the neighborhood to all
possible swaps between cells of a same square. The eval function is related to
the notion of solution and is deﬁned for each constraint alldiﬀ c as a cost of
violation (number of assignments to correct to satisfy the constraint). It is equal
to 0 if the constraint is satisﬁed.
Concerning LS methods, on one hand, Tabu search (TS) [4] has been successfully applied to solve CSP [5]. Basically, this algorithm forbids moving to a
sample that was visited less than l steps before. To this end, the list of the last
l visited samples is memorized. On the other hand, we consider a basic descent
technique with random walks RW where random moves are performed according
to a certain probability p. According to our model, we only have now to design
functions of the generic algorithm of Section 4.1 to model strategies. Neighborhood functions are functions C → C such that (p, V ) → (p, V ∪V ) with diﬀerent
conditions:

A Generic Framework for Local Search: Application to the Sudoku Problem

647

F ullN eighbor : V = {s ∈ D|s ∈ V }
T abuN eighbor : V = {s ∈ D| ∃k, n − l ≤ k ≤ n, sk = s}
DescentN eighbor : p = (s1 , . . . , sn ) and V = s ⊂ D s.t. ∃s ∈ V s.t eval(s ) <
eval(sn )
Move functions are functions C → C such that (p, V ) → (p , ∅) with diﬀerent
conditions:
BestM ove : p = p ⊕ s and eval(s ) = mins ∈V eval(s ).
ImproveM ove : p = p ⊕ sn and p = p ⊕ s s.t. eval(s ) < eval(sn ).
RandomM ove : p = p ⊕ s and s ∈ V.
We can precise here the input set of function F for algorithm GI.
T abusearch : {T abuN eighbor; BestN eighBor}
Randomwalk : {F ullN eighbor; BestN eighBor; RandomN eighbor}
T abuSearch + Descent : {T abuN eighbor; DescentN eighbor
; ImproveN eighBor; BestN eighBor}
Randomwalk + Descent : {F ullN eighbor; BestN eighBor
; RandomN eighbor; DescentN eighbor
; ImproveN eighBor}
Remark that the diﬀerent algorithms correspond here to diﬀerent sets of input
functions and diﬀerent behaviours of the choose function in the GI algorithm.
This choose function select alternatively neighborhood function and move functions. For the Random Walk algorithm, given a probability parameter p, we have
to introduce a quota of p BestM ove functions and 1 − p RandomM ove used
in GI. Concerning Tabu Search, we use here a T abuN eighbor with l = 10 and
BestM ove functions to built our Tabu Search algorithm. At last, we combine a
descent strategy by adding DescentN eighbor and ImproveM ove to the previous sets in order to design algorithms in which a Descent is ﬁrst applied in order
to reach more quickly to a good conﬁguration.
5.2

Experimentation Results

In Table 1. we compare results of the tabu search and random walks associated with descent on diﬀerent instances of Sudoku problem. Note that we have
evaluated the diﬃculty of the problem thanks to a classic complete method with
propagation and split, we obtained a more than one day cpu time cost for a 36×36
grid. At the opposite, by a simple formalization of the problem and thanks to a
function application model, we are able to reach to a solution with classical local
search algorithms and this starting from an empty grid. For each method and
for each instance, 2000 runs have been performed except for 36 × 36 problem,
500 runs. Results we obtain by adding descent in a Tabu Search or in a Random
Walk method, allows us to reduce the computation time to reach a solution. We
may remark that the hybrid strategies combining several move and neighborhood
functions provide better results. Our framework allows us to tune easily the balance between the diﬀerent basic functions that characterize basic solving strategies and thus to design various algorithms in a single generic algorithm, which is
not so clear if the methods are considered from a pure algorithmic point of view.

648

T. Lambert, E. Monfroy, and F. Saubion
Table 1. Results of Sudoku problem by diﬀerent search approaches
TabuSearch
16x16 25x25 36x36
3,14 115,08 3289,8
1,28 52,3 1347,4
405 3240
22333
Descent + TabuSearch
n2 x n2
16x16 25x25 36x36
cpu time Avg 2,34 111,81 2948
deviations 1,42 55,04
1476
mvts Avg
534 3666
20878
n2 x n2
cpu time Avg
deviations
mvts Avg

6

RandomWalk
16x16 25x25 36x36
3,92 105,22
2495
1,47 49,3
1099
443 2318
13975
Descent +RandomWalk
16x16 25x25 36x36
2,41 82,94
2455
1,11 36,99
1092
544 2581
14908

Conclusion

In this paper, we have proposed a framework for modeling CSP resolution with
local search techniques. This framework provides a computational model as the
computation of a ﬁxed point of functions over a partial ordering, inspired the
initial works of K.R. Apt [2]. The generic algorithm has been used to solve the
Sudoku problem and allow us to compare diﬀerent resolution approach in a very
uniform framework where strategies can be easily designed.
This framework could be extended in order to include complete resolution
mechanisms (constraint propagation, domain splitting) and even other metaheuristics such as evolutionary algorithms. It could also be used for experimental
studies as it provides a uniform description framework for various methods in
an hybridization context.

References
1. E. Aarts and J.K. Lenstra, editors. Local Search in Combinatorial Optimization.
John Wiley and Sons, 1997.
2. K. Apt. From chaotic iteration to constraint propagation. In ICALP ’97, number
1256 in LNCS, pages 36–55. Springer, 1997. invited lecture.
3. F. Focacci, F. Laburthe, and A. Lodi. Local search and constraint programming.
In Handbook of Metaheuristics, Kluwer, 2002.
4. F. Glover and M. Laguna. Tabu Search. Kluwer Academic Publishers, 1997.
5. J.K. Hao and R. Dorne. Empirical studies of heuristics local search for constraint
solving. In CP’96 LNCS 1118, pages 184–208, 1996.
6. N. Jussien and O. Lhomme. Local search with constraint propagation and conﬂictbased heuristics. Artiﬁcial Intelligence, 139(1):21–45, 2002.
7. E. Monfroy, F. Saubion, and T. Lambert. On hybridization of local search and
constraint propagation. In ICLP 2004, number 3132 in LNCS, pages 180–194, 2004.
8. J.C. R´egin. A ﬁltering algorithm for constraint of diﬀerence in csps. In National
Conference of Artiﬁcial Intelligence, pages 362–367, 1994.

