Procedia Computer Science
Volume 80, 2016, Pages 834–844
ICCS 2016. The International Conference on Computational
Science

Scalability of direct solver for non-stationary Cahn-Hilliard
simulations with linearized time integration scheme
M. Wo´zniak1 , M. Smolka1 , A. Cortes2 , M. Paszy´
nski1 , and R. Schaefer1
1

2

AGH University of Science and Technology, Krakow, Poland
King Abdullah University of Science and Technology, Thuwal, Saudi Arabia

Abstract
We study the features of a new mixed integration scheme dedicated to solving the non-stationary
variational problems. The scheme is composed of the FEM approximation with respect to the
space variable coupled with a 3-leveled time integration scheme with a linearized right-hand
side operator. It was applied in solving the Cahn-Hilliard parabolic equation with a nonlinear,
fourth-order elliptic part. The second order of the approximation along the time variable was
proven. Moreover, the good scalability of the software based on this scheme was conﬁrmed during simulations. We verify the proposed time integration scheme by monitoring the GinzburgLandau free energy. The numerical simulations are performed by using a parallel multi-frontal
direct solver executed over STAMPEDE Linux cluster. Its scalability was compared to the
results of the three direct solvers, including MUMPS, SuperLU and PaSTiX.
Keywords: isogeometric analysis, Cahn-Hilliard equations, non-stationary problems, multi-frontal parallel direct solver, parallel eﬃciency and speedup

1

Introduction

In this paper we analyze the numerical properties of linearized time integration scheme concerning non-stationary Cahn-Hilliard equations proposed in [15]. We show that scheme is of the
second order. We apply the scheme for numerical solution of Cahn-Hilliard equations [10, 11],
but this time we split the fourth order Cahn-Hilliard equations into a system of two second
order PDEs, following [12].
In the space domain the solution of the split Cahn-Hilliard equations is approximated by
means of the isogeometric ﬁnite element method, utilizing B-spline basis functions [9]. The
linearized version of the Crank-Nicolson integration scheme, that is unconditionally stable, is
utilized for the time integration.
Our time integration scheme has been implemented within PETIGA toolkit [7], a part of
the PETSc library [4, 5, 6]. The linearized system of equations is solved in every time step
by using a parallel multi-frontal direct solver, executed over a STAMPEDE Linux cluster. For
the numerical solution we test three multi-frontal direct solvers, including MUMPS [1, 2, 3],
834

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.373

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

SuperLU [17, 14] and PaSTiX [13]. We test the scalability of these solvers on the STAMPEDE
linux cluster. We extend the results of sequential tests [8] performed for the simple Laplace
problem. For eﬃcient parallelization of the integration process, we refer to [16].
The structure of the paper is the following. We start with introduction of the strong formulation in Secton 2.1. It is followed by the two weak formulations in Sections 2.2 and 2.3,
the ﬁrst one L2 in time, the second one C 1 in time. Later, we introduce the linearized time
integration scheme in Section 2.4. We proof its second order in Section 3. We conclude the
paper with numerical results discussed in Section 4. Finally, we perform numerical simulations
with parallel multi-frontal direct solver executed over STAMPEDE Linux cluster. We test the
scalability of the three direct solvers, including MUMPS, SuperLU and PaSTiX in Section 4.1.

2
2.1

Weak formulations of the Cahn-Hilliard equations
Strong formulation

This section presents the derivation of the weak form of Cahn-Hilliard equations based on [10].
We consider the following Cauchy problem: Find u ∈ C 1 (0, T ; C 4 (Ω)) such that
ut = ∇ · (B(u)∇ (−γΔu + Ψ (u))) on [0, T ] × Ω and u(0, x) = u0 (x) on Ω,

(1)

where Ω is an open subset of Rn , n = 2, 3 with smooth boundary and γ > 0 is a constant. u is
usually interpreted as the diﬀerence of the two ﬂuid phase concentrations, hence u ∈ [−1, 1]. In
such a case B(u) ≥ 0 is the diﬀusional mobility, whereas Ψ(u) is the homogeneous free energy.
A crucial notion in the theory of Cahn-Hilliard equations is the Ginzburg-Landau free energy
E(u) =

Ω

γ
|∇u|2 + Ψ(u) dx.
2

(2)

As for the boundary conditions for (1), we choose the following ones:
n · (B(u)∇ (−γΔu + Ψ (u))) = 0,

∂u
=0
∂n

on [0, T ] × ∂Ω,

(3)

where n is the outer normal to ∂Ω.
As in paper [10], we select the following functions B and Ψ:
B(u) = 1 − u2 ,
θ
Ψ(u) = ((1 + u) log(1 + u) + (1 − u) log(1 − u)) + 1 − u2 ,
2

(4)

where θ = 1.5. Similarly to [12] we split (1) into two second-order equations
ut = ∇ · (B(u)∇v)
v = Ψ (u) − γΔu.

(5)

In this case the boundary conditions have the following form
B(u)

∂v
= 0,
∂n

∂u
= 0.
∂n

(6)
835

Scalability of direct solver for Cahn-Hilliard simulations

2.2

M. Wo´zniak, et. al.

Weak formulation L2 in time

The following weak formulation is presented in [10] together with the respective existence
theorem. We seek u ∈ L2 (0, T ; H 2 (Ω)) ∩ L∞ (0, T ; H 1 (Ω)) ∩ C([0, T ]; L2 (Ω)) such that
ut ∈ L2 (0, T ; (H 1 (Ω)) ) and B(u)∇ (−γΔu + Ψ (u)) ∈ L2 (ΩT ; Rn ), that satisﬁes (1) in the
following sense
T
0

ut (t), ζ(t) dt = −

ΩT

[γΔu∇ · (B(u)∇ζ) + (BΨ )(u)∇u · ∇ζ] dxdt,

(7)

for arbitrary ζ ∈ L2 (0, T ; H 1 (Ω)) such that ∇ζ ∈ L2 (0, T ; H 1 (Ω; Rn ))∩L∞ (ΩT ; Rn ) and ∇ζ·n =
0.

2.3

Weak formulation C 1 in time

Following [11, 10] we introduce the space diﬀerential operator A : H 2 (Ω) → (H 2 (Ω)) , such
that
A(u), w =
[γΔu∇ · (B(u)∇w) + (BΨ )(u)∇u · ∇w] dx.
(8)
Ω

For technical purposes, we introduce the simple dual operator τ : H 1 (Ω) → (H 1 (Ω)) such that
τ (u), w =
Ω

u · w dx, ∀w ∈ H 1 (Ω).

(9)

The time-derivative operator ·t : C 1 (0, T ; H 1 (Ω)) → C(0, T ; (H 1 (Ω)) ) is deﬁned in the following
way
∂u
ut (t), w = τ
(t) , w , ∀w ∈ H 1 (Ω), ∀t ∈ [0, T ].
(10)
∂t
Then we look for u ∈ C 1 (0, T ; H 2 (Ω)) such that
ut (t), w + A(u(t)), w = 0 ∀w ∈ H 1 (Ω), ∀t ∈ [0, T ] and u(0, x) = u0 (x) a.e. on Ω.

(11)

For the numerical convenience and similarly to [12, 10] we can split equation (11) into the
following system:
ut , w
= − Ω B(u)∇u · ∇w dx
(12)
v z dx = Ω Ψ (u) z dx + γ Ω ∇u · ∇z dx,
Ω
with arbitrary w, z ∈ H 1 (Ω).

2.4

Finite diﬀerence schemes for semi-continuous variational equation

We introduce the network {t0 = 0, t1 , . . . , tK = T } ⊂ [0, T ]. Let U = H 2 (Ω). Three ﬁnite
diﬀerence schemes will be considered. The ﬁrst is the forward Euler scheme:
ui+1 − ui
ti+1 − ti

τ

, w + < A(ui ), w >= 0, ∀w ∈ U, i = 1, . . . , K,

(13)

where u0 ∈ U is the initial condition, and ui = u(ti ). The second scheme is the Crank-Nicolson
method:
τ

836

ui+1 − ui
ti+1 − ti

,w +

1
< (A(ui+1 ) + A(ui )), w >= 0,
2
∀w ∈ U, i = 1, . . . , K.

(14)

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

Finally, if A ∈ C 1 (U ) we can use a linearized three-level scheme
τ

ui+2 − ui
ti+2 − ti

,w +

1
DA|ui+1 (ui+2 + ui − 2ui+1 ) + A(ui+1 ) , w = 0,
2
∀w ∈ U, i = 1, . . . , K.

3

(15)

Order of the linearized 3-leveled schema

Consider the following autonomous ODE
y = f (y(t)).

(16)

Let us assume that we know the solution of (16) on interval [t0 − h, t0 ]. Take r > t0 . If f is
C 2 , then we can write the Taylor’s formula for f in the following form
f (w + Δw) = f (w) + f (w)Δw + R(w, Δw),
1

R(w, Δw) =
0

(1 − s)f (w + sΔw)ds (Δw)2 .

(17)
(18)

Applying (17)-(18) and assuming R is small enough we can write down a linearized version
of (16) for an initial condition y(t0 ) and for r > t0
y (r + ξ) ≈ f (y(r)) + f (y(r)) (y(r + ξ) − y(r)) .

(19)

For (19) we write down the 2-leveled Crank-Nicolson scheme subsequently linearizing the righthand side f in central points of subintervals
y(t + 2h) − y(t)
≈
2h
1
f (y(t + h)) + f (y(t + h)) y(t) − y(t + h) + f (y(t + h)) + f (y(t + h)) y(t + 2h) − y(t + h)
2
1
2f (y(t + h)) + f (y(t + h)) y(t) + y(t + 2h) − 2y(t + h) . (20)
=
2
Hence
y i+2 = y i + h 2f (y i+1 ) + f (y i+1 ) y i + y i+2 − 2y i+1 .
(21)
Theorem 1. If f is C 4 then scheme (21) has order 2.
Proof. We assume that y is computed exactly at ti and ti+1 . Denote by ri (h) the approximation
error in time step ti+2 = ti + 2h. Then
ri (h) = y(ti + 2h) − y i+2
= y(ti + 2h) − y i − h 2f (y i+1 ) + f (y i+1 ) y i + y i+2 − 2y i+1
= y(ti + 2h) − y(ti ) − h 2f (y(ti+1 )) + f (y(ti+1 )) y(ti ) + y(ti+2 ) − 2y(ti+1 )
= y(ti + 2h) − y(ti )+
− h 2f (y(ti + h)) + f (y(ti + h)) y(ti ) − y(ti + h) + f (y(ti + h)) y(ti + 2h) − y(ti + h)

.
837

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

From (17) and (16) it follows that
ri (h) = y(ti + 2h) − y(ti ) − hy (ti ) + hR1 (h) − hy (ii + 2h) + hR2 (h),
where
R1 (h) = R y(ti + h), y(ti ) − y(ti + h) ,

(22)

R2 (h) = R y(ti + h), y(ti + 2h) − y(ti + h) .

(23)

and
To conclude the proof we need to show that ri vanishes at 0 along with its ﬁrst and second
derivative. But it is easy to see that
ri (0) = 0.
Next
ri (h) = 2y (ti +2h)−y (ti )−y (ti +2h)−2hy (ti +2h)+h(R1 (h)+R2 (h))+R1 (h)+R2 (h), (24)
and
ri (h) = 4y (ti + 2h) − 2y (ti + 2h) − 2y (ti + 2h) − 4hy (ti + 2h)+
+ h(R1 (h) + R2 (h)) + 2(R1 (h) + R2 (h)).
But because R has the form

(25)

R(h) = a(h)h2 ,

from (22) and (23) it follows that
Rj (0) = Rj (0) = Rj (0) = 0.
Therefore, from (24), (25) we have
rh (0) = rh (0) = 0.

It is easy to see that Theorem 1 can be used to study the order of scheme (15) applied to
the Cahn-Hilliard equation in the form (11). This equation can be rewritten in form (16) by
replacing y(t), y (t) and f (y(t)) with u(t), ut (t) and −A(u(t)), respectively. The state space
of the new equation is now (H 2 (Ω)) . Hence, it follows that scheme (15) applied to equation
(11) has order 2 if B has class C 4 and Ψ has class C 5 , which obviously holds in the sequel. Of
course, if a spatial approximation of dimension n is applied, equation (11) is reduced to the
system of n ordinary diﬀerential equations of ﬁrst order with respect to the time variable t, so
y, y : [0, T ] → Rn and f : Rn → Rn .

4

Numerical results

We performed the numerical simulations of our modiﬁed time integration scheme with PETIGA
toolkit installed over STAMPEDE [18] Linux cluster from Texas Advanced Computing Center.
We have executed our tests up to 256 nodes, 1 core per node, 32 GB of RAM per node.
We solved the Cahn-Hilliard equation over two dimensional domain with the parameters
setup identical to those in [15]:
838

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

1
u
Ω = (0, 1)2 , B(u) = 1 − u2 , Ψ (u) = 2θ
log 1−u
+ 1 − 2u, where θ = 1.5 is a dimensionless
number which represents the ratio between the critical temperature Ξc (the temperature at
which the two phases attain the same composition) and the absolute temperature Ξ, γ = N12
where N is the mesh size in one direction with periodic boundary conditions and u0 (x) =
2¯
c − 1 + r, where c¯ = 0.63 is the average concentration, and r is the scalar random perturbation
with the uniform distribution U(Ω).
In our simulations we utilize three diﬀerent multi-frontal direct solvers for the solution of
the linear system at every time step. We performed our tests over 2D grids with 256 times
256 elements. We used diﬀerent polynomial orders of approximation, from p = 1, 2, ..., 8, with
C 0 global continuity, possible to apply since we have split the Cahn-Hilliard equations into the
system of second order PDE.
The snapshots from the Cahn-Hilliard simulations with our time integration scheme are
presented in Figures 1-2.
The simulation stability has been controlled by monitoring the Ginzburg-Landau free energy,
that has been constantly decreasing during the simulation.

4.1

Comparison of the scalability of the parallel multi-frontal direct
solvers

We have performed the comparison of the scalability of the three multi-frontal direct solvers
executed over a distributed memory Linux cluster. We have utilized one processor per node,
up to 256 nodes on the STAMPEDE Linux cluster. We have tested the three solvers, MUMPS
[1, 2, 3], SuperLU [17, 14] and PaSTiX [13], available through PETSC interface [4, 5, 6].
We have executed the tests for the number of processors increasing from 1 till 256, and for
the polynomial B-spline orders of approximations varying from p = 1, ..., 8 with global C p−1
solution. The results of the comparison are presented in Figures 3-5.
It is the open problem what we really gain by using higher order B-splines, since we utilize
the split systems. It may be a matter of our future experiments. The scalability results will be
identical that one performed for the Laplace equations, except here we have a system of two
equations, so there are two unknowns per mesh node.

5

Conclusions

We have studied a new mixed integration scheme dedicated to solving the non-stationary variational problems, composed of the FEM approximation with respect to the space variable coupled
with a The second order of the approximation along the time variable has been proven for the
case of Cahn-Hilliard equations. We have tested the numerical scalability of the multi-frontal
direct solvers applied at each time step of the time integration scheme under consideration. We
have performed parallel simulations with three direct solvers, including MUMPS, SuperLU and
PaSTiX, available through PETSc toolkit behind the PETIGA framework. From the above experiments we may conclude that increasing the degree of approximation polynomials p improves
the parallel scalability of the multi-frontal direct solver. For the C 0 continuity of the solution,
the computational cost of the multi-frontal solver is of the order of O(N 3 /2p3 + N p6 ). The second term is related to the static condensation that can be fully parallelized. The computations
related to the ﬁrst term are harder to parallelize. With increasing p, this static condensation
cost is growing, and the parallelization is becoming more eﬃcient.
839

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

(a) Snapshot 1

(b) Snapshot 2

(c) Snapshot 3

(d) Snapshot 4

(e) Snapshot 5

(f) Snapshot 6

Figure 1: Snapshots from the split Cahn-Hilliard simulation solution by using the linearized
scheme.

840

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

(a) Snapshot 1

(b) Snapshot 2

(c) Snapshot 3

(d) Snapshot 4

(e) Snapshot 5

(f) Snapshot 6

Figure 2: Further snapshots from the split Cahn-Hilliard simulation solution by using the
linearized scheme.

841

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

Figure 3: MUMPS solver. Comparison of scalability for C p−1 for diﬀerent number of processors
and diﬀerent polynomial order of approximation, for problem size 256 ∗ 256 elements

Figure 4: SuperLU solver. Comparison of scalability for C p−1 for diﬀerent number of processors
and diﬀerent polynomial order of approximation, for problem size 256 ∗ 256 elements
842

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

Figure 5: PaSTiX solver. Comparison of scalability for C p−1 for diﬀerent number of processors
and diﬀerent polynomial order of approximation, for problem size 256 ∗ 256 elements

Acknowledgments
The work of MW, MS, MP, RS presented in this paper concerning the development of CahnHilliard scheme has been supported by National Science Centre, Poland grant no. DEC-2012/
07/ B/ST6/ 01229. The visit of AC and his work concerning the PETIGA solver interface has
been supported by National Science Centre, Poland grant no. DEC-2012/06/M/ST1/00363.

Bibliography
References
[1] P. R. Amestoy , I. S. Duﬀ, M ultifrontal parallel distributed symmetric and unsymmetric solvers,
Computer Methods in Applied Mechanics and Engineering, 184 (2000) 501-520.
[2] P. R. Amestoy, I. S. Duﬀ, J. Koster, J.Y. L’Excellent, A fully asynchronous multifrontal solver
using distributed dynamic scheduling, SIAM Journal of Matrix Analysis and Applications, 1(23)
(2001) 15-41.
[3] P. R. Amestoy, A. Guermouche, J.-Y. L’Excellent, S. Pralet, H ybrid scheduling for the parallel
solution of linear systems, Computer Methods in Applied Mechanics and Engineering, 2(32) (2001)
136-156.

843

Scalability of direct solver for Cahn-Hilliard simulations

M. Wo´zniak, et. al.

[4] S. Balay, S. Abhyankar, M. F. Adams, J. Brown, P. Brune, K. Buschelman, V. Eijkhout, W.
D. Gropp, D. Kaushik, M. G. Knepley, L. Curfman McInnes, K. Rupp, B. F. Smith, H. Zhang,
PETS c Web Page, http://www.mcs.anl.gov/petsc (2014)
[5] S. Balay, S. Abhyankar, M. F. Adams, J. Brown, P. Brune, K. Buschelman, V. Eijkhout, W.
D. Gropp, D. Kaushik, M. G. Knepley, L. Curfman McInnes, K. Rupp, B. F. Smith, H. Zhang,
PETSc User Manual, Argonne National Laboratory ANL-95/11 - Revision 3.4 (2013)
[6] S. Balay, W. D. Gropp, L. Curfman McInnes, B. F. Smith, Eﬃcient Management of Parallelism
in Object Oriented Numerical Software Libraries, Modern Software Tools in Scientiﬁc Computing,
Editors E. Arge, A. M. Bruaset and H. P. Langtangen (1997) Birkh¨
a user Press.
[7] N. Collier, L. Dalcin, V. M. Calo., PetIGA: High-performance isogeometric analysis, arxiv,
(1305.4452), (2013) http://arxiv.org/abs/1305.4452
[8] N. Collier, D. Pardo, L. Dalcin, M. Paszynski, V. Calo, The cost of continuity: A study of the
performance of isogeometric ﬁnite elements using direct solvers, Computer Methods in Applied
Mechanics and Engineering (213-216) (2012) 353-361.
[9] J. A. Cottrell, T. J. R. Hughes, Y. Bazilevs, Isogeometric Analysis: Toward Uniﬁcation of CAD
and FEA John Wiley and Sons, (2009)
[10] C. M. Elliott, H. Garcke, On the Cahn-Hilliard equation with degenerate mobility SIAM Journal
of Mathematical Analysis, 27 (1996) 404-423.
[11] H. Gomes, V. M. Calo, Y. Bazileves, T.J.R. Hughes, Isogeometric analysis of the Cahn-Hilliard
phase-ﬁeld model, Computer Methods in Applied Mechanics and Engineering, 197 (2008) 43334352.
[12] H. Gomes, T.J.R. Hughes, Provably unconditionally stable, second-order time-accurate, mixed variational methods for phase-ﬁeld models, Journal of Computational Physics, 230 (2011) 5310-5327.
[13] P. Hnon, P. Ramet, J. Roman, P aStiX: A High-Performance Parallel Direct Solver for Sparse
Symmetric Deﬁnite Systems, Parallel Computing, 28(2) (2002) 301-321.
[14] X.S. Li, J.W. Demmel, J.R. Gilbert, iL. Grigori, M. Shao, I. Yamazaki, S uperLU Users’ Guide,
Lawrence Berkeley National Laboratory, LBNL-44289 http://crd.lbl.gov/ xiaoye/SuperLU/ (1999).
[15] R. Schaefer, M. Smolka, L. Dalcin, M. Paszynski, A new time integration scheme for Cahn-Hilliard
equations, Procedia Computer Science, 51 (2015) 1003-1012.
[16] M. Wo´zniak, Fast GPU integration algorithm for isogeometric ﬁnite element method solvers
using task dependency graphs, Journal of Computational Science, (2015) in press. DOI:
10.1016/j.jocs.2015.02.007
[17] Xiaoye S. Li, An Overview of SuperLU: Algorithms, Implementation, and User Interface, TOMS
Transactions on Mathematical Software, 31(3) (2005) 302-325.
[18] https://portal.tacc.utexas.edu/user-guides/stampede

844

