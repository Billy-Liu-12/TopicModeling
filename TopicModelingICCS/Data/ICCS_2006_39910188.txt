Knowledge-Based Multiclass Support Vector Machines
Applied to Vertical Two-Phase Flow
Olutayo O. Oladunni1, Theodore B. Trafalis1, and Dimitrios V. Papavassiliou2
1

School of Industrial Engineering, The University of Oklahoma
202 West Boyd, CEC 124 Norman, OK 73019 USA
{tayo, ttrafalis}@ou.edu
2 School of Chemical, Biological, and Materials Engineering, The University of Oklahoma
100 East Boyd, SEC T-335 Norman, OK 73019 USA
dvpapava@ou.edu

Abstract. We present a knowledge-based linear multi-classification model for
vertical two-phase flow regimes in pipes with the transition equations of
McQuillan & Whalley [1] used as prior knowledge. Using published experimental data for gas-liquid vertical two-phase flows, and expert domain knowledge of the two-phase flow regime transitions, the goal of the model is to identify the transition region between different flow regimes. The prior knowledge
is in the form of polyhedral sets belonging to one or more classes. The resulting
formulation leads to a Tikhonov regularization problem that can be solved using
matrix or iterative methods.

1 Introduction
Multiphase flow in a pipe causes certain flow patterns to appear depending on pipe
size, flow rates, fluid properties, and pipe inclination angle (when appropriate). Considerable progress has been made in defining such flow patterns [1-5], however there
is no exact theory for their characterization. There is often disagreement about the
transition boundaries between flow patterns making the selection of appropriate flow
correlations for the description of the flow difficult. Therefore, it is important to develop a flow pattern model that minimizes the rate of misclassification errors (i.e.,
predicting the wrong flow regime for a given set of flow data) as well as extend the
applicability of any new multiphase flow correlation to different pipe sizes, flow rates
and fluid properties.
More recently, attempts have been made to identify multiphase flow regimes using
non-linear classifiers derived from machine learning algorithms [6-8]. Trafalis et al.
[9] employed a multi-classification support vector machine (MSVM) model, in which
the superficial velocities and pipe sizes were used to detect flow regime transitions for
two-phase flow in pipes. The model was data driven, and it outperformed the theoretical vertical flow correlation in terms of correct flow regime classification.
The primary objective of the present paper is to extend the model of [9] by exploring the effects of expert knowledge on the MSVM model. If one has prior information
regarding a class or label, representing such knowledge and incorporating it into a
classification problem can lead to a more robust solution. The vertical two-phase flow
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 188 – 195, 2006.
© Springer-Verlag Berlin Heidelberg 2006

Knowledge-Based Multiclass Support Vector Machines

189

regimes considered herein are bubble flow (class 1), intermittent flow (slug & churn
flow, class 2), and annular flow (class 3). These flow regimes occur for a given set of
parameters, (i.e., flow rates, fluid properties and pipe diameter). The theoretical correlations of McQuillan and Whalley [1], which were found to perform well for vertical
two phase flow in [9], are used here as prior knowledge.

2 Linear Multiclassification Tikhonov Regularization
Knowledge-Based Support Vector Machine: Pairwise
Knowledge Set Formulation
Recently, prior knowledge formulation, incorporation, and solution have been studied
in both the context of function approximations [10] and in the context of classifiers
n

[11]. Here, we consider a problem of classifying data sets in R that are represented
by a data matrix Ai ∈ R m × n , where i = 1,.., k ( k ≥ 2 classes). Let Ai be an mi × n matrix
i

whose rows are points in the ith class, and mi is the number of data in class i. Let A j be
an m j × n matrix whose rows are points in the jth class, and m j is the number of data in
class j, and y = ±1 for classes i and j, respectively. This problem can be modeled
through the following optimization problem:
ij

min

λ

w, γ ,ξ

2

2

k

∑

w

ij

+

i< j

1
2

mij

k

∑∑ (ξ
i < j t =1

ij
t

)

2

s.t. ξ = y ( A w − γ ij ) − 1, t = 1,...., mij
ij

ij

ij

t

t

t

ij

.

(2.1)

⎛ A ⎞ ij ⎛ y ⎞ ⎛ +1⎞
⎟, y = ⎜ j ⎟ = ⎜ ⎟
j
⎝A ⎠
⎝ y ⎠ ⎝ −1⎠
i

i

where mij = mi + m j , A = ⎜
ij

Above, λ is the tradeoff constant, and ξ ij are error slacks measuring the deviation of
points from their respective bounding planes. Classification weights (wij, γij) characterize the optimal separating planes
x w =γ ,
T

ij

ij

i< j.

(2.2)

The locations of the optimal separating planes relative to the origin are determined by
the value of γij. Problem (2.1) is minimized parametrically with the tradeoff constant λ , which accounts for the tradeoff between minimum norm and minimum misclassification error.
Now, suppose that in addition to the classification problem, there is prior information belonging to one or more categories. The knowledge sets in n dimensional space
are given in the form of a polyhedral set determined by the set of linear equalities and
linear inequalities. The given knowledge sets are (see Fig. 1)
{ x | B i x ≤ bi } or { x | B i x = b i } , belonging to class i, and

(2.3)

g i or g i are the number of prior knowledge (equality or inequality) constraints in class i.

190

O.O. Oladunni, T.B. Trafalis, and D.V. Papavassiliou

{ x | B j x ≤ b j } or { x | B j x = b j } , belonging to class j, and

(2.4)

d j or d j are the number of prior knowledge (equality or inequality) constraints in class j.

Fig. 1. A knowledge-based classification diagram

One can rewrite the constraints, and create an unconstrained optimization problem,
called Linear Multi-classification Tikhonov Regularization Knowledge-Based Support Vector Machine (LMTRKSVM) [12, 13, 14].
1
2
2
⎡λ
⎤
⎢ 2 w + 2 Aw + Eγ − e +
⎥
⎢
⎥
2
2
1⎡ T
T
⎢
⎥.
⎤
min f L T KSVM ( w, γ , ξ , u, v) =
B u + I u w + Bv v − I v w +
⎦
⎢2 ⎣ u
⎥
w ,γ , ξ , u , v
⎢
⎥
⎢ 1 ⎡ BbuT u + Eu γ + eu 2 + BbvT v − Ev γ + ev 2 ⎤ ⎥
⎦ ⎥⎦
⎣⎢ 2 ⎣
M R

(2.5)

Where u = [u ij T , ...., u ( k −1) k T , u ij T , ...., u ( k −1) k T ]T is the vector of all multipliers referring to
the ith class, and v = [v ij T , ...., v ( k −1) k T , v ij T , ...., v ( k −1) k T ]T is the vector of all multipliers
referring to the jth class. ξ is a residual error vector accounting for the training data
error, and vectors r , s, p, σ are residual error vectors accounting for the knowledge set
error (i.e., violation of the knowledge constraints). The following matrices are defined
for all i < j, i, j = 1,....k classes (note that matrices describe the formation of the prior
knowledge): Matrices Ai ∈ R m ×n , A j ∈ R m × n , i < j are matrices whose rows belong to
i

j

the ith and jth class respectively; e i , e j ∈ R

mi , m j ×1

are vectors of ones. Matrices

Knowledge-Based Multiclass Support Vector Machines

191

Bu and Bv are diagonal block matrices whose diagonals contain knowledge sets belonging to the ith (or jth) class. The ith (or jth) knowledge set is derived from the inequality and equality prior knowledge constraints. The diagonals of Bu , Bv are
Bij , Bij ∈ R
i

i

bij , bij ∈ R
i

i

gi ×n

g i ×1

( Bijj , Bijj ∈ R
( bij , bij ∈ R
j

j

g j ×n

g j ×1

). Matrices Bbu , Bbv are matrices consisting of vectors

) and each component of these vectors describes the bounds

of the knowledge set. Matrices I u , I v are block matrices consisting of identity matrices I uij , I uij ∈ R n× n ( I vij , I vij ∈ R n× n ). Matrices Eu , Ev are matrices consisting of entries
eu ij , euij ∈ R ( ev ij , evij ∈ R ), where eu ij , euij is equal to one. Vector eu ( ev ) is a vector of

ones, where each entry corresponds to a vector biji , biji ∈ R g ×1 ( bijj , bij j ∈ R
i

g j ×1

). Each ith

and jth entry into Bu , Bbu , I u , Eu , eu , and Bv , Bbv , I v , Ev , ev completes a pairwise
comparison. The formulation is applicable to k ≥ 2 [14].
Problem (2.5) is the unconstrained LMTRKSVM model which incorporates the
knowledge sets (2.3) and (2.4) into the LMTRSVM model (2.1). The tradeoff constant λ is also run through a range of values to achieve the best result. If its value
increases then the minimum norm is achieved, but at the expense of having a higher
training residual error and higher knowledge set residual error. If data is not available,
the second term of the LMTRKSVM model can be dropped. This result in classifiers
based strictly on knowledge sets, and it is useful for situations in which only expert
knowledge exists. The L2 norm of all terms is considered because of its strong convexity of the objective function. Problem (2.5) is a convex unconstrained optimization
problem that has a unique minimum point [14]. The decision function for classifying
a point is given by:
D ( x ) = sign[ x w − γ ] =
T

ij

ij

⎧ +1,
⎨
⎩ −1,

if point (x ) is in class A

i

if point (x ) is in class A

j

.

(2.6)

A new point x is classified according to the voting approach [15, 16]. For example, if
sign [ xT wij − γ ij ] indicates that x belongs to class i, then the vote for class i is increased by one (otherwise j is increased by one). Finally, x belongs to the class with
the largest vote. If two classes have identical votes, then select the one with the smallest index.

3 Vertical Two-Phase Flow Data and Prior Knowledge
Fifty percent of each data set described below were trained on the LMTRKSVM
model, and the other 50 % were used as test samples (for data source details see [9]).
2D classification (data): The 2D vertical flow data set uses two flow rates (superficial
gas and liquid velocity) for one inch diameter pipes, with fluid properties at atmospheric conditions, to delineate three different flow regimes. There are 209 instances
(points) and 2 attributes (features), 107 points were used as training samples and 102

192

O.O. Oladunni, T.B. Trafalis, and D.V. Papavassiliou

points were used as test samples. The distribution of instances with respect to their
class is as follows: 44 instances in class 1 (bubble flow), 102 instances in class 2 (intermittent flow), and 63 instances in class 3 (annular flow).
3D classification (data): The 3D vertical flow data set uses the pipe size in addition to
the superficial gas and liquid velocity to delineate three different flow regimes. There
are 424 instances, and 3 attributes, 206 data points used as training samples, 218
points used as test samples. The distribution of instances is 98 instances in class 1
(bubble flow), 217 instances in class 2 (intermittent flow), and 109 instances in class
3 (annular flow).
Prior Knowledge: In addition to the vertical flow data, prior knowledge is included to
develop knowledge based classification models. Since the flow regime data are scaled
by taking the natural logarithm of each instance, the prior knowledge also needs to be
scaled. Below are the transition equations [1, 9] and their equivalent logarithmic
transformations for 2D and 3D knowledge based classification:
-

Bubble – intermittent flow transition
⎡ gσ ( ρ L − ρG ) ⎤
⎥
ρ L2
⎣
⎦

1

4

vLS = 3.0vGS − 1.15 ⎢

.

(3.1)

⇒ −0.9883ln(vGS ) + ln(vLS ) = 1.0608, For both 2D & 3D classification

-

Bubble – dispersed bubble flow transition
vLS ≥

6.8

ρ L0.444

{ gσ ( ρ L − ρG )}

0.278

⎛D⎞
⎜ ⎟
⎝ μL ⎠

0.112

.

⎧ln(vLS ) ≥ 1.03345, 2D classification
⇒⎨
⎩ln(vLS ) ≥ 1.4466 + 0.112 ln( D), 3D classification

(3.2)

Above, D is the pipe diameter, g is the acceleration due to gravity, vGS , v LS are the
gas and liquid superficial velocities, respectively, ρG , ρ L are the gas and liquid densities, σ is the surface tension, and μG , μ L are the gas and liquid viscosities, respectively. The correlations were selected based on the uncertainty of the transition lines
as evidenced by the misclassification errors of the MSVM [9]. Also, as a result of the
uncertainty, the threshold values of the vertical and horizontal correlations were deviated by a small deviation factor, ±ε. This is in fact necessary because the correlation
equations identify points on transition boundaries that have no distinct flow regime.
So a small deviation of the thresholds facilitates the formation of bounds (deviated
thresholds) for each flow regime. For instance equation (3.1), 2D case will be represented by
−0.9883ln(vGS ) + ln(vLS ) ≥ 1.0608(1 + ε ) → Bubble
−0.9883ln(vGS ) + ln(vLS ) ≤ 1.0608(1 − ε ) → Intermitent

.

(3.3)

Knowledge-Based Multiclass Support Vector Machines

193

4 Computational Results
In this section, the results of the analyzed data sets and prior sets described in section
3 are presented and discussed. The LMTRKSVM model is used to train the data sets
with prior knowledge. To compare between the different models, a performance parameter (misclassification error) was defined as the fraction of misclassified points for
a given data set

⎛ Total number of correctly classified points ⎞ .
⎟
Total number of observed points
⎝
⎠

β = 1−⎜

(4.1)

The tradeoff constants considered are between 0 – 100, and the deviation factors considered are within the interval 0.01 – 0.1. The outputs (flow regimes) were coded as: 1
– bubble, 2 – intermittent (slug and churn) and 3 – annular.
Results of the 2D & 3D vertical flow data with prior knowledge information
trained on the LMTRKSVM model and compared with the LMTRSVM model (2.1),
are shown in Fig. 2 & 3. It should be noted that CPU time is measured in seconds.
The theoretical correlations of McQuillan & Whalley [1] were also simulated to
compare with the learning models. The error rate is 0.0163 for the 2D vertical flow
data and 0.1227 for the 3D vertical flow data. All computations were performed
using MATLAB [18]. In bold face are the lowest error rates for each tradeoff
constant λ.
Fig. 2 presents the average test error rate results, based on three random samples
for the 2D vertical flow data with prior knowledge as defined in section 4. The
LMTRSVM and LMTRKSVM models generally report promising error rates. The error
rate (0.0098) for the model with prior knowledge (LMTRKSVM) is the same as the
one for the data driven model (LMTRSVM), but smaller than the error rate of the
theoretical correlations for 2D vertical flow. Fig. 3 presents the average test error
rate results, based on four runs with random samples for the 3D vertical flow data
with prior knowledge. The model with prior knowledge (error rate of 0.0413) performs better than both the data driven model and the 3D vertical flow theoretical
model.

Fig. 2. Average test error rate for LMTRKSVM on 2D vertical flow data (varying tradeoff)

194

O.O. Oladunni, T.B. Trafalis, and D.V. Papavassiliou

Fig. 3. Average test error rate for LMTRKSVM on 3D vertical flow data (varying tradeoff)

Irrespective of the deviation factor, ε, the prior knowledge models appear to perform better or at least display equal level of performance (error rate) with the data
driven model (LMTRSVM). For all data sets, the LMTRKSVM performs better than the
theoretical model. However, since most of the theoretical correlations are nonlinear
models, a nonlinear classification of the data is likely to achieve better generalization
ability and lower error rate (note that the present model assumes that the data are
linearly separable).

5 Conclusion
In this paper, a knowledge-based multi-classification model called the Linear Multiclassification Tikhonov Regularization Knowledge-based Support Vector Machine
(LMTRKSVM) was applied to vertical, two-phase flow data and comparisons were
made with a data driven model (LMTRSVM) and a theoretical model. The
LMTRKSVM model using pipe size and superficial velocities as input training vector
attributes of the flow regime produces a better overall misclassification error in comparison to theoretical models. Increasing the dimensionality of the classification problem to 3D for the vertical flow data still produces better error rates for LMTRKSVM
models. The theoretical model error rate is quite large and clearly out of the error rate
interval of the LMTRKSVM 3D vertical flow model. This highlights the strengths of
the prior knowledge learning model.

References
1. McQuillan, K.W., Whalley, P.B.: Flow Patterns in Vertical Two-Phase Flow. Int. J. Multiphase Flow, (1985) 11, 161 – 175
2. Mandhane, J.M., Gregory, G.A., Aziz, K.: A Flow Pattern Map for Gas-Liquid Flow in
Horizontal Pipes. Int. J. Multiphase Flow, (1974) 1, 537 – 553
3. Taitel, Y., Bornea, D., Dukler, A.E.: Modeling Flow Pattern Transitions for Steady Upward Gas-Liquid Flow in Vertical Tubes. AIChE J., (1980) 26, 345
4. Taitel, Y., Dukler, A.E.: A Model for Predicting Flow Regime Transitions in Horizontal
and Near Horizontal Gas-Liquid Flow. AIChE J, (1976) 22, 47

Knowledge-Based Multiclass Support Vector Machines

195

5. Petalas, N., Aziz, K.: A Mechanistic Model for Multiphase Flow in Pipes. CIM98-39, Proceedings, 49th Annual Technical Meeting of the Petroleum Society of the CIM, Calgary,
Alberta, Canada, (1998) June 8-10
6. Osman, E.A.: Artificial Neural Networks Models for Identifying Flow Regimes and Predicting Liquid Holdup in Horizontal Multiphase Flow. SPE 68219, (2000) March
7. Mi, Y., Ishii, M., Tsoukalas, L.H.: Flow Regime Identification Methodology with Neural Networks and Two-Phase Flow Models. Nuclear Engineering and Design, (2001), 204, 87 – 100
8. Ternyik, J., Bilgesu, H.I., Mohaghegh, S.: Virtual Measurement in Pipes, Part 2: Liquid
Holdup and Flow Pattern Correlations. SPE 30976, (1995) September
9. Trafalis, T.B., Oladunni, O., Papavassiliou, D.V.: Two-Phase Flow Regime Identification
with a Multi-Classification SVM Model. Industrial & Engineering Chemistry Research,
(2005) 44, 4414 – 4426
10. Mangasarian, O.L., Shavlik, J.W., Wild, E.W.: Knowledge-Based kernel approximation.
Journal of Machine Learning Research, 5, 1127-1141, (2004)
11. Fung, G., Mangasarian, O.L., Shavlik, J.W.: Knowledge-Based support vector machine
classifiers. Neural Information Processing Systems 2002 (NIPS 2002), Vancouver, BC,
December 10-12, (2002). ``Neural Information Processing Systems 15", S. Becker, S.
Thrun and K. Obermayer, editors, MIT Press, Cambridge, MA, 2003, 521-528
12. Tikhonov, A.N., Arsenin, V.Y.: Solution of Ill-Posed Problems. Winston, Washington
D.C., (1977)
13. Pelckmans, K., Suykens, J.A.K., De Moor, B.: Morozov, Ivanov and Tikhonov regularization based LS-SVMs. In Proceedings of the International Conference On Neural Information Processing (ICONIP 2004), Calcutta, India, Nov. 22-25, (2004)
14. Oladunni, O., Trafalis, T.B.: Linear Multi-classification Tikhonov Regularization Knowledge-based Support Vector Machine (LMTRKSVM), Technical Report, School of Industrial Engineering, University of Oklahoma, Norman, Oklahoma (2005)
15. Santosa, B., Conway, T., Trafalis, T.B.: Knowledge Based-Clustering and Application of
Multi-Class SVM for Genes Expression Analysis. Intelligent Engineering Systems
through Artificial Neural Networks, (2002), 12, 391 – 395
16. Hsu, C-W., Lin, C-J.: A Comparison of Methods for Multi-class Support Vector Machines. IEEE Transactions on Neural Networks, (2002) 13, 415 – 425
17. Lewis, J. M., Lakshmivarahan, S., Dhall, S.: Dynamic Data Assimilation. Cambridge
University Press, (2006)
18. MATLAB User’s Guide. The Math-Works, Inc., Natwick, MA 01760, (1994-

2003). http://www.mathworks.com

