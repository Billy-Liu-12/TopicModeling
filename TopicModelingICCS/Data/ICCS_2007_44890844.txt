Belief Combination for Uncertainty Reduction in
Microarray Gene Expression Pattern Analysis
Kajia Cao and Qiuming Zhu
Department of Computer Science, University of Nebraska
Omaha, Omaha, NE 68182
kcao@mail.unomaha.edu, qzhu@mail.unomaha.edu

Abstract. Many classification methods are used in microarray gene expression
data analysis to identify genes that are predictive to clinical outcomes
(survival/fatal) of certain diseases. However, the reliability of these methods is
often not well established due to the imprecision of the method and uncertainty
of the dataset. In this paper, a knowledge-based belief reasoning system (BRS)
is proposed to solve the problem by dealing with the uncertainties inherent in
the results of various classification methods. Through the belief combination
process, we pursue a means to reduce the uncertainty and improve the reliability
of classification so that the underlying features of gene behavior recorded in the
microarray expression profiles could be convincingly revealed.
Keywords: uncertainty reasoning, belief reasoning system, Dempster Shafer
Theory, microarray gene expression.

1 Introduction
Theories and techniques that dealt with incompleteness (but maybe precise) of
information have been evolved in the development of non-monotonic logics, truth
maintenance systems (TMSs), reason maintenance systems (RMSs), and other
approaches [5]. Meanwhile, theories and techniques for reasoning uncertainty (but
maybe complete) of information have also been attempted. For example, techniques
adapted from fuzzy measurement and probability theories that accept non-realistic
global assumptions have been studied [5, 6, and 11]. Specially, Dempster Shafer
theory (DST) of belief projection provides a subtle and more thorough way of
reasoning under uncertain and incomplete information which is easier to be
referenced than the statistical confidence interval approach [3].
There are a number of methods discussed in the literature for identifying genes that
are indicators of certain diseases, health disorders, or clinical treatment outcomes.
Known as a classification problem, the identification process corresponds roughly to a
clinical diagnosis process: given a set of known models based on prior knowledge,
determine the correct model that best fit to the data obtained from measurement and
observations [12].
In the expert systems, three distinct layers are defined: representation, inference,
and control layers [5]. It is our claim that the treatment of uncertainty in Belief
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 844–851, 2007.
© Springer-Verlag Berlin Heidelberg 2007

Belief Combination for Uncertainty Reduction

845

Reasoning System (BRS) must address each of these layers. Most of researches in this
area do not properly cover these issues. Some approaches lack clarity on
representation paradigm. Others require unrealistic assumptions to provide uniform
combining rules defining the plausible inferences. As we know that non-numerical
approaches are inappropriate to represent measures of uncertainty. The numerical
approaches need some restrictions on the observations (statistical information, or
exclusiveness of hypotheses and so on). All the information that needs in numerical
approaches should be precise and numerical. In this case, the input of whole reasoning
procedure is complicated and restricted. We then propose a Belief Reasoning System
for numerical approaches of reasoning with uncertainty, which organizes its
description around the three-layer structure.
Representation Layer
There should be an explicit and consistent representation of the amount of evidence
for supporting any given hypothesis on this layer. The presentation of the information
about the evidence which is known as meta-information, such as the evidence source,
the reasons for supporting a given hypothesis, should be given in an explicit way.
Specially, all the evidence and its meta-information should be factual-based, but could
be incomplete, in terms on the possibly limited observation on evidence. The
representation of observation (evidence) should be available on discriminant
information gathering which may be used to define the knowledge functions in
inference layer. Multi-measurements that applied in the gene pattern classification are
the inputs of the layer in this paper.
General approaches of classification include: (a) parametric methods where a model
is often assumed prior the classification process, such as the principal component
analysis (PCA) [7], independent component analysis (ICA), and separation correlation
metric (SCM) [8], alternatively known as the Fisher’s discrimination criterion (FDC)
[1]; and (2) non-parametric methods where a model is often learned (formed) gradually
during the classification process, such as the threshold number of misclassification
(TNoM) [10], projection pursuit regression (PPR) [2], support vector machines (SVM)
[11], and expectation maximization (EM) [13]. Each of these methods solves the
uncertainty problem partially, from different aspect and at different levels, however. No
single method of above can provide a completely certain and reliable solution to the
classification problem of most real world applications, such as the microarray data
analysis.
Inference Layer
The inference should be based on global assumptions of evidence independence and
should not depend on any assumption on probability distribution or model of the
propositions in terms of the objectivity of the reasoning [3]. For example, Triangular
norms (T-norms) are presented to summarize and propagate the uncertain information
previously [5]. T-norm is a binary function that satisfies the requirements of the
conjunction and disjunction operators which should be monotonic, commutative, and
associative.
Dempster Shafer Theory (DST) which proposed by Shafer which also satisfies all
the assumptions is selected as the reasoning inference in this paper (section 2).
Combination rules of evidence should also maintain the closure of the syntax and
semantics of the representation of uncertainty, i.e., any knowledge functions that used

846

K. Cao and Q. Zhu

to propagate the uncertainty should have logically clear definition to allow the
Control Layer to decide the most appropriate combination rule and making decision.
Control Layer
The appropriate uncertainty operator will be first decided in this layer, and then the
related combination rule. It is important to measure the uncertainty of the information
as well as the uncertainty of the measure itself. The aggregation and propagation of
uncertainty through the reasoning process must be traceable to solve conflicts or
contradictions that may be occurred in evidence and inference procedure. It should be
possible to make pair-wise comparisons of uncertainty.
In this paper, the problem of reasoning uncertainty of multi-measurements based
on belief reasoning system will be first generalized in section 2. Specifically,
reasoning under uncertainty using Dempster Shafer Theory (DST) for identifying
genes indicative to clinical survival outlook of DLBCL from gene profiling data
analysis will be described. Experimental result and discussion are presented in section
3 and 4 respectively.

2 Uncertainty Reduction of Gene Pattern Analysis Based on Belief
Reasoning System
2.1 Measurements Applied to DLBCL Gene Expression Profiling Data
(Representation Layer)
Identifying genes that are predictive to clinical outcomes is one of the important goals
in the analysis of gene expression profiling data from tumor samples. Two gene
expression profiling studies of diffuse large B-cell lymphoma (DLBCL) have
identified genes predictive of clinical outcomes [20, 21]. Rosenwald et al identify
from functional (gene expression signature) groups of genes that are predictive of
survival including genes that divide the tumor into distinct biologic subtypes [15].
Shipp et al applied supervised learning method on an expression profiling dataset of
7139 genes over 58 tumor specimens, and identified 13 genes that are highly
predictive to the outcomes [14].
To create an outcome predicator that integrates a number of highly indicative genes,
we concentrated on evaluating individual genes with respect to the expected outcome on
Shipp’s microarray dataset (www.genome.wi.mit.edu/MPR/lymphoma) applying
multiple measurements [16]. The patient cases are pre-classified into two groups: Group
0 (26 cases) as fatal cases and Group 1 (32 cases) which represents survival cases. The
measurements that applied to the dataset are Fisher’s Discrimination Criterion (FDC)
Cross-Projection (CP) and Discrete Partition (CP). FDC method is the parametric
method identifying data attributes and their projections that are most likely to be
separable among different classes. Cross-projection and Discrete Partition are proposed
to fuse with the FDC in order to diminish the side effects of the outliers on FDC. All of
these approaches are independent to each other. In Belief Reasoning System, the
uncertainty and reliability of the three measurements: FDC, CP and DP will be
discussed.

Belief Combination for Uncertainty Reduction

847

2.2 Dempster Shafer Theory as the Inference Layer
There are number of functions of measurements used in DST: the basic probability
assignment (bpa) function (m), the Belief function (Bel), and the Plausibility function
(pl). All these functions are related to each other in some ways. The basic probability
assignment defines a mapping of the power set of independent variables to the
interval between 0 and 1, m: p(X) → [0, 1], which satisfies: m(∅) = 0,

∑ m( A) = 1 .

A∈P ( x )

Where p(X) represents the power set of a universal event set X, ∅ is the null set, and A
is a subset in the power set [8]. The value of m(A) pertains only to the set A and
makes no additional claims about any subsets of A. Any further evidence on the
subsets of A would be represented by another bpa, i.e. B ⊂ A , where m(B) would be
the bpa for the subset B.
Formally, for all sets A that are elements of the power set A ∈ p(X ) , we have the
following relations [8]:

∑ m( B )

(1)

∑ m( B) = 1 − Bel ( A )

(2)

Bel ( A) =

B B⊆ A

Pl ( A) =

B B ∩ A≠ ∅

where A is the classical complement of A.
Given two independent evidences which are expressed as two bpa’s: m1, and m2,
they can be combined into a single joined basic assignment m12 by applying
Dempster’s rule of combination, as shown in the following manner:
m12 ( A) =

∑ m ( B)m (C )
1 − ∑ m ( B) m (C )
1

2

B ∩C = A

1

(3)

2

B ∩C =∅

m12 (∅) = 0

where 1 −

(4)

∑ m ( B)m (C ) is a normalization factor which is represented by letter K
1

2

B ∩C = ∅

normally. When K = 1, it has the effect of completely ignoring conflict and attributing
any probability mass associated with conflict to the null set [6].
2.3 Choice of Combination Rules of DST in Control Layer
There is no need to include page numbers. If your paper title is too long to serve as a
running head, it will be shortened. Your suggestion as to how to shorten it would be
most welcome.
Combination rules are the special types of aggregation methods for data obtained
from multiple sources. Dempster’s rule of combination is critical to the conception of
belief projection in DST since the measures of Belief and Plausibility are derived
from the combined basic assignments. There also derived several other combination

848

K. Cao and Q. Zhu

rules, for example, Yager’s rule, Inagaki’s rule, Zhang’s rule etc., which may concern
about other properties of the data that Dempster’s rule of combination may not be
applied.
In this paper, all the sources in the experiment (section 4) are independent to each
other. This satisfies the request of Dempster’s rule of DST: the Dempster’s rule of
combination is purely a conjunctive operation (AND), that is, the combination rule
results in a belief function based on conjunctively pooled evidence [4].
To account for uncertainties, we choose several sets of candidate measurements,
marked as S1, S2, …, Sn, respectively, in terms of their specific aspects merited to the
problem of classification. All of these candidate measurements should be independent
to each other according to the principle of belief projection [4].
For each set A of measurement objectives, we calculate the basic probability
assignments (bpa) based on
m: p( X ) → [0, 1]

(5)

for each sample in our experimentation using:
m( A) = (m1 ⊕ m 2 ⊕ m3 ⊕ ... ⊕ m n ) =

∑ ∏ m (A ) / K

∩ Ai = A 1≤ i ≤ n

i

i

(6)

where
K = 1−

∑ ∏ m (A ) = ∑ ∏ m (A )
i

∩ Ai =φ 1≤ i ≤ n

i

i

i

∩ Ai ≠φ 1≤ i ≤ n

(7)

A is the designated pattern (target); n is the number of measurements in each set of
candidate measurements.
After the calculation, the belief function for each objectives Bel(A) can be
calculated by using formula (1).

3 Belief Projections of Multi-measurements on DLBCL
According to the multi-measurements (Fisher’s Discrimination Criterion, CrossProjection, and Discrete Partition) that mentioned above, one combinatorial set of
candidate measurements is conducted. FDC and CP which are parametric methods
perform maximum likelihood classification on gene dataset, while DP is the nonparametric method that calculates the minimum likelihood for each gene. It is possible
that the result of FDC or CP is contradicted with DP result, that is, the statistics of the
certain gene is not consistent with its geometrical display. The process of computation
for belief projection using DST’s rule of combination in gene pattern analysis is then
described as follow:
1.

For each gene gk
//Measurements calculation
1.1 Compute FDC, CP and DP value separately (see figure 1 through 3).
The computation is given in [16].

Belief Combination for Uncertainty Reduction

849

1.2 Sort the results of FDC, CP and DP values separately. For the fairness of
the experiments, pick up the first 400 genes (over 5% of whole 7129
genes) in the experiment result of FDC, CP and DP.
1.3 Present algorithmic fusion on the candidate lists and 15 genes are
retrieved (see figure 4). We also do the ordinary overlapping on the 400
genes, and pick up the first 15 genes (see figure 5) as a comparison to 15
genes selected by algorithmic fusion.
//Calculate basic probability assignments
1.4 For the designated pattern Ak (from probability prospective, it is called
“event”) of the certain gene – “gene gk is significantly expressed”, the
basic probability assignments (bpas) of FDC, CP and DP are projected
into the interval [0, 1] by formula (5).
1.5 Because of the nature (possible contradiction) of input measurements,
we would set the bpas which are shown in table 1.
1.6 Calculate the Belief function m({A}) by formula (6) where normalization
factor K could be calculated by formula (7).
Calculate Bel(A) by formula (1) for each contradicted or non-contradicted
cases.

2.

To compare the belief(A) on each gene list, we first sort the belief(A) in descending
order on each list and draw the histogram for both, see figure 6.
Table 1. bpas of FDC, CP and DP
A will happen
FDC

m FDC ({ A}) = bpa ( FDC )

CP

mCP ({ A}) = bpa (CPI )

DP

mDP ({ A}) = 0

A will never happen

mCP ({¬A}) = 0
m DP ({¬A}) = bpa( DPI )

Fig. 1. FDC values of all genes

Uncertain
m FDC ({ A, ¬A}) = 1 − bpa( FDC )

m FDC ({¬A}) = 0

mCP ({ A, ¬A}) = 1 − bpa (CPI )

m FDC ({ A, ¬A}) = 1 − bpa ( DPI )

Fig. 2. CP values of all genes

850

K. Cao and Q. Zhu

Algorithmic fusion's 15 genes with bpas
0.8
0.7
0.6
0.5

bpa(FDC)

0.4
0.3

bpa(CPI)
bpa(DPI)

0.2
0.1
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

Fig. 3. DP values of all genes

Fig. 4. Algorithmic fusion’s 15 genes

overlapped 15 genes with bpas of FDC, CP and DP
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

bpa(FDC)
bpa(CPI)
bpa(DPI)

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

Fig. 5. Overlapped 15 genes

Algorithmic Fusion Vs. Overlapped 15 genes
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Overlapped
AF

1

3

5

7

9

11

13

15

Fig. 6. Algorithmic Fusion Vs. 15 genes

4 Conclusion and Discussion
In this paper, we generated Belief Reasoning System and its application on DLBCL
gene pattern analysis. We also adopted Demspter Shafer theory as numerical
reasoning approach on testing the multi-sources during the reasoning procedure. From
the experiments on DLBCL Microarray gene analysis, we found that BRS helps to
build a modularized way which makes the multi-sources uncertainty reasoning
procedure more organized and easy handling. In figure 5, it is intuitive that bpa of
FDC varies significantly from the other two measurements while overlapped 15 genes
in figure 6 shows more consistent relationship among the three measurements. But it
is hard to say which list is trustable. After DST is applied on the measurements, the
genes selected from algorithmic fusion outperformed highly the gene list picked from
simply overlapped 15 genes in figure 7. So the conclusion can be made that the more
comprehensive selection of genes is the more reliability can be guaranteed.
However, it needs to be pointed out that when the combination of measurements is
large enough, the calculation of DST is too complex to be applied in real problem. For
example, in the three measurements combination cases, six factors are needed to
calculate normalization factor K, while in the four measurements combination cases,
more than ten factors are needed on calculating K. Generally, DST could be used in
microarray gene prediction, because three to four measurements are practically
enough due to the similarity and relativity of parametric or non-parametric
approaches.

Belief Combination for Uncertainty Reduction

851

References
1. Fisher, R. A. Sc. D., F. R. S.: The Use of Multiple Measurements In Taxonomic Problems,
Reproduced from the Annals of Eugenics, Vol. 7 (1936) 179 – 188
2. Friedman, J. H., Tukey, J. W.: A Projection Pursuit Algorithm for Exploratory Data
Analysis, IEEE Trans. of Computers, c-23(9), (1974) 881-890
3. Shafe, G. r: A Mathematical Theory of Evidence, Princeton University Press (1975)
4. Shafe, G. r: Probabiliy Judgement in Aritificial Intelligence, Uncertainty in Artificial
Intelligence, L.N.Kanal and J.F. Lemmer, New York, Elsevier Science. 4 (1986)
5. Bonissone, P. P.: Summarizing and Propagating Uncertain Information with Triangular
Norms, International Journal of Approximate Reasoning (1987) 1: 71 – 101
6. Yager, R.: On the Dempster-Shafer Framework and New Combination Rules, Information
Sciences , 41 (1987) 93 – 137
7. Oja, E.: Principal Components, Minor Components, and Linear Neural Networks, Neural
Networks, 5 (1992) 927-935
8. Klir,G. J., Wierman, M. J.: Uncertainty-Based Information: Elements of Generalized
Information Theory, Heidelberg, Physica-Verlag (1998)
9. Wessels, L. F., Reinders, M. Baldocchi,J. R., Gray, J.: Statistical Analysis of Gene
Expression Data, Proceedings of the Belgium-Netherlands Artificial Intelligence
Conference (1999)
10. Ben-Dor, A., Fridman, N., Yakhini, Z.: Scoring Genes for Relevance, Technical report
AGL-2000-13, Agilent Labs, Agilent Technologies (2000)
11. Brown, M., et. al.: Knowledge-Based Analysis of Microarray Gene Expression Data by
Using Support Vector Machines, Proceedings of the National Academy of Sciences, USA,
97 (2000) 262 – 267
12. Slonim, D. K., Tamayo, P. J., Mesirov, P., Golub, T. R., LandeE, S. r: Class Prediction and
Discovery Using Gene Expression Data, Proceedings of the fourth annual international
conference on Computational molecular biology, Tokyo, Japan (2000) 263 - 272
13. Duda,R. O., Hart, P. E., Stork, D. G.: Pattern Classification, Second edition, John Wiley &
Sons (2001)
14. Shipp, M. A., et. al.: Diffuse Large B-Cell Lymphoma Outcome Prediction by Gene
Expression Profiling and Supervised Machine Learning, Vol. 8. Number 1, Nature
Medicine (2002) 68-74
15. Rosenwald, A., Wright, G., Chan, W. , Connors, J., Campo, E., Fisher, R., Gascoyne,
Muller-Hermelink, R. H., Smeland, E., Staudt, L.: The Use of Molecular Profiling to
Predict Survival After Chemotherapy for Diffuse Large B-cell Lymphoma, The New
England Journal of Medicine, Vol. 346, No. 25 (2002) 1937 – 1947
16. Zhu,Q., Cui, H., Cao, K., Chan,J.: Algorithmic Fusion of gene expression profiling for
diffuse large B-cell lymphoma outcome prediction. IEEE Trans. on Information
Technology in BioMedicine, Vol.8, June (2004) 79-88

