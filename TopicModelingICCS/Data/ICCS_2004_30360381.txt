Mobile-Based Synchronization Model for Presentation
of Multimedia Objects
Keun-Wang Lee1 , Hyeon-Seob Cho2 , and Kwang-Hyung Lee3
1
2

Dept. of Multimedia Science Chungwoon University, Korea
kwlee@cwunet.ac.kr
Dept. of Electronics Engineering Chungwoon University, Korea
3
School of Computing, Soong-sil University, Korea

Abstract. This paper presents a synchronization model that implements the presentation of multimedia objects as well as a synchronization scheme that improves
media data latency and quality of service (QoS) in mobile environments. The proposed model meets synchronization requirements among multimedia data because
it employs an approach to not only adjusting synchronization intervals using the
maximum available delay variation or jitter at the base station (BS) but also flexibly
dealing with variable latencies due to variations in delay time.

1

Introduction

Synchronization is a critical prerequisite to ensuring an adequate QoS in providing multimedia services. The reason behind that lies in the disruption of original timing relations
resulting from the occurrence of random delays in mobile networks or mobile host(MH)
system clock inconsistencies among inter-media, all of which is attributable to difference in the time of arrival of data being transferred from the server side to the MH
over wireless communications networks. Therefore, for the multimedia data in which
timing relations are disrupted, an artificially synchronized presentation of data streams
is required to ensure similarity or identicalness to the original ones, through the use of
the requirements for application services or the limitations of human perception toward
loss and delays occurring in individual media [1][2][3].
This paper deals with live synchronization involving the real-time synchronization of
multimedia information as well as synthetic synchronization for stored media. For this
example, let us assume that we are taking 3D animation training for electrical safety from
a MH. While a lecturer is providing verbal explanations, his/her voice, moving images,
texts, and 3D animation should be presented simultaneously. As in wired environments,
smooth audio/visual presentations should be delivered in mobile environments. In this
regard, this paper proposes a synchronization model that allows for simultaneous presentations of multimedia objects such as voice, 3D animation, moving images and texts
on a MH as well as presents an intra-media and inter-media synchronization scheme that
enables mobile multimedia services.

2

Related Work

Previous studies have focused on describing synchronization models for multimedia
applications [5][6]. Among them, Petri-net based specification models are effective in
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3036, pp. 381–388, 2004.
c Springer-Verlag Berlin Heidelberg 2004

382

K.-W. Lee, H.-S. Cho, and K.-H. Lee

specifying temporal relationships among media objects. These models allow various media to be integrated and give easy descriptions of QoS requirements. However, previous
extended forms of Petri-net modeling like Object Composition Petri-Net (OCPN) and
Real Time Synchronization Model (RTSM) exhibit limitations as far as QoS parametric
modeling is concerned.
Many existing studies pose significant problems in that delay in wireless networks causes
a reduction in the maximum media playout latency. That’s because conventional research
places focus on determining the sequence and playout time of the media created by the
server side and fixing the queuing time at the buffer on the MH side.
Delay jitter causes discontinuity. If any discontinuity is permissible at a MH, it should be
smaller than the worst end-to-end playout delay. This case leaves you with two strategy
options; one with I-strategy in which belatedly arrived frames from the BS are discarded,
and the other with E-strategy in which belatedly arrived frames from the BS are played
out.
This paper proposes a dynamic synchronization scheme that adjusts intervals between
synchronization activity using the maximum available delay variation or jitter, reduces
data loss caused by variations in latency, and synchronizes inter-media and intra-media.

3

Proposed Synchronization Model

The proposed synchronization model is Petri-net based standard model that enables the
presentation of multimedia objects.
3.1

Definition of Synchronization Model

The proposed synchronization model for specifying Petri-net in any BS is defined as
follows:
The model is specified by the tuple [P, T, K, A, Re, M]
where
P = p1 , p2 , . . . , pn ; Regular places(single circles).
T = t1 , T2 , . . . , tm ; Transitions.
K = k1 , k2 , . . . , ki ; Key places.
X = P ∪ K; All places.
A = (X × T ) ∪ (T × X) → I, I, = 1, 2, 3, . . . ; Directed arcs.
Re : X → r1 , r2 , . . . , rk ; Type of media.
M : X → I, I = 0, 1, 2 ; State of places
The "Place" is used to represent a medium unit and its action. It may have tokens. A
place without any token indicates that it is currently in an inactive state. A place with a
token stands in an active state and may be in either a blocked or unblocked state.
The information determining the firing of a transition ti is delivered by a control medium.
When a key medium arrives within the time specified by an absolute time, the transition
ti is immediately fired at the corresponding transition’s input place that has open tokens.
However, in the event that the key medium reaches beyond the time specified by an
absolute time, the absolute time initiates the firing.

Mobile-Based Synchronization Model for Presentation of Multimedia Objects

3.2

383

Control Medium

As a control medium, CT has the information about the number of input places and
key media while transmitting this information to a subsequent transition. The roles of a
control medium is addressed by the following:
(1) Check the set of input places;
(2) Determine the number of objects selected as key media
(3) Transmit the number of input places and key media as well as an absolute time to a
subsequent transition.
Figure 1 shows the state of a key medium and the active state stored in the control
medium, which will be transmitted to subsequent transitions. 7 bits at the front and 7
bits at the back indicate the information of a key medium and the information of its
active state, respectively.

active state

Key Medium state
K_T

Au

I

Ani

Tx

Po

V

a_T

Au

I

Ani

Tx

Po

V

Fig. 1. Information of Control Medium

All media are transmitted over networks, so real-time constraints are likely to be
exceeded. In the event of the delay of a key medium, a firing is available via the absolute
time of the control medium.
3.3

Presentation of Synchronization Model

Figure 2 shows an overall view of Petri-nets. 1’(125,3,1,1,1,0,0,0,6,1,1,1,1,1,1) indicates
the information of a control medium. The first parameter 125 refers to the absolute time,
3 the number of key media, and 6 the number of input places. As Control indicates
type, Control in is applicable to all conditions. When an event (i.e. number of key media
and number of input places) occurs, the control medium transmits the information to
subsequent transitions.
HS indicates a hierarchical submodule that goes to a lower level module for job processing before going to the next phase. HS goes to a relative duration routine - one of its lower
level modules - to find the relative duration before executing After duration. Therefore,
HS has synchronization intervals three times, which results in effective synchronizations in a way that computes the relative duration before executing sync1, computes the
compensation time for jitters before executing sync2, and computes the flexible playout
time before executing sync3.
Verifications of the proposed multimedia synchronization model have been performed in order to make sure that it corresponds to the analysis methods of petri-nets
including a reachability graph and a matrix-equation.
Verification of Reachability Graph. The reachability tree represents the reachability set of petri-nets. In the proposed model, the initial marking is (1, 1, 1, 1, 1,

384

K.-W. Lee, H.-S. Cho, and K.-H. Lee
Control
control_in

check_control

(125,3,1,1,1,0,0,0,6,1,1,1,1,1,1)
Control
Medium
_on
Medium

relative_du
ration_time
HS

Jitter_compe
nsate_time
HS

Medium

After_du
ration

Au1

Au2

smooth_play
out_time
HS

Medium

After_jitt
er

After_s
mooth

Au3

Au4

Control
Medium
_on
Medium

Jitter_compe
nsate_time

relative_du
ration_time

smooth_play
out_time

Medium
After_du
ration

I1

Medium
After_jitt
er

I2

After_s
mooth

I3

I4

Control
Medium
_on
Medium

Jitter_compe
nsate_time
Medium

relative_du
ration_time
After_du
ration

Ani1

Ani2

smooth_play
out_time
Medium
After_s
Ani3
mooth

After_jitt
er

Ani4

Control
Medium
_on
Medium

relative_du
ration_time
After_du
ration

Tx1

sync
1

Jitter_compe
nsate_time
Medium
After_jitt
er

Tx2

sync
2

smooth_play
out_time
Medium
After_s
Tx3
mooth

sync
2
3
Tx4

Control
Medium
_on
Medium

Medium
After_du
ration

Po1
Control
Medium
_on
Medium

Jitter_compe
nsate_time

relative_du
ration_time

After_jitt
er

Po2

relative_du
ration_time
After_du
ration

V2

After_s
mooth

Po3

Jitter_compe
nsate_time
Medium

V1

smooth_play
out_time
Medium
Po4

smooth_play
out_time
Medium

After_jitt
er

V3

After_s
mooth

V4

Fig. 2. Presentation of Synchronization Model

1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0). The transition t1 is generated from this initial
marking. If t1 is fired, t1 [giving(0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0)] is
obtainable, and a transition to t2 is possible. If t2 is fired, t2 [giving(0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1)] is obtainable. The result of this tree is represented as follows:
(1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
↓ t1
(0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0)
↓ t2
(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1)
Verification of Matrix-Equation. Verifications of the proposed model were performed
using matrix-equations as the second analysis method of the petri-nets. The following
are two matrices D− and D+ indicating input function and output function, respectively.
Matrices D− and D+ are expressed as follows:
1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0
0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0
D+ =
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1

D− =

And the matrix D is expressed as follows:

Mobile-Based Synchronization Model for Presentation of Multimedia Objects

385

D = D+ - D− =
−1, −1, −1, −1, −1, −1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0
0, 0, 0, 0, 0, 0, −1, −1, −1, −1, −1, −1, 1, 1, 1, 1, 1, 1
The result of applying the equation µ = µ + x · D
to the matrices is addressed by the following :
(0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1) =
(1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0)
+
x

−1, −1, −1, −1, −1, −1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0
0, 0, 0, 0, 0, 0, −1, −1, −1, −1, −1, −1, 1, 1, 1, 1, 1, 1

(-1,-1,-1,-1,-1,-1,0,0,0,0,0,0,1,1,1,1,1,1)=

X

−1, −1, −1, −1, −1, −1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0
0, 0, 0, 0, 0, 0, −1, −1, −1, −1, −1, −1, 1, 1, 1, 1, 1, 1

where x is (x1 , x2 )
−1 = −1 · x1
0 = x1 - x2
1 = x2
1 = x2
For (1), x1 = 1;
For (2), x1 = 1;
Therefore, for (3), x1 − x2 = 0
Through the verification described above, the proposed synchronization model
proved to be consistent with the reachability graph and matrix-equation.

4

Synchronization Scheme

This chapter describes a delay jitter scheme. Delay time or latency is an important
factor in evaluating the playout quality of a frame. This paper provides a description
of delay jitter strategies such as I-strategy and E-strategy. It also makes a comparison
between those two strategies and the proposed delay jitter strategy using the waiting
time in the queue as well as playout time.
[Theorem] A frame waits for as long as variable latency or jitter times until they are
presented.
[Proof] Where the maximum latency or jitter time is below 10ms, temporary discontinuity is tolerable for voice media without causing any impact to quality of service. If
the discontinuity tolerance is δ, an extended synchronization interval becomes ∆ = ∆

386

K.-W. Lee, H.-S. Cho, and K.-H. Lee

+ δ. Therefore, if the instantaneous discontinuity tolerance permitted by the corresponding media data is δ, an extended synchronization interval becomes ∆ = ∆ + δ. If the
(j + 1)th packet arrival time at the buffer is Bi(j·i) , the synchronization requirements
are met when Bi(j·1) is smaller than or equal to the frame playout time Mi(j·i) . Formula
1 meets the synchronization requirements.
Bij
Bij
Bij
Bij

< Mi(j·1)
< Mij + ∆
< Mij + ∆ + δ
< Mij + 1/N + δ · · · (F ormula1)

The proposed strategy illustrates that, if the (j)th packet for media data stream i is
presented at the time Mij , the (j + 1)th packet is presented at the time Mi(j+1) = Mij +
∆ . In other words, (j)th and (j + 1) th packets meet Formula 1 within synchronization
intervals.

Proposed Jitter Strategy
Proposed Jitter Strategy
Waiting Time in the Queue

Queue Length
N 3
u
m
b
e
r 2

Q3
u
e
u
e

2

S
i
z
e 1

a

b

c

d

e

f

g

h

o
f
F 1
r
a
m
e

0

0
2

3

4

5

6

7
8
9 10
Presentation Time

2

3

4

5

6

7
8
9 10
Presentation Time

Fig. 3. Proposed Strategy Applied Under Reduced Network Traffic

Figure 3 shows the proposed jitter strategy that complements the shortcomings of
both the I-strategy and E-strategy. Belatedly arrived frames wait for as long as latency or
jitter times until they are presented, instead of being deleted unconditionally or waiting
indefinitely until they are presented at the next playout time. As depicted in Figure 3,
the frames b and c are played out in the units 4 and 6 by compensating for the maximum
latency or jitter. The frame f indicates that it has not arrived within the variable delay
jitter time. In this case, the frame f cannot be played out even if it waits for as long as
the variable latency or jitter times.
Therefore, the unit 8 in the frame f indicates that it cannot be compensated for the
maximum delay jitter time due to excessive delay.
Figure 4 shows that the unit 4 in the frame c was skipped due to excessive delay and
the unit 5 in the frame d was compensated by applying the maximum delay jitter time.

Mobile-Based Synchronization Model for Presentation of Multimedia Objects

387

Proposed Jitter Strategy
Proposed Jitter Strategy
Waiting Time in the Queue

Queue Length
N 3
u
m
b
e
r 2

Q3
u
e
u
e

2

S
i
z
e 1

b

a

c

d

e

f

g

i

h

o
f
F 1
r
a
m
e

0

0
2

3

5

4

6

7

8

9

10

2

3

4

5

6

Presentation Time

7

8

9

10

Presentation Time

100
90
80
70
60
50
40
30
20
10
0

(Playout rates)

(Playout rates)

Fig. 4. Proposed Strategy Applied Under Heavy Network Congestion
70
60
50
40
30

Proposed Strategy
E-Strategy
I-Strategy

Proposed Strategy
E-Strategy
I-Strategy

20
10
0

1

2

3

4

5

6

7

8

9

10

(Number of Experiments)

Fig. 5. Comparison of Playout Rates

5

80

1

2

3

4

5

6

7

8

9

10

(Number of Experiments)

Fig. 6. Comparison of Playout Rates

Performance Evaluation

With focus on the playout time and loss time, we performed a comparative analysis
between the existing scheme and the delay jitter & playout scheme using the maximum
delay jitter time. Comparisons among the I-strategy, E-strategy, and the proposed strategy were made in consideration of the following two cases; Circumstances of reduced
network traffic and circumstances of heavy network congestion. As a result, the proposed strategy proved to be vastly superior to other two strategies. For the purpose of
this paper, we have assumed that the average delay is 100ms and the variance is 20ms
in the event of delay in the audio stream.
Figure 5 shows the result of comparisons of playout rates among the I-strategy, Estrategy, and the proposed strategy that were applied under reduced network traffic. The
playout rates of the proposed strategy were obtained by conducting experiments ten
times. The proposed strategy showed more improved playout rates than the I-strategy
and E-strategy by 17.33 % and 7.8%, respectively.
As shown in Figure 6, under heavy network congestion, the proposed strategy showed
more improved playout rates than the I-strategy and E-strategy by 15.48% and 6.3%,
respectively.

388

6

K.-W. Lee, H.-S. Cho, and K.-H. Lee

Conclusions

This paper has proposed a scheme for implementing intra-media and inter-media synchronizations by means of smooth buffering at the BS in mobile environments. The
proposed scheme delivered optimized synchronizations without causing any degradation of quality of service. The superiority of the proposed scheme was demonstrated by
extending intra-media synchronization intervals using the maximum delay jitter time
of the audio media as a key medium, as well as by synchronizing irregularly arriving
packets within the extended intervals through applications of the said maximum delay
jitter time to inter-media synchronizations.
The proposed scheme for enabling intra-media and inter-media synchronizations is ideally suitable for the temporary increase in network load as well as unforeseeable disconnections.
Furthermore, it allows us to take 3D animation training for electrical safety while on the
road.
Future work needs to focus not only on standard schemes for mobile multimedia synchronizations which take interactions with users into account, but also on optimized
synchronization mechanisms which employ minimum buffering.
Acknowledgements. This research is supported by the Electric Power Industry R&D
Fund 2003 supported by Ministry of Commerce, Industry and Energy in republic of
Korea.

References
1. D. H. Nam and S. K. Park, "Adaptive Multimedia Stream Presentation in Mobile Computing
Environment," Proceedings of IEEE TENCON, 1999.
2. A. Boukerche, S. Hong and T. Jacob, "MoSync: A Synchronization Scheme for Cellular Wireless and Mobile Multimedia Systems," Proceedings of the Ninth International Symposium
on Modeling, Analysis and Simulation of Computer and Telecommunication Systems IEEE,
2001.
3. M. Woo, N. Prabhu and A. Grafoor, "Dynamic Resource Allocation for Multimedia Services
in Mobile Communication Environments,"IEEE J. selected Areas in Communications, Vol.13,
No.5, June. 1995.
4. D. H. Nam, S. K. Park, "A Smooth Playback Mechanism of Media Streams in Mobile Computing Environment," ITC-CSCC’98, 1998.
5. P. W. Jardetzky, and C. J. Sreenan, and R. M. Needham, "Storage and synchronization for
distributed continuous media," Multimedia Systems/Springer-Verlag, 1995.
6. C.-C. Yang and J.-H. Huang, "A Multimedia Synchronization Model and Its Implementation
in Transport Protocols," IEEE J. selected Areas in Communications, Vol.14, No.1, Jan. 1996.

