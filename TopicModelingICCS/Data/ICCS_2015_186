Procedia Computer Science
Volume 51, 2015, Pages 2493–2502
ICCS 2015 International Conference On Computational Science

Spectral Validation of Measurements in a Vehicle Tracking
DDDAS
Burak Uzkent1 , Matthew J. Hoffman2 , and Anthony Vodacek1
1

Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, New York, USA
bxu2522@rit.edu, vodacek@cis.rit.edu
2 School of Mathematical Sciences, Rochester Institute of Technology, Rochester, New York, USA
mjhsma@rit.edu

Abstract
Vehicle tracking in adverse environments is a challenging problem because of the high number of factors constraining their motion and possibility of frequent occlusion. In such conditions, identiﬁcation
rates drop dramatically. Hyperspectral imaging is known to improve the robustness of target identiﬁcation by recording extended data in many wavelengths. However, it is impossible to transmit such a
high rate data in real time with a conventional full hyperspectral sensor. Thus, we present a persistent
ground-based target tracking system, taking advantage of a state-of-the-art, adaptive, multi-modal sensor controlled by Dynamic Data Driven Applications Systems (DDDAS) methodology. This overcomes
the data challenge of hyperspectral tracking by only using spectral data as required. Spectral features
are inserted in a feature matching algorithm to identify spectrally likely matches and simplify multidimensional assignment algorithm. The sensor is tasked for spectra acquisition by the prior estimates
from the Gaussian Sum Filter and foreground mask generated by the background subtraction. Prior
information matching the target features is used to tackle false negatives in the background subtraction
output. The proposed feature-aided tracking system is evaluated in a challenging scene with a realistic
vehicular simulation.
Keywords: vehicle tracking, efﬁcient outlier exclusion, spectral features, multi-modal sensor

1

Introduction

Aerial surveillance in urban environments has been extensively studied in the literature. Most of them
try to tackle tough tracking problems with limited information. A large volume of studies focus on
using Ground Moving Target Indicator radars, which measure the locations of moving ground objects
as well as their doppler velocities, to tackle problems in ground target tracking [1, 11, 6, 7, 15]. With
radar, however, we are limited to kinematic information to achieve persistent tracking, and kinematic
data alone is very likely to fail in challenging situations due to occlusions, parallax, or clutter. To
achieve a more robust system, one can consider utilizing unique ﬁngerprints of objects in addition to
the kinematic data. The Dynamic Data-Driven Applications Systems (DDDAS) framework is perfectly
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.358

2493

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

Uzkent, Hoﬀman, and Vodacek

suited for allowing the tracking application to manage the control of the runtime reconﬁguration of
the sensor to collect the most beneﬁcial data and the feedback of this data into an adaptive modeling
framework for the dynamic scene.
Most of the narrow-area surveillance studies extract local features from the scene to identify their
targets. These features can be texture, color histogram, SIFT, optical ﬂow, edges, or corners [18, 14, 19].
However, in a wide-area ground-based tracking system, one can not rely on these features due to low
resolution. Instead, the hyperspectral data sampled from a single pixel of a target of interest (TOI)
can be beneﬁcial since it provides a unique ﬁngerprint. Hyperspectral imaging involves of acquiring
data in hundreds of narrow adjacent spectral bands. Thus, by inserting extended data, classiﬁcation of
objects can be further improved. It is impossible to transmit the volume of data from a conventional
full hyperspectral sensor in real time tracking. However, with the recent advancements in the sensor
technology, it becomes possible to quickly collect only desired spectral data [10]. As a result, such a
sensor in fact can be employed in a real time tracking system. Employing an adaptive sensor requires
DDDAS-based tools for determining the locations and modalities most useful for the the tracker at a
given time and controlling the realtime reconﬁguration of the sensor to collect the requested data.
In this paper, a persistent target tracking system utilizing an adaptive optical multi-modal sensor is
proposed. Since some portion of spectral data to be recorded is determined by the performance of the
ﬁlter, the executing tracker request external data from OpenStreetMap to acquire an intersection mask
of the scene where the true target density can be multi-modal. This way we can gain prior knowledge
of a possible maneuver and the tracker then adaptively can tune the transition models. However, abrupt
motion changes still might result in highly nonlinear true target densities. In these cases, it is extremely
challenging to collect spectra at the TOI pixels by relying on prediction-based spatial sampling. Hence,
we perform measurement-based sampling in addition to the prediction-based sampling to maximize the
likelihood of collecting data from the TOI.

2

Tracking System and Sensor Resource Management

A sensor capable of collecting spatial and spectral data is required to perfom high rate tracking of objects
of interest. For this reason, Rochester Institute of Technology Multi-object Spectrometer (RITMOS) is
considered as an adaptive performance-driven sensor together with a performance-driven algorithm to
detect, identify and track targets in highly cluttered scenes [10]. RITMOS utilizes a micromirror array
to reﬂect the light to the one of two sensors; spectrograph and panchromatic channel. The switch from
panchromatic to spectral data mode for a pixel can happen very fast due to the compactness and speed
of micromirror arrays. To capture the panchromatic image of the scene, an array of micromirrors reﬂect
the light to a panchromatic imaging array. Individual micromirrors imaging the object are then tilted
to reﬂect the light and collect the full spectrum of a speciﬁed pixel. All these conﬁgurations can be
performed in real time using DDDAS algorithms.
The performance-driven tracking algorithm needs to be designed in a way that it meets the speciﬁcations of RITMOS. RITMOS requires about 0.1 − 0.125 s to obtain panchromatic image of a scene.
On the other hand, the full spectrum of a single pixel in the visible to near infrared wavelength takes 1
ms. Spatial and spectral data can not be collected simultaneosly. The frame rate 1 s is used in this study,
meaning that track estimates are updated at every second. Panchromatic images are used to accomplish
motion segmentation. While the sensor collects a panchromatic image, the tracking algorithm outputs
the prior results that will be fed to the sensor resource management system for spectral data acquisition.
Full spectral data for 100 pixels can be collected in about 0.1 s. Tracking system workﬂow can be seen
in Fig.1.
2494

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

Uzkent, Hoﬀman, and Vodacek

Spectra Collection
(Prediction-based Sampling)
Time
Step
tk s

tn s

Feature Matching,
Blob Extraction
and Validation

Blob
Extraction
tk + 0.1s

Image
Acquisition

tm s

tn + 0.4s

Data
Association,
Measurement
Step

tn + 0.7s

tk + 1s

Spectra Collection
(Blob-based Sampling)

Figure 1: The workﬂow of the proposed tracking system using a performance-driven sensor.

3

Scenarios

To develop and test the system in a controlled environment that allows us a knowable ground truth,
we use synthetic imagery generated by the Digital Imaging and Remote Sensing Image Generation
(DIRSIG) model [5]. In addition, the Simulation of Urban Mobility (SUMO) trafﬁc simulator has been
integrated with DIRSIG to produce dynamic imagery for tracking scenarios [8]. The scenario used in
this paper comes from DIRSIG Megascene I, which is built to resemble part of Rochester, NY, USA.
The simulation uses hyperspectral imaging from a ﬁxed aerial platform assuming a static sensor mount.
The spectral range is 400 to 1000 nm with a spectral resolution of 10 nm. Thus, generated synthetic
images have 61 wavelength bands. Eighty six vehicles are placed in the 130 seconds long simulation.
Among them, we will focus on tracking four vehicles at separate runs.

Figure 2: Trajectories of the vehicles to be tracked.
Synthetic spectral data is extremely helpful for the reasons mentioned before, however, it is crucial
to simulate data matching real-world phenomenology. DIRSIG output has to be further processed to
meet this need. DIRSIG yields sensor reaching radiance output relative to sensor speciﬁcations such
as aperture width. The ultimate goal is to process sampled data obtained by a representative of a real
Watt
world imaging scpectrometer. This process converts the sensor reaching radiance values ( cm
2 .m ) into
the digitally sampled values (Volt). In this process, we account for factors that exist in real-world
phenomenology such as ﬁlter effects, shot noise, readout noise, integration time, detector elements, and
analog to digital converters. An extensive treatment on this radiometric sampling process is given in
[13].
2495

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

4

Uzkent, Hoﬀman, and Vodacek

Motion Segmentation

This step provides us measurements that are associated to the tracks to correct prior estimations. In this
study, we use the background subtraction technique on the panchromatic images from RITMOS. Background subtraction is a simple technique that subtracts two frames to detect moving objects. These two
frames are the current frame I(x, y, k) at time k and the background frame IB (x, y) for x and y coordinates
of each pixel. The result ID (x, y, k) = abs(I(x, y, k) − IB (x, y)) is generaly applied an empirical threshold.
We apply the Median ﬁlter to the previous n − 1 number of frames in addition to the current frame to
generate a reference frame IB as
IB (x, y) = median{I(x, y, k − i)}, i = 0, 1, ..., n − 1.

(1)

The Median ﬁlter is a computationally efﬁcient method which makes it eligible for our tracking system.
It is especially applicable for background dominated scenes and it perfectly ﬁts in our system since we
only perform vehicular simulation. In this study, we consider 9 previous scans in addition to the current
scan to generate a background mask. In ﬁg. 3, you can see the generated background and foreground
mask at a time step in the given scenario.

(a)

(b)

(c)

Figure 3: (a) Panchromatic image (I) at k , (b) background mask generated by Median ﬁltering multiple
frames (n = 10), IB , (c) foreground mask after background subtraction, ID .
The resultant difference image (ﬁg.3c) is applied an empirically predetermined threshold. Next, we
apply the morphological closing operation to remove the noise due to lighting changes, tiny nonstationary objects, and other sources and ﬁll in the gaps.
The second step in the motion segmentation is deriving a possible true measurement for a target
based on the prior estimates matching the target features. By relying on the uniqueness of spectral
features we can tackle possible false negatives in the background subtraction algorithm. Overall foreground mask is estimated by adding the global foreground mask from the background subtraction and
local foreground mask from the feature matching as in ﬁg. 4. Finally, the connected component analysis
is applied to uniquely label extracted blobs.

5

Gaussian Sum Kalman Filter

The GSF represents a non-Gaussian distribution by a ﬁnite mixture of Gaussian distrubutions. It allows
us to implement a multiple model set strategy that can be crucial in multi-modal true target density
cases. The GSF together with intersection network concept might lead to an adaptive multiple model
set strategy in the junctions. This way, nonlinear true target density in the intersections can be better approximated which in turn results in directing the sensor to collect useful spectral features. The
state-space and covariance matrix of each density kernel is updated by a linear or nonlinear recursive,
2496

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

+

(

⇒

)=

(b)

(a)

Uzkent, Hoﬀman, and Vodacek

(c)

(d)

Figure 4: (a) A foreground mask generated by the background subtraction method, (b) pixels from four
different prior Gaussians whose spectra match the TOI, (zoomed on the targeted area) (c) the predictionbased foreground mask for the TOI after averaging the prior Gaussians in (b), (d) ﬁnal foreground mask.
Bayesian estimator such as the Kalman ﬁlter (KF), Extended Kalman ﬁlter (EKF), or Unscented Kalman
ﬁlter (UKF). We have both linear and nonlinear models, thus, the KF will be used to transit Gaussians
with linear models whereas the EKF is used for nonlinear ones.
Assume we have a process and observations, Xk−1 and Yk−1 = {yk−1 |i = 1, 2, ..., k − 1}, the uncertainty Pk|k−1 associated with the state vector Xk is determined by p(Xk |Yk−1 ). The GSF estimates the
prior mean and uncertainty of the mixture as
n
),
xk|k−1 = ΣNn=1 wnk−1 (Xk−1|k−1

pk|k−1 =

(2)

n
n
n
ΣNn=1 wnk−1 ([Pk−1|k−1
(Xk−1|k−1
− xk|k−1 )(xk|k−1 − Xk−1|k−1
)T ]

(3)

where xk|k−1 and pk|k−1 are the expected mean and covariance of the prior mixture and wnk−1 and N represent the weight for the nth Gaussian kernel and number of kernels. The expected mean and covariance
of the posterior density p(Xk |Yk ) is estimated in the same way. A more detailed documentation of the
GSF in a similar adaptive multi-modal sensor-inspired tracking system is explained in [16, 17].

6

Spectral Feature-Aided Identiﬁcation

Data association is required to successfully correct prior target density p(Xk |Yk−1 ) with observations yk .
In this study, we propose a two step data association method. In the ﬁrst step, we rely on the strength
of spectral features to eliminate spectrally unlikely validated measurements within a gate drawn by the
ﬁlter. By doing so, we can both decrease the complexity of the cost function and increase identiﬁcation
accuracy. In the next step, a multi-dimensional assignment algorithm (MDA) is employed to formulate
the assignment problem [4].

Segmented
Blobs

Kinematic
Elimination

Spectral
Elimination

Formulate
Assignment
Algorithm

Cost
Minimization

Figure 5: Target classiﬁcation workﬂow.

6.1

Validating Measurements via Spectral Features

Two kinds of spatial sampling are performed to feed the sensor for spectral data acquisition. The ﬁrst
is prediction-based spatial sampling. In this case, the sensor is tasked to collect spectral data without
any prior knowledge of segmented blobs. Therefore, sampling is performed by taking a subset of the
pixels from where the ﬁlter predicts the target will be. This process is repeated for each Gaussian,
2497

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

Uzkent, Hoﬀman, and Vodacek

n
Xk|k−1
= {n = 1, 2, ..N}, in the GSF. The Gaussians that spectrally match the TOI are averaged to get
an additional blob on top of the segmented blobs generated by the background subtraction step as in
ﬁg. 4. The second one is measurement-based sampling. This sampling process is implemented with the
knowledge of segmented blobs. The sensor is tasked to collect full spectra at the pixels in the vicinity
of a blob centroid. The second step can be very beneﬁcial in the non-Gaussian target density case since
the prediction-based sampling might fail in collecting target data. The Spectral Angle Mapper (SAM)
is used to measure the similarity of spectral vectors. An extensive treatment on the SAM metric can be
found in [16]. The proposed algorithm to spectrally validate measurements is displayed below.

Form feature matrix Dbk for each ﬁlter-validated foreground blob b = 1, ..., B;
for t = k − 1, ..., 2 do
if the target is not lost at t then
Fkb ←− mean{min{SAM(Dbk , Dtmatch )}, min{SAM(Dbk , Duser
1 )}};
for b = 1, ..., B do
if Fkb > SAM T hreshold then
eliminate it;
end
end
break;
end
end
Algorithm 1: The proposed feature matching algorithm for blob elimination.

6.2

Data Association

The MDA algorithm, ﬁrst proposed by [12], considers S number of past scans to formulate the data
association problem. This is why it is also named as the S − D assignment algorithm. In 2-D case,
only the current scan, k, is used for assignment. This computationaly cheap method suffers from two
major drawbacks: the lack of time depth and information on target motion evolution. By considering
a sufﬁcient number of scans (S > 2), a data association algorithm may be able to better approximate
the evolution of the target trajectory. This way, the time depth issue is resolved. Also, we can improve
false assignments with upcoming measurements. This is especially beneﬁcial in maintaining the track
in challenging scenarios. By doing so, the decisions are softened. The major drawback of this approach
is that it is a non-deterministic polynomial time hard (NP-hard) problem for S ≥ 3 whereas the 2-D
assignment algorithm can be solved in quasi-polynomial time. This method becomes infeasible for real
time tracking with an increasing number of tracks (v > 10). However, it ﬁts perfectly in our system
since we are interested in single (v < 2), user selected target and simplify the minimization problem by
reducing the number of ﬁlter-validated measurements through feature matching (Fkb > T hreshold).
We will provide a brief overview of how the MDA is implemented in our case. Extensive documentation on it can be found in [7]. A binary assignment variable s is deﬁned as
⎧
⎨ 1
s(k, {ys }ks=k−S+2 , v) =
⎩ 0

yk , yk−1 , ..., yk−S+2 is assigned to T v (k − S + 1)
otherwise

,

(4)

where ys = 0, 1, ..., M(s) and v = 0, 1. M denotes the spectrally validated measurement list at scan s and
ys = 0 and v = 0 corresponds to the dummy measurement and nonexistant target. The multi-dimensional
2498

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

Uzkent, Hoﬀman, and Vodacek

assignment algorithm is then formulated as
M(k−S+2) M(k−S+3) M(k−S+4)

C(k|A) =

∑

∑

∑

yk−S+2 =0 yk−S+3 =0 yk−S+4 =0

M(k)

.....

∑ s(k, {ys }ks=k−S+2 , 1)c(k, {ys }ks=k−S+2 ),

(5)

yk =0

where A contains the candidate tuples (set of measurements) and c is the cost function that evaluates the
association cost. The goal is to ﬁnd the tuple a ∈ A that minimizes the overall association cost C. The
association cost formula in our case is given by
c(k, {ys }ks=k−S+2 ) = −ln(

φ (k, {ys }ks=k−S+2 , 1)
φ (k, {ys }ks=k−S+2 , 0)

),

where φ represents the association likelihoods. For v = 1 and v = 0, it is estimated as
⎧
⎨ ∏ (1 − P )1−u(ys ) (P τ(s, y ))u(ys )
v=1
D
D
s
s
,
φ (k, ys , v) =
⎩ ∏ V −u(ys )
v=0
s
⎧
⎨ 1
ys > 0
u(ys ) =
,
⎩ 0
y =0

(6)

(7)

(8)

s

where V and τ denote the volume of the surveillance area and the ﬁlter-based likelihood function. τ is
deﬁned as
τ(s, ys ) = N(ys ; h(xs|s−1 ), S),

(9)

where h1 and S represent the measurement function and innovation uncertainty. Finally, the tuple, a =
n
n
, ..., Xk−S+2|k−S+1
.
{yk , ..., yk−S+2 }, minimizing the cost function is used to update prior estimates Xk|k−1

7

Road Network Constrained Filtering

In a given scenario, we aim to cover all possible paths a target can follow in a particular time step so
that we can collect target spectral data in prediction-based sampling. On a straight road there is no
need for assigning a turn model since the likelihood of a manuever is extremely low and noise can
account of non-straight paths. On the other hand, on an intersection a target is very likely to change its
direction. For this reason, in this paper, speciﬁc motion models are adaptively removed/inserted in the
GSF based on the external intersection map. OpenStreetMap data-based intersection extraction is given
extensive treatment in [3].On a straight road, the Stop model is employed in about 10% of the Gaussians
whereas the remaning ones are given the Constant Velocity (CV) model with low or high amount of
noise to account for rapid or slow accelarations [6]. Meanwhile, in the intersections, around 60% of the
Gaussians are applied left or right turn models whereas the other 30% and 10% are applied the CV and
Stop models [9].

8

Simulation Results

We focus on three metrics to evalute tracking and identiﬁcation performance in the given scenarios.
First, the Root Mean Square Error (RMSE) metric is considered to measure positioning accuracy in EastNorth-Up (ENU) real world coordinates since we utilize this coordinate system in DIRSIG simulation.
1 In this study we use a linear measurement model since the measurements are extracted in cartesian coordinates. The measurement model considers the central coordinates and physical dimensions of a blob.

2499

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

Uzkent, Hoﬀman, and Vodacek

The second performance metric is track purity (TP). It measures how many frames a tracker maintains a
correct track identity within an estimated gate of the actual target position during the track life. Finally,
the Current Assignment Ratio (CAR) metric is utilized to measure the ratio of maximum number of
times a ground truth is associated to a track to the duration of ground truth. Details on these metrics can
be found in [2].
The proposed spectral feature-aided tracking (SFAT) system is compared to a (1) kinematic only
tracker (KT) and a (2) spectral only tracker (ST). This way, the beneﬁt of further reduction of validated
measurements in target identiﬁcation is evaluated. In the KT method, spectral features are ignored
whereas in the ST, only SAM scores in the last scan, k, are considered. In the SFAT and KT cases,
experiments are performed with S = 6 in the S-D assignment algorithm as it is a widely accepted value
in the literature. The number of Gaussians in the GSF is 33 in all cases. Obviously, more Gaussians can
be employed to better approximate true target density at a higher computational cost. A hundred Monte
Carlo runs were carried out for each TOI. A track is terminated when it has not been associated with
any measurement for more than 7 s. Fig. 6 displays the RMSE results whereas table 1 displays TP and
CAR scores.

RMSE (m)

150

KT
ST
SFAT

100

150

KT
ST
SFAT

100

100

100

KT
ST
SFAT

KT
ST
SFAT

50
50
0

50

50
20

40 60
Time Step

80

0

0

20

(a)

40
60
Time Step

80

0

(b)

20

40
60
Time Step

80

0

(c)

20

40
60
Time Step

(d)

Figure 6: RMSE results for the 1st (a), 2nd (b), 3th (c), and 4th (d) TOI.

Track Purity (%)

Current Assignment Ratio (%)

Tracker/ID

1st

2nd

3th

4th

Overall

1st

2nd

3th

4th

Overall

KT (6-D)

49.03

77.82

38.05

38.37

50.82

20.85

70.52

36.70

37.45

41.38

ST (2-D)

20.01

65.04

87.48

50.24

55.69

4.82

65.04

87.48

43.63

50.24

SFAT (6-D)

80.14

81.89

94.61

89.63

86.57

70.80

81.09

94.26

89.63

83.95

Table 1: TP and CAR scores for TOIs. Reasonable SAM threshold values were used in the experiments.
(1st TOI Threshold - 0.05, 2nd TOI Threshold - 0.15, 3th TOI Threshold - 0.15, 4th TOI Threshold 0.25)
The KT method suffers from vehicles with similar trajectories in cluttered scenes. In addition,
severe obscurations have a higher impact on the KT than the SFAT and ST. On the other hand, the SFAT
and ST handle these challenges by eliminating vehicles with similar trajectories utilizing the spectral
signatures. Furthermore, if we can capture spectral features from the obscured target once it becomes
visible, then we can re-associate the track with the true measurements. The ST method performs poorly
in scenarios with many vehicles having similar paint models regardless of their kinematic features. The
SFAT method accomplishes higher tracking rates since it utilizes kinematic features in a scene with
many similar vehicles. It performs relatively poor in the ﬁrst TOI case due to the very high density of
2500

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

Uzkent, Hoﬀman, and Vodacek

spectrally similar vehicles to the TOI.
One major drawback of the current feature-aided method is its sensitivity to the spectral threshold.
A proper threshold for the ﬁrst (white) car does not work well for the other TOIs (red, blue, red). As
seen in table 2, tracking rates for the ﬁrst TOI drop dramatically for the threshold values 0.15, 0.2, 0.25,
and 0.3. On the other hand, for the other TOIs, 0.15 is the global optimum value in terms of overall
rates. Main reason for this sensitivity is that the radiometric sampling process is a function of the sensor
reaching radiance magnitude. Therefore, spectral data is effected by a lesser amount of noise for the
ﬁrst TOI than the others due to its higher signal level. This leads to sensitivity in the spectral threshold.
By comparing the table 2 to table 1, one can notice that 4 − D assignment algorithm outperforms the
6 − D one in the ﬁrst TOI case. The main reason behind this is the severe occlusions in the scene. If
the sufﬁcient prior estimates at time k − S + 1 are not corrected, then the ﬁlter diverges. In this case, the
algorithm is more vulnerable and likely to assign a false tuple. Therefore, there is no guarantee of more
persistent tracking with the increasing number of dimensions in the S − D assignment algorithm.
Spectral Feature-Aided Tracking
Track Purity (%)

Current Assignment Ratio (%)

Threshold

1st

2nd

3th

4th

Overall

1st

2nd

3th

4th

Overall

0.05

88.43

14.29

14.28

100.00

54.25

88.43

1.16

1.11

9.21

24.98

0.10

68.80

87.36

14.51

94.27

66.24

65.59

86.46

1.24

92.39

61.42

0.15

51.71

77.04

97.11

95.07

80.23

40.39

76.05

97.11

95.07

77.16

0.20

46.89

80.09

73.48

92.17

73.16

25.25

80.09

65.42

91.24

65.50

0.25

8.28

79.80

76.88

88.36

63.33

7.27

79.34

69.60

88.36

61.14

0.30

6.96

79.63

15.44

72.52

43.64

6.36

77.93

14.36

69.71

42.09

Table 2: TP and CAR scores for the SFAT with different SAM thresholds. (4-D assignments)

9

Conclusions

Inserting spectral features in a wide area air-to-ground surveillance system can increase the persistency
of tracking in cases where a single modality struggles. For this reason, we consider an adaptive multimodal performance-driven sensor capable of adaptive spectral data acquisition. Discriminative spectral
features are inserted into the tracking algorithm to exclude outliers in data association. This way, cost
minimization problem is simpliﬁed and false assignments are reduced. In addition, only around 1.5%
of the spectral data of the full scene is collected in each revisit, which makes real time spectral databased tracking feasible as long as it does not require high frame rate. One current issue, however, is
the feature-aided system is highly sensitive to the emprical spectral threshold. In the future, we plan on
fusing spectral and kinematic likelihoods in a Bayesian fashion to decrease the sensitivy of the spectral
threshold in feature matching without degrading tracking accuracy rates.

10

Acknowledgements

This work is supported by the Dynamic Data Driven Applications Systems Program, Air Force Ofﬁce
of Scientiﬁc Research, under Grant FA9550-11-1-0348.
2501

Spectral Validation of Measurements in a Vehicle Tracking DDDAS

Uzkent, Hoﬀman, and Vodacek

References
[1] M Sanjeev Arulampalam, Neil Gordon, Matthew Orton, and Branko Ristic. A variable structure multiple
model particle ﬁlter for GMTI tracking. In Information Fusion, 2002. Proceedings of the Fifth International
Conference on, volume 2, pages 927–934. IEEE, 2002.
[2] Erik P Blasch and Pierre Valin. Track purity and current assignment ratio for target tracking and identiﬁcation
evaluation. In Information Fusion (FUSION), 2011 Proceedings of the 14th International Conference on,
pages 1–8. IEEE, 2011.
[3] Bin Chen, Weihua Sun, and Anthony Vodacek. Improving image-based characterization of road junctions,
widths, and connectivity by leveraging OpenStreetMap vector map. In Geoscience and Remote Sensing Symposium (IGARSS), 2014 IEEE International, pages 4958–4961. IEEE, 2014.
[4] Somnath Deb, Murali Yeddanapudi, Krishna Pattipati, and Yaakov Bar-Shalom. A generalized SD assignment
algorithm for multisensor-multitarget state estimation. Aerospace and Electronic Systems, IEEE Transactions
on, 33(2):523–538, 1997.
[5] Emmett J Ientilucci and Scott D Brown. Advances in wide-area hyperspectral image simulation. In AeroSense
2003, pages 110–121. International Society for Optics and Photonics, 2003.
[6] T Kirubarajan and Y Bar-Shalom. Tracking evasive move-stop-move targets with a GMTI radar using a
VS-IMM estimator. Aerospace and Electronic Systems, IEEE Transactions on, 39(3):1098–1103, 2003.
[7] Thiagalingam Kirubarajan, Yaakov Bar-Shalom, Krishna R Pattipati, and Ivan Kadar. Ground target tracking
with variable structure IMM estimator. Aerospace and Electronic Systems, IEEE Transactions on, 36(1):26–
46, 2000.
[8] Daniel Krajzewicz, Georg Hertkorn, C R¨ossel, and P Wagner. Sumo (simulation of urban mobility). In Proc.
of the 4th middle east symposium on simulation and modelling, pages 183–187, 2002.
[9] X Rong Li and Vesselin P Jilkov. Survey of maneuvering target tracking. Part I. Dynamic models. Aerospace
and Electronic Systems, IEEE Transactions on, 39(4):1333–1364, 2003.
[10] Reed D Meyer, Kevin J Kearney, Zoran Ninkov, Christopher T Cotton, Peter Hammond, and Bryan D Statt.
RITMOS: a micromirror-based multi-object spectrometer. In Astronomical Telescopes and Instrumentation,
pages 200–219. International Society for Optics and Photonics, 2004.
[11] Oliver Payne and Alan Marrs. An unscented particle ﬁlter for GMTI tracking. In Aerospace Conference,
2004. Proceedings. 2004 IEEE, volume 3. IEEE, 2004.
[12] Aubrey B Poore. Multidimensional assignment formulation of data association problems arising from multitarget and multisensor tracking. Computational Optimization and Applications, 3(1):27–57, 1994.
[13] Andrew Rice, Juan Vasquez, Michael Mendenhall, and John Kerekes. Feature-aided tracking via synthetic
hyperspectral imagery. In Hyperspectral Image and Signal Processing: Evolution in Remote Sensing, 2009.
WHISPERS’09. First Workshop on, pages 1–4. IEEE, 2009.
[14] Jeongho Shin, Sangjin Kim, Sangkyu Kang, Seong-Won Lee, Joonki Paik, Besma Abidi, and Mongi Abidi.
Optical ﬂow-based real-time object tracking using non-prior training active feature model. Real-Time Imaging,
11(3):204–218, 2005.
[15] Abhijit Sinha, Thiagalingam Kirubarajan, and Yaakov Bar-Shalom. Autonomous ground target tracking by
multiple cooperative UAVs. In Aerospace Conference, 2005 IEEE, pages 1–9. IEEE, 2005.
[16] Burak Uzkent, M Hoffman, Anthony Vodacek, and Bin Chen. Feature Matching with an Adaptive Optical
Sensor in a Ground Target Tracking System. IEEE Sensors Journal, 15(1):510–519, 2015.
[17] Burak Uzkent, Matthew J Hoffman, Anthony Vodacek, John P Kerekes, and Bin Chen. Feature Matching
and Adaptive Prediction Models in an Object Tracking DDDAS. Procedia Computer Science, 18:1939–1948,
2013.
[18] Junqiu Wang and Yasushi Yagi. Integrating color and shape-texture features for adaptive real-time object
tracking. IEEE Transactions on Image Processing, 17(2):235–240, 2008.
[19] Huiyu Zhou, Yuan Yuan, and Chunmei Shi. Object tracking using SIFT features and mean shift. Computer
vision and image understanding, 113(3):345–352, 2009.

2502

