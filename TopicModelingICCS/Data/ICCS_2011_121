Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1383–1392

International Conference on Computational Science, ICCS 2011
Algorithm for waiting time distribution of a discrete-time multiserver queue with
deterministic service times and multi-threshold service policy
Feng Wei1,∗
Graduate School of Scientiﬁc and Engineering Simulation
Nagoya Institute of Technology

Abstract
In this paper, a discrete-time multiserver queueing system with inﬁnite buﬀer size is studied. Packets arrive at the
system according to a Bernoulli arrival process, and the service times of the packets are assumed to be constant equal
to an integer multiple of slots. The number of active servers in the system is controlled by a so-called multi-threshold
service policy with a set of thresholds predeﬁned. For this multiserver system, we derive its stationary waiting time
distribution by using the stochastic complement and Crommelin’s techniques. We also present an algorithm for
computing the stationary waiting time distribution.
Keywords: discrete-time queue, multi-threshold service policy, stochastic complement, Crommelin’s technique

1. Introduction
Discrete-time queueing models have been used to analyze the performance of digital communication systems,
such as multiplexers and packet switches. In such models, the time axis is divided into ﬁxed-length time intervals,
referred to as slots. Arrivals and services (transmission) of packets can start or end at slot boundaries only. The models
have been studied under various assumptions with respect to packet arrival processes and service-time distributions
(see [2]-[7], [10]-[12], [16]). In particular, the works for the discrete-time multiserver systems with constant service
times have received extensively attention in the literature. Crommelin [7] presented a very simple approach for the
M/D/c system by studying it as a batch service system. Crommelin’s idea was also discussed and generalized to the
MAP/D/c system in Neuts [15]. Now, the method is known as Crommelin’s technique and has been applied by other
researchers in analyzing the multiserver systems with constant service times. Nishmura [16] studied the MAP/D/N
system in continuous-time based on this idea and used spectral technique for the analysis. Franx [10] presented a
simple solution for the M/D/c waiting times. Recently, Chaudhry et al. [6] and Alfa [3] analyzed the discrete-time

∗

Email address: feng.wei@nitech.ac.jp (Feng Wei)
author: Tel. +81-052-735-5384

1 Corresponding

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.149

1384

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

MAP/D/k system using Crommelin’s technique and presented the eﬃcient computational algorithms for the waiting
time distribution.
In this paper, we also consider a discrete-time multiserver system with constant service times, but the system is
controlled by a so-called multi-threshold service policy. Under this service discipline, the number of servers employed
in service at any discrete-time is governed by a threshold sequence F ≡ {F1 , F2 , · · · , F K−1 } of positive integers such as
F1 < F2 < · · · < F K−1 . For notational convenience, we set F0 = 0 and F K = ∞. When a customer arrives at an empty
system, he/she is served by a single server. Whenever the number of customers is greater than or equal to a threshold
Fk , a server is added to the system and immediately starts to serve. Similarly, whenever the number of customers falls
below the threshold Fk , a server is removed from the system. As a simple and eﬃcient control scheme, the thresholdbased service policies have been widely used in the continuous-time multiserver queueing systems (see [12], [13], [8],
[9]). To the best of our knowledge, however, no researches have been conducted for the discrete-time system with
the multi-threshold service policy. For such the system, the variety of the number of active servers (being in service)
complicates the analysis of the system performance. First, Crommelin’s idea can not be applied directly as it has
been done in [3], [6], [7] and [16], where the analysis was carried out by focusing on the behavior of a ﬁxed server.
Secondly, the waiting time of any customer is aﬀected not only by the number of the customers ahead of him on arrival
epoch, but also by the further arriving situation of customers, since this may result in an increase or decrease of the
number of active servers. For this sake, in this paper we derive the stationary waiting time distribution in two steps:
ﬁrst we verify that the waiting time distribution in our queueing system is the same as that of the last arriving customer
in a discrete-time single server queueing system with bulk service, the size of which is controlled by F. For this single
server queueing system, we derive the steady state distribution of the queue length using a combination technique
of stochastic complement and Crommelin’s methods. Next, we compute the stationary waiting time distribution by
introducing an inﬁnite absorbing discrete-time Markov chain with an appropriate state space. The waiting time of a
customer is given by the time until absorption. Hence, the stationary waiting time distribution is of phase type.
The remainder of the paper is organized as follows. In Section 2, we describe the queueing model in detail and
give some preliminary results. In Section 3, we perform the analysis of the queueing system. Instead of working on
the original multiserver queueing system, we consider a single server queue that has the same waiting time distribution
and derive its steady-state distribution of the queue length using Crommelin’s and stochastic complement ideas. In
Section 4, we introduce an absorbing Markov chain to describe the dynamics of the system after the tagged customer
arrived and derive the stationary waiting time distribution. We also present an algorithm for computing this stationary
distribution. Finally, some conclusions are included in Section 5.
2. Model and Preliminaries
In this section, we describe the discrete-time queueing model in detail, and present a brief introduction to the
concepts of Crommelin and stochastic complementation, and some related results.
2.1 The discrete-time queueing model
Consider a Geo/D/K queueing system in discrete-time. Customers arrive at the system according to a Bernoulli
process with parameter λ. The service times of the customers are constant equal to d slots. The distribution of the
deterministic service times can be represented as the phase type distribution (α, S ) as in [3] and [6], where α =
0 Id−1
[1, 0, · · · , 0], S =
and I j is an identify matrix of order j. All arrivals occur just after the beginning of
0
0
a slot, and departures take place just before the end of a slot. K servers serve the customers by following the multithreshold service scheme with F as follows. When a customer arrives at an empty system, it is served by a single
server. Whenever the number of customers is greater than or equal to the threshold Fk , a server is added to the system
and immediately starts to serve. Similarly, whenever the number of customers falls below the threshold Fk , a server
is removed from the system. We deﬁne the traﬃc intensity ρ = λd/K and assume that ρ < 1 for the stability of the
system. Furthermore, we assume that the service discipline is FIFO and that the servers serve customers in the cyclic
service order.
2.2 Crommelin’s method
For an M/D/k queueing system, Crommelin’s method presents actually a study of customers j, k+ j, 2k+ j, · · · , vk+
j, · · · (e.g., j = 1) in a single server system where the single server is the jth server in the multiserver system, under

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

1385

assumptions of the FIFO service discipline and cyclic service order. Alternatively, this can also be looked as studying
a system of group service queue with a single server in which the server attends to exactly a group of k customers at
a time [3]. Crommelin [7] showed that the stationary distribution of the queue length at arbitrary time in the M/D/k
model is the invariant probability vector in this group service queue. Neuts [15] extended the Crommelin’s results to
the MAP/D/k model. Recently, this idea has also been used in studying the waiting time distribution for a discretetime MAP/D/k model by Chaudhry et al. [6] and Alfa [3], based on the fact that the waiting time distribution of an
arbitrary customer in the MAP/D/k model is the same as that of the last arriving customer in a group of k customers
at a time.
For the discrete-time Geo/D/K queueing model considered in the present paper, since the number of servers
added into service is controlled by the multi-threshold service scheme, the associated single server model with group
service, in fact, is one with varying group service size. Concretely, when the number of the customers is between the
thresholds Fk−1 and Fk , the size of group service in the single server model is k. Hence, Crommelin’s approach that
only observes the behavior of a ﬁxed server is not directly applicable in our model. For this reason, we will decompose
the system into K sub-systems using the concept of stochastic complementation described below, and then for each
sub-system, we apply Crommelin’s idea to derive its steady-state distribution.
2.3 Stochastic complementation
Here, we state brieﬂy the concept of stochastic complementation and quote some useful results from [12]. For a
given irreducible discrete time Markov chain M with state space S, let us partition this state space into two disjoint
sets A and B. Then, the one-step transition probability matrix of M is
P=

PA,A
PB,A

PA,B
PB,B

and the corresponding steady state probability vector is π = [πA , πB ]. The stochastic complement of PA,A is deﬁned by
the matrix C A,A = PA,A + PA,B [I − PB,B ]−1 PB,A . For the stochastic complement matrix C A,A and steady state probability
πA , then, the following results hold.
Proposition 2.1 (i) C A,A is always a stochastic matrix and the associated Markov chain is always irreducible, if the
original Markov chain is irreducible. (ii) Let π|A be the steady state probability vector for the stochastic complement
C A,A , then π|A = 1/(πA e)πA , where e is the column vector with all entries equal to 1.
The implication of the above theorem is that the steady state probabilities of the stochastic complement are the
conditioned steady state probabilities of the associated states of the original Markov chain. For more details on the
stochastic complement concept, refer to [12] and the references therein.
3. Analysis of the model
We observe the Geo/D/K queueing system with the multi-threshold service scheme just after the arrivals. Then,
its dynamics can be described by a multi-dimensional Markov process M = {(Ln , S n , Kn ), n ≥ 0}, where Ln ,
S n = (S 1n , S 2n , · · · , S Kn n ) and Kn denote, respectively, the number of customers, the remaining service time vector and number of the active servers (being in service) at the nth slot. The state space of M is given by S =
{(l, (s1 , s2 , · · · , sk ), k) | l ≥ 0, 1 ≤ si ≤ d; 1 ≤ i ≤ k, 1 ≤ k ≤ K}. Note that the random variable Kn may be
dropped, because according to the multi-threshold service scheme, we know that the number of the active servers
is k when the number of customers is in the range Fk−1 ≤ l < Fk . However, we remain it here for the sake of
descriptive completeness. By the analogous arguments in Crommelin [7], Neuts [14] and Chaudhry et al. [6], we
conclude that under the assumptions of FIFO and cyclic service scheme, the waiting time distribution of an arbitrary
customer in the system with the multi-threshold service scheme is the same as that of the last arriving customer in a
group in a single MAP/D/1 queueing system with bulk service, the size of which is controlled by the multi-thresholds
F. Instead of our original Geo/D/K queueing system, therefore, we analyze its associated single server MAP/D/1
queueing system. The dynamics of this queueing system can be described by the multi-dimensional Markov process
M∗ = {(Ln , Jn , S n , Kn ), n ≥ 0}, where Ln , Jn , S n and Kn denote, respectively, the number of customers, phase of
the Markov arrival process, remaining group service time and the bulk size (i.e., the number of the active servers) at
the nth slot. We refer M∗ to as the associated process of the original Markov chain M. The state space of M∗ is

1386

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

given by S∗ = {(l, j, s, k), | l ≥ 0, 1 ≤ j ≤ k, 1 ≤ s ≤ d, 1 ≤ k ≤ K}. As mentioned before, due to the controlled
number of active servers, Crommelin’s idea can not be applied directly in deriving the steady state distribution of M∗ .
In this section, we divide the derivation of the stationary distribution into the following three steps. First, according
to the number of the active servers, we partition the state space into K disjoint state sub-spaces using the concept of
stochastic complementation, and corresponding to each sub-state space, we deﬁne an Markov chain on it. Since the
number of active servers is ﬁxed on each sub-state space, this allows us to apply Crommelin’s idea in computing the
steady-state distribution of the sub-Markov chain. In fact, this steady state distribution is a conditional steady state
probability vector, given that the Markov chain M∗ is in that sub-state set. Secondly, we aggregate each sub-state
space into a single state and compute the steady state probabilities of the system being in any aggregated state. Lastly,
we utilize these steady state distributions to compute the (unconditional) steady state probabilities of the associated
Markov chain M∗ .
3.1 The partition of the state space S and deﬁnition of the associated Markov processes
For the sake of clarity, we begin with the decomposition of the original Markov process M, and then establish a
decomposition of the associated Markov process M∗ . For the Markov process M, let us partition its state space S into
K disjoint sets Sk such as: S1 = {(0, 0, 0), (l, (s1 ), 1) | 1 ≤ l < F1 , 1 ≤ s1 ≤ d}, Sk = {(l, (s1 , · · · , sk ), k) | Fk−1 ≤ l <
Fk , 1 ≤ si ≤ d; 1 ≤ i ≤ k}, k = 2, · · · , K − 1 and SK = {(l, (s1 , · · · , sK ), K) | F K−1 ≤ l < ∞, 1 ≤ si ≤ d; 1 ≤ i ≤ K}.
In each sub-state space Sk , the lexicographical order is deﬁned. Corresponding to Sk , we introduce an Markov chain
Mk with the transition structure similar to that of M in Sk , except for the following modiﬁcations: (1) for k = 1
and 2 ≤ s1 ≤ d, a transition from (F1 − 1, (s1 ), 1) to (F1 , (s1 − 1), 2) with probability λ in the original process M is
replaced by a transition from (F1 − 1, (s1 ), 1) to (F1 − 1, (s1 − 1), 1) with probability 1. (2) for 2 ≤ k ≤ K − 1, note
that due to a single arrival, the cyclic service order and constant service times, we have that all the remaining service
times, s1 , · · · , sk are diﬀerent. Without loss of generality, we assume that s1 > s2 > · · · > sk . Then, a transition from
(Fk−1 , (s1 , · · · , sk−1 , 1), k) to (Fk−1 −1, (s1 −1, · · · , sk−1 −1), k−1) with probability 1−λ in the Markov chain M is replaced
by a transition from (Fk−1 , (s1 , · · · , sk−1 , 1), k) to (Fk−1 , (s1 − 1, · · · , sk−1 − 1, d), k) with probability 1, and for 2 ≤ si ≤
d, i = 1, · · · , k, a transition from (Fk − 1, (s1 , · · · , sk ), k) to (Fk , (s1 − 1, · · · , sk − 1, d), k + 1) with probability λ in the
Markov chain M is replaced by a transition from (Fk −1, (s1 , · · · , sk ), k) to (Fk −1, (s1 −1, · · · , sk −1), k) with probability
1, and (3) for k = K, a transition from (F K−1 , (s1 , · · · , sK−1 , 1), K) to (F K−1 − 1, (s1 , · · · , sK−1 ), K − 1) with probability
1 − λ in the Markov chain M is replaced by a transition from (F K−1 , (s1 , · · · , sK−1 , 1), K) to (F K−1 , (s1 , · · · , sK−1 , d), K)
with probability 1. These modiﬁcations are mainly based on the observation that there exists only a single return and
entry among Sk , k = 1, 2, · · · , K in the original Markov chain, and the transition rates do not depend on the states of
the remaining service time. According to this fact and Proposition 2.1, we obtain the following result for the Markov
chains Mk .
Proposition 3.1. The steady state probabilities of the Markov chain Mk is the conditional steady state probabilities
for the states in Sk of the original Markov chain M, given that the system is in partition Sk .
For each k, Mk describes the dynamics of the Geo/D/k queueing system with the ﬁnite state space Sk . For this
model, we can use Crommelin’s idea because the number of active servers is k, ﬁxed. That is, we can consider an
equivalent queueing system by observing the behavior of the server who is just added in service when the number
of the customers exceeds Fk−1 . This queueing model is one with a single server and Markovian arrival process,
namely, D − MAP(C ∗(k) , D∗(k) )/D/1. For the proof of the equivalence, see Proposition 1 in [6]. Here, C ∗(k) and D∗(k)
are, respectively, k−dimensional square matrices implying the transition probability of the phase of the underlying
Markov chain without and with arrivals such that
⎛ ¯
⎞
⎛
⎞
⎜⎜⎜ λ λ
⎟⎟⎟
⎜⎜⎜
⎟⎟⎟
⎜⎜⎜
⎟⎟⎟
⎜⎜⎜⎜
⎟⎟⎟⎟
.. ..
⎜⎜⎜
⎟
⎟⎟⎟
.
.
⎜⎜⎜
⎟⎟⎟
∗(k)
∗(k)
⎜
C
= ⎜⎜⎜
= ⎜⎜⎜
D
⎟⎟⎟
⎟⎟⎟⎟ ,
..
⎜⎜⎜
⎜⎜⎜
⎟⎟⎟
. λ ⎟⎟⎟⎟
⎜⎜⎝
⎜
⎟⎠
⎝
¯λ ⎠
λ
where λ¯ = 1 − λ. For the D − MAP(C ∗(k) , D∗(k) )/D/1 queueing system, we consider the Markov process M∗k =
{(Ln , Jn , S n , k); n ≥ 0}, where Ln , Jn and S n denote, respectively, the number of customers, phase of the Markov arrival
process MAP(C ∗(k) , D∗(k) ), and remaining service time at the nth slot. Then, M∗k is a ﬁnite quasi-birth-death (QBD)

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

1387

process on the state space S∗k = {(l, j, s, k) | Fk−1 ≤ l < Fk ; 1 ≤ j ≤ k; 1 ≤ s ≤ d}. Its transition probability matrix
will be given below. The processes M∗k = {(Ln , Jn , S n , k); n ≥ 0}, in fact, describe the dynamics of M∗ when its state
is limited in the state space S∗k . Therefore, we have that the steady state probabilities of M∗k is the conditional steady
state probabilities for the states in S∗k of the associated Markov chain M∗ , given that the system is in partition S∗k .
3.2 The steady state probabilities of M∗k
In this sub-section, we derive the steady state probabilities of the Markov chain M∗k , k = 1, 2, · · · , K. For M∗1 , we
¯ 1×1 , D∗(1) = (λ)1×1 because of only one active server (hence, j ≡ 1, we can think M1 = M∗ ). The
have C ∗(1) = (λ)
1
transition probability matrix of the Markov chain M∗1 with the state space S∗1 is given as follows:
⎤
⎡ (1)
(1)
⎥⎥⎥
⎢⎢⎢ B00 B01
⎥⎥⎥⎥
⎢⎢⎢⎢ B(1) A(1) A(1)
⎥⎥⎥
⎢⎢⎢ 10
1
2
(1)
(1)
(1)
⎥⎥⎥
⎢⎢⎢
A
A
A
0
1
2
⎥⎥⎥
⎢⎢⎢
(1)
⎥⎥⎥
⎢
.
.
.
P = ⎢⎢
..
..
..
⎥⎥⎥
⎢⎢⎢
⎥⎥
⎢⎢⎢
..
⎥⎥⎥
⎢⎢⎢
(1) ⎥
. A(1)
A
⎢⎣⎢
1
2 ⎥
⎦⎥
A(1)
C (1)
0
∗(1)
∗(1)
∗(1)
∗(1)
∗(1)
∗(1)
, B(1)
⊗α and B(1)
⊗s0 ; A(1)
⊗s0 α, A(1)
⊗s0 α+C ∗(1) ⊗S , A(1)
⊗S ,
where B(1)
00 = C
01 = D
10 = C
0 =C
1 = D
2 = D
(1)
∗(1)
0
0
T
and C = D ⊗ s α + (1)1×1 ⊗ S , here s = [0, · · · , 0, 1] . Let π|1 = ( π|1 (0), π|1 (1), · · · , π|1 (F1 − 1)) be the steady state
probability vector of the Markov chain M1 , where π|1 (0) = (π|1 (0, 1, 0, 1)) and π|1 (l) = (π|1 (l, 1, d, 1), · · · , π|1 (l, 1, 1, 1))
for l = 1, 2, · · · , F1 − 1. By direct calculation of the equations π|1 = π|1 P(1) , π|1 e = 1, we have the following result.

Theorem 3.1-1 For l = 1, 2, · · · , F1 − 1, s = 1, 2, · · · , d, π|1 (l, 1, s, 1) can be expressed in terms of π|1 (0, 1, 0, 1) as
follows:
π|1 (1, 1, s, 1) =

λ
π (0, 1, 0, 1),
¯λ s |1

π|1 (l, 1, s, 1) =

λ
λ¯ (l−1)d+s
+(−1)l (

−(

π|1 (2, 2, s, 1) = (

s

d

d

al−1,i and bl,s =

i=1

d+1

a4,i +

al−4,i (
i=1

i=1

i+

al−4,i
i=1

i=1

i=1

al−1,i )λl−1
) π|1 (0, 1, 0, 1)
λ¯ s+l−2

i=1

d

s

al−3,i + . . . +

a3,i
i=1

al−5,i
i=1

a5,i
i=1

d+s

i + ... +
i=1

s
i=1

d

s

al−2,i +

a2,i

i=1
d+3

al−4,i
i=1

d

s

al−1,i +
i=1
s−2

d+2

s−1

i) +

sλ2
λ
− )π (0, 1, 0, 1)
¯λ s+1 λ¯ s |1

s
l
(
bl,s λl−1
bl−1,s λl−2
l+1 ( i=1 al,i )λ
+
)
+
(−1)
(
+
¯λd+s+l−2
¯λd+s+l−3
¯λ s+l−1

i=1

+

λ¯ s+d

−

( (l−3)d+s
i)λ3 ((l − 3)d + s)λ2
((l − 2)d + s)λ2
λ
i=1
+
)
+
(
+
) + ···
λ¯ (l−2)d+s+1
λ¯ (l−2)d+s
λ¯ (l−3)d+s+2
λ¯ (l−3)d+s+1

s

where a2,s = 1, al,s =

λ

i. Moreover, π|1 (0, 1, 0, 1) can be determined
i=1

by the normalization condition
π|1 (0, 1, 0, 1) + π|1 (1, 1, 1, 1) + . . . + π|1 (1, 1, d, 1) + · · · + π|1 (F1 − 1, 1, 1, 1) + · · · + π|1 (F1 − 1, 1, d, 1) = 1.
Next, we consider the cases k = 2, 3, · · · , K − 1. For each k, M∗k is a ﬁnite quasi-birth-death (QBD) process on the
state space S∗k = {(l, j, s, k) | Fk−1 ≤ l < Fk ; 1 ≤ j ≤ k; 1 ≤ s ≤ d} with transition probability matrix of the block
tridiagonal form:
⎤
⎡ (k)
⎥⎥⎥
⎢⎢⎢ B
A(k)
2
⎥⎥⎥
⎢⎢⎢ (k)
(k)
A(k)
A
⎥⎥⎥
⎢⎢⎢ A0
1
2
⎥⎥⎥⎥
⎢⎢⎢⎢
.
.
(k)
..
..
⎥⎥⎥
P(k) = ⎢⎢⎢⎢
A0
⎥⎥⎥
⎢⎢⎢
.
⎢⎢⎢
. . A(k) A(k) ⎥⎥⎥⎥
⎥⎦
1
2 ⎥
⎢⎢⎣
A(k)
C (k)
0

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

1388

∗(k)
∗(k)
∗(k)
where B(k) = (C ∗(k) + D∗(k) ) ⊗ s0 α + C ∗(k) ⊗ S , A(k)
⊗ s0 α, A(k)
⊗ s0 α + C ∗(k) ⊗ S , A(k)
⊗ S and
0 =C
1 = D
2 = D
(k)
∗(k)
0
∗(k)
∗(k)
C = D ⊗ s α + (C + D ) ⊗ S , all are kd × kd matrices. Let π|k = (π|k (Fk−1 ), π|k (Fk−1 + 1), · · · , π|k (Fk − 1)) be
the steady state probability vector of the Markov chain M∗k , where π|k (l) = (π|k (l, d, k), π|k (l, d − 1, k), · · · , π|k (l, 1, k))
for l = Fk−1 , · · · , Fk − 1, and π|k (l, s, k) = (π|k (l, 1, s, k), π|k (l, 2, s, k), · · · , π|k (l, k, s, k)) for 1 ≤ s ≤ d. Furthermore, let
(k)
matrices R(k)
1 and R2 are, respectively, the unique minimal non-negative solutions of the quadratic matrix equations
(k)
(k)
(k)
(k)
(k)
2 (k)
R = A2 + RA1 + R2 A(k)
and R = A(k)
0
0 + RA1 + R A2 , and deﬁne the matrix B[R1 , R2 ] as follows:
(k)
B[R(k)
1 , R2 ] =

(k)
B(k) + R(k)
1 A0
(k) Fk −Fk−1 −2 (k) (k)
(R2 B + A(k)
(R2 )
0

−

Fk −Fk−1 −2 (k)
(k)
(R(k)
(A0 + R(k)
− R(k)
1 )
1 C
1 )
(k)
(k)
(k)
C + R2 A2

R(k)
2 )

.

Applying Theorem 1 in [1] yields the following result.
(k)
(k)
Theorem 3.1-2 Let v(k) = [v(k)
1 , v2 ], where vi , i = 1, 2 are a row vector of length d, be the left invariant eigen(k)
(k)
(k)
(k) (k)
(k) (k)
(k)
vector of B[R1 , R2 ] , i.e., v(k) = v(k) B[R1 , R(k)
=
2 ] normalized so that (v1 T 1 + v2 T 2 )e1 = 1 where T i
Fk −Fk−1 −1 (k) m
(R
)
,
i
=
1,
2.
Then,
the
steady
state
probability
vector
π
are
given
by
|k
i
m=0
(k) l
(k) (k) Fk −Fk−1 −(l+1)
π|k (Fk−1 + l) = v(k)
,
1 (R1 ) + v2 (R2 )

M∗K

l = 0, 1, · · · , Fk − Fk−1 − 1.

S∗K

with the state space
= {(l, j, s, K); F K−1 ≤ l < ∞; 1 ≤ j ≤ K, 1 ≤ s ≤ d} is a
Finally, the Markov chain
inﬁnite QBD process with the transition probability matrix of the form:
⎞
⎛ (K)
⎟⎟⎟
⎜⎜⎜ B
A2(K)
⎟⎟⎟
⎜⎜⎜ (K)
A1(K) A2(K)
⎟⎟⎟
⎜⎜⎜ A0
(K)
⎟⎟⎟
(K)
(K)
(K)
P = ⎜⎜⎜⎜
A
A
A
⎟⎟⎟
⎜⎜⎜
0
1
2
⎜⎝
..
..
. . ⎟⎟⎠
.
.
.
= C ∗(K) ⊗ s0 α, A1(K) = D∗(K) ⊗ s0 α + C ∗(K) ⊗ S and A(K)
=
where B(K) = (C ∗(K) + D∗(K) ) ⊗ s0 α + C ∗(K) ⊗ S , A(K)
0
2
∗(K)
D
⊗ S . Let π|K = (π|K (F K−1 ), π|K (F K−1 + 1), π|k (F K−1 + 2), · · · · · ·) be the steady state probability vector of
the Markov chain M∗K , where π|K (l) = (π|K (l, d, K), π|K (l, d − 1, K), · · · , π|K (l, 1, K)) for l = F K−1 , F K−1 + 1, · · ·, and
π|K (l, s, K) = (π|K (l, 1, s, K), π|K (l, 2, s, K), · · · , π|K (l, K, s, K)) for 1 ≤ s ≤ d. Furthermore, let matrix R(K) is the unique
(K)
2 (K)
and deﬁne the
minimal non-negative solution of the following quadratic matrix equation R = A(K)
2 + RA1 + R A0
(K)
(K)
(K)
(K)
matrix B[R ] = B + R A0 . By simple application of the results in Neuts [14], we have the following theorem.
Theorem 3.1-3 Let π|K (F K−1 ) be the solution vector of the equations π|K (F K−1 ) = π|K (F K−1 )B[R(K) ], π|K (F K−1 )(I −
R(K) )−1 e1 = 1. Then, the steady state probability vectors π|K (F K−1 + l) have the matrix geometric form
π|K (F K−1 + l) = π|K (F K−1 )(R(K) )l ,

l = 1, 2, · · · .

3.3 The steady state probabilities of the aggregated Markov chain
Through Theorem 3.1-1 to 3.1-3, therefore, we have derived the steady state probability vectors π|k for the Markov
chains M∗k , k = 1, 2, · · · , K, which are also the conditional steady state probabilities for the states in S∗k of the associated Markov chain M∗ , given that the system is in partition S∗k . The remaining work is to ﬁnd the steady state probability that the system is in S∗k . To do so, for k = 1, 2, · · · , K, let us aggregate all the states in S∗k into a single state (with a
little abuse of notations, we denote the aggregated state still by S∗k ) and deﬁne the steady state probabilities of the queue
length as follows: π|1 (l) = ds=1 π|1 (l, 1, s, 1) for l = 0, 1, 2, · · · , F1 −1, π|k (Fk−1 +l) = kj=1 ds=1 π|k (Fk−1 +l, j, s, k) for
l = 1, 2, · · · , Fk − Fk−1 , k = 2, 3, · · · , K − 1 and π|K (F K−1 + l) = Kj=1 ds=1 π|K (F K−1 + l, j, s, K) for l = 1, 2, · · · . Then,
the resulting aggregated process is the Markov chain with the state space {S∗1 , S∗2 , · · · , S∗K } and transition probability
matrix
⎛
⎜⎜⎜ 1 − λπ|1 (F1 − 1)
⎜⎜⎜
¯ |2 (F1 )
λπ
⎜⎜⎜
⎜⎜⎜
⎜⎜⎜
⎜
P = ⎜⎜⎜⎜
⎜⎜⎜
⎜⎜⎜
⎜⎜⎜
⎜
⎝⎜⎜

λπ|1 (F1 − 1)
¯ |2 (F1 ) − λπ|2 (F2 − 1)
1 − λπ
¯ |3 (F2 )
λπ

λπ|2 (F2 − 1)
···
..

.

..

.

¯ |K (F K−1 )
λπ

¯ |K (F K−1 )
1 − λπ

⎞
⎟⎟⎟
⎟⎟⎟
⎟⎟⎟
⎟⎟⎟
⎟⎟⎟
⎟⎟⎟
⎟⎟⎟ .
⎟⎟⎟
⎟⎟⎟
⎟⎟⎟
⎟⎟⎠

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

1389

The steady state distribution vector π = (π1 , π2 , · · · , πK ) of the aggregated Markov chain can be obtained by directly
solving the equations π = πP, πeK = 1. We have the following theorem.
Theorem 3.2 The steady state probabilities πk for k = 1, 2, · · · , K are determined by
⎡
K−1
⎢⎢⎢
λ
π1 = ⎢⎢⎢⎣1 +
( )k−1
λ¯
k=2

k−1
l=1

⎤−1
π|l (Fi − 1) ⎥⎥⎥⎥
⎥⎥ ,
π|l+1 (Fi ) ⎦

⎡
K−1
⎢⎢⎢
λ
πk = ⎢⎢⎢⎣1 +
( )k−1
λ¯
k=2

k−1
l=1

⎤−1
π|l (Fi − 1) ⎥⎥⎥⎥ λ k−1
⎥⎥ ( )
π|l+1 (Fi ) ⎦ λ¯

k−1
l=1

π|l (Fi − 1)
.
π|l+1 (Fi )

Finally, the steady state probabilities of M∗ can be expressed as
π(l, j, s, k) = π|k (l, j, s, k)πk ,

(l, j, s, k) ∈ S∗ .

4. Stationary waiting time distribution
In this section, we derive the stationary waiting time distribution of an arbitrary customer for the discrete-time
Geo/D/K queueing model with the multi-threshold service policy. As stated previously, this stationary waiting time
distribution is the same as that of the last arriving customer in a group in the D − MAP/D/1 queueing system, whose
arriving phase and bulk size (the number of active servers) are controlled by the thresholds F. Due to the variation of
the number of active servers, the waiting time distribution of an arbitrary customer depends not only on the number
of the customers ahead of him at arrival, but also on the number of the further arriving customers behind of him. Here
we use the absorbing Markov chain method to compute the waiting time distribution. Take an arbitrary customer as
the tagged one. Then, we introduce an absorbing discrete-time Markov chain to describe the dynamics of the system
since the arrival instant of the tagged customer. As will be seen, the waiting time of this customer coincides with the
time until the introduced Markov process reaching an absorption state. Thus, the resulting stationary waiting time
distribution is of phase-type.
Let Z = {(Mn , Ln , Jn , S n , Kn ), n ≥ 0}, where Mn and Ln denote, respectively, the number of customers behind of
the tagged customer and the number of customers ahead of the tagged customer; Jn , S n and Kn denote, respectively,
the phase of the Markovian arrival process, remaining group service time and the number of active servers at the nth
slot. Note that 1) Mn as well as Ln do not include the tagged customer; 2) M0 = 0 and 3) Kn represents the number
of active servers immediately after a transfer of servers (i.e., addition or remove) if any. Especially, K0 = k − 1 if
K
Fk−1 ≤ L0 < Fk − 1, and k if L0 = Fk − 1. Then, Z is an Markov chain with the state space T = k=1
(Tk ∪ Tko )
where Tk = {(m, l, j, s, k) | m ≥ 0, l ≥ 1, Fk−1 ≤ m + l + 1 < Fk ; 1 ≤ j ≤ k, 1 ≤ s ≤ d} and Tko = {(m, 0, j, 0, k) | m ≥
0, Fk−1 ≤ m + 1 < Fk ; 1 ≤ j ≤ k}. In fact, Tko represents the set of the absorbing states when the number of active
servers is k. Arranging the state sets in the order: T1 , T2 , · · · , TK ; T1o ; T2o , · · · , TKo , we obtain the following transition
probability matrix of Z
⎡
⎢⎢⎢ Q11
⎢⎢⎢ Q
⎢⎢⎢ 21
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢
Q = ⎢⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎣

Q12
Q22
..
.

Q23
..
.
Q KK−1

V1o

Q KK

I F1 −1

V2o

..

.
V Ko

I2(F2 −F1 +1)

..

.
I K(FK −F K−1 +1)

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎦

where the sub-matrices Q kk , Q kk+1 , Q kk−1 and V ko are given in Appendix.
Next, we estimate the initial distribution of the Markov chain Z = {(Mn , Ln , Jn , S n , Kn ), n ≥ 0}. Let x(0,0,1,0,1) =
P((M0 , L0 , J0 , S 0 , K0 ) = (0, 0, 1, 0, 1)) and x(m,l, j,s,k) = P((M0 , L0 , J0 , S 0 , K0 ) = (m, l, j, s, k)) for 0 ≤ m; 0 ≤ l; 1 ≤
j ≤ k; 1 ≤ s ≤ d; 1 ≤ k ≤ K. Furthermore, deﬁne the vectors x(m,l, j,k) = (x(m,l, j,d,k) , · · · , x(m,l, j,1,k) ) and π(l, j, k) =
(π(l, j, d, k), · · · , π(l, j, 1, k)). Note that M0 = 0 when the tagged customer arrives at the system. We have x(m,l, j,k) = 0

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

1390

for all m > 0. Hence, we only need to consider the case m = 0. These initial probability vectors can be obtained from
x(0,0,1,0,1) =

1
π(0, 1, 0, 1)D∗(1) + π(1, 1, 1)D∗(1) ⊗ s0 = π(0, 1, 0, 1) + π(1, 1, d, 1)
λ

1
π(l, j, k)D∗(k) ⊗ S + π(l + 1, j, k)D∗(k) ⊗ s0 α
λ
1
π(l, j, K)D∗(k) ⊗ S + π(l + 1, j, K)D∗(k) ⊗ s0 α ,
=
λ

x(0,l, j,k) =
x(0,l, j,K)

Fk−1 ≤ l < Fk − 1; 1 ≤ k ≤ K − 1
F K−1 ≤ l < ∞.

Finally, we can identify the stationary waiting time distribution of the tagged customer with the phase distribution
(x, Q). The precise algorithm for computing this stationary distribution can also be established.
[Algorithm for the stationary waiting time distribution]
STEP.1 Calculate the steady state probability vector π|1 according to Theorem 3.1-1.
(k)
STEP.2 (1) Calculate matrix geometric factors R(k)
1 and R2 for k = 2, · · · , K
(k)
(k)
(k)
(k)
(k)
(k)
(k)
(k)
(k)
(i) calculate the matrices: H0(k) = A(k)
H1(k) = 2(A(k)
0 +A1 +A2 −I ,
0 −A2 ) and H2 = A2 −A1 +A0 +I ,
(k)
(k)
(k) −1
(k)
Gi = Hi (H2 ) , i = 0, 1, where I denotes the kd × kd identity matrix. Deﬁne the 2kd × 2kd matrix
0 −G(k)
0
E (k) such as E (k) =
.
I (k) −G(k)
1
(k)
(k)
(k)
y(k) ek = 1, where
(ii) Let y(k) be an invariant vector satisfying the equations: y(k) (A(k)
0 + A1 + A2 ) = y ,
(k)
ek is a column vector of ones of length kd. Then, we have y = (1/kd, 1/kd, · · · , 1/kd). Deﬁne the
H1(k) ek
. Deﬁne the 2kd × 2kd matrix
row vector α(k) = (y(k) , 0)2kd×1 and the column vector β(k) =
H2(k) ek 2kd×1
β(k) α(k)
Em(k) = E (k) +
.
α(k) β(k)
(iii) Find the bases of the matrix (Em(k) )τ by the matrix sign function approach. Denote the left bases and right
V1(k)
U1(k)
(k)
and
U
.
=
bases, respectively, by V (k) =
V2(k)
U2(k)
(k)
(k) −τ
(k)
(k) τ
(k)
(k)
(k) −τ
(k)
(k) τ
(iv) Calculate R(k)
1 = (V1 − V2 ) (V1 + V2 ) and R2 = (U 1 − U 2 ) (U 1 + U 2 ) .
(2) Calculate the steady state probability vector π|k for k = 2, · · · , K − 1 and π|K , respectively according to
Theorem 3.1-2 and 3.1-3.
STEP.3 Calculate the steady state probability vector {π1 , π2 , · · · , πK } and π(l, j, s, k) according to Theorem 3.2.
STEP.4 Calculate the initial distribution x(0,0,1,0,1) , x(0,l, j,k) and x(0,l, j,K) .
STEP.5 Finally, calculate the stationary waiting time distribution from (x, Q).
Some numerical examples have been performed. We omit to show the results here due to the page limitation.
5. Conclusion
In this paper we have analyzed the discrete-time Geo/D/K queue with the multi-threshold service policy. We derived the steady state distribution of the queue length for the corresponding discrete-time MAP/D/1 queueing system
using Crommelin’s and Stochastic complement techniques, and utilizing this steady-state distribution and the absorbing Markov process method we identify the stationary waiting time distribution with the phase type. Furthermore,
we presented the algorithm for computing the steady-state distribution. As known, the discrete-time Markovian arrival process (D-MAP) has been extensively introduced because of the limitation of Bernoulli processes in modeling
the correlated arrivals. As the further work, we will consider the analysis for the waiting time distribution of the
D − MAP/D/K queuing system under the multi-threshold service policy.
Acknowledge This work was supported in part by Grant-in-Aid for Scientiﬁc Research(No.21510143), Ministry of
Education, Culture, Sports, Science and Technology, Japan.

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

1391

Reference
[1] N. Akar and K. Sohraby, “Finite and inﬁnite QBD chains: a simple and unifying algorithmic approach,” In Proc. INFOCOM 97. 1997
[2] A.S. Alfa, L.K. Dolhun and S. Chakravarthy, “A discrete single server queue with Markovian arrivals and phase type group services,” J. Appl.
Math. Stoch. Anal. 8(2) (1995) 151-176.
[3] A.S. Alfa, “Waiting time distribution of the MAP/D/k system in discrete time - a more eﬃcient algorithm,” Oper. Res. Lett. 31 (2003) 263-267.
[4] H. Bruneel and I. Wuyts, “Analysis of discrete-time multiserver queueing models with constant service times,” Oper. Res. Letter. 15(1994)
231-236.
[5] S. Chakravarthy and A.S. Alfa, “A multiserver queue with Markovian arrivals and group services with thresholds.” Nav. Res. Logis. 40 (1993)
811-827.
[6] M.L. Chaudhry, B.K. Yoon and K.C. Chae, “Waiting-time distribution of a discrete multiserver queue with correlated arrivals and deterministic
service times: D-MAP/D/k system.” Oper. Res. Lett. 30 (2002) 174-180.
[7] C.D. Crommelin, “Delay probability formulae when the holding times are constant,” Post Oﬀ. Electr. Eng. J 25 (1932) 41-50.
[8] W. Feng, M. Kowada and K. Adachi, “Performance analysis of a two-queue model with an (M, N)-threshold service schedule,” J. Oper. Res.
Soc. Jpn. 44 (2) (2001) 101-124.
[9] W. Feng, K. Adachi and M. Kowada, “A two-queue and two-server model with a threshold-based control service policy,” Euro. J. Oper. Res.
137 (2002) 593-611.
[10] G.J. Franx, “A simple solution for the M/D/c waiting time distribution,” Oper. Res. Lett. 29 (5) (2001) 221-229.
[11] I. Frigui, A.S. Alfa and X. Xu, “Algorithms for computing waiting-time distributions under diﬀerent disciplines for the D-BMAP/PH/1,” Nav.
Res. Logist. 44 (1997) 559-576.
[12] J.C.S. Lui and L. Golubchik, “Stochastic complement analysis of multi-server threshold queues with hysteresis,” Perform. Eval. 35 (1999)
19-48.
[13] O.C. Ibe and J. Keilson, “Multi-server threshold queues with hysteresis,” Perform. Eval. 21 (1995) 185-213.
[14] M.F. Neuts, Matrix-geometric Solutions in Stochastic Models, The Johns Hopkins University Press. Baltimore, MD, 1981.
[15] M.F. Neuts, Structured Stochastic Matrices of the M/G/1 Type and Their Applications, Marcel Dekker Inc., New York, 1989
[16] S. Nishmura, “A spectral analysis for a MAP/D/N queue, in: G. Latouche, P. Taylor(Eds.), Advances in Algorithmic Methods for Stochastic
Models, Notable Publications, Inc., Neshanic Station, NJ, 2000, 279-294.

Appendix [The deﬁnition of the matrices Q kk , Q kk+1 , Q kk−1 and V ko ]

Q kk

⎡ (0,0)
⎢⎢⎢ Q
⎢⎢⎢ kk
⎢⎢⎢
= ⎢⎢⎢⎢⎢
⎢⎢⎢
⎢⎢⎣

Q(0,1)
kk
Q(1,1)
kk

Q(1,2)
kk
..
.

Q kk−1

..

.

k −3,F k −3)
Q(F
kk

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥ ,
⎥⎥⎥
⎥⎥⎥
⎥⎦

Q kk+1

⎡
Q(0)
⎢⎢⎢
kk−1
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
= ⎢⎢⎢⎢⎢
⎢⎢⎢
⎢⎢⎢ 0(Fk −Fk−1 )kd×(Fk−1 −2)kd
⎢⎢⎢
..
⎢⎢⎢
.
⎢⎢⎣
0kd×(Fk−1 −2)kd

⎡
⎢⎢⎢ 0 Q(0)
kk+1
⎢⎢⎢
⎢⎢⎢
0
= ⎢⎢⎢⎢⎢
⎢⎢⎢
⎢⎢⎣

Q(1)
kk−1

..

.

···

···

···

···

Q(1)
kk+1
..
.

..

.
k −3)
0 Q(F
kk+1
⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
k−1 −3)
Q(F
⎥⎥⎥
kk−1
⎥
0(Fk −Fk−1 )kd×kd ⎥⎥⎥⎥
⎥⎥⎥
..
⎥⎥⎥
.
⎥⎥⎦
0kd×kd

0
0
..
.
0

···
···
···

0
0
..
.
0

here for i = 0, 1, · · · , Fk − 3,
0 J(i)
(i)
∗(k)
∗(k)
0
k
,
=
C
⊗
S
⊗
I
+
C
⊗
s
α
⊗
Q(i,i)
k
kk
0 0
⎧
⎪
⎪
⎨ IFk −Fk−1 for i = 0, 1, · · · , Fk−1 − 2
I(i)
,
⎪
k =⎪
⎩ IF −(i+2) for i = Fk−1 − 1, · · · , Fk − 3
k
and
Q(i)
kk+1

⎡
⎢⎢⎢
⎢⎢
∗(k)
= D ⊗ S ⊗ ⎢⎢⎢⎢
⎢⎣

0
..
.
0

···
..
.
···

1
..
.
0

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎦
(Fk −(i+2))×(Fk+1 −Fk −1),

0
J(i)
∗(k)
0
k
Q(i,i+1)
+ D∗(k) ⊗ S ⊗
=
D
⊗
s
α
⊗
kk
0
J(i)
k
⎧
⎪
for
i
=
0,
1,
·
·
·
,
F
−
2
I
⎪
k−1
⎨ Fk −Fk−1 −1
J(i)
⎪
k =⎪
⎩ IF −(i+3)
for i = Fk−1 − 1, · · · , Fk − 3.
k

Q(i)
kk−1

⎡
⎢⎢⎢
⎢⎢
∗(k)
0
= C ⊗ s α ⊗ ⎢⎢⎢⎢
⎢⎣

0
..
.
1

···
..
.
···

0
..
.
0

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎦
(Fk −Fk−1 )×(Fk−1 −(i+2)).

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎦

Feng Wei / Procedia Computer Science 4 (2011) 1383–1392

1392

τ

(0)
(Fk−1 −3)
(Fk −3)
, where τ denotes the matrix transpose and for i = 0, 1, · · · , Fk−1 − 3,
· · · Vko
· · · Vko
Vko
= 0, and for i = Fk−1 − 2, · · · , Fk − 3
⎡ (i)
⎤
(i)
⎢⎢⎢ VKo (Fk − (i + 2), Fk−1 − 2) V(i)
⎥⎥
Ko (1, F k−1 − 1) · · · VKo (F k − (i + 2), F k − 2) ⎥
⎢⎢⎢
⎥⎥⎥
.
.
.
.
⎢
⎥⎥⎥
.
.
.
.
⎢⎢⎢
(i)
.
.
.
.
⎥⎥⎥
VKo = ⎢⎢⎢
(i)
(i)
(i)
⎥⎥⎥
⎢⎢⎢
V
(2,
F
−
2)
V
(2,
F
−
1)
·
·
·
V
(2,
F
−
2)
k−1
k−1
k
⎥⎥⎦
Ko
Ko
Ko
⎣⎢
(i)
(i)
(i)
VKo (1, Fk−1 − 1) · · ·
VKo (1, Fk − 2)
VKo (1, Fk−1 − 2)

V ko =
(i)
Vko

here for m = 1, 2, · · · , Fk − (i + 2); j = Fk−1 − 2, Fk−1 − 1, · · · , Fk − 2
⎡ (0,0)
⎧ ∗(k)
⎢⎢⎢ Q KK
⎪
if
(m,
j)
=
(1,
i)
C
⎢⎢⎢
⎪
⎪
⎨ ∗(k)
(i)
D
if (m, j) = (1, i + 1)
Furthermore,
Q KK = ⎢⎢⎢⎢⎢
Vko (m, j) = ⎪
⎪
⎪
⎢⎢⎣
⎩ 0
otherwise.

Q(0,1)
KK
Q(1,1)
KK

Q(1,2)
KK
..
.

..

.

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎦

where for i = 0, 1, 2, · · ·,
∗(K)
= C ∗(K) ⊗ S ⊗ I(i)
⊗ s0 α ⊗
Q(i,i)
K +C
KK

0 J(i)
K
0 0

,

Q(i,i+1)
= D∗(K) ⊗ s0 α ⊗
KK

(i)
and I(i)
dimensional identify matrices such that
K and JK are both the inﬁnite
⎡
⎡
⎤
.
⎢⎢⎢⎢ . .
⎢⎢⎢⎢ . . .
⎥⎥⎥⎥
⎢⎢⎢
⎢⎢⎢
⎥⎥⎥
⎢⎢⎢
⎢⎢
⎥⎥⎥
1
1
(i)
(i)
⎥⎥⎥ ,
IK = ⎢⎢⎢
JK = ⎢⎢⎢⎢
..
..
⎢⎢⎢
⎢⎢⎢
⎥⎥⎥
.
.
⎢⎢⎣
⎢⎢⎣
⎥⎥⎦
1
1
(i)
and
J
are
counted
The superscript i denotes that the dimensional numbers of I(i)
K
K
F K−1 − (i + 2) to inﬁnite, respectively.
⎤
⎡ (0)
⎥⎥⎥
⎢⎢⎢ Q KK−1
⎥⎥⎥
⎢⎢⎢
(1)
⎥⎥⎥
⎢⎢⎢
Q KK−1
⎥⎥⎥
⎢⎢⎢
⎥⎥⎥
⎢⎢⎢
..
.
⎥⎥⎥
⎢⎢⎢⎢
(F K−1 −3) ⎥
⎥⎥⎥
Q KK−1 = ⎢⎢⎢⎢
Q
⎥⎥⎥
⎢⎢⎢
KK−1
⎥⎥⎥
⎢⎢⎢
0
···
···
0
⎥⎥⎥
⎢⎢⎢
⎥⎥⎥
.
.
⎢⎢⎢
.
.
⎥⎥⎥
.
.
⎢⎢⎣
⎦
0
···
···
0

where for i = 0, 1, · · · , F K−1 − 3

Q(i)
KK−1

⎡
⎢⎢⎢
⎢⎢⎢
⎢⎢⎢
∗(K)
0
=C
⊗ s α ⊗ ⎢⎢⎢⎢
⎢⎢⎢
⎢⎢⎣

.. . .
.
.
0 ···
.. . .
.
.
1 ···

..
.
0
..
.
0

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎦
(F K −F K−1 )×(F K−1 −(i+2)).

J(i)
K
0

+ D∗(K) ⊗ S ⊗

0
J(i)
K

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥ .
⎥⎥⎥
⎥⎥⎥
⎦
from F K−1 − (i + 1) and from

⎡
⎢⎢⎢ V(0)
Ko
⎢⎢⎢
⎢⎢⎢ V(1)
⎢⎢⎢
Ko
⎢
..
V Ko = ⎢⎢⎢⎢⎢
⎢⎢⎢ (F . −1)
⎢⎢⎢⎢ VKoK−1
⎢⎢⎣
..
.

⎤
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎥⎥⎥
⎦

where for i = 0, 1, · · · , Fk−1 − 3, V(i)
Ko = 0, and for i = F K−1 − 2, F K−1 − 1, · · · and m = 1, 2, · · · ; j = i, i + 1, · · ·
⎡
⎤
⎧ ∗(K)
..
..
⎢⎢⎢
⎥⎥⎥
⎪
if (m, j) = (1, i)
C
⎪
.
.
·
·
·
⎢
⎥⎥⎥
⎪
⎢⎢⎢ (i)
⎨ ∗(K)
(i)
(i)
D
if (m, j) = (1, i + 1) .
VKo = ⎢⎢⎢ V (2, i) V(i) (2, i + 1) · · · ⎥⎥⎥⎥ ,
VKo (m, j) = ⎪
⎪
⎪
Ko
Ko
⎢⎣ (i)
⎥⎦
⎩ 0
(i)
otherwise
VKo (1, i) VKo (1, i + 1) · · ·

