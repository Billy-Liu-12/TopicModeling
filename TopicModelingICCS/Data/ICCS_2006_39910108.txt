Image-Based Robust Control of Robot Manipulators with
Integral Actions
Min Seok Jie and Kang Woong Lee
School of Electronics, Telecommunication and Computer Engineering,
Hankuk Aviation University, 200-1, Hwajeon-dong, Deokyang-gu,
Koyang-city, Kyonggi-do, 412-791, Korea
Tel.: +82 2 3158 0166; Fax: +82 2 3159 9257
tomsey@korea.com, kwlee@mail.hangkong.ac.kr

Abstract. In this paper, we propose a robust visual feedback controller with
integral action for tracking control of n-link robot manipulators in the presence
of constant bounded parametric uncertainties. The proposed control input has
robustness to the parametric uncertainty and reduces tracking error in the
steady-state. The stability of the closed-loop system is shown by Lyapunov
method. The effectiveness of the proposed method is shown by simulation and
experiment results on the 5-link robot manipulators with two degree of
freedom.
Keywords: robust control, visual feedback, integral action, robot manipulator.

1 Introduction
Applications of visual based robot control have been increased when the robot is
working in unstructured environments. The use of visual feedback in these
applications is an attractive solution for the position and motion control of robot
manipulators. A visual servo control scheme can be classified in two configurations:
fixed-camera, where the visual servoing camera is fixed with respect to the world
coordinate frame and camera-in-hand, where the camera is mounted on the endeffector of the robot manipulator [1], [2]. In the camera-in-hand configuration, the
camera supplies visual information of the object in the environment to the controller.
The objective of this visual feedback control scheme is to move the robot manipulator
in such a way that the projection of an object be at a desired position in the image
plane obtained by the camera.
The manipulator vision system whose dynamics do not interact with the visual
feedback loop can not achieve high performance for high speed tasks. In order to
overcome this drawback, the controller must take into account the dynamics of robot
manipulators [3]. The robot dynamics, however, includes parametric uncertainties due
to load variations and disturbances. A visual servo controller taking into account robot
dynamics must be robust to the parametric uncertainties and disturbances. Kelly [4]
proposed an image-based direct visual servo controller for camera-in-hand robot
manipulators, which is of a simple structure based on a transpose Jacobian term plus
gravity compensation. In [5], a robust tracking controller has been designed to
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 108 – 116, 2006.
© Springer-Verlag Berlin Heidelberg 2006

Image-Based Robust Control of Robot Manipulators with Integral Actions

109

compensate the uncertainty in the camera orientation and to ensure globally uniformly
ultimate boundedness.
Robust control schemes require high feedback gains in order to reduce the tracking
error. In practice, high feedback gains are limited because of hardware issues such as
digital implementation, actuator saturation and noise contained in velocity measurements. Limitation of feedback gains induces large tracking errors. This problem can
be overcome by integral control [6].
In this paper, we design a robust visual servo controller with integral action to
compensate parametric uncertainties due to load variations or disturbances and to
reduce tracking error. The closed-loop stability including the whole robot dynamics is
shown by the Lyapunov method. The proposed robust visual servo controller is applied on a two degree of freedom 5-link robot manipulator to show the performance
of the closed-loop system. The simulation and experimental results show convergence
behavior of the image feature points.
This paper hereafter is organized as follows. In Sections 2 present the robot and
camera models. The proposed robust control system with integral action is analyzed
in Section 3. In Section 4 we introduce simulation and experiment results on a two
degrees of freedom robot manipulators. The paper is finally summarized in Section 5.

2 Robot Model and Camera Model
In this work, we consider a robot manipulator with end effector which a camera is mo
unted on. The mathematical model of this system consists of the rigid robot dynamic
model and the camera model.
In the absence of friction and disturbance, the dynamic equation of an n-link rigid r
obot manipulator can be expressed as [7]

M (q)q + C (q, q )q + G(q) = τ

(1)

where q ∈ R n is the vector of joint displacements, τ ∈ R n is the vector of torques
applied to the joints, M ( q) ∈ R n× n is the symmetric positive definite inertia matrix,

C (q, q )q ∈ R n is the vector of centripetal and Coriolis torques, and G (q) ∈ R n is the
vector of the gravitational torques. The robot dynamic model (1) has the following
properties.
Property 1: For the unknown constant parameter vector θ ∈ R p , the dynamic
equation (1) can be expressed linearly

M (q)q + C (q, q )q + G(q) = Y (q, q, q)θ = τ

(2)

where Y (q, q , q) ∈ R n× p is the known regression matrix.
The dynamic equation (1) can be changed to the error dynamic equation. Defining
the tracking error as q~ = q − qd , the error dynamic equation for the robot manipulator
of (1) is given by

110

M.S. Jie and K.W. Lee

 = M −1 (q )[− M (q) q − C (q, q )q − G (q ) + τ ]
q~
d

(3)

where qd is the twice continuously differentiable desired trajectory.
In order to include integral action in the controller, let us define the new state vector
t
σ = ∫ q~ (τ )dτ

(4)

0

where σ = [σ 1 σ 2 " σ n ]T .
Defining the augmented state vector as ζ = [σ T q~ T q~ T ]T , the augmented state
equation is given by

ζ = Aζ + BM −1 (q) [− Y (q, q, qd )θ + τ

]

(5)

where
⎡0 I n × n
A = ⎢⎢0
0
0
⎣⎢0

0 ⎤
⎡ 0 ⎤
I n× n ⎥⎥ , B = ⎢⎢0 n× n ⎥⎥ , and Y (q, q , qd )θ = M (q )qd + C (q, q )q + G (q ) (6)
⎢⎣ I n× n ⎦⎥
0 n× n ⎦⎥

The motion dynamics of the image feature point described by the robot joint velocity as
ξ = J (q, ξ , Z )q
(7)
⎡c
where J (q, ξ , Z ) = J img (q, ξ , Z )⎢ Rw
⎣⎢ 0

c

0 ⎤
0 ⎤ ⎡I
⎥⎢
⎥ J A (q )
Rw ⎦⎥ ⎣0 T (q)⎦

(8)

In robot control with visual feedback, the control problem is to design a
controller to move the end-effector in such a way that the actual image features
reach the desired ones specified in the image plane. Let us denote with ξ d the
desired image feature vector which is assumed to be constant. We define the image
feature error as

~

ξ = ξ − ξd

(9)

Using (7), the time derivative of (9) can be expressed by

~

ξ = J (q, ξ , Z )q = J ( q, ξ , Z )(q~ + q d )

(10)

We take the desired joint velocity qd as

~
q d = − J + (q, ξ d , Z ) K cξ

(11)

where K c is the positive definite matrix and J + (q, ξ d , Z ) is the pseudo inverse

[

]

−1

matrix defined by J + (q,ξd , Z) = J T (q,ξd , Z)J (q,ξd , Z) J T (q,ξd , Z) .
Substituting (11) into (10) leads to

~

~

ξ = J (q, ξ , Z )q~ − J (q, ξ , Z ) J + (q, ξ d , Z ) K cξ

(12)

Image-Based Robust Control of Robot Manipulators with Integral Actions

111

3 Robust Control with Visual Feedback
In this section, we consider a robust visual feedback controller including integral
action in order to compensate the bounded constant parametric uncertainties of robot
manipulators. The proposed controller is given by

~

τ = Y ( q, q , qd )θ o − M o ( q) Kζ + J + (q, ξ d , Z ) K iξ + τ N

(13)

where K and Ki is the symmetric positive definite gain matrices, τ N is an additional
nonlinear control input compensating for the bounded parametric uncertainties,
M o (q) is the nominal matrix of M (q ) , θ o is the nominal value of the unknown

d )θ o is defined as
parameter vector θ and Y (q, q , q

Y (q, q , qd )θ o = M o (q )qd + Co (q, q ) q + Go ( q)

(14)

where Co (⋅) and Go (⋅) are the nominal matrices of C (⋅) and G (⋅) , respectively.
Substituting the proposed input torque (13) into the equation (5) leads to

~
ζ = ( A − BK )ζ + BM −1 (q)[−Y ( q, q , qd )θ
~
~
+ M ( q ) Kζ + J + ( q , ξ d , Z ) K iξ + τ N ]
~

(15)

~

where θ = θ o − θ , M (q ) = M (q) − M o ( q) and gain matrix K is chosen such that
( A − BK ) is Hurwitz. We make the following assumptions to select an additional
nonlinear input term and to prove the stability of the close-loop system.
Assumption 1: The norms of the following matrices can be bounded such that

λm ≤|| M −1 ( q) ||≤ λM , λ j ≤|| J (q, ξ , Z ) ||≤ λJ , λ j + ≤|| J + (q, ξ d , Z ) ||≤ λ J + ,
K m ≤|| K ||≤ K M , K 0 m ≤|| K 0 ||≤ K 0 M , K cm ≤|| K c ||≤ K cM
Assumption 2: There exist positive constants

α M , α C and α G

(16)

such that

|| M (q) − M o ( q) || ≤ α M

(17)

|| C (q, q ) − Co (q, q ) || ≤ α C || q ||

(18)

|| G (q ) − Go ( q) || ≤ α G

(19)

Assumption 3: There exist nonnegative constants β1 , β 2 and β3 such that

~
Y (q, q , qd )θ ≤ β1 + β 2 ζ + β 3 ζ

2

where β1 = α M || qd || +α C || q d ||2 +α G , β 2 = 2α C || q d || , β 3 = α C .

(20)

112

M.S. Jie and K.W. Lee

These assumptions are hold since it is assumed that the desired qd , qd and qd
belong to the compact set and parametric uncertainties of the robot manipulators are
bounded.
We choose the nonlinear control input term τ N as

τN

⎧ λM β1 (ζ , ξ~ ) s β 2 (ζ , ξ~ ) s
−
⎪−
λm || s ||
2λm || s ||2
⎪
=⎨ 2
~
~
2
⎪ − λ M β1 (ζ , ξ ) s − β 2 (ζ , ξ ) s
⎪
λm μ
2λm || s ||2
⎩

if
if

~

λM β1 (ζ , ξ ) || s ||≥ μ
~

(21)

λM β1 (ζ , ξ ) || s ||< μ

where μ > 0 is a design parameter to be chosen, s = BT Pζ ,

~

β1 (ζ , ξ ) = β1 + β 2 ζ + β 3 ζ
~

2

+ αM KM + λ

J+

~
K M || ξ || , and

~

β 2 (ζ , ξ ) = λ J K oM || ξ || || ζ || .
Theorem 1: Suppose that assumption 1, 2 and 3 hold. Given the error dynamic equations (5) and (15), the proposed controller (13) with (21) ensures position tracking
errors to be globally uniformly bounded.
Proof: Consider the Lyapunov function candidate

1~
V = ζ T Pζ + ξ T K 0ξ
2

(22)

where K 0 is the positive definite matrix and P = PT > 0 is the solution of the Lyapu
nov equation ( A − BK )T P + P ( A − BK ) = − I
Define the set Ω c include the initial value

~
~
Ω c = {(ζ , ξ ) ∈ R3n + 2 | V (ζ , ξ ) ≤ c}, c > 0

(23)

The time derivative of V along the trajectories of the equations (12) and (15) yields

~
~
V = ζ T Pζ + ζ T Pζ + ξ T K 0ξ
≤ − || ζ ||2 − K om λ j λ

j+

~
K cm || ξ ||2 +2λM || s || β1 (⋅)

+ β 2 (⋅) + 2sT M −1 (q )τ N

(24)

~

If λM β1 (ζ , ξ ) || s ||≥ μ , we have

~
V ≤ − || ζ ||2 −η || ξ ||2
where η = K om λ j λ

j+

K cm .

(25)

Image-Based Robust Control of Robot Manipulators with Integral Actions

113

~

If λM β1 (ζ , ξ ) || s ||< μ , we have

~
μ
V ≤ − || ζ ||2 −η || ξ ||2 +
2

For μ ≤

(26)

4ηc
with a > 1
aλmin ( P) K om

V ≤ 0
(27)
~
~
If we define the set Ω μ = {λM β1 (ζ , ξ ) || s ||< μ} , from (27) the trajectory ζ , ξ

( )

will enter the set Ω μ in infinite time and remain thereafter.
Therefore, the control law (13) with (21) guarantees the uniformly ultimate boundedness of the closed-loop system.

4 Simulation and Experimental Results
The proposed control method was implemented on 2-link robot manipulator manufactured by Samsung Faraman-AS1. The dynamic equation of the manipulators is
given by
0
C12 (q, q )⎤ ⎡ q1 ⎤ ⎡ G1 (q )⎤ ⎡τ 1 ⎤
⎡ M 11 (q ) M 12 (q )⎤ ⎡ q1 ⎤ ⎡
⎢ M (q ) M (q )⎥ ⎢  ⎥ + ⎢
⎥ ⎢q ⎥ + ⎢G (q )⎥ = ⎢τ ⎥
0
⎦ ⎣ 2⎦ ⎣ 2 ⎦ ⎣ 2⎦
22
⎣ 12
⎦ ⎣q2 ⎦ ⎣C21 (q, q )

Setup for experiments is shown in Fig. 1. A motion control board(MMC) mounted
in a main computer is used to execute the control algorithm. The feature signal is
acquired by a image processing board(Matrox Meteor II) mounted on a main computer which processes the image obtained from a CCD camera and extracts the image
feature. The CCD camera is mounted on the end-effector. The image obtained by the
image processor has a 640 × 480 pixels resolution

Fig. 1. Block diagram of vision systems

114

M.S. Jie and K.W. Lee

The variation interval of the parameter due to an unknown load is considered

0 ≤ Δm4 ≤ 4.5kg , 0 ≤ ΔI 2 ≤ 0.005Kgm 2
In the experimental test, we have considered one object feature point on a whiteboard. The white board was located at a distance Z = 1 m in front of the camera and
parallel to the plane where the manipulator moves. The controller gain matrices
K c and K are chosen as K c = 10 I and K = [2 I 50 I 50 I ] , respectively. The control
gains Ki and K o are chosen as K i = 7 ×10 −8 and K o = 7 × 10−8 , respectively. The
initial positions of each joint are q1 = π / 2(rad ) , q2 = π (rad ) . It was assumed that
the initial feature point of the object was ξ = [100 100]T pixels. The desired feature
point coordinate was ξ d = [0 0]T pixels.
The simulation results are shown in Figs. 2, 3 and 4. Fig. 2 illustrates the trajectory of
feature point on the image plane which shows the convergence to the desired feature

Fig. 2. Simulation results: Trajectories of
feature errors using integral action(solid) and
without integral action(dashed)

Fig. 3. Simulation results: Tracking errors
of link 1 using integral action(solid) and
without integral action(dashed)

Fig. 4. Simulation results: Tracking errors of
link 2 using integral action(solid) and without i
ntegral action(dashed)

Fig. 5. Experimental results: Trajectories of
feature errors using integral action(solid) and
without integral action(dashed)

Image-Based Robust Control of Robot Manipulators with Integral Actions

115

point. Fig. 3, 4 represents the tracking errors of joint 1 and 2. The results by the proposed
method are compared to those without integral action. It is shown that better tracking
performance results are archived by the robust controller with integral actions.
Figs. 5, 6 and 7 are experimental results that the proposed control algorithm applies
to the 5-link Samsung Faraman robot. Experimental results show that the tracking
performance is effective.

Fig. 6. Experimental results: Tracking errors
of link 1 using integral action(solid) and
without integral action(dashed)

Fig. 7. Experimental results: Tracking
errors of link 2 using integral action(solid)
and without integral action(dashed)

5 Conclusions
In this paper, a robust controller with visual feedback for robot manipulators was
proposed. The controller is of structure based on the image feature errors and the
joint velocities fed back by the CCD camera and the encoder, respectively. The
proposed controller with integral action reduces tracking error due to parametric
uncertainties.
The ultimate uniform stability of the overall closed-loop system is proved by using
the Lyapunov method. Simulation and Experiment results on a two degree of freedom
manipulator have shown that the proposed control method has effectiveness to
control robot manipulators with uncertainty.

References
1. Hashimoto, K.: VISUAL SERVOING. World Scientific (1993)
2. Espiau, E., Chaumette, F., Rives, P.: A new approach to visual servoing in robotics. IEEE
Trans. Robotics and Automation, Vol. 8, No.3 (1992) 313-326
3. Hashimoto, K., Kimoto, T., Ebine, T., Kimura, H.: Manipulator control with image-based
visual servo. IEEE International Conference on Robotics and Automation (1991)
2267-2272

116

M.S. Jie and K.W. Lee

4. Kelly, R., Carelli, R., Nasisi, O., Kuchen, B., Reyes, F.: Stable visual servoing of camerain-hand robotic systems. IEEE/ASME Trans. Mechatronics, Vol. 5, No.1, (2000) 39-43
5. Zergeroglu, E., Dawson, D. M., Queiroz, M. S. de., Setlur, P.: Robust visual-servo control
of robot manipulators in the presence of uncertainty. Journal of Robotic Systems, Vol. 20,
issue, 2(2003) 93-106
6. Liu, G. J.,Goldenberg, A. A., Robust control of robot manipulators based on dynamic
decomposition. IEEE Trans. Robotics and Automation, vol. 13, no. 5, (1997) 783-789
7. Spong, M. W., Vidyasagar, M.: Robot Dynamics and Control. Wiley, NewYork (1989)

