Mobile Animation Algorithm for Cyber Museum
Sung-Soo Hong1 and Sang-Kil Kim2
1
2

Dept. of Computer Eng. Hoseo University, Korea
sshong@office.hoseo.ac.kr
Dept. of Computer Eng. Hoseo University, Korea
ksknet@empal.com

Abstract. Communication technologies have been brought tremendous
change to various aspects of an ever-fast changing world at present. Particularly, the use of Internet and cyberspace is widespread in every corner of our life. In this paper we propose a gesture algorithm using an
animation technology. It was developed for educational purposes, and
accessible through the WWW of Internet. The visual processes can be
adapted for a variety of ﬁelds. For instance, in Cyber Clam Museum,
the visual processes were used to design a screen with a realistic image and create a system that makes possible show at 360. Therefore, in
the system, mobile hosts can observe the detailed clam’s structure and
save the image. This proposed algorithm provides multiple techniques
to user may manipulate, visualize and interact with image on the Web.
And every such transformation as translation, rotation, and scaling can
be applied in the picture interactively for the convenient and eﬀective
viewing. . . .

1

Introduction

As information industry has been developed modern times, the demand for useroriented information has increased more than text-oriented one. Human being
prefer visual technique method to written text, for the visual recognition has
been developed in recent years. Especially, he or she is trying to make every eﬀort
to communicate more easily with information users with visual conﬁguration,
using computer and through them. [3]
The previous computers provided only linguistic and two-dimensional pictures and to and to use mouse and keyboard only to control cyber world. But,
it didn’t provide enough for information users to believe the world as he or she
saw it in cyber world. Displaying information on Internet gives users both timesaving and economic beneﬁts. To provide museum and other useful information
on Internet or through Internet will give much more educational eﬀects. One of
new methods which constructed museum on Internet, especially visualization,
is new one which is generating interaction between computer and human. This
visual scheme is creative art in expressing graphic and factual image, depicting
on screen and giving the feeling of real thing vividly. Of course in mobilizing
human imagination through three-dimensional space it is useful too. There are
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 586–595, 2003.
c Springer-Verlag Berlin Heidelberg 2003

Mobile Animation Algorithm for Cyber Museum

587

a lot of problems to solve in order to construct factual image on Internet. First,
the biggest problems of all, is the lacking of reality and control of the image for
users. Furthermore, there is a problem in terms of Internet transmission velocity.
In order to transform a real thing into object in cyber space through computer,
the art which deals with factual method with three-dimensional space is required. That is, the emphasis on visualization make us artiﬁcial feeling without
understanding traits of real objects. On the contrary, the constructing on factual
movement causes this disharmony, confusion between fact and visual situation.
The visualization using the JAVA can solve these problems at once. The animation generating from it can express real things freely and make the control
of image on screen smoothly according to intention of producer. We can display
animation on screen, stop, enlarge, contract, and control animation speed freely.
Thus we can construct user-oriented system.

2

Related Work

One of the goals of image-based animations is rendering. There have been many
great minds in the ﬁeld. Chen [11] created images at a new point of view by
preserving the images from one frame to another instead of using the traditional
3D rendering. Expanding [11] and Chen [12] introduced the Quick Time VR,
which provides many diﬀerent points of view using the environmental map from
the real world to create images. In making panoramic images, Szeliski [4] used
a new technique, which has no limits in inputting images. This rotating matrix
technique only requires three parameters instead of typical eight and thus lets
the user make panoramic images in a fast and easy way. Solving the problem of
unexpected curves with the image technique Chen used in View Interpolation,
Seitz [4] applied the principles of the projective geometry and called his way
View Morphing. Levoy [8] interpreted that the 2D slices in a 4D function made
a set using new images and created images in new points of view by sampling
with no 3D information such as particular point matching. Horry [14] suggested
Tour into the Picture, with which you can do animations by only using a piece
of 2D image. Although it’s amazing in that you can create animations even
without a perfect 3D environment, it does have a disadvantage that you should
make distinctions of backgrounds and select vanishing points manually. In his
new portal texture algorithm, Aliage[1] divided the inside of a building into two
groups, one of which is the space surrounded by the walls and the other of which
is the portals that can been in the space such as doors, windows, and furniture.
Then he replaced the geometric models seen through the portals with images.
While the old approach presented all 3D models seen through the portals, this
new method provides 2D images, which makes real-time processing possible. Debevec and Niamark succeeded in making the virtual environment of a Canadian
national park by installing two 16mm cameras and catching the stereo images
every meter. Kanade[13] introduced a stereo image matching technique with 50
cameras. Debevec[9] used aerial photographs to suggest a new approach to modeling and rendering a building. In this approach, the prepared 3D structures will

588

S.-S. Hong and S.-K. Kim

come up as the user moves the pre-deﬁned primitives over the pictures and gets
close to a boundary.
Recently, the technology for providing three-dimensional image on Internet
has been regarded as an important ﬁeld. Indeed, VRML that makes threedimensional graphic image, requires VRML Plug-in set-up and is diﬃcult to
express a real image. Also, users should take a special training to operate the
system. Moreover, the translating rate becomes much slower with a big ﬁle [3][5].
Currently, information through the Internet is provided by means of the ﬁrst
dimensional image or text. Although there are several ways to transfer a variety
of information, it is rare to be shown as three-dimensional translation on the
web. Such a three dimensional presentation is normally carried out in the space
through Java Applets program. In fact, the JAVA language may be the best tool
for expressing a three dimensional image on the Internet. However, there are
still some problems such as ways to add real images to the Internet graphic or
the object in the three dimensional space. The three-dimensional graphic tool or
image-extracting procedure may be available to visualize the object. However,
three-dimensional images can be created on the Internet by producing an optical
illusion through a succeeding two-dimensional image. Indeed a system using a
realistic image is a better way rather than simple graphic manufacturing for the
creation of an eﬀective visualization [10].

3

Mobile Animation Model

In a theoretical point, it is natural to make an imaginary actuality equivalent to
real condition by using of imagination. On the other hand, an imaginary actuality
may become a new art mode in a point of artistic view. As artists create a world
through a painting, a musical score, a stage or a stone, the world of imaginary
actuality will be artiﬁcially realized in the computer. If users plunge into the
imaginary actuality and interact with a variety of items in the world, they must
obtain a better pleasure. Now we ﬁrst suggest a model for the interaction between
users and system for the animation of imaginary actuality. How can we deﬁne a
relationship between users and system for the animation of imaginary actuality?
And what is the basic relationship? A model that we are to suggest in the
present paper is based on the model provided by J. Latta et al. [2]. Our model
mainly consists of inter-phases connecting human with imaginary environment.
The ﬁnal goal of our animation system of imaginary reality is that when users
replace a real situation with imaginary one, users cannot realize any diﬀerence
between two situations. Furthermore, our system shall enable users to feel the
better color sense or contours.
As shown in Figure 1, users can look real things through a monitor on displaying module. Sensing module in our system is to sense human’s action or
gesture. This module includes a variety of sensors and digital camera equipped
with input and output devices. Information received through above two modules is processed on Virtual Perception module and extracted according to user’s
idea. This module connects the physical module with the logical sensor and a

Mobile Animation Algorithm for Cyber Museum

589

Fig. 1. Virtual Reality Animation Model

limitation that can be interacted with imaginary world is determined according
to user’s goal. All these works are determined on Interactive module.
Interactions with pre-determined environment are actually performed in the
Simulation module. Of course, users can operate the basic processes without
establishment of Interactive. Rendering module takes a part to draw the changed
imaginary world. This module can reduce or magnify a real object and make a
rotation to all sides in the monitor. The DB for the imaginary reality contains
an image and a text of all objects in the imaginary world. This also includes
geometrical, physical and behavioral characteristics on the intellectual action.
Saving view can save and output the part that a user aims to.
The animation algorithm consists of an Init processor, a Display processor,
a Zoom processor, and a Speed processor and all processors run by calling a
run processor. The animation is done by creating a ﬁle from the image to be
animated taken by a camera and by utilizing a Java program that is saved
in the memory address of an image. In the run processor, a thread runs ﬁrst
to determine a rotation/stop and left/right rotation situation and then the
animation is performed sequentially if the satisfaction is made. The reverse
operation is performed in the case that the nix is reducing. Then, the Speed
processor and Display processor are called.

Init Processor()
{
imgName = getParameter ("image");
pauseTimer =
Integer.valueOf(getParameter("pausetime")).intValue();
for (int i=0; i<count; i++) {
img [i]=getImage (getCodeBase (),imgName+indexName [i]+".jpg");
}

590

S.-S. Hong and S.-K. Kim

offscreenImage =
createImage (this.size (). width, this.size (). height);
offscreenGraphics = offscreenImage.getGraphics ();
setLayout (new BorderLayout ());
Panel panel = new Panel ();
add ("South",panel);
panel.setLayout (new FlowLayout ());
panel.add(button shift = new Button("reverse"));
panel.add(button rotate = new Button("stop"));
panel.add(button lowspeed = new Button("slow"));
panel.add(button highspeed = new Button("fast"));
panel.add(button zoomin = new Button("zoom in"));
panel.add(button zoomout = new Button("zoom-out"));
}
Run Processor ()
while (runner != null) // thread start
if(rotate == 0) // rotation, stop
if (shift == 0) // left, right
inx++;
if (inx >= aniCount-1) inx=0;
else
inx--;
if (inx < 0) inx=aniCount-1;
Speed ();
currentImg = img [inx]; // change image
Display ();

The display processor is one that displays an image sequentially on the
screen after getting the information of the size and position of an image to
be displayed by calling a zoom processor. The xpos represents an x-axis position, ypos is a y-axis position. Img Width is the width of an image, imgHeight
is the height of an image, and drawImage is a Java function that draws an image.
Display Processor ()
Zoom (); // Calling zoom processor
{
int imgWidth = currentImg.getWidth (this);
int imgHeight = currentImg.getHeight(this);
if (zoom == 1) {
xpos=0;
ypos=0;

Mobile Animation Algorithm for Cyber Museum

591

offscreenGraphics.drawImage(currentImg,xpos,ypos,this);
g.drawImage(offscreenImage,xpos,ypos,imgWidth,imgHeight,this);
}
else {
xpos=0;
ypos=0;
offscreenGraphics.drawImage (currentImg,xpos,ypos,this);
xpos=-1*imgWidth/2;
ypos=-1*imgHeight/2;
g.drawImage(offscreenImage,xpos,ypos,imgWidth*2,imgHeight*2,this);
}
}

The zoom processor is one that controls the size of an object. Here, the
current image is the image to be displayed, the zoom parameter controls the
image with the step of 1/10, and xpos and yos are an x-axis and y-axis positions
of an image to be displayed, respectively.
Zoom Processor ()
int imgWidth = currentImg.getWidth(this) + (zoom * 60);
int imgHeight = currentImg.getHeight(this) + (zoom * 40);
xpos = -1 * (zoom * 30);
ypos = -1 * (zoom * 20);

The speed processor is one that makes the speed of an image to be animated
as optimum as possible.
Speed Processor ()
try
Thread.sleep (pauseTime);
catch (InterruptedException e);

4

Implementation

The Cyber Shell Museum is implemented using HTML, Java Script and Java
based on the Web. Technologies employed in this paper can provide better reality
than still images of existing museums through visual eﬀects that allows zoom,
rotation as well as still views as shown in http://cyber.hoseo.ac.kr. The implementation has performed as follows: First, digital camera digitizes real shells
with 360 rotational views or using animation technologies on developer’s purpose. Second, real parts of shells are extracted and their sizes are adjusted to

592

S.-S. Hong and S.-K. Kim

employ using the Photoshop. Third, animation programs were developed to provide interactions with users considering zoom-in, zoom-out, 360-degree rotation.
Finally, background of shells was determined and Java programs were developed
to get system worked as animation.
For the shells of the world, about 1,000 species of shells are selected and
they are classiﬁed into 5 kinds; Gastropods, Bivalves, Tusk shells, Chitons and
Cephaloplds, and more detailed classiﬁcation has been done respectively. For
example, in case of Gastropods, shells are classiﬁed into nine kinds of Ear, Cap,
Pear, Corkscrew, Top, Spindle, Club, Barrel, and Egg using the appearance of
shells in Fig. 2.

Fig. 2. World Shell

The Bivalves is classiﬁed into 7 categories, i.e. Discus, Fan, triangular, Boat,
Paddle, Heart, Irregular. If the CLUB of Gastropods is clicked using mouse,
selected kinds of shells are displayed in the left side of the screen. A user can
select one of them to see related information and the front view of the selected
shell through animated pictures. With various functions such as still picture,
zoom-in, zoom-out, 360-degree rotation, the use can enjoy nice virtual reality in
Fig. 3.

Fig. 3. Virtual Reality of Shell

Mobile Animation Algorithm for Cyber Museum

593

Fig. 4. Korean Shell

For the shells of Korea in Fig.4, shells are classiﬁed into 10 categories
and selected shells are displayed continuously with time interval. The world
of Marvelous-shells contains 20 kinds of marvelous shells in the world and gives
uses curiosity due to the fancy looking shells.
The Story-shells was implemented in order for students to get knowledge
about shells. For example, it provides pictorial and textual information for easy
understanding about what Gastropods is, terminologies for spire, aperture, apex,
growth line, and etc. The Rare-shells contains ﬁve categories about rare shells in
the world. A user can search shells by using images when the user doesn’t know
shells’ name or appearance in Fig. 5.

Fig. 5. Visual Search

If the user knows shell’s name, the textual search can be used with shell’s
names and characteristics in Fig. 6.
After experiment was done by joining the shell museum system on Internet
network (http://cyber.hoseo.ac.kr), advantages were found. The diﬀerences and
advantages of using the animation technology with VRML system [Table. 1].

594

S.-S. Hong and S.-K. Kim

Fig. 6. Textual Search
Table 1. Comparison of Animation technology and VRML
Animation

VRML

Advantage

f actual mage cyber image

Need System

No

P lug − in program

Image express very easy

very hard

Dimension

3D, 2D

3D

Train

No

special train

Memory

small f ile

big f ile

Internet

easy

very dif f icult

Speed

f ast

slow

In deed, VRML system that makes three dimensional graphic image, but
there are big problem. First VRML system need a plug-in setup program.
Second it is very diﬃcult to express a real image. Also, users should take a
special training to operate the system. Moreover, the translating rate becomes
much slower with a very big ﬁle. So, we can not accept mobile system. The
animation system can express real images freely and make the control of
image on screen smoothly according to intention of Producer. We can display
animation on screen, stop, enlarge, contract and continue animation speed
freely. Thus we can construct animation system based on the mobile system.

5

Conclusion

In this paper we showed the similar system three dimension, using shell museum
on cyber space technique and animation. So far we have utilized simple image,
and the graphic visual objectives on Internet. Besides these, we could give more

Mobile Animation Algorithm for Cyber Museum

595

detailed information that of going to museum in person using the factual image.
The visualization of utilizing Java makes the Internet users who are familiar with
complicated and diﬃcult information understand easier. Furthermore, the users
control the necessary information which is available directly. What is called a
kind of users-oriented system? The weak-points of this system realized rather
slow when we use telephone line. But we can solve the problem naturally by
improving Internet transmission velocity promptly and the processing speed of
computer. This paper, diﬀerent from the visual image of graphic, gives not only
users using the Internet much interests but also, the educational value. This
cyber shell museum provides new conceptual Internet information and share
materials which are display on web beyond space limitation. So far, we construct
based on the materials for shell over 1000 species worldwide with animation.

References
1. D.G. Aliage, Anselmo, A. Lastra, “Architectural Walkthroughs Using Portal Textures”, IEEE Visualization97, pp. 355–362,1997.
2. J. Latta, D. Orberg, A conceptual Virtual Reality Model, IEEE Computer Graphic
and Application; vol. 4, No.1, pp. 23–20, Jan, 1994
3. John J. McArdle, “Beneﬁts and Limitation of Mega-Analysis Illustrated using the
WAIS, Vol.18, No.1, pp. 12–16 Sep, 2002
4. J.W. Shade, S.J.Gortler, R.Szeliski, “Layered Derpth Images” , SIGGRAPH98,
1998.
5. Kah-Seng Chung, Yia fourg Chen, “A versatile Digital Mobile Channel Simulation.” Apcc 2002, pp. 10–14, Sep. 17. 2002.
6. L. McMillan, G. Bishop, “Plenoptic Modeling: An Image-Based Rendering System
”, SIGGRAPH95, pp. 39-46, 1995.
7. M. Brady et al, VRML Testing: Making VRML Worlds Look the same Everywhere,
IEEE Computer Graphics and Application, Mar 1999, pp. 59–67
8. M. Levoy, P. Hanrahan, “Light Field Rendering”, SIGGRAPH96, pp. 31–42, 1996.
9. P. Debvec, “Randering Synthetic Objects into Real Scenes : Bridging Traditional
and Image Based Graphics with Global Illumination and High Dynamic Range
Photography”, SIGGRAPH98, pp. 189–198, 1998.
10. Saied Hoezzi et. al, Virtual view generation for 3D digital video, IEEE Multimedia,
pp. 18–26, Jan 1997
11. S.E. Chen, L. Williams, “View Interpolation for Image Synthesis”, SIGGRAPH93,
pp. 279–288, 1993.
12. S.E. Chen , “QuickTime VR-An Image Based Approch to Virtual Environment
Navigation”, SIGGRAPH95, pp. 29–38, 1995
13. T. Kanade et.al, “Constructing Virtual Words Using Dense Stereo”, ICCV98, Bombay, India, pp. 3–10, Jan. 1998.
14. Y. Horry, K.I. Anjyo, K. Arai, “Tour Into the Picture: using a Spidery Mesh
Interface to Make Animation from a Single Image”, SIGGRAPH 97, pp. 225–232,
1997.

