Streamlining Oﬄoad Computing to High
Performance Architectures
Mark Purcell1 , Owen Callanan1 , and David Gregg2
1

Dublin Software Lab, IBM Ireland
Trinity College Dublin, Ireland
{mark_purcell,owen.callanan}@ie.ibm.com,david.gregg@cs.tcd.ie
2

Abstract. Many important scientiﬁc, engineering and ﬁnancial applications can beneﬁt from oﬄoading computation to emerging parallel
systems, such as the Cell Broadband EngineTM (Cell/B.E.). However,
traditional remote procedure call (RPC) mechanisms require signiﬁcant
investment of time and eﬀort to rewrite applications to use a speciﬁc
RPC system. As a result, oﬄoading functions to remote systems is not
viable for many applications. IBM R Dynamic Application Virtualization
TM
(DAV) insulates the application developer by automatically generating stub libraries that allow direct calling of remote procedures without
application source code modiﬁcation. In this paper, we describe DAV
automates the conversion of client applications to use remote procedure
calls. DAV can generate stub libraries for a wide variety of client applications running on a variety of architectures, allowing allows simple
and fast remote procedure call enablement of applications with minimum
programming eﬀort.
Keywords: Oﬄoad computing,
computing, remote procedure call.

1

computer

architecture,

parallel

Introduction

Oﬄoading computation onto remote computer systems is a useful way to accelerate computationally intensive applications. For example, in the ﬁnancial services sector, spreadsheet applications are used to evaluate options prices using
the Black-Scholes formula. This is a computationally intensive algorithm which
can be signiﬁcantly accelerated on specialised processors such as the Cell/B.E.
[2]. Oﬄoading the Black-Scholes formula onto remote high performance systems
signiﬁcantly improves performance of the spreadsheet, allowing faster response
to ﬁnancial market conditions. Oﬄoading calculations from the application to
the remote library is a signiﬁcant challenge in the industrial setting however.
Traditional remote procedure call (RPC) mechanisms enable applications to
call functions from libraries running on remote machines. These systems require
the client application to use a speciﬁc API, forcing an application rewrite. The
time and eﬀort required is signiﬁcant and, as a result, oﬄoading functions using
traditional remote procedure call mechanisms is often not viable. Such RPC
G. Allen et al. (Eds.): ICCS 2009, Part I, LNCS 5544, pp. 974–983, 2009.
c Springer-Verlag Berlin Heidelberg 2009

Streamlining Oﬄoad Computing to High Performance Architectures

975

mechanisms can also create maintenance problems since changes in the API
require rewriting the client applications. In the industrial domain, these problems
are a major barrier to oﬄoading computation to systems optimised for particular
types of processing, such as machines based on the Cell/B.E. processor, which
is heavily optimised for numerical computing [2].
The Virtualizer component of IBM Dynamic Application Virtualization (DAV)
addresses this problem. Based on library and function speciﬁc tags supplied by the
library developer, the Virtualizer generates libraries that exactly mimic the interface of the local machine libraries. As a result, no application code changes are required to oﬄoad functions to remote machines using DAV. The client application
need only relink to the Virtualizer generated libraries, instead of the native code
libraries. The Virtualizer currently generates stub libraries C, C++ and Java stub
libraries. These stub libraries are generated from simple tags in a small domainspeciﬁc language. Furthermore DAV can be extended to support other languages
and applications if required.
This paper presents an overview of DAV and the Virtualizer tool and we
discuss the eﬃcacy of using generative code techniques to eliminate application
code changes when oﬄoading functions to remote machines. The paper starts
with an overview of the DAVsystem in section 2.1. Section 3 then continues
with a discussion of the problems faced in automatically generating libraries
that handle variables and function parameters with unknown size and usage.
In section 4 we describe how Virtualizer uses a simple domain-speciﬁc language
to describe the size and usage of parameters, and a generator to automatically
generate interface code for remote procedure calls. Finally in section 5, a brief
discussion of a traditional remote procedure call system, RPCGen, is included.

2
2.1

DAV Overview
DAV Architecture

The default DAV data transport system provides a ﬂexible, extendable, light
weight, low-latency infrastructure to allow client applications to access libraries
on remote systems, giving clients access to multiple remote libraries, or services,
through a central broker. Services register availability with the broker, which
then maintains information on the available services. To increase availability of
a service, multiple instances of a service can be run concurrently on multiple
machines. In order to access an DAV service, client applications send a service
request to the broker and the broker then chooses the best available service
node to process the request. The client processes its service request by interacting
directly with this service node. DAV services can run on various high performance
architectures including x86 processors and the Cell/B.E. processor. Thus the
broker provides a single interface to multiple services, running on multiple nodes
with heterogeneous architectures.
DAV can use other transport systems. For example, DAV could use a third party
grid scheduling system. This is possible since DAV deﬁnes a simple interface API.

976

M. Purcell, O. Callanan, and D. Gregg

Fig. 1. DAV Architecture

Any transport subsystem that implements this API can be used by DAV. By implementing a wrapper interface for this grid scheduling system, an organisation
can use DAV to allow their applications to easily oﬄoad calculation to remote
machines, whilst utilising their investment in their existing grid infrastructure.
The DAV code generator generates client-side stub libraries that duplicate the
interface of the original native code libraries. These libraries enable client applications to call remote library functions without changing the application source
code. For an application to use DAV services, the library developer must write
tags, which are included in the library header ﬁle, for all the functions in the library to be oﬄoaded. The Virtualizer takes the modiﬁed header ﬁle as input and
uses the DAV tags to generate client-side stub libraries and server-side skeleton
libraries. The server-side skeleton libraries are automatically deployed to the remote server using the DAV deployment tool. To access the oﬄoaded library, the
client application need only be linked to the generated client stub libraries instead
of to the original native code libraries. Once the DAV service has been started and
registered with the broker, the oﬄoaded library is available for use.
Traditional function oﬄoad systems require that the client application is
rewritten to use a speciﬁc API; a process which is often diﬃcult and timeconsuming. The resulting code can be diﬃcult to maintain since changes to
the API require rewriting of the client application. Automatically generating
libraries that handle all communication to and from the DAV services addresses
these problems, making DAV-enabled applications easy to use and maintain.
If the DAV infrastructure changes then the developer need only regenerate the
stub libraries and relink the application.
2.2

DAV Application Areas

Performance is is often limited by the hardware platform running an application.
For example, a spreadsheet performing computationally intensive data analysis

Streamlining Oﬄoad Computing to High Performance Architectures

977

is limited by the desktop computer it is run on. Meanwhile, specialised high
performance computing systems such as the Cell/B.E. processor can deliver signiﬁcant performance improvements over standard processors for many common
computing kernels [3,8]. Larger multiple processor machines such as clusters of
x86 or Cell/B.E. processors now provide signiﬁcant processing power and DAV
oﬀers an excellent solution to accessing the performance of these systems from
existing applications.
DAV is initially targeted at the ﬁnancial services sector, but it has applications
in other ﬁelds of business, science and engineering. For example many science
and engineering applications are based on standard linear algebra packages such
as BLAS [4]. The Cell/B.E. delivers signiﬁcant performance for many of the
core BLAS routines, and DAV provides a straightforward way to access this
performance.

3

RPC Challenges

Many languages, including C, do not have self-describing data structures. Given
a pointer to a data structure, the language doesn’t know the size or shape of
the data structure. Pass-by-reference array parameters are an example of this
problem. Unless the size of the array is known at compile time, then extra information must be passed to the function to indicate the size of the array. An
example of this is shown in ﬁgure 2. Unknown parameter sizes are a problem
for remote procedure oﬄoad systems such as DAV, since the operand data must
be transferred to the remote server and unless the size of the data is known,
data transfer is not possible. Thus some mechanism is required to specify the
size of pass-by-reference parameters to allow DAV to generate correct stub libraries.
Pass-by-reference parameters can also be modiﬁed within a function, or a
function may allocate memory to a pointer passed as a parameter. As a result,
operand data may only need to be sent, retrieved, or sent and retrieved. The
C language syntax does not specify how a pointer passed to a function is used
inside the function and, to maximise eﬃciency, data should only be transferred
when necessary. Again, a mechanism is required to specify the transfer direction
of pass-by-reference parameters.

4

A Solution: DAV Tags

DAV tags provide a solution to automatic transfer of pass-by-reference parameters. Using these tags, the library developer can specify that a function is to
be hosted in the remote library, and the size and transfer direction of any
pass-by-reference parameters. DAV tags are based on the DOxygen/JavaDoc
tags used to specify documentation information within application source code.
DAV tags can also pass other information to the Virtualizer, such as the library name or information about structs. The format of the DAV tags is as
follows:

978

M. Purcell, O. Callanan, and D. Gregg

/**IBMDAV*
@tagType value
@property value
@property value
... */
There are three main tag types:
1. Library tags specify settings for the entire library including adding preﬁxes
or suﬃxes to DAV exported functions.
2. Function tags set properties for speciﬁc functions, including the size and
transfer direction of pass-by-reference parameters and return values.
3. Struct tags are used to inform the Virtualizer about any structs used by DAV
exported functions, including the size of any pointer type struct members.
Various property tags are used by the three tag types, and are shown in table 1.

Table 1. DAV semantic property tags
Property Tag
@library <name>
@func <name>
@struct <name>
@param[in|out|inout]<name>
@return
@dimensions [<size>]
@ type string
@preﬁx <p>, @suﬃx <s>
@lib options “<options>”

Purpose
Used with
Library name
Virtualize function <name>
Describe struct <name>
Function-param details
@func, @struct
Specify size of returned data
@func
Specify size of an array
@param, @return
Denote string parameter
@param, @return
Function preﬁx or suﬃx
@library
Additional linker options
@library

Figure 2 shows a C function that takes two pointers to arrays as operands,
along with an integer to specify the size of the arrays. Also shown in ﬁgure 2
are the tags required for the Virtualizer to create stub libraries for the function.
The Virtualizer handles the integer parameter s, automatically because it is a
scalar type, but extra information is required for the two pointer parameters
to describe the data that they point to. In this case, they are both pointers to
arrays of size s. The ﬁrst array, a, is input only, whilst the second, z, is both
an input and an output since it is modiﬁed by the function. The @param and
@dimensions tags are used to pass this information to the Virtualizer.
Figure 3 shows the code generation process used by the Virtualizer. The user
runs the Virtualizer from the command line, passing the library header ﬁle including tags, as input. The Virtualizer checks the syntax of the C header definitions and of the tags, and parses the header ﬁle using the Eclipse C/C++
parser, CDT. Function prototype information is extracted and stored in a temporary internal representation. The tags are extracted from the header ﬁle using

Streamlining Oﬄoad Computing to High Performance Architectures

979

/**IBMDAV* @function calcArray
@param[in] a @dimensions[s]
@param[inout] z @dimensions[s] */
double calcArray( double *a, double *z, int s ){
double res = 0;
for (int i = 0; i < size; i++) {
z[i] = a[i]{*}2;
res += z[i];
}
return res;
}
Fig. 2. Function with DAV tags for unknown parameter size and transfer direction

CDT and passed to the Java parser-generator, Javacc, which extracts the information from the tags and stores it. The Virtualizer processes the stored tag
and the header ﬁle information, combining them into a single XML document.
Using XSLTs, the Virtualizer produces the source code for both client-side stub
libraries and server-side skeleton libraries. Finally the client-side stub library is
compiled on the client system. The server-side skeleton library is then deployed
to the machine that will run the service using the DAV deployer tool.
When run using the tag information shown in ﬁgure 2, the Virtualizer will
produce a client-side stub library that exports a calcArray function with identical syntax to the original native code function. This function consists of code
to construct the transportable data, manage calling of the remote DAV function and extract the returned result data. All interactions with the underlying
infrastructure are completely contained by the generated function, so no code
changes to the client application source are required.
By using generative code techniques DAV supports a variety of client types
including C, C++, Java and VBA applications. C/C++ are supported for server
side libraries. All standard basic types in each language are supported as well
as strings, arrays, two dimensional arrays and data structures. Pointers to all
of these types, including pointers to arrays of up to two dimensions, are also
supported. All supported types are natively supported, no DAV speciﬁc types
are required, so DAV requires no client side code changes of any kind.

5

Related Work

RPCGen is an example of a traditional API based RPC mechanism [5]. RPCGen simpliﬁes the use of RPC by generating stub libraries that wrap much of the
RPC API. However RPCGen still requires signiﬁcant code changes to the client
application. RPCGen remote procedures use a diﬀerent function call syntax to
the original native code functions, and some parameter types, such as variable
length arrays, must use RPC speciﬁc data types instead of the native C types.
As a result the client application code must be changed to allow RPCGen remote procedures to be used. A signiﬁcant amount of work is required to convert

980

M. Purcell, O. Callanan, and D. Gregg

Fig. 3. Code generation process

double *matrix = new double[N*N];
for ( int i = 0; i < N; i++ ) {
matrix[i] = i;
}
result res;
result *resPtr;
double sum = summat(&m, *N, &resPtr);
Fig. 4. Original Native Source Code

an application to use RPCGen remote procedures, as shown by comparing the
original source in ﬁgure 4 with the source modiﬁed to use RPCGen in ﬁgure 5.
CORBA is an object request broker system that allow applications written
in diﬀerent languages to exchange data objects [1]. CORBA uses a languageindependent interface deﬁnition language (IDL) to deﬁne the interface between
client applications and the object broker system. This interface code is then
compiled into language-speciﬁc stub and skeleton libraries using the IDL compiler provided with a CORBA implementation. The use of an interface deﬁnition
language allows CORBA implementations to insulate the application developer
from some of the complexity of the CORBA object broker system. However substantial code changes are still required, as can be seen in ﬁgure 6. Component
Object Model (COM) from Microsoft is another technology that allows diﬀerent
applications to interact though a common object format [6]. In a similar fashion
to CORBA, COM uses an IDL to deﬁne the interface between applications and
the COM data transport system.

Streamlining Oﬄoad Computing to High Performance Architectures

981

double *matrix = new double[N*N];
for ( int i = 0; i < N; i++ ) {
matrix[i] = i;
}
matrices m;
m.matrix_len = N*N;
m.matrix_val = matrix;
result res;
result *resPtr;
double sum = *summat(&m, *N, &resPtr);
Fig. 5. Example of use of RPCGen speciﬁc types for 2d matrix function
CORBA_ORB_var = CORBA_ORB_init();
ifstream in(Example.ref);
char s[1000];
in >> s;
CORBA_Object_var obj = orb->string_to_object(s);
Example_var p = Example::_narrow(obj);
double *matrix = new double[N*N];
for (int i = 0; i < N; i++) {
matrix[i] = i;
}
result res;
double sum = p->summat(matrix, N, &res);
Fig. 6. Example of CORBA code changes for a 2d matrix function

Automatically partitioning an application to distribute it across multiple systems is a related problem to the one we address. An example is J-Orchestra
[7] which can automatically partition and distribute Java bytecode programs to
execute just as if they were running on a single system. J-Orchestra works by
rewriting the Java bytecode to insert an extra level of indirection into all object
references. By intercepting memory accesses in this way, references to objects on
remote systems can be redirected, and similarly local method invocations can be
replaced by remote procedure calls. It is important to note that J-Orchestra only
works because Java has well-behaved references and self-describing data structures. Redirecting all memory references would be much more diﬃcult in C/C++
because general pointers can be used to access arbitrary parts of memory.

6

Experimental Results

To maximise the performance gain from calculation oﬄoad to a remote system
using DAV, the oﬄoad overhead must be minimised. There are two main causes

982

M. Purcell, O. Callanan, and D. Gregg
Table 2. DAV latency performance data
Performance Test
Latency (µs)
Local Transport
59.9
DAV Transport (localhost interface)
260
DAV Transport (remote server, Gigabit Ethernet) 406

of overhead in an DAV request. The ﬁrst is the data marshalling overhead which
is the time required to pack and unpack request and result data into a transportable format. The second overhead is the cost of transporting the data to the
remote system. To measure the data marshalling overhead, a diﬀerent transport
subsystem is used, which is called the local transport. The local transport is a
skeleton transport that processes requests on the client machine, and does not
use the network stack at all. Measuring the time required to process requests
using the local transport allows measurement of the calculation overhead from
using DAV to process requests. The network stack overhead is measured using
the standard DAV transport by running the client and server on the same machine, accessing the server through the network stack localhost interface. Finally
the latency is measured for a client accessing a remote service over a typical
network. Latency ﬁgures are presented for these three scenarios. The test function used is shown in ﬁgure 2. The operand arrays contain 4 elements each. As
a result the time required to execute the test function is very small compared
to the overall time required to process a remote request. The client machine is
a 2.4 GHz Intel Core 2 processor running Windows, and the server machine is a
3.0 GHz Intel Xeon processor running Linux.
The performance ﬁgures in table 2 show that processing required for a single
small DAV request is low, and overall takes less than 60 microseconds. Processing
an DAV request using a service running on the client machine, accessed through
the localhost network interface adds a further 200 microseconds to this ﬁgure.
This reﬂects the increased processing overhead caused by moving data through
the network stack. Finally, processing the DAV request over a Gigbit Ethernet
network takes a little over 400 microseconds, which shows the cost of transporting
the request and result data across the network.
Functions with high computational complexity are easier to accelerate, since
the oﬄoad overhead is small compared to calculation time. For large data volumes, the speed of the network system is the critical factor in determining oﬄoad
overhead, since the cost of making the remote function call is small compared
to the cost of transporting the data. For small data volumes, where the data
transport cost is low, the cost of the function call is comparitvely large. We can
see from the above ﬁgures that DAV has a low function call overhead, allowing
DAV to accelerate even relatively small calculations.

7

Conclusion

Traditional RPC mechanisms require signiﬁcant application code changes to ofﬂoad functions onto remote machines. This a major barrier to adoption of oﬄoad

Streamlining Oﬄoad Computing to High Performance Architectures

983

computing in industry, because customers are reluctant to signiﬁcantly modify
their software. DAV’s Virtualizer tool addresses this issue and eliminates any
application code changes when converting to remote procedure calls, substantially simplifying the process of converting an application. The Virtualizer uses
a straightforward set of tags to allow the developer to supply information about
unknown variables and function parameters such as pointers to arrays. When
supplied with these tags in the library header ﬁle, the Virtualizer generates
source code for client stub libraries and server skeleton libraries that wrap all
interactions with the DAV infrastructure, completely insulating the client application. The external interface of the client-side stub library is identical to the
original native code library, so no application code changes are required to enable an application to use remote procedures. Furthermore the client application
is protected from any changes to the middleware API. If the API changes, then
the source code for the libraries need only be regenerated, and the application
rebuilt using the new libraries. This greatly reduces the eﬀort required by industrial users of DAV to oﬄoad computations from the desktop to more powerful
cluster computers. The use of domain-speciﬁc generative code techniques allows
DAV to substantially reduce the cost and eﬀort required to write and maintain
applications that oﬄoad calculation to remote systems.

References
1. Common object request broker architecture: Core speciﬁcation. Technical report,
Object Management Group (2004)
2. Kahle, J.A., Day, M.N., Hofstee, H.P., Johns, C.R., Maeurer, T.R., Shippy, D.:
Introduction to the cell multiprocessor. IBM J. Res. Dev. 49(4/5), 589–604 (2005)
3. Kurzak, J., Buttari, A., Dongarra, J.: Solving Systems of Linear Equations on the
CELL Processor Using Cholesky Factorization–LAPACK Working Note 184. LAPACK Working Note 184 (May 10, 2007)
4. Lawson, C.L., Hanson, R.J., Kincaid, D.R., Krogh, F.T.: Basic linear algebra subprograms for fortran usage. ACM Trans. Math. Softw. 5(3), 308–323 (1979)
5. Rago, S.A.: UNIX System V network programming. Addison-Wesley Longman Publishing Co., Inc., Boston (1993)
6. Rogerson, D.: Inside COM. Microsoft Press, Redmond (1997)
7. Tilevich, E., Smaragdakis, Y.: J-orchestra: Automatic java application partitioning,
pp. 178–204. Springer, Heidelberg (2002)
8. Williams, S., Shalf, J., Oliker, L., Kamil, S., Husbands, P., Yelick, K.: Scientiﬁc
computing kernels on the cell processor. International Journal of Parallel Programming 35(3), 263–298 (2007)

