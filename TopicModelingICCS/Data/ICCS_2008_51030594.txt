Social Layers in Agents’ Behavior Evaluation
System
Krzysztof Cetnarowicz1 , Renata Cięciwa2 , and Gabriel Rojek3
1

Institute of Computer Science
AGH University of Science and Technology
Al. Mickiewicza 30, 30-059 Kraków, Poland
cetnar@agh.edu.pl
2
Department of Computer Networks
Nowy Sącz School of Business — National-Louis University
ul. Zielona 27, 33-300 Nowy Sącz, Poland
rcieciwa@wsb-nlu.edu.pl
3
Laboratory of Computer Science
AGH University of Science and Technology
Al. Mickiewicza 30, 30-059 Kraków, Poland
rojek@agh.edu.pl

Abstract. Behavior evaluation is an approach to a security problem
in a multi-agent system that reﬂects security mechanisms in a human
society. The main idea of this approach is behavior evaluation of all
agents existing in society that is done autonomously by every agent belonging to that society. All autonomous behavior evaluations have to be
collected and processed in order to create a collective decision of a society of agents. This approach reﬂects security mechanisms existing in
a small society in which every human being has enough possibilities to
observe and evaluate all other members of the society. This results in
large computational complexity. In this paper a modiﬁcation to behavior evaluation is presented which involves two simple social layers. Social
layers are characteristic for more complex and larger societies and could
be a means of lower computational complexity.

1

Introduction

Ethically-social mechanisms play a key role in everyday life of every member in
a society. These mechanisms enable to ﬁnd dishonest and undesirable humans
on the basis of continuous observation and evaluation of their behavior, or results of that behavior. In a small society every individual observes and evaluates
the behavior of all other observable people. The results of autonomous behavior
evaluations form one decision of the whole society e.g. decision to exclude somebody from a group. Security mechanisms in society have the decentralized and
distributed character — all individuals make their own autonomous evaluations.
The results of those evaluations form one decision of the entire society.
In order to design security mechanisms in a multi–agent system that are similar to those functioning in small human societies, two base problems have to be
M. Bubak et al. (Eds.): ICCS 2008, Part III, LNCS 5103, pp. 594–603, 2008.
c Springer-Verlag Berlin Heidelberg 2008

Social Layers in Agents’ Behavior Evaluation System

595

solved. The ﬁrst problem is the design of evaluation mechanisms with which every agent will be equipped. These mechanisms should enable an agent to evaluate
the behavior of another agent functioning in society. The results of an agent’s
behavior are actions which are perceived in a computer system as objects. These
objects registered in a certain period of time create a sequence of actions that
could be processed in order to qualify whether it is a good or a bad acting agent
in this particular system, in which evaluation takes place. Another problem is
management, collecting and processing of results of autonomously made behavior evaluations in order to state if a particular agent, which is possibly variously
evaluated by diﬀerent agents, is generally good or intruder (also called a bad
agent).
The solutions of the base problems mentioned in the above paragraph were
presented in our earlier work (e.g. [5]). After implementing and testing characteristic of security mechanisms for small societies, 3 problems concerning ethicallysocial approach emerge:
– an agent with undesirable behavior could be unidentiﬁed by a society of
evaluating agents as bad and in consequence this agent would not be excluded
from that society,
– a good agent could be mistakenly treated as an intruder,
– computational complexity of security mechanisms is too high because of the
base nature of ethically-social mechanisms.
However, we could limit the disadvantageous phenomena with the use of e.g.
actions sampling (as presented in [1]), or earlier results collection (as presented in
[2]), some additional mechanisms which are noticed in societies are still possible
to use and implement in the ethically-social behavior evaluation. The idea of
dividing all members of society into two (or even more) groups called social layers
seems very useful. The individuals in one social layer could evaluate the behavior
of all members of the society and decide which individual is an intruder. The
individuals belonging to the other social layer could not have direct mechanisms
to discriminate and remove intruders. Clarifying, the ﬁrst presented layer will
be called the remove layer (because of the possibility of direct removing some
bad agents) and the second presented layer will be called the subordinate layer
(because this layer does not have a direct impact on intruders’ removing).
In the above paragraph only some main assumptions about the idea of social
layer are presented. To implement this idea the main criterion for belonging to
the remove layer has to be decided. Before presenting those details, the main
mechanisms of ethically-social security solutions have to be presented: in Sect. 2
behavior evaluation mechanisms that are built into agents and in Sect. 3 mechanisms of management, collecting and processing of results of behavior evaluations. In Sect. 4 the details of the idea of social layers are presented, which is the
main topic of this article. The presented theoretical assumptions are next tested
and results of these tests are presented in Sect. 5. The main conclusions of this
paper are stated in Sect. 6.

596

2

K. Cetnarowicz, R. Cięciwa, and G. Rojek

The Division Profile

All security mechanisms, which enable an agent to make behavior evaluations
are named the division profile. Algorithms of the division proﬁle are inspired by
immunological mechanisms of T cells generation, which enable to detect some
anomalies. In a case of behavior evaluation, immunological intruders detection
mechanisms have to operate on observed actions made by evaluated agent. This
approach is opposite to the one proposed in e.g. [3,4] in which immunological
mechanisms operate on the structure of resources. Another diﬀerence between
artiﬁcial immunology and ethically–social approach is the autonomy of a process
(an agent) in a secured system — in artiﬁcial immunology approach one detection system is considered for a particular computer system (or sub-system). In
ethically–social approach every agent autonomously uses his own instantion of
detection mechanisms, what induces the necessity of application of some additional algorithms in order to agree collective decision of all agents.
According to immunological mechanisms of T cells generation the division
proﬁle has three stages of functioning: creation of collection of good (self ) sequences of actions, generation of detectors and behavior evaluation stage. In
further subsections some key aspects of three mentioned stages are presented.
More precise description of the division proﬁle functioning is presented in e.g.
[5,6].
2.1

Collection of Good Sequences of Actions

The collection W of good sequences of actions of an agent consists of sequences
of actions undertaken by this agent. The length of a sequence is ﬁxed to l. Presuming there are stored h last actions undertaken by every agent, own collection
W will contain h − l + 1 elements. An agent in order to generate the collection W should collect information representing actions undertaken by him in
the past. But, on the other hand, an agent in order to evaluate behavior of an
other agent has to collect information representing actions undertaken by the
evaluated agent. So an agent should have information about all actions made
in the system. This information is stored in the table of actions, in which every
agent is equipped. In the table of actions there are stored last h actions of every
visible agent.
2.2

Generation of Detectors

The generation of detectors of an agent happens when an agent ﬁrst ’knows’
his last h actions, so after this agent has undertaken h actions. The algorithm
of detectors generation uses the negative selection — from set R0 of generated
sequences of length l those matching with any sequence from collection W are rejected. At the start of presented process set R0 contains every possible sequence.
Sequence matching means that elements of those sequences are the same. Sequences from set R0 which will pass such a negative selection create a set of
detectors R.

Social Layers in Agents’ Behavior Evaluation System

2.3

597

Behavior Evaluation Stage

Once detectors of an agent have been generated, this agent can evaluate behavior
of an other agent. The result of behavior evaluation process of an evaluating
agent a is a coeﬃcient attributed to an evaluated agent k. This coeﬃcient marked
as mka is a number of counted matches between:
– detectors of the agent a which evaluates behavior,
– sequences of actions undertaken by the agent k (this sequences of actions
are taken from the table of actions of the agent a).
Marking the length of a detector as l and the number of stored actions as h, the
coeﬃcient mka is a number from a range 0, h − l + 1 . The maximum of counted
matches is equal h − l + 1, because every fragment of sequence of actions, which
has length equal to the length of a detector, can match only one detector.

3

Mechanisms of Distributed Evaluations Agreement

An algorithm of agents evaluations management, collection and processing is
used to agree one common decision of all agents, which belong to the remove
layer. The diﬃculty in this agreement is caused by the fact that an agent could
be diﬀerently evaluated by various agents. The discussion of this problem is
presented in [5], in this section are presented only key information essential to
discuss the main topic of this article.
Each action undertaken by an agent may cause change of the results of behavior evaluations that are done by other agents in the system. This approach
lets us formulate the algorithm of evaluation management as follows: If an agent
k belonging to any social layer undertakes an action, a request of evaluation of
the agent k is sent to all agents (except the agent k) in the remove layer, which
have direct impact on agent removing.
An agent a in case of receiving a request of evaluation of an agent number k
sends back only the coeﬃcient oka in the range 0 ≤ oka ≤ 1. The coeﬃcient oka is
given by function:
oka =

mka
h−l+1

4

(1)

where h − l + 1 is the maximum of counted matches of agent a. The power
function of evaluation behavior increases a weight of high coeﬃcient mka (the
exponent was set empirically).
In order to decide if the agent k is in general good or bad the environment
uses the algorithm of evaluation’s collecting and processing, which consists of
following actions:
1. All results of behavior evaluations are stored (that results are sent by agents
in response to the request of evaluation of the agent k).

598

K. Cetnarowicz, R. Cięciwa, and G. Rojek

2. Gained coeﬃcients are summed and then this sum is divided by the number
of agents which got the request of evaluation. If this obtained number is
greater than 12 agent k is eliminated.

4

Social Layers

The presented work focuses on the idea of two coexisting social layers: the remove
layer and the subordinate layer. Agents belonging to the remove layer have direct
impact on removing of all agents (of all social layers) existing in the environment.
Agents belonging to the subordinate layer can only evaluate behavior, but do
not have a possibility of presenting their results in order to remove the agents.
In order to make this idea implementable in our ethically-social security system, the criterion for agents to belong to the remove layer has to be stated.
Hypothetically, the criterion could be ’experience’ of an agent — agents which
have been in the secured system long enough could have the right to evaluate
and, on this basis, eliminate other agents from their environment. Another criterion is also possible — only those agents are chosen to the remove layer, which
evaluations results mostly conform to the opinion of the whole society of agents.
Checking this criterion and changing of agents between social layers can be done
permanently after some constant time periods. The short discussion presented
here does not include all variants of possible criteria. The research presented in
this article focuses on the second mentioned criterion.
Analyzing presented ideas, the algorithm of determination which agent will
belong to the remove layer could be presented as follows:
1. During the ﬁrst h + 1 constant time periods Δt all agents belong to the
remove layer.
2. Afterwards, during the next checking_time the agents observe each other’s
evaluation results. If an agent’s opinion is the same as the opinion of the
whole society it increases its social rank by 1 point.
3. In each h + 1 + n ∗ checking_time (n=1,2,..) constant time period Δt 25 per
cent of agents with the highest social ranks are chosen. Only these agents
form the remove layer. The opinions of individuals belonging to this social
layer are taken into consideration in the process of distinction between good
entities and intruders.
4. The social ranks of all agents are reset. The society of agents acts in accordance with the algorithms of management, collecting and processing of
results of behavior evaluations presented in Sect. 3. Nonetheless, in the randomly chosen time periods the whole society is requested to evaluate the
behavior of an agent a with the purpose of establishing the social ranks of
all agents existing in the society. If it happens that any agent belonging to
the remove layer is deleted, an agent from the subordinate layer with the
highest social rank is moved to the remove layer.
5. The steps number 3. and 4. are repeated.
In the research presented below tests are performed in which checking_time
is equal to 10, 100 constant time periods Δt. Moreover, the subordinate layer is

Social Layers in Agents’ Behavior Evaluation System

599

not relieved from the duty of constant behavior evaluation of all other entities in
the society despite the fact that their opinions are not taken into consideration
in the process of making decision of an agent removing. Consequently, such an
approach to the algorithm presented above does not decrease the computational
complexity of the security mechanisms, but lets us choose the agents to the
remove layer with a high degree of precision.

5

Results of Experiments

A multi–agent system was implemented in order to test the security mechanisms
existing in a society divided into social layers . The environment of designed system has two types of resources: type A and type B. Resources are used by agents
independently, but reﬁlling of all resources is only possible when every type of
resources reaches the established low level. The researched system reﬂects operations in a computer system which should be executed in couples e.g. opening /
closing a ﬁle. There are a lot of attack techniques that are limited to only one
from a couples (or trios...) of obligatory operations (e.g. SYN ﬂood attack [7]).
The simulated system has three types of agents:
– type 50/50 agents – agents which take one unit of randomly selected (A–
50%, B–50%) resource in every full life cycle; only this type of agents needs
resources to reﬁll its energy (if energy level of a 50/50 agent wears oﬀ, this
agent will be eliminated)
– type 80/20 agents – agents which take one unit of randomly selected (A–
80%, B–20%) resource in every full life cycle; type 80/20 agents should be
treated as intruders because the increased probability of undertaking actions
of one type can block the system;
– type 100/0 agents – agents which take one unit of A resource in every full
life cycle; type 100/0 agents are also called intruders.
To some degree, the behavior of 80/20 agents is similar to the behavior of 50/50
agents but is undesirable in the secured system like intruders behavior. In all
experiments presented here there are initially 80 agents of type 50/50, 10 – 80/20
agents and 10 – 100/0 agents. All agents in the system are equipped with the
division proﬁle mechanisms with parameters h = 18 and l = 5. The simulations
are run to 1000 constant time periods Δt and 20 simulations were performed.
Diagrams presented in the next paragraphs show the average taken from 20
simulations.
In the experiments presented below we compare the results obtained in simulations of a homogeneous society and societies divided into two social layers
with diﬀerent checking_time ﬁxed at 10 constant time periods Δt in one case
and 100 in the other one.
5.1

The Phenomenon of Self–destruction

In particular situations a good agent could be mistakenly treated as an intruder.
Such a problem is a consequence of the random choice of undertaken actions. As

600

K. Cetnarowicz, R. Cięciwa, and G. Rojek

a result, some sequences of actions of good agents can be similar to actions of bad
agents. This phenomenon has been named the phenomenon of self–destruction.
Several tests were performed in order to check what is the level of mentioned
phenomenon depending on the checking_time of remove layer of agent society.
Afterwards, the results of these experiments were compared with the results
obtained for a homogeneous society. The diagram in Fig. 1 shows the average
number of agents type 50/50 in separate time periods.
number of agents
80
79
78
77
76
time
100

200

300

400

500

600

700

800

900 1000

homogeneous society
stratified society with checking_time = 10
stratified society with checking_time = 100

Fig. 1. Number of type 50/50 agents in separate time periods

In the homogeneous society the level of self–destruction was equal 3,31% which
means that on average not more than 3 good agents were mistakenly treated as
intruders and removed from the implemented system. The simulations of the
society divided into two social layers showed that the level of the self–destruction
phenomenon slightly increased – 4,75% in case of checking_time set to 10 and
3,81% for checking_time set to 100 constant time periods Δt. However, the
rate of agents’ removing tends to be higher during the early stage of the system
with checking_time equals 10. Such a problem could stem from the fact that
with so short checking_time it is very diﬃcult to diﬀerentiate good agents from
type 80/20 agents. Therefore, intruders can be chosen to the remove layer and,
consequently, have the direct impact on removing of other agents.
The presented research indicate that the social layers have not signiﬁcant
eﬀect on the phenomenon of self–destruction. Nevertheless, the checking_time
of the society should be carefully chosen in order to recognize intruders more
precisely.

Social Layers in Agents’ Behavior Evaluation System

5.2

601

The Rate of Intruders Detection

In every security system, it is crucial to recognize bad entities as soon as possible
and remove them from the environment. In some cases an agent with undesirable
behavior could be not identiﬁed by a society of evaluating agents as bad and, as
a result, this agent would not be excluded from that society.
In our simulations type 100/0 agents were detected during the ﬁrst 28 constant
time periods Δt. Thus, when the system achieved the behavior evaluation stage
all type 100/0 agents were identiﬁed properly and eliminated from the system
when they tried to undertake actions.
number of agents
10
8
6
4
2
time
100

200

300

400

500

600

700

800

900 1000

homogeneous society
stratified society with checking_time = 10
stratified society with checking_time = 100

Fig. 2. Number of type 80/20 agents remained in the system in separate time periods

However, the precise recognition of type 80/20 agents is more diﬃcult and
takes more time. The division between 50/50 agents and 80/20 agents is hindered by random character of agents decision which resource to undertake (some
solutions of this problem were suggested in [2,6]). The diagram in Fig. 2 shows
the average number of agents type 80/20 remained in the system in separate
time periods.
In the homogeneous society the level of intruders elimination was equal 80%.
The simulations of the society divided into two social layers with checking_time
equals 10 showed that this level insigniﬁcantly increased to 82,5%. In the case
of the stratiﬁed society with checking_time equals 100 the level of intruders
detection decreased to 68,5%. During the initial stage of simulations the rate
of bad agents removing was similar to the results obtained in other mentioned
cases. However, this rate seems to be reduced at the moment of dividing the

602

K. Cetnarowicz, R. Cięciwa, and G. Rojek

society into two social layers. Such a problem could be caused by the fact that
the checking_time is too long. Therefore, if the type 80/20 agent hadn’t been
recognized as an intruder before the division of the society, it could act almost
not endangered during the next 100 constant time periods Δt due to the fact
that the agents, which formed the remove layer probably do not possess detectors
to identify its malicious behavior.

6

Conclusion

Some modiﬁcations in the ethically–social security approach were presented in
this paper. The modiﬁcations are named social layers, because society of agents
is divided into two coexisting groups: remove layer that consist of agents, which
can make behavior evaluations and have direct impact on intruder removing and
subordinate layer that consists of agents, which do not have direct impact on
intruder removing (but can make behavior evaluations). The implementation of
idea of social layers presented in the paper contains the criterion which agent
should belong to the remove or subordinate layers. The researched criterion is
connected with the opinion that only those agents should belong to the remove
layer, which behavior evaluations are the closest to all evaluations undertaken
in the secured society.
The main ﬁeld of our interest was how the introducing of social layers would
inﬂuence on the base problems of the ethically-social security mechanisms. The
results of experiments were presented for three cases:
– all agents belong to the remove layer (called in this paper homogeneous
society),
– only 25% of agents belong to the remove layer and the criterion of belonging
to this layer is checking every 10 constant time periods Δt,
– only 25% of agents belong to the remove layer and the criterion of belonging
to this layer is checking every 100 constant time periods Δt.
The obtained results indicate that the implementation of social layers in
ethically–social security system does not have a signiﬁcant eﬀect on the self–
destruction phenomenon and the rate of intruders detection. However, the time
of checking which agent should belong to which layer should be carefully chosen
in order to recognize intruders precisely and eliminate them from the system as
soon as possible.
To conclude, the idea of social layers seems very interesting because it does
not make security mechanisms worse and makes it possible to reduce the computational complexity. The computational complexity could be reduced due to
the fact that the agents belonging to the subordinate layer do not have to make
behavior evaluations every time, which could be the ﬁeld of our future research.

Acknowledgments
This work is partially supported by the Ministry of Science and Higher Education
of Poland, grant No. 3 T08B 042 29.

Social Layers in Agents’ Behavior Evaluation System

603

References
1. Cetnarowicz, K., Cięciwa, R., Rojek, G.: Behavior Evaluation with Actions’ Sampling in Multi–agent System. In: Pěchouček, M., Petta, P., Varga, L.Z. (eds.)
CEEMAS 2005. LNCS (LNAI), vol. 3690, pp. 490–499. Springer, Heidelberg (2005)
2. Cetnarowicz, K., Cięciwa, R., Rojek, G.: Behavior Evaluation with Earlier Results
Collection in Multi–agent System. In: Proceedings of The Agent Days 2005, Malaga,
July 7-8, 2005, pp. 77–84 (preprint, 2005)
3. Forrest, S., Perelson, A.S., Allen, L., Cherukuri, R.: Self-nonself Discrimination in
a Computer. In: Proc. of the 1994 IEEE Symposium on Research in Security and
Privacy, pp. 202–212. IEEE Computer Society Press, Los Alamitos (1994)
4. Hofmeyr, S.A., Forrest, S.: Architecture for an Artiﬁcial Immune System. Evolutionary Computation 7(1), 45–68 (2002)
5. Rojek, G., Cięciwa, R., Cetnarowicz, K.: Algorithm of Behavior Evaluation in Multiagent System. In: Sunderam, V.S., van Albada, G.D., Sloot, P.M.A., Dongarra, J.
(eds.) ICCS 2005. LNCS, vol. 3516, pp. 711–718. Springer, Heidelberg (2005)
6. Rojek, G., Cięciwa, R., Cetnarowicz, K.: Heterogeneous Behavior Evaluations in
Ethically–Social Approach to Security in Multi-agent System. In: Alexandrov, V.N.,
van Albada, G.D., Sloot, P.M.A., Dongarra, J. (eds.) ICCS 2006. LNCS, vol. 3993,
pp. 823–830. Springer, Heidelberg (2006)
7. Schetina, E., Green, K., Carlson, J.: Internet Site Security. Addison-Wesley Longman Publishing Co., Boston (2002)

