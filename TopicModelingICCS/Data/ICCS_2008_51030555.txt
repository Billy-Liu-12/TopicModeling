Grounding of Human Observations as Uncertain
Knowledge
Kamil Szyma´
nski and Grzegorz Dobrowolski
AGH University of Science and Technology, Cracow, Poland
camel sz@go2.pl, grzela@agh.edu.pl

Abstract. The article presents some methods of uncertain, humanoriginated knowledge grounding, accomplished with the use of ontologies
with uncertainities and several ontology ABox joining techniques. Several people with uncertain knowledge about some domain write down
their domain knowledge in a form of simple text in english. The goal is
to obtain uncertain ontology ABoxes, representing their knowledge, and
to join them, resulting in total, grounded, uncertain domain knowledge.
The joining process takes care of diﬀerent facts description details, possible facts conﬂicts as well as varied facts certainity degrees and people
credibility.
Keywords: uncertain knowledge, uncertain knowledge grounding, ontology ABoxes joining, human-originated knowledge.

1

Introduction

The paper is a proposition of solving the task of uncertain, human-originated
knowledge grounding. Several people with uncertain knowledge about some domain write down uncertain domain facts in a form of simple text in english.
The goal is to provide one, total uncertain domain knowledge, based on mentioned information pieces, that can vary in described facts, their certainities and
description details. It is also necessary to take into consideration diﬀerent people credibilities and possible facts conﬂicts. The solution presented in the paper
is based on automated building of several domain ontologies [4] with uncertainities from the text (ABoxes only, with constant TBox supplied externally).
Subsequently, ABoxes of the ontologies are joined [2,12] in a way that reﬂects
total knowledge the most adequately. The resulting ontology contains evaluated
certainity degrees of every sentence as well, depending on subjective certainity
degrees of knowledge contributors and their credibilities.

2

Solution Concept

The whole process of knowledge grounding presented in this paper is shown
in Fig. 1. The abstract TBox, called also the base TBox, is a kind of upper
ontology [9] for all possible domain TBoxes. It contains several basic concepts:
M. Bubak et al. (Eds.): ICCS 2008, Part III, LNCS 5103, pp. 555–563, 2008.
c Springer-Verlag Berlin Heidelberg 2008

556

K. Szyma´
nski and G. Dobrowolski

Fig. 1. Solution concept

Entity — Existence, for representing classes of objects, Relation — Relation,
for representing relations between two entities, a subject and an object, and
Property — Property, which represents entity attributes. Among relations, there
are actions and states. In the abstract TBox it is also modelled that each action
can have many following actions. It is important for events chronology. Among
properties, there are numerical properties, NumericalProperty, and enumerative
properties, EnumProperty, the latter having a ﬁnite set of values.
The domain TBox contains concrete, domain terminology. All its concepts
should extend a proper base concept from the abstract TBox. Domain concepts,
like a car or a person should be subclasses of Existence, while concrete action
hitting and state has color should inherit abstract action and state relations
respectively. Speed, Height or Age could serve as domain examples of NumericalProperty.
There are several human beings, sources of information, who have knowledge
about some domain. The knowledge is uncertain as well as diﬀerent people have
varied credibilities. To model those uncertainities in ontologies [13,14], which
were chosen for knowledge representation, several certainity factors are introduced, with values within −1..1 , where 1 means total certainity and −1 —
total contradiction. There are three kinds of relation certainities:
– relationCertainity — performing action certainity
– relationSubjectCertainity — the action subject certainity
– relationObjectCertainity — the action object certainity

Grounding of Human Observations as Uncertain Knowledge

557

A similar certainity degree for entity attributes can be deﬁned — let it be called
propertyCertainity. All degrees mentioned above are related to subjective opinions of a source of information and can be assigned to each sentence. Additionally
each person has yet another certainity degree assigned that reﬂects his credibility.
Each certainity value present in a sentence must be multiplied by the credibility
factor of the information source.
It is assumed that people know domain terminology — the domain TBox. They
write down their domain knowledge in a form of a piece of text in english. This is
where knowledge processing, described in the article, begins. Firstly, all pieces of
text are parsed in order to extract domain ABoxes — known domain facts.
Then, previously obtained ABoxes are joined using several techniques, like
identiﬁer-based joining, pattern-based joining, action sequences joining (used in
domains describing events with many actions, where chronology is an important
factor) or closure-based joining. For output ontology, although grounded, after
using mentioned methods, is still uncertain, proper certainity evaluation formulas
needed to be suggested as well. All phases of the process and used methods are
more precisely described in the following sections.
The implemented solution with text parsing is temporary as it has a few
disadvantages. Firstly, a person writing the text, must know what sentences are
permissible, in what order they should be written for the resulting ontology to
be correct and logical and what domain aspects are served. Those requirements
are hard to fulﬁll in real conditions. Secondly, there is no way to assure that all
needed information were written — the writer could still forget to mention some
facts he knows about. Those ﬂaws will greatly be limitted when a domain-aware
agent is introduced. The agent will lead the dialog with a person, traversing the
domain ontology and available terminology, thus restricting the role in the whole
process of a human being to giving the answers to concrete, precise questions.
This intelligent agent will have the ability of asking proper questions, because
of its converstation history and context awareness. The abilities of the agent are
thought to be similar to those described in [6].

3

Domain ABoxes Building

At ﬁrst, the text is formatted and all unnecessary phrases and prepositions are
deleted for every sentence in the text to be identiﬁed. Then, semantic analysis of
each sentence takes place. It is done using WordNet project [1]. A list of the most
probable parts of speach, like a noun or a verb, is created for every word in each
sentence. The building module, basing on a list of available sentence schemes in
the form of
subject, relation, object, sentence certainity phrase ,
builds the domain ontology connected with the concrete person, contributing to
the knowledge. Several associate lists, which need to be provided externally, are
used, such as

558

K. Szyma´
nski and G. Dobrowolski

certainity phrase, certainity value , eg. ‘maybe’, 0.4 , ‘certainly’, 1.0 ,
or base speach forms to a corresponding class in ontology mapping, like
‘getting closer’, class:Approaching ,
(‘Toyota’,‘Avensis’), class:ToyotaAvensisCar .
The ‘it’ preposition is also served. This way, the subject of the current sentence
does not need to be repeated in the following one as long as it stays the same.
Instances are identiﬁed and created in the knowledge base as well.

4

Domain ABoxes Joining

Having all domain ABoxes, forming knowledge from several human beings, the
joining process [3,8] can be started to obtain aggregate, complete knowledge.
Diﬀerent credibilities of sources of information or points of view and possible
missing facts must be taken into account while performing ontology ABoxes
joining.
4.1

Identiﬁer-Based Joining

The idea of performing joining based on identiﬁers has its origin in assumption
that in real world there are certain entity kinds for which an identiﬁcation system
was created, like unique car licence plates. Two objects with the same identiﬁers
are found to be synonims. The big advantage of the method is high matching accuracy, but from the other hand the amount of such entity types is rather small.
4.2

Pattern-Based Joining

An instance can be described by a set of numerical properties, like speed or
height, and discrete properties with ﬁnite number of possible values, such as
colours. If two individuals represent the same class and their corresponing properties’ values are similar, there is a chance for these two instances to be synonims.
A pattern is a set of elements of the following two types:
– A discrete role — its values must be equal in comaparing instances, like sex,
– A numerical role with fault margin — certain diﬀerences in values are permitted
All patern conditions have to be met to make two instances synonims. This
method works the best if the domain is not too broad and the number of actors
is not large.
4.3

Action Sequences Joining

A speciﬁcation of events chronology in events-oriented domains is one of the most
important things to be taken care of. Matching action types and succession is

Grounding of Human Observations as Uncertain Knowledge

559

an important factor in synonims searching between corresponding actions and
their actors. The analysis of possible successive actions for every action in domain
ABoxes results in directed graph of action succession creation. Then, the action
succession graph need to be linearized, using the breadth-ﬁrst searching algorithm. For example, after linearization of the graph from the Fig. 2 (left side),
the following action sequences will be created: (A, B, E, F), (A, C, E, F), (A, D,
F). After all graphs linearization is complete, a comparison between each pair of

Fig. 2. An example action graph (left), Action sequences (right)

sequences from diﬀerent ABoxes is performed. The comparison results in correspondence sequence detection, which consists of potentially synonimical actions.
For an action pair to be accepted to the correspondence sequence, both actions
have to be of the same kind. Additionally, the actions’ subjects or objects have
to be of the same class or classes near each other in class hierarchy (if the classes
represent detailed concepts and only for certain, conﬁgurable cases).
Compared action sequences can, and probably will be only similar, not equal,
because diﬀerent descriptions of a complex event may vary in details. That is
why not all actions from the sequence have to form a correspondence sequence
— only matching ones. For example, in case of action sequences from Fig. 2
comparison, a correspondence sequence ((A1, A2), (D1, D2), (E1, E2)) will be
created. From all correspondence sequences found for a certain pair of ontologies,
the longest sequence is chosen. All its paired actions are considered synonims if
the sequence length is more than three.
4.4

Closure-Based Joining

Ontologies can be treated like a connection graph with individuals or actions
as vertices and hasSubject or hasObject relations as edges. The main idea behind closure-based joining is an assumption that if, for example, two individuals
(verticies in the connection graph) are synonims, their adjoining vertices (for

560

K. Szyma´
nski and G. Dobrowolski

example two other individuals) could be synonims as well unless they are not
similar or have diﬀerent types.
Two kinds of closures are deﬁned:
– action closure — if two actions have the same type and their subjects and
objects are synonims, the actions are synonims as well,
– subject (object) closure (entity closure) — if two actions are synonims and
their objects (subjects) are synonims, their subjects (objects) are synonims
as well.
These closures are applied multiple times so as synonims discovery propagates
through the connection graph.
4.5

Certainities Evaluation

If two facts do not collide with each other, there is not any problem with them —
both are taken into the joined ABox as they were in domain ABoxes. Undoubtly
there will be some colliding facts too, and not colliding facts, but with diﬀerent
certainity factors. In the ﬁrst case, a fact with the highest certainity value must
be taken, in the latter — although there is no argue concerning the fact itself,
its ﬁnal certainity degree needs to be calculated.
A fact with diﬀerent certainity values. Let the fact in question has certainity values p1 , p2 , . . . , pn , coming from information sources 1..n. These values
already include credibilities w1 ..wn of sources (pi = wi ∗ qi , where qi is a subjective opinion of the ith source about the fact). The ﬁnal certainity p is the mean
of pi values.
Colliding facts. In this case one of the facts need to be taken and its ﬁnal
certainity value must be evaluated. There are two possibilities, depending on
property kind:
– discrete properties — a property value with the highest certainity degree
need to be chosen. Let property values ai , (i = 1..n) have among n people
certainities pi,1 ..pi,k(i) , (1 ≤ k(i) ≤ n), and these certainities include sources
credibilities (the same as previously). Property value ax with the highest
mean certainity value px =
j=1..k(x) px,j /k(x) is taken into the joined
ABox. The value px is an output certainity value of the fact as well.
– numerical properties with fault margin — in this case two values are considered not equal if their diﬀerence is greater than the fault margin. Otherwise,
the means of the values and their certainities (pi ) are calculated and treated
like a common value. The rest of the procedure is analogous to the previous case, barring the diﬀerence that now the calculations can be performed
many times for diﬀerent mean combinations (eg. when a and b are within
the fault margin, b and c, too, but a and c not any more, both the mean
of a and b and the mean of b and c must be taken into account, in different iterations). When the means are evaluated, the number of elements
forming the means have to be remembered, because those values must have
proportionally higher wage in following evaluations.

Grounding of Human Observations as Uncertain Knowledge

5

561

Experiments

Road crashes ontology was designed for experiments. It includes, among other
things, cars and road signs hierarchies — both concepts inherit Existence class
from base TBox. Actions include cars approaching, hitting, turn signalling and
road line crossing, to name a few. A car can have colour, speed and licence plates.
Four crash witness reports were created and then joined.
Report 1 (witness credibility — 0.3):
I was driving a red Opel Vectra. Its license plates are ABA2010. I approached
Toyota Avensis. Its license plates are ABA2557. I indicated left. I crossed the
dashed line. I was driving 60 km/h. I hit Citroen C3. Its license plates are
ABA3232. It was driving 100 km/h.
Report 2 (witness credibility — 0.6):
I was driving green Toyota Avensis. Opel Vectra approached me. It indicated left.
Maybe it crossed the dashed line. It hit Citroen C3.
Report 3 (witness credibility — 0.9):
I was watching Opel Vectra with license plates ABA2010. No way it indicated
left. It hit Citroen C3. Its license plates are ABA3232.
Report 4 (witness credibility — 0.3):
I was driving silver Citroen C3. Its license plates are ABA3232. I was driving 60
km/h. Red Opel Vectra crossed continuous line. Its license plates are ABA2010.
I hit it.
The result of joining witnesses’ reports is as following:
Red Opel Vectra with licence plates ABA2010 was riding 60km/h. Silver Citroen
C3 with licence plates ABA3232 was riding 80km/h. The Opel Vectra maybe approached green Toyota Avensis with licence plates ABA2557. It is very doubtful
that the Opel Vectra turned on its signalization. It maybe overran a dashed line.
It probably hit the Citroen C3.
It can be spotted that information coming from a witness with high credibility
(report 3) has clearly higher ﬁnal certainity factor (minimal certainity of Opel
Vectra driver’s turn signaling, greater certainity of Opel Vectra and Citroen C3
crash). Synonims among car instances were detected because of non-conﬂicting
car identiﬁers (licence plates). The joined knowledge is a kind of all reports sum
— contains even those facts that were not mentioned by all information sources,
like colours of cars. The speed of Citroen C3 (numerical property), 80 km/h,
was calculated as the mean of 100 km/h and 60 km/h. It is worth noting that
both values had the same certainity degrees in corresponding domain ABoxes, so
the waged mean was not necessary here. Witness 2 credibility was high enough
that even if he was not totally sure that Opel Vectra crossed the dashed line,

562

K. Szyma´
nski and G. Dobrowolski

it outclassed a certain sentence of low credible witness 4, who was saying the
line was continous — there is a dashed line in the output ontology. Moreover,
that version was conﬁrmed by witness 1.
It is worth noting that testing presented process of uncertain knowledge joining (grounding) is a complex task which cannot be truely automated. A proper
domain ontology must be manually created, basing on provided abstract TBox,
and several additional mappings, dependant on used domain, need to be provided as well — they were mentioned in the text. Every ontology is diﬀerent
in its structure, too, and that greatly inﬂuences the outcome of the used algorithms. It was assumed that automatically obtained results would be checked by
confronting them with anticipated ones. It is subjective to each person reading
them wether they are satisfying or not.

6

Conclusions and Future Work

The article presented the methodology of human-origined, uncertain knowledge
grounding with the use of several ABoxes with uncertainities joining methods.
Knowledge gaining was based on domian ABoxes with uncertainity values building. Each ABox was built from the text which contained domain knowledge of
some particular information source. Several joining methods, like identiﬁer-based
joining, pattern-based joining, closure-based joining and action sequences joining,
together with sentence certainity values evaluation, resulted in domain knowledge
joining in such a way that maximized knowledge credibility and gave broader view
on problem domain. Presented methodology supports diﬀerent fact certainity degrees as well as credibilities of information sources. Possible fact conﬂicts and differently detailed event descriptions are also taken care of. The experiments from
the previous section were to show eﬀectiveness of used methods.
Future work will focus on knowledge gaining method extension. Inclusion of
domain-aware agent [6] that will lead the dialogue with people, asking them
proper questions, related to dialog context and history, is planned. That approach will eliminate some current disadvantages, like demanding knowledge
about domain and system features from people.
Acknowledgements. We would like to thank Grzegorz Twardu´s and Michal
Pelczar for their help in writing this paper and system implementation.

References
1. Cognitive Science Laboratory, Princeton University: WordNet - a lexical database
for the English language, http://wordnet.princeton.edu/
2. Euzenat, J., Le Bach, T., Barrasa, J., Bouquet, P., De Bo, J., Dieng, R., Ehrig,
M., Hauswirth, M., Jarrar, M., Lara, R., Maynard, D., Napoli, A., Stamou, G.,
Stuckenschmidt, H., Shvaiko, P., Tessaris, S., Van Acker, S., Zaihrayeu, I.: State
of the art on ontology alignment. Knowledge Web Deliverable, Technical Report,
INRIA (2004)

Grounding of Human Observations as Uncertain Knowledge

563

3. Fridman, N., Musen, M.: SMART: Automated Support for Ontology Merging
and Alignment. In: Twelth Workshop on Knowledge Acquisition, Modeling and
Management, Banﬀ, Canada (1999)
4. Gruber, T.: What is an Ontology,
http://www-ksl.stanford.edu/kst/what-is-an-ontology.html
5. Haase, P., Motik, B.: A Mapping System for the Integration of OWL-DL Ontologies. In: IHIS 2005, Bremen (November 2005)
6. Josyula, D.P., Fults, S., Anderson, M.L., Wilson, S.: Application of MCL in a dialog
agent
7. Kalfoglou, Y., Schorlemmer, M.: Ontology Mapping: The State of the Art.
The Knowledge Engineering Review 18(1), 1–31 (2003)
8. Luszpaj, A., Szyma´
nski, K., Zygmunt, A., Ko´zlak, J.: The Process of Integrating
Ontologies for Knowledge Base Systems. In: 7th Software Engineering Conference,
Cracow (2005)
9. Niles, I., Pease, A.: Towards a Standard Upper Ontology. In: Proceedings of the 2nd
International Conference on Formal Ontology in Information Systems. FOIS-2001
(2001)
10. Pan, J.Z., Stamou, G., Tzouvaras, V., Horrocks, I.: f-SWRL: A Fuzzy Extension
of SWRL
11. Pazienza, M.T., Stellato, A., et al.: Ontology Mapping to support ontology-based
question answering. In: 4th International Semantic Web Conference (ISWC-2005),
Galway, Ireland (November 2005)
12. Pinto, H.S., Martins, J. P.: Some Issues on Ontology Integration. Portugal (2001)
13. Stoilos, G., Stamou, G., Tzouvaras, V., Pan, J.Z., Horrocks, I.: Fuzzy OWL: Uncertainty and the Semantic Web
14. Straccia U.: Answering Vague Queries in Fuzzy DL-Lite

