Procedia Computer Science
Volume 80, 2016, Pages 2332–2337
ICCS 2016. The International Conference on Computational
Science

Best practices in debugging Kepler workﬂows
Michał Owsiak1 , Marcin Płóciennik1 , Bartek Palak1 , Tomasz Zok1
, and Olivier Hoenen2
1

Poznań Supercomputing and Networking Center IBCh PAS, Poznan, Poland
michalo@man.poznan.pl, marcinp@man.poznan.pl, bartek@man.poznan.pl, tzok@man.poznan.pl
2
Max-Planck-Institut für Plasmaphysik, Garching, Germany
olivier.hoenen@ipp.mpg.de

Abstract
In this paper we present various techniques related to Kepler development, debugging, and
JVM customisation. We highlight some aspects of development process that may help people
to perform better while working with Kepler (especially in case they develop new components
for the Kepler platform). We present knowledge and ideas that were gained over the time while
working with Kepler tools throughout various projects and diﬀerent applications of Kepler into
existing environments. These ideas are presented for the sake of saving time and eﬀort by other
people who just start their experience with Kepler project.
Keywords: Kepler, debugging, development, DevOps

1

Introduction

Development in Kepler platform may be challenging at some aspects - especially when you
develop for variety of legacy code and combine numerous components within workﬂows [3].
Our experience comes from many projects like PLGridPlus, EUFORIA or EUROFusion[2]12 ,
with many complex scenarios orchestrated by Kepler.
In our research we work at the edges of various technologies that overlap just partially. Very
often we have to develop components that has no precedence and make numerous languages
(like Fortran, C, C++, Python, Java) and technologies work together. In addition to that, we
have to combine them within a workﬂow platform - Kepler.
This paper is divided into three main sections, each describing diﬀerent aspects of Kepler
related developments. The ﬁrst section focuses on workﬂow level, the second section puts actors
into focus, and the last one describes JVM internals that helps to debug Kepler. Each section
1 Part of this work has been carried out within the framework of the EUROfusion Consortium and has
received funding from the Euratom research and training programme 2014-2018 under grant agreement No
633053.
2 Part of this work has been co-funded by the Horizon 2020 Framework Programme through the INDIGODataCloud Project, RIA-653549.

2332

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.433

Best practices in debugging Kepler workﬂows

˙
Owsiak, Pl´
ociennik, Palak, Zok,
Hoenen

is independent and highlights just part of a process. Of course, we just cover a small fraction
of what can be done with Kepler and its ecosystem.

2

Workﬂows

Sometimes the workﬂow just stops and the perception of what has been called ﬁrst is lost. You
can encounter this issue while working with DDF based workﬂows. Quite often this is related
to data stream draining. It means that data are produced at one place, but are not properly
consumed somewhere else.

2.1

Looking for ﬂoating tokens

You can always ﬁnd ﬂoating data by using ptolemy.vergil.actor.lib.MonitorReceiverContents.
This way, you can spot all the tokens that are still pending. They have not been consumed
by actors, yet. If you add ptolemy.vergil.actor.lib.MonitorReceiverContents into the canvas and
run workﬂow, you can easily spot the place where data are not transferred correctly3 .

2.2

Checkpoints

If you are developing large workﬂow, with lots of parallel components, you should pay attention
to proper handling of data ﬂow. Sometimes you want to stream data in a particular way. We
ﬁnd Expression or Constant actors really helpful in this case. To stream data ﬂow we simply
connect all outputs of actors that have to ﬁnish their job before we can proceed and, after all
inputs are ready, we simply pass data to other part of the workﬂow4 .

2.3

Using Multiple Tab Display to control text output

The simple Display actor has one disadvantage - it can not be plugged into workﬂow in a
synchronised way. It means it is hard to tell whether it ﬁred before or after particular actor.
This can lead to incorrect interpretation of results. You can easily solve that by replacing the
Display by a Multiple Tab Display. Just put it somewhere in the workﬂow, where you want to
check output, and connect it with following actor5 .

3

Actors

3.1

Prototyping with Groovy

In case you want to test some ideas for an actor and develop it quickly, there is a great, new
actor in Kepler 2.5 - Groovy. It allows you to embed Groovy code directly in the Kepler actor.6

3.2

Prototyping with Jython

Python is widely used within scientiﬁc projects. A few possibilities exist in order to execute
a Python script from a Kepler workﬂow. By default, you can use Jython implementation of
3 https://raw.githubusercontent.com/mkopsnc/keplerhacks/master/workflows/lock.kar

4 https://raw.githubusercontent.com/mkopsnc/keplerhacks/master/workflows/synchronize.kar
5 https://raw.githubusercontent.com/mkopsnc/keplerhacks/master/workflows/mtd.kar

6 https://raw.githubusercontent.com/mkopsnc/keplerhacks/master/workflows/Groovy.kar

2333

Best practices in debugging Kepler workﬂows

˙
Owsiak, Pl´
ociennik, Palak, Zok,
Hoenen

Python in Kepler. This approach is quite eﬃcient when it comes to simple activities that do
not require access to JVM data (e.g. shared libraries). However, while using this approach, we
have faced numerous compatibility issues and we had to develop diﬀerent approach for handling
Python based scripts. Issues were related to accessing native code via the cython based bridge.
Incompatibilities and lack of support for cython7 based types lead to developing solution based
on running Python as external process.

3.3

Prototyping with Python

If you want to overcome Jython limitations, you can always call Python directly from Kepler
via java.lang.ProcessBuilder. This way, you can run everything as if you run it directly in
Python. However, there are few limitations in this solution. First of all, you are running your
code in separate process. If are using shared libraries then they all will be duplicated, which
may have increase memory consumption. In addition, they will not be shared between the JVM
and Python - this might be the issue in case you want to share some low level components from
shared libraries. Another issue with invoking Python as an external process is the startup time
of Python. Each time you start new Python process, you have to load Python environment and
all the modules that are used by your code. This might have huge impact on execution time.
Running workﬂow that contains code invoking Python triggers huge performance issues. This
aﬀects mostly parallel executions. For a simple Python code dealing with NumPy based data
types, we have observed execution times as presented in Table 1. These kind of results were
not acceptable. In order to reduce times, we had to developed diﬀerent approach for Kepler
based executions. We have decided to run Python via direct JNI [7] calls to Python library.
In Table 1 we present some timing tests executed for exactly the same Python script, however, this time we call it directly from the JVM via a call to the Python shared library. To call
Python library we use JNI mechanism. However, it is also possible to use JNA for the same purpose. JNA library has slightly diﬀerent approach in terms of calling shared libraries. You can
¨
check the diﬀerences by looking at sample code implementing simple Hello
worldäpplication8 .
In the ﬁrst case (ﬁrst column), we have executed the Python script as an external process
(as shown in previous section) for various numbers of CPUs being used. The second column
shows results for the same Python script called via JNI call, the third column shows results
that are based on JNI and, in addition, beneﬁt from internal caching mechanism of one of the
libraries. Thanks to running Python in exactly the same process space as Java process we could
beneﬁt from optimisations done at shared library level. Its internal cache was fully accessible
for the Python script as it was executed in the same process space as JVM itself. In this case,
the gain is huge and we beneﬁt from some internals that are project speciﬁc[1]. Of course, this
is not the solution for all Python based cases9 .
CPUs
1
2
4
8
16

Python process [s]
385
415
564
1365
6557

JNI open [s]
186
200
235
902
3800

JNI cache [s]
13
16
14
21
50

Table 1: Diﬀerent execution times for python code extracted from SYCOMORE workﬂow
7 http://www.jython.org/archive/22/userfaq.html
8 JNI

vs. JNA - https://github.com/mkopsnc/keplerhacks/tree/master/jnijna
code - https://github.com/mkopsnc/keplerhacks/tree/master/python

9 Sample

2334

Best practices in debugging Kepler workﬂows

˙
Owsiak, Pl´
ociennik, Palak, Zok,
Hoenen

While calling native code via JNI or JNA one must pay attention to segmentation faults in
the native code. They will have impact on JVM. We are discussing this topic later in the text,
in section 4.5.

3.4

Embedding multiple versions of a native library

When a native code (Fortran or C++ in our case) is turned into a library and executed as
an actor through JNI, developers might want to switch easily between diﬀerent versions of the
native library. One of such use case is to switch from an optimised version of the library to a
more verbose version when debugging is required directly from the workﬂow. As Java does not
bring the capability to safely unload such native library, we need to use the dynamic linking
loader C API (dlfcn.h).
In the actor Java class, a simple boolean parameter or a multiple choice string parameter
can be added to allow diﬀerent versions of the native library to be selected. In the JNI code,
additional steps consist of: loading the speciﬁc dynamic library (exact path/name is required,
depending on choice made in actor’s parameter), getting the address of the targeted symbol
in memory (pointer on function to be executed), unloading the dynamic library (when its
reference count drops to zero). Of course this ﬂexibility comes with a small overhead, but in
the development phase much time can be saved by allowing such run-time choice.

4

Working close to the JVM

When working with native code, especially legacy code, you can experience various issues that
may impact workﬂow execution: calls to exit(), segmentation faults, runtime errors and bugs in
the native code. These issues are hard to handle as they are embedded (typically) inside code
you cannot access or require debugging of the code outside JVM. However, there are ways to
overcome these issues.

4.1

Customising startup parameters

The startup procedure of Kepler consists of two steps. In the ﬁrst step you run a startup class,
then it creates a new JVM instance and starts it with the speciﬁed parameters. Unfortunately,
not all the parameters can be passed to the second instance as its creation process is statically.
However, there is a way to pass separate and highly customised parameters for the JVM via the
JAVA OPTIONS environment variable10 . Let us say we want to quickly set some properties
for JVM, e.g. we want to customize memory settings. It is as easy as exporting an environment
variable with proper settings, just before running Kepler.
e x p o r t _JAVA_OPTIONS="−Xmx2G −Xms1G −Dmy_propert=’some v a l u e ’ "

In addition, you can specify separate settings for the startup process and for the the main
Kepler module. By altering the environment.txt 11 ﬁle inside your main module it is possible to
specify custom settings for the JAVA OPTIONS environment variable. It can be quite useful
in case you want to attach a debugger to your JVM before Kepler starts. You can also ﬁne tune
memory settings or diagnostic related information provided by JVM (e.g. JNI being verbose).

10 This

11 Each

environment variable is not mentioned by oﬃcial JVM documentation
module can have separate environment.txt ﬁle that deﬁnes system variables

2335

Best practices in debugging Kepler workﬂows

4.2

˙
Owsiak, Pl´
ociennik, Palak, Zok,
Hoenen

Debugging Kepler in Eclipse without projects

Debugging Kepler in Eclipse might be a quite time consuming process especially in case we
want to make quick checks on some actors. It can get even worse if you have number of Kepler
versions being used at the same time. There is, however, a way that can save you lots of time
while working with Kepler sources.
Instead of building Eclipse projects (based on description in Generating Project Files for
Your Favorite IDE 12 )
cd b u i l d −a r e a ; ant e c l i p s e

and importing them into Eclipse (with all the necessary conﬁgurations, e.g. adding external
jars, etc.) you can do a dirty debugging by creating empty project in Eclipse, adding source
path with Java classes, you want to debug, and attaching Eclipse to already running process.
This way, you can quickly and easily make some tests in your code without building proper,
Eclipse based, environment for Kepler. All you have to do is to export JAVA OPTIONS
variable
e x p o r t _JAVA_OPTIONS="−a g e n t l i b : jdwp=t r a n s p o r t=dt_socket , \
s e r v e r=y , suspend=y , a d d r e s s =8000"

before running Kepler and then, attach to already running Java process from Eclipse Run >
Debug Conﬁgurations > Remote Java Application. This way, you can focus on the source code
in which you are interested.

4.3

Debugging Kepler in gdb

Debugging Kepler under gdb[5] can be very useful in case you want to debug some native code
that is used by Kepler (e.g. shared library, JNI code). You can easily attach gdb to running
Kepler session by attaching JVM that runs Kepler. You have to make sure to connect to
correct Java process. To get its PID you should examine process tree. It is possible to get this
information either with pstree or with ps f.
shell > jps
17220 Jps
9502 Kepler
9468 Kepler
s h e l l > ps f
5 6 3 6 p t s /5
9 4 6 2 p t s /5
9 4 6 8 p t s /5
9 5 0 2 p t s /5

Ss
S+
S l+
S l+

0 : 0 0 −b i n / t c s h
0:00
\_ / b i n / b a s h
0:01
\_ j a v a
0:24
\_ j a v a

As you can see, process 9502 is a child of process 9468 (startup process). Process 9502 is
the one that will actually run workﬂows. Once you know it, you can attach debugger to Kepler
by running gdb.
> gdb / p r o c / 9 5 0 2 / e x e

9502

This way, you can debug the whole JVM together with all loaded shared libraries.

4.4

Handling exit calls

Handling exit calls can be done using atexit[4] function. It is possible to combine atexit,
siglongjmp and sigsetjmp to simulate try/catch approach inside JNI code. This way, legacy
code will not terminate JVM. Sometimes it might be very useful, especially in case we do not
have access to source code of the library that calls exit() function. All we have to do is: deﬁne
12 https://kepler-project.org/developers/teams/build/documentation/build-system-instructions

2336

Best practices in debugging Kepler workﬂows

˙
Owsiak, Pl´
ociennik, Palak, Zok,
Hoenen

a method to call when exit function is called, set handler for the exit call via atexit and then
use sigsetjmp to handle incorrect call to exit()13 .
Another approach to handle exit() calls is to set custom handler via -Dexit=new handler
option for the compiler: each call to exit() function is replaced by the new handler code. This
solution is even better as it allows the setting of diﬀerent exit handlers for diﬀerent libraries.
However, it requires an access to legacy code source. The main diﬀerence, comparing to solution
based on atexit is the way code is compiled and the way we deﬁne the handler for exit call14 .

4.5

Handling SIGSEGV

Segmentation faults generated by native code cause the JVM process to exit prematurely[6].
In case JVM encounters SIGSEGV it produces fatal error log and terminates. Sometimes you
would like to avoid this kind of behavior. You would like to produce informative message and
use some better means of informing user that something went wrong. In the case of SIGSEGV
you can apply a similar technique as described above. This way, you can handle Segmentation
Faults and proceed with JVM execution. In order to set the handler one must do following:
deﬁne signal handler for signal SIGSEGV, setup new signal handler in the code, use sigsetjmp
to handle incorrect call to exit, and eventually bring back original signal handler15 .

5

Conclusions

We have shown various techniques that can help people speed up and ease up Kepler based
developments. All these techniques can be applied without too much eﬀort but, at the same
time, may lead to better understanding of problems that occur during development process. Of
course, we presented just a small subset of various debugging techniques choosing solutions we
ﬁnd most useful and tightly related to Kepler based development.

References
[1]

L. Di Gallo and C. Reux et al. “Coupling between a multiphysics workﬂow engine and an optimization framework”. Computer Physics Communications 00. 2015, pp. 1–19.

[2]

M. Płóciennik et al. “Tools, Methods and Services Enhancing the Usage of the Kepler-based
Scientiﬁc Workﬂow Framework”. Procedia Computer Science, Volume 29. 2014, pp. 1733–1744.

[3]

M. Płóciennik et al. “Approaches to Distributed Execution of Scientiﬁc Workﬂows in Kepler”.
Fundamenta Informaticae 128. 2013, pp. 1–22.

[4]

“The Open Group Base Speciﬁcations Issue 7”. http : / / pubs . opengroup . org / onlinepubs /
9699919799/nframe.html. 2013.

[5]

“8 gdb tricks you should know”. https://blogs.oracle.com/ksplice/entry/8_gdb_tricks_
you_should. 2011.

[6]

“Troubleshooting Guide for Java SE 6 with HotSpot VM”. http://www.oracle.com/technetwork/
java/javase/crashes-137240.html. 2010.

[7]

Sheng Liang. The Java Native Interface: Programmer’s Guide and Speciﬁcation. 1999.

13 atexit

sample - https://github.com/mkopsnc/keplerhacks/tree/master/atexit
sample - https://github.com/mkopsnc/keplerhacks/tree/master/dexit
15 SIGSEGV handler sample - https://github.com/mkopsnc/keplerhacks/tree/master/sigsegv
14 dexit

2337

