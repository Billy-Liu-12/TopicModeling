Available online at www.sciencedirect.com

ScienceDirect
This
This
This
This

Procedia
108CProcedia
(2017) 525–534
space
isComputer
reservedScience
for the
header,
space is reserved for the Procedia header,
space is reserved for the Procedia header,
space is reserved for the Procedia header,

do
do
do
do

not
not
not
not

use
use
use
use

it
it
it
it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Parallel
Parallel
Parallel
Parallel

Parity
Parity Games:
Games: aa Multicore
Multicore Attractor
Attractor for
for the
the
Parity
Games:
a
Multicore
Attractor
for
the
Zielonka
Recursive
Algorithm
Parity
Games:
a Multicore
Attractor for the
Zielonka
Recursive
Algorithm
Zielonka Recursive Algorithm
Rossella Arcucci, Umberto
Marotta,
Aniello Murano,
and Loredana Sorrentino
Zielonka
Recursive
Algorithm
Rossella Arcucci, Umberto
Marotta,
Aniello Murano,
and Loredana Sorrentino
Rossella Arcucci, Umberto
Marotta,
University
of Naples Aniello
“Federico Murano,
II”, Naples,and
Italy.Loredana Sorrentino
University
of
Naples
“Federico
II”,
Naples,
Italy.Loredana Sorrentino
Rossella Arcucci, Umberto
Marotta,
Aniello
Murano,
and
{name.surname}@unina.it
University {name.surname}@unina.it
of Naples “Federico II”, Naples, Italy.
University {name.surname}@unina.it
of Naples “Federico II”, Naples, Italy.
{name.surname}@unina.it

Abstract
Abstract
Parity games are abstract infinite-duration two-player games, widely studied in computer science.
Abstract
Parity
are algorithms
abstract infinite-duration
two-player
widely studied
in computer
science.
Severalgames
solution
have been proposed
and games,
also implemented
in the
community
tool
Abstract
Parity
games
are algorithms
abstract infinite-duration
two-player
games,
widely studied
in computer
science.
Several
solution
have
been
proposed
and
also
implemented
in
the
community
tool
of
choice
called
PGSolver,
which
has
declared
the
Zielonka
Recursive
(ZR)
algorithm
the
best
Parity
games
arePGSolver,
abstract infinite-duration
two-player
games,
widely studied
inalgorithm
computer
science.
Several
solution
algorithms
have has
beendeclared
proposed
and
also implemented
in the
community
tool
of
choice
called
which
the
Zielonka
Recursive
(ZR)
the
best
performing
on randomly
generated
games.
With the
aim
ofimplemented
scaling and solving
wider classes
of
Several
solution
algorithms
have
been
proposed
and
also
in
the
community
tool
of
choice
called
PGSolver,
which
has
declared
the
Zielonka
Recursive
(ZR)
algorithm
the
best
performing
on several
randomly
generated games.
With the aim have
of scaling
and
solvingover
wider
classes
of
parity
games,
improvements
and
optimizations
been
proposed
the
existing
of
choice
called
PGSolver,
which has
declared
thethe
Zielonka
Recursive
(ZR)
algorithm
the
best
performing
on several
randomly
generated
games.
With
aim have
of scaling
and
solving
wider
classes
of
parity
games,
improvements
and
optimizations
been
proposed
over
the
existing
algorithms.
However,
no one
has yetgames.
explored
the benefit
ofofusing
theand
full computational
power of
of
performing
on
randomly
generated
With
the
aim
scaling
solving
wider
classes
parity
games,
several
improvements
and
optimizations
have
been
proposed
over
the
existing
algorithms.
However,modern
no one has
yet explored
the benefit
of using
the
fulliscomputational
power of
which
even
common
multicore
processors
are
capable
of.
This
even
more
surprisingly
parity even
games,
severalmodern
improvements
and
optimizations
have
been
proposed
over the
existing
algorithms.
However,
no
one has
yet explored
the benefit
of
using
the
fulliscomputational
power
of
which
common
multicore
processors
are capable
of.
This
even more
surprisingly
by
considering
that most
of the
advanced
algorithms
in of
PGSolver
are
sequential.
algorithms.
However,
no
one
has
yet
explored
the
benefit
using
the
full
computational
power
of
which
even
common
modern
multicore
processors
are
capable
of.
This
is
even
more
surprisingly
by
considering
that
most of and
the advanced
algorithms
in PGSolver
are sequential.
In this
paper
we
introduce
implement,
on aare
multicore
architecture,
a parallel
version of
which
even
common
modern
multicore
processors
capable
of.
This
is
even
more
surprisingly
by
considering
that
most
of
the
advanced
algorithms
in
PGSolver
are
sequential.
In
this
paper we
introduce
and
implement,
on aofmulticore
architecture,
a parallel
versionour
of
the
Attractor
algorithm,
the main algorithms
kernel
the
algorithm.
This
choice follows
by
considering
that
most that
of and
theis
advanced
in ZR
PGSolver
are sequential.
In
this
paper we
introduce
implement,
on aofmulticore
architecture,
a parallel
versionour
of
the
Attractor
algorithm,
that
is
the
main
kernel
the
ZR
algorithm.
This
choice
follows
investigation
that
more of the
99%
of the execution
time of architecture,
the ZR algorithm
is spent
in this
In
this
paper
we
introduce
and
implement,
on
a
multicore
a
parallel
version
of
the
Attractor
algorithm,
that
is
the
main
kernel
of
the
ZR
algorithm.
This
choice
follows
our
investigation
that more
of the
of the
execution
timegenerated
of the ZRthrough
algorithm
is spentand
in this
module.
We provide
testing
onis99%
graphs
up kernel
to 20Kofnodes
PGSolver
we
the
Attractor
algorithm,
that
the
main
the
ZR
algorithm.
This
choice
follows
our
investigation
that
more
of
the
99%
of
the
execution
time
of
the
ZR
algorithm
is
spent
in
this
module.
We provide analysis
testing on
graphsofup
to 20K
generated
through PGSolver and we
discuss
performance
in99%
terms
strong
andnodes
weak
scaling.
investigation
that more
of the
of of
the
execution
timegenerated
of the ZRthrough
algorithm
is spentand
in this
module.
We provide
testing
on
graphs
up
to 20K
PGSolver
we
discuss performance
analysis
in terms
strong
andnodes
weak
scaling.
module.
We
provide
testing
on
graphs
to
20K
PGSolver and we
Keywords:
Parity
Games,
multicore
Attractor,
parallel
Zielonka
Recursivethrough
algorithm
discuss
performance
analysis
in terms
ofup
strong
andnodes
weakgenerated
scaling.
©
2017 The
Authors.
Published
by Elsevier
B.V.
Keywords:
Parity
Games,
multicore
Attractor,
parallel
Zielonka
Recursive
algorithm
Peer-review
under
responsibility
of the
committee
of
the
International
Conference
on Computational Science
discuss performance
analysis
in scientific
terms
of
strong
and
weak
scaling.
Keywords: Parity Games, multicore Attractor, parallel Zielonka Recursive algorithm
Keywords: Parity Games, multicore Attractor, parallel Zielonka Recursive algorithm

1
1 Introduction
Introduction
1 parity
Introduction
A
game [10, 21] is an abstract infinite-duration game played on a directed graph, where
1
Introduction
A
parity
[10, 21]
abstract
infinite-duration
game
played onmathematical
a directed graph,
where
each nodegame
is colored
byisa an
priority.
Parity
games represent
a powerful
framework

A
parity
[10, 21]
abstract
infinite-duration
game
played onmathematical
a directed graph,
where
each
nodegame
is
colored
byisquestions
a an
priority.
games
represent
a powerful
framework
to parity
address
fundamental
inParity
computer
science
and
mathematics.
connection
with
A
[10, 21]
abstract
infinite-duration
game
played onmathematical
a Their
directed
graph,
where
each
nodegame
is
colored
byisquestions
a an
priority.
Parity
games
represent
a powerful
framework
to
address
fundamental
in
computer
science
and
mathematics.
Their
connection
with
other
infinite
duration
games
is
strict,
for
example
’mean’
and
’discounted’
payoff,
’stochastic’,
each
node
is
colored
bygames
a priority.
games
represent
aand
powerful
mathematical
framework
to
address
fundamental
questions
inParity
computer
science
and mathematics.
Their
connection
with
other
infinite
duration
is
strict,
for
example
’mean’
’discounted’
payoff,
’stochastic’,
and
’multi-agent’
gamesquestions
[5, 6, 19].inIn
formal system
design
and verification
[7,connection
10, 17], parity
to
address
fundamental
computer
science
and
mathematics.
Their
with
other
infinite
duration
games
is
strict,
for
example
’mean’
and
’discounted’
payoff,
’stochastic’,
and
’multi-agent’
games [5,
6, 19]. Inmachinery
formal system
design and verification
[7, 10, 17],
parity
games
arise as
a natural
evaluation
to’mean’
automatically
and exhaustively
check
for
other
infinite
duration
games
is
strict,
for
example
and
’discounted’
payoff,
’stochastic’,
and
’multi-agent’
games
[5,
6,
19].
In
formal
system
design
and
verification
[7,
10,
17],
parity
games
arise
as
a naturaland
evaluation
machinery to automatically and exhaustively check for
reliability
of
distributed
reactive
systems.
and
’multi-agent’
games and
[5,
6,reactive
19]. Insystems.
formal system
design and verification
[7, 10, 17],
parity
games
arise
a natural
evaluation
machinery
to automatically
and exhaustively
check
for
reliability
of as
distributed
Through
the
years
severalevaluation
algorithms
to solve parity
games have been
proposed. Among
the
games
arise
as
a
natural
machinery
to
automatically
and
exhaustively
check
for
reliability
of
distributed
and
reactive
systems.
Through
theknown
years are
several
algorithms
to solve (ZR)[21],
parity games
have been
proposed.
Among
others,
well
the
Zielonka
Recursive
the Small
Progress
Measures
[16], the
the
reliability
of
distributed
and
reactive
systems.
Through
the
years
several
algorithms
to
solve
parity
games
have
been
proposed.
Among
the
others,
known are[20]
the and
Zielonka
Recursive
the All
Small
Progress
Measures
[16],
Strategywell
Improvement
the Big
Step
[18](ZR)[21],
algorithms.
of them
have
been implemented
Through
theknown
years are
several
algorithms
to solve
parity
games
have
been
proposed.
Among
others,
well
the and
Zielonka
Recursive
(ZR)[21],
the All
Small
Progress
Measures
[16], the
Strategy
Improvement
[20]
the
Big
Step
[18]
algorithms.
of
them
have
been
implemented
in
PGSolver,
a collection
ofZielonka
tools toRecursive
solve, benchmark
and
generate
parityMeasures
games. The
others,
well
known
are
the
(ZR)[21],
the
Small
Progress
[16],tool
the
Strategy
Improvement
[20]
and
the
Big
Step
[18]
algorithms.
All
of
them
have
been
implemented
in PGSolver, a collection of tools to solve, benchmark and generate parity games. The
tool
Strategy
Improvement
[20] of
andtools
the Big
Step [18]
algorithms.
of themparity
have been
implemented
in PGSolver,
a collection
to solve,
benchmark
andAll
generate
games.
The tool
in PGSolver, a collection of tools to solve, benchmark and generate parity games. The tool11
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
1
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
1
10.1016/j.procs.2017.05.120

526	

Parallel Parity Games

Arcucci,
Marotta,
Murano and Sorrentino
Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534

is written in OCaml by Oliver Friedman and Martin Lange [12, 13]. Noteworthy, PGSolver
declared the Zielonka Recursive Algorithm as the best performing in practice.
Along the years several improvements on the existing parity games algorithms and implementations have been considered in order to speed-up their execution time. PGsolver itself brings some
general preprocessing optimizations such as SCC decomposition, self-cycles removal, and priority
compression [1, 16]. A direction that has been positively exploited recently concerns improving
the code implementation along with the use of better performing programming languages. For
a long time, the scientific community relied on OCaml as the best performing language to be
used in this settings. In [9] an Improved Recursive Algorithm is introduced and presented a
tool written in Scala to solve parity games, showing a capability of gaining up to two orders
of magnitude in running time compared to PGSolver. Here, as a side result, we also show
that a similar gain can be obtained by using Java instead of Scala. The sequence reported in
(1) schematically represents the improvements over Zielonka Recursive algorithm. Although
PGSolver is no longer state of the art anymore, it is still a main reference point for comparison.
To have a real feeling of such an improvement, observe that the OCaml Classic Implementation
(OCI, for short) [13], included in PGSolver, with one of the biggest (completely) random game
it could handle, having 8000 nodes, takes 418 seconds on our machine to be solved. With
a simple improvement and the same programming language, the Improved Implementation
(IRI, for short) [9] takes 47 seconds being 10 times faster. With the introduction of the Java
implementation (JRI, for short), solving the same game on the same machine takes just 0.7
seconds being over 50 times faster.
OCI <×10 IRI <×50 JRI

(1)

The problem of declaring the winner in a parity game is known to be in UPTime ∩ CoUPTime
[15]. The time complexity of the recursive parity algorithms encourages the implementation
of software in High Performance Computing (HPC) environment expecially for big size games.
In [14] the authors present a GPU-specific implementation of algorithms for solving parity
games. They compare the obtained results with the PGSolver implementation of some algorithm.
Precisely, they provided a comparison with a multicore CPU version of the Strategy Improvement
algorithm. Conversely and noteworthy, no multicore version of the ZR algorithm are provided or
presented. Also, they provide comparisons of execution times but a study in terms of performance
gain for their algorithm is not provided.
In this paper, we face the development of a parallel ZR algorithm able to exploit the resources
of the available multicore architecture. One important issue is the study of scalability of the
algorithm itself [4]. Here, scalability refers to the capability of the algorithm to (i) exploit
performance of the available computing architectures in order to get a solution in a reduced
execution time (strong scaling), (ii) use additional computational resources effectively to solve
increasingly larger problems (weak scaling). We start by implementing an Improved version of
the ZR algorithm we describe in the next section. As we have seen that more than the 99% of
the execution time (see Table 1) of the ZR Algorithm is spent in its Attractor, we focus our
attention on the development of a parallel version of this module.
Game Size
Tot (seconds)
Attr (seconds)
%

4000
0.215
0.214
99.70%

8000
0.959
0.958
99.83%

12000
1.917
1.911
99.77%

16000
3.614
3.612
99.96%

20000
5.229
5.227
99.97%

Table 1: Percentage of the Attractor execution time with respect the Total execution time.
2

	

Parallel Parity Games

Arcucci,
Marotta,
Murano and Sorrentino
Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534

We have implemented the parallel algorithm (JRP, for short) on a multicore processor with
Hyper-Threading. As we show in Section 4, we have obtained a gain in terms of reductions of
execution times by using Hyper-Threading such that:
JRI <×q JRP

(2)

where q is the number of cores involved into the computations. Then, from (2) and (1), we have
obtained a gain of 500 × q with respect the OCI version, thus performing 2000 times faster on our
tests on random graphs by using a machine with 4 hyper-threaded cores. Then, if the solution
of a game with OCI would require one year, by using JRP on an hyper-threaded processor (like
Intel’s Xeon E5-2699 v4 Processor) it would require less than one hour.
The paper is structured as follows. In Section 2, we provide some preliminary notion about
the Parity Games. We introduce the Zielonka Recursive Algorithm and the Attractor routine
on which is based the solution of the game. In Section 3 we introduce the parallel version
of the Improved Attractor introduced in [9]. The parallel approach we employ is based on a
decomposition of the problem with a distribution of the nodes along the cores. In Section 4, we
provide the implementation of the proposed paralled algorithm and discuss its performance in
terms of weak and strong scaling. In this section we also report the link where our Java solver
is available. Finally, in Section 5 we give some conclusions and future work directions.

2

Parity Games

In this section, we report some basic concepts about parity games, including the Zielonka
Recursive Algorithm. As they are common definitions, an expert reader can also skip this part.
A parity game is a tuple G = (V, V0 , V1 , E, Ω) where (V, E) forms a directed graph whose set of
nodes is partitioned into V = V0 ∪ V1 , with V0 ∩ V1 = ∅, and Ω : V → N is the priority function
that assigns to each node a natural number called the priority of the node.
We assume E to be total, i.e. for every node v ∈ V , there is a node w ∈ V such that (v, w) ∈ E.
In the following we also write vEw in place of (v, w) ∈ E and use vE := {w | vEw}.
Parity games are played between two players called Player 0 and Player 1. Starting in a node
v ∈ V , both players construct an infinite path (the play) through the graph as follows. If the
construction reaches, at a certain point, a finite sequence v0 . . . vn and vn ∈ Vi then Player i
selects a node w ∈ vn E and the play continues with the sequence v0 . . . vn w.
Every play has a unique winner, defined by the maximum priority that occurs infinitely often.
Precisely, let j, k ∈ N be the indexes of positions, the winner of the play v0 v1 v2 . . . is Player i if
and only if max {p | ∀j.∃k ≥ j : Ω(vk ) = p} mod (2) = i.
A strategy for Player i is a partial function σi : V ∗ Vi → V , such that, for all sequences v0 . . . vn
with vj+1 ∈ vj E, with j = 0, . . . , n − 1, and vn ∈ Vi we have that σ(v0 ...vn ) ∈ vn E. A
play v0 v1 . . . conforms to a strategy σ for Player i if, for all j we have that, if vj ∈ Vi then
vj+1 = σ(v0 . . . vj ). A strategy σ for Player i(σi ) is a winning strategy in node v if Player i wins
every play starting in v that conforms to the strategy σ. In that case, we say that Player i wins
the game G starting in v. A strategy σ for Player i is called memoryless if, for all v0 . . . vn ∈ V ∗ Vi
and for w0 . . . wm ∈ V ∗ Vi , we have that if vn = wm then σ(v0 . . . vn ) = σ(w0 . . . wm ). That is,
the value of the strategy on a path only depends on the last node on that path. Starting from
G we construct two sets W0 , W1 ⊆ V such that Wi is the set of all nodes v such that Player i
wins the game G starting in v. Parity games enjoy determinacy, meaning that for every node v
either v ∈ W0 or v ∈ W1 [10].
Solving a parity game means deciding, for a given starting position, which of the two players
has a winning strategy. Formally, given a parity game, the sets W0 and W1 are computed,
3

527

528	

Parallel Parity Games

Arcucci,
Marotta,
Murano and Sorrentino
Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534

as well as the corresponding memoryless winning strategies σ0 for Player 0 and σ1 for Player
1 on their respective winning regions. The construction procedure of winning regions makes
use of the notion of Attractor. Let U ⊆ V and i ∈ {0, 1}. We define the attractor for Player
i, namely the i-attractor, of U as the least set W s.t. U ⊆ W and whenever v ∈ Vi and
vE ∩ W = ∅ , or v ∈ V1−i and vE ⊆ W then v ∈ W . Hence, the i-attractor of U contains all
nodes from which Player i can move ”towards” U and Player 1 − i must move ”towards” U . The
i-attractor of Uis denoted by Attri (G, U ). Formally, for all k ∈ N, the i-attractor is defined as
∞
Attri (G, U ) = k=0 Attri (G, U )k where Attri (G, U )0 = U and Attri (G, U )k+1 = Attri (G, U )k
∪ {v ∈ Vi | ∃ (v, w) ∈ E : w ∈ Attri (G, U )k } ∪ {v ∈ V1−i | ∀ (v, w) ∈ E : w ∈ Attri (G, U )k }.
Intuitively, the set Attri (G, U ) is the largest set of nodes from which the Player i with i ∈ {0, 1}
can attract the token from any node in Attri (G, U ) to U in a finite number of step.
In other words, Attri (G, U )k consists of all nodes such that Player i with i ∈ {0, 1} can force
any play to reach U in at most k moves.
Let A be an arbitrary attractor set. The game G \ A is the game restricted to the nodes V \ A,
i.e. G \ A = (V \ A, V0 \ A, V1 \ A, E \ (A × V ∪ V × A), ΩV \A ). It is worth observing that the
totality of G \ A is ensured from A being an attractor.[11]

2.1

The Zielonka Recursive Algorithm

The ZR algorithm makes use of a divide and conquer technique. It constructs the winning sets
for both players using sub-games that remove the nodes with the highest priority from the game
and the ones “attracted”. For this reason the corresponding subroutine that takes care of this is
called Attractor. Here, we consider the Attractor described in Algorithm 1, which is an improved
version of the classical one [9].1
The ZR algorithm starts by invoking the routine win(G), which takes a graph G as input
and, after a number of recursive calls over ad hoc built sub-games, returns the winning sets
(W0 , W1 ) for Player 0 and Player 1, respectively. The running time complexity of the algorithm
is exponential in the number of priorities, and polynomial in the number of edges and nodes.
See [9, 21] for more details.

3

The Parallel Algorithm

In this section we introduce, in Algorithm 2 , the parallel version of the Zielonka’s Attractor
algorithm. We start from the improved Attractor proposed in [9]and reported in Algorithm 1.
The parallel approach we introduce is based on a decomposition of the problem [2, 3] with a
distribution of the nodes along the cores. The Input of the resulting algorithm is split into
independent chunks which are processed by the parallel tasks in a completely parallel manner.
Algorithm 2 still takes as input the graph G, its transposed graph T , the Removed set containing
all the nodes filtered out, the initial set A and i, the attracting player. It returns the set A
containing all the attracted nodes exactly as in Algorithm 1.
A new function asyncAttr is introduced in Algorithm 2 as its parallel task which, besides the
same Graph G, Transposed T , Set Removed and player i, takes as input a single node of the set
A, namely A[index], and returns a set containing all the nodes attracted from that single one.
1 As an improvement, the Attractor introduced in [9] is able to check if a given node is excluded or not in
constant time. Moreover, it completely removes the need for a new graph in every recursive call. This is done in
the calling recursive algorithm in [9], by adding the node in a set called Removed that is given as input to the
Attractor, so it can work only on the nodes present in the evaluated sub-graph.

4

	

Parallel Parity Games

Arcucci,
Marotta,
Murano and Sorrentino
Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534

For each attracted node in A, we assign the task to the first available processor, that would
then take care of its edges in parallel (see vertical arrows in Figure 1) so that their result can be
combined into the set returned by the Attractor, until no more nodes are attracted.

Algorithm 1 Zielonka Improved Attractor
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28

function A t t r (G, T, Removed , A, i ) :
tmpM ap = []
f o r x = 0 t o |V | :
i f x ∈ A : tmpM ap[x] = 0
e l s e : tmpM ap[x] = −1
index = 0
while index < |A| :
f o r v0 ∈ adj(T, A[index]) :
i f v0 ∈ Removed :
i f tmpM ap[v0 ] == −1 :
i f player(v0 ) == i :
A = A ∪ v0
tmpM ap[v0 ] = 0
else :
adj counter = −1
f o r x ∈ adj(G, v0 ) :
i f x ∈ Removed :
adj counter+ = 1
tmpM ap[v0 ] = adj counter
i f adj counter == 0 :
A = A ∪ v0
e l s e i f ( player(v0 ) == j and
tmpM ap[v0 ] > 0 ) :
tmpM ap[v0 ]− = 1
i f tmpM ap[v0 ] == 0 :
A = A ∪ v0
index+ = 1
return A

Algorithm 2 Zielonka Parallel Attractor
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44

function P a r A t t r (G, T, Removed , A, i ) :
tmpM ap = []
f o r x = 0 t o |V | :
i f x ∈ A : tmpM ap[x] = 1
e l s e : tmpM ap[x] = ∞
index = 0
while index < |A| :
p = numproc(p, |A| − index, pmax)
f o r idproc ∈ (0, p) :
Aidproc = Aidproc ∪ asyncAttr(G, T,
A[index], Removed, i)
A = A ∪ Aidproc
index+ = 1
return A
function numproc ( p , i n d e x L e f t , pmax ) :
i f indexLef t < pmax :
p = indexLef t
else :
p = pmax
return p
function a s y n c A t t r (G, T, i n d e x , Removed , i ) :
A = {}
f o r v0 ∈ adj(T, index) :
i f v0 ∈ Removed :
i f test(tmpM ap[v0 ] == ∞) and
set(tmpM ap[v0 ] = 0) :
i f player(v0 ) == i :
A = A ∪ v0
tmpM ap[v0 ] = 1
else :
adj counter = 1
f o r x ∈ adj(G, v0 ) :
i f x ∈ Removed :
adj counter+ = 1
tmpM ap[v0 ]+ = adj counter
i f adj counter == 1 :
A = A ∪ v0
e l s e i f player(v0 ) == j :
tmpM ap[v0 ]− = 1
i f tmpM ap[v0 ] == 1 :
A = A ∪ v0
return A

The function numproc, at line 15, determines the number of threads p involved as function of
the number of nodes processed and the maximum number of concurrently executable threads
pmax . In Algorithm 1, on each iteration two important aspects have to be faced: (a) whether it
is the first to stumble upon that edge (see line 10) and to count all the adjacent edges (see line
18); (b) how many edges remain to be excluded before the node is attracted (see lines from 14
to 21); this information is stored in tempM ap.
These aspects are also faced in Algorithm 2. Regarding the point (a), we have that the counting
needs to be done just once, and to do it, each iteration still needs to know if it has been done
already or not. This can be achieved with a simple test and set (see line 26). The point (b) is
5

529

530	

Parallel Parity Games

Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534
Arcucci,
Marotta,
Murano and Sorrentino

Figure 1: Snapshot of an execution of the Attractor algorithm: Player 0’s (Even) nodes are
represented by circles while squares represent Player 1’s (Odd) nodes. The numbers indicated
inside represent the priorities. On the right there is a depiction of a directed graph representing
a Parity Game where the blue and the red regions are Player 0’s and Player 1’s winning region
respectively, while the blue and red arrows are Player 0’s and Player 1’s winning strategies.
On the left the snapshot of execution is represented on an adjacency matrix, particularly, the
adjacent edges (horizontal blue arrow) of incoming nodes of ”8” (vertical blue arrow) are being
examined by the attractor, as the one from node ”5” is. The attracted node are marked by ”A”,
notably, node ”5” is being attracted not having any edge going to a non attracted node. In
colored nodes, the winning region belonging is known. The values of Improved’s tempM ap are
also reported, with 0 marking attracted nodes, -1 unreached and 1 non-attracted. As indicated
by the vertical arrows, each node is processed in parallel by the Algorithm 2.
actually redundant, as it does not really need to know how many edges are left, but simply if any
edge is left. This means that it does not matter if there are one or more edges to be excluded,
if one is found it can be excluded regardless (see lines 38 and 39). This trick is useless on the
sequential algorithm as all the edges are always counted first, but on a parallel algorithm this
allows an edge to be excluded even before they are counted with no need to wait, and the same is
true for counting that can be translated in a simple addition to all the removed edges. Another
important aspect to consider is to avoid concurrency. Using an atomic increments/decrements
is enough to address the issue when updating the tempM ap counter on lines 35 and 39.
Regarding tempM ap, we introduce a new notation described in Table 2.
Read
tmpM ap[v0 ] < 0
tmpM ap[v0 ] == 0
tmpM ap[v0 ] == 1
tmpM ap[v0 ] > 1
tmpM ap[v0 ] → ∞

Meaning in Algorithm 2
At least one edge of v0 has been excluded
before the edges have been counted.
Someone is counting v0 ’s edges.
v0 can be attracted
At least one edge of v0 needs to be excluded for it to be attracted.
v0 has not been reached yet.

Meaning in Algorithm 1
v0 has not been reached yet.
v0 can be attracted
At least one edge of v0 needs to
be excluded for it to be attracted.
At least two edges of v0 need to
be excluded for it to be attracted.

Table 2: tmpMap’s notation.
6

Parallel Parity Games

	

Arcucci, Marotta, Murano and Sorrentino

Rossella Arcucci et al. / Procedia Computer Science 108C (2017) 525–534

531

The negative numbers no longer have no meaning to indicate uninitialized nodes. All numbers
minor or equal to zero tell us how many edges were excluded before counting, and the value
keeps going down until that happens. After counting, each value is never below 1. Nodes
with the value set to 1 can be successfully attracted. To indicate uninitialized nodes, the first
irrelevant number can be used, namely the maximum number of edges plus one, or infinite, as
we indicated at line 5 and 26 in Algorithm 2.

4

Implementation and Performance Analysis

We have implemented Algorithm 2 by using Java 8 on a quad cores Intel(R) i7-4790K CPU
@4.0GHz, 16GB of Ram DDR3 with Hyper-Threading.
The resulting compiled JAR, including all dependencies, is around 4MB on disk. Our Java
solver is available at http://ow.ly/haia305hMoV, to build the package we use Apache Maven,
you can run ”mvn clean compile assembly:single” to compile and produce a JAR artifact.
We used multiple instances of random parity games. The graph data structure is represented as
a fixed length Array of objects, where every node contains perfect information such as player,
priority, and adjacency and incidence lists. Precisely, following traditions, we have used 1000
random games generated through PGSolver, with a random number of outgoing edges and
priorities. In the settings of our arenas we benchmark graphs with 4K ≤ n ≤ 20K.
In Table 3, we present the execution times we denote with T p (n) for values of p = 1, . . . , 8 where
p denotes the number of threads (see line 15 in Algorithm 2, by fixing pmax = 8).
n
Nodes
4000
8000
12000
16000
20000

T 1 (n)
Seconds
0.536
1.013
2.011
3.787
5.420

T 2 (n)
Seconds
0.322
0.612
1.198
2.239
3.231

T 3 (n)
Seconds
0.232
0.435
0.852
1.609
2.286

T 4 (n)
Seconds
0.191
0.354
0.693
1.312
1.837

T 6 (n)
Seconds
0.157
0.275
0.549
1.058
1.506

T 8 (n)
Seconds
0.154
0.263
0.503
0.951
1.398

Table 3: Execution times.
We evaluate the performance of the parallel algorithm on the reference architecture by measuring
scalability in terms of strong and weak scaling. For the strong scaling analysis we evaluate the
speed-up we denote as:
T 1 (n)
(3)
SS p (n) = p
T (n)
for n = 4K, . . . , 20K and p = 1, . . . , 8 as showed in Figure 2. The ideal speed-up, according with
its classical definition is equals the number of physical execution units involved which is cores
in this case. Values of speed-up show how the performance improve as the size of the game
increases. This is due to the overhead decreasing.
We also evaluate the values of the efficiency:
SE p (n) =

T 1 (n)
qT p (n)

(4)
7

532	

Parallel Parity Games

Arcucci,
Marotta,
Murano and Sorrentino
Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534

Figure 2: Strong Scaling: SS p (n) as function of p for n = 4K, 8K, 12K, 16K, 20K.
where q and p denote the numbers of cores and threads, respectively. Results in Table 4 underline
as the use of Simultaneous Multi-Threading, or more specifically, Intel’s Hyper-Threading (see
last line of Table 4) available on our test machine, allow to gain back the efficiency, of a quad-core
architecture, lost due to memory accesses. This result is strictly in accord with the estimates
provided in [8] in which measured performance on common server application benchmarks for
this technology show performance gains of up to 30%.
q
1
2
4
4

p
1
2
4
8

SE p (4K)
1.00
0.83
0.70
0.87

SE p (8K)
1.00
0.83
0.71
0.96

SE p (12K)
1.00
0.84
0.72
0.99

SE p (16K)
1.00
0.85
0.72
0.99

SE p (20K)
1.00
0.84
0.74
0.97

Table 4: Strong Scaling Efficiency.
For the weak scaling analysis, the problem size and the number of processors increase. In
this case the scalability means the ability of maintaining a fixed time-to-solution solving larger
problems on larger architectures. We evaluate the scaling factor W S q (n) defined as the ratio:
W S q (n) =

Tf1lop (n)
qTfplop (q · n)

(5)

where Tf1lop (n) is the computing time required for the execution of T (n) floating point operations
and where the values of n and q are fixed such that n = q · 4K. As the time complexity of
the ZR Attractor algorithm is T (n) = O(e · nd ) where n, e, and d denote the number of nodes,
edges, and priorities in the game, respectively, the Theoretical scaling factor in (5) is such that:
W S q (n) 

e · nd
1
 d 
q
qe · q·n
q

(6)

We observe that, considering the implementation of Algorithm 2 in a software on our architecture,
the values of W S q (n), we denote here with M easured W S q (n), are obtained as
M easured W S q (n) =
8

Tf1lop (n)
p
qTfplop (q · n) + qTmem
(q · n)

(7)

	

Arcucci,
Marotta,
Murano and Sorrentino
Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534

Parallel Parity Games

p
where Tmem
(q · n) denotes the time for processors synchronization and memory accesses. Then,
it is

M easured W S q (n) =

Tf1lop (n)
qTfplop (q·n)

1+

p
qTmem
(q·n)
qTfplop (q·n)

<

Tf1lop (n)
= W S q (n)
qTfplop (q · n)

(8)

Table 5 shows values of the M easured W S q (n) compared with the values given by (6). Weak
scalability results provide informations about the performance of the algorithm on the available
Hyper-Threading architecture for solving a game of bigger size without a meaningful increase of
the execution time. The blue values obtained by using Hyper-Threading exhibit improvements
in terms of weak scalability with six threads running. As expected, performance decrease with
eight threads running due to the memory overhead.

q
1
2
3
4

p
1
2
3
4 |

6

|

8

M easured W S q (n)
1.00
0.44
0.21
0.10 | 0.24 | 0.14

T heoretical W S q (n)
1.00
0.50
0.33
0.25

Table 5: Weak Scaling where n = 4K
The obtained performance results confirm that the parallel approach which we have introduced
,based on a decomposition of the problem with a distribution of the nodes along the cores, allows
us to lead to an effective reduction of the overall execution time needed to solve the problem on
architectures such as multicore processors with Hyper-Threading.

5

Conclusion

Parity game is an important subject of study in computer science. However, the high computational complexity required to solve these games represents a serious bottleneck in their
application in complex and general domains. In the last twenty years, several attempts have
been caried out in order to introduce fast algorithms or to improve existing ones. An important
contribution in this direction is the ZR Algorithm, which has been used for some years now
as the best performing algorithm in practice. This algorithm and its implementation have
been the subject of several improvements, mainly consisting of graph manipulation, improved
implementations or just by using better performing programming languages [9].
In this paper, we have taken for the first time a different and promising scalable approach.
Precisely we have shown that it is possible to run efficiently the ZR algorithm on multiple cores
by parallelizing its Attractor, which has been observed to take more than 99% of execution time
on random arenas. We have implemented the parallel algorithm using Java 8 and compared it
to its sequential implementation in the same language and the widely used one in PGsolver (i.e.,
in OCaml). Our benchmarks show that the parallel implementation performs even faster than 4
times with 4 hyper-threaded cores, on random games, on average, compared to the sequential
counterpart, thus achieving an overall (bounded) linear-time speedup. Compared to PGsolver’s
implementation, the execution gets as high as 2000 times faster.
9

533

534	

Parallel Parity Games

Rossella Arcucci et al. / Procedia Computer Science
108C
(2017) 525–534
Arcucci,
Marotta,
Murano and Sorrentino

References
[1] A. Antonik, N. Charlton, and M. Huth. Polynomial-time under-approximation of winning regions
in parity games. ENTCS, 225:115–139, 2009.
[2] R. Arcucci, L. D’Amore, and L. Carracciuolo. On the problem-decomposition of scalable 4d-var
data assimilation models. In HPCS’15, pages 589–594. IEEE, 2015.
[3] R. Arcucci, L. D’Amore, L. Carracciuolo, G. Scotti, and G. Laccetti. A decomposition of the
tikhonov regularization functional oriented to exploit hybrid multilevel parallelism. International
Journal of Parallel Programming, pages 1–22, 2016.
[4] R. Arcucci, L. D’Amore, S. Celestino, G. Laccetti, and A.Murli. A scalable numerical algorithm
for solving tikhonov regularization problems. In PPAM’15, pages 45–54. Springer, 2016.
[5] K. Chatterjee, L. Doyen, T. A. Henzinger, and J.-F. Raskin. Generalized mean-payoff and energy
games. In FSTTCS’10, LIPIcs 8, pages 505–516, 2010.
[6] K. Chatterjee, T. A. Henzinger, and M. Jurdzinski. Mean-payoff parity games. In LICS’05, pages
178–187, 2005.
[7] E. M. Clarke, O. Grumberg, and D. A. Peled. Model Checking. MIT Press, 2002.
[8] D. L. Hill G. Hinton D. A. Koufaty J. A. Miller D. T. Marr, F. Binns and M. Upton. Hyper-threading
technology architecture and microarchitecture. Intel Technology Journal, Q1:1–12, 2002.
[9] A. Di Stasio, A. Murano, V. Prignano, and L. Sorrentino. Solving parity games in scala. In
FACS’14, LNCS 8997. Springer, 2014.
[10] E. A. Emerson and C. Jutla. Tree automata, µ-calculus and determinacy. In FOCS’91, pages
368–377, 1991.
[11] O. Friedmann. Recursive algorithm for parity games requires exponential time. RAIRO-Theoretical
Informatics and Applications, 45(04):449–457, 2011.
[12] O. Friedmann and M. Lange. The pgsolver collection of parity game solvers. University of Munich,
2009.
[13] O. Friedmann and M. Lange. Solving parity games in practice. In ATVA’09, LNCS 5799, pages
182–196. Springer, 2009.
[14] P. Hoffmann and M. Luttenberger. Solving parity games on the gpu. In ATVA’13, pages 455–459.
Springer, 2013.
[15] M. Jurdzinski. Deciding the winner in parity games is in up ∩ co-up. Inf. Process. Lett., 68(3):119–
124, 1998.
[16] M. Jurdzinski. Small progress measures for solving parity games. In STACS’00, LNCS 1770, pages
290–301. Springer, 2000.
[17] M. Y. Vardi O. Kupferman and P. Wolper. An automata theoretic approach to branching-time
model checking. JACM, 47(2):312–360, 2000.
[18] S. Schewe. Solving parity games in big steps. In FSTTCS’07, LNCS 4855, pages 449–460. Springer,
2007.
[19] A. Murano V. Malvone and L. Sorrentino. Concurrent multi-player parity games. In AAMAS 2016,
pages 689–697. ACM, 2016.
[20] J. Vöge and M. Jurdzinski. A discrete strategy improvement algorithm for solving parity games.
In CAV’00, LNCS 1855, pages 202–215. Springer, 2000.
[21] W. Zielonka. Infinite games on finitely coloured graphs with applications to automata on infinite
trees. Theor. Comput. Sci., 200(1-2):135–183, 1998.

10

