On the Properties of Runge-Kutta
Discrete Adjoints
Adrian Sandu
Department of Computer Science,
Virginia Polytechnic Institute and State University,
Blacksburg, VA 24061
sandu@cs.vt.edu
Abstract. In this paper we analyze the consistency and stability properties of Runge-Kutta discrete adjoints. Discrete adjoints are very popular in optimization and control since they can be constructed automatically by reverse mode automatic diﬀerentiation. The consistency
analysis uses the concept of elementary diﬀerentials and reveals that the
discrete Runge-Kutta adjoint method has the same order of accuracy as
the original, forward method. A singular perturbation analysis reveals
that discrete adjoints of stiﬀ Runge-Kutta methods are well suited for
stiﬀ problems.
Keywords: Runge-Kutta methods, discrete adjoints.

1

Introduction

Consider the ordinary diﬀerential equation (ODE)
y = f (t, y) ,

y (t0 ) = y0 ,

t0 ≤ t ≤ t F .

(1)

We will denote the Jacobian of the ODE function by J(t, y) = ∂f (t, y)/∂y.
We are interested in the following optimization problem, which arises in important applications like control and data assimilation. Find the initial conditions
for which a function of the system state at the ﬁnal time is minimized,
min Ψ (y0 ) = h y(tF )

subject to (1) .

y0

(2)

To apply a gradient based optimization procedure one needs to compute the
derivatives of the cost function Ψ with respect to the initial conditions. It can
be shown [6] that these derivatives can be obtained eﬃciently by solving the
continuous adjoint equation
λ = −J T t, y(t) λ ,

λ (tF ) =

∂h
y(tF ) ,
∂y

tF ≥ t ≥ t 0

backwards in time from tF to t0 to obtain
λ(t0 ) =

∂Ψ
.
∂y0

V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 550–557, 2006.
c Springer-Verlag Berlin Heidelberg 2006

(3)

On the Properties of Runge-Kutta Discrete Adjoints

551

Note that the continuous adjoint equation (3) is formulated based on the forward
solution y(t).
In practice the equation (1) is solved numerically on a computer to obtain
approximations of the ODE solution yn ≈ y(tn ). Using a one-step numerical
method (e.g., Runge-Kutta) the numerical solution is advanced in time as follows
yn+1 = Mn (yn ) ,

yN = MN −1 MN −2 · · · M0 (y0 )

,

(4)

where tN = tF and the numerical solution at the ﬁnal time is yN ≈ y(tF ).
The optimization problem (2) is formulated in terms of the numerical solution
minimized,
subject to (4) .
(5)
min Ψ (y0 ) = h yN
y0

To estimate the gradient of the cost function (5) several approaches are possible. In the continuous adjoint approach one solves the continuous adjoint equation (3) backwards in time using any numerical discretization technique, e.g.,
a Runge-Kutta method. The terminal value of the adjoint variable λ(t0 ) is an
approximation of the gradient of (2), and (hopefully) is also an approximation
of the gradient of (5).
In the discrete adjoint approach the gradient of (2) is computed directly from
(4) using the transposed chain rule
dΨ
dy0

T

=

dM0
(y0 )
dy0

T

···

dMN −1
(yN −1 )
dyN −1

T

dh
(yN )
dyN

T

.

This calculation proceeds backwards in time, i.e. the expression is evaluated
right to left as follows
λN =

dh
(yN )
dyN

T

...

λn =

dMn
(yn )
dyn

T

λn+1 . . .

λ0 =

dΨ
dy0

T

. (6)

We will call λn discrete adjoint variables. Their evaluation requires the forward
numerical solution y0 to yN to be available during the backward calculation.
Discrete adjoints are useful in optimization since they provide the gradients of
the numerical function that is being minimized. Continuous adjoints are useful
for sensitivity analysis studies. They are relatively easy to compute by applying a
numerical solver of choice to the continuous equation (3), and using the forward
solution y(t) obtained by interpolation from a sequence of checkpoints.
The calculation of gradients by reverse automatic diﬀerentiation leads to the
discrete adjoint approach. This paper is focused on analyzing some of the properties of the discrete adjoint variables λn and their relationship with the continuous adjoint variables λ(tn ) when the numerical integration (both forward and
backward in time) is performed by Runge-Kutta methods.
Consistency properties of discrete Runge-Kutta adjoints have been studied
by Hager [5], who gives additional order conditions necessary in the context of
control problems. Walther [7] has studied the eﬀects of reverse mode automatic

552

A. Sandu

diﬀerentiation on explicit Runge-Kutta methods, and ﬁnds that the order of the
discretization is preserved by discrete adjoints. Giles [2] has discussed RungeKutta adjoints in the context of steady state ﬂows. In this paper we consider
control problems where only the initial conditions are the control variables. This
setting is simpler than the distributed control case considered by Hager [5] and
Walther [7].
1.1

Runge-Kutta Methods

A general s-stage Runge-Kutta discretization method is deﬁned as [3, Section
II.1]
s

yn+1 = yn + h

h = tn+1 − tn ,

bi ki ,
i=1

(7)

s

ki = f ( tn + ci h, Yi ) ,

Yi = yn + h

ai,j kj ,
j=1

where the coeﬃcients ai,j , bi and ci are prescribed for the desired accuracy and
stability properties. If ai,j = 0 for j ≥ i the stage derivative values ki are deﬁned
implicitly, and are obtained by solving the nonlinear system (7).
Hager [5] has shown that the discrete adjoint (6) of the Runge-Kutta method
(7) is
s

λn = λn+1 +

θj ,
⎛

j=1

θi = h J T tn + ci h, Yi ⎝bi λn+1 +

s

⎞
aj,i θj ⎠ ,

(8)
i = 1···s .

j=1

Hager has also shown that if all bi = 0 then the discrete adjoint reads
s

λn = λn+1 + h

bi

i

,

i

= J T tn + ci h, Yi Λi ,

i=1
s

Λi = λn+1 + h

ai,j

j

,

with bi = bi , ai,j =

j=1

aj,i bj
.
bi

(9)

In the continuous adjoint approach one solves the equation (3) with a RungeKutta method (7) with coeﬃcients a
˜i,j , ˜bi , c˜i to obtain
s

˜bi ˜i ,

λn = λn+1 + h
i=1

˜i = J

T

tn+1 − c˜i h, y(tn+1 − c˜i h) Λi ,

(10)

s

a
˜i,j ˜j .

Λi = λn+1 + h
j=1

On the Properties of Runge-Kutta Discrete Adjoints

2

553

Consistency of the Discrete Adjoint Method

We now regard the discrete adjoint equation (8) as a numerical method applied to
the continuous adjoint equation (3) and try to assess how accurate this numerical
method is. At a ﬁrst glance if bi = 0 we can use the similarity between (9) and
(10) and apply the standard Runge-Kutta order conditions to the method with
coeﬃcients ai,j = (aj,i bj )/bi , bi , ci . The diﬃculty consists in the fact that in
the continuous adjoint (10) the transposed Jacobian is evaluated using the exact
numerical solution y(tn+1 − c˜i h), while in the discrete adjoint (9) the Jacobian
is evaluated using the stage solutions in the forward method Yi . Therefore the
accuracy with which these stage solutions are evaluated in the forward run aﬀects
the accuracy of the discrete adjoint method.
In implicit Runge-Kutta processes Yi are the solutions of a nonlinear system
of equations. The accuracy with which the nonlinear system is solved impacts
further the accuracy of the discrete adjoint. In this paper we will analyze the
order conditions under the assumption that the nonlinear systems are solved
exactly in both the forward (7) and the discrete adjoint (8) methods. An additional complication is given by the fact that black-box application of automatic
diﬀerentiation tools will result in a diﬀerentiation of the iterations needed to
solve the nonlinear system in the forward method. A discussion of the behavior
of the resulting (diﬀerentiated) iterations is beyond the scope of this paper.
Walther [7] found that the order of the discrete adjoints of explicit RungeKutta methods is the same as the order of the original method. In this section
we will prove the same result in greater generality; our proof is applicable to
both explicit and implicit Runge-Kutta methods.
Before we start the analysis we introduce the following “transfer functions”.
The discrete adjoint is obtained from the “discrete transfer function” RD
λn =

dyn+1
dyn

T

λn+1 = RD λn+1

Similarly from the linear continuous adjoint equation (3) we derive a linear
dependence between the continuous adjoint variables at diﬀerent time, and
call this dependence the “continuous transfer function” RC such that λ(tn ) =
RC λ(tn+1 ).
The analysis of the order of discrete adjoints is based on the concept of elementary diﬀerentials in the theory of order conditions explained in Hairer et al.
[3, section II.2]. The numerical solution of the forward Runge-Kutta method (7)
satisﬁes
(q)
J
=
γ(τ )
bj Φj (τ )F J (τ )(yn )
(11)
yn+1
h=0

τ ∈LTq

j

where the superscipt J denotes the component number, the ﬁrst summation is
taken after all labeled trees of order q, and F (τ )(yn ) is the elementary diﬀerential
associated with τ . Φj (τ ) is a combination of method coeﬃcients associated with
τ and γ(τ ) is the multiplicity of tree τ .

554

A. Sandu

The derivative of the solution yn+1 with respect to yn satisﬁes
J
∂yn+1
∂ynP

(q)

=
h=0

∂
yJ
∂ynP n+1

(q)

=
h=0

bj Φj (τ )FPJ (τ )(yn )

γ(τ )
τ ∈LTq

j

(12)
where FPJ (τ )(yn ) is the partial derivative of the elementary diﬀerential with
respect to P -th argument, namely ynP . Consequently the (P, J)-th entry in the
discrete transfer function has the following derivatives
P,J
RD

(q)

=
h=0

bj Φj (τ )FPJ (τ )(yn ) .

γ(τ )
τ ∈LTq

(13)

j

The exact solution of the direct system satisﬁes [3, Section II.2]
yJ

(q)

F J (τ )(yn ) .

=
t=tn

(14)

τ ∈LTq

Consider now the continuous adjoint equation. With Δt = tn −tn+1 the Taylor
series of RC about tn+1 is
λ(tn ) = RC λ(tn+1 ) =
j≥0

Δtq (q)
R λ(tn+1 ) =
q! C

j≥0

Δtq (q)
λ (tn+1 )
q!

(q)
RC

and therefore
maps λ(tn+1 ) to λ(q) (tn+1 ). It can be shown that the derivatives of the exact solution of the adjoint equation, taken with respect to (−t) at
tn , are
(q)
=
FPJ (τ )(yn )λJ (tn ) .
(15)
λP
t=tn

τ ∈LTq

This implies that for the continuous transfer function
P,J
RC

(q)

FPJ (τ )(yn ) .

=

(16)

τ ∈LTq

For example taking the derivative w.r.t. (−t) in (3) gives
λ(1) = J T t, y(t) λ ⇒ λP

(1)

fPJ λJ =

=
J

FPJ (τ1 )λJ .
J

This implies that for the continuous transfer function
P,J
RC

(1)

= FPJ (τ1 )(yn ) .

Similarly
λP

(2)

fPJ K f K λJ +

=
J,K

⎛

fPJ (λJ )(1) =
J

⎝fPJ K f K +

=
J,K

⎞

fPJ K f K λJ +
J,K

J K⎠ J
fK
fP λ =
J,K

J,K

FPJ (τ21 )λJ ,
J

fPJ fJK λK

On the Properties of Runge-Kutta Discrete Adjoints

555

and therefore for the continuous transfer function we have
(2)

P,J
RC

= FPJ (τ21 )(yn ) .

Continuing this process one obtains (16).
A comparison of (13) and (16) shows that the numeric transfer function equals
the continuous transfer function up to order p iﬀ
bj Φj (τ ) =
j

1
,
γ(τ )

for all trees τ of order ≤ p. But these are exactly the conditions under which
the forward method is of order p. Consequently, the discrete adjoint of an order p Runge-Kutta method is a discretization of order p of the continuous adjoint equation if the problem is suﬃciently smooth (y(t) has p+1 continuous
derivatives).

3

Discrete Adjoints and Stiﬀ Problems

The traditional linear stability analysis approach [4] considers the transfer function R(z) of a Runge-Kutta method when applied to a linear scalar test problem
y = αy. One can easily see that the transfer function of the discrete adjoint
method (8) is the same as the transfer function of the forward Runge-Kutta
method (7), and therefore the discrete adjoints inherits the stability properties
of the original method.
To better understand the behavior of discrete Runge-Kutta adjoints on stiﬀ
systems we consider the singular perturbation model problem
y = f (y, z) ,

t0 ≤ t ≤ t F

z = g(y, z) ,

(17)

with the sub-Jacobian gz assumed nonsingular. For this system we distinguish
between the adjoint variables of the nonstiﬀ and of the stiﬀ components
λ(t) =

∂Ψ y(tF ), z(tF )
,
∂y(t)

μ(t) =

∂Ψ y(tF ), z(tF )
.
∂z(t)

The adjoint variables satisfy the continuous adjoint equation
⎡ ⎤
⎡ T
fy
λ
⎣ ⎦ = −⎣
μ
fzT

⎤ ⎡ ⎤
λ
⎦ ⎣ ⎦ .
−1 T
μ
gz
−1 T
gy

(18)

Consider an -expansion of the solution
i

λ=
i≥0

λi ,

i

μ=
i≥0

μi ,

(19)

556

A. Sandu

insert it into (18) and equate the

series. The

−1

term leads to

μ0 = 0 .

(20)

We equate recursively the higher order terms to obtain
(λi ) = −fyT + gyT gz−T fzT λi + gyT gz−T (μi )
μi+1 = −gz−T (μi ) + fzT λi ,

for

i = 0, 1, 2, . . .

(21)

The zeroth order term evolution is given by the equation
(λ0 ) = −fyT + gyT gz−T fzT λ0 .
Consider now the Runge-Kutta discrete adjoint (8) for the method applied to
the singular perturbation systems (17). Denote by A, b, c the coeﬃcient matrices
of the Runge-Kutta method, by e a vector of ones, and let
GZ = diagi gz (Yi , Zi ) ,

FZ = diagi fz (Yi , Zi ) ,

GY = diagi gy (Yi , Zi ) ,

FY = diagi fy (Yi , Zi ) ,

T

S =

FYT

−

GTY

T
G−T
Z FZ

,

A careful analysis based on -expansions of the discrete solution and of the
stage vectors leads to the following conclusions.
If the Runge-Kutta coeﬃcient matrix A is invertible then the adjoints of the
stiﬀ variables are integrated using
μ0n = R(∞) μ0n+1 ,
where R(·) is the stability function of the RK method. We see easily that for
methods with R(∞) = 0 the ﬁrst order term in the μ adjoint is zero, μ0n = 0.
This is desirable considering the exact solution (20). In this case the values of μ
are solved with the same accuracy as the original method, within O( ).
The adjoints of the non-stiﬀ variables are integrated as
λ0n = 1 + heT I − hS T AT
+eT I − hS T AT

−1

−1

ST b

λ0n+1

−T
GTY G−T
b μ0n+1
Z A

(22)

Therefore the adjoint with respect to the nonstiﬀ variable depends on both μ0n+1
and λ0n+1 .
If R(∞) = 0 and we are away from the initial condition then μ0n+1 = 0 and
we have a discretization of the reduced adjoint equation (21). The same holds if
the cost function depends only on the non-stiﬀ variables, Ψ = Ψ (y). In this case
the values of λ are solved with the same accuracy as the original method, within
O( ). Note that the initialization of μ0N = 0 can introduce an O(1) perturbation
in λ0N −1 .

On the Properties of Runge-Kutta Discrete Adjoints

4

557

Conclusions

In this paper we analyze the consistency and stability properties of Runge-Kutta
discrete adjoints. Discrete adjoints are very popular in optimization and control
since they can be constructed automatically by reverse mode automatic differentiation. However, the properties of the discrete adjoints are often poorly
understood.
The consistency analysis uses the concept of elementary diﬀerentials and reveals that the Runge-Kutta discrete adjoint method has the same order of accuracy as the original, forward method. The discrete adjoint also inherits the
linear stability properties of the original method. A singular perturbation analysis shows that L-stable Runge-Kutta methods with an invertible coeﬃcient
matrix are well-behaved under discrete adjoint operation.

Acknowledgments
This work was supported by the National Science Foundation (NSF) through the
awards NSF CAREER ACI-0413872, NSF ITR AP&IM 020519, and NSF CCF–
0515170, by the National Oceanic and Atmospheric Administration (NOAA)
and by the Texas Environmental Research Consortium (TERC).

References
1. M.L. Baguer and W. Romisch. Computing gradients in parametrizationdiscretization schemes for constrained optimal control problems. Approximation
and Optimization in the Carribbean II, p. 14–34, M. Florenzano editor, Peter Lang,
Frankfurt am Main, 1995.
2. M.B. Giles. On the Use of Runge-Kutta Time-Marching and Multigrid for the Solution of Steady Adjoint Equations. Technical Report NA00/10, Oxford University
Computing Laboratory, 2000.
3. E. Hairer, G. Wanner, and S.P. Norsett. Solving Ordinary Diﬀerential Equations I.
Nonstiﬀ Problems. Springer Series in Computational Mathematics, 1991.
4. E. Hairer and G. Wanner. Solving Ordinary Diﬀerential Equations II. Stiﬀ and
Diﬀerential-Algebraic Problems. Springer Series in Computational Mathematics,
1996.
5. W. Hager. Runge-Kutta methods in optimal control and the transformed adjoint
system. Numerische Mathematik 87(2):247–282, 2000.
6. A. Sandu, D. Daescu, and G.R. Carmichael: “Direct and Adjoint Sensitivity Analysis of Chemical Kinetic Systems with KPP: I – Theory and Software Tools”, Atmospheric Environment, Vol. 37, p. 5083–5096, 2003.
7. A Walther. Automatic Diﬀerentiation of Explicit Runge-Kutta methods for Optimal
Control. Technical University Dresden technical report WR-06-2004. To appear in
Journal of Computational Optimization and Applications.

