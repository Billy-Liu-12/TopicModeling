Procedia
Computer
Science

Procedia Computer Science 00 (2009) 000‚Äì000

Procedia Computer Science 1 (2012) 2529‚Äì2538

www.elsevier.com/locate/procedia

www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Pattern mining from saccadic motion data
Peter Liang a, Yingzhen Yang b, Yang Cai c,*
a,b,c

Carnegie Mellon University, 4720 Forbes Ave., Pittsburgh, PA 15213, USA

Abstract
A saccade contains fixations between rapid movements. Human movements are often saccadic in a fast forwarding video tape. In
this paper, we present a novel model for pattern representation and pattern matching in saccadic motions, by converting a twodimensional saccadic motion sequence into a string of letters or numbers, with linear, extended chain code or direct encoding
methods. This enables us to cluster and pattern matching with the fast text search algorithm. Our model is tested with the data of
eye movement in video analysis and human movement in a building. The results show that the both extended chain code and
linear encoding methods can be applied to eye gazing data analysis effectively. Extended chain code yields more accuracy in
pattern clustering. However, it may accumulate errors when the motion pattern sequence is long and contain parallel subsequences. The direct labeling method works effectively in the Smart Building data analysis. Using the fast text algorithm, we
found interesting patterns of the human movement.

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
‚Éù
Keywords: saccadic motion; sensor network; smart environment; data mining; encoding; clustering

1. Introduction
A saccade is usually referred to a rapid movement of an eye or body parts. It contains fast shift and frequent fixation.
Saccadic motion is very important to study human attention and visual routines. Eye movement reveals user
behaviors in routine tasks such as browsing the web or watching television [1,2,3,8]. Moreover, gaze fixation in
between the movements can be used to trigger actions [4, 5] or infer the user task [6] and multimodal user interfaces
[13]. The gaze tracking data is also analyzed to predict the skill levels between different users in [7].
Human movements also can be saccadic if we fast forward the video tape. We move from one place to another
frequently and stay there for a period of time. Our daily motion is a sequence of saccadic moves and stops. For over
a decade, Ambient Intelligence developers aim to build smart environments with sensor networks to pervasively
monitor human activities in a building for elderly and disabled people [16]. Recent studies include designing a home
for elderly people or people with disabilities. Healthcare systems are looking for an easy and cost effective way to
collect and transmit data from a patient‚Äôs home. Universities and corporations launched labs to explore the healthy
living environment, such as LiveNet, HomeNet, and Philips‚Äô HomeLab. With growing amount of pervasive sensing
data, it is a challenge to search, sort and compare the patterns in spatiotemporal sensing data. So far, visualization is
a prevailing method for studying the saccadic motions.
Both eye gaze and body motion cases involve spatial and temporal information about the trajectories of saccadic
points. Mining through the maze of the patterns appears to be challenging in terms of pattern representation methods

*

Corresponding author. E-mail: ycai@cmu.edu

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ‚Éù
doi:10.1016/j.procs.2010.04.286

2530

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

and computational cost. Stochastic models such as Hidden Markov Chain [14] is developed to predict the saccadic
motion, however, it doesn‚Äôt provide clustering and search functions. Spatial Bayesian model is developed to
discover the two-dimensional patterns in satellite images [15]. However, it doesn‚Äôt work well on sparse datasets
where the probability function is conditional to the context or situations.
In this paper, we present an algorithm for analyzing general saccadic motion. The goal is to develop a reliable
and fast analytical tool to map the dynamic two-dimensional data into a one-dimensional string. We perform pattern
clustering and search from a massive database. Then we study the saccadic eye movement in video analysis and
human movements in a smart building. We use these two significantly different case studies to validate the general
saccadic motion model, especially the power of the data mapping and pattern discovery.
2. Encoding Saccadic Motion
Given a two-dimensional motion space that can divide the space into m by n cells with rows i = 1, ‚Ä¶ , m and
columns j = 1, ‚Ä¶ , n, the minimal fixation time for each movement is «ª, the maximal length of a sequence of
saccadic motions is q¬∑ «ª, we can linearly map the two-dimensional motion into a one-dimensional string L(k):
L(k) = (i‚Äì 1)¬∑n + j

(1)

where L(k) can be an ASCII letter, a number, or a memory address. For example, human motion in a building can
be represented as a sequence of actions. Fig 1 shows a simplified home model, where the space is divided into four
areas: kitchen, bedroom, bathroom and living room. The correspondent activities are Eat (E), Sleep (S), Toilet (T)
and Play (P). Here we can set L(1) = E, L(2) = S, L(3) = T, and L(4) = P. Assume each saccadic movement take a
unit time «ª, a sequence of activities for an elderly can be represented as a string sequence directly, similar to the
DNA strand: SETPETPS‚Ä¶. If a fixation period takes more than one unit «ª, then multiple letters can be used, such
as SSS, or PP. In this way, we compress temporal and spatial data into a graph, which preserves the order of the
event sequences as well as patterns. This is the key step of our modeling for saccadic motion.

Fig. 1. A simplified home model of four connected areas

Linear encoding presents absolute position. However, it doesn‚Äôt reflect the orientation and shape information very
well. Chain Code is an orientation-based encoding method. It represents an outline of a shape with straight line
segments. The direction of each segment is coded by a unique number. Studies show that chain code is translation
invariant [9], which is an advantage in saccadic motion analysis. In order to fully capture the variability in both
direction and magnitude in the saccadic gaze movement, we extend the 8-direction Freeman chain code to include
much more directions. Instead of restricting the number of directions to a constant 8, we set it as a customized
variable. Suppose O is the origin of all direction vectors, we put O as the center of a (2n+1) x (2n+1) grid. Each grid
point A except O can be the end point of the direction vector OA . Thereby we have a total number of (2n+1) x
(2n+1) -1 direction vectors. Although some of them have the same direction, they would differ in magnitude and we
argue that magnitude difference can indubitably help represent the variability in the raw gaze data. Like Freeman

2531

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

chain code, we also use a unique number to label each direction vector. If grid point A has coordinates (i, j), then the
label for direction vector is defined as below:
Label (OA)

i u (2n  1)  j

(2)

It can be easily verified that the 8-direction Freeman chain code is a special case of the extended chain code for n =
1.

Fig. 2. The Illustration of sequential code (a) and the extended chain code (b) used in this paper for n=3. Each black dot
A and the origin O represent a direction vector OA .

In many cases, we can ignore the exact layout of the motion and only deal with the order of the action sequences.
We then may simplify the mapping function to a direct label assignment:
L(k) = S(k)

(3)

where S(k) is the name of the kth sensor and L(k) is the kth letter of the saccadic motion dictionary. Note that the
linear mapping is not limited by the capacity of the single letters. The L(k) can be multiple letters. Besides, the
length of the L(1),‚Ä¶L(q) is unlimited, which can be more than the maximal string length.
3. Clustering Saccadic Sequences
Given a set of saccadic motion sequences, how do we find similar patterns in the data? Ideally, we hope to find a
mean of saccadic trajectories and calculate the standard deviations from the mean. Unfortunately, it is not often the
case for human behaviors ‚Äì there is no typical ‚Äòmean‚Äô behavior in real world because of the diversity of humans.
Therefore, we have to cluster the similar trajectories into several groups. In this study, we use a K-mean based
model [10] for the one-dimensional saccadic motion clustering.
K-means algorithm partitions the observed data points into k clusters where each data point belongs to the cluster
with the nearest mean. There are two phases in K-means: re-assigning data points to clusters and re-computing the
cluster means. K-means runs these two phases in an iterative way until there is no further change in the assignments
or some maximum number of iterations is exceeded. In our implementation, we use Euclidean distance as the
distance measurement between data points, and we use both the distance threshold d, namely the distance centers
move by between the subsequent iterations and a maximal iteration number to control the iteration procedure.
Suppose we have a data set {x1, x2, ‚Ä¶ , xn}, which has been portioned into K clusters {s1, s2, ‚Ä¶ , sk}, and the
means vectors for these K clusters are {c1, c2, ‚Ä¶ , ck} respectively. Then we define the error measurement as the
sum of the squares of the distances of each data point to its assigned vector, that is,
K

Error

¬¶¬¶

i 1 x j ¬èSi

x j  ci

2

(4)

2532

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

4. Partial Matching Saccadic Sequences
In many cases, the saccadic sequences don‚Äôt have equal lengths. How do we match a sub-sequence from a massive
sequence database? This problem is similar to a DNA sequence search. But DNA only contains four letters. Here we
want to generalize the number of unique positions or activities to an arbitrary amount. To realize such a pattern
matching algorithm, we apply the fast text search with errors [11]. Given a set of symbols A, sequence T with length
n, the sub-sequence pattern P with length m, and tolerance of errors k, Bitap(A, T, P, k) finds all substrings of T that
is within a Levenshtein distance of k or less from P and returns a value k‚Äô <= k where k‚Äô is the smallest tolerance
such that there is still a match and infinity otherwise:
First, consider the case of k = 0 meaning we want an exact match. Suppose R[j][i] = 1 if the first i characters of
P matches the last i characters of the prefix of T ending at the j-th index. In other words, P1P2...Pi = Tj-i+1...Tj-1Tj.
Thus, we can evaluate R[j][i] recursively as:
R[j][i] =

R[j-1][i-1] AND Tj = Pi

Since R[j][i] contains a single bit, R[j] for each j is just a bit string. Then for any given j, we can evaluate R[j][i] for
all i in parallel. Instead of accessing R[j-1][i-1] for each individual i, we can just right shift the entire bit string R[j1] by 1. The second part of the equation T[j] = P[i] can be pre-computed in the following way: For each element u
in the alphabet A, define a bit vector Map[u] = B such that
Bi = 1 if Pi = u and 0 otherwise

Thus, we can evaluate R[j] recursively as:
R[j] = (R[j-1]>>1) AND Map[Tj]

Note that since we only need R[j-1] to find R[j], we only need to keep 1 bit string in memory. Suppose we are
allowed to have k errors in the matching. Then define R[j][i][k]=1 if the first i characters of P matches the last i
characters of the prefix of T ending at the j-th index with k errors or less. Then there are 4 cases:
match:
mismatch:
delete a letter from P:
insertion a letter into P:

R[j-1][i-1][k] and T[j] = P[i]
R[j-1][i-1][k-1]
R[j][i-1][k-1]
R[j-1][i][k-1]

Again these cases can be evaluated in parallel in the following way
Rnew[k] =

RightShift(R[k]) AND map[T[j]]
OR RightShift(R[k-1])
OR RightShift(Rnew[k-1])
OR R[k-1]

//match
//mismatch
//delete
//insert

Similar to the k=0 case, we only need to keep k bit arrays in memory and the runtime of the algorithm is O(nk).
Given this string searching algorithm, the procedure buildData takes every unique string S from the database and
give it an importance score I where I is the number of strings S2 from the database (non-unique) such that Bitap(A,
S2, S, |A|) returns 0. In other words, I is the number of times S appears as an exact substring of a string S2 in the
database.
buildData:
For String S in String Set
matches = -1;
List closest;
Map kNN;
For String S2 in String List
res = Bitap(S, S2, |A|);

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

if res = 0
matches++;
updateClosest( S, S2, res );
if closest.size < K
avg = INFINITY;
else
avg = findAverage(closest) / K;
kNN.put( str, avg);
if matches > 5
output(S, matches);
End

While we calculate the importance score for each unique string S, we can at the same time find its K nearest
neighbors. We can then test for anomalies using the distance based KNN model. For this study, we used K = 30. A
string S is an outlier if the average V of the distance between S and its closest k neighbors is large. In particular, if: V
> G/ƒ±, then S is an anomaly, where G = floor(|S| * (1.0 ‚Äì 1.09 / sqrt( |A| ))), and ƒ± is the constant
value as 2.2 [12]. It is known that for a tolerance of G, only few strings will match and most won‚Äôt. We can divide
this value by ƒ± to be more restricted. Similarly, to query whether an input string is normal or abnormal, the same
model is used.
5. Case Study: Eye Movement
Eye movement is an important channel for psychological studies. How to cluster and retrieve the saccadic motion
patterns is a challenging task. In this case study, we collected our own data at the lab environment. We recruited 15
people to collect 15 gaze samples for experimental analysis using the eye tracker Quick Glance 2 [8].

Fig. 3. Snapshots of the video clip for the eye movement experiments

The 15 subjects, including 8 males and 7 females, are all undergraduate or graduate students with an average age of
25. When sampling the gaze data, we require all subjects to view the same 30 seconds video clip, in which there are
salient moving objects and crowd. The sampling rate of Quick Glance 2 is set to be 40 milliseconds. Figure 3 shows
a sample of the test video screenshots.
The raw data is stored in order of user id, x, y, and fixation time. Figure 4 shows all the 15 original trajectories.
We then use formula (1) to map the two-dimensional data into one-dimensional string. In this case, we divided the
screen into a 120 x 120 cells. We use 40 milliseconds as the minimal fixation time.
We then cluster the saccadic trajectories into groups (k = 2 to 6), corresponding errors in the k-clustering. The
results are listed in Table 1. Given the same lengths of the trajectory strings, we found that the errors decrease as the
number of groups increases.

2533

2534

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

Fig. 4. Trajectories of the 15 gaze samples, where ‚Äòx‚Äô and ‚Äòy‚Äô are display axes and ‚Äòtime‚Äô is the gaze period

Table 1. Error measurement of K-means clustering for gaze data analysis
K

Clustering Results

Error of K-means by
Sequential Code

2

(1,2,3,4,5,6), (7,8,9,10,11,12,13,14,15)

1.69 x 107

3

(2,6,7,8,9), (1,3,4,5), (10,11,12,13,14,15)

1.30 x 107

4

(1,2,3,4,5,8), (7,9), (6), (10,11,12,13,14,15)

1.34 x 107

5

(1,2,3,4,6), (5), (7,8,9,10,14), (11,12,13), (15)

0.98 x107

6

(1,3,4,5), (2,6), (7,11), (9,10,14), (8), (12,13,15)

0.81 x107

We also compared our method against the Extended Chain Code based model described above. We find that our
Extended Chain Code method yields more accurate results than linear encoding method. It is because our linear
encoding method assigns individual sub-areas of the screen, while the Extended Chain Code uses directional cues.
However, Chain Code would accumulate errors if the sequence is very long and the sequence contains parallel
motions.
Table 2. Comparison between linear mapping and the Extended Chain Code mapping
K

Linear Mapping

Extended Chain Code Mapping

2

1.69 x 107

1.68 x 105

3

1.30 x 10

7

1.51 x 105

1.34 x 10

7

1.46 x 105

7

1.25 x 105

7

1.16 x 105

4
5
6

0.98 x10
0.81 x10

In addition, we found that the linear encoding method enables saccadic motion analysis at multiple resolutions. For
example, a coarse segmentation of the screen can lead to a fewer labels in a string, vice versa.

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

6. Case Study: Human Motion in Smart Building
Our second case study is about human motion in a large building with over 10 access points. At each access point,
the user identification and time is recorded. The human motion can be viewed as a sequence of saccadic movements
because the motion combines with shifts and fixations. Given the real-world database of movement sequences over a
two-month period, we aim to discover which sequences of movements are popular, and which are anomalous. The
access point sensor can be encoded as a sequence of symbols. The layout of the access points is shown in Fig 5.

Fig. 5. Floor plan layout of 10 access point sensors. The labels are directly mapped from the sensors.
The width of the links represents the traffic volume between the nodes. The first problem in this case is that human motion
sequences in the database have significant different length, which is a challenging to k-mean based clustering
method because it assumes all the sequences are equal in length. To resolve this problem, we force the sequence
length to a defined value, e.g. length = 4. Then we are able to group the motion patterns from the database. Figure 6
shows our results of K=5 from 15 motion sequences. We also show the error measurement of the K clusters (from 2
to 6) for the human movement analysis in Table 3.

Fig. 6. 3D illustration of 15 motion strings with length 4. They are partitioned into 5 clusters, marked with symbol ‚Äò+‚Äô,‚Äôx‚Äô,‚Äô*‚Äô,
square and circle respectively. The axis ‚Äòposition‚Äô and ‚Äòtime step‚Äô specify a single motion string of length 4, and the axis
‚Äòsequence number‚Äô are the indices of the 15 motion strings

2535

2536

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

Table 3. Error measurement and the composition of the K clusters for 15 motion strings with length 4
Composition of K clusters

Error of
K-means

K

(EEIG,EEIG,AAAA,AAAJ,EEEE), (JJEG,JJGH,JGHH,JJHG,JJEI,JJJG,JJHG,JJJJ,JJJJ,JEIG)

14.667

2

(JJEG,JJGH,JGHH,EEIG,EEIG,JJHG,JJEI,JJHG,JEIG), (JJJG,JJJJ,JJJJ), (AAAA,AAAJ,EEEE)

12.667

3

(EEIG,EEIG,AAAA,AAAJ,EEEE), (JGHH,JJJJ,JJJJ,JEIG), (JJEG,JJEI), (JJGH,JJHG,JJJG,JJHG)

12.093

4

(JJEG,JJGH,JJEI), (AAAA,EEEE), (EEIG,EEIG), (AAAJ), (JGHH,JJHG,JJJG,JJHG,JJJJ,JJJJ,JEIG)

5.302

5

(EEIG,EEIG), (JJEG,JJGH,JJHG,JJEI,JJHG), (AAAJ), (JGHH,JJJG,JJJJ,JJJJ,JEIG), (AAAA), (EEEE)

3.067

6

With our partial matching algorithm, we find that location J is the most commonly triggered, and it is also triggered
repeatedly often (J = 7227, JJ = 2884, JJJ = 782). Strings of length 2 containing E is also frequent (EI = 973, JE =
304, EG = 232, EJ = 199, HE = 118) suggesting that E branches off to a lot of other locations. Also, most
occurrences of J also involve E, suggesting that employees at position J usually transfer to E. It also means J is a
major chokehold in the building because E is the center of the building. Also, it might be problematic if employees
could not access J since they may be cut off from the rest of the building. Certain anomalies were also detected in
the database. Some motion strings describe routes from A to B that are roundabout and obviously not the closest
way between A and B. For instance, DCI was detected as an anomaly. Looking at the floor plan, it is easy to find
that the path from D directly to I is much shorter than D ‡µ∫ C ‡µ∫ I. Furthermore, sometimes errors might happen and a
scanner fails to record an employee walking back. For example, EB was detected as an anomaly and looking at the
floor plan, it seems unlikely to get from E to B without triggering any other sensors. Thus, it‚Äôs possible that this
sequence was produced because the sensor didn‚Äôt work that times (events like this would occur rarely). Other
suspicious sequences including walking in a circle (IHEI, GHJEI, CFAC) and walking back and forth for long
periods of time (HGHGGHGGHGHGH).
We can also compute the frequency ranks of motion strings with length 4 or more in Fig 7, and the outlier score
distribution for motion strings of length 4 in Fig 8. We find that many anomalous events are conditional or local. For
example, our algorithm picks up a unique anomalous event sequence: (JJJJJJJJ). However, when we consider the
time of day when the events happened, the sequences become (JJ, JJJ, JJ, ‚Ä¶ ), which are normal. On the other hand,
a few cases seem normal but in fact they are anomalous events, if we consider the ‚Äòtime of day‚Äô variable. For another
example, frequent accessing living room after middle night is often considered as an anomalous event.

Fig. 7. Frequency ranks of motion strings with length 4 or more. JJJJ* indicate motion strings whose length is 4 or
more and only contain J‚Äôs

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

Fig.8. Outlier score distribution for sequences of length 4 (err = 1.75, anomaly rate = 11.6%)

7. Conclusion
In this paper, we present three encoding methods to map the two-dimensional saccadic motion to one-dimensional
string: linear, extended china code and direct labeling. The mapping function enables rapid spatiotemporal analysis
with mature models such as K-mean based clustering and fast text search with partial pattern matching.
We then study two saccadic motion cases: eye movement and human motion in a smart building. The results show
that the both Extended Chain Code and Linear encoding can be applied to eye gazing data analysis effectively.
Extended Chain Code yields more accuracy in pattern clustering. However, it may accumulate errors when the
motion pattern sequence is long and contain parallel sub-sequences. The Direct Label method works effectively in
our Smart Building data analysis. Using the fast text algorithm, we found interesting patterns of the human
movement.
Acknowledgement
This research is in part supported by CyLab at Carnegie Mellon under grant DAAD19-02-1-0389 from the Army
Research Office, CERT, and Bosch Research Center in Pittsburgh. The authors would like to thank the comments
from the reviewers and Brian Zeleznik.

References
1.
2.
3.
4.
5.
6.
7.

M.A. Just and P.A. Carpenter. A theory of reading: From eye fixations to comprehension. Psychological Review, vol.
87(4), pp. 329‚Äì354, 1980.
D. Beymer and D. M. Russell. Web gaze analyzer: a system for capturing and analyzing web reading behavior using eye
gaze. In Proceedings of CHI‚Äô05, 2005, pp. 1913‚Äì1916.
R. J.K Jacob. The use of eye movements in human computer interaction techniques: Toward non-command interfaces.
ACM Transactions on Information Systems, vol. 9 (3), pp. 152‚Äì169, 1991.
H. Takagi. Development of an eye-movement enhanced translation support system. In Proc. Asian-Pacific Computer
Human Interaction Conference (APCHI), 1998, pp. 114‚Äì119.
J.L. Sibert, M. Gokturk, and R.A. Lavine. The reading assistant: Eye gaze triggered auditory prompting for reading
remediation. In Proceedings of CHI‚Äô07, 2000, pp. 101‚Äì107.
S.T. Iqbal and B. P. Bailey. Understanding and developing models for detecting and differentiating breakpoints during
interactive tasks. In Proceedings of CHI‚Äô07, 2007.
Yan Liu, Pei-Yun Hsueh, Lai, J., Sangin, M., Nussli, M.-A., Dillenbourg, P. Who is the expert? Analyzing gaze data to
predict expertise level in collaborative applications. Proc. of IEEE Int. Conference on Multimedia and Expo, 2009.

2537

2538

P. Liang et al. / Procedia Computer Science 1 (2012) 2529‚Äì2538
P.Liang, Y.Z. Yang and Y. Cai / Procedia Computer Science 00 (2010) 000‚Äì000

8.
9.
10.
11.
12.
13.
14.
15.
16.

http://www.eyetechds.com/.
M. Seul, L. O'Gorman, M.J. Sammo. Practical Algorithms for Image Analysis: Description, Examples and Code.
Cambridge University Press, 1999.
Lloyd, S. P., Least squares quantization in PCM. IEEE Transactions on Information Theory 28(2), 1982, 129‚Äì137.
Manber, Udi and S. Wu. Fast text search allowing errors. Communications of the ACM, 35(10): pp. 83‚Äì91, October 1992.
Navarro, G. A guided tour to approximate string match, ACM Computing Surveys, Vol. 33, Issue 1, March 2001
Wang Jian. Integration model of eye-gaze, voice and manual response in multimodal user interface. Journal of Computer
Science and Technology, vol.11(5), pp. 512-518, 1996
Wang, J. Markov Model for Eye Movement, Ph.D. Dissertation, Hangzhou University, 1998
Cai, Y. et al, Visual Transformation for Spatiotemporal Data Mining, Journal of Knowledge and Information Systems
(KAIS), Vol. 11, No. 5, 2007, Springer.
Cai, Y. and Abascal, J. (eds.) Ambient Intelligence for Everyday Life, LNAI 3864, Springer, 2007

