A Monte Carlo Algorithm for State
and Parameter Estimation of Extended Targets
Donka Angelova1 and Lyudmila Mihaylova2
1

Institute for Parallel Processing, Bulgarian Academy of Sciences
25A Acad. G. Bonchev St, 1113 Sofia, Bulgaria
donka@bas.bg
2
Department of Communication Systems, Lancaster University,
South Drive, Lancaster LA1 4WA, UK
mila.mihaylova@ieee.org

Abstract. This paper considers the joint state and parameter estimation of extended targets. Both the target kinematic states, position and speed, are estimated
with the target extent parameters. The developed algorithm is applied to a ship,
whose shape is modelled by an ellipse. A Bayesian sampling algorithm with finite
mixtures is proposed for the evaluation of the extent parameters whereas a suboptimal Bayesian interacting multiple model (IMM) filter estimates the kinematic
parameters of the maneuvering ship. The algorithm performance is evaluated by
Monte Carlo comparison with a particle filtering approach.

1 Introduction
The increasing interest in simulation-based Bayesian methods for analysis of dynamic
models has been resulted in a variety of powerful techniques for filtering and prediction
of complex dynamic systems [1, 2]. The problem of state and parameter estimation of
dynamic systems has many applications such as in signal processing, machine learning,
robotics, target (e.g., aircraft, ship) tracking [3, 4]. In the present work, a Monte Carlo
(MC) algorithm is applied to ship size evaluation in the framework of state filtering
(tracking) of a maneuvering ship, modeled by a Markovian jump system.
Most of the target tracking algorithms available in the literature consider the moving
object as a single point and estimate its state vector based on the incoming sensor data,
e.g. range and bearing. However, recent sensor systems are able to resolve individual
features or measurement sources on an extended object. The possibility to additionally
make use of this measurements is referred to extended target tracking. For example, a
high-resolution radar can provide a measure of down-range object extent given a reasonable signal-to-noise ratio [5, 6]. This valuable information can help for more precise
estimation of the object behaviour. It can assist in resolving measurement association
uncertainty in situations of closely spaced objects in dense clutter. Furthermore, the
knowledge of objects size is especially important for the purposes of classification.
Research supported in part by the Bulgarian Foundation for Scientific Investigations:
I-1202/02,I-1205/02,MI-1506/05 and by Center of Excellence BIS21++, 016639.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part III, LNCS 3993, pp. 624–631, 2006.
c Springer-Verlag Berlin Heidelberg 2006

A Monte Carlo Algorithm for State and Parameter Estimation of Extended Targets

625

In this paper we address the problem of extended target tracking. There exist several
ways for modelling object extent parameters. Models, based on measurements of individual points on object require complicated techniques for multiple hypotheses testing
[7]. A simple ellipsoidal object model is proposed in [5] and adopted in our work.
The lengths of the major and minor axes of the ellipse have to be calculated, based on
the measurements of down-range extent. Shape parameters are included in [5] in the
state vector together with kinematic parameters and are estimated by Extended and Unscented Kalman Filters (EKFs and UKFs) and particle filtering. However, it is pointed
out is [5] that the EKF implementation is prone to divergence due to high nonlinearity
conditions and a straightforward particle filter can avoid this problem.
Having in mind the inferences in [5, 6], we develop a Bayesian algorithm able to
deal with the nonlinear estimation problem. Taking into account the possibility for subsequent classification, we assume that the unknown shape parameters are defined over
the discrete set of values, with a given prior distribution. Within this formulation of the
problem, data augmentation (DA) algorithm for finite mixture estimation [9] offers an
alternative solution. DA represents a special case of Gibbs sampling [2] and belongs
to the class of Markov Chain Monte Carlo (MCMC) methods. We develop a DA procedure for the parameter estimation, along with an IMM algorithm for kinematic state
estimation. The scheme implemented here is inspired by the ideas in [8].
The paper is organised as follows. Section 2 describes the system dynamics and measurement model. Section 3 presents the formulation of the problem. The designed DA
algorithm is presented in Section 4. Section 5 illustrates and compares the performance
of the proposed algorithm with a particle filter (PF). Conclusions are given in Section 6.

2 System Dynamics and Measurement Models
Target motion tracking is performed by a recursive reconstruction of the state probability density function given the available prior information and current measurement
data. Prior information includes dynamic models, models of the measurement process,
initial state and noise probability distributions.
System Model. Consider the following model of a discrete-time jump Markov system,
describing object dynamics and sensor measurements
xk = f (mk , xk−1 , θ) + g (mk , θ) wk ,
z k = h (mk , xk , θ) + d (mk , θ) v k , k = 1, 2, . . . ,

(1)
(2)

where xk ∈ Rnx is the base (continuous) state vector, with transition function f ,
z k ∈ Rnz is the measurement vector with measurement function h, and θ ∈ Θ is
a vector, containing unknown static parameters. The noises wk and v k are independent
identically distributed (i.i.d.) Gaussian processes having characteristics wk ∼ N (0, Q)
and v k ∼ N (0, R), respectively. All vectors and matrices are assumed of appropriate dimensions. The modal (discrete) state mk ∈ S
{1, 2, . . . , s} is a first-order
Markov chain with transition probabilities pij P r {mk = j | mk−1 = i} , (i, j ∈ S)
and initial probability distribution P0 (i) P r {m0 = i}, i ∈ S, such that P0 (i) ≥ 0,
s
and i=1 P0 (i) = 1. k = 1, 2, . . . is a discrete time.

626

D. Angelova and L. Mihaylova

Consider a base state vector in the form xk = (xk , x˙ k , yk , y˙ k ) , where x and y specify
the ship position with respect to an observer position, assumed known, and (x,
˙ y)
˙ is the
velocity in the Cartesian plane, centered at the observer location. All possible s motion
regimes of the maneuvering ship are modelled by the modal state variable m. The static
parameter vector θ = ( , γ) contains shape parameters: the length of the major axis of
the ship ellipse and the ratio of the lengths of the minor and major axes γ.
Measurement Equation. Similarly to [5, 6], we assume, that a high-resolution radar
provides measurements of range r and bearing β to the object centroid, as well as the
object down-range extent L along the observer-object line-of-sight (LOS). The relationship between L and the angle φ between the major axis of the ellipse and the targetobserver LOS is given by
L(φ) =

cos2 φ + γ 2 sin2 (φ).

The measurement function h in (2) is nonlinear,
⎛
⎞
(xk − xo )2 + (yk − yo )2
h(xk , θ) = ⎝arctan((yk − yo )/(xk − xo ))⎠
L(φ(xk ))

(3)

(4)

where the measurement vector is z k = (rk , βk , Lk ) . Here (xo , yo ) is the location of
the observer. If it is assumed that the target ellipse is oriented so that its major axis is
parallel to the velocity vector (x,
˙ y)
˙ then from (3) the along-range target extent can be
written in terms of the state vector and θ as
L(φ(xk )) = θ(1) cos2 φ(xk ) + θ(2)2 sin2 φ(xk ),

(5)

where φ(xk ) = arctan ((xk y˙ k − x˙ k yk ) / (xk x˙ k + yk y˙ k )).
The problem that we consider has own particularities: the measurements of L are not
used for the base state vector estimation. The kinematic states are estimated through r
and β. The estimated kinematic states are, however, used for the estimation of and γ.
This is the motivation for applying separate estimators to the two estimation problems.

3 Problem Formulation
The goal is to estimate the state vector xk and the extent parameter vector θ, based on
all available measurement information Z k = {z 1 , z 2 , . . . , z k }. If we can calculate the
posterior joint state-size probability density function (PDF)
p xk , θ | Z k = p θ|xk , Z k p xk |Z k ,

(6)

then for any integrable function (xk , θ) the required estimate is given by
E

(xk , θ)|Z k

=

(xk , θ)p θ|xk , Z k p xk |Z k dθdxk .

(7)

A Monte Carlo Algorithm for State and Parameter Estimation of Extended Targets

627

If we denote the l-th mode history, realised by a Markovian jump system through time
k as mlk , l = 1, . . . , εk then the conditional PDF of the state is obtained as a Gaussian
mixture with an exponentially increasing number of terms [10]
εk

p xk |Z k =

p xk |mlk , Z k P mlk |Z k .

(8)

l=1

The exponentially increasing computations can be avoided by different ways of combining histories of models. For example, the Interacting Multiple Model (IMM) filter
ˆk = E
[10] provides an approximate state estimate x
(xk ) |Z k and its associated
covariance matrix P k , by using s working in parallel EKFs. Then the estimate of θ can
ˆ k = E (θ k )|ˆ
be expressed as θ
xk , Z k . Note that the k index of θ indicates that it is
calculated based on the information up to time instant k, not that θ is time-varying.
MC algorithms (PF or MCMC) can be applied to the highly nonlinear extent estimation problem. The use PF for the first step is not justifiable, as ships exhibit moderate
maneuvers and the time interval between the measurements is rather short. Since the
size estimate could be obtained along with the filtering process, but not necessary online, the more precise MCMC algorithm can be applied.
The scheme implemented here is similar to [8]. It comprises the following steps. On
receipt of a new measurement z k :
ˆ k−1 in order to update
a) run the IMM algorithm with the previous state estimate x
ˆk.
the current state estimate x
ˆ k of the parameter vector θ based on the previous estimates
b) find the estimate θ
ˆ k−1 , z k−1 , by PF or DA scheme.
ˆ
ˆ k , and the measurement likelihood p z k |θ
θk−1 , x

4 Extent Parameters Estimation by Stochastic Simulation
Based on a priori information about ship types, we assume that θ takes values from a
known discrete set θ ∈ T
{1, 2, . . . , t} with known prior distribution: Pθ0 (i)
t
P r {θ = i}, i ∈ T , such that Pθ0 (i) ≥ 0, and i=1 Pθ0 (i) = 1. Let us suppose that
along-range extent measurements Lk , k = 1, . . . , n, . . . have Gaussian distributed zeromean errors with known variance RL . The PDF of the measurement Lk is represented
in the following mixture form [9, 11]:
t

p (Lk |π, θ, xk ) =

πj G (Lk |θj , xk ) ,

(9)

j=1

where π = (π1 , . . . , πt ) are the mixture proportions which are constrained to be nonˆ k ) , RL ) is a Gaussian dennegative and sum to unity. G (Lk |θ j , xk ) ∼ N (Lk ; L (θj , x
ˆ k ) is the measurement prediction, calculated according to (5). Thus,
sity and L (θj , x
the task is reduced to the well known finite mixture estimation problem: for the mixture model (9) with known component PDFs G (Lk |θj , xk ), one needs to estimate
the unknown weights π = (π1 , . . . , πt ), given a sequence of independent observations L1 , L2 , . . . , Ln . The mixture component with a maximum weight identifies the

628

D. Angelova and L. Mihaylova

most probable ship type. The estimate of the extent parameters can be calculated as the
weighted by π sum of the possible θ values in the set.
Mixture Weights Estimation by Data Augmentation. DA algorithm approximately
evaluates the mixture posterior distribution, relying on the missing data structure of
mixture model. Generally, the mixture model is given by the observation of n independent random variables y1 , . . . , yn from a t-component mixture [9, 11],
t

(yk ) =

πj

j (yk ),

k = 1, . . . , n,

(10)

j=1

where the densities j , j = 1, . . . , t are known or are known up to a parameter and
the proportions πj satisfy the above conditions. We consider the special case, where
only the weights π have to be estimated. According to [9], the mixture model can always be expressed in terms of missing (or incomplete) data. That is, define vectors
δ(k) = (δ1 (k), δ2 (k), . . . , δt (k)), k = 1, 2, . . . , n with components δj (k) ∈
{0, 1}, j = 1, 2, . . . , t, which indicate that the measurement yk has density j (yk )
[8]. The model is hierarchical with, on top, the true parameters of the mixture, π, then
the missing data whose distribution depends on π, δ ∼ p(δ|π), and, at the bottom, the
observed data y ∼ p(y|π, δ). Starting with an initial value π (0) , the algorithm implements two-step iterative scheme: at the iteration u, u = 1, 2, . . .
a) generate δ (u) ∼ p(δ|y, π (u) ) from a multinomial distribution with weights propor(u)
(u)
tional to the observation likelihoods: δj (k) ∝ πj
j (yk );
(u)
(u+1)
∼ p(π|y, δ ).
b) generate π
Since the conjugate priors on π are with Dirichlet distributions (DD) D(α1 , . . . , αt )
[9], π (u+1) is generated according to the DDs with parameters, depending on the missing data. Bayesian sampling produces an ergodic Markov chain (π(u) ) with stationary distribution p(π|y). Thus, after u0 initial (warming up) steps, a set of U samples
π (u0 +1) , . . . , π (u0 +U) are approximately distributed as p(π|y) and, due to ergodicity,
averaging can be made with respect to time [8, 9].
In the next scheme, the sequence of observations yk , k = 1, . . . is replaced by the
along-range extent measurements Lk , k = 1, . . .. The joint IMM and data augmentation
scheme is given below. DA is realised in a sliding window mode.
Algorithm Outline
For k = 1, 2, . . .
ˆ k−1 , covariance ma• Run the IMM algorithm with the previous state vector x
trix P k−1 and posterior model probability vector μk−1 to update the current
ˆ k , together with P k and μk .
estimate x
• Compute Mixture Components Conditional PDFs
˜ j (k)
G

−1
ˆ k ))T RL
ˆ k ))
G (Lk |θ j , xk ) ∝ exp −0.5 (Lk − L (θ j , x
(Lk − L (θ j , x

• Implement Data Augmentation
- Initialisation: π (0) = π (k − 1)

A Monte Carlo Algorithm for State and Parameter Estimation of Extended Targets

629

- Iterations (u = 0, 1, . . . , u0 + U − 1)
* Missing Data Conditional Probability Mass Functions (PMFs)
(u)

qj (l) =

(u) ˜
πj G
j (l)
,
(u) ˜
t
π Gj (l)
j=1

l = 1, 2, . . . k,

j = 1, 2, . . . t

j

* Missing Data Generation (Multinomial Sampling)
t

(u)

δ (u) (l) = (0, . . . , 0, 1, 0, . . . , 0) ∼ qj (l)

,

l = 1, 2, . . . k

j=1

* Parameter Evaluation (Dirichlet Distribution Sampling)
k

k
(u)

π (u+1) ∼ D π; α1 +

(u)

δ1 (l) , . . . , αt +
l=1

δt

(l)

l=1

• Calculate the Output Estimates
π (k) =

1
U

U

t

π (u0 +σ)
σ=1

and

ˆk =
θ

πj (k)θ j
j=1

5 Simulation Results
The algorithm performance is evaluated by simulations over trajectories, including consecutive segments of uniform motion and maneuvers (a typical scenario is shown in
Fig.1(a)). The observer is static, located at the origin of x − y plane. The initial target
state is x0 = (18e3, −14, 90e3, 5) . It performs two turn maneuvers with a normal acceleration of ±1.4 [m/s2 ]. The object length is = 50 [m] and the ratio of the lengths
of the minor and major axes (aspect ratio) is γ = 0.2. The sensor parameters are as follows [6]: sampling interval T = 0.2 [s]; the standard deviations of measurement errors
along range, azimuth and along-range target extent are respectively:
σr = 5 [m],σβ = 0.2 deg and σL = 5 [m].
Root-Mean Squared Errors (RMSEs) [10] are selected as a quantitative measure for the
algorithm performance evaluation.
An IMM algorithm with s = 3 models is designed. The first model corresponds to
the nearly constant velocity motion. The next two models are matched to the nearly
coordinated turn maneuvers with a turn rate of ω = ±1.4 [rad/s]. The form of the
transition matrices in (1) for these models can be found in [10].
A particle filter for extent parameters estimation is realised for the purposes of comparison with DA algorithm, with N = 300 particles. Similarly to the procedure, described in [1] (Ch.10), N particles (θ (i) )N
i=1 are generated according to a priori normal
distribution with mean, corresponding to the true θ. After that the particles are predicted according to a normal distribution with small deviations to provide “artificial

630

D. Angelova and L. Mihaylova
4

x 10

0.8

9.001

0.7

y [m]

9

START

0.6

8.999
0.5

8.998
8.997

0.4

8.996

0.3

mixture weights, π

9.002

8.995
0.2
8.994
0.1

8.993

θ set

x [m]
8.992
1.74

1.75

1.76

1.77

1.78

1.79

1.8

0

1

2

3

4

4

x 10

Fig. 1. Object trajectory and Mixture proportions π
70
True Length, [m]
PF estimate
DA estimate

65

True aspect ratio
PF estimate
DA estimate

0.28
0.26

60
0.24
55

0.22

40
35

0.2
0.18
0.16
0.14
0.12

Scans, [k]
30
20

40

60

80

100

120

140

160

180

200

Aspecr ratio

45

Length, [m]

50

0.1
20

40

Scans, [k]
60

80

100

120

140

160

180

200

16

0.06
PF RMSE
DA RMSE

14

0.05
12
0.04
10

6
4
2
0
20

0.03

Lenght RMSE, [m]

8

Aspecr ratio RMSE

Fig. 2. PF and DA comparison: True and estimated and γ
PF RMSE
DA RMSE

0.02

0.01

Scans, [k]

Scans, [k]
40

60

80

100

120

140

160

180

200

0
20

40

60

80

100

120

140

160

180

200

Fig. 3. PF and DA comparison: RMSE of and γ

evolution” of parameters. Then the particle weights are evaluated using likelihoods of
the received measurements and finally resampling is implemented according to a known
rule.
In accordance with (Sec. 4), we assume that θ takes values from a discrete set
of t = 4 components: {(30, 0.15), (50, 0.2), (70, 0.25), (100, 0.3)} with equal initial
probabilities. θ2 corresponds to the true θ. The mixture proportions πj , j = 1, . . . , t,
estimated by the DA procedure are given in Fig.1(b). It can be seen that DA identifies

A Monte Carlo Algorithm for State and Parameter Estimation of Extended Targets

631

the correct θ with a high probability. The results are obtained from one MC realisation
and confirm the reliability of the algorithm for classification tasks.
Figs.(2) and (3) demonstrate the better performance of the DA in comparison with
the PF: the estimation errors of and γ obtained by the PF are quite large. It is natural to expect a better performance of DA scheme. It has additional prior information,
available from the θ set. DA is an off-line procedure and processes the cumulative
measurement information. In addition, PF involves additional noise, necessary for prediction which deteriorates the estimation accuracy of the parameters (they are fixed).
Its performance is highly sensitive to the choice of noise deviations, which are design
parameters. However, the better performance is achieved at the increased computational
time. The relative execution time is approximately 17:1 in PF favour.

6 Conclusion
An alternative solution to the problem of extended object tracking is proposed in this
paper. Two different Bayesian algorithms are developed for kinematic state and size
parameter estimation of a ship, based on positional and along-range object extent measurements. A Monte Carlo algorithm (Data augmentation) is designed for length and
aspect ratio assessment of the elliptical ship shape. The performance of the proposed algorithm is evaluated by Monte Carlo simulation. The results show that DA is capable to
deal with highly nonlinear relationships between states, parameters, measurements and
complicated target-observer geometry. A combined IMM-DA procedure is proposed
which provides accurate joint state-parameter estimation and reliable identification of
the ship type.

References
1. Doucet, A., de Freitas, N., Gordon, N. (ed.): Sequential Monte Carlo Methods in Practice.
Springer-Verlag, New York, (2001).
2. Liu, J.: Monte Carlo Strategies in Scientific Computing. Springer-Verlag, New York, (2003).
3. Storvik, G.: Particle filters in state space models with the presence of unknown static parameters. IEEE. Trans. of Signal Processing, Vol. 50, No. 2, (2002) 281–289.
4. Doucet, A., Tadic, V.: Parameter estimation in general state-space models using particle
methods. Ann. Inst. Stat. Math., vol. 55, No. 2, (2003) 409–422.
5. Salmond, D., Parr, M.: Track maintenance using measurements of target extent. IEE Proc.Radar Sonar Navig., Vol. 150, No. 6, (2003) 389–395.
6. Ristic, B., Salmond, D.: A study of a nonlinear filtering problem for tracking an extended
target. Proc. Seventh Intl. Conf. on Information Fusion, (2004) 503–509.
7. Vermaak, J., N. Ikoma, S. Godsill: Sequential Monte Carlo Framework for Extended Object
Tracking. IEE Proc.-Radar Sonar Navig., Vol. 152, No. 5 (2005), 353–363.
8. Jilkov, V., Li,X. Rong, Angelova, D.: Estimation of Markovian Jump Systems with Unknown
Transition Probabilities through Bayesian Sampling. LNCS, Vol. 2542 (2003), SpringerVerlag, Berlin, pp. 307-315.
9. Diebolt, J., Robert, C.P.: Estimation of Finite Mixture Distributions through Bayesian Sampling. J. of Royal Statist. Soc. B 56, No. 4, (1994) 363–375.
10. Bar-Shalom, Y., Li, X.R., Kirubarajan, T.: Estimation with Applications to Tracking and
Navigation: Theory, Algorithms, and Software. Wiley, New York (2001).
11. Stephens, M.: Bayesian methods for mixture of normal distributions. PhD Thesis, 1997.

