Available online at www.sciencedirect.com

ScienceDirect
Procedia Computer Science 108C (2017) 272–284
Procedia Computer Science 00 (2017) 1–13
Procedia Computer Science 00 (2017) 1–13

Procedia
Procedia
Computer
Computer
Science
Science

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Efficient Simulation of Financial Stress Testing Scenarios with
Efficient Simulation of Financial Stress Testing Scenarios with
Suppes-Bayes Causal Networks
Suppes-Bayes Causal Networks
Gelin Gaoaa , Bud Mishraaa , Daniele Ramazzottibb
Gelin Gao , Bud Mishra , Daniele Ramazzotti
a New

York University, New York, USA
Stanford,
NewUniversity,
York University,
NewCalifornia,
York, USA USA
b Stanford University, Stanford, California, USA
b Stanford
a

Abstract
Abstract

The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management
The most recent
upheavals
cast doubt
on situations.
the adequacy
of some of there
the conventional
quantitative
riskfor
management
strategies,
such asfinancial
VaR (Value
at Risk),have
in many
common
Consequently,
has been an increasing
need
verisimilar
strategies,
such testings,
as VaR (Value
at simulating
Risk), in many
common situations.
Consequently,
there has
been
anscenarios.
increasingUnlike
need for
verisimilar
financial stress
namely
and analyzing
financial portfolios
in extreme,
albeit
rare
conventional
financial
stress testings,
analyzingamong
financial
portfolios
in extreme,
albeit
rare scenarios.
Unlike
conventional
risk
management
whichnamely
exploitssimulating
statistical and
correlations
financial
instruments,
here
we focus
our analysis
on the
notion of
risk management
whichwhich
exploits
statisticalby
correlations
among
financial
instruments,
here
we focus
our analysisgraphical
on the notion
of
probabilistic
causation,
is embodied
Suppes-Bayes
Causal
Networks
(SBCNs),
SBCNs
are probabilistic
models
probabilistic
causation,
which
is embodied
Suppes-Bayes
Causalanalysis
Networks
SBCNs
are stress
probabilistic
graphical models
that
have many
attractive
features
in terms by
of more
accurate causal
for(SBCNs),
generating
financial
scenarios.
that In
have
attractive
features
in terms
of more
accurate causal
forfinancial
generating
financial
stress
thismany
paper,
we present
a novel
approach
for conducting
stressanalysis
testing of
portfolios
based
onscenarios.
SBCNs in combination
this paper,
we present
a novel
approachtools.
for conducting
stress
testing
financial
on SBCNs
in combination
withIn
classical
machine
learning
classification
The resulting
method
is of
shown
to beportfolios
capable ofbased
correctly
discovering
the causal
with classicalamong
machine
learningfactors
classification
tools.
resulting
is shown tostress
be capable
correctlywith
discovering
causal
relationships
financial
that affect
the The
portfolios
andmethod
thus, simulating
testingofscenarios
a higherthe
accuracy
relationships
among financial
factors than
that affect
the portfolios
thus,
simulating stress testing scenarios with a higher accuracy
and lower computational
complexity
conventional
Monte and
Carlo
Simulations.
and lower computational complexity than conventional Monte Carlo Simulations.
©
The Authors.
Published
c 2017

2011 Published
by Elsevier
Ltd. by Elsevier B.V.
Peer-review
underbyresponsibility
c 2011 Published

Elsevier Ltd. of the scientific committee of the International Conference on Computational Science
Keywords:
Keywords:
Stress Testing, Graphical Models, Causality, Suppes-Bayes Causal Networks, Classification, Decision Trees
Stress Testing, Graphical Models, Causality, Suppes-Bayes Causal Networks, Classification, Decision Trees

1. Introduction
1. Introduction
Risk management has increasingly become a central part of world finance in the past century. Quantitative risk
Risk management
increasingly
a central
part the
of world
finance
in the of
past
century.agency
Quantitative
risk
management
generallyhas
targets
the risk ofbecome
insolvency:
namely,
depletion
of capital
a trading
to the point
management
generally
the risk
of insolvency:
the depletion
ofaccount
capital of
a trading
agency
to thebonds
point
that the trading
agency targets
has to stop
its operations.
Fornamely,
any trading
agency, its
consists
of cash,
stocks,
thatother
the trading
has to stop
its operations.
ForEquity
any trading
its account
consistsThe
of cash,
bonds
or
financialagency
instruments,
and net
equity, where
= Cashagency,
+ Financial
Instruments.
task ofstocks,
quantitative
or
financial instruments,
andthe
netamount
equity, where
Equity
Cash
Theequity
task ofwill
quantitative
riskother
management
is to calculate
of equity
that=has
to +
beFinancial
reserved Instruments.
so that the net
not drop
risk
management
is to calculate
the amount
of equity
that hedge
has to funds,
be reserved
the net
equity
drop
to negative
[1]. Depending
on different
financial
agencies,
banks so
or that
clearing
houses,
andwill
on not
different
to
negative
[1].
Depending
on
different
financial
agencies,
hedge
funds,
banks
or
clearing
houses,
and
on
different
financial instruments, stocks, bonds, or derivatives, the method of risk management may vary, but the central idea
financialconventional
instruments,risk
stocks,
bonds, orremains:
derivatives,
the method
of risk management
may
central idea
behind
management
we assess
the statistical
distribution of
thevary,
assetbut
(orthe
portfolio),
and
behind
riskscenarios,
management
remains:
we assess
theasstatistical
distribution
of the
estimateconventional
the worst-case
generally
by methods
such
Monte Carlo
Simulation
[2].asset (or portfolio), and
estimate
the worst-case
scenarios,
generally
methods such
as recent
Monteevents
Carlo Simulation
[2]. financial catastrophes.
However,
such conventional
approach
gotbydiscredited
by the
leading to major
such
approachcrisis,
got discredited
by calculated
the recent events
to major
financial
For However,
example, in
theconventional
recent 2008 financial
the reserves
the riskleading
by using
methods
such ascatastrophes.
VaR (Value
ForRisk)
example,
in theproved
recentto2008
financialinadequate.
crisis, the reserves
the risk by
using had
methods
as VaRnamely
(Value
at
[3] which
be painfully
Becausecalculated
of that, a different
method
to be such
introduced,
at
[3]stress
whichtesting.
provedStress
to be painfully
inadequate.
Becauseorofsimulation
that, a different
had
be introduced,
namely
theRisk)
one of
testing refers
to the analysis
of themethod
response
oftofinancial
instruments
or
the one of stress testing. Stress testing refers to the analysis or simulation of the response of financial instruments or
1
1
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.167

	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

2

institutions, given intensely stressed scenarios that may lead to a financial crisis [4]. For example, narrowly speaking, stress testing may model the response of a portfolio when Dow Jones suddenly drops by 5%. The difference
between stress testing and conventional risk management is that stress testing deliberately introduces an adversarial,
albeit plausible event, which may be highly improbable but not implausible – e.g., a black swan event triggering an
unforeseen scenario. Thus, stress testing must be capable of observing the response of financial instruments or institutions under extremely rare scenarios. Such scenarios may be deemed to be unlikely to be observed in conventional
risk management, where the simpler system may fail to estimate a 99th percentile of the loss distribution, and subsequently leading to a claim that, with 99% confidence level, a specific portfolio will perform well, giving a false sense
of security.
Recently, many different approaches have been developed to implement some form of stress testing. In terms
of stress scenario generation, the most direct method is the historical one, in which observed events from the past
are used to test contemporary portfolios [5]. The historical approach is objective since it is based on actual events,
but it is not necessarily relevant under the present conditions, which necessitate some hypothetical methods. As an
alternative, the event-based method has been proposed in order to quantify a specific hypothetical stress scenario
subjectively, by domain experts, and then estimate the possible consequence of such event using macroeconomic and
financial models [5]. Event-based methods rely intensively on expert judgement on whether a hypothetical event
will be severely-damaging, albeit still plausible to occur. Sometime such judgement becomes difficult when the
relationship between the underlying risk factors and the portfolio is unknown. To ensure a scenario is damaging to
the portfolio, a portfolio-based method has been also studied in order to link scenarios directly with the portfolio [5].
To this extent, portfolio-based methods rely on Monte Carlo Simulation to identify the movements of risk factors that
stress the given portfolio most severely, however brute force Monte Carlo Simulation is computationally inefficient
especially when dealing with many risk factors. To solve this problem, Rebonato et al. proposed a sampling approach
based on Bayesian networks in [6].
Roadmap: This paper is organized as follow. Next section describes the theoretical foundations of our approach
and, in particular, it shows how combining the expressivity of Suppes-Bayes Causal Networks together with classical classification approaches can effectively capture the dynamics of financial stress testing. Section 3 provides an
algorithm for the efficient inference of SBCNs from financial data, discusses its performance in-depth and shows on
realistic simulated data how our approach is preferable in comparison to the standard Bayesian methods. Section 4
concludes the paper.
2. Method
In this work we use Bayesian Graphical Models [7], popularly known as Bayesian networks, as a framework to
assess stress testing, as previously done in this context by [6]. Bayesian networks have long been used in biological
modeling such as -omics data analysis, cancer progression or genetics [8, 9, 10], but their application to financial data
analysis has been rare. Roughly speaking, Bayesian networks attempt to exploit the conditional independence among
random variables, whether the variables represent genes or financial instruments. In this paper we adopt a variation of
the traditional Bayesian networks as done in [11, 12], where the authors show how constraining the search space of
valid solutions by means of a causal theory grounded in Suppes’ notion of probabilistic causation [13] can be exploited
in order to devise better learning algorithms. Also, by accounting for Suppes’ notion of probabilistic causation, we
ensure not only conditional independence but also prima facie causal relations among variables, leading us to a better
definition of the actual factors leading to risk. Moreover, through a maximum likelihood optimization scheme which
makes use of a regularization score, we also attempt to only retain edges in the Bayesian network (graphically depicted
as a directed acyclic graph, DAG) that correspond to only genuine causation, while eliminating all the spurious causes
[11, 12].
Yet, given the inferred network, we can sample from it to generate plausible scenarios, though not necessarily
adversarial or rare. In the case of stress testing, it is crucial to also account for rare configurations, for this reason, we
adopt auxiliary tools from machine learning to discover random configurations that are both unexpected and undesired.
In this Section we expand the concept sketched above and specifically we provide a background of our framework,
by describing the adopted Bayesian models and causal theories and we show how classification given an inferred
SBCN can effectively guide stress testing simulations.
2

273

274	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

3

2.1. Bayesian networks
Informally, Bayesian networks are defined as a directed acyclic graph (DAG) G = (V, E), in which each node V
represents a random variable to which is associated a conditional probability table, and each arc E models dependency relationships. The nodes induce an overall joint distribution that can be written as a product of the conditional
distributions associated with each variable [7]. In this paper, without any loss of generality, we restrict our attention
to Bernoulli random variables with support in (0, 1). Specifically, we will consider as inputs for our analyses a dataset
D of m observations over n Bernoulli variables; we refer to the next Sections for a detailed description of the meaning
of such variables. More details about Bayesian networks may be found in [7].

Figure 1. Example of graphical structure of a Bayesian network with 4 random variables.

Let us now consider as an example the Bayesian network shown in Figure 1, where A, B, C, and D are 4 random
variables represented by four nodes, and the dependencies among the nodes are modelled by directed arcs. Loosely
speaking, the link A → B indicates that the knowledge of A (the parent) influences the probability of B (the child), or
A and B are statistically dependent. Furthermore, for node B, node A is called B’s parent and nodes C and D are called
B’s children. More precisely, in the conditional probability tables related to the afore mentioned Bayesian network,
the rows for node B specifies how the knowledge of A affects the probability of B being observed. For example, let
A and B be both binary random variables with support over (0, 1). Table 1 specifies the distribution of B under the
condition of A, and we can see clearly the effect of the parent on the child in this example.
B=0
B=1

A=0
P(B = 0|A = 0) = 0.3
P(B = 1|A = 0) = 0.7

A=1
P(B = 0|A = 1) = 0.4
P(B = 1|A = 1) = 0.6

Table 1. Example of conditional probability table of node B having node A is unique parent.

One of the most significant feature of Bayesian network is the notion of conditional independence. Simply speaking, for any node X in a Bayesian network, given the knowledge of node X’s parents, X is conditionally independent
of all nodes that are not its children, or all its predecessors [7]. For example, in the Bayesian network in Figure 1,
node C is conditionally independent of node A, when conditioned on node B being fixed. The possibility of exploiting
conditional dependencies when computing the induced distribution of the Bayesian network is a powerful property
since it simplifies the conditional probability table tremendously. For example, the conditional probability table of
node C, will not contain entries P(C|A, B) since P(C|A, B) = P(C|B), or node C is independent of A conditioned on B:
A ⊥ C|B.
In the context of stress testing, Rebonato [6] suggests a subjective approach to constructing Bayesian networks.
After carefully selecting a set of random variables as the nodes of the network, Rebonato proposes to subjectively
connect the variables and assign the relevant conditional probability tables with the help of risk managers or other
experts. Then with the inferred Bayesian network, reasoning about stressed events or simulation can be conducted.
Please see [6] for details.
Our framework builds upon many of Rebonato’s intuitions but exploits our recent works on causality to address all
the key problems, of which the subjective approach comes short. The subjective approach is handy under the condition
3

	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

4

of expert knowledge of the causal relationships of some variables. However, such reliance becomes unnatural when
experts are confronted with random variables that are clearly beyond their expertise: for example, the relationship
of unemployment and stock market performance, or more simply, the relationship of two random stocks. Therefore,
instead of completely abandoning the role of data in the construction of Bayesian network, here we adopt learning
algorithms that can learn both the structure and the conditional probability table of the Bayesian network from the
data, which, in turn, can be further augmented by expert knowledge if deemed necessary.
2.2. Suppes-Bayes Causal Networks
Thus, unlike [6], our stress testing approach builds on the foundation of Suppes-Bayes Causal Networks (SBCNs),
which are not only more strictly regularized than the general Bayesian networks but also enjoys many other attractive features such as interpretability and refutability. SBCNs exploit the notion of probabilistic causation, originally
proposed by Patrick Suppes [13].
In [13], Suppes described the notion of prima facie causation. A prima facie causal relation between any event u
and its effect v is verified when the following two conditions hold: (i) temporal priority (TP), i.e., any cause happens
before its effect and (ii) probability raising (PR), i.e., the presence of the cause raises the probability of observing its
effect.
Definition 1 (Probabilistic causation, [13]). For any two events u and v, occurring respectively at times tu and tv ,
under the mild assumptions that 0 < P(u), P(v) < 1, the event u is called a prima facie cause of v if it occurs before
and raises the probability of u, i.e.,



(T P) tu < tv
(1)


(PR) P(v | u) > P(v | u)
The notion of prima facie causality was fruitfully exploited for the task of modeling cancer evolution in [9, 10, 14],
and the SBCNs were finally described for the first time in [15] and, later on, defined in [11, 12] as follow.

Definition 2 (Suppes-Bayes Causal Network). Let us consider an input cross-sectional dataset D of n Bernoulli
variables and m samples, the Suppes-Bayes Causal Network S BCN = (V, E) subsumed by D is a directed acyclic
graph such that the following requirements hold:
[Suppes’ constraints] for each arc (u → v) ∈ E involving a prima facie relation between nodes u, v ∈ V, under the
mild assumptions that 0 < P(u), P(v) < 1:
P(u) > P(v)

and

P(v | u) > P(v | ¬u) .

[Simplification] let E  be the set of arcs satisfying the Suppes’ constraints as before; among all the subsets of E  , the
set of arcs E is the one whose corresponding graph maximizes the likelihood of the data and of a certain regularization
function R( f ):
E = argmax (LL(D|G) − R( f )) .
E⊆E  ,G=(V,E)

Intuitively, the advantage of SBCNs over general Bayesian networks is the following. First, with Temporal Priority, SBCN accommodates the time flow among the nodes. There are obvious cases where some nodes occur before
the other and it is generally natural to state that nodes that happen later cannot be causes (or parents) of nodes that
happen earlier. Second, when learning general Bayesian networks, arcs A → B and A ← B may sometimes be equally
acceptable, resulting in an undirected arc A − B (this situation is called Markov Equivalence [7]). For SBCNs, such a
situation does not arise because of the temporal flow being irreversible [11, 12]. Third, because of the two constraints
on the causal links, the SBCN graph is generally more sparse (has fewer edges) than the graph of general Bayesian
networks with the final goal of disentangling spurious arcs, e.g., due to spurious correlations [16], from genuine
causalities.

4

275

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284

276	

/ Procedia Computer Science 00 (2017) 1–13

5

2.3. Machine Learning and Classification
Even if with SBCNs we typically obtain sparser DAGs than when we use Bayesian networks, the modelled relations both involve positive and negative financial scenarios, but only in the latter financial stress may arise. Thus, the
extreme events which are of key relevance for stess testing are still rare in the data and unlikely to be simulated in
naively generated stress scenarios by sampling from the SBCN directly. Therefore, in this work we improve this basic
model with several key ideas of classic machine learning, namely, feature classification. Recall that, in stress testing, we wish to target the unlikely, but risky scenarios. Specifically, when generating random sample from a SBCN
to obtain possible scenarios, each node in the SBCN can take any value in its support according to its conditional
probability table, generating different branches of scenarios. To narrow down the search space, we can classify each
possible branch as leading to profitable or lossy scenarios, and if, the branch is classified as profitable, then random
sampling is guided to very likely avoid that branch, thus focusing on events and causal relations that can be adversarial
and risky, though uncommon. In this way, computation can be reduced significantly to discover the extreme events
(see the next Sections for details).
3. Results and discussion
In this Section we investigate the capabilities of our framework based on SBCNs to perform stress testing assessment. We first describe the adopted generative model and then present our algorithm and investigate its performance
paying specific attention to the problem of false discoveries.
3.1. Simulating the Training Data
To assess the performance of the algorithm to learn the SBCNs and the quality of inferred Bayesian networks, a set
of training data is developed with embedded causal relationships. If the algorithms, when performed on the training
data are capable of accurately recover the causal relationships embedded in them, then such accuracy can be expected
on real data.
To simulate the training data, we adopt a common stock factor model, the Fama French Five Factor Model [17],
where the return of the asset is defined as follow:
r = R f + β1 (Km − R f ) + β2 S MB
+ β3 HML + β4 RMW + β3CMA + α.

(2)

In the equation, r is the return of the asset; R f is the risk free return, usually measured in terms of government
treasury returns; Km stands for market factor, measured as value-weighted market portfolio, similar to stock indexes;
S MB (Small Minus Big) stands for company size factor, measured by return on a diversified portfolio of small stocks
minus the return on a diversified portfolio of big stocks; HML (High Minus Low) stands for company book-tomarket (B/M) ratio factor, measured by difference between the returns on diversified portfolios of high and low B/M
stocks, where B/M is the ratio between company’s book value to market value; RMW (Robust Minus Weak) stands
for company operating profitability factor, measured by the returns on diversified portfolios of stocks with robust
and weak profitability and CMA (Conservative Minus Aggressive) stands for company investment factor, difference
between the returns on diversified portfolios of low and high investment stocks, called conservative and aggressive
[17].
To simulate the training data with embedded causal relationship, we linearly regress historical returns r, onto the
five factors, and obtain the distribution of each factor coefficient and the empirical residual. We notice that a key
characterization of a SBCN is an underlying temporal model of the causal relations depicted in the network, namely
the temporal priority between any pair of nodes which are involved in a causal relationship. Therefore, the five factors
described in our generative model are lagged with respect to the historical returns to comply with the temporal priority.
Thus,

ri,t =
(3)
βi, j f j,t−lag + .
i, j

Then, the simple training data is simulated by randomly drawing the factor coefficients βi, j and residuals  from
the distribution we obtained from the linear regression, and apply these coefficients and residuals on a set of new
5

	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

6

factor data. Such historical data consists of daily series of five factors and returns of 10 portfolios also constructed by
Fama French, and of 10000 days. We use the first 5000 for regression and the other 5000 for simulation.
In reality, many factors will present causal relationships among themselves. For example, some factor do not
directly influence the asset, but affect the asset indirectly by affecting other factors. Therefore, the simulated training
data can be complicated by embedding spurious relationships also among factors. We linearly regress some factors
on the other factors and simulate the training data in the same way. The choice of factors is arbitrary. In this paper, as
an example, we regress the other four factors S ML, HML, RMW and CMA on the market factor Km .
Therefore, the causal relationships which are described in the simulated training data can be simplified as shown
in Figure 2.

Figure 2. Example of causal relationships described in the simulated training data.

3.2. Learning the SBCNs
In this Section we show results on 100 independent random simulations generated on networks of 15 nodes, i.e.,
10 stocks and 5 factors with the generative model discussed in the previous Section. Each node represents a Bernoulli
random variable taking binary values in (0, 1), where 1 represents the stock or factor going up and 0, the stock or factor
going down. Specifically, the input of our learning task is a dataset D of n × m binary entries. Starting with such an
input, we attempted to experiment with our learning algorithms previously described in [10] and [15]. In particular, as
in [15], we lacked explicitly observed time in the data, which are only cross-sectional. To overcome this problem we
imputed as a further input to our algorithm a topological ranking r providing information about the temporal priority
among the nodes. In interpreting these experiments, we set ranking as a proxy of time precedence among the factors
influencing the stocks, i.e., in our model factors can cause stock moves but not the other way around.
Algorithm 1 summarizes the learning approach adopted for the inference. Given the above mentioned inputs,
Suppes’ constraints are verified (Lines 3-8) to first construct a DAG. Then, the likelihood fit is performed by hill
climbing (Lines 9-20), an iterative optimization technique that starts with an arbitrary solution to a problem (in our
case an empty graph) and then attempts to find a better solution by incrementally visiting the neighbourhood of the
current one. If the new candidate solution is better than the previous one, it is considered in place of it. The procedure
is repeated until the stopping criterion is matched. In our implementation, the ! S toppingCriterion occurs (Line 11)
in two situations: (i) the procedure stops when we have performed a large enough number of iterations or, (ii) it stops
when none of the solutions in Gneighbors is better than the current G f it , where Gneighbors denotes all the solutions that
are derivable from G f it by removing or adding at most one edge.
For more information about the algorithm, also refer to [10, 15].
3.2.1. The Problem of False Discovery
We first test the performance of Algorithm 1 on a training data of 10 portfolios, 5 factors and 5000 observations.
On such settings, the algorithm was capable of recovering almost the whole set of embedded causal relationships with
only 13 false negatives, roughly, 33% of total arcs; however, the number of false positives were unacceptably larger,
reaching around 49% of the total causal arcs obtained, thus requiring more attention to how the model was regularized.
The explanation for this trend can be found in how the algorithm implements the regularization via Bayesian
Information Criterion (BIC) [18], that is:
BIC = k · ln(N) − 2 ln(L),
6

277

278	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

7

Algorithm 1 Learning the SBCN [15]
1: Inputs: D an input dataset of n Bernoulli variables and m samples, and r a partial order of the variables
2: Output: S BCN(V, E) as in Definition 2
3: [Suppes’ constraints]
4: for all pairs (v, u) among the n Bernoulli variables do
5:
if r(v) ≤ r(u) and P(u | v) > P(u | ¬v) then
6:
add the arc (v, u) to S BCN.
7:
end if
8: end for
9: [Likelihood fit by hill climbing]
10: Consider G(V, E) f it = ∅.
11: while ! S toppingCriterion() do
12:
Let G(V, E)neighbors be the neighbor solutions of G(V, E) f it .
13:
Remove from G(V, E)neighbors any solution whose arcs are not included in S BCN.
14:
Consider a random solution Gcurrent in G(V, E)neighbors .
15:
if scoreREG (D, Gcurrent ) > scoreREG (D, G f it ) then
16:
G f it = Gcurrent .
17:
end if
18: end while
19: S BCN = G f it .
20: return S BCN.
where k is the number of arcs in the SBCN (i.e. number of causal relationships), n is the number of observations of
the data, and L is the likelihood. The algorithm searches for the Bayesian network that minimizes the BIC.
For large number of observations, the maximum likelihood optimization ensures that asymptotically all the embedded relationships are explored and the most likely solution is recovered. However, maximum likelihood is known
to be susceptible to overfitting [7], especially when, as in our case, it deals with small sample size in the training data.
Furthermore, in the training data, all the portfolios are assumed to depend on the same five factors, although with
different coefficients, but very likely some portfolios will have very similar coefficients, resulting in co-movements
across the portfolios. This co-movement will often induce correlations that affect the probability raising and thus the
spurious prima facie causal relations, making these settings an interesting, and yet a very hard test case. See Figure 3.

Figure 3. The figure simplifies the true causal relationships (on the left), and the spurious relationships (on the right) emerging from the simulated
data.

3.2.2. Sample Size and Information Criterion
To reduce the spurious causalities, we recall some intrinsic properties of the information criteria. The Bayesian
Information Criterion BIC = k · ln(N) − 2 ln(L), not only maximizes the likelihood, but also penalizes the complexity
of the model by the term k · ln(N). For small sample sizes, BIC is generally biased towards simple models because of
the penalty. However, for large sample size, BIC is willing to accept complex models. For additional discussion, see
the details in [7].
7

	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

279
8

In our simulations we adopted a sample size of 5000 which is considerably large relative to the degree of freedom
of the score function, therefore using BIC may lead to the inference of a relatively complex model with a number
of unnecessary spurious arcs. Counter-intuitively, we could improve the solutions by using smaller sized data and
letting the complexity penalty take a bigger effects in BIC score. This also addresses the nonstationarity in the data,
an endemic problem for financial data. Following this intuition, we performed further experiments by reducing the
original sample size of 5000 samples, which describes around 10 years of data, in turn to 250 and 500, and we
observed a significant reduction in the number of false positives, to 38% and 40% of total arcs respectively. However,
at the same time, because of smaller sample size, the number of false negatives inevitably increased to more than 50%
of total arcs.
To reconcile this dilemma, we now next considered an alternative information criterion, the AIC, Akaike Information Criterion [19], defined as in the following:
AIC = 2k − ln(L).
We notice that for AIC, the coefficient of k is set to 2, leading to definitely smaller factor than ln(N) of BIC when
the sample size N is large. For this reason, AIC has the trend of accepting more complex models for given sample
sizes than BIC. Applying AIC, the number of false negatives typically decreases, while the number of false positive
gets larger.
3.2.3. Improving Model Selection by Bootstrapping
Up to this point, we described the different characteristics of two state-of-the-art likelihood scores with respect to
the number of resulting false positive and false negative arcs. Specifically, we showed a trade-off where, because of
their characteristics, the best results on large sample sizes is obtained using BIC, while for small sample sizes AIC is
more effective, but neither of the two regularization schemes have a satisfactory trend. To improve their performance,
now we propose to make use of a bootstrap [20] procedure for model selection.
The idea of bootstrap is the following: we first learn the structure and parameters of the SBCN as before, but
we perform subsequently a resampling procedure where we sample with repetitions data from the dataset in order to
generate a set of bootstrapped datasets, e.g., 100 times, and then we calculate the relative confidence level of each arc
in the originally inferred SBCN, by performing the inference from each of the bootstrapped dataset and counting how
many times a given arc is retrieved. In this way, we obtained a confidence level for any arc in the SBCN.
We once again tested such an approach on our simulations and we observed empirically that the confidence level
of spurious arcs are typically smaller than the confidence level for true causal relations. Therefore, a simple method
of pruning the inferred SBCN to constrain for a given minimum confidence level is here applied. Such a threshold
reflect the number of false positives that we are willing to include in the model, with higher thresholds ensuring
sparser models. Here, we test our approach by requiring a minimum confidence level of 0.5, i.e., any valid arc must
be retrieved at least half of the times.
We now conclude our analysis by showing in Tables 2 and 3 the contingency tables resulting from our experiments
both for Algorithm 1 (Table 3) and for the standard likelihood fit method to infer Bayesian Networks (Table 2):
Sample
250
500
1000
2500
3500
5000

BIC
FP FN
50.4 94.9
51.8 94.7
55.2 93.5
60.3 90.3
62.5 84.2
66.6 80.9

BICBoot
FP FN
31.9 95.3
45.6 96.6
47.6 94.5
54.8 99.9
58.0 94.3
65.6 85.7

AIC
FP FN
57.0 89.5
61.6 93.5
63.7 85.5
68.4 85.7
69.5 85.7
71.8 85.7

AICBoot
FP FN
39.3 95.2
51.5 98.7
50.4 95.2
62.4 99.8
63.7 96.8
70.7 85.7

Table 2. Contingency Table of the Performances by standard Bayesian Networks of Different Information Criteria and Sample Sizes.

Table 3 presents the results in terms of false positives (FP) and false negatives (FN) by Algorithm 1 with the
various methods on the training data with different information criteria, sample sizes, and whether Bootstrapping is
8

280	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

Sample
250
500
1000
2500
3500
5000

BIC
FP FN
37.6 67.7
39.6 52.3
43.1 39.1
52.2 50.8
48.7 33.3
48.7 33.3

BICBoot
FP FN
24.7 83.3
36.8 55.9
40.7 47.8
45.1 50.8
48.7 33.3
47.5 33.3

AIC
FP FN
42.8 40.1
43.7 38.5
47.9 37.6
57.1 28.5
58.8 28.5
57.1 14.3

9

AICBoot
FP FN
27.9 51.5
40.9 39.0
43.9 38.0
50.2 38.6
57.1 28.5
53.8 19.9

Table 3. Contingency Table of the Performances by Algorithm 1 of Different Information Criteria and Sample Sizes.

applied. The trade-off between false positive rates and false negative rates usually is case-specific. We observe that,
in general, the objective of such an approach is to correctly and precisely recover the true distribution underlying the
training data. For this reason, unless differently specified for specific uses, there is not an overall preference toward
either lower false positive or lower false negative. Therefore, we evaluate our methods by considering the sum of
both false positive and false negative rates. This metric is baiased toward a combination of relatively low FP and
FN rather that the combination of very low FP and high FN and so on. By analyzing the results shown in Table
3, we can clearly observe a trend where AIC with Bootstrapping on small sample datasets (i.e., 250) and BIC with
Bootstrapping on large sample datasets (i.e., 5000) produces the best results, consistently with the discussion of the
previous Section. Also, we observe that both for AIC without any bootstrapping on sample sizes of 250 and BIC
without any bootstrapping on sample size of 5000, the false positive rates are reduced without a significant increase
in the false negative rates.
We conclude by pointing out the significant increase in performance (both in termf of FP and FN) when using
SBCNs in place of standard BNs (compare Tables 2 and 3).
3.2.4. Assumption of Sparse Relationships
The resulting false positive rate may still seem relatively high. But, one important assumption is worth mentioning.
In the training data, such high false positive rate derives from the fact that portfolios are dependent on the 5 common
factors, which very likely will induce co-movements. However, in the real data, such nested dependencies do not
always occur, while a feature of sparse relationships appears frequently, and portfolios depend on distinctively small
sets of factors. This assumption of sparsity can significantly improve the performance of the algorithm.
To implement the assumption of sparsity, we deviate from the original Fama French five factor model. For simplicity, we generate data with sparse relationships using a random linear model with 10 factor variables and 20 stock
variables. With 30% probability, each stock variable is dependent linearly on one of the 10 factor variables, so on
average, each stock variable will be dependent on 3 factor variables, which will likely be distinct from the dependent
factor variables of other stock variables. Then we sample factor variable data from normal distribution and compute
the corresponding stock data using the linear model.
Implementing this sparsity on a new set of purely random training data we obtain with Algorithm 1 much better
results, and, e.g., following the BIC with Bootstrapping method mentioned above, we obtain on small sample size
(250 samples) 18.1% false positive and 39.2% false negative rates, while on large sample size (2500 samples), we
obtain 50.2% false positive and 38.6% false negative rates.
Also the results for general BNs improve, but still being less effective than SBCNs.
3.2.5. Summary, ROC Space
We finally summarize in Figure 4 the results of this Section by interpolating and then smoothing out some kinks,
and we obtain an ROC Space, whose x axis represent the False Positive Rate and y axis the True Positive Rate.
ROC Space depicts the performance of the different methods we discussed on different sample sizes. By examining
the plot, one can conclude that AICs generally have high true positive rates but also high false positive rates, as a
result of its less stringent complexity penalty. In contrast, BICs generally have smaller false positive rates, but its
true positive rates are also lower. Comparing the algorithms with and without bootstrapping, one can notice that the
bootstrap procedure shifts the curves to the left. Still, the best performance lies in the data with the assumption of
9

	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

10

sparse relationships. Based on these results, we can conclude that with Bootstrapping and the assumption of sparse
relationships, our algorithm is capable of recovering accurately the causal relationships in the data.

Figure 4. Performance in the ROC Space, depicts the trade-offs between false positive rates and true positive rates. The better results lie in the
upper-left corner of the graph where false positive rate is low and true positive rate is high.

3.3. Performing Stress Testing
In this Section we present how to assess stress testing scenarios given the inferred Suppes-Bayes Causal Network
and we present the results on the simulated data.
3.3.1. Risk Management by Simulations
After the inference of the SBCN, we perform Monte Carlo Simulation in the same way as conventional risk
management, by drawing large number of samples to discover the worst 5% scenarios as the value at risk (VaR). Nevertheless, here in stress testing, we are targeting the most extreme events, which have very low but nonzero probability
of occurrence. Thus, they still can occur, for example, the 2008 financial crisis or the most recent market reactions to
BREXIT. Therefore, when drawing samples from the network, we would like to reject the normal scenarios, and place
more importance on the extreme events. To achieve this goal, when conducting random sampling, we classify each
possible branch as profitable or risky, and if the branch is classified as profitable, then we will avoid that branch.
Figure 5 represents a simple binary classification where for this factor only Factor.i with value 0 is considered
risky and, hence, this scenario is the only one to be sampled. In this way, we target the extreme risky events and reduce
computation. But, unlike conventional risk management, this approach does not allow us to estimate the probability
of occurrence of the sampled extreme events, therefore we will not conclude a value at risk with certain confidence
level.
The simple binary classification with certain features is a standard machine learning problem. Here we explore a
simple solution of such a task based on decision trees [21]. A decision tree is a predictive models that maps features of
an object to a target value of the object. Here, the features are the factors of interest, and the target value is whether the
portfolio is prone to profit or loss. To perform classification, we first draw 1000 sample trajectories from the inferred
SBCN. Then we construct a simple portfolio, which is long on all the stocks in the SBCN by the same amount, and
calculate the Profit and Loss (P/L) of each observation. Here however, because the underlying SBCN depicts binary
variables, exact Profit and Loss (P/L) statistics cannot be obtained. Instead, since the toy portfolio is long on all stocks
by the same amount, the ratio of stocks that goes up is an approximate measure of risk. Of course, for continuous
Bayesian network, Profit and Loss can be calculated directly. In the next step, we sort this measure, and denote the
bottom-most 100 scenarios as risky, and the rest as profitable. The 100 ‘risky’ scenarios contain at least 7 stocks that
10

281

282	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

11

Figure 5. Risk classification in our SBCN.

fall. Then we consider 1000 samples each of them labeled as ‘risky’ or ‘profitable’. In our experiments, we used the
R ‘tree’ package [22].
Using the SBCN learned from the simulated training data, we obtain the following decision tree shown in Figure
6.

Figure 6. Decision tree obtained from the SBCN.

In the decision tree of Figure 6, S denotes factor S MB; M denotes Market Km ; H denotes HML; R denotes RMW
and C denotes CMA. Here we show only the left part of the entire computed decision tree, the subtree with S = 1
is omitted, since the entire subtree with S = 1 is classified as ‘Profitable’, which is not of interest for stress testing.
In the tree, we identify two paths that are classified as ‘Risky’. Path S = 0, M = 0, H = 0, R = 0, C = 0 and Path
S = 0, M = 0, H = 0, R = 0, C = 1. The paths classified are intuitive, since our example portfolio is long with equal
amount invested over all 10 stocks. Since 10 stocks are generally positively dependent on the factors, most factors
with 0 values will likely induce a ‘Risky’ path. For more complicated portfolios and real factors, such intuition cannot
be easily found so we have to rely on the result of classification.
11

	

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284
/ Procedia Computer Science 00 (2017) 1–13

12

3.3.2. Scenario Generation and Results
Given the tree of Figure 6, we then used the bnlearn R package [23] to sample from the SBCN. Given the
network, we can simulate random scenarios, however, we wish not to simulate all of them, which will prove to be
inefficient, but following the informations provided by the classification tree we choose the configurations which are
likely to indicate risk to drive our sampling. For instance, we may pick the first path in the tree, which is S = 0,
M = 0, H = 0, R = 0, C = 0, and constrain the distribution induced by the SBCN. In order to avoid sampling the
scenarios which are not in accordance with the path, we adjust the conditional probability table of the SBCN. Since
we want paths with all five factors taking value 0, we set the conditional probability of these five factors taking value
1 to 0, and the conditional probability of factors taking value 0 to 1. In this way, the undesirable paths will be unlikely
to be simulated, while the intrinsic distribution of how factors affect the stocks is still modeled. More sophisticated
implementation based on this intuition are possible: e.g., using branch-and-bound, policy valuation, tree-search, etc,
but we will leave this to further research.
Comparing the results of the simulations given the original SBCN and the one taking into account the decision
tree, we show the distribution of the risk measure, the number of stocks that go up in the Figure 7.

Figure 7. Distribution of Number of Stocks Going Up.

The number of stocks going up from 100 samples generated by the original SBCN is roughly evenly distributed.
At the same time, the 100 samples generated by the modified SBCN contain no scenarios with more than 5 stocks
going up, and 84 out of the 100 samples have at most 1 stock going up. We can clearly see that the modified
SBCN places far more importance on the stressed scenarios, and in turn confirms the result of the classification
algorithm by the decision tree. In this way, computational complexity involved in generating stressed scenarios can
be improved tremendously. This kind of computational efficiency issues will be more critical when we move from a
simple Bernoulli random variable to multi-categorical variables or continuous random variable. Therefore, with the
same computing power, the modified SBCN makes it possible to generate more stressed scenarios, and observe how
portfolios or other assets respond to stressed factors.
4. Conclusions
In summary, in this paper we develop a novel framework to perform stress testing combining Suppes-Bayes
Causal Networks and machine learning classification. We learn SBCNs from data using Algorithm 1 and assess the
quality of the learned model by switching information criteria based upon sample sizes and bootstrapping. We then
simulate stress scenarios using SBCNs, but reduce computation by classifying each branch of nodes in the network as
‘profitable’ or ‘risky’ using classification trees. For simplicity, the paper implements SBCNs with Bernoulli variables
and simulates data using Fama French’s Five Factor Model, but the logic of the problem is easily extended to deal
with more practical situations. First of all, the SBCNs can accommodate more complicated variables (nodes). In
addition to the factor based portfolios considered here, other factor models, or directly other financial and economic
factors like foreign exchange rates, can also be included, and the accuracy of the model can ensure that the true causal
12

283

Gelin Gao et al. / Procedia Computer Science 108C (2017) 272–284

284	

/ Procedia Computer Science 00 (2017) 1–13

13

relationships among the factors are discovered. In practice, variables like stock prices are continuous, thus, one can
easily extend to these situations by adopting a hybrid SBCN, where the variables can take either discrete or continuous
values, making it possible to represent precisely the values of the variables we are interested in.
To use the model, the role of experts is still important. After learning the SBCN from data and applying classification, we can identify a number of stressed scenarios. However, we expect that some of these to be unacceptable
for various unforeseen reasons, e.g., as those known to domain experts. These scenarios may be thought of as highly
stressed with respect to the corresponding portfolio but they could prove to be less useful in practice. Therefore,
experts can select from the identified stressed scenarios only the plausible ones, and discard the ones deemed to be
flawed. Even in this case, we can perform simulations following the selected stressed paths in the SBCN and observe
the reactions of the portfolios in these stressed scenarios of interest, and thus adjust the portfolios based on the reactions. Another direct usage of our approach is when experts have a particular candidate stress scenario in mind, which
can be justified a priori; in this case one can skip the process of classification and directly adjust the SBCN mutatis
mutandis. Therefore, simulations of the adjusted SBCN will also offer the reactions of the portfolio to this particular
stressed scenario.
We believe, based on our empirical analysis, that we have devised an efficient automated stress testing method
using machine learning and causality analysis in order to solve a critical regulatory problem, as demonstrated by the
algorithm’ ability to recover the causal relationships in the data, as well as its efficiency, in terms of computation and
data usage.
References
[1] A. J. McNeil, R. Frey, P. Embrechts, Quantitative Risk Management: Concepts, Techniques and Tools, Princeton University Press, 2010.
[2] S. Raychaudhuri, S. J. Mason, R. R. Hill, L. Mnch, O. Rose, T. Jefferson, J. W. Fowler, Introduction to monte carlo simulation, in: 2008
Winter Simulation Conference, 2008.
[3] S. Manganell, R. F.Engle, Value at risk models in finance, European Central Bank Working Paper Series.
[4] S. Claessens, M. A. Kose, Financial crises: Explanations, types and implications, IMF Working Paper Series.
[5] C. on the Global Financial System, Stress testing at major financial institutions: survey results and practice (2005).
[6] R. Rebonato, Coherent Stress Testing: a Bayesian approach to the analysis of financial stress, John Wiley & Sons, 2010.
[7] D. Koller, N. Friedman, Probabilistic graphical models: principles and techniques, MIT press, 2009.
[8] N. Beerenwinkel, N. Eriksson, B. Sturmfels, Conjunctive bayesian networks, Bernoulli (2007) 893–909.
[9] L. O. Loohuis, G. Caravagna, A. Graudenzi, D. Ramazzotti, G. Mauri, M. Antoniotti, B. Mishra, Inferring tree causal models of cancer
progression with probability raising, PloS one 9 (10) (2014) e108358.
[10] D. Ramazzotti, G. Caravagna, L. O. Loohuis, A. Graudenzi, I. Korsunsky, G. Mauri, M. Antoniotti, B. Mishra, Capri: efficient inference of
cancer progression models from cross-sectional data, Bioinformatics 31 (18) (2015) 3016–3026.
[11] D. Ramazzotti, A. Graudenzi, G. Caravagna, M. Antoniotti, Modeling cumulative biological phenomena with suppes-bayes causal networks,
arXiv preprint arXiv:1602.07857.
[12] D. Ramazzotti, M. Nobile S, A. Graudenzi, M. Antoniotti, Learning the probabilistic structure of cumulative phenomena with suppes-bayes
causal networks, Submitted.
[13] P. Suppes, A probabilistic theory of causality, North-Holland Publishing Company Amsterdam, 1970.
[14] G. Caravagna, A. Graudenzi, D. Ramazzotti, R. Sanz-Pamplona, L. De Sano, G. Mauri, V. Moreno, M. Antoniotti, B. Mishra, Algorithmic
methods to infer the evolutionary trajectories in cancer progression, PNAS.
[15] F. Bonchi, S. Hajian, B. Mishra, D. Ramazzotti, Exposing the probabilistic causal structure of discrimination, arXiv preprint
arXiv:1510.00552.
[16] K. Pearson, Mathematical contributions to the theory of evolution.–on a form of spurious correlation which may arise when indices are used
in the measurement of organs, Proceedings of the royal society of london 60 (359-367) (1896) 489–498.
[17] E. F. Fama, K. R. French, Multifactor explanations of asset pricing anomalies, The journal of finance 51 (1) (1996) 55–84.
[18] G. Schwarz, et al., Estimating the dimension of a model, The annals of statistics 6 (2) (1978) 461–464.
[19] H. Akaike, Information theory and an extension of the maximum likelihood principle, in: Selected Papers of Hirotugu Akaike, Springer,
1998, pp. 199–213.
[20] B. Efron, Nonparametric estimates of standard error: the jackknife, the bootstrap and other methods, Biometrika 68 (3) (1981) 589–599.
[21] S. R. Safavian, D. Landgrebe, A survey of decision tree classifier methodology.
[22] B. Ripley, Tree: Classification and Regression Trees, r package version 1.0-37 (2016).
URL https://CRAN.R-project.org/package=tree
[23] M. Scutari, Learning bayesian networks with the bnlearn r package, arXiv preprint arXiv:0908.3817.

13

