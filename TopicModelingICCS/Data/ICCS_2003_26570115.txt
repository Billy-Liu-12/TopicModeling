Studying System Properties with Rough Sets
Alicja Mieszkowicz-Rolka and Leszek Rolka
Department of Avionics and Control,
Rzesz´
ow University of Technology,
ul. W. Pola 2, 35-959 Rzesz´
ow, Poland
{alicjamr, leszekr}@prz.rzeszow.pl

Abstract. This paper considers the analysis of decision system properties basing on the rough sets theory. Investigation of human operator’s
decision model in dynamic processes is discussed. Extensions of the basic rough sets theory are presented, which are useful in case of analysing
inconsistent decision tables. Rough sets aided research of data sets properties, in order to facilitate the synthesis of feedforward neural networks,
is proposed. Examples based on real data are given.

1

Introduction

The rough sets theory was introduced by Pawlak [1,2] in early 80’s years and
can be used for analysing information systems expressed in form of decision
tables. Many applications of the rough sets theory were proposed [3,8] and some
theoretical modiﬁcations and extensions were introduced [4,6,7]. In this paper the
rough sets theory will be discussed in two diﬀerent contexts. The ﬁrst one refers
to evaluation of human operator’s decision model, who controls a dynamic plant.
This is contrary to the most recognised applications of the rough sets theory,
which concerned industrial processes with slow dynamic or static information
systems [2,8]. The second one deals with design and veriﬁcation of artiﬁcial
neural networks for diagnosis of the grinding wheel wear.

2

The Rough Sets Measures

An information system is deﬁned as an ordered 4-tuple
S = X, Q, V, f

(1)

where:
X – a nonempty set, called the universe,
Q – a ﬁnite set of attributes,
V – a set of attributes values, V = q∈Q Vq ,
f – an information function, f : X × Q → V, f (x, q) ∈ Vq , ∀q ∈ Q and ∀x ∈ X.
The elements of the universe X can be compared by considering the values
of their attributes. A binary indiscernibility (equivalence) relation R deﬁned in
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2657, pp. 115–124, 2003.
c Springer-Verlag Berlin Heidelberg 2003

116

A. Mieszkowicz-Rolka and L. Rolka

the universe, generates a partition of the universe into indiscernibility classes
denoted by X/R.
Let [x]R denote an indiscernibility class that contains the element x.
R-lower approximation of a set A ⊆ X, denoted as R(A), is a set deﬁned as
follows:
R(A) = {x ∈ X: [x]R ⊆ A} .
(2)
R-upper approximation of a set A ⊆ X, denoted as R(A), is a set deﬁned as
follows:
R(A) = {x ∈ X: [x]R ∩ A = ∅} .
(3)
The pair of sets (R(A), R(A)) is called the rough set approximating A.
A positive area of the set A ⊆ X is a set denoted by PosR (A) = R(A).
Each subset of attributes P ⊆ Q generates in the universe X a binary indiscernibility relation, denoted by IND(P ). A decision model divides the universe
into subsets (classes) denoted by Y = {Y1 , Y2 , . . . , Yn }. The classiﬁcation Y
can be approximated using the indiscernibility classes obtained for a subset of
attributes P .
P (Y ) = {P (Y1 ), P (Y2 ), . . . , P (Yn )} is a family of the lower approximations
of the classiﬁcation Y . The sum of the subsets contained in the family of lower
approximations is called a positive area PosP (Y ).
P (Y ) = {P (Y1 ), P (Y2 ), . . . , P (Yn )} is a family of the upper approximations
of the classiﬁcation Y .
The approximation quality of Y by P denoted by γP (Y ) is deﬁned as follows:
γP (Y ) =

card(PosP (Y ))
=
card(X)

n
i=1

card(P (Yi ))
card(X)

(4)

where card denotes the cardinality of a set.
The approximation accuracy of a set A ⊆ X by P denoted by βP (A) is
deﬁned as the quotient of cardinalities of the P -lower approximation and the
P -upper approximation of A:
βP (A) =

card(P (A))
.
card(P (A))

(5)

For a classiﬁcation Y the deﬁnition of approximation accuracy (accuracy of
classiﬁcation) βP (Y ) is given as follows:
βP (Y ) =

n
i=1
n
i=1

card(P (Yi ))
.
card(P (Yi ))

(6)

The above notation can be further expanded, when the set of attributes is
divided into subsets of condition attributes C and decision attributes D and

Studying System Properties with Rough Sets

117

used to describe a system of decision rules (decision table). The classiﬁcation
Y = {Y1 , Y2 , . . . , Yn } is then given by indiscernibility classes obtained with respect to decision attributes D. We can evaluate the approximation quality of the
classiﬁcation Y by means of the indiscernibility classes generated for condition
attributes C.

3

Variable Precision Rough Sets in Human Operator’s
Decision Model

The control actions of the operator can be expressed in form of decision table.
It is necessary to specify the condition and decision attributes and take into
account the lag caused by human factor and the characteristic of the controlled
plant. The recorded process data are used to build a decision table, which is the
base for determining the decision model of the operator. It is easy to ﬁnd contradictory decisions in control of dynamic systems since the obtained universes
are relatively large. The non-deterministic decision rules are always omitted (in
lower approximation) in the original rough sets theory, and the calculated value
of approximation quality γC (D) can be low. The described problems may be
avoided by using the approach of variable precision rough sets theory (VPRS)
[4,6,7] which is more suitable for analysis of dynamic plant control. We proposed
some modiﬁcations of VPRS.
It is possible to determine the consistence of control actions of the operator,
who controls a dynamic system, and specify his decision model in form of deterministic decision rules. This is done by evaluating the measure denoted by
kAR (described bellow) that expresses the dependence of decision attributes on
condition attributes.
We proposed [6] a new deﬁnition of the α-positive area of a set A ⊆ X:
Posα
R (A) = {x ∈ X: x ∈ ([x]R ∩ A) and e([x]R , A) ≤ α}
where
e(A, B) = 1 −

card(A ∩ B)
.
card(A)

(7)

(8)

The quantity e(A, B), deﬁned for any nonempty sets A and B, is called the
inclusion error of A in B [4]. The value of α should be limited: 0 ≤ α ≤ 0.5.
The notion Posα
R (A) can be applied to a family of sets. By using it to a family
of equivalence classes D∗ obtained from a decision table we get a new measure
denoted by kAR .
The α-approximation quality of D∗ by C is expressed as follows:
kAR =
where:

∗
card(Posα
C (D ))
=
card(X)

n
i=1

m
j=1 δij card(Ci

card(X)

∩ Dj )

(9)

118

A. Mieszkowicz-Rolka and L. Rolka

δij =

1
0

if e(Ci , Dj ) ≤ α
otherwise

n – number of equivalence classes for decision attributes C,
m – number of equivalence classes for condition attributes D,
α – acceptable inclusion error; 0 ≤ α ≤ 0.5,
D∗ = {D1 , D2 , . . . , Dm }.
If the value of kAR is nearly equal to 1, then the consistence (determinism)
of operator’s decisions is large and his decision model is constant. A low value
of kAR indicates that the decisions are random and don’t depend on the values
of condition attributes (assuming a complete set of condition attributes).
This means that the operator’s abilities to process the information are not
correctly formed. One can also detect the importance of particular condition
attributes and determine the subset of attributes necessary for identiﬁcation
of the operator’s decision model. If, after removing a condition attribute, the
value of kAR is not changing, it means that the attribute is not necessary and
doesn’t have a signiﬁcant importance in the decision process.
A lot of pilot’s control protocols were analysed using the VPRS approach.
The condition attributes consisted of: deviations from required values of selected
ﬂight parameters, and the changes of the former parameters as a source of
prognostic information for the pilot. The decision attributes were deﬂection
angles or changes of deﬂection angles of the aircraft’s control elements. The
values for particular condition attributes were coded as integer numbers e.g. (-3,
-2, -1, 0, 1, 2, 3) basing on ﬁxed intervals for deviations from the required values
of the parameters. The boundaries of the intervals conform to valid norms or
suggestions of experts. For decision attributes the linguistic values ”negative”,
”zero”, ”positive” were used.
In order to analyse the control task of selected variables two methods were
used and the results of them were compared:
a) method, which determine the values of kAR for all discrete-time instants (all
elements of the universe) for a given decision table,
b) method, which determine the values of kAR for those instants only, were a
qualitative change of control occurred.

Table 1. Analysis of decision table for altitude stabilisation
Method

k = γC (D)

kAR
α = 0.2

Number
of elements
in universe

Number
of det.
rules

Number
of non-det.
rules

a
b

0.128
0.648

0.859
0.722

658
54

11
16

40
11

Studying System Properties with Rough Sets

119

The examples of decision tables analysis are presented in the tables 1 and 2.
The values of kAR in the table 1 show that the consistence of operator’s decisions
is quite large and his decision model is rather constant. One can observe a big
diﬀerence between the calculated value of approximation quality k = γC (D) and
the value of kAR , especially for the method a.
Table 2. Importance of condition attributes for altitude stabilisation (method b)
Removed attribute
kAR (α = 0.2)

none
0.722

c1
0.722

c2
0.556

c3
0.211

c4
0.0

Basing on the evaluated importance of condition attributes we can state, in
case of altitude stabilisation (table 2), that for the generated decision table the
attributes: c2 – rate of climb, c3 – change of rate of climb and c4 – previous
change of rudder deﬂection angle are particularly important. The attribute c1
– deviation of altitude from the required value has not a big importance. After
analysis of many control tasks realised by pilots on a ﬂight simulator we can
observe that the VPRS modiﬁcation is a useful method, which helps to identify
the decision model of human operator who controls a dynamic plant.
The presented approach was combined with another (statistical) methods in
order to fully describe the process of control performed by a human operator.

4

Application of the Rough Sets Theory to Synthesis of
Artiﬁcial Neural Networks

An important question in the area of artiﬁcial neural networks is – how utilise
eﬀectively all information contained in the training data sets in the process of
synthesis of feedforward neural networks. We propose to apply the rough sets
measures for research of data sets expressed in form of information systems.
The rough sets measures were used during design of neural networks and
applied to data sets obtained from a real classiﬁcation task [5]. The problem
was to build a classiﬁer that could automatically evaluate the degree of wear of
the grinding wheel, in the grinding process. This classiﬁcation is commonly performed by a skilled operator (expert). In order to do the task automatically the
characteristic process quantities must be measured (e.g. grinding forces, acoustic
emission) and fed into the inference system. Trying to create a classiﬁer based
on neural networks was one of the used approaches.
Basing on registered process data and classiﬁcation of an expert, decision
tables for training and testing set were obtained. The investigations concerned
classiﬁcation with only two values of the decision attribute, which represent two
characteristic states of the grinding wheel (Y1 - sharp, Y2 - blunt). An attempt
was made to obtain a ﬁner classiﬁcation with one additional characteristic state.
The analysis of properties of data sets (quality of approximation, dependencies between attributes, signiﬁcance of the condition attributes in the decision

120

A. Mieszkowicz-Rolka and L. Rolka

process) led to a conclusion, that the training patterns are suitable to create
a good classiﬁer. The results of the analysis are given in the table 3. The obtained
quality of approximation for the original universal set was about 0.9, which is
a good value in real applications. The properties of independently generated
training and testing sets were qualitatively similar. When these properties are
comparable for both the sets, a conclusion can be made, that both the training
and testing sets are similarly representative for the considered problem.
Table 3. The approximation quality and accuracy of the training set
Removed attributes

γP (Y )

βP (Y )

βP (Y1 )

βP (Y2 )

none
c1
c2
c3
c4
c5
c6
c7
c5 , c6
c5 , c7
c6 , c7
c5 , c6 , c7

0.88
0.82
0.65
0.79
0.88
0.78
0.38
0.88
0.15
0.77
0.38
0.074

0.78
0.69
0.49
0.65
0.78
0.64
0.24
0.78
0.087
0.63
0.24
0.038

0.78
0.68
0.49
0.63
0.78
0.64
0.22
0.78
0.079
0.63
0.22
0.046

0.78
0.70
0.48
0.66
0.78
0.64
0.26
0.78
0.072
0.63
0.26
0.031

In the next step a feedforward neural network with one hidden layer was
created and trained. Various network structures (number of hidden neurones)
were tested. Good training results have been received because the consistency
of the training set was high (0.9).
In another case the approximation quality for training set was only about
0.61 (table 4) and we could expect poor training results of a neural classiﬁer as
shown in the table 5. It is of course possible to increase the number of hidden
neurones and improve the learning on the training set, but we could easily verify
(using the testing set) that such a neural classiﬁer is not a good one.
Table 4. Training set with low approximation quality
Removed attributes

γP (Y )

βP (Y )

βP (Y1 )

βP (Y2 )

none

0.61

0.41

0.46

0.34

We made also an attempt to modify the training algorithm. The importance
of patterns in the training set is not equal. It is possible to divide the training
set into subsets, which could be classiﬁed with various number of condition
attributes (a condition attribute is identical with a network input, and a decision

Studying System Properties with Rough Sets

121

Table 5. Training results for low approximation quality (network structure 7-4-3)
Trial
number

Number
of present.

Training
error [%]

1
2
3
4
5

9005
5154
7223
5602
5918

4.0
2.8
5.2
2.7
5.2

attribute corresponds to a network output). One can generate a division of the
universe basing on minimal number of condition attributes needed to classify
each of the training examples. We can use a modiﬁed method of presenting the
examples to the network during training, by regarding the ability of classiﬁcation
for each of the training patterns. In the standard training algorithm each of the
training examples is presented with an equal frequency. It seems reasonable to
base the number of presentations of the training patterns on the number of
condition attributes needed to classify them.
Let denote by Xk a subset of elements of the training patterns universe X,
which require for a correct classiﬁcation at least k most signiﬁcant condition
attributes. For a small value of k the subset Xk may be empty.
We can assign to each nonempty subset Xk a coeﬃcient ck denoting the frequency of presentation of a given subset during the training of the network. If an
equal frequency for all training examples (probability for a random presentation)
is applied, then the following condition is fulﬁlled:
ck =

card(Xk )
.
card(X)

(10)

When regarding diﬀerent classiﬁcation ability of the subsets Xk , the coeﬃcients ck can be modiﬁed. For a subset Xk , which contains training patterns,
that require a greater number of condition attributes for classiﬁcation, the coefﬁcient ck may be slightly increased. Such a modiﬁcation of the network training
is equivalent to seeking for minimum of a modiﬁed cost function Em , in which
some of the elements in the sum of the square errors would me multiplied by a
number greater then 1. The modiﬁed cost function Em has generally a greater
value than the original cost function E (Em ≥ E). Thus, reaching the required
value for the modiﬁed cost function also delivers an acceptable value for the
original cost function.
The training patterns, divided into subsets based on the number of the most
signiﬁcant condition attributes needed for their classiﬁcation, are shown in the
table 6. The neural network was then trained using the subsets X4 and X5 more
frequently. This resulted in some cases in a better convergence of the training
(table 7). The removal of contradictory training patterns was important to attain
a better quality of the training set.

122

A. Mieszkowicz-Rolka and L. Rolka

Table 6. Training subsets with respect to the most signiﬁcant condition attributes
Subset

Condition
attributes

Approximation
quality

Number
of elements

X5
X4
X3
X2
X1

1,
2,
2,
2,
6

0.88
0.77
0.43
0.39
0.00

14
47
5
53
0

2, 3, 5, 6
3, 5, 6
5, 6
6

Table 7. Training results for diﬀerent presentation of sets (network structure 7-4-2)
Required
training
error [%]

Additional
presentation
of set

Number
of trials

Total number
of present.

0.5
0.5
0.5
0.05
0.05
0.05

U5
U4
U5
U4

1
1
1
7
1
7

240
192
149
94163
7697
56422

In the last step the importance of connections between neurones for created
variants of neural network was researched. It was an interesting stage, during
which the possibility to discover superﬂuous connection was conﬁrmed and
eﬀectively used. The table 8 contains the values of approximation quality for a
hidden layer and for single neurones in that layer. In the table 9 the values of
approximation quality for the output layer are given.
It must be emphasised that the training patterns itself were not changed in
any way by the algorithms used to investigate the properties of the patterns
set. A random character of the training algorithm was maintained in order to
eﬀectively reach a minimum of the cost function. The obtained practical results
conﬁrm the usefulness of the proposition given in this paper. Nevertheless more
complex investigations would be necessary to make well-founded conclusions.
We suggest in any case to carry out an research of data set properties when
designing neural networks.

5

Conclusions

The rough sets theory and its extensions (e.g. VPRS) can be relatively easy
applied to analysis of data sets expressed in form of decision tables. Basing on
various rough sets measures one is able to discover the properties of information
systems and to optimise decision rules by ﬁnding the reducts of attributes. The
variable precision rough sets theory (VPRS) was especially helpful in research

Studying System Properties with Rough Sets

123

Table 8. Approximation quality for the hidden layer (network structure 7-4-2)
Removed input

γP (Y )

γP 1 (Y )

γP 2 (Y )

γP 3 (Y )

γP 4 (Y )

none
1
2
3
4
5
6
7

0.82
0.77
0.59
0.73
0.79
0.72
0.34
0.82

0.91
0.90
0.85
0.88
0.91
0.91
0.70
0.91

1.00
0.98
1.00
1.00
1.00
1.00
1.00
1.00

0.90
0.87
0.73
0.86
0.90
0.81
0.61
0.90

0.94
0.93
0.82
0.90
0.92
0.94
0.52
0.94

Table 9. Approximation quality for the output layer (network structure 7-7-2)
Removed input

γP (Y )

none
1
2
3
4
5
6
7

1.00
0.74
1.00
1.00
1.00
0.82
0.60
0.36

of large universes that are obtained in case of control of dynamic systems. The
VPRS measures are not so “restrictive” as those of the original rough sets theory and are better suited for analysis of inconsistent decision tables. The rough
sets theory can be used on various stages of neural networks design to: optimise
training and testing sets, asses representativeness of training and testing sets,
predict convergence of training by inspecting consistency of training patterns,
modify pattern presentation using the evaluated signiﬁcance of training examples, analyse and optimise (reduce) trained networks. We can conclude that the
rough sets theory constitutes an useful framework especially for creating hybrid
soft computing systems.

References
1. Pawlak, Z.: Information systems. Theoretical fundamentals. WNT, Warszawa (1983)
(in Polish)
2. Pawlak, Z.: Rough Sets. Theoretical Aspects of Reasoning about Data. Kluwer Academic Publishers, Dordrecht Boston London (1991)
3. Slowi´
nski, R. (ed.): Intelligent Decision Support. Handbook of Applications and Advances of the Rough Sets. Kluwer Academic Publishers, Dordrecht Boston London
(1992)

124

A. Mieszkowicz-Rolka and L. Rolka

4. Ziarko, W.: Analysis of Uncertain Information in the Framework of Variable Precision Rough Sets Modelling. Proceedings of Workshop. Rough Sets. State of Art and
Perspective. Kiekrz, Poland (1992)
5. Rolka, L., Mieszkowicz-Rolka, A.: The application of rough sets and fuzzy sets in
the grinding process. Proceedings of the 4-th Conference – Knowledge Engineering
and Expert Systems. Wroclaw, (2000) (in Polish)
6. Mieszkowicz-Rolka, A., Rolka, L.: Variable Precision Rough Sets in Analysis of Inconsistent Decision Tables. In: Rutkowski, L., Kacprzyk, J. (eds.): Advances in Soft
Computing. Proceedings of the Sixth International Conference on Neural Network
and Soft Computing. Zakopane, Poland, Physica-Verlag (2003)
7. Mieszkowicz-Rolka, A., Rolka, L.: Variable Precision Rough Sets. Evaluation of
Human Operator’s Decision Model. In: Soldek, J., Drobiazgiewicz, L. (eds.): Advanced Computer Systems. Proceedings of the 9-th International Conference on
ACS. Mi¸edzyzdroje, Szczecin, Poland (2002)
8. Mr´
ozek, A.: Inference Models of Human Operators and their Application in Computerization of Technological Objects. Scientiﬁc Papers of the Silesian University of
Technology, Gliwice (1989) (in Polish)

