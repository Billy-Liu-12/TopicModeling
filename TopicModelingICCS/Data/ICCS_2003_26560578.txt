Round Eﬃciency of Multi-party Computation
with a Dishonest Majority
Jonathan Katz1 , Rafail Ostrovsky2 , and Adam Smith3
1

2

Dept. of Computer Science, University of Maryland, College Park, MD.
jkatz@cs.umd.edu
Telcordia Technologies, Morristown, NJ. rafail@research.telcordia.com
3
MIT Lab. for Computer Science, Cambridge, MA. adsmith@mit.edu

Abstract. We consider the round complexity of multi-party computation in the presence of a static adversary who controls a majority of
the parties. Here, n players wish to securely compute some functionality
and up to n − 1 of these players may be arbitrarily malicious. Previous
protocols for this setting (when a broadcast channel is available) require
O(n) rounds. We present two protocols with improved round complexity: The ﬁrst assumes only the existence of trapdoor permutations and
dense cryptosystems, and achieves round complexity O(log n) based on a
proof scheduling technique of Chor and Rabin [13]; the second requires a
stronger hardness assumption (along with the non-black-box techniques
of Barak [2]) and achieves O(1) round complexity.

1

Introduction

Protocols for secure multi-party computation (mpc) allow a set of n parties to
evaluate a joint function of their inputs such that the function is evaluated correctly and furthermore no information about any party’s input — beyond what is
leaked by the output of the function — is revealed (a formal deﬁnition is given in
Section 2). Since the initial results showing that mpc was feasible [34,24,7,12], a
number of works have focused on improving the eﬃciency of these protocols and
in particular their round complexity (e.g., [1,6,29,28,22,30,15]). Known results
for generic mpc secure against malicious adversaries in the computational setting
may be summarized as follows (results are stated for the setting when a broadcast channel is available; we discuss the setting without a broadcast channel in
Section 2.1):
– Secure two-party computation may be achieved in a constant number of
rounds by applying the compiler of Lindell [30] (based on earlier work of
Goldreich, Micali, and Wigderson [24]) to the constant-round protocol of
Yao [34] (which is secure against semi-honest adversaries).
Supported in part by U.S. Army Research Oﬃce Grant DAAD19-00-1-0177
E. Biham (Ed.): EUROCRYPT 2003, LNCS 2656, pp. 578–595, 2003.
c International Association for Cryptologic Research 2003

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

579

– Secure mpc for honest majorities (i.e., when the number of corrupted players
is strictly less than n/2) may be achieved in a constant number of rounds
using the protocol of Beaver, Micali and Rogaway [6,33].
– Secure mpc with dishonest majority (i.e., where up to n − 1 players may be
corrupted) can be achieved in O(n) rounds using the protocols of Beaver,
Goldwasser, and Levin [5,26]. (Actually, these works show a protocol requiring O(k + n) rounds where k is the security parameter. Using the techniques
of [30], however, this may be improved to O(n).)
– Canetti, et al. [11] give a protocol tolerating adaptive adversaries controlling a dishonest majority in a model in which a common random string is
assumed; the round complexity of this protocol depends on the depth of the
circuit for the function being computed, but is independent of n.
Note that the setting with a dishonest majority (t ≥ n/2) requires a weaker
variant of the usual deﬁnition of mpc. Even for the case n = 2, one cannot prevent
the adversary from aborting the protocol, or from possibly learning information
about the value of the function even when an abort occurs [24,14].
Our Results. We focus on improving the round complexity of mpc when a majority of the players may be corrupted. We show two protocols for that setting
which have improved round complexity compared to previous work. Our ﬁrst
protocol assumes the existence of trapdoor permutations and dense cryptosystems, and achieves round complexity O(log n). Our second protocol runs in a
constant number of rounds, but requires slightly stronger hardness assumptions
as well as non-black-box proof techniques. We prove our results in the standard
model of a synchronous, complete network with a broadcast channel. Our results
can be extended to the setting when no broadcast channel is available, and give
improved round complexity there as well; see Section 2.1.
Our overall approach consists of two steps. We ﬁrst consider the speciﬁc case
of the coin ﬂipping functionality, and give protocols for securely computing this
functionality in the presence of a dishonest majority. We then note that mpc
of arbitrary functions can be reduced to the problem of secure coin ﬂipping; in
fact, we show that any functionality can be computed in a constant number of
rounds following an execution of a secure coin-ﬂipping protocol.
Our main result, then, is to give two protocols with improved round complexity for the speciﬁc case of coin ﬂipping. The ﬁrst, based on a proof scheduling
technique of Chor and Rabin [13], requires O(log n) rounds. (Interestingly, the
Chor-Rabin protocol itself does not seem suﬃcient to implement mpc; we need to
ﬁrst establish a common random string and then use that string for secure computation.) Our second coin-ﬂipping protocol extends recent work of Barak [2];
speciﬁcally, we show how to modify his (asynchronous) two-party non-malleable
coin-ﬂipping protocol to obtain one which is secure even when composed in parallel n times, and from there obtain a constant-round coin-ﬂipping protocol which
is secure in the (synchronous) multi-party setting. We may thus summarize our
results as follows (here, n is the number of players, k is the security parameter,
and we always assume a synchronous network with broadcast):

580

J. Katz, R. Ostrovsky, and A. Smith

Theorem 1.1. There exist protocols for (n − 1)-secure simulatable coin-ﬂipping
with the following properties:
1. O(log n) rounds, assuming one-way permutations.
2. O(1) rounds, assuming collision-free hashing, trapdoor permutations, and
dense cryptosystems secure against 2k -size circuits. The proof uses a non-blackbox simulation.
Theorem 1.2. For any poly-time function f , there exist (n−1)-secure protocols
for computing f with the following properties:
1. O(log n) rounds, assuming trapdoor permutations and dense cryptosystems.
2. O(1) rounds, assuming collision-free hashing, trapdoor permutations, and
dense cryptosystems secure against 2k -size circuits. The proof uses a non-blackbox simulation.
Note that information-theoretically secure protocols are impossible in our
setting: generic mpc protocols tolerating t ≥ n/2 imply the existence of twoparty oblivious transfer protocols, which require computational assumptions [29].
In Section 2 we specify our model and deﬁnition of mpc. Section 3 shows
how to achieve coin ﬂipping in logarithmic rounds; the constant-round protocol
is explained in Section 4. Section 5 shows how to achieve mpc for arbitrary
functionalities given a protocol for secure coin ﬂipping.

2

Deﬁnitions

Our deﬁnition of security for mpc is taken from the works of Canetti [8] and
Goldwasser and Lindell [27], which in turn follow a long line of work on deﬁning
security of protocols (e.g., [24,26,31,4,23]). More recently, a stronger deﬁnition
of universally composable (uc) computation has been proposed [9]; however, ucmpc is known to be impossible in the presence of a dishonest majority without
the prior assumption of a common random string [10]. Since we wish to avoid a
setup assumption of this form (indeed, we give explicit protocols for obtaining a
common random string), we do not use the uc framework directly. Nonetheless,
some of the protocols we use as building blocks were proven secure in the uc
framework, a fact which highlights the utility of such deﬁnitions.
2.1

Network Model

Formal deﬁnitions of security are given below, but we provide an overview of
our model and deﬁnition of security here. We consider a system of n parties
who interact in a synchronous manner. Each pair of parties is connected by
a perfect (authenticated, secret, unjammable) point-to-point channel, and we
also assume a broadcast channel to which all players have access. This channel
provides authenticity (i.e., that a given broadcast message originated from a

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

581

particular party) and also ensures that all parties receive the same message even
if the broadcasting party is dishonest. Messages sent on any of these channels
are delivered in the same round they are sent.
We assume a static adversary who corrupts up to n − 1 of the players before
execution of the protocol. The adversary is active, and corrupted parties may
behave in an arbitrary manner. Although the adversary may not delay or block
messages from honest parties, we do make the standard rushing assumption: i.e.,
the adversary sees all messages sent by honest players to corrupted players at a
given round i (including broadcast messages) before sending its own messages for
round i. Finally, we considercomputational security only and therefore restrict
our attention to adversaries running in probabilistic, polynomial time.
Although we assume a broadcast channel, our techniques yield protocols
with improved round complexity even when broadcast is not available. When
only point-to-point links are assumed, broadcast may be implemented using an
O(t)-round authenticated Byzantine agreement protocol (where t < n players
are dishonest) [18]; this protocol assumes a pre-existing public-key infrastructure (PKI) but in our context a PKI may be constructed “from scratch” in
O(t) rounds without aﬀecting overall security of the protocol [20] (this relies
on the fact that the adversary is allowed to abort when controlling a dishonest majority). Thus, when broadcast is unavailable our techniques reduce the
round complexity of known mpc protocols from O(tn) to O(t log n) using our
ﬁrst coin-ﬂipping protocol, or O(t) using our second coin-ﬂipping protocol. (For
a weaker version of mpc in which the honest players need not agree on whether
or not the protocol aborted [27], only a constant increase in round complexity is
necessary over the broadcast-based protocols given here [27].) The assumption
of a broadcast channel is therefore made for simplicity of exposition only.
2.2

Secure Multi-party Computation and Coin-Flipping

Following the outline of [8,27], we deﬁne an ideal model of computation and a
real model of computation, and require that any adversary in the real model can
be emulated (in the speciﬁc sense described below) by an adversary in the ideal
model. Our randomized function f to be computed by the n parties is denoted by
n
n
f : ({0, 1}∗ ) → ({0, 1}∗ ) where f = (f1 , . . . , fn ); that is, for a vector of inputs
x = (x1 , . . . , xn ), the output is a vector of values (f1 (x), . . . , fn (x)). Note that
we may also view f as a deterministic function on n + 1 inputs, where the ﬁnal
input represents the random coins used in evaluating f . In a given execution of
the protocol we assume that all inputs have length k, the security parameter.
Ideal model. In the ideal model there is a trusted party which computes the
desired functionality based on the inputs handed to it by the players. Let I ⊂ [n]
denote the set of players corrupted by the adversary. Then an execution in the
ideal model proceeds as follows [23] (this particular deﬁnition is called secure
computation with unanimous abort and no fairness in the taxonomy of [27]):
Inputs. Each party i has input xi . We represent the vector of inputs by x.

582

J. Katz, R. Ostrovsky, and A. Smith

Send inputs to trusted party. Honest parties always send their inputs to the
trusted party. Corrupted parties, on the other hand, may decide to abort or
to send modiﬁed values to the trusted party. Let x denote the vector of
inputs received by the trusted party.
Trusted party sends results to adversary. If x is a valid input (i.e.,
no parties aborted in the previous round), the trusted party generates
uniformly-distributed random coins, computes f (x ) = (y1 , . . . , yn ), and
sends yi to party Pi for all i ∈ I. In case a party aborted in the previous
round, the trusted party sends ⊥ to all parties.
Trusted party sends results to honest players. The adversary, depending
on its view up to this point, may decide to abort the protocol. In this case,
the trusted party sends ⊥ to the honest players. Otherwise, the trusted party
sends yi to party Pi for each i ∈
/ I.
Outputs. An honest party Pi always outputs the response yi it received from
the trusted party. Corrupted parties output ⊥, by convention. The adversary
outputs an arbitrary function of its entire view throughout the execution of
the protocol.
For a given adversary A, the execution of f in the ideal model on input x
(denoted idealf,A (x)) is deﬁned as the vector of the outputs of the parties along
with the output of the adversary resulting from the process above.
Real model. As described in Section 2.1, we assume a synchronous network
with rushing. Honest parties follow all instructions of the prescribed protocol,
while corrupted parties are coordinated by a single adversary and may behave
arbitrarily. At the conclusion of the protocol, honest parties compute their output
as prescribed by the protocol, while corrupted parties output ⊥. Without loss
of generality, we assume the adversary outputs exactly its entire view of the
execution of the protocol. For a given adversary B and protocol Π for computing
f , the execution of Π in the real model on input x (denoted realΠ,B (x)) is
deﬁned as the vector of outputs of the parties along with the output of the
adversary resulting from the above process.
Having deﬁned these models, we now deﬁne what is meant by a secure protocol. (Note: By probabilistic polynomial time (ppt), we mean a probabilistic
Turing machine with non-uniform advice whose running time is bounded by a
polynomial in the security parameter k. By expected probabilistic polynomial time
(eppt), we mean a Turing machine whose expected running time is bounded by
some polynomial, for all inputs.)
Deﬁnition 2.1 ([8]). Let f and Π be as above. Protocol Π is a t-secure protocol
for computing f if for every ppt adversary A corrupting at most t players in
the real model, there exists an eppt adversary S corrupting at most t players in
the ideal model, such that:
c

{idealf,S (x)}x∈({0,1}∗ )n ≡ {realΠ,A (x)}x∈({0,1}∗ )n .
As mentioned in the Introduction, our protocols for mpc proceed in the
following way: First, a common random string is generated using a coin-ﬂipping

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

583

protocol; next, the resulting string is used by the parties for the remainder of
their execution. Thus, using a simple composition result, we may construct our
protocols for (n−1)-secure mpc in two steps: (1) construct an (n−1)-secure coinﬂipping protocol (i.e., a protocol computing the functionality f (1m , . . . , 1m ) →
Um , where Um denotes the uniform distribution over {0, 1}m ); and (2) construct
an (n−1)-secure protocol for evaluating any functionality in the common random
string model (i.e., where all parties are ﬁrst given a uniformly-distributed string
of the appropriate length). Step (1) is discussed in Sections 3 and 4, and step
(2) and the composition theorem are discussed in Section 5.
Since our main contributions are our protocols for coin ﬂipping (achieving
(n − 1)-secure mpc in the common random string model is relatively straightforward), and since the deﬁnition of security simpliﬁes considerably in this case, we
present a stand-alone deﬁnition here. Note that the deﬁnition does not reduce
to the most simplistic notion of coin-ﬂipping in which we simply have a guarantee that the output of the protocol is indistinguishable from random. Instead,
it must be that a simulator can produce a view which is indistinguishable from
that of the real adversary, but where the outcome has been forced to be a particular random string provided by an outside party.1 Thus, we refer to the notion
as “simulatable coin ﬂipping” (even though this is precisely the same notion as
(n − 1)-secure evaluation of the coin-ﬂipping functionality).
Deﬁnition 2.2 (Simulatable Coin Flipping). A protocol Π is a simulatable
coin-ﬂipping protocol if it is an (n − 1)-secure protocol realizing the coin-ﬂipping
functionality. That is, for every ppt adversary A corrupting at most n−1 parties,
there is an eppt machine SA such that the outcomes of the following experiments
are computationally indistinguishable (as a function of k):
real(1k , 1m )
c, V iewA ← realΠ,A (1k , 1m )
Output (c, V iewA )

ideal(1k , 1m )
c ← {0, 1}m
c˜, V iew ← SA (c , 1k , 1m )
If c˜ ∈ {c , ⊥}, Output (˜
c, V iew)
Else Output fail

Here we parse the result of running protocol Π with adversary A (denoted
realΠ,A (1k , 1m )) as a pair (c, V iewA ) where c ∈ {0, 1}m ∪ {⊥} is the outcome
and V iewA is the adversary’s view of the computation.

3

Simulatable Coin-Flipping in O(log n) Rounds

In order to construct a simulatable coin-ﬂipping protocol, we will use a protocol
in which all pairs of players can prove statements (in zero-knowledge) to each
other. More precisely, suppose that each player Pi has a (publicly known) statement xi and each honest player also has private input wi (where wi is a witness
for xi ). We would like a protocol in which each player Pi proves that xi is true
(and that furthermore, Pi knows a witness); upon completion of this protocol, all
1

A related notion of simulatable bit-commitment was considered in [32].

584

J. Katz, R. Ostrovsky, and A. Smith

honest players should accept the result if and only if all players have successfully
completed their proofs.
The naive approach to solving this problem is to have every (ordered) pair
of players Pi , Pj simultaneously execute some constant-round zero-knowledge
proof of knowledge in which Pi proves knowledge of wi to Pj . However, such
an approach does not work (in general) due to the potential malleability of the
proof system. Namely, it is possible that an adversary controlling Pj could divert
a proof being given to Pj by Pi and hence prove a false statement (or, at least,
one for which Pj does not explicitly know a witness) to Pk . In particular, this is
always possible without some mechanism to prevent simple copying of proofs.
An alternate approach — one taken by previous work in the case of dishonest
majority [5,26] — is to have each pair of parties execute their proofs sequentially
over a total of n “stages” of the protocol. In stage i, player Pi proves knowledge
(in parallel) to all other players. This clearly avoids the malleability problem
discussed above, but results in an O(n)-round protocol.
In fact, the issue of proof scheduling was previously dealt with by Chor and
Rabin [13] in the context of mutually independent commitments. They proposed a
scheduling strategy which results in a round complexity of O(log n). The scheduling guarantees that at any given time, no player is playing both the prover and
the veriﬁer. Moreover, every player eventually proves to every other player. This
means that no matter what set of players is controlled by the adversary, he will
eventually have to prove all his statements to some honest player. We present
the Chor-Rabin (cr) scheduling strategy in Protocol 1.
To use cr scheduling in our context, we will require a zero-knowledge argument of knowledge (ZKAK) which satisﬁes two additional properties (informally):
Public veriﬁability: A third party who views a transcript of an execution of the
proof should be able to determine in polynomial time whether or not an
honest veriﬁer would have accepted.
Parallel composability: In our application, n/2 copies of the proof system will
be run synchronously and in parallel. We require the existence of: (1) a
simulator that can simulate the view of a dishonest veriﬁer executing n/2
copies of the proof system in parallel with independent provers; and (2) a
witness extractor that can extract a witness for each proof from a malicious
prover who is executing n/2 proofs in parallel with independent veriﬁers.
Although not all ZKAKs satisfy both the above properties [25], the 5-round
ZKAK of Feige and Shamir [19] (which only requires one-way functions) does.
Chor and Rabin [13] proved that when the {xi } are commitments and the
{wi } are the corresponding decommitments, their proof-scheduling technique
guarantees mutually independent commitments. However, to use the protocol
as a module in a larger protocol (i.e., as in a gmw-style compiler from the
honest-but-curious model to the malicious model [24]), a more sophisticated
notion of security is necessary. Speciﬁcally, it is tempting to try to prove that cr
scheduling realizes the ideal functionality of mutually independent proofs, that
is, the functionality in which all players hand their pair (xi , wi ) to a trusted
party who broadcasts only the list of players who supplied valid pairs.

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

585

Protocol 1 (Chor-Rabin proof scheduling).
Inputs: Player i holds (wi , x1 , ..., xn ).
(1)
(r)
For i = 1, .., n, let ci , ..., ci denote the r = log n -bit binary representation of i.
(t)

Let Bluet = i : ci

=0

(t)

and Redt = i : ci

=1 .

Let (P, V ) denote a constant-round publicly veriﬁable, parallel-composable ZKAK.
1. For t = 1, ..., r = log n , repeat: O(n2 ) pairs of proofs in parallel.
(a) ∀i ∈ Bluet , j ∈ Redt : Pi runs P (xi , wi ), Pj runs V .
(b) (After all proofs of (a) are ﬁnished)
∀i ∈ Bluet , j ∈ Redt : Pj runs P (xj , wj ), Pi runs V .
All messages are sent over the broadcast channel. If any proof between any pair of
parties fails, all players abort immediately.

It seems that the cr protocol does not satisfy this stronger property. Suppose
the players use a malleable zk proof system for which it is possible, given access
to a prover for either x1 or x2 , to prove knowledge of a witness for the statement
x1 ∨ x2 . (Artiﬁcial examples of such systems can be constructed.2 ) Consider
an execution of the protocol for which only P1 and P2 are honest. Player P3
is never proving to both P1 and P2 simultaneously—only ever to one or the
other. Moreover, when P3 is proving to P1 , then P2 is proving to some other
corrupted player, and similarly when P3 is proving to P2 . Thus, P3 could claim
the statement x1 ∨ x2 without ever knowing an actual witness, and successfully
pass all the proving stages.
Nevertheless, the cr scheduling protocol does satisfy very strong properties
when the adversary controls all but one player, and this is suﬃcient for our
purposes. The formulation of the property as it appears here is inspired by the
notion of witness-extended emulation, due to Lindell [30].
Lemma 3.1 (Chor-Rabin Scheduling). When Chor-Rabin scheduling is instantiated with any parallel-composable, publicly veriﬁable ZKAK we have:
Completeness: If all players are honest, and R(xi , wi ) = 1 for all i, then all
players will accept the output of the protocol.
Simulatability: For a machine A, let Ax,r denote the adversary with inputs x =
(x1 , ..., xn ) and random tape r.
2

Consider the standard zk protocol for Graph Isomorphism of (G0 , G1 ). Prover sends
H and then Veriﬁer asks for the isomorphism H ↔ Gb , for random b. The proof for
(G0 , G1 ) ∨ (G0 , G1 ) works as follows: Prover sends H, H , Veriﬁer replies with a bit
b, and Prover shows isomorphisms H ↔ Gb1 and H ↔ Gb2 such that b = b1 ⊕ b2 . A
cheating intermediary who has access to a prover for (G0 , G1 ) or (G0 , G1 ) can fake
a proof for (G0 , G1 ) ∨ (G0 , G1 ). A similar modiﬁcation of Blum’s Hamitonian Path
proof system also works.

586

J. Katz, R. Ostrovsky, and A. Smith

There is a simulator S with inputs 1k , x and oracle access to Ax,r and two
outputs: a protocol view V and a list of potential witnesses w = (w1 , ..., wn ).
For any ppt adversary A who controls all but one player Pi , S is eppt and:
1. When (∃wi s.t. R(xi , wi ) = 1), the simulator’s output is computationally
indistinguishable from the view of A in an interaction with the honest
c
Pi . For all x: V ≡ viewA,Pi (x, r).
2. When the simulated transcript is accepting, the simulator is almost certain to extract a witness for xj , for all j = i:
Pr[acceptPi (V ) and (∃j = i : R(xi , wi ) = 0)] < negl(k).
Proof. Completeness of the protocol follows directly from the completeness of
the ZKAK, and so we turn to simulatability. The proof follows the reasoning
of [13]. Without loss of generality, say the adversary controls all players except
P1 . From the perspective of P1 , the Chor-Rabin protocol is a sequence of 2 log n
stages, where each stage consists of n/2 parallel executions of the ZKAK. In log n
of these stages, P1 is acting as the prover and in log n stages P1 acts as a veriﬁer.
By parallel composability of the ZKAK, we immediately see that the simulator
can always simulate the view of the adversary for those stages when P1 acts as
a prover. By the same token, in those stages when P1 acts as a veriﬁer (and
assuming that all proofs given to P1 by other players are successful), P1 can
extract witnesses for n/2 of the {xi }i=1 . That P1 in fact extracts witnesses for
all the {xi }i=1 follows from the fact that every other player acts as a prover to
P1 at some point in the protocol. We can combine these observations to form a
simulator using the witness-extended emulation technique of Lindell [30].
3.1

From Scheduled Proofs to Simulatable Coin-Flipping

To use cr scheduling for simulatable coin-ﬂipping, we apply a technique due
to Lindell [30]. Suppose that we have a non-interactive, perfectly binding commitment scheme (these can be constructed based on one-way permutations, for
example). Players ﬁrst commit to individual random coins and prove knowledge
of the committed values. Next, they reveal the values (not the decommitment
strings) and prove correctness of their decommitments. We give the resulting
construction in Protocol 2. Note that primitives weaker than ZKAKs are suﬃcient: we may use strong witness-indistinguishable proofs of knowledge in the
ﬁrst phase, and zero-knowledge proofs (of membership) in the second phase.
However, using these would make the protocol and proofs more cumbersome.
Theorem 3.1. Protocol 2 is a simulatable coin-ﬂipping protocol.
Proof. (sketch) The simulator is given a value c and needs to simulate the view of
an adversary who corrupts n−1 players, while also ensuring that the ﬁnal output
of the protocol is c (we ignore for the present discussion the possibility of abort).
Assume without loss of generality that the adversary corrupts all players except
P1 . The simulator begins by following steps 1 and 2 exactly, and committing to a
random value r1 . In step 3, the simulator may extract witnesses {(rj , sj )}j=1 by

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

587

Protocol 2 (Simulatable coin ﬂipping). On input 1k , 1m :
1.
2.
3.
4.
5.
6.

∀i, Pi : ci ← Commit(ri ; si )
∀i, Pi sends ci
Invoke cr scheduling to show that ∀i, ∃(ri , si ) such that ci = Commit(ri ; si ).
∀i, Pi sends ri .
Invoke cr scheduling to show that ∀i, ∃si such that ci = Commit(ri ; si ).
Output c = n
i=1 ri , or ⊥ if any proofs failed.

All messages are sent over the broadcast channel.

Lemma 3.1 (in this case, the simulator does not even need to be able to simulate
the proofs of P1 since it in fact has the necessary witness).
n
At this point, the simulator knows {rj }j=1 . It sets r1 = c⊕ j=2 rj and sends
r1 in step 4. In step 5, the simulator can simulate (false) proofs that its commitment in step 1 was indeed a commitment to r1 ; this follows from Lemma 3.1
(in fact, here the simulator no longer needs to extract any witnesses). These
simulated proofs are computationally indistinguishable from “real” proofs, thus
ensuring that the entire simulated protocol is computationally indistinguishable
from an actual execution of the protocol.

4

Simulatable Coin Flipping in Constant Rounds

To obtain a constant-round coin-ﬂipping protocol, we introduce a simple notion
of parallel composability for two-party non-malleable coin-ﬂipping protocols, and
show that protocols satisfying this notion can be used to achieve multi-party
coin-ﬂipping. Although the recent two-party protocol of Barak [2] does not satisfy
our notion of non-malleability, we show how to extend it so that it does.
Our resulting coin-ﬂipping protocol is described in Protocol 3. As noted
above, it relies on a modiﬁcation of the coin-ﬂipping protocol of Barak [2] which is
described in Section 4.1 and is denoted by NMCF(1k , 1m ) for security parameter
k and coin-length m. The protocol also uses an adaptively secure, unboundeduse non-interactive zero-knowledge proof of knowledge (nizkpk) in Steps 4 and
5. De Santis and Persiano showed how to construct these based on dense cryptosystems (pkc) and trapdoor permutations [16].3 The use of n diﬀerent strings
to guarantee independence of non-interactive proofs is due to Gennaro [21].
The completeness of Protocol 3 follows trivially from the completeness of
the coin-ﬂipping protocol and the nizkpk proof system. To prove the security
of the protocol, we consider the eﬀect of a coin-ﬂipping protocol (A, B) in the
following scenario. The adversary, C, simultaneously plays man-in-the-middle
3

In fact, one needs only weaker primitives: a strong witness-indistinguishable proof of
knowledge in Step 4 and a zero-knowledge proof in Step 5. However, these distinctions
make the notation of the protocol more cumbersome.

588

J. Katz, R. Ostrovsky, and A. Smith

Protocol 3 (Constant-round simulatable coin ﬂipping).
Let R(c, (x, s)) denote the relation c = Commit(x; s), where Commit is a perfectly
binding, non-interactive commitment scheme. Suppose that for security parameter
k, the nizkpk system uses a crs of length = (k, m).
1. Run 2 n2 protocols in parallel. For each ordered pair (i, j) ∈ [n]×[n], i = j:
Run coin-tossing protocol NMCF(1k , 1n ) (see Lemma 4.1) to generate a string
(1)
(n)
of n coins which will be parsed as n strings σi,j , ..., σi,j ∈ {0, 1} .
m
2. Pi : xi ← {0, 1}
3. Pi sends ci = Commit(xi , si )
4. Pi sends, for j = 1, ..., n: nizkpkσ(i) of (xi , si ) such that R(ci , (xi , si )).
i,j

5. Pi sends xi and also, for j = 1, ...n: nizkpkσ(i) that there exists si such that
i,j

R(ci , (xi , si ))
6. Output n
i=1 xi , or ⊥ if any previous proofs or coin-ﬂipping protocols failed.
All messages are sent over the broadcast channel. Honest players abort immediately
if any nizkpk proofs fail.

A1 ←→
A2 ←→
..
..
.
.
An ←→

C

(Man in the
middle)

←→
←→
..
.
←→

B1
B2
..
.
Bn

Fig. 1. Parallel Composition of Non-Malleable Protocols

against with n pairs of copies of the protocol executed synchronously and in
parallel (cf. Figure 1). We call this an n-fold, parallel man-in-the-middle attack.
It is a restriction of the more robust versions of non-malleability deﬁned by
Dolev, Dwork and Naor [17], but it seems incomparable to that of Barak [2].
Let r1 , ..., rn be the outputs of the left-hand protocols, and r˜1 , ..., r˜n be the
outputs of the right-hand protocols. We clearly cannot prevent the adversary
from mounting a trivial relaying attack, in which she copies messages from one
or more protocols on the right to one or more protocols on the left. This allows the
adversary to force the outcomes of some of the protocols to be identical. Instead,
we require that the left-hand outputs r1 , ..., rn all be random and independent,
and that each of the right-hand outputs r˜i is either random and independent of
the others, or equal to one of the left-hand outputs rj .
Deﬁnition 4.1. A coin-ﬂipping protocol Π = (A, B) is non-malleable against
n-fold parallel composition if for any ppt algorithm C, there is an eppt algorithm Cˆ such that the following are computationally indistinguishable:

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

589

1. output(A,B,C),Π (1k ) where this denotes the 2n+1-tuple consisting of the 2n
outputs of A1 , ..., An , B1 , ..., Bn and the view of C, when executing an n-fold
parallel man-in-the-middle attack.
2. (ρ1 , ...ρn , ρ˜1 , ..., ρ˜n , τ ), where ﬁrst the strings ρ1 , ...ρn , σ1 , ...σn are selected
ˆ 1 , ...ρn , σ1 , ...σn ) consists of τ
uniformly at random, and the output of C(ρ
followed by a speciﬁcation, for each i, of which value to assign ρ˜i out of
{σi } ∪ {ρ1 , ..., ρn }.
It is not clear a priori that all non-malleable coin-ﬂipping schemes satisfy
this deﬁnition. In fact, it appears to be orthogonal to the deﬁnition of nonmalleability in [2]: on one hand, it requires synchronous (not concurrent) execution of the 2n protocol pairs, and so a protocol which satisﬁes it may be insecure
when any one of the executions is not synchronized. On the other hand, this
deﬁnition requires security when the adversary has access to several protocols.
In particular, if any of the building blocks of the coin-ﬂipping protocol are not
parallel-composable, then the resulting protocol may not satisfy the deﬁnition.
Lemma 4.1. The coin-ﬂipping protocol of [2] can be modiﬁed to satisfy Deﬁnition 4.1.
We present the modiﬁed protocol in the following section. However, we ﬁrst
show that we can use it to obtain a constant-round simulatable coin-ﬂipping
protocol.
Lemma 4.2. Protocol 3 is a simulatable coin-ﬂipping protocol.
Proof. (sketch) We begin by describing the algorithm used by the simulator, and
then show that the simulation satisﬁes Deﬁnition 2.2. In addition to the simulator
for the coin-ﬂipping protocol, we will use the extractor and simulator for the
nizkpk system and the languages we need. The two phases of the extractor
(generation and extraction) are denoted by Ext1 , Ext2 . Similarly, the simulator
is denoted by Sim1 and Sim2 .
On input c ∈ {0, 1}m , the simulator does the following:
– Pick an honest player at random (w.l.o.g. P1 ). Allow the adversary to control
the remaining honest players. That is, wrap the original adversary A in a
circuit A which makes the honest players follow the protocol. No special
simulation of these players is required.
– Pick 2(n − 1) strings ρ2 , ..., ρn , σ2 , ..., σn as follows. Recall that each string is
parsed as n segments, each of which is long enough to serve for nizkpk. Use
the nizkpk simulator to generate segment 1 of each string (independently),
(1)
(1)
i.e. ρi , σi ← Sim(1k ) for all i.
Use the nizkpk extractor to generate segments 2, .., n of each string, that is
(j)
(j)
ρi , σi ← Ext(1k ) for all i and for j = 2, ..., n.
The simulator keeps the side-information necessary for simulation and extraction with respect to each of these strings.
– (Step 1) Run the simulator Cˆ from (n − 1)-fold parallel composition on the
adversary, on inputs ρ2 , ..., ρn , σ2 , ..., σn . Note that here, P1 is playing the
roles of A1 , .., An−1 and B1 , ..., Bn−1 . Denote the outputs of the coin ﬂipping
protocol by σ1,j and σj,1 for j = 2, ..., n, as in Protocol 3.

590

J. Katz, R. Ostrovsky, and A. Smith

– (Steps 2, 3 and 4) Run these steps honestly: choose x1 ← {0, 1}m , pick coins
s1 , let c1 = Commit(x1 ; s1 ) and prove knowledge of x1 using nizkpk.
– Extract the values x2 , ..., xn from the proofs at Step 4 (this is possible since
the values used by other players were all generated by the extractor for the
n
nizkpk). Compute x = c ⊕ j=2 xj .
– (Step 5) Send x . For each j = 2, ..., n, use the simulator for the nizkpk to
(1)
fake proofs of “∃s such that R(c1 , (x , s ))” with respect to σ1,j .
– Either the protocol aborts, or all honest players output the string
n
x ⊕ j=2 xj = c.
The proof of the success of this simulation relies on several observations. First,
the strings output by the generators are pseudo-random, and so the behaviors
of the adversary and simulator are the same as if the strings were truly random.
By Lemma 4.1, the simulation of the NMCF protocols is indistinguishable from
a real execution, and the strings generated will, with overwhelming probability,
be from {ρ2 , ..., ρn , σ2 , ..., σn }.
Second, as observed by Barak [2], nizk proof of knowledge systems remain
secure even if the adversary may choose the crs from among a polynomial set
of random (or pseudo-random) strings. The adversary will not be able to make
his committed values (in Step 3) dependent on those of the honest players,
since that would violate the hiding property of the commitment or the zeroknowledge property of the proof system (in fact, all we need here is strong
witness indistinguishability). Moreover, the simulator will be able to extract the
committed values of the cheater since the adversary proves with respect to the
strings generated by the extractor. Finally, the simulator’s proof of consistency
of his decommitment will appear legitimate, again because of the zero-knowledge
property, and the adversary’s proofs will have to remain sound.
Remark 4.1. The use of nizkpk in the above protocol requires a dense pkc. We
expect that one can avoid this assumption by using (non-malleable) interactive
zk proofs of knowledge which rely on a public random string. We defer details
to the ﬁnal version.
4.1

Parallel Composability of Barak’s Coin-Flipping Protocol

The proof of Lemma 4.1 is similar to the proofs of Theorems 2.4 and 3.4 in [2].
There are two main modiﬁcations to Barak’s protocol which are necessary. First,
the two proof systems that are used as sub-protocols must themselves be parallel composable. This is trivial for the strong witness-indistinguishable proof of
knowledge. As for the zk universal argument, the original paper of Barak and
Goldreich [3] gives a construction which is concurrently composable and thus
parallel composable.
Second, the evasive set family that is used in the proof of security must resist
generation of an element by ppt ccircuits, even when n strings from the family
are given (here n is the number of players and not the security parameter). By

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

591

Protocol 4 (Parallel NM coin ﬂipping (NMCF(1k , 1m ))).
Steps L0.1.x, R0.1.x (Left commits to α): Left party chooses a hash function
h1 , and sends h1 and y1 = Com(h1 (0k )). It then proves using a PSWIUAK that
it knows a value α of length at most klog k such that y1 = Com(h1 (α)).
Steps L0.2.x, R0.2.x (Right commits to β): Left party chooses a hash function
h2 , and sends h2 and y2 = Com(h2 (0k )). It then proves using a PSWIUAK that
it knows a value β of length at most klog k such that y1 = Com(h1 (β)).
Step L1 (Commitment to r1 ): Left party selects r1 ← {0, 1}m and commits to
it using a perfectly binding commitment scheme. The commitment is denoted
α1 .
Steps L2.2–L2.4,R2.1–R2.3 (Prove knowledge of r1 ): The left party proves
to the right party its knowledge of the value r1 committed by α1 using a
P SW IP OK.
Step R3 (Send r2 ): The right party selects r2 ← {0, 1}m and sends it. Step
L4 (Send r) The left party sends r = r1 ⊕ r2 . (No decommitment string is
revealed).
Steps L5.1–5.9, R5.2–R5.10 (Prove that r = r1 ⊕ r2 ): The left party proves,
using a PZKUAK, that either r = r1 ⊕ r2 or r ∈ Rα β,k , where {R·,· } is an
n-evasive set family.

changing the union bound in the proof of existence of evasive set families ([2],
Theorem 3.2), it is possible to show the existence of sets which remain evasive
given n elements, provided that we increase the security parameter appropriately.
The remainder of this section contains the deﬁnitions necessary to state the
NMCF protocol (Protocol 4). The notation used in the protocol deﬁnition is
taken from [2] for consistency. A proof of security is deferred to the ﬁnal version. Note that here PZKUAK (resp. PSWIUAK) refers to a parallel composable
universal argument of knowledge which is also zero-knowledge (PZKUAK) or
witness-indistinguishable (PSWIUAK). These can be constructed based on trapdoor permutations and collision-free hash families secure against 2k -size circuits
[3]. The conditions on the set family {R·,· } in the protocol appear below.
Deﬁnition 4.2 (n-Evasive Set Family). Let n = n(k) = k c for some constant
c > 0. An ensemble of sets {Rα,k }α∈{0,1}∗ ,k∈IN , where Rα,k ∈ {0, 1}k is said to be
an n(k)-evasive set family if the following conditions hold with respect to some
negligible function µ(·):
Constructibility: For any k ∈ IN, and any string α ∈ {0, 1}∗ , the set Rα,k
3
can be constructed in time |α|2k . That is, there exists a TM MR such that
3
M (1k , 1n ) runs in time |α|2k and outputs all the elements of Rα,k .
Pseudorandomness: For all probabilistic 2O(k) -time Turing Machines M , and
for all α ∈ {0, 1}∗ , it holds that
Pr[r ← Rα,k : M (α, r) = 1] − Pr[r ← {0, 1}k : M (α, r) = 1] < µ(k).
n-Evasiveness: Given n elements of Rα,k , it is hard for algorithms with advice α
to ﬁnd an (n+1)-st element: for all probabilistic 2O(k) -time Turing Machines

592

J. Katz, R. Ostrovsky, and A. Smith

M , and for any r1 , ..., rn ∈ Rα,k ,
Pr[M (α, r1 , ..., rn ) ∈ Rα,k \ {r1 , ..., rn }] < µ(k).
Deﬁnition 4.3 (String Equivalence with respect to a prg G). Let G be
a prg from t bits to g(t) bits secure against algorithms which take time o(g(t)).
Let φ( ) be any integer function such that < φ( ) < 2 . Consider two strings
α, α ∈ {0, 1}∗ and let = |α| + |α |. The strings α, α are φ-equivalent with
respect to G if there exist φ( )-time Turing machines M and M which can each
be described in space log( ), and such that
min

Pr[s ← {0, 1}t : M (α; G(s)) = α ] ,
Pr[s ← {0, 1}t : M (α ; G(s)) = α]

>

1
φ( )

where the second input to M, M denotes a random tape, and t = g −1 (φ( )).
Lemma 4.3. Suppose that G is a pseudo-random generator from t bits to 2t
2/
bits. Let φ( ) = 2log ( ) . There exists an n-evasive set family for all n(k) ≤ k /2 ,
most , and are φwith the additional property that if α and α have length at √
equivalent with respect to G, then Rα,k = Rα ,k for all k > 2 log .
Proposition 4.1. Suppose that 2k -strong trapdoor permutations and hash families exist and that {Rα,k } is an n-evasive set family as in Lemma 4.3. Then
NMCF (Protocol 4) is non-malleable against n-fold parallel composition.

5

Multi-party Computation

In this section we show how to obtain mpc protocols for arbitrary functionalities
using any simulatable coin-ﬂipping protocol. Let a ﬁxed-round protocol be one
which always requires the same number of rounds in every execution; we only discuss ﬁxed-round protocols for poly-time computable functions f . Beaver, Micali
and Rogaway [6] (with further extensions in [33]) shows that:
Theorem 5.1 ([6,33]). Suppose that trapdoor permutations exist. For any
function f , there is an O(1)-round protocol for computing f which is (n − 1)secure against honest-but-curious adversaries.
For malicious adversaries, Canetti, et al. [11] construct mpc protocols in the
common random string (crs) model which are (n − 1)-secure against adaptive
adversaries (in fact, their protocols achieve the stronger notion of universal composability). Because their goal is security against adaptive adversaries, the round
complexity of their protocols is proportional to the depth of the circuit being
evaluated. Nonetheless, many of the tools they develop (such as uc commitment
and zero-knowledge proofs) run in constant rounds. The following result for the
case of static adversaries is not explicit in [11], but follows directly from their
work (we use the expression abortable mpc to emphasize that in our setting the
adversary may abort the protocol):

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

593

Theorem 5.2 ([11]). Given an r-round protocol for mpc of a function f
which is (n − 1)-secure against static, honest-but-curious adversaries, there is
an abortable mpc protocol for f with O(r) rounds which is (n − 1)-secure against
static, malicious adversaries in the common random string model, assuming the
existence of trapdoor permutations and dense pkc.4
Combining the two previous theorems, we obtain:
Corollary 5.1. Suppose that trapdoor permutations and dense pkc exist. For
any function f , there is an O(1)-round (abortable) protocol for computing f in
the crs model which is (n − 1)-secure against static, malicious adversaries.
The key to using simulatable coin-ﬂipping protocols in our setting — when
no setup assumptions are made and a crs is unavailable — is the following
composition result:
Proposition 5.1. Given a simulatable coin-ﬂipping protocol ρ, and an abortable
protocol π for computing f in the crs model which is (n − 1)-secure against
static, malicious adversaries, the natural composition of the two is a protocol for
computing f with no setup assumptions which is (n − 1)-secure against static,
malicious adversaries.
Canetti [8] proved a much more general composition result of this sort for the case
of non-abortable mpc protocols. In fact, however, his proof applies in our context
more or less directly. Since our particular composition result is considerably
simpler, we provide a proof sketch here.
Proof. (sketch) Let stateA denote the internal view of A at the end of the
round in which the coin-ﬂipping protocol ρ terminates (call this round r). We
may imagine the adversary A as the composition of two adversaries: A1 operates
for r rounds and produces output stateA . A2 takes as input stateA , operates for
the remainder of the protocol and produces the ﬁnal view viewA . We can now
invoke the security of the coin-ﬂipping protocol ρ to create a simulator S1 which
takes a string σ ∈ {0, 1}m as input and outputs variables σ , stateA such that
c
σ ∈ {σ, ⊥} (with overwhelming probability) and stateA ≡ stateA when σ is
indistinguishable from random.
We may now deﬁne an adversary A2 for the crs model as follows: upon
receiving σ from the trusted party, run S1 to produce σ , stateA . If σ = ⊥, then
broadcast “I abort” and halt. Otherwise, run A2 on input stateA to complete the
protocol. Note that an execution of A2 in the ideal model can be modiﬁed to yield
a view and protocol outputs which are indistinguishable from those generated by
A in the real model.5 Finally, we invoke the security of π to obtain a simulator
S2 for the ideal model which emulates the behavior of A2 . The output of the
simulator S2 can be similarly modiﬁed to yield outputs indistinguishable from
those of A in the real model.
4
5

As in Remark 4.1, one should be able to remove the assumption of a dense pkc.
The only diﬀerence is the “abort” message, which can simply be stripped from the
transcript.

594

J. Katz, R. Ostrovsky, and A. Smith

Our main result (Theorem 1.2) follows from Corollary 5.1, Proposition 5.1,
and the simulatable coin-ﬂipping protocols given in Sections 3 and 4.
Acknowledgments. We are very grateful for helpful discussions with Cynthia
Dwork, Shaﬁ Goldwasser, Yehuda Lindell, and Moni Naor, and also for the
comments from our anonymous referees. We also thank Boaz Barak for personal
communication clarifying the deﬁnitions and proofs of security in [2].

References
1. J. Bar-Ilan and D. Beaver. Non-cryptographic fault-tolerant computing in constant
number of rounds of interaction. In Eighth ACM Symposium on Principles of
Distributed Computing, pages 201–209, 1989.
2. B. Barak. Constant-round coin-tossing with a man in the middle. In 43rd IEEE
Symposium on the Foundations of Computer Science, 2002. References are to the
preliminary full version, available from the author’s web page.
3. B. Barak and O. Goldreich. Universal arguments of knowledge. In 17th IEEE
Conference on Computational Complexity, pages 194–203, 2002.
4. D. Beaver. Foundations of secure interactive computing. In Advances in Cryptology
– CRYPTO ’91, volume 576 of Lecture Notes in Computer Science, pages 377–391.
IACR, Springer-Verlag, Aug. 1991.
5. D. Beaver and S. Goldwasser. Multiparty computation with faulty majority. In
Advances in Cryptology – CRYPTO ’89, volume 435 of Lecture Notes in Computer
Science, pages 589–590. IACR, Springer-Verlag, Aug. 1989.
6. D. Beaver, S. Micali, and P. Rogaway. The round complexity of secure protocols.
In 22nd ACM Symposium on the Theory of Computing, pages 503–513, 1990.
7. M. Ben-Or, S. Goldwasser, and A. Wigderson. Completeness theorems for noncryptographic fault-tolerant distributed computation. In 20th ACM Symposium
on the Theory of Computing, pages 1–10, May 1988.
8. R. Canetti. Security and composition of multiparty cryptographic protocols. J.
Cryptology, 13(1):143–202, 2000.
9. R. Canetti. Universally composable security: A new paradigm for cryptographic
protocols. In 42nd IEEE Symposium on the Foundations of Computer Science,
pages 136–147, Las Vegas, Nevada, Oct. 2001. IEEE.
10. R. Canetti and M. Fischlin. Universally composable commitments. In Advances in
Cryptology – CRYPTO 2001, volume 2139 of Lecture Notes in Computer Science,
pages 19–40. IACR, Springer, 2001.
11. R. Canetti, Y. Lindell, R. Ostrovsky, and A. Sahai. Universally composable twoparty and multi-party secure computation. In 34th ACM Symposium on the Theory
of Computing, pages 494–503, Montr´eal, Qu´ebec, May 2002. ACM.
12. D. Chaum, C. Cr´epeau, and I. Damg˚
ard. Multiparty unconditionally secure protocols. In 20th ACM Symposium on the Theory of Computing, May 1988.
13. B. Chor and M. Rabin. Achieving independence in logarithmic number of rounds.
In 6th ACM Symposium on Principles of Distributed Computing, 1987.
14. R. Cleve. Limits on the security of coin ﬂips when half the processors are faulty.
In 18th ACM Symposium on the Theory of Computing, pages 364–369, 1986.
15. R. Cramer and I. Damg˚
ard. Secure distributed linear algebra in a constant number
of rounds. In Advances in Cryptology – CRYPTO 2001, volume 2139 of Lecture
Notes in Computer Science. IACR, Springer, 2001.

Round Eﬃciency of Multi-party Computation with a Dishonest Majority

595

16. A. De Santis and G. Persiano. Zero-knowledge proofs of knowledge without interaction. In 33rd IEEE Symposium on the Foundations of Computer Science, pages
427–436. IEEE, 1992.
17. D. Dolev, C. Dwork, and M. Naor. Nonmalleable cryptography. SIAM J. Computing, 30(2):391–437, 2000.
18. D. Dolev and H. Strong. Authenticated algorithms for byzantine agreement. SIAM
J. Computing, 12(4):656–666, 1983.
19. U. Feige and A. Shamir. Zero knowledge proofs of knowledge in two rounds. In
Advances in Cryptology – CRYPTO ’89, volume 435 of Lecture Notes in Computer
Science, pages 526–544. IACR, Springer-Verlag, Aug. 1989.
20. M. Fitzi, D. Gottesman, M. Hirt, T. Holenstein, and A. Smith. Detectable Byzantine agreement secure against faulty majorities. In 21st ACM Symposium on Principles of Distributed Computing, pages 118–126, 2002.
21. R. Gennaro. Achieving independence eﬃciently and securely. In ACM Symposium
on Principles of Distributed Computing, pages 130–136, 1995.
22. R. Gennaro, Y. Ishai, E. Kushilevitz, and T. Rabin. The round complexity of
veriﬁable secret sharing and secure multicast. In 33rd ACM Symposium on the
Theory of Computing, June 2001.
23. O. Goldreich. Secure multi-party computation. Electronic working draft, 2001.
24. O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game or a
completeness theorem for protocols with honest majority. In 19th ACM Symposium
on the Theory of Computing, pages 218–229. ACM, May 1987.
25. O. Goldreich and Y. Oren. Deﬁnitions and properties of zero-knowledge proof
systems. J. Cryptology, 7(1):1–32, 1994.
26. S. Goldwasser and L. A. Levin. Fair computation of general functions in presence
of immoral majority. In Advances in Cryptology – CRYPTO ’90, volume 537 of
Lecture Notes in Computer Science, pages 77–93. Springer-Verlag, Aug. 1990.
27. S. Goldwasser and Y. Lindell. Secure computation without a broadcast channel.
In 16th International Symposium on Distributed Computing (DISC), 2002.
28. Y. Ishai and E. Kushilevitz. Randomizing polynomials: A new representation with
applications to round-eﬃcient secure computation. In 41nd IEEE Symposium on
the Foundations of Computer Science, Redondo Beach, CA, Nov. 2000. IEEE.
29. J. Kilian, E. Kushilevitz, S. Micali, and R. Ostrovsky. Reducibility and completeness in private computations. SIAM J. Computing, 29(4), 2000.
30. Y. Lindell. Parallel coin-tossing and constant-round secure two-party computation.
In Advances in Cryptology – CRYPTO 2001, volume 2139 of Lecture Notes in
Computer Science, pages 171–189. IACR, Springer, 2001.
31. S. Micali and P. Rogaway. Secure computation. In Advances in Cryptology –
CRYPTO ’91, volume 576 of Lecture Notes in Computer Science, pages 392–404.
IACR, Springer-Verlag, Aug. 1991.
32. M. Naor, R. Ostrovsky, R. Venkatesan, and M. Yung. Perfect zero-knowledge
arguments for np using any one-way permutation. J. Cryptology, 11(2), 1998.
33. P. Rogaway. The Round Complexity of Secure Protocols. PhD thesis, MIT, 1991.
34. A. C.-C. Yao. How to generate and exchange secrets. In 27th IEEE Symposium
on the Foundations of Computer Science, pages 162–167, 1986.

