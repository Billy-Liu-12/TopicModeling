Privacy Preserving Data Mining Research:
Current Status and Key Issues
Xiaodan Wu1, Chao-Hsien Chu2, Yunfeng Wang1, Fengli Liu1, and Dianmin Yue1
1
School of Management, Hebei University of Technology, Tianjin 300130, China
xwu@hebut.edu.cn, ywang@hebut.edu.cn, liufengli312@163.com,
dyue@hebut.edu.cn
2
College of Information Sciences and Technology, The Pennsylvania State University, 301K
IST Building, University Park, PA 16802, USA
chu@ist.psu.edu

Abstract. Recent advances in the Internet, in data mining, and in security
technologies have gave rise to a new stream of research, known as privacy
preserving data mining (PPDM). PPDM technologies allow us to extract
relevant knowledge from a large amount of data, while hide sensitive data or
information from disclosure. Several research questions have often being asked:
(1) what kind of option available for privacy preserving? (2) Which method is
more popular? (3) how to measure the performance of these algorithms? And
(4) how effective of these algorithms in preserving privacy? To help answer
these questions, we conduct an extensive review of 29 recent references from
years 2000 to 2006 for analysis.
Keywords: Privacy preserving; data mining.

1 Introduction
Data mining is a well-known technique for automatically and intelligently extracting
information or knowledge from a large amount of data, which, however, can also
disclosure sensitive information about individuals compromising the individual’s
right to privacy. Moreover, data mining techniques can reveal critical information
about business transactions, compromising the free competition in a business setting
[1]. Therefore, privacy preserving data mining (PPDM) has becoming an increasingly
important field of study.
PPDM is a new era of research in data mining, where data mining algorithms are
analyzed for possible infringement in privacy. PPDM research usually takes one of
the three philosophical approaches: (1) data hiding, in which sensitive raw data like
identifiers, name, addresses, etc. were altered, blocked, or trimmed out from the
original database, in order for the users of the data not to be able to compromise
another person’s privacy; (2) rule hiding, in which sensitive knowledge extracted
from the data mining process be excluded for use, because confidential information
may be derived from the released knowledge; and (3) secure multiparty computation,
where distributed data are encrypted before released or shared for computations; thus,
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 762–772, 2007.
© Springer-Verlag Berlin Heidelberg 2007

Privacy Preserving Data Mining Research: Current Status and Key Issues

763

no party knows anything except its own inputs and the results. The ultimate goal of
PPDM is to develop efficient algorithms that allow one to extract relevant knowledge
from a large amount of data, while prevent sensitive data and information from
disclosure or inference.
PPDM is a fast growing research area. Given the number of different algorithms
have been developed over the past years, there is an emerging need of synthesizing
literature to understand the nature of problems, identify potential research issues,
standardize new research area, and evaluate the relative performance of different
approaches [1] [28].

2 Related Work
Several researchers have attempted to synthesize the literature. Kantarcioglu and
Clifton [7] suggested that adopting a common framework for discussing privacy
preservation will enable next generation data mining technology to make substantial
advances in alleviating privacy concerns. Verykios et al. [28] analyzed the state-ofthe-art, classified the proposed algorithms from five different dimensions: data
distribution, data modification, data mining algorithm, data or rule hiding, and privacy
preservation. They also suggested a set of metrics for assessing PPDM performance.
Bertino et al. [1] proposed a taxonomy for classifying existing PPDM algorithms.
They also developed a framework and based upon which to evaluate the relative
performance of selected heuristic-based hiding algorithms. In this paper, we propose
to consolidate and simplify the taxonomy brought by [1]. We have also attempted to
examine the relative performance of PPDM from individual component level instead
of the complete PPDM algorithms.

3 Current Status
We present a simplified classification scheme, adopted from early studies, to guide
the review process. The proposed taxonomy contains four levels (see Figure 1). This
scheme differs from existing studies in two ways: (1) we treat data modification
methods as part of privacy preserving techniques, and (2) we consider the purpose of
hiding as a key classifier and place it before data mining task/algorithm level. The
number appears below each category indicated its percentage of usage (popularity).
3.1 Data Distribution
The PPDM algorithms can be first divided into two major categories, centralized and
distributed data, based on the distribution of data. In a centralized database (C-DB)
environment, data are all stored in a single database; while, in a distributed database
(D-DB) environment, data are stored in different databases [3]-[6] [13]-[22] [27] [29]
[31]. Distributed data scenarios can be further classified into horizontal and vertical
data distributions. Horizontal distributions refer to the cases where different records
of the same data attributes are resided in different places [7] - [11] [26]; while in a
vertical data distribution, different attributes of the same record of data are resided in
different places [2] [23] [24] [25] [30] [33]. As can be seen, earlier research has been

764

X. Wu et al.

Fig. 1. Taxonomy of PPDM algorithms

predominately focused on dealing with privacy preservation in a centralized DB. The
difficulties of applying PPDM algorithms to a distributed DB can be attributed to:
first, the data owners have privacy concerns so they may not willing to release their
own data for others; second, even if they are willing to share data, the communication
cost between the sites is too expensive. However, in today’s global digital
environment, most data are often stored in different sites, so more attention and
research should be focused on distributed PPDM algorithms.
3.2 Hiding Purposes
The PPDM algorithms can be further classified into two types, data hiding and rule
hiding, according to the purposes of hiding. Data hiding refers to the cases where the
sensitive data from original database like identity, name, and address that can be
linked, directly or indirectly, to an individual person are hided. In contrast, in rule
hiding, we remove the sensitive knowledge (rule) derived from original database after
applying data mining algorithms. We summarize the related literature in Table 1.
Majority of the PPDM algorithms used data hiding techniques. This is especially true
in a distributed database environment, as the techniques can be used to prevent
individual information from being discovered by other parties in the joint
computational process. Please note that most PPDM algorithms hide sensitive patterns
by modifying data. Also, at present, the rule hiding techniques is only being adopted
by association rule mining for centralized DB. The reason for such a restriction is
mainly due to its ease of implementation.

Privacy Preserving Data Mining Research: Current Status and Key Issues

765

Table 1. Summary of the hiding purpose of PPDM
References
Centralized DB
Distributed DB
[3] [4] [5] [6] [17] [18] [20] [29]
[2] [7] [8] [9] 10] [11] [23] [24] [25]
Data hiding
[31]
[27] [30] [33]
Rule hiding [14] [15] [16] [19] [27] [21] [22]
None
Purpose

3.3 Data Mining Tasks/Algorithms
Currently, the PPDM algorithms are mainly used on the tasks of classification,
association rule and clustering. Association analysis involves the discovery of
associated rules, showing attribute value and conditions that occur frequently in a
given set of data. Classification is the process of finding a set of models (or functions)
that describe and distinguish data classes or concepts, for the purpose of being able to
use the model to predict the class of objects whose class label is unknown. Clustering
Analysis concerns the problem of decomposing or partitioning a data set (usually
multivariate) into groups so that the points in one group are similar to each other and
are as different as possible from the points in other groups. We summarize the
distribution of literature in Table 2. About 52% of the PPDM algorithms used
association rule method for mining data, followed by classification, and then
clustering. Compared with association rule mining, classification rule mining is more
complicated to perform. Also, unlike association rules mining, which deals with
existing data items, classification deals with attributes and its values. Moreover,
instead of associating links between attribute values, it also needs to classify the
attributes of each dataset.
Table 2. Summary of PPDM for data mining tasks
Data mining
References
techniques
Centralized DB
Classification
[3] [6] [13] [29]
Association Rules [4] [5] [14] [15] [16] [20] [21] [22] [27] [31]
Clustering
[17] [18]

Distributed DB
[2] [8] [10] [25] [30]
[7] [8] [25] [26]
[9] [11] [24]

3.4 Privacy Preservation Techniques
We can further divide PPDM algorithms according to privacy preservation techniques
used. Four techniques – sanitation, blocking, distort, and generalization -- have been
used to hide data items for a centralized data distribution. The idea behind data
sanitation is to remove or modify items in a database to reduce the support of some
frequently used itemsets such that sensitive patterns cannot be mined. The blocking
approach replaces certain attributes of the data with a question mark. In this regard,
the minimum support and confidence level will be altered into a minimum interval.
As long as the support and/or the confidence of a sensitive rule lie below the middle
in these two ranges, the confidentiality of data is expected to be protected. Also

766

X. Wu et al.

known as data perturbation or data randomization, data distort protects privacy for
individual data records through modification of its original data, in which the original
distribution of the data is reconstructed from the randomized data. These techniques
aim to design distortion methods after which the true value of any individual record is
difficult to ascertain, but “global” properties of the data remain largely unchanged.
Generalization transforms and replaces each record value with a corresponding
generalized value.
The privacy preservation technique used in a distributed database is mainly based
on cryptography techniques. SMC algorithms deal with computing any function on
any input, in a distributed network where each participant holds one of the inputs,
while ensuring that no more information is revealed to a participant in the
computation than can be inferred from that participant’s input and output. The
distribution of the literature is given in Table 3. Data distort is the most popular
method used in hiding data, followed by data sanitation and generalization. If one
wants to obtain data mining results from different data sources, then the only method
can be used is a cryptography technique. Since the parties who use SMC operators
cannot reveal anything from others except final results, it can have benefits of both
accuracy of data mining results and the privacy of the database.
Table 3. Summary for privacy preservation techniques
PP Techniques
Data Sanitation
Blocking
C-DB
Data Distort
Generalization
D-DB Cryptography Techniques

References
[14] [15] [16] [19] [22] [27]
[21]
[3] [4] [5] [6] [17] [18] [20] [31]
[13] [29]
[2] [7] [8] [9] [10] [11] [23] [24] [ 24] [26] [30] [33]

3.5 Evaluation Criteria
The metrics commonly used in early research are:
1. Efficiency, which concerns the ability of an algorithm to execute with good
performance in terms of all the resources implied by the algorithm; Performance is
assessed, as usually, in terms of computational costs [14] [15] [18] [19] [21] [27], and
in case of distributed algorithms, in terms of the communication costs incurred
during information exchanges [2] [7] [8] [9] [10] [11] [23] [24] [25] [27] [30] [33].
2. Effectiveness, which considers both the capability of hiding sensitive information
[3] [4] [5] [6] [13] [14] [15] [17] [18] [19] [20] [21] [22] [27] [29] [31] and
accuracy of the data mining results [3] [4] [5] [6] [13] [14] [4] [16] [17] [18] [19]
[20] [21] [27] [29] [31]. For example, the accuracy of data sanitation technique
may be measured in terms of hiding failure, that is, the portion of sensitive
information that is not hidden by the technique, and misses cost, that occurs when
some legitimate patterns are hidden by accident.
3. Scalability, closely related to computational cost, concerns the size of problem the
algorithm can solve within a reasonably acceptable timeframe. The higher the
computational cost, the less chance the algorithms be used for solving larger size of
problems.

Privacy Preserving Data Mining Research: Current Status and Key Issues

767

3.6 Performance Assessment
Assessing the relative performance of PPDM algorithms is a very difficult task, as it
is often the case that no single algorithm outperforms others on all possible criteria.
Also, for maximum flexibility, we rate the relative merit of individual module that
comprised by the PPDM algorithm. The rating is given in three different levels -high, medium, and low. We summarize the results in Table 4, and discuss the general
principles below.
Table 4. Relative performance of PPDM components
Elements
Computational Cost
Hiding Purpose:
Data Hiding
Low
Rule Hiding
High
Data Mining Tasks:
Classification
Low
Clustering
High
Association Rule
Low
Privacy Preserving Technique:
Sanitation
Medium
Distortion
Low
Blocking
Medium
Generalization
Low
Cryptography
High

Privacy Preserving

Accuracy of Mining

Scalability

Contingent
Contingent

Contingent
Contingent

High
Low

N/A
N/A
N/A

Contingent
Contingent
Contingent

High
Low
High

Medium
High
Low
High
High

Medium
Low
Medium
Medium
High

Low
High
Low
High
Low

In term of computational efficiency, rule hiding is less efficient than data hiding,
because one has to identify the items that contribute to the sensitive rule first and then
hide the rule. For the privacy requirement, we think hiding rule is more critical than
hiding data, because after the sensitive rules are found, more information is possible
to be inferred. This is not to say that rule hiding is more accurate than data hiding.
The selection of either hiding data or rule often depends on the goal of privacy
preserving (hiding purpose) and data distribution. For instance, we can only hide data
under a distributed database environment.
In general, clustering is more complex than classification (including association
rules) because it often requires using an unsupervised learning algorithm. The
algorithm used for association rule and classification can learn from known results,
thus, they are more efficient. However, the preserving power and accuracy are highly
dependent on hiding technique used or the algorithm used, not the data mining task.
Assessing the performance of traditional data mining algorithms is out of the scope of
this study.
The key idea behinds sanitization type of algorithms is to hide the set of frequent
patterns from containing highly sensitive knowledge. The complexity of this type of
algorithm is O(n1*NlogN), where n1 is the number of restrictive patterns and N the
number of transactions in the database [14]. Thus, comparing with other methods, the
computational cost of sanitation type of algorithm is medium. Study has shown that
the more sensitive patterns are hidden, the more legitimate patterns are missed, so it
also degrades the accuracy of data mining results. Moreover, the optimal sanitization

768

X. Wu et al.

is proved to be NP-hard in the context of association rule mining; therefore, it is
computationally intensive as compared with a data perturbation approach.
The inherent mechanism of blocking and sanitization is basically similar. The
former uses a ‘?’ notation to replace selected items to be protected, while the latter
deletes or modifies these items from viewing; thereby, their complexity are almost the
same. However, the privacy preserving capability of blocking is lower than
sanitization. Moreover, like sanitization, blocking technique is NP-hard. Therefore,
these two modification methods cannot be used to solve larger size of problems.
Most existing studies which used distortion method focus on maintaining the level
of privacy disclosure and knowledge discovery ability. It seems that efficiency and
computational cost are not the issues for distortion method. In general, data distortion
algorithms have good effectiveness in hiding data. However, these methods are not
without faults. First, the distorting approach only works if one does not need to
reconstruct the original data values. Thus, if the data mining task changed, new
algorithms need to be developed to reconstruct the distributions. Second, this
technique considers each attribute independently; as a result, when the number of
attributes became large, the accuracy of data mining results will degrade significantly.
Finally, there is a trade-off between accuracy of data mining results and data security
using distortion methods. These methods may not be suitable for mining data in
situations requiring both high accuracy and high security.
The generalization technique has been widely used in protecting individual privacy
with the k-anonymity model in the past; however, it is relatively new to the data
mining community. Since generalization has the advantage of not modifying the true
value of attributes, it may have higher accuracy of data mining result than data
distortion techniques. The complexity of this algorithm is O(k log k), where the
constant in the big-O is less than 4. Although the runtime of this algorithm is
exponential in k, its efficiency can be greatly enhanced as suggested by [12].
Cryptography-based SMC has the highest accuracy in data mining and good
privacy preservation capability as well; however, it has strict usages as it is only
applicable to a distributed data environment. Two models of SMC are available: semihonest model and malicious model. The semi-honest models assume each party
follows the protocol rules, but is free to later use what it sees during execution to
compromise security; while the malicious model assumes parties can arbitrarily
“cheat,” and such cheating will not compromise either security or the results. How to
prevent or detect malicious party in a computation process is an unsolved issue. Not
to mention that SMC has the burden of high communicational cost, when the number
of parties participated increased. Usually, the communicational cost increases at the
exponential speed when data size increases linearly. Also, different problems need
different protocols and the complexities vary naturally [30].

4 Key Issues
The following issues/directions were derived for future research. First, currently
several groups of researchers have devoted effort in studying PPDM from different
perspectives (e.g., statistics, database, data mining, knowledge discovery, and

Privacy Preserving Data Mining Research: Current Status and Key Issues

769

information security), but they tend to use different terminology to describe similar or
related practice. For instance, people have used data modification, data perturbation,
data sanitation, data hiding, and preprocessing as possible methods for preserving
privacy; however, all are in fact related to the use of some types of technique to modify
original data so that private data and knowledge remain private even after the mining
process. Lacking a common language for discussions will cause misunderstanding and
slow down the research breakthrough. Therefore, there is an emerging need of
standardizing the terminology and PPDM practice.
Second, although many machine learning methods have been used for
classification, clustering, and other data mining tasks (e.g., diagnose, prediction,
optimization), currently only the association rules method has been predominately
used. It would be interesting to see how to extend the current technique and practice
into other problem domains or data mining tasks. It may be also interesting in using
different mining algorithms, especially the nature-based intelligent technologies such
as genetic algorithms, neural networks, ant colony, and immune systems to mining
and preserving privacy. Furthermore, it is important to find the privacy preserving
technique that is independent of data mining task and algorithm so that after applying
privacy preserving technique a database can be released without being constrained to
the original task and mining algorithms.
Third, most prior PPDM algorithms were developed for use with data stored in a
centralized database. However, in today’s global digital environment, data is often
stored in different sites. With recent advances in information and communication
technologies, the distributed PPDM methodology may have a wider application,
especially in medical, health care, banking, military and supply chain scenarios. In
addition, current PPDM algorithms mainly focus on preserving tuples in the database.
Fundamental questions such as where does privacy may happen, what kind of data,
data attributes and data type need to preserve remain to be explored.
Fourth, data hiding techniques have been the dominated methods for protecting
privacy of individual information. However, those algorithms do not pay full attention
to data mining results, which may lead to sensitive rules leakages. While some
algorithms are designed for preserving the rule liking with sensitive information, it
may degrade the accuracy of other non-sensitive rules. Thus, further investigation,
focusing on combining data and rule hiding, may be beneficial, specifically, when
taking into account the interactive impact of sensitive and non-sensitive rules, the
dependence relationship of the sensitive rules and problem-domain knowledge.
Fifth, various data distortion algorithms have been designed and developed for
protecting privacy of individual information. However, those algorithms are usually
limited to specialized type of data like integer and float numerical value. Further
research could pay more attention to other types of data like character or hybrid type
of data.
Finally, a framework for evaluating selected association rule hiding algorithms has
been proposed by Bertino et al. [1]. Future research can consider testing the proposed
evaluation framework for other privacy preservation algorithms, such as data
distortion or cryptography methods.

770

X. Wu et al.

5 Conclusions
PPDM has recently emerged as a new field of study. A portfolio of algorithms has
been suggested for possible solutions. As a new comer, PPDM may offer a wide
application prospect but at the same time it also brings us many issues / problems to
be answered. In this study, we conduct a comprehensive survey of 29 prior studies to
find out the current status of PPDM development. We propose a simplified taxonomy
to help understand the problem and explore possible research issues. We also examine
the strengths and weaknesses of different privacy preserving techniques and
summarize general principles from early research to guide the selection of PPDM
algorithms. As part of future work, we plan to formally test a complete spectrum of
PPDM algorithms.

References
1. Bertino, E., Fovino, I., and Provenza, L.: A Framework for Evaluating Privacy Preserving
Data Mining Algorithms. Data Mining and Knowledge Discovery 11: 2 (September 2005)
121-154
2. Du, W., and Zhan, Z.: Building Decision Tree Classifier on Private Data. In: Proc. Of the
IEEE ICDM Workshop on Privacy, Security and Data Mining (PSDM’02), Maebashi City,
Japan ( Dec. 2002) 1-8
3. Du, W., and Zhan, Z.: Using Randomized Response Techniques for Privacy- Preserving
Data Mining. In: Proc. of the Ninth ACM SIGKDD Int. Conf. on Knowledge Discovery
and Data Mining, Washington, D.C. (Aug. 2003)
4. Evfimievski, A., Gehrke, J., and Srikant, R.: Limiting Privacy Breaches in Privacy
Preserving Data Mining. In: Proc. of the Twenty-second ACM SIGMODSIGACTSIGART Symposium on Principles of Database Systems, San Diego, California
(June 2003) 211-222
5. Evfimievski, A., Srikant, R., Agarwal, R., and Gehrke, J.: Privacy Preserving Mining of
Association Rules. In: Proc. of the 8th ACM SIGKDD Int. Conf. on Knowledge Discovery
in Databases and Data Mining (KDD’02), Edmonton, Alberta, Canada (July 2004) 217-228
6. Islam, M. Z., and Brankovic, L.: A Framework for Privacy Preserving Classification in
Data Mining. In: Proc. of the 2nd workshop on Australasian information security, Data
Mining and Web Intelligence, and Software Internationalization (AISW’04,
AWDM&WI’04, AWSI’04), Dunedin, New Zealand (Jan. 2004) 163-168
7. Kantarcioglu, M., and Clifton, C.: Privacy-preserving Distributed Mining of Association
Rules on Horizontally Partitioned Data. In: Proc. of ACM SIGMOD Workshop on
Research Issues in Data Mining and Knowledge Discovery (DMKD) (June 2002)
8. Kantarcıoglu, M., and Clifton, C.: Assuring Privacy when Big Brother is Watching. In:
Proc. of the 8th ACM SIGMOD Workshop on Research Issues in Data Mining and
Knowledge Discovery, Privacy & Security (2003) 88-93
9. Klusch, M., Lodi, S., and Moro, G.: Distributed Clustering Based on Sampling Local
Density Estimates. In: Proc. of the 18th Int. Joint Conf. on Artificial Intelligence
(IJCAI’03), Acapulco, Mexico (Aug. 2003) 485-490
10. Lindell, Y., and Pinkas, B.: Privacy Preserving Data Mining. In: Advances in Cryptology –
CRYPTO 2000, Springer-Verlag (Aug. 2000) 36–54

Privacy Preserving Data Mining Research: Current Status and Key Issues

771

11. Merugu, S., and Ghosh, J.: Privacy-Preserving Distributed Clustering Using Generative
Models. In: Proc. of the 3rd IEEE Int. Conf. on Data Mining (ICDM’03), Melbourne, FL,
USA (Nov. 2003) 211-219
12. Meyerson, A. and Williamsy, R.: On the Complexity of Optimal K-Anonymity. In:
Deutsch A, ed. Proc. of the 23rd ACM SIGACT- SIGMOD-SIGART Symposium on
Principles of Database Systems (PODS 2004). New York: ACM (2004) 223-228
13. Natwichai1, J., Li, X., and Orlowska, M.: Hiding Classification Rules for Data Sharing
With Privacy Preservation. In: Proc. of 7th International Conference on Data Warehousing
and Knowledge Discovery (DaWaK’05), Copenhagen, Denmark (Aug. 2005) 468-477
14. Oliveira, S. R. M., and Zaïane, O. R.: Privacy Preserving Frequent Itemset Mining. In:
Proc. of the IEEE international conference on Privacy, Security and Data Mining
(PSDM’02), Maebashi City, Japan (Dec. 2002) 43-54
15. Oliveira, S. R. M., and Zaïane, O. R.: Algorithms for Balancing Privacy and Knowledge
Discovery in Association Rule Mining. In: Pro. of the 7th Int. Database Engineering and
Applications Symposium (IDEAS'03), Hong Kong, China (July 2003) 54-65
16. Oliveira, S. R. M., and Zaïane, O. R.: Protecting Sensitive Knowledge By Data
Sanitization. In: Proc. of the 3rd IEEE Int. Conf. on Data Mining (ICDM’03), Melbourne,
Florida, USA (Nov. 2003b) 613–616
17. Oliveira and, S. R. M., and Zaïane, O. R.: Privacy Preserving Clustering by Data
Transformation. In: Pro. of the 18th Brazilian Symposium on Databases, Manaus,
Amazonas, Brazil (Oct. 2003c) 304-318
18. Oliveira, S. R. M., and Zaïane, O. R.: Achieving Privacy Preservation When Sharing Data
for Clustering. In: Pro. of the Int. Workshop on Secure Data Management in a Connected
World (SDM’04), In Conjunction with the 30th Very Large Data Base Conference
(VLDB’04), Toronto, Canada (Aug. 2004a) 76-82
19. Oliveira, S. R. M., Zaïane, O. R., and Saygin, Y.: Secure Association Rule Sharing. In:
PAKDD 2004b 74-85
20. Rizvi, J., and Haritsa, R.: Maintaining Data Privacy in Association Rule Mining. In: Pro.
of the 28th Very Large Data Base Conf. (VLDB'02), Hong Kong, China (Aug. 2002)
682-693
21. Saygin, Y., Verykios, V., and Clifton, C.: Using Un-knowns to Prevent Discovery of
Association Rules. ACM SIGMOD Record 30: 4 (2001)
22. Saygin, Y., Verykios, V., and Elmagarmid, A.: Privacy Preserving Association Rule
Mining. In: Proc. of 12th Int. Workshop on Research Issues in Data Engineering (RIDE)
(Feb. 2002).
23. Vaidya, J., and Clifton, C.: Privacy Preserving Association Rule Mining in Vertically
Partitioned Data. In: Proc. of the 8th ACM SIGKDD Int. Conf. on Knowledge Discovery
and Data Mining (2002) 639–644
24. Vaidya, J., and Clifton, C.: Privacy-Preserving K-Means Clustering over Vertically
Partitioned Data. In: Proc. of the 9th ACM SIGKDD Int. Conf. on Knowledge Discovery
in Data (KDD’03), Washington D.C., USA (Aug. 2003) 206-215
25. Vaidya, J., and Clifton, C.: Privacy-Preserving Decision Trees over Vertically Partitioned
Data. In: Proc. of the 19th Annual IFIP WG 11.3 Working Conf. on Data and Applications
Security (DAS’05), Storrs, CT, USA (Aug. 2005) 139-152
26. Veloso, A., Meira, Jr., W., Parthasarathy, S., and de Carvalho, M.: Efficient, Accurate and
Privacy-Preserving Data Mining for Frequent Itemsets in Distributed Databases. In: Proc.
of the 18th Brazilian Symposium on Databases, Manaus, Amazonas, Brazil (Oct. 2003)
281-292

772

X. Wu et al.

27. Verykios, S., Elmagarmid, K., Elisa, B., Saygin, Y. and Elena, D.: Association Rule
Hiding. IEEE Transactions on Knowledge and Data Engineering (2003)
28. Verykios, S., Bertino, E., Fovino, I., Provenza, L., Saygin, Y., and Theodoridis, Y.: Stateof-the-art in Privacy Preserving Data Mining. ACM SIGMOD Record 33: 1 (March 2004)
50-57
29. Wang, K., Yu, S., and Chakraborty, S.: Bottom-Up Generalization: A Data Mining
Solution to Privacy Protection. In: Proc. the 4th IEEE Int. Conf. on Data Mining
(ICDM’04), Brighton, United Kingdom (Nov. 2004) 249-256
30. Wenliang, D. and Zhijun, Z.: A Study of Several Practical Approach to Solve Secure
Multiparty Computation Problems. In: Pro. of the Int. Conf. on Computer Networks and
Mobile Computing (ICCNMC'03) (2003)
31. Xia, Y., Yang, Y., Chi, Y., and Muntz, R. R.: Mining Association Rules with Nonuniform
Privacy Concerns. Technical Report CSD-TR No. 040015, University of California
(March 2004)
32. Yang, Z., Zhong, S., Wright, R. N.: GrC. Privacy-Preserving Model Selection. In: Proc. of
the IEEE Int. Conf. on Granular Computing (2006)
33. Zhan, J. Z., Matwin, S., and Chang, L.: Privacy-preserving Collaborative Association Rule
Mining. DBSec (2005) 153-165

