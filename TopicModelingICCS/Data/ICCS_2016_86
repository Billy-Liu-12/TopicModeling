Procedia Computer Science
Volume 80, 2016, Pages 744–751
ICCS 2016. The International Conference on Computational
Science

Novel Heuristic Algorithm for Large-scale Complex
Optimization
Honghao Qiu1*and Yehong Liu2†
1

University of California, Berkeley, U.S.A
The University of Hong Kong, Hong Kong, China
jimyau@berkeley.edu, liuyh@hku.hk

2

Abstract
Research in finance and lots of other areas often encounter large-scale complex optimization problems
that are hard to find solutions. Classic heuristic algorithms often have limitations from the objectives
that they are trying to mimic, leading to drawbacks such as lacking memory-efficiency, trapping in
local optimal solutions, unstable performances, etc. This work considers imitating market competition
behavior (MCB) and develops a novel heuristic algorithm accordingly, which combines characteristics
of searching-efficiency, memory-efficiency, conflict avoidance, recombination, mutation and
elimination mechanism. In searching space, the MCB algorithm updates solution dots according to the
inertia and gravity rule, avoids falling into local optimal solution by introducing new enterprises while
ruling out of the old enterprises at each iteration, and recombines velocity vector to speed up solution
searching efficiency. This algorithm is capable of solving large-scale complex optimization model of
large input dimension, including Over Lapping Generation Models, and can be easily applied to solve
for other complex financial models. As a sample case, MCB algorithm is applied to a hybrid
investment optimization model on R&D, riskless and risky assets over a continuous time period.
Keywords: Large-Scale Complex Optimization, Heuristic Algorithm, Market Behavior, Investment Decision

1 Introduction
Complex modeling technique is widely used in applications of finance, operations research and
other areas. As the complexity of computation soars up, many intelligent heuristic algorithms are
developed to improve efficiency. J Holland came up with Genetic Algorithm in his work Adaptation
in Natural and Artificial Systems (J Holland, 1988) that can approach optimal solutions. Later in 1995,
Particle Swarm Optimization algorithm (RC Eberhart, 1995) was put forward as another heuristic
algorithm to achieve high computation efficiency by group’s mutual imitations. Intelligent algorithm
research was divided to deterministic and nondeterministic algorithms after 1990s, and Simulated
*
†

744

Created the first draft and algorithm part of this document
Created the financial case in this document

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.364

Novel Heuristic Algorithm for Large-scale Complex Optimization

Honghao Qiu and Yehong Liu

Annealing algorithm (WL Goffe, 1994) as a popular probability based nondeterministic algorithm
helped in solving problems in complex solution searching space. Later heuristic algorithms focuses on
solving specific problems, for example, the harmony search algorithm (ZW Geem, 2001) for traveling
salesman problem. More recent heuristic algorithms works on fundamental computer system control
such as assigning Internet files (R Kolisch, 2015) and system state prediction (L Dong, 2015).
However, the above works have their limitations respectively due to the restrictions of objects that
they are trying to imitate. Some intelligent algorithms like GA do not have the memory of past
searching history, while some other algorithms like PSO often stuck in local optimal solutions (JW
Zhuo, 2011). And some nondeterministic algorithms such as SA are not efficient and fast enough in
situations where the solution searching space is large and complex. If we apply Monte Carlo Method
in such situations aiming to speed up searching process, we lose stability of the searching results.
Recent works often try to combine these methods and create hybrid algorithms such as hybrid genetic
algorithm, while many of them are till restricted by the original objects that their algorithms are trying
to imitate.
This paper focuses on finding another imitation object to build a new intelligent algorithm that
could be capable of solving large-scale complex optimization problems with efficiency, stability and
accuracy. We find out the Market Competition Behavior is a object that have comprehensive favorable
characteristics to imitate in intelligent algorithm, and this algorithm can achieve efficiency, stability
and accuracy that we want in complex searching space while avoiding local optimal solutions. We
then use a novel investment decision case from financial engineering research to test and prove this
algorithm.

2 The Market Competition Behavior (MCB) Algorithm
2.1 The Idea
The objective of Market Competition Behavior is to make decisions within restrictions based on
past information over a series of time to develop optimal product of best return (in a certain industry),
which is very similar to the process of finding optimal solution in a complex system. Market players
compete under certain rules, steadily and effectively develop their products toward the optimal point.
Different market competition behaviors provide comprehensive characteristics for our intelligent
algorithm to imitate and aggregates to overcome past algorithms’ drawbacks.

2.2 Main Features for Imitation
1. Dispersion: As many players are competing in a market and constantly updating products
over time, we assume a dispersion of players in the market at the very beginning.
2. Identification: Identification can be categorized into individual identification and group
identification. If one player in the market develops a successful product, then very likely it
will capture some features leading to success in market and develop product with similar
features in the next release. This is individual identification. At the same time, other players
in this market will also notice and learn from those successful features and try to incorporate
those features into their next product release, which is group identification.
3. Memory: The historical best selling product of the firm and historical best selling product of
the market provides guidance for players in the market and allows them to develop better
product faster. In other words, they keep their memory of historical product release and never
produce products that are worse than before, which improves efficiency of developing toward
the best product.

745

Novel Heuristic Algorithm for Large-scale Complex Optimization

Honghao Qiu and Yehong Liu

4. Vector-Recombination: The directions (vectors) of product development can recombine with
each other across players in the market during competition. For example, one company may
find out some features that are attractive to customers while another company may find out
some other features, later it is likely that a company would try to combine features from both
sides in their product development, which is the effect of vector-recombination. This
improves the players’ possibility of finding optimal product.
5. Elimination and Renewal: Once in a while some competitors are ruled out from the market
due to bad performance, while some other new companies join the market trying to develop
some new-featured products. The market characteristics by nature improve the overall
performance of the players’ performance (through elimination) and prevent current players
from being stuck in local optimal solution instead of global optimal solution (through
renewal).
6. Conflict Avoidance: The players would not collapse into each other and develop same
products in market competition, which avoids repeated searching and unnecessary conflicts.

2.3 Model and Flowchart for Algorithm Development
In Market Competition Behavior (MCB) model each company is considered as a point in ,
dimensional searching space% -       ]-^( 	)/(
"*  C X [ 3  4    G \( 	   # !   
#(.--
##!#(	
*.--"(
The objective optimization function is & X [ 3  4    G \, which can be considered as return of
each company in specific time. Each company point memorize the historical best return point it has
found, which is local best point FI><F=@KL X [ F=3  F=4    F=G \(      !

BFI=<F=@KL X [ B=3  B=4    B=G \(
The update for the point set is subject to influences from three forces: 1) Inertia: the inertia from
past movement take into consideration by multiplying a inertia multiplier 0 for the velocity, we use
0 X 
; 2) Gravity force from local best: each time when one point is being updated, it tends to be
attracted by the historical best return it has found before, we call this local best gravity force F ; 3)
Gravity force from global best: for all the points (companies) in the searching space (market), they are
attracted by the historical best return point that has been ever found, and this force is denoted as B .
Both gravity forces are inversely proportional to the Euclidean distance between each point and the
historical best point, this feature allows points to quickly cluster to optimal point. Assume each point
has ‘mass’ of 1, the update rule can be deducted as follows:
H@M X IF? U H@M W$/
H@M X 0WIF? U "W$/
9

9S 59Q

X #F W[FI><F=@KL V IF? \ U #B W[BFI=<F=@KL V IF? \
"X X
G
3
Combining the above equations together, we get:
H@M X IF? U ]0WIF? U _#F W[FI><F=@KL V IF? \ U #B W[BFI=<F=@KL V IF? \`W$/^W$/.
Above is the position update trajectory function. Here $/ is the update interim ($/ X  as default
value), while multiplier #F and #B are the noise for gravity force, meaning other external factors that
may influence direction and distance for point (product) update such as confidence level, management
change or new information added in the market. #F and #B are set as Normal Random Numbers.
As for the restriction functions, the + constrains are '3   '4     'E  and the constraint set
is denoted as ]'^. For initialization and each update, all the new points added should satisfy ]'^,

746

Novel Heuristic Algorithm for Large-scale Complex Optimization

Honghao Qiu and Yehong Liu

otherwise it will be renewed until meeting this requirement. Especially, the allowable maximum
velocity G<N is 10% to 20% proportional to the size of searching space.
	!%!!%7
 * ! !     !      " !
 #   ( 	         
(
As for vector-recombination, each time we update the point set, its velocity as a vector will be the
recombination of new velocity of this point and the velocity of current global best point if it returns a
higher objective value than merely applying the its own new velocity. Basing on repeated simulation,
we find this feature improves searching efficiency by approximately 20%.
The simplified flowchart of MCB intelligent algorithm is shown below in Figure 1.
Start MCB Algorithm
Reinitialize to Satisfy Constraints

Random
om Init
Initialization

Record Current Position and Value
Update: Position
ion Tra
Trajectory Function

Satisfy Constraints?

Velocityy Reco
Recombination
Partial Elimination and Renewal

Max Iterations?
It

Position and Value for
fo Global Optimal
Figure 1: Flowchart of MCB Algorithm

747

Novel Heuristic Algorithm for Large-scale Complex Optimization

Honghao Qiu and Yehong Liu

3 Algorithm Application in Financial Investment Decision
3.1 Continuous Time R&D, Riskless and Risky Assets Hybrid
Investment Model
In this paper we consider a hybrid investment decision across R&D, riskless and risky assets over a
continuous time. Portfolio analysis with R&D project is a challenging work. On one hand, the value of
R&D project can be estimated in many different ways and so is full of uncertainty. On the other hand,
it needs to be considered together with risky and risk-free assets. Here we want to find out the best
asset allocation strategy for different targets from / X    that leads to optimal return. At each
time spot /, the allocable capital is: L  / X     2 as starting capital.
Assume , R&D projects to be considered. For R&D project, the market value (Economic Net
Present Value) of each project can be calculated by adding its Real Option Value (ROV) and Net
Present Value (NPV), which is:  X  U 
 We use B-S formula (F Black, 1973) to
calculate ROV for each R&D project respectively: DL X DL  $3 V D % 6JR

$3 X

:RT
8R

U [.A U

ORP
4

\[ V /\

1D  V /


 $4 X

:RT
8R

U [.A V

ORP
4

;6L

 $4 , !'

\[ V /\

1D  V /

X $3 V 1D  V /

DL is the */( R&D project’s NPV at time /, D is the capital investment (cost) for */( R&D project.
.A is the risk-free interest rate, 1D is the standard variation of */( R&D project’s market price. [
 \ is
the standard normal distribution function.
Assume there are - risky assets to be considered, investment in risky assets at time / is denoted as
L 
 0L X [03L  04L    0HL \; and L X [ 3L  4L    HL \; denotes investment weigh and expected
return rate on different assets at time /. Therefore, the overall expected return from / to / U  is:
L 0L ; L . Weighs should be non-negative (assume shorting is not allowed) and add up to 1 for each
time /	0L Z , % ; 0L X  % X    ; .
Investment in risk-free asset over / X    is:  X 3  4    ; 
 Thus, the return from
risk-free asset from / to / U  is: L .A , where .A is the risk-free return rate.
As for the investment decision for */( R&D project at time / we use binary indicator DL to
quantify decision (1 means investing while 0 means not investing). The overall R&D investment at
time / is: !L X G
D73 D DL 
 Since we only make investment decision once for each potential R&D
project, there is: ;L73 DL Y  * X   ,

The above investments on three targets are subjected to budget limit: L U !L U L Y L  L Z 
for each time /.
Available capital at time / is determined by: L X L63 U  L 0L ; L U  L .A V !L .
Through deduction we have: L X 2 U  LC73 C 0C ; C U LC73 C .A V LC73 !C . The objective
optimization function is the total available capital at exit time :
;

G

_[ ; U

;

G

DL DL U
L73 D73

DL DL \`
L73 D73

  %.A     )  %     $
%"
$!
(

748

Novel Heuristic Algorithm for Large-scale Complex Optimization

Honghao Qiu and Yehong Liu

0(/ 
This is a typical complex optimization model in financial investment: it is an overlapping
generation model with large input parameters, many constraints and high computation complexity.
Here we apply MCB intelligent algorithm to this model as a testing case.
In this model, we set investment periods  X number of risky assets and R&D projects - X
, X  lag length for VAR is 6, market variation is 0.1, risk-free interest rate at 0.08, cost for each
R&D project is =50, initial capital 2 X . Based on these parameters, we can randomly initiate
L  DL [\, and DL 

The MCB algorithm initialize 100 points upon initialization, each point’s C is a vector with the
length of , U  U - W X : the first ,W stands for binary variable , the next  stands for
investment in risky asset , and the last -W stands for weigh 0. The maximum velocity allowed for
this three parameters are set at 0.5, 100 and 0.3 respectively. Each time when we receive a new point’s
position C ,   0 is set, then we can take turns to calculate             Once all 
and  are calculated, we can put them into objective function and get the objective value. Each time
upon position update, the following 5 constraints are checked to see if satisfied:  Z   Z  & Z
2 2 Z     U ! U  Y  / 


0(0 	
According to 100 times’ MCB algorithm running output, the optimal investment return of 1000
initial capital after 10 periods is approximately 2420. The corresponding optimal investment strategy
is:
1) Invest the 4th R&D project at period 8, invest the 2nd R&D project at period 9, and invest the 1st,
rd
3 , and 5th R&D project at period 10;
2) Invest .---45/3-412.3--2/13//62.2  1/4  "   
.- &
0,	!" .-'
+-(.2%-(/3%-(.5%-(/3%-(.2,%+-(/-%-(.4%-(/1%-(.1%-(/2,%+-(/-%-(.-%-(/4%-(.4%-(/3,%
+-(//%-(/2%-(.1%-(0-%-(-6,%+-(0-%-(.4%-(/3%-(..%-(.3,%+-(/5%-(-5%-(-1%-(0-%-(0-,%
+-(/.%-(.6%-(.6%-(./%-(/6,%+-(/4%-(/0%-(.1%-(.6%-(.4,%+-(/3%-(/3%-(-3%-(/.%-(/.,%
+-(-1%-(/0%-(/3%-(.5%-(/6,(
Our MCB intelligent algorithm successfully solve for this complex optimization problem within 20
seconds, twice as effective as Simulated Annealing algorithm with similar optimal output. The starting
point (optimal value at 2360), is the optimal value that Monte Carlo algorithm can find, while the
MCB algorithm successfully find a higher optimal value at 2420, which is approximately 3% increase
of investment return. Also, Monte Carlo method is high unstable in terms of the optimal value that it
find in large-scale complex optimization model, while MCB algorithm almost always find the exact
global optimal solution at around 2420. Figure 2 shows an one-time running result of MCB algorithm,
as we can see, as iterations increase, the MCB algorithm steadily find better solution, and when it
finds out a local optimal solution around Iteration No.24, it successfully get rid of local optimal and
approaches the global optimal in the end.

749

Novel Heuristic Algorithm for Large-scale Complex Optimization

Honghao Qiu and Yehong Liu

Figure 2: Sample Outcome of Running MCB Algorithm on Financial Optimization Case

4 Conclusions
This paper develops a new intelligent algorithm that can cope with large-scale complex
optimization problems. By imitating market competition behavior, it embraces the strengths of current
heuristic algorithms such as efficiency, accuracy, and stability. On the other hands, it overcomes the
problems of finding local optimal solutions and lacking memory in searching process. In the financial
investment case, the test result proves its effectiveness. Further, we can cross-test MCB algorithm with
classic optimization algorithms and improve it by considering other competition forces in the market
such as substitutes. It can also be combined with other heuristic algorithms in different phases of
searching process to optimize speed and accuracy.

References
Ariadji, T., Haryadi, F., Rau, I. T., Aziz, P. A., & Rinaldy Dasilfa. (2014). A novel tool for designing
well placements by combination of modified genetic algorithm and artificial neural network.
Journal of Petroleum Science and Engineering [J], .
Beaujon, G. J. (2001). "Balancing and optimizing a portfolio of R&D projects.". Naval Research
Logistics (NRL) 48.1 , 18-40.
Black, F. a. (1973). "The pricing of options and corporate liabilities.". The journal of political
economy, 637-654.
Dong, L. e. (2015). "Predictive event-triggered control based on heuristic dynamic programming for
nonlinear continuous-time systems.". 2015 International Joint Conference on IEEE.
Eberhart, R. C. (1995). "A new optimizer using particle swarm theory.". Proceedings of the sixth
international symposium on micro machine and human science., Vol. 1.
Fang, Y. L. (2008). "A mixed R&D projects and securities portfolio selection model.". European
Journal of Operational Research 185.2, 700-715. .
Geem, Z. W. (2001). "A new heuristic optimization algorithm: harmony search." . Simulation 76.2,
60-68.

750

Novel Heuristic Algorithm for Large-scale Complex Optimization

Honghao Qiu and Yehong Liu

Goffe, W. L. (1994). "Global optimization of statistical functions with simulated annealing." . Journal
of Econometrics 60.1, 65-99.
Goldberg, D. E. (1988). "Genetic algorithms and machine learning.". Machine learning 3.2, 95-99.
Jinwu Zhuo, W. Y.-s. (2011). "Application of MATLAB in mathematical modeling [M].". Beijing:
Beijing University of Aeronautics and Astronautics Press 4.
Kirkpatrick, S. C. (1983). "Optimization by simulated annealing.". science 220.4598 , 671-680.
Niknam, T., & Amiri, B. (2009). An efficient hybrid approach based on PSO, ACO and k -means for
cluster analysis. Applied Soft Computing Journal , [J] .
Stummer, C. a. (2001). "Interactive R&D portfolio selection considering multiple objectives, project
interdependencies, and time: A three-phase approach.". Management of Engineering and
Technology, .
Taillard, E. (1990). "Some efficient heuristic methods for the flow shop sequencing problem." .
European journal of Operational research 47.1, 65-74.
Trelea, I. C. (2003). "The particle swarm optimization algorithm: convergence analysis and parameter
selection." . Information processing letters 85.6 , 317-325.

751

