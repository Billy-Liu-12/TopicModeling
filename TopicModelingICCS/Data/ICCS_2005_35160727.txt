The Dynamics of Computing Agent Systems
M. Smolka , P. Uhruski , R. Schaefer , and M. Grochowski
Institute of Computer Science, Jagiellonian University, Krak´
ow, Poland
{smolka, uhruski, schaefer, grochows}@ii.uj.edu.pl

Abstract. The paper presents the Multi Agent System (MAS) designed
for the large scale parallel computations. The special kind of diﬀusionbased scheduling enables to decompose and allocate the migrable computing agents basing only of the local information. The paper introduces
the formal model of the MAS under consideration in order to depict the
roles of agent behavior and the whole system dynamics. The optimal
scheduling problem for MAS as well as the way of its veriﬁcation was
presented in terms of such model. The brief report of the test results is
stressed in the section 6.

1

Motivation

The Multi-Agent System (MAS) governed by the local diﬀusion scheduling is a
reasonable alternative for the centrally governed distributed computing systems.
Although the idea of mobile task diﬀusion is well known since more then ten years
(see. e.g. [6]) we propose the policy that consists in on-demand task partitioning
and task remaping obtained by the dynamic agent creation and migration. It
was implemented and initially tested for the regularly and irregularly concurrent
computations (see [2, 1, 5, 7]). The brief report of the test results is stressed in the
section 6. The paper introduces the formal model of the MAS under consideration
in order to depict the roles of agent behavior and the whole system dynamics.
The optimal scheduling problem for MAS as well as the way of its veriﬁcation
was presented in terms of such model.

2

Formal Description of the Architecture

The MAS under consideration that allows the diﬀusion governed scheduling is
a collection of: a computational environment (MAS platform) and a computing
application composed of mobile agents called Smart Solid Agents (SSA). The
computational environment is a triple (N, BH , perf ), where:
N = {P1 , . . . , Pn } , where Pi is the Virtual Computation Node (VCN). Each
VCN can maintain more than one agent (the number of hardware processors
usage is not relevant in our assumptions).

This author has been supported by the State Committee for Scientiﬁc Research of
the Republic of Poland under research grants 2 P03A 003 25 and 7 T07A 027 26.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3516, pp. 727–734, 2005.
c Springer-Verlag Berlin Heidelberg 2005

728

M. Smolka et al.

BH is the connection topology BH = {N1 , . . . , Nn }, Ni ⊂ N is an immediate
neighborhood of Pi (including Pi as well).
perf = {perf1 , . . . , perfn }, perfi : R+ → R+ is a family of functions, which describes relative performance of all VCN with respect to the total memory
i
i
of all allocated agents. If Mtotal
on Pi is small, perfi turns
request Mtotal
back the constant value, which depends only on the CPU architecture. If
i
is larger, the perfi decreases due to the intensive swap utilization.
Mtotal
Each SSA is represented by the pair Ai = (Ti , Si ) where: Ti is the computational
task executed by agent, including all data required for computation, and Si
stands for the shell responsible for the agent’s logic. The index i stands for an
unambiguous agent identiﬁer.
Each task Ti has to denominate the current requirement for computational
power (Ei , Mi ) where: Ei is the task remaining time measured in units common
for all application tasks, and Mi is the RAM requirement in bytes. Another
important condition we imposed for the task is that it must allow pausing and
continuation of it’s computation. Pausing is needed for the hibernating task in
case of agent migration or partitioning, and continuation is needed to restore the
paused job. In particular it can be designed in such a way that it can work from
one checkpoint to the next one, and during this checkpoint operation, it saves
its present state. Moreover each task Ti can be partitioned into two subtasks
Ti → {Ti1 , Ti2 } such that Ei > Eij , Mi > Mij , j = 1, 2. The task partitioning
rule depends strongly on the computational problem to be solved (see [3]).
The state of the computing application is the triple (At , Gt , Scht ), t ∈ [0, +∞)
where:
At is the set of application agents, At = {Aξj }ξj ∈It , It is the set of indices of
agents active at the time t,
Gt is the tree representing agents partitioning at the time t. All agents cont
stitute the set of nodes ξ∈Θ Aξ , Θ = j=0 Ij , while Gt edges show the
partitioning history. All information on how to rebuilt Gt is spread among
all agents such that each of them knows only its neighbors in the tree.
{Scht }t∈[0,+∞) is the family of functions such that Scht : At → N is the current schedule of application agents among the MAS platform servers. The
function is represented by the sets ωj of agents’ indices allocated on each
Pj ∈ N. Each of ωj is locally stored and managed by Pj .
The shell Si communicates with both Ti and the local server Pj = Sch(Ai ). It
supports inter–task communication and queries task requirements for resources
as well as implements the necessary logic to perform scheduling. Each server
Pj ∈ N periodically asks all local agents (allocated on Pj ) for their requirements
and computes the local load concentration
Lj =

j
Etotal

j
perfj (Mtotal
)

j
=
where Etotal

i∈ωj

j
Ei and Mtotal
=

Mi
i∈ωj

(1)

The Dynamics of Computing Agent Systems

729

Then Pj communicates with neighboring servers and establishes
ζ
ζ
Lj = {(Lζ , Etotal
, Mtotal
, perfζ )} where ζ is such that Pζ ∈ Nj

(2)

as well as the set of node indices Qj such that
k ∈ Qj ⇐⇒ k = j, Pk ∈ Nj , Lj − Lk > 0

(3)

The current values of both Lj and Qj are available to the local agents.

3

Diﬀusion of the Smart Solid Agent

We introduce the binding energy Ei,j of the agent Ai allocated on VCN Pj
characterized by the following conditions: Ei,j is a descending function of Ei and
a nonascending function of Lj . One of the simplest form of the binding energy
utilized in computational tests (see section 6) is Eij = max{Emin , (α1 Ei +
α2 Lj )} where α1 , α2 are the proper scaling parameters and Emin stands for the
minimum binding energy assigned to each agent.
We assume that the agent Ai may dynamically evaluate its binding energy for
other nodes from the neighborhood Nj using the information contained in Lj .
The current value of the binding energy gradient is a vector deﬁned by:
∇ti,j = ((j, l), Ei,l − Ei,j ) where Pj = Sch(Ai ) and l ∈ Qj is such that
Ei,l − Ei,j = maxζ∈Qj {Ei,ζ − Ei,j }

(4)

An agent Ai allocated on Pj migrates to Pl indicated by ∇ti,j if the binding
energy Ei,l on the destination VCN exceeds the current Ei,j more than . The
threshold stands for the migration parameter.
In general Smart Solid Agent Ai = (Ti , Si ) currently allocated on Pj ∈ N can
perform the following actions:
(a-1)
(a-2)
(a-3)
(a-4)
(a-5)
(a-6)
(a-7)
(a-8)

Execute task Ti (solve and communicate with other agents).
Pause Ti .
Continue Ti .
Denominate own load requirements (Ei , Mi ).
Compute ∇ti,j and check the condition Ei,l − Ei,j > .
Partition Ti → {Ti1 , Ti2 }, create child agents {Aij = (Tij , Sij )}, j = 1, 2.
Migrate to Pl ∈ N, l = j.
Disappear.

These actions allow Ai to accomplish two goals:
(G-1) Perform computation of carried task by executing action (a-1) and then
perform action (a-8) when the task is done.
(G-2) Find a better execution environment. We suggest following the algorithm utilizing actions (a-2) - (a-8).

730

M. Smolka et al.

If Qj = ∅ then continue Ti
else { compute ∇ti,j ;
If Ei,l − Ei,j >
then { pause Ti ; migrate along the gradient ∇ti,j ; continue Ti }
else { Partition Ti → {Ti1 , Ti2 };
create {Aij = (Tij , Sij )}, j = 1, 2; // Gt gets modiﬁed
disappear }
}.
The overall SSA intention is to accomplish the goal (G-1) in the shortest possible
time. If the agent recognizes the local VCN resources as insuﬃcient, it tries to
accomplish the goal (G-2). On the other hand, Pj may force {Ai }, i ∈ ωj to
realize goal (G-2) when its performance is endangered.

4

The MAS Dynamics

The diﬀusion-based scheduling strategy has proven to be simple and eﬃcient
(cf. section 6) but it lacks a theoretical background allowing to determine if it
is optimal or quasi-optimal in any sense. In this section we shall try to state
a formal mathematic model for multi-agent computations. Consider for a while
that we are given a space of all possible agents and denote it by A. We shall
consider discrete-time evolution of a given MAS. Let us introduce the notion of
the vector weight of an agent which is the mapping w : N × A −→ R2+ whose
components are Ei and Mi as introduced earlier. Assume that we know how
the total weight of child agents after partition depends on their parent’s weight
before partition and that this dependency is componentwise, i.e. we know the
functions f 1 , f 2 : R+ → R+ such that in the case of partition A → {A1 , A2 } we
have
i
i
(A1 ) + wt+1
(A2 ) = f i (wti (A))
wt+1
for i = 1, 2. Such an assumption seems realistic, in simple cases f i can be even
the identity.
Next denote by W : N × N −→ R+ the total weight of all agents allocated on
a virtual node at any time, i.e.
Wt (P ) =

wt (A)
Scht (A)=P

(obviously we put 0 if no agent is maintained by P ). The main idea of introducing
such a notion is the need to ﬁnd a global quantity describing the state of the
system appropriately and allowing us to avoid considering the dynamics of a
single agent.
In the sequel we shall assume that the number of virtual nodes N = N
is fixed. Thus we can consider Wt as a nonnegative vector in R2N whose jj
and (N + j)-th component corresponds to
th component corresponds to Etotal

The Dynamics of Computing Agent Systems

731

j
Mtotal
. In fact we shall treat Wt as a stochastic (vector-valued) process. Now we
shall state the equations of evolution of Wt (i.e. state equations of our system).
Let Ft be a time-dependent stochastic nonnegative vector ﬁeld on R2N
+ describing
the dynamics of our system in ’established’ state, i.e. when there are neither
M
migrations nor partitions. Let uE
ij,t (Wt ), uij,t (Wt ) ∈ [0, 1] denote the proportions
of the weight components of agents migrating from node i to node j to the
corresponding components of the total weight of all agents at node i and let
M
uE
ii,t (Wt ), uii,t (Wt ) denote the proportions of the weight components of splitting
agents to the corresponding components of the total weight of all agents at node
i. Then the state equations have the form:
⎧
N
N
⎪
i
i
⎪
Wt+1
= Fti (1 − k=1 uE
⎪
ik,t (Wt ))Wt
⎪
i=1
⎪
⎪
⎪
N
⎪
(Wt )Wti − ( k=1 uE
(Wt ))Wti
+f 1 uE
⎪
ii,t
ik,t
⎪
⎪
j
⎨
+ j=i uE
ji,t (Wt )Wt
(5)
N
⎪
N
N +i
N +i
N +i
M
⎪
(1
−
W
=
F
u
(W
))W
⎪
t
t
t
t+1
k=1 ik,t
⎪
⎪
i=1
⎪
⎪
N
N +i
⎪
2
M
⎪
− ( k=1 uM
+f uii,t (Wt )Wt
(Wt ))WtN +i
⎪
ik,t
⎪
⎩
N +j
+ j=i uM
ji,t (Wt )Wt
N ×N
for i = 1, . . . , N . Note that u = (uE , uM ) where uE , uM : N × RN
+ −→ [0, 1]
is in fact a control of our system. From the nature of our problem it is easy to
see that any control strategy must satisfy the following conditions for any t ∈ N
and x ∈ RN
+
E
M
M
uE
ij,t (x) · uji,t (x) = 0, uij,t (x) · uji,t (x) = 0 for i = j,
N
N
E
M
for i = 1, . . . , N .
k=1 uik,t (x) ≤ 1,
k=1 uik,t (x) ≤ 1

(6)

The ﬁrst pair of equalities means that at a given time migrations between two
nodes may happen in only one direction. The remaining conditions mean that
the number of agents leaving a node must not exceed the number of agents
present at the node just before the migration.
The initial state of equation (5)
ˆ
W0 = W

(7)

usually has all except one components equal to 0 which means that a system
starts with one agent or a batch of agents placed on a single VCN but of course
in general we need not make such an assumption.

5

The Optimal Scheduling Problem

Now let us propose two examples of cost functionals which seem appropriate for
multi-agent computations. The ﬁrst is the expected total time of computations
N

ˆ ) = E(min{t ≥ 0 :
V (u; W
i=1

Wti = 0}),

(8)

732

M. Smolka et al.

The second takes into account the mean load balancing over time. It has the
following form
∞

N

ˆ ) = E(
V (u; W

(Lit − Lt )2 )

(9)

t=0 i=1
Wi

N

where Lit = perf (Wt N +i ) is the load concentration and Lt = N1 i=1 Lit is its mean
i
t
over all nodes. Let us introduce the following notation for the set of admissible
controls
2(N ×N )
| u satisﬁes conditions (6)}.
U = {u = (uE , uM ) : N × RN
+ → [0, 1]

Assume that V has either the form (8) or (9). Given an initial conﬁguration
ˆ our optimal scheduling problem is now to ﬁnd such control strategy u∗ ∈ U
W
that
ˆ ) = min{V (u; W
ˆ ) : u ∈ U, W is a solution of (5), (7)}.
(10)
V (u∗ ; W

6

Numerical Tests

This section presents performed experiments and discusses how they ﬁt presented analytical model. The results cover two major problem domains examined in course of our experiments: Mesh Generator (MG) and Hierarchic Genetic
Strategy (HGS). The presented tests are broadly described in [5, 7] while papers
[1, 2] contain the MAS implementation details. Computations were run in the
same physical environment with LAN of 30 to 50 PCs connected with 100MBit
network.
6.1

Mesh Generator

The MG is a CAD/CAE task implementation. Each agent is equipped with a
single part of the partitioned solid, for which the mesh has to be generated. The
application had the following execution path:
1. Create all the agents, equip each with the part of the solid to generate the
mesh for. The agent’s size varies from very small to large depending on the
solid partitioning and each piece shape - the more complex the shape is, the
bigger mesh is generated.
2. Agents are put on the MAS network and distribute freely using the encoded
diﬀusion rule. After a single agent ﬁnds satisfying executing environment it
starts computations.
3. Single solid piece meshes are send to the master application and joined together.
The MG implements evolution and migration cases of the system dynamics, so
the main points of results analysis was to check if the local, diﬀusion based
scheduling policy does not put too much overhead on the total execution time
and if the available resources were fully utilized from the very beginning - any
utilization ’holes’ would signal synchronization points or diﬀusion rule not performing local scheduling properly or being not eﬃcient.

The Dynamics of Computing Agent Systems

733

In short, we have formulated the following conclusions concerning the results:
– Diﬀusion based scheduling allows all agents to spread quickly among computers on the network.The time needed to allocate tasks is small in comparison
to the whole computation time.
– Available resources were utilized at 96%, the application used up to 32
agents.
– The load is perfectly balanced according to the given local diﬀusion law.
It is clear from these conclusions that the diﬀusion based, local scheduling policy is well suited for such regular problems. The results also conﬁrm that the
communication factor may be omitted for certain class of applications, since the
total communication overhead is minimal. Also the communication required for
the diﬀusion (examine a VCN node neighborhood and reevaluate the binding
energy for every agent) did not degrade the system eﬃciency.
6.2

HGS

The HGS [4] is a stochastic, hierarchical genetic algorithm optimizing a given
function on a deﬁned domain. The application produces agents dynamically
in the course of the runtime. A single HGS agent is a container, which starts
executing its internal populations as soon as it founds suitable computation
environment. The total amount of agents at the execution time may be diﬀerent
even for a particular input data. The algorithm execution path is the following:
1. Create single agent with the initial populations, agent migrates to ﬁnd suitable execution environment.
2. Agent starts computing and the amount of internal populations changes due
to the genetic evolution.
3. If during the computation agent’s internal populations amount grows beyond
a ﬁxed number, the agent is split and new one is created out of part of the
populations set.
The HGS agents perform all three elements of MAS dynamics: evolution, migration and partitioning. The communication overhead (performing agent’s migration requires agent’s to pass the initial populations) and dynamic scheduling
eﬃciency were tested within this experiment. On a basis of this experiment the
following conclusions concerning the diﬀusion scheduling were drawn:
– Diﬀusion based scheduling deals properly and eﬀectively with the dynamic
rescheduling of the computing units.
– The communication overhead is around 5% of total execution time with
application using up to 300 actively computing agents.
Therefore the ﬁnal conclusion may be stated that the diﬀusion based local
scheduling performs well in case of irregular stochastic problem with dynamic
amount of agents. It is very adaptive and local scheduling evaluation does not
signiﬁcantly decrease the solution’s eﬀectiveness.

734

M. Smolka et al.

In addition we have also tested the eﬀectiveness of the dynamic, diﬀusion
based scheduling versus centralized, greedy scheduling policy (a Round Robin
solution) utilizing low level network message passing mechanisms (Java RMI).
Please see [7] for detailed results, which showed that the dynamic scheduling
shows moderate speedup loses (up to 30% of total computation time), which
disappear when agent’s amount grows - in case of 300 agents, diﬀusion based
scheduling performs 10% better that Round Robin.

7

Conclusions and Further Research

The diﬀusion analogy as well as the MAS technology give way to an eﬀective
design of a local diﬀusion-based scheduling strategy for a distributed environment. Its eﬀectiveness is achieved by the low complexity of local scheduling rules
and the lack of intensive communication required by centralized schedulers. The
formal description introduced in sections 4 and 5 provides the discrete equation of evolution and the characterization of admissible controls as well as the
cost functional for computing MAS. Such considerations put our problem into
the solid framework of the stochastic optimal control theory which provides us
with tools such as Bellman-type principles allowing us to study the optimality
of control strategies as well as the MAS asymptotics.

References
1. Grochowski M., Schaefer R., Uhruski P.: An Agent-based Approach To a Hard
Computing System - Smart Solid. Proc. of the International Conference on Parallel Computing in Electrical Engineering (PARELEC 2002), 22-25 September 2002,
Warsaw, Poland. IEEE Computer Society Press 2002, pp. 253-258.
2. Uhruski P., Grochowski M., Schaefer R.: Multi-agent Computing System in a Heterogeneous Network. Proc. of the International Conference on Parallel Computing in
Electrical Engineering (PARELEC 2002), 22-25 September 2002, Warsaw, Poland.
IEEE Computer Society Press 2002, pp. 233-238.
3. Schaefer R., Flasi´
nski M., Toporkiewicz W.: Optimal Stochastic Scaling of CAE
Parallel Computations. Lecture Notes in Computer Intelligence, Vol. 1424, Springer
1998, pp.557-564.
4. Wierzba B., Semczuk A., Kolodziej J., Schaefer R.: Hierarchical Genetic Strategy
with real number encoding. Proc. of the 6th Conf. on Evolutionary Algorithms and
Global Optimization Lag´
ow Lubuski 2003, Wydawnictwa Politechniki Warszawskiej
2003, pp. 231-237.
5. Grochowski M., Schaefer R., Uhruski P.: Diﬀusion Based Scheduling in the AgentOriented Computing Systems. Lecture Notes in Computer Science, Vol. 3019,
Springer 2004, pp. 97-104.
6. Luque E., Ripoll A., Corts A., Margalef T.: A distributed diﬀusion method for dynamic load balancing on parallel computers. Proc. of EUROMICRO Workshop on
Parallel and Distributed Processing, San Remo, Italy, January 1995. IEEE CS Press.
7. Momot J., Kosacki K., Grochowski M., Uhruski P., Schaefer R.; Multi-Agent System
for Irregular Parallel Genetic Computations. Lecture Notes in Computer Science,
Vol. 3038, Springer 2004, pp. 623-630.

