The Measurement Architecture of the Virtual
Traﬃc Laboratory
A Design of a Study in a Data Driven Traﬃc Analysis
Arnoud Visser, Joost Zoetebier, Hakan Yakali, and Bob Hertzberger
Informatics Institute, University of Amsterdam
Abstract. In this paper we introduce the measurement architecuture
of an application for the Virtual Traﬃc Laboratory. We have seamlessly
integrated the analyses of aggregated information from simulation and
measurements in a Matlab environment in which one can concentrate
on ﬁnding the dependencies of the diﬀerent parameters, select subsets
in the measurements, and extrapolate the measurements via simulation.
Available aggregated information is directly displayed and new aggregate
information, produced in the background, is displayed as soon as it is
available.

1

Introduction

Our ability to regulate and manage the traﬃc on our road-infrastructure, essential for the economic welfare of a country, relies on an accurate understanding of
the dynamics of such system. Recent studies have shown very complex structures
in the traﬃc ﬂow [1]. This state is called the synchronized state, which has to be
distinguished from a free ﬂowing and congested state. The diﬃculty to understand the dynamics originates from the diﬃculty to relate the observed dynamics
in speed and density to the underlying dynamics of the drivers behaviors, and
the changes therein as function of the circumstances and driver motivation.
Simulations play an essential role in evaluating diﬀerent aspects of the dynamics of traﬃc systems. As in most application areas, the available computing
power is the determining factor with respect to the level of detail that can be
simulated [2] and, consequently, lack of it leads to more abstract models [3].
To be able to aﬀord more detailed situations, we looked how we could use the
resources provided by for instance Condor or the Grid.
Simulation and real world experimentation both generate huge amount of
data. Much of the eﬀort in the computer sciences groups is directed into giving scientists smooth access to storage and visualization resources; the so called
middle-ware on top of the grid-technology. Yet, for a scientist seamless integration of the information from simulated data and measurements is the most
important issue, the so called data-driven approach.
In this article we show our experience with building our Virtual Traﬃc Laboratory as a data driven experimentation environment. This experience can be
used as input for the future development of the Virtual Laboratory on other
application domains.
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3036, pp. 515–518, 2004.
c Springer-Verlag Berlin Heidelberg 2004

516

2

A. Visser et al.

Measurement Analysis Architecture

Traﬃc ﬂow on the Dutch highway A12 is investigated for a wide variety of
circumstances in the years 1999-2001. This location has the unique characteristic
that, although the ﬂow of traﬃc is high, traﬃc jams are very sporadically seen.
In this sense it is a unique measurement point to gather experimental facts to
understand the microscopic structures in synchronized traﬃc states [1], which
was not reported outside of Germany yet.
For the understanding the microscopic structures in synchronized traﬃc
states the relations between several aggregates of single vehicle measurements
have to be made. Important aggregate measurements are for instance average
speed, average ﬂow, headway distribution and speed diﬀerence distribution. The
dynamics of these one-minute aggregates over 5-10 minutes periods are important for a correct identiﬁcation of the state.
To facilitate the analysis of aggregate measurements over time we designed
the following architecture:
manual
validation

Sybase
database

Matisse
database

’DCP’

’A12’

Raw
measurements

Readin

traffic state
analysis

measurement
verification

Validated
measurements

Matisse
database

Matisse
database

’a12sim’

’a12meta’

CreateA12meta

Aggregated
measurements

AdsSim
Traffic Simulator

CreateStochasticModel

Simulated
traffic states

AnalyzeSimulation

Fig. 1. The measurement analysis architecture

Along the A12 there was a relational database from Sybase that collected
the measurements from two independent measurement systems. One system was
based on inductive loops in the road, the other on an optical system on a gantry
above the road. Although both were quality systems, some discrepancies occur
between measurements due to diﬀerent physical principles. Video recordings were
used to manually decide the ground truth when the measurements were not clear.
After this validation process, the measurements were converted to an object
oriented database from Matisse. This database was used to verify the quality
of the measurement systems themselves. While the manual validation process
was used to get the overall statistics of errors in the measurements, the object
oriented database was used to analyze the circumstances of the measurement
errors.
The validated measurements were used to generate the statistics that characterize the traﬃc ﬂow. Diﬀerent measurements-periods could be combined based

The Measurement Architecture of the Virtual Traﬃc Laboratory

517

on diﬀerent criteria. The right combination of criteria results in candidate traﬃc
ﬂow states. The statistics that are important to characterize the microscopic
structure of the traﬃc ﬂow require ﬁts of complex (non-Gaussian) probability
density functions. The statistics were stored as meta-data in a separate database.
An example of such analysis is given in ﬁgure 2, where the average speed is
given as a function of the ﬂow (as percentage of the maximum ﬂow) and the
fraction of lorries (as percentage of the number of passages).

(a) measured

(b) simulated

Fig. 2. The average speed as function of the ﬂow and the fraction heavy traﬃc

The average speed is indicated with a colorcode, red (top of the bar) indicates
high speeds, blue (bottom of the bar) indicates low speeds. Each point indicates
an aggregate over longer period (30-60 minutes), which are typically equivalent
with a few thousand passages.
Combinations of measurement-periods that showed the same patterns on
their aggregated traﬃc ﬂow measurements over time were candidate traﬃc ﬂow
states. These aggregated measurements could be translated into the parameters
of a microscopic traﬃc simulator, AdsSim [4], which is based on the microscopic
Mixic model [5].
The characteristics of the simulated data were aggregated in the same way
as the real data, and the resulting dynamics were compared to the original
dynamics, to see if the model was complete (see ﬁgure 2). As one can see, the
simulated points are more homogeneous spread over the spectrum because one
can generate a dependency grid. Yet, the results are less to be trusted when one
has to extrapolate far from actual measured parameter-combinations space.

3

Discussion

We have chosen this application, because of the complexity of both the measurement analysis and the traﬃc ﬂow model. For instance, the Mixic model has

518

A. Visser et al.

68 parameters in its traﬃc ﬂow model [5], and most parameters are described
as functions of single vehicle data such as lane, speed and headway. For AdsSim
this resulted in 585 variables that can be adjusted to a speciﬁc traﬃc condition.
Compare this with the 150 keywords in the standard application in molecular
dynamics in the UniCore environment [6].
To be able to calibrate such a model for a certain traﬃc state, one needs to be
able to select characteristic subsets in the bulk of measurements, and visualize
the dynamics of the aggregates in diﬀerent ways. It is no problem that it takes
some time to generate aggregates, as long as one is able to switch fast between
diagrams of parameters and their dependencies as soon as the aggregates are
ready. Storing the analysis results in a database solves this problem.

4

Conclusions

In this article we have described the architecture for combining data on measurements and simulation in our Traﬃc Laboratory. Analysis results are stored
in databases with aggregated meta-data. New aggregate data can be generated
by exploring a dependency by performing new analysis on sets selected on diﬀerent parameter-combinations in the background. This analysis can be performed
seamlessly on both real data and simulated data. New data can be automatically
displayed by adding monitors to the databases, where the scientist does not have
to worry that too rigorous ﬁltering will force him to do the aggregation again.

References
1. L. Neubert, et al., ”Single-vehicle data of highway traﬃc: A statistical analysis”,
Physical Review E, Vol. 60, No. 6, December 1999.
2. K. Nagel, M.Rickert, ”Dynamic traﬃc assignment on parallel computers in TRANSIMS”, in: Future Generation Computer Systems, vol. 17, 2001, pp.637-648.
3. A. Visser et al. ”An hierarchical view on modelling the reliability of a DSRC-link
for ETC applications”, IEEE Transactions on ITS, Vol. 3: No. 2, June 2002.
4. A. Visser et al. ”Calibration of a traﬃc generator for high-density traﬃc, using the
data collected during a road pricing project”, paper 4052 to the 9th World congress
on Intelligent Transport Systems, Chicago, Illinois, October 2002
5. C. Tamp´ere, C. ”A Random Traﬃc Generator for Microscopic Simulation”, Proceedings 78th TRB Annual Meeting, Jan. 1999, Washington DC, USA.
6. D.W. Erwin et al. ”UNICORE: A Grid Computing Environment”, in LNCS 2150,
p. 825-839, Springer-Verlag, 2001.

