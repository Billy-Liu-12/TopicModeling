Multiclass Credit Cardholders’ Behaviors
Classification Methods*
Gang Kou1, Yi Peng1,**, Yong Shi1, 2, and Zhengxin Chen1
1
College of Information Science & Technology,
University of Nebraska at Omaha, Omaha, NE 68182, USA
2
Chinese Academy of Sciences Research Center on Data Technology
& Knowledge Economy, Graduate University of the Chinese Academy of Sciences,
Beijing 100080, China
{gkou, ypeng, yshi, zchen}@mail.unomaha.edu

Abstract. In credit card portfolio management a major challenge is to classify
and predict credit cardholders’ behaviors in a reliable precision because
cardholders’ behaviors are rather dynamic in nature. Multiclass classification
refers to classify data objects into more than two classes. Many real-life
applications require multiclass classification. The purpose of this paper is to
compare three multiclass classification approaches: decision tree, Multiple
Criteria Mathematical Programming (MCMP), and Hierarchical Method for
Support Vector Machines (SVM). While MCMP considers all classes at once,
SVM was initially designed for binary classification. It is still an ongoing
research issue to extend SVM from two-class classification to multiclass
classification and many proposed approaches use hierarchical method. In this
paper, we focus on one common hierarchical method – one-against-all
classification. We compare the performance of See5, MCMP and SVM oneagainst-all approach using a real-life credit card dataset. Results show that
MCMP achieves better overall accuracies than See5 and one-against-all SVM.
Keywords: multi-group classification, decision tree, See5, Multiple criteria
mathematical programming (MCMP), one-against-all SVM.

1 Introduction
One of the major tasks in credit card portfolio management is to reliably predict credit
cardholders’ behaviors. This task has two impacts in credit management: (1) identify
potential bankrupt accounts and (2) develop appropriate policies for different
categories of credit card accounts. To appreciate the importance of bankrupt accounts
prediction, some statistics are helpful: There are about 1.2 billion credit cards in
circulation in US. The total credit card holders declared bankruptcy in 2003 are
1,625,208 which are almost twice as many as the number of 812,898 in 1993 (New
Generation Research 2004). The total credit card debt at the end of the first quarter
*

This work was supported in part by Key Project #70531040, #70472074, National Natural
Science Foundation of China; 973 Project #2004CB720103, Ministry of Science and
Technology, China and BHP Billion Co., Australia.
**
Corresponding author.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 485 – 492, 2006.
© Springer-Verlag Berlin Heidelberg 2006

486

G. Kou et al.

2002 is about $660 billion (Cardweb 2004). Bankrupt accounts caused creditors
millions of dollars lost each year. In response, credit card lenders have made great
effort to improve traditional statistical methods and recognized that more
sophisticated analytical tools are needed in this area. Development of appropriate
policies for various groups of credit card accounts also has a great impact on credit
card issuers’ profits. From the creditor’s standpoint, the desirable policies should help
to keep the profitable customers and minimize the defaults. It is meaningful to
conduct multiclass credit cardholders’ behaviors classification because it enables card
issuers to better manage credit card portfolio.
As one of the major data mining functionalities, classification has broad
applications such as credit card portfolio management, medical diagnosis, and fraud
detection. Based on historical information, classification builds classifiers to predict
categorical class labels for unknown data. Multiclass classification refers to classify
data objects into more than two classes.
Researchers have suggested various multiclass classification methods. Multiple
Criteria Mathematical Programming (MCMP), decision tree, and Hierarchical Method
for Support Vector Machines (SVM) are three of them. Decision tree induction is a
tree structure wherein leaves represent classifications and branches represent
conjunctions of features that lead to those classifications (Menzies and Hu, 2003).
The decision tree software we used in this paper is See5, a Windows95/NT decision
tree and rule induction product (RuleQuest 2004). Because See5 is well-known for its
high classification accuracy, it is included in this study as a benchmark. MCMP and
SVM are both based on mathematical programming and there is no comparison study
has been conducted to date. The purpose of this paper is to compare these multiclass
classification approaches. While MCMP considers all classes at once, SVM was
initially designed for binary classification. It is still an ongoing research issue to
extend SVM from two-class classification to multiclass classification and many
proposed approaches use hierarchical approach. In this paper, we focus on one
common hierarchical method – one-against-all classification. Decision tree induction
is a popular classification, so we won’t describe it here. For more information about
decision tree, please refer to Quinlan (1993).
This paper is structured as follows. The next section discusses the formulation of
multiple-group multiple criteria mathematical programming classification model. The
third section describes one-against-all SVM multiclass classification method. The
fourth section compares the performance of See5, MCMP, and one-against-all SVM
using a real-life credit card dataset. The last section concludes the paper.

2 Multi-group Multi-criteria Mathematical Programming Model
This section introduces a MCMP model for multiclass classification. The following
models represent this concept mathematically: Given an r-dimensional attribute

= (a1 ,..., ar ) , let Ai = ( Ai1 ,..., Air ) ∈ ℜ r be one of the sample records,
where i = 1,..., n ; n represents the total number of records in the dataset. Suppose k
groups, G1, G2, …, Gk, are predefined. Gi ∩ G j = Φ, i ≠ j ,1 ≤ i, j ≤ k and
vector a

Multiclass Credit Cardholders’ Behaviors Classification Methods

487

Ai ∈ {G1 ∪ G2 ∪ ... ∪ G k } , i = 1,..., n . A series of boundary scalars
b1<b2<…<bk-1, can be set to separate these k groups. The boundary bj is used to
separate Gj and Gj+1. Let X = ( x1 ,..., x r ) ∈ R be a vector of real number to be
determined. Thus, we can establish the following linear inequations (Fisher 1936):
T

r

A i X < b1, ∀ A i ∈ G1; (1)bj-1≤A i X< bj,∀ A i ∈ Gj; (2)A i X ≥ bk-1, ∀ A i ∈ Gk;
2≤ j ≤ k-1, 1≤ i ≤n.

(1)

In the classification problem, A i X is the score for the ith data record. If an element
Ai

∈ G j is misclassified into a group other than G j , then let α i , j be the distance

from A
from A

to bj, and AiX = bj +

i

i

let

α i , j −1

be the distance

∈ G j to bj-1, and AiX = bj-1 - α i , j −1 , 2 ≤ j ≤ k . Otherwise,

α i , j ,1 ≤ j ≤ k, 1 ≤ i ≤ n ,
k

can be represented as

equals to zero. Therefore, the total overlapping of data
n

∑∑ (α
j =1 i =1

into

α i, j , 1 ≤ j ≤ k − 1 and

i, j

) p . If an element Ai ∈ G j is correctly classified

G j , let ζ i , j be the distance from A

i

to bj, and AiX = bj -

ζ i, j

,

1 ≤ j ≤ k − 1 and let ζ i , j −1 be the distance from A i ∈ G j to bj-1, and AiX = bj-1 +

ζ i , j −1 , 2 ≤ j ≤ k .

Otherwise,

ζ i , j ,1 ≤ j ≤ k, 1 ≤ i ≤ n ,

objective is to maximize the distance

ζ i, j

p

b j − b j −1

and is to minimize the distance

2

equals to zero. Thus, the

from A i to boundary if A i ∈

− ζ i, j

p

G1 or Gk

from A i to the middle of two

adjunct boundaries bj-1 and bj if A i ∈ G j , 2 ≤ j ≤ k − 1 . So the distances of every
n

data to its class boundary or boundaries can be represented as

∑∑

j =1ork i =1
k −1 n

b j − b j −1

j = 2 i =1

2

∑∑

− ζ i, j

ζ i, j

p

-

. As a result, the single-criterion mathematical

p

programming model can be set up as:
k

（ Model

1） Minimize wα

n

∑∑
j =1 i =1

k −1 n

b j − b j −1

j = 2 i =1

2

∑∑

S. T.: AiX = bj +

− ζ i, j

p

α i, j

n

p

- wζ

(

∑ ∑

j =1orj = k i =1

ζ i, j

p

-

)

α i, j - ζ i, j , 1 ≤ j ≤ k − 1

(2)

488

G. Kou et al.

AiX = bj-1 -

ζ i, j ≤ bj

- bj-1 , 2 ≤

α i , j −1 + ζ i , j −1 , 2 ≤ j ≤ k

(3)

j ≤ k (a) ζ i, j ≤ bj+1 - bj , 1 ≤ j ≤ k − 1 (b)

α i, j

where Ai, i = 1, …, n are given, X and bj are unrestricted, and

ζ i , j ≥ 0,1 ≤ i ≤ n. .(a)

,

and (b) are defined as such because the distances from any

correctly classified data (A i ∈ G j , 2 ≤ j ≤ k − 1 ) to two adjunct boundaries bj-1 and
bj must be less than bj - bj-1 . Let p = 2, then objective function in Model 1 can now be
a quadratic objective and we have:
k

2） Minimize

(Model

wα

j =1 i =1

k −1 n

∑∑[(ζ
j = 2 i =1

i, j

n

n

∑∑ (α

i, j

)2 -

wζ

(

) 2 − (b j − b j −1 )ζ i , j ] )

∑ ∑ (ζ

j =1orj = k i =1

i, j

)2 (4)

Subject to: (4), (5), (c) and (d)

3 SVM One-Against-All Multiclass Classification
Statistical Learning Theory was proposed by Vapnik and Chervonenkis in the 1960s.
Support Vector Machine (SVM) is one of the Kernel Machine based Statistical
Learning Methods that can be applied on various types of data and can detect the
internal relations among the data objectives. Given a set of data, one can define the
kernel matrix to construct SVM and compute an optimal hyperplane in the feature
space which is induced by a kernel (Vapnik, 1995). There exist different multi-class
training strategies for SVM such as one-against-all classification, one-against-one
(pairwise) classification, and Error correcting output codes (ECOC).
SVM-light (Joachims 2004) is a well known software package for support vector
machine binary classification. It is not designed to perform multiclass classification.
We apply SVM-light to two-group classifications, then implement a one-against-all
procedure for a four-class classification. Suppose the four groups are A, B, C and D.
The four-class one-against-all procedure is: ABCD⇒ A⎪B+C+D ⇒ A⎪B⎪C+D ⇒
A⎪B⎪C⎪D. Table 1 shows the classification results and is displayed in the format of
confusion matrices, which pinpoint classification accuracies. Table 2 gives an
analysis of classification accuracies and false alarm rates (the percentage of
misclassified records to all records which are classified to a group). The assumption
of one-against-all procedure is described as following:
The classification accuracy is stable. The classification accuracy of the forecasting
dataset is equal to the classification accuracy of the testing dataset as well as the
classification accuracy of the training dataset. The following symbols are used in this
section.
Nx Number of records in group x
Nxyz Number of records in group x, y and z

Multiclass Credit Cardholders’ Behaviors Classification Methods

489

4 Credit Cardholders’ Behaviors Classification
The model proposed can be used in many fields, such as general bioinformatics,
antibody and antigen, credit fraud detection, network security, text mining, etc. This
research will focus on credit card classification. The real-life credit card dataset used
in this paper is come from a US bank. It contains 6000 records and 7 variables. The
variables are Interest charge, Interest charge as percent of credit line, Number of
months since last payment, Credit line, Average payment of revolving accounts, Last
balance to payment ratio, and Average OBT revolving accounts. This dataset has been
used as a classic working dataset for various data analyses to support the bank’s
business intelligence. We define four classes for this dataset using a label variable:
The Number of Over-limits. The four classes are: Bankrupt charge-off accounts
(Number of Over-Limits≥ 12), Non-bankrupt charge-off accounts (7 ≤Number of
Over-Limits ≤ 11), Delinquent accounts (2 ≤ Number of Over-Limits ≤ 6), and
Current accounts (0 ≤ Number of Over-Limits ≤ 2). Bankrupt charge-off accounts are
accounts that have been written off by credit card issuers because of cardholders’
bankrupt claims. Non-bankrupt charge-off accounts are accounts that have been
written off by credit card issuers due to reasons other than bankrupt claims. The
charge-off policy may vary among authorized institutions. Delinquent accounts are
accounts that haven’t paid the minimum balances for more than 90 days. Current
accounts are accounts that have paid the minimum balances or have not balances. For
decision tree method, we use See5.0. MCMP is solved by LINGO 8.0, a software tool
for solving nonlinear models (LINDO Systems Inc.). SVM one-against-all is
implemented using SVM-light version 6.01 (Joachims 2004), a well-known SVM
software.
Table 1. A example of one-against-all 4-classes classification results

1st step
Classified as Group A
Classified as Group
B,C,D
2nd step
Classified as Group B

Classified
C,D

as

Group

A
a

B+C+D

Na − a

bcd

B
b

C+D

bcd
× Nb − b
N bcd

N bcd − bcd

bcd
× N cd − cd
N bcd
cd

3rd step
Classified as Group C

C
c

D

Classified as Group D

bcd
cd
×
× Nc − c
bcd
N bcd
× N cd
N bcd

d

bcd
cd
×
× Nd − d
bcd
N bcd
× N cd
N bcd

490

G. Kou et al.

The four-group classification results of See5, MCMP, and SVM-light on the
credit card data are summarized in Table 3, 4, and 5, respectively. In addition, we
compute Type I and II error rates. Type I error is defined as the rate of records that
are misclassified as Current to records that are classified as Current. Type II error is
defined as the rate of records that are actually Current but are misclassified as the
other three classes (Bankrupt charge-off, Non-bankrupt charge-off, and Delinquent)
to records that are classified as the other three classes. Since misclassified Current
accounts contribute to huge lost in credit card business and thus creditors are more
concern about Type I error than Type II error. From the confusion matrices in
Table 3, 4, and 5, we observe that (1) MCMP achieves the lowest test Type I error
rate: 1.65%. SVM-light has the second lowest test Type I error rate: 1.7%. See5 has
the highest test Type I error rate: 2.2%; (2) Among the three classification
methods, MCMP has the best test classification accuracies for Delinquent, Chargeoff, and Bankrupt classes. See5 has the best test classification accuracy for Current
class.
Table 2. Accuracy and False Alarm Rate analysis of 4-classes classification results

Accurac
y
A

B

a
Na
b
Nb

C

c
Nc

D

d
Nd

False Alarm Rate

N bcd − bcd
a + N bcd − bcd
Na − a
bcd
× N cd − cd +
×b
N bcd
bcd + N a − a
bcd
× N cd − cd + b
N bcd
bcd
× Nb − b
Na − a
Nbcd
cd
bcd
cd
×c +
×
×
× Nd − d +
bcd
bcd
bcd + Na − a
Nbcd bcd
cd +
cd +
× Nb − b
×N
× Ncd
Nbcd
Nbcd
Nbcd
bcd
cd
×
× Nd − d + c
bcd
Nbcd
× Ncd
Nbcd

bcd
× Nb −b
Nbcd
Na −a
bcd
cd
cd
×
× Nc −c +
×d +
×
bcd
bcd
Nbcd bcd × N
+
−
bcd
N
a
a
× Nb −b
× Nb
cd+
cd +
cd
Nbcd
Nbcd
Nbcd
bcd
cd
×
× Nc −c + d
Nbcd bcd
× Ncd
Nbcd

Multiclass Credit Cardholders’ Behaviors Classification Methods
Table 3. See5 Credit Card Classification Results

Evaluation on training data (280 cases):
(1)
(2)
(3) (4) <-classified as
66
3
0
1
(1): Current
6
35
27
2
(2): Delinquent
1
5
56
8
(3): Charge-off
0
6
37
27
(4): Bankrupt
Evaluation on test data (5720 cases):
(1)
(2)
(3) (4) <-classified as
3830 609 455 87
(1): Current
83
182 289 48 (2): Delinquent
3
16
83
24 (3): Charge-off
0
1
7
3
(4): Bankrupt

Accuracy

Error Rate

94.29%
50.00%
80.00%
38.57%

Type I
9.59%
Type II
1.93%

76.89%
30.23%
65.87%
27.27%

Type I
2.20%
Type II
63.80%

Table 4. MCMP Credit Card Classification Results

Evaluation on training data (280 cases):

Accuracy

Error Rate

(1)

(2)

(3)

(4)

<-classified as

50

12

8

0

(1): Current

71.43%

Type I

5

55

10

0

(2): Delinquent

78.57%

13.79%

2

5

55

8

(3): Charge-off

78.57%

Type II

1

1

5

63

(4): Bankrupt

90.00%

9.01%

Type I

Evaluation on test data (5720 cases):
(1)
3406

(2)

(3)

(4)

<-classified as

1012

559

4

(1): Current

68.38%

53

440

100

9

(2): Delinquent

73.09%

1.65%

4

23

92

7

(3): Charge-off

73.02%

Type II

0

0

2

9

(4): Bankrupt

81.82%

69.78%

Table 5. SVM-light Credit Card Classification Results

Evaluation on training data (280 cases):
(1)
(2)
(3)
(4)
<-classified as
40
22
8
0
(1): Current
1
69
0
0
(2): Delinquent
0
0
70
0
(3): Charge-off
1
1
2
66
(4): Bankrupt
Evaluation on test data (5720 cases):
(1)
(2)
(3)
(4)
<-classified as
3411 1135 136 299
(1): Current
55
199
66 282 (2): Delinquent
3
27
23
73 (3): Charge-off
1
0
1
9
(4): Bankrupt

Accuracy

Error Rate

57.14%
98.57%
100.00%
94.29%

Type I
4.76%
Type II
12.61%

68.48%
33.06%
18.25%
81.82%

Type I
1.70%
Type II
69.78%

491

492

G. Kou et al.

5 Conclusion
This is the first time that we investigate the differences among decision tree, MCMP,
and one-against-all SVM for multiclass classification using a real-life credit card
dataset. The results indicate that MCMP achieves better classification accuracy than
See5 and one-against-all SVM. In our future research, we will focus on the theoretical
differences between MCMP and one-against-all SVM. Another topic of interest is to
study the subject of reducing computational cost and improving algorithm efficiency
for high dimensional or massive datasets.

References
[1] Bradley, P.S., Fayyad, U.M., Mangasarian, O.L. (1999) Mathematical programming for data
mining: Formulations and challenges. INFORMS Journal on Computing, 11, 217-238.
[2] Cardweb.com, The U.S. Payment Card Information Network, accessed April 23, 2004,
[available at: http://www.cardweb.com/cardlearn/stat.html].
[3] Quinlan, J.R. (1993) C4.5: Programs for Machine Learning, Morgan Kauffman
Publication.
[4] Hsu, C. W. and Lin, C. J. (2002) A comparison of methods for multi-class support vector
machines, IEEE Transactions on Neural Networks, 13(2), 415-425.
[5] Joachims, T. (2004) SVM-light: Support Vector Machine, available at:
http://svmlight.joachims.org/.
[6] Knerr, S., Personnaz, L., and Dreyfus, G. (1990), “Single-layer learning revisited: A
stepwise procedure for building and training a neural network”, in Neurocomputing:
Algorithms, Architectures and Applications, J. Fogelman, Ed. New York: Springer-Verlag.
[7] Kou, G., Peng, Y., Shi, Y., Chen, Z. and Chen X. (2004b) “A Multiple-Criteria Quadratic
Programming Approach to Network Intrusion Detection” in Y. Shi, et al (Eds.):
CASDMKM 2004, LNAI 3327, Springer-Verlag Berlin Heidelberg, 145–153.
[8] Li, J.P, Liu, J.L, Xu, W.X., Shi, Y. Support Vector Machines Approach to Credit
Assessment. In Bubak, M., Albada, et al (Eds.) , ICCS 2004, LNCS 3039, SpringerVerlag, Berlin, 892-899, 2004.
[9] LINDO Systems Inc., An overview of LINGO 8.0, http://www.lindo.com/
cgi/frameset.cgi?leftlingo.html;lingof.html.
[10] New
Generation
Research,
Inc.,
April
2004,
[available
at:
http://
www.bankruptcydata.com/default.asp].
[11] Menties, T. and Hu, Y. (2003) Data Mining for Very Busy People, IEEE Computer, p.
18-25.
[12] RuleQuest research (2004) [available at: http://www.rulequest.com/see5-info.html].
See 5.0. (2004) [available at:http://www.rulequest.com/see5-info.html].
[13] Stolfo, S.J., Fan, W., Lee, W., Prodromidis, A. and Chan, P.K. (2000) Cost-based
Modeling and Evaluation for Data Mining With Application to Fraud and Intrusion
Detection: Results from the JAM Project, DARPA Information Survivability Conference.
[14] Vapnik, V. N. and Chervonenkis (1964), On one class of perceptrons, Autom. And
Remote Contr. 25(1).
[15] Vapnik, V. N. (1995), The Nature of Statistical Learning Theory, Springer, New York.
[16] Zhu, D., Premkumar, G., Zhang, X. and Chu, C.H. (2001) Data Mining for Network
Intrusion Detection: A comparison of Alternativest Methods, Decision Sciences, Volume
32 No. 4, Fall 2001.

