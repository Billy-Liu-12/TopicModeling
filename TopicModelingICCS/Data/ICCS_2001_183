A Two-Phase Fuzzy Mining and Learning Algorithm
for Adaptive Learning Environment
Chang-Jiun Tsai, S. S. Tseng*, and Chih-Yang Lin
Department of Computer and Information Science
National Chiao Tung University
Hsinchu 300, Taiwan, R.O.C.
E-mail: sstseng@cis.nctu.edu.tw
Abstract. As computer-assisted instruction environment becomes more popular
over the world, the analysis of historical learning records of students becomes more
important. In this work, we propose a Two-Phase Fuzzy Mining and Learning
Algorithm, integrating data mining algorithm, fuzzy set theory, and look ahead
mechanism, to find the embedded information, which can be provided to teachers
for further analyzing, refining or reorganizing the teaching materials and tests, from
historical learning records.
Keywords: Fuzzy set theory, Data Mining, Machine Learning, CAI

1. Introduction
As Internet becomes more popular over the world, the amounts of teaching materials
on WWW are increasing rapidly and many students learn knowledge through WWW.
Therefore, how to design and construct computer-assisted instruction environment
together with its teaching materials is of much concern. In recent years, an adaptive
learning environment [13], [14], [15] has been proposed to offer different teaching
materials for different students in accordance with their aptitudes and evaluation
results. After students learn the teaching materials through the adaptive learning
environment, the teachers can further analyze the historical learning records and
refine or reorganize the teaching materials and tests.
In this work, we propose a Two-Phase Fuzzy Mining and Learning Algorithm to
find the embedded information within the historical learning records for teachers to
further analyze, reorganize and refine the learning path of teaching materials or tests.
The first phase of proposed algorithm uses a fuzzy data mining algorithm, Look
Ahead Fuzzy Mining Association Rule Algorithm (LFMAlg), integrating association
rule mining algorithm, Apriori [1], fuzzy set theory, and look ahead mechanism, to
find the embedded association rules from the historical learning records of students.
The output of this phase can be fed back to teachers for reorganizing the tests, and
will be treated as the input of the second phase. The second phase uses an inductive
learning algorithm, AQR algorithm, to find the concept descriptions indicating the
missing concepts during students learning. The results of this phase can be provided
to teachers for further analyzing, refining or reorganizing the learning path.
*Corresponding author
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2074, pp. 429–438, 2001.
© Springer-Verlag Berlin Heidelberg 2001

430

C.-J. Tsai, S.S. Tseng, and C.-Y. Lin

Some related works and our motivation are first described in Section 2. Section
3 presents the framework of analyzing the historical learning records. Section 4 shows
the algorithms. Concluding remarks are given in Section 5.

2. Related Works and Motivation
The web-based educational systems are becoming more and more popular over the
world. Several approaches, which can be used to organize the teaching materials, have
been developed in the past ten years [2], [3], [7], [10], [12]. As to the evaluation, [7]
provides the evaluation mechanism to find out what instructional objectives in some
sections the students do not learn well. However, the students always need to learn all
teaching materials in each section for the first time no matter how the teaching
materials are suitable for them or not. Therefore, an adaptive learning environment
was proposed in [13] and [14], which can offer different teaching materials for
different students in accordance with their aptitudes and evaluation results. The idea is
to segment the teaching materials into teaching objects that is called Object-Oriented
Course Framework as shown in Figure 1 The teaching materials can be constructed by
organizing these teaching objects according to learning path, which can be defined
and provided by teachers or teaching materials editors for students learning.
Traditional Course Framework
Chapter

Section

Section

Section

nstruced in
Sequential & Monotonous
Way
Teaching Object

OO Course Framework
Chapter

Section

Section

Section

Constructed in
Individualized & Intelligent
Way
Quizzes

Fig. 1. The comparison between traditional and OO course framework

The architecture of adaptive learning environment is shown in Fig. 2. All
teaching objects are stored in Teaching Object Resource Database. When teachers
want to construct the teaching materials about some subjects, they can retrieve the
teaching objects from Teaching Object Resource Database, and define the learning
path about these teaching objects.

Fig. 2. The architecture of adaptive learning environment

As we know, the learning path is usually defined as tree structure containing
some teaching materials, and each teaching object of teaching materials may contain

A Two-Phase Fuzzy Mining and Learning Algorithm for Adaptive Learning

431

the teaching content and quizzes or tests to discriminate the students’ learning
performance. Therefore, students can learn these teaching materials by following the
learning path. For the example of learning path shown in Fig. 3, there is a specific
subject of teaching material including four teaching objects, A, B, C, and D. That
means A is the pre-requisite knowledge of B and C. In other words, students should
first learn teaching object A, learn teaching objects B and C, and finally learn
teaching object D.

Fig. 3. An example of learning path
All learning records, which are stored into Historical Learning Record Database, would
be used in the adaptive learning environment. In other words, the system would reconstruct the
course framework according to these learning records for students learning again, if students
cannot learn well about the teaching material [14]. Besides, the learning records also can be
used to refine the learning path by teachers. Because each quiz or test may consist of more than
one concept, some embedded information about the relationships among the high grades of
quizzes and low grades of quizzes can be used to determine whether the previously defined
learning path is reasonable or not. Therefore, we propose a Two-Phase Fuzzy Mining and
Learning Algorithm to find the embedded information about relationships among the learning
records.

Second Phase

First Phase

3. The Flow of Two-Phase Fuzzy Mining and Learning Algorithm

Fig. 4. The flow of Two-Phase Fuzzy Mining and Learning Algorithm

Fig. 4 shows the flow of our Two-Phase Fuzzy Mining and Learning Algorithm,
which can provide teachers the some embedded information for further analyzing,
refining and reorganizing the learning path and the tests.

432

C.-J. Tsai, S.S. Tseng, and C.-Y. Lin

Two-Phase Fuzzy mining and Learning Algorithm
Input: The learning records of students from Historical Learning Record Database.
Output: The information of missing concepts.
Phase1: Use Look Ahead Fuzzy Mining Association Rule Algorithm to find the fuzzy association rules of
quizzes from the historical learning records.
Phase2: Use Inductive Learning Algorithm to find the missing concept during students learning.

The first phase, data mining phase, applies fuzzy association rule mining
algorithm to find the associated relationship information, which is embedded in
learning records of students. In Table1, there are ten learning records of students, and
each record has the grades of 5 quizzes, where the highest grade of each quiz is 20.
Table 1. An example of students’ learning record
Student ID
1
2
3
4
5
6
7
8
9
10

Q1
12
10
3
8
16
0
1
2
12
6

Q2
14
6
6
10
18
3
8
3
16
8

Q3
18
12
6
8
20
3
6
3
14
12

Q4
3
6
1
2
20
1
4
0
4
2

Q5
9
7
5
8
20
4
10
3
14
10

Total
56/100
41/100
21/100
36/100
94/100
11/100
29/100
11/100
60/100
38/100

Assume each quiz may contain one or more learning concepts. As shown in
Table 2, related learning concepts A, B, C, D, and E may be contained in these five
quizzes, where “1” indicates the quiz contains this concept, and “0” indicates not.
Table 2. An example of learning concepts information
Q1
Q2
Q3
Q4
Q5

A
1
1
1
0
0

B
0
0
0
1
1

C
0
1
0
1
0

D
1
0
0
0
0

E
0
0
0
0
1

Assume most students get the low grades for Q1 and Q2, and thus Q1 may
associate with Q2. This means for students missing the learning concept of Q1 (A, D),
they may also miss the learning concept of Q2 (A, C). The fuzzy association rule
mining algorithm is then used to find the embedded information about the
relationships among the low grades of quizzes and the relationships among the high
grades of quizzes. These embedded information can be viewed as the positive and
negative instances, which will be the input of the second phase. In addition, the
obtained embedded information can be provided to teachers for making up
appropriate quizzes. Accordingly, we can suggest that at most one of Q1 and Q2
should be included in the same test to improve the discriminative ability, if there
exists the association relationship between Q1 and Q2.
The second phase is to find the missing concepts for most students. We apply
inductive learning strategy, AQR learning algorithm [8] which is suitable for
symbolic learning, to include all positive instances and exclude all negative instances.
Then the teachers can refine learning path according to these information and original

A Two-Phase Fuzzy Mining and Learning Algorithm for Adaptive Learning

433

learning path. As mentioned above, in Table 2, the Q1 (A, D) and Q2 (A, C) belong to
the set of low grades of quizzes. Thus the set of missing concepts, (A, C, D), can be
regarded as a positive instance for AQR learning algorithm. On the contrary, the set of
hitting concepts can be regarded as the negative instance. By using AQR algorithm
for these training instances, some rules which can include all positive instances and
exclude all negative instances can be learned.

4. Algorithm
In this section, Look Ahead Fuzzy Mining Association Rule Algorithm (LFMAlg)
used in the first phase and AQR algorithm used in the second phase will be described.
4.1 Fuzzy Data Mining Algorithm
IBM Almaden Research Center proposed the association rule mining algorithm,
Apriori algorithm [1], to find the embedded information within a large number of
transactions. The famous example of supermarket shows trend of buying behavior of
customers. Unfortunately, the Apriori algorithm only works in ideal domains where
all data are symbolic and no fuzzy data are present. However, real-world applications
sometimes contain some numeric information, which need to be transformed into
symbolic. For example, if the grade of quiz is 78, different experts may have different
opinions of the concept “high grade”. Thus, how to transform the linguistic data into
the symbolic data and how to let Apriori algorithm be able to handle numeric
information of these linguistic data are of most importance. Our idea is to improve
Apriori algorithm by applying fuzzy set theory to overcome the problem of existing
fuzzy regions among the data.
A fuzzy set is an extension of a crisp set, which allows only full membership or
no membership at all, whereas fuzzy set allows partial membership. To apply fuzzy
concepts, the membership function of each quiz’s grade, which can transform numeric
data into fuzzy set, is defined in Fig. 5.
As we know, in the association rule mining algorithm, the support of association
rule is larger than a minimum support threshold, defines as � � , and the confidence of
association rule is larger than a minimum confidence threshold, defined as �, in � large itemset. In Apriori algorithm, � � is a constant, and then the number of
association rules may decrease when � increases in � -large itemset. That may cause
losing of some association rules in larger itemsets. However the minimum support
threshold may be too small to exhibit the meaning of association rule. Hence, we
apply Look Ahead mechanism to generate Next Pass Large Sequence [6] to overcome
the above problem.

Fig. 5. The given membership function of each quiz’s grade

As mentioned above, we proposed the Look Ahead Fuzzy Mining Association
Rule Algorithm, integrating Apriori algorithm, Look Ahead mechanism, and Fuzzy
Set Theory, to find the association rules within fuzzy data set as below.

434

C.-J. Tsai, S.S. Tseng, and C.-Y. Lin

Definition

f ij ( k ) : indicates the kth student’s fuzzy values for the ith quiz and the jth degree of
fuzzy function.
Fij : indicates the sum of all students’ fuzzy value for the ith quiz and the jth degree of
n

fuzzy function, i.e., Fij �

�f

ij ( k

) , where n indicates the number of students.

k �1

C� : indicates � -candidate itemset.
NPLS � : indicates � -Next Pass Large Sequence (NPLS) [6].
L� : indicates � -large itemset.

� � : indicates the minimum support threshold of � -large itemset.
support(x) : indicates the support values of the element x for x� C� .
Look Ahead Fuzzy Mining Association Rule Algorithm
Input: The learning records of students from Historical Learning Record Database.
The minimum support threshold � 1 in the 1-large itemset, L1.
The minimum confidence threshold �.
Output: The fuzzy association rules of learning records of students.
STEP1: Transform the grades of each quiz into fuzzy value, f ij ( k ) , for all students
according to the fuzzy membership function.
STEP2: C1 � � Fij | Fij �

n

�f

ij ( k

) �, and

��1

(1)

k �1

STEP3: L� � � x | support(x) � � � ,
STEP4: � � �1 � max(

�1
2

, �� �

for

x � C�

�

�1
) , where c is a constant .
��c

STEP5: NPLS � � { x | support(x) � � � �1 ,

for

x � C� }

(2)
(3)
(4)

STEP6: If NPLS � is null,
then stop the mining process and go to STEP8,
else generate the ( � +1)-candidate set, C � �1 , from NPLS � .
STEP7: � � � � 1 and go to STEP3.
STEP8: Determine the association rules according to the given � and all large
itemsets.
Example 4.1
According to the given membership function defined in Fig. 5, Table 3 shows
the fuzzication result of the data of Table 1. The “Low” denotes “Low grade ”, “Mid”
denotes “Middle grade”, and “High” denotes “High grade”. Qi.L denotes the low
degree of fuzzy function of the ith quiz, Qi.M denotes the middle degree of fuzzy
function of the ith quiz, and Qi.H denotes the high degree of fuzzy function of the ith
quiz.

A Two-Phase Fuzzy Mining and Learning Algorithm for Adaptive Learning

435

Table 3. The fuzzication results of the data of Table 1
Q1
Student ID Low Mid
High
1
0.0 0.0 0.7
2
0.0 0.5 0.3
3
0.8 0.0 0.0
4
0.0 1.0 0.0
5
0.0 0.0 1.0
6
1.0 0.0 0.0
7
1.0 0.0 0.0
8
1.0 0.0 0.0
9
0.0 0.0 0.7
10
0.3 0.5 0.0

Q2
Low Mid High
0.0 0.0 1.0
0.3 0.5 0.0
0.3 0.5 0.0
0.0 0.5 0.3
0.0 0.0 1.0
0.8 0.0 0.0
0.0 1.0 0.0
0.8 0.0 0.0
0.0 0.0 1.0
0.0 1.0 0.0

Q3
Low Mid High
0.0 0.0 1.0
0.0 0.0 0.7
0.3 0.5 0.0
0.0 1.0 0.0
0.0 0.0 1.0
0.8 0.0 0.0
0.3 0.5 0.0
0.8 0.0 0.0
0.0 0.0 1.0
0.0 0.0 0.7

Q4
Low Mid High
0.8 0.0 0.0
0.3 0.5 0.0
1.0 0.0 0.0
1.0 0.0 0.0
0.0 0.0 1.0
1.0 0.0 0.0
0.7 0.0 0.0
1.0 0.0 0.0
0.7 0.0 0.0
1.0 0.0 0.0

Q5
Low Mid High
0.0 0.8 0.2
0.2 0.8 0.0
0.5 0.3 0.0
0.0 1.0 0.0
0.0 0.0 1.0
0.7 0.0 0.0
0.0 0.5 0.3
0.8 0.0 0.0
0.0 0.0 1.0
0.0 0.5 0.3

According to the fuzzy data shown in Table 3, Fig. 6 shows the process of
finding the association rules for the original data shown in Table 1. In this case,
assume � 1 = 2.1 and � = 0.75. Table 4 shows the process of calculating the
confidence of 2-large itemset. For example, the confidence value of the itemset (Q2.L,
Q1.L) is 0.86, means that many students get low grades of Q1 and Q2 simultaneously.
The embedded information shows that Q1 may have similar property or may contain
similar learning concept with Q2. Therefore, we may suggest that Q1 and Q2 do not
appear at the same test.
Table 4. The process of calculating the confidence of 2-large itemset
Itemset
(Q1.L, Q2.L)
(Q2.L, Q1.L)
(Q1.L, Q3.L)
(Q3.L, Q1.L)
(Q1.L, Q5.L)
(Q5.L, Q1.L)
(Q2.L, Q3.L)
(Q3.L, Q2.L)
(Q2.L, Q5.L)
(Q5.L, Q2.L)

Confidence
0.46
0.86
0.54
1
0.49
0.91
0.86
0.86
0.9
0.9
� 1 ( 2.1 ), C 1 � L1

Itemset
(Q1.H, Q2.H)
(Q2.H, Q1.H)
(Q1.H, Q3.H)
(Q3.H, Q1.H)
(Q1.H, Q5.H)
(Q5.H, Q1.H)
(Q2.H, Q3.H)
(Q3.H, Q2.H)
(Q2.H, Q5.H)
(Q5.H, Q2.H)

Confidence
0.89
0.72
1
0.61
0.7
0.68
0.9
0.68
0.67
0.79

� � 2 ( 1.89 ) � NPLS 1 � C 2 � L 2
� � 3 ( 1.79 ) � NPLS 2 � C 3 � L3
� � 4 ( 1.72 ) � NPLS 4 � C 4 � L4
� � 5 ( 1.66 ) � NPLS 5 ( Null )

Fig. 6. The process of mining association rules
In the process of data mining, only any two items both with high grades or both with low
grades would be considered as a 2-large itemset, because if one with high grades and the other
with low grades, the found embedded information is meaningless for teachers. However,
teachers cannot explain why students do not learn well for some specific quizzes according to
the output of first phase. In other words, we cannot intuitively induce what learning concepts
the students miss in accordance with the information about association rules of the quizzes,
although information about what concepts are contained in quizzes is known. Therefore, we
apply inductive machine learning strategy, AQR algorithm [8], to find the missing learning
concepts.

436

C.-J. Tsai, S.S. Tseng, and C.-Y. Lin

4.2 Inductive Learning Algorithm
AQR is one kind of the batch and inductive learning algorithm [8] that uses the basic
AQ algorithm [11] to generate the concept description, which can include all positive
instances and exclude all negative instances. When learning process is running, AQR
performs a heuristic search through the hypothesis space to determine the description.
The training instances, including the set of positive instances and the set of negative
instances, are learned in stages; each stage generates a single concept description, and
removes the instances it covers from the training set. The step is repeated until enough
concept descriptions have been found to cover all positive instances.
In the first phase of the Two-Phase Fuzzy Mining and Learning Algorithm,
LFMAlg is used to find the association rules embedded in the historical learning
records of students. The large itemsets except 1-large itemset can be considered as the
training instances for AQR algorithm. Because the large itemsets of low grades, the
missing concepts, can be considered as positive instances of the training instances,
and because the large itemsets of high grades can be considered as negative instances,
the concept descriptions which include/exclude all positive/negative instances can
show the more precise missing concepts of students. The association rule of the first
phase’s output consists of the left-hand-side (LHS) and right-hand-side (RHS). The
LHS may consist of one or more items. To transform the LHS into the training
instance, the union operator for the concepts contained by the items of LHS is used.
For example, the item (Q1.L, Q3.L, Q4.L) is one of 3-large itemset, and the confidence
� is larger than the defined minimum confidence threshold. Then the itemset can be
transformed into a positive instance by run the union operator for Q1’s and Q3’s
learning concepts shown in Table 2, i.e., (10010, 10000) = (10010). To combine the
learning concept of RHS of this item, Q4, the positive instance can be expressed as
(10010, 01100).
Before using AQR algorithm to induce the concept descriptions, which cover
missing concepts, the pre-process of transforming the itemsets found by the first
phase into the training instances should be done as mentioned above.
The concepts derived from AQR are represented as the multiple-valued logic
calculus with typed variables, which can be represented as follows.
If <cover> then predict <class>
, where <cover> = <complex 1> or or <complex m>,
<complex> = <selector 1> and and <selector n>,
<selector> = <attributes r values>,
<r> = relation operator.

A selector relates a variable to a value or a disjunction of values. A conjunction
of selectors forms a complex. A cover is a disjunction of complexes describing all
positive instances and none of the negative ones of the concept. The AQR algorithm is
described as below.
AQR Algorithm [8]
Input: The set of positive instances and the set of negative instances.
Output: The information of missing concepts.

A Two-Phase Fuzzy Mining and Learning Algorithm for Adaptive Learning

437

SETP1: Let POS be a set of positive instances and let NEG be a set of negative instances.
SETP2: Let COVER be the empty cover.
SETP3: While COVER does not cover all instances in POS, process the following steps.
Otherwise, stop the procedure and return COVER.
SETP4: Select a SEED, i.e., a positive instance not covered by COVER.
SETP5: Call procedure GENSTAR to generate a set STAR, which is a set of complex that covers
SEED but that covers no instances in NEG.
SETP6: Let BEST be the best complex in STAR according to the user-defined criteria.
SETP7: Add BEST as an extra disjunction of COVER.
GENSTAR procedure
SETP1: Let STAR be the set containing the empty complex.
SETP2: While any complex in STAR covers some negative instances in NEG,
process the following steps. Otherwise, stop the procedure and return STAR.
SETP3: Select a negative instance Eneg covered by a complex in STAR
SETP4: Specialize complexes in STAR to exclude Eneg by:
Let EXTENSION be all selectors that cover SEED, but not Eneg .
Let STAR be the set {x � y | x�STAR, y�EXTENSION}
SETP5: Repeat this step until sizes of STAR � max-star (a user-defined maximum).
Remove the worst complex from STAR.

Example 4.2
Table 5 shows the training instances of transforming the 2-large itemsets, in
which support value are larger than the defined minimum confidence threshold.
Table 5. An example of training instances
Positive (+)/
Negative (-)
+
+
+
+
+

Itemset
(Q2.L, Q1.L)
(Q3.L, Q1.L)
(Q5.L, Q1.L)
(Q2.L, Q3.L)
(Q3.L, Q2.L)

Instance

Itemset

(10100, 10010)
(10000, 10010)
(01001, 10010)
(10100, 10000)
(10000, 10100)

(Q2.L, Q5.L)
(Q5.L, Q2.L)
(Q1.H, Q2.H)
(Q1.H, Q3.H)
(Q5.H, Q2.H)

Positive (+)/
Negative (-)
+
+
-

Instance
(10100, 01001)
(01001, 10100)
(10010, 10100)
(10010, 10000)
(01001, 10100)

The three pairs, (11101, 10010), (00100, 10000), and (01001, 10100), which are
the learning concepts students do not learn well, are found by the learning process of
AQR algorithm. For example, (00100, 10000) means that the learning concept, (C),
have high degree of relationship with (A), even if (C) may introduce (A). The
teachers may analyze learning results of AQR algorithm as shown in Fig. 7.
(11101, 10010)
(B, C, E) (D)

�

B

C
E

(00100, 10000) (10100,01001)
(C) (A)
(B, E) (A, C)

�

�

� �
�

C
A

C

B

E

�

(C) (A) (B, E) (D)
(C) (D)
C
A

A
B

D

E

D

Fig. 7. The analysis of learning results of AQR algorithm

438

C.-J. Tsai, S.S. Tseng, and C.-Y. Lin

5. Concluding Remarks
In this work, we proposed the Two-Phase Fuzzy Mining and Learning Algorithm. In
the first phase, LMFAlg was proposed to find the embedded association rules from the
historical learning records of students. In the second phase, the AQR algorithm was
applied to find the concept descriptions indicating the missing concepts during
students learning. The obtained results can be fed back to the teachers for analyzing,
refining or reorganizing learning path of teaching materials and the tests. Now, we are
trying to apply our algorithm to the virtual mathematics curriculum of senior high
school in Taiwan.
Acknowledgement. This work was partially supported by the National Science Council of
the Republic of China under Grant No. NSC 90-2511-S009-023.

Reference
1. Agrawal, R., Srikant, R.: Fast Algorithms for Mining Association Rules. Proc. Of the 20th
Int’l Conference on Very Large Database. (1994)
2. Alessi, S.-M., Trollip, S.-R.: Computer-based Instruction: Methods and Development. 2nd.
Englewood Cliffs, NJ: Prentice-Hall (1991)
3. Antal, P.: Animated Explanations Using Adaptive Student Models. Proc. of INES’97.
(1997) 573-576
4. Au, W.-H., Chan, K.-C.-C.,: FARM: A Data Mining System for Discovering Fuzzy
Association Rules. Proc. of FUZZ-IEEE’99. 3 (1999) 1217-1222
5. Chen, M.-S., Han, J., Yu, P.-S.: Data Mining: An Overview from A Database Perspective.
IEEE Transaction on Knowledge and Data Engineering. 8(6) (1996) 866-883
6. Chen, S.-S., Hsu, P.-Y., Chen, Y.-L.: Mining Web Traversal Rules with Sequences. MIS
Review 1(1999) 53-71
7. Chou, C.: A Computer Logging Method for Collecting Use-reported Inputs During
Formative Evaluation of Computer Network-assisted Distance Learning. Proc. of EDMedia’96. (1996)
8. Clark, P., Niblett, T.: The CN2 Induction Algorithm. Machine Learning. 3 (1989) 261-283
9. Hong, T.-P., Kuo, C.-S., Chi, S.-C.: A Fuzzy Data Mining Algorithm for Quantitative
Values. Proc. of Knowledge-based Intelligent Information Engineering Systems. (1999)
480-483
10. Hwang, G.-J.: A Tutoring Strategy Supporting System for Distance Learning on Computer
Networks. IEEE Transactions on Education. 1(4) (1998) 343-343
11. Michalski, R.-S.: On The Quasi-minimal Solution of The General Covering Problem. Proc.
of the 5th International Symposium on Information Processing. (1969) 125-128
12. Sun, C.-T., Chou, C.: Experiencing CORAL: Design and Implementation of Distance
Cooperative Learning. IEEE Transactions on Education. 39(3) (1996)357-366
13. Su, G.-H., Tseng, S. S., Tsai, C.-J., Zheng, J.-R.: Building An Object-oriented and
Individualized Learning Environment on the WWW. Proc. of ICCE’99. (1999) 728-735
14. Su, G.-H., Tseng, S. S., Tsai, C.-J., Zheng, J.-R.: Implementation of An Object-Oriented
Learning Environment Based on XML,” Proc. of ICCE’00. 2 (2000) 1120-1127
15. Tsai, C.-J., Tseng, S. S., Su, G.-H.: Design of An Object-oriented and Rule-based Virtual
School. Proc. of GCCCE’00. (2000) 320-327

