Reliability Evaluation Using Monte Carlo Simulation
and Support Vector Machine
C. M. Rocco S., J. A. Moreno
Universidad Central, Facultad de Ingeniería, Apartado 47937, Caracas 1040A, Venezuela
e-mail: {rocco,jose}@neurona.ciens.ucv.ve

Abstract. In this paper we propose the use of Support Vector Machine

(SVM) to evaluate system reliability. The main idea is to develop an
estimation algorithm, by training a SVM on a data set, and replace
system performance model evaluation by a simpler and faster
calculation. The proposed approach is illustrated by an example.
System reliability is properly emulated by training a SVM with a little
amount of information.

1

Introduction

Reliability evaluation of real engineering systems is often performed using simulation
tools. Indeed, reliability indices of a system can be seen as the expected value of a test
function applied to a system state Xi (vector representing the state of each element) in
order to assess whether that specific configuration corresponds to an operating or
failed state [1].
For example, in a s-t network, to assess if a selected state Xi correspond to an
operating or failed state, we need to determine its connectivity, which requires
knowledge of the cut sets or path sets of the system [2] or to use a depth-first
procedure [3].
In other cases, such as telecommunication networks as well other real systems, the
success of the network requires that a given state is capable of transporting a required
flow. To assess a state, for example, we can use the max-flow min-cut algorithm [45].
In general, to determine the state of the system (operating or failed) as a function of
the state of its components we need to evaluate a function (one or more) that is called
System Function [6] or Structure Function [7].
In a Monte Carlo simulation we evaluate system reliability by generating several
systems states, and evaluating the SF. Since we require a large number of SF
evaluations, we substitute its evaluation with a fast, approximated, algorithm.
There are several approaches that have been used to address the definition of these
approximated algorithms [8-12]. In our work, we employ an empirical model built by
training a Support Vector Machine (SVM). SVM provides a new approach to the two-

category classification problem (operating or failed)[13]. Nowadays, SVM has
reached a high level of maturity, with algorithms that are simple, easy to implement,
faster and with good performance [14].
Section 2 contains an overview of Monte Carlo approach. The SVM approach is
presented in Section 3. Finally, section 4 presents the proposed approach and the
results of an example.

2 Monte Carlo Approach
Monte Carlo method is one of the methods used to evaluate system reliability. The
basic idea is that one could estimate reliability by a relatively simple sampling plan
that requires little information about the system under study [15].
For example, let us consider the simple state approach. A system state depends on
the combination of all component states and each component state can be determined
by sampling the probability that the component appears in that state [5].
If we assume that each component has two states (failure and success) and that
component failures are independent events, then the state of the ith component (xi)
can be evaluated using its failure probability Pfi and a random number Ui, distributed
uniformly between [0,1], as [5]:

1 (succes state) if Ui ≥ Pfi 
xi = 

0 (failure state) if 0 ≤ Ui < Pfi 
The jth-state of the system containing NC components is expressed by the vector
Xj = ( x1, x2 , …, xNC)
In general, to evaluate if Xj is an operating or failure state, we need to define a SF
and evaluate it at Xj. The SF should have the form:

1 if system is operational in this state
SF(Xj) = 

0 if system is failed in this state

In the Monte Carlo approach the conceptual scheme for reliability evaluation
consist on [1]:
1.
2.
3.
4.
5.

Select a system state Xj
Calculate the System Function for the selected state Xj
Update the estimate of the expected value of SF(Xj) (E(SF(Xj))
Calculate the uncertainty of the estimate
If the uncertainty is acceptable (within a target tolerance), stop; otherwise
return to step 1)

Other sample techniques exist which are more effective [15]. But, in general, all
Monte Carlo Methods require SF evaluations. As previously mentioned, the SF
depends on the type of reliability evaluation required. In this paper we consider the
emulation of the SF using a SVM.

3

Support Vector Machine

Support Vector Machines provide a new approach to the two-category classification
problem [13].
SVMs have been successfully applied to a number of applications ranging from
particle identification, face identification and text categorization to engine detection,
bioinformatics and data base marketing. The approach is systematic and properly
motivated by statistical learning theory [16].
SVM is an estimation algorithm (“learning machine”) based on [13]:
• Parameter estimation procedure (“Training”) from a data set
• Computation of the function value (“Testing”)
• Generalization accuracy (“Performance”)
Training involves optimization of a convex cost function: there are no local
minima to complicate the learning process. Testing is based on the model evaluation
using the most informative patterns in the data (the support vectors). Performance is
based on error rate determination as test set size tends to infinity [17].
Suppose Xi is a system state and yi is the result of applying the SF to Xi: yi =
SF(Xi). In order to apply the SVM theory we will change the notation. If Xi is a failed
state we will assign –1 instead of 0.
Suppose we have N training data points {(X1,y1), …. (XN,yN)}. The main idea is to
obtain a hyperplane that separates failed from non-failed in this space, that is to
construct the hyperplane H: y = w · X-b = 0 and two hyperplanes parallel to it:
H1: y = w · X-b = +1 and
H2: y = w · X-b = -1
with the condition, that there are no data points between H1 and H2, and the
distance between H1 and H2 (the margin) is maximized. Figure 1 shows the situation
[18].
The quantities w and b are the parameters that control the function and are referred
as the weight vector and bias [16].
The problem can be formulated as:
Min ½ wTw
w,b
s.t yi (w · X-b) ≥ 1

ma
rg
in

Data point in Class 1
Data point in Class 2

H1: w · X – b = +1
H:w· X–b=0

H2: w · X – b = -1
Fig. 1. Decision hyperplanes generated by a linear SVM [18]

This is a convex, quadratic programming problem in (w, b), in a convex set. Once
we have trained a SVM, we simply determine on which side of the decision boundary
a given test pattern X* lies and assign the corresponding class label, using sgn (w · X*
+ b).
When the maximal margin hyperplane is found, only those points which lie closest
to the hyperplane have αi > 0 and these points are the support vectors, that is, the
critical elements of the training set. All other points have αi = 0. This means that if all
other training points were removed and training was repeated, the same separating
hyperplane would be found [13]. In figure 2, the points a, b, c, d and e are examples
of support vectors [18].
Small problems can be solved by any general-purpose optimization package that
solves linearly constrained convex quadratic programs. For larger problems, a range
of existing techniques can be used [16].
If the surface separating the two classes is not linear, we can transform the data
points to another high dimensional feature space such the data points will be linearly
separable. Figure 3 is an example of such transformation [16].
The algorithm that finds a separating hyperplane in the feature space can be
obtained in terms of vector in input space and a transformation function Φ(·). We
need not be explicit about the transformation Φ(·) as long as we know that a kernel
function K(Xi,Xj) is equivalent to the dot product of some other high dimensional
feature space [13,16-19].
There are many kernel functions that can be used this way, for example [13,16]:
- Xi-Xj ²/2 ²
K(Xi,Xj) = e || || σ the Gaussian radial basis function kernel
p
K(Xi,Xj) = (Xi · Xj + m ) the polynomial kernel
The Mercer’s condition can be used to determine if a function can be used as
kernel function [19].
With a suitable kernel, SVM can separate in the feature space the data that in the
original input space was non-separable. This property means that we can obtain
nonlinear algorithms by using proven methods to handle linearly separable data sets
[19].

c
d

a

e

b

w · X – b = +1

w ·X – b = 0
w · X – b = -1

Fig. 2. Example of support vectors [18]
Φ()

Φ(x)

x
x
x
o o
o o

Φ(x)
Φ(x)
Φ(o)

x
x

x

Φ(o)
Φ(o)

Φ(x)
Φ(x)

Φ(x)
Φ(x)
Φ(o)

x

Fig. 3. A non-linear separating region transformed in to a linear one [16]

The choice of the kernel is a limitation of the support vector approach. Some work
has been done on limiting kernels using prior knowledge [19]. However, it has been
noticed that when different kernel functions are used in SVM, they empirically lead to
very similar classification accuracy [19]. In these cases, the SVM with lower
complexity should be selected.
The performance of a binary classifier is measured using sensitivity, specificity and
accuracy [20]:
TP
TP + FN
TN
specificity =
TN + FP
TP + TN
accuracy =
TP + TN + FP + FN
sensitivity =

where:
TP=Number of True Positive classified cases (SVM correctly classifies)
TN=Number of True Negative classified cases (SVM correctly classifies)

FP=Number of False Positive classified cases (SVM labels a case as positive while
it is a negative
FN=Number of False Negative classified cases (SVM labels a case as negative
while it is a positive
For reliability evaluation, sensitivity gives the percentage of correctly classified
operational states and the specificity the percentage of correctly classified failed
states.

4 Proposed Approach
In order to apply SVM in Monte Carlo reliability evaluations, we need first to build a
data set using the system state vector Xi and yi = SF(Xi) and then train the SVM. As
we are going to replace the SF with a SVM, we will build the data set sampling the
possible space configuration. We generate at random a system state and then evaluate
its SF. During the system state generation we select only different states, that is there
are no replicated states in the training data set. We repeat this process (N+NT) times.
The first N data are used to train the SVM and the following NT data are used to
evaluate the SVM performance.
Once we get a suitable SVM, we are ready to evaluate the system reliability. We
*
generate at random a system state X i and decide if it is a failed state or not using sgn
*
(w · X i + b). We repeat this process NM times. At the end, we can estimate the system
reliability as:

Reliability =

Number of Operating States
NM

4.1 Example

Figure 4 shows the system to be evaluated [21]. We assume that each link has
reliability ri and capacity of 100 units. We want to evaluate the reliability between the
source node s and the terminal node t. A system failure is defined when the flow at
terminal node is less than 200 unit. Using a pure Monte Carlo approach and a maxflow min-cut algorithm as the SF, the estimated reliability is 0.93794.
21
In this case there are 2 possible combinations. We sampled the state space and
generated a training data set with 500 different states. We tried different kernels and
found that the best SVM has a second order polynomial kernel, with only 90 support
vectors.
Once the SVM is selected, we used it to evaluate the system reliability. We
generate several random data sets with variable number of states. Table 1 shows the
size of the testing data set, the system reliability based on the number of operating
states obtained evaluating the SF, the system reliability using SVM and the relative
error:

16

5
21

17

6
1

18
7

2
s

3

8

14

9

t

15

10

19

4
11

20

12

r7 = 0.81
r4 = r12 = r13 = r19 = 0.981
other ri = 0.9

13
Fig. 4. Network for example 4.1 [21]

Relative Error (%) =

(SF Evaluation - SVM Evaluation )
x 100
SF Evaluation

System reliability obtained using SF or SVM are very close. It is interesting to note
that the system reliability is properly emulated using only a little fraction of the state
space (90 support vectors/221 states = 0.0043 %).
Table 1. SF and SVM Reliability results

Testing data
set size
1000
5000
10000
20000

SF Reliability

SVM Reliability

Relative Error (%)

0.9390
0.9390
0.9367
0.9382

0.9423
0.9410
0.93820
0.93980

-0,96%
-0,21%
-0,16%
-0,17%

5 Conclusions
This paper has presented a faster approach to evaluate system reliability based on
SVM. The excellent results obtained in the example show the applicability of this
method for evaluating the reliability of a system by emulating the SF with a SVM. In

the example presented the SVM, built from a little fraction of the total state space,
produces very close reliability estimation with relative error less than 1 %

REFERENCES
1.

2.
3.
4.
5.
6.

7.
8.

9.

10.

11.

12.
13.
14.
15.

16.

Pereira M.V.F, Pinto L.M.V.G.: “A New Computational Tool for Composite
Reliability Evaluation”, IEEE Power System Engineering Society Summer Meeting,
1991, 91SM443-2
Billinton, R. Allan R.N: Reliability Evaluation of Engineering Systems, Concepts and
Techniques. Second Edition. Plenum Press. 1992
Reingold E., Nievergelt J., Deo N.: Combinatorial Algorithms: Theory and Practice,
Prentice Hall, New Jersey, 1977
Papadimitriou C. H., Steiglitz K.: Combinatorial Optimization: Algorithms and
Complexity, Prentice Hall, New Jersey, 1982
Billinton, R. Li W.: Reliability Assessment of Electric Power System Using Monte
Carlo Methods. Plenum Press. 1994
Dubi A.: “Modeling of Realistic System with the Monte Carlo Method: A Unified
System Engineering Approach”, Proc. Annual Reliability and Maintainability
Symposium, Tutorial Notes, 2001
Pohl E.A., Mykyta E.F.: “Simulation Modeling for Reliability Analysis”, Proc.
Annual Reliability and Maintainability Symposium, Tutorial Notes, 2000
Marseguerra M., Masine R., Zio E., Cojazzi G.: “Using Neural Networks as
Nonlinear Model Interpolators in Variance Decomposition-Based Sensitivity
Analysis”, Third International Symposium on Sensitivity Analysis of Model Output,
Madrid, June 2001.
Merrill H., Schweppe F.C., “Energy Strategic Planning for Electric Utilities Part I and
Part II, Smarte Methodology”, IEEE Transactions on Power Apparatus and Systems,
Vol. PAS - 101, No. 2, February 1982
Sapio B.: “SEARCH (Scenario Evaluation and Analysis through Repeated Cross- impact
Handling): A new method for scenario analysis with an application to the Videotel
service in Italy”, International Journal of Forecasting, (11) 113-131, 1995
Mukerji R., Lovell B.: “Creating Data Bases for Power Systems Planning Using High
Order Linear Interpolation”, IEEE Transactions on Power Systems, Vol.3, No.4,
November 1988
Rahman S., Shrestha G.: “Analysis of Inconsistent Data in Power Planning”, IEEE
Transactions on Power Systems, Vol.6, No.1, February 1991
Burges C.: “A tutorial on Support Vector Machines for Patter Recognition”,
http://www.kernel-machines.org/
Platt J.:”Fast Training of Support Vector Machines using Sequential Minimal
Optimization”, http://www.research.microsoft.com/~jplatt
Fishman G.: “A Comparison of Four Monte Carlo Methods for Estimating the
Probability of s-t Connectedness”, IEEE Transaction on Reliability, Vol. R-35, No. 2,
June 1986
Cristianini N., Shawe-Taylor J.: “An introduction to Support Vector Machines”,
Cambridge University Press, 2000

17. Campbell C.: “Kernel Methods: A survey of Current Techniques”,
http://www.kernel-machines.org/
18. http://www.ics.uci.edu/~xge/svm/
19. Campbell C.: “An Introduction to Kernel Methods”, In R.J. Howlett and L.C. Jain,
editors, Radial Basis Function Networks: Design and Applications, page 31. Springer
Verlag, Berlin, 2000
20. Veropoulos K., Campbell C., Cristianini N.: “Controlling the Sensitivity of Support
Vector Machines”, Proceedings of the International Joint Conference on Artificial
Intelligence, Stockholm, Sweden, 1999 (IJCAI99), Workshop ML3, p. 55-60.
21. Yoo Y.B., Deo N.: “A Comparison of Algorithm for Terminal-Pair Reliability”,
IEEE Transaction on Reliability, Vol. 37, No. 2, June 1988

