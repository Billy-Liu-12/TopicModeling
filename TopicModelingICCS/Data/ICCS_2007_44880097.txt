Studies on Shape Feature Combination and Efficient
Categorization of 3D Models
Tianyang Lv1,2, Guobao Liu1, Jiming Pang1, and Zhengxuan Wang1
1

2

College of Computer Science and Technology, Jilin University, Changchun, China
College of Computer Science and Technology, Harbin Engineering University, Harbin, China
raynor1979@163.com

Abstract. In the field of 3D model retrieval, the combination of different kinds
of shape feature is a promising way to improve retrieval performance. And the
efficient categorization of 3D models is critical for organizing models. The paper proposes a combination method, which automatically decides the fixed
weight of different shape features. Based on the combined shape feature, the
paper applies the cluster analysis technique to efficiently categorize 3D models
according to their shape. The standard 3D model database, Princeton Shape
Benchmark, is adopted in experiment and our method shows good performance
not only in improving retrieval performance but also in categorization.
Keywords: Shape-based 3D model retrieval; feature combination; categorization; clustering.

1 Introduction
With the proliferation of 3D models and their wide spread through internet, 3D model
retrieval emerges as a new field of multimedia retrieval and has great application
value in industry, military etc.. [1]. Similar to the studies in image or video retrieval,
researches in 3D model retrieval concentrate on the content-based retrieval way [2],
especially the shape-based retrieval. The major problem of shape-based retrieval is
extracting model’s shape feature, which should satisfy the good properties, such as
rotation invariant, representing various kinds of shape, describing similar shape with
similar feature, etc…
Although many methods for extracting shape feature have been proposed [3], researches show that none is the best for all kinds of shapes [4, 5, 6, 7]. To solve this problem, it is an effective way to combine different shape features [5, 6, 7]. The critical step
of the combination is determining the weights of shape features. For instance, ref. [5]
determines the fixed weight due to user’s experience, which is based on numerous
experiments; meanwhile it decides the dynamic weight based on the retrieval result
and the categorization of 3D models.
However, the shortcomings of these methods are: need user experience to decide
the appropriate fixed weight, and cannot appoint weight for new feature; it is too time
consuming to compute the dynamic weight, while its performance is just a little better
than the fix-weighted way.
Y. Shi et al. (Eds.): ICCS 2007, Part II, LNCS 4488, pp. 97–104, 2007.
© Springer-Verlag Berlin Heidelberg 2007

98

T. Lv et al.

Moreover, it is still an open problem to categorize 3D models. Nowadays, the
categorization of 3D models depends on manual work, such as Princeton Shape
Benchmark (PSB) [4]. Even if the drawback of time consuming is not taken into consideration, the manual way also results in the following mistakes: first, models with
similar shape are classified into different classes, like the One Story Home class and
Barn class of PSB; second, models with apparently different shapes are classified into
the same class, like the Potted Plant class and Stair class. Table 1 states the detail. It
is because that human categorize 3D models according to their semantics in the real
life, instead of their shape.
Table 1. Mistakes of manual categorization of PSB

One Story Home

Barn

Potted Plant

Stair

To solve these problems, the paper conducts researches in two aspects: first, we
analyzes the influence of the value of weight on the combination performance, and
proposes an method, which automatically decide the value of the fixed weight; second, we introduces an efficient way for categorizing 3D models based on clustering
result.
The rest of the paper is organized as follows: Section 2 introduces the automatic
combination method; Section 3 states the categorization based on clustering result;
Section 4 gives the experimental results of PSB; and Section 5 summarizes the paper.

2 An Automatic Decision Method of Features’ Fixed-Weight
When combining different shape features with fixed weight, the distance dcom between
model q and model o is computed as follows:
l

d com ( q, o) = ∑ wi
i =1

d i ( q, o )
max(d i (q))

(1)

Where l is the number of the different shape features, wi is the fixed weight of the ith
shape feature, di(q, o) is the distance between q and o under the ith shape feature vector, and max(di(q)) is maximum distance of q and the others. Previous researches
show that the Manhattan distance performs better than the Euclidian distance, thus the
paper adopts the Manhattan distance in computing di(q, o).

Studies on Shape Feature Combination and Efficient Categorization of 3D Models

99

In this paper, four kinds of feature extraction methods are adopted and 5 sets of
feature vectors are obtained from PSB. The detail is stated as follows: (1) the shape
feature extracting method based on depth-buffer [11], termed DBD, which obtains the
feature vector with 438 dimensions; (2) the method based on EDT [12], termed NEDT,
which obtains the vector with 544 dimensions; (3) the method based on spherical
harmonic [13], which obtains two sets of vectors with 32 dimensions and 136 dimensions, termed RSH-32 and RSH-136 respectively; (4) the method performing the
spherical harmonic transformation on the voxelized models, termed SHVF, which
obtains the feature vector with 256 dimensions.
We conduct experiment on PSB to analyze the influence of the value of wi on the
combination performance. Table 2 evaluates the performance of combining any two
out of 5 different features of PSB. The weight of each feature is equal and the criterion R-precision is adopted [8]. It can be seen that there co-exist the good cases, like
combining DBD and NEDT, and the bad cases, like combining DBD and RSH-32.
But if the fixed weight (4:4:2:1:1) decided according to our experience is adopted, the
performance is much better.
Table 2. Combination performance comparision under different fixed weights
DBD NEDT
wi

RSH
-136

RSH
-32

SHVF DBD

NEDT

RSH
-136

RSH
-32

SHVF

1

1

1

1

1

4

4

2

1

1

+DBD

0.354

-- --

-- --

-- --

-- --

0.354

-- --

-- --

-- --

-- --

+NEDT

0.390

0.346

-- --

-- --

-- --

0.390

0.346

-- --

-- --

-- --

+RSH-136 0.364

0.376

0.292

-- --

-- --

0.372

0.378

0.292

-- --

-- --

+RSH-32

0.283

0.286

0.258 0.168

-- --

0.351

0.343

0.279 0.168

+SHVF

0.308

0.308

0.286 0.204

0.201

0.360

0.350

0.299 0.204 0.201

-- --

This experiment shows that the appropriate value of wi can greatly improve the
combination performance. Although wi decided due to experience performs well, it
has the limitations like time consuming and hard to popularize.
Thus, it is necessary to automatically decide wi. To accomplish this task, we suppose that if a feature is the best for most models, its weight should be the highest. And
if one feature is the best for a model, its weight should be summed by 1/N, where N is
the total number of models. As for a set of classified 3D models, we follow the “winner-take-all” rule. It means that if the ith feature is the best for the jth class Cj of models, wi is summed by nj/N, where nj is the size of Cj.
Finally, states the automatic decision formula of the fixed-weights wi as follows:

∑ f (C )* n

nClass

wi =

j =1

i

j

N

j

(2)

100

T. Lv et al.

Where nClass is the number of the classes of models; fi(Cj)=1, iff the R-precision of the
l

ith feature is the highest for Cj, otherwise fi(Cj)=0. And

∑w
i =1

i

= 1.

Obviously, the proposed method can automatically decide the fixed weight for a
new shape feature by re-computing the Formula (2). During this process, the weights
of the existing features are also adjusted.

3 Efficient Categorization of 3D Models Based on Clustering
Result
As an unsupervised technique, cluster analysis technique is a promising candidate for
categorizing 3D models. It is good at discovering the concentration situation of the
feature vectors without prior knowledge. Since the models with similar feature are
grouped together and their feature reflects their shape, the clustering result can be
considered as a categorization of 3D models based on their shape. Ref. [10] performs
the research in this field. However, it relies on just one kind of shape feature, thus the
clustering result is highly sensitive to the performance of shape feature.
In contrast, the paper adopts the proposed fix-weighted feature combination
method and achieves a much better and more stable shape descriptor of 3D model.
The distance among models is computed according to Formula (1) and (2).
The X-means algorithm is selected to analyze the shape feature set of 3D models.
X-means is an important improvement of the well known method K-means. To overcome the highly dependency of K-means on the pre-decided number k of clusters, Xmeans requires but not restricts to the parameter k. Its basic idea is that: in an iteration
of clustering, it splits the center of selected clusters into two children and decides
whether a child survives. During clustering, the formula BIC(c x)=L(x c)k(m+1)/2*logn is used to decide the appropriate opportunity to stop clustering, where
L(x c) is the log-likelihood of dataset x according to the model c, and m is the dimensionality of the data. In this way, the appropriate number of clusters can be automatically decided.
Although X-means is efficient in classifying models according to their shape, there
still exist mistakes in the clustering result for two reasons:

｜

｜

｜

(1) Due to the complexity and diversity of models’ shape, it is very difficult to describe all shapes. The combination of different shape features can partially solve this
problem, but still has its limit.
(2) X-means may make clustering mistakes. Up to now, it seems that the clustering
process ensure most data is clustered into the right groups, but not every data.
Thus, we import human correction to correct the mistakes lies in the clustering result. To avoid mistakes caused by manual intervene, like those in Table 1, we make
the restriction that a user can just delete some models from a cluster or delete the
whole cluster. And the pruned models are considered as the wrongly categorized and
are labeled as “unclassified”.
Finally, the refined clustering result is treated as the categorization of 3D models.

Studies on Shape Feature Combination and Efficient Categorization of 3D Models

101

In comparison with the pure manual work, the categorization base on clustering result is much more efficient and objective. The clustering technique not only shows the
number of classes according to models’ shape, but also states the member of a class.

4 Experiment and Analysis
We conduct series experiments on the standard 3D model database, Princeton Shape
Benchmark, which owns 1814 models. And the 5 sets of shape feature vector introduced in Section 2 are used for combination.
First, we analyze the performance of the automatic fix-weighted combination. According to Formula (2), the automatic fixed weight for 5 features are DBD=0.288,
NEDT=0.373, RSH-136=0.208, RSH-32=0.044 and SHVF=0.087. And Table 3 states
the R-Precision and improvement after combining any two features for PSB. Compared with Table 2, the performance of the automatic fix-weighted combination is
much better. The highest improvement is 24%=((0.208-0.168)/ 0.168), while the best
combination improves by 9.6%=((0.388-0.354)/0.354).
Table 3. The performance of combining two features based on the automatic fixed weight
DBD

NEDT

RSH-136

RSH-32

SHVF

R-Precision/Improvement
+DBD

0.354/--

-- --

-- --

-- --

-- --

+NEDT

0.388/+9.6%

0.346/--

-- --

-- --

-- --

+RSH-136

0.368/+4.8%

0.378/+9.3%

0.292/--

-- --

-- --

+RSH-32

0.360/+1.7%

0.353/+2.0%

0.298/+2.1%

0.168/--

-- --

+SHVF

0.356/+0.6%

0.350/+1.2%

0.302/+3.4%

0.208/+24%

0.201/--

Fig. 1. states the Precision-Recall curves along with R-Precision of 5 features, the
combination of 5 features based on equal fixed weight (Equal Weight), the combination using fixed weight (4:4:2:1:1) decided by experience (Experience Weight), and
the combination adopting the proposed automatic fixed weight (Automatic Weight).
It can be seen that the proposed method is the best under all criterions. It achieves
the best R-Precision 0.4046, which is much better than that of the Equal Weight
0.3486 and is also slightly better than the Experience Weight 0.4021. And its performance improved by 14.5% than the best single feature DBD.
After combining 5 features based on the proposed method, we adopt X-means to
analyze the PSB, and 130 clusters are finally obtained. In scanning these clusters, we
found that most clusters are formed by the models with similar shape, like the cluster
C70, C110, C112, C113 in Table 4. However, there also exist mistakes, such as C43 in
Table 4. After analyzing the combined feature of those wrong models, we find that
the mistakes are mainly caused by the shape feature, instead of clustering.

102

T. Lv et al.

Fig. 1. Performance comparison adopting Precision-Recall and R-Precision
Table 4. Detail of some result clusters of PSB

C70

C110

C112

Studies on Shape Feature Combination and Efficient Categorization of 3D Models

103

Table 4. (continued)

C113

C43

Then, we select 3 students that never contact these models to refine the clustering
result. At least two of them must reach an agreement for each deletion. In less than 2
hours, including the time costs on arguments, they labeled 202 models as the unclassified out of 1814, viz. 11.13%, and 6 clusters out of 130 are pruned, viz. 4.6%.
Obviously, the clustering result is a valuable reference for categorizing 3D models.
Even if the refinement time is included, the categorization based on clustering result
is much faster than the pure manual work, which usually costs days and is exhaustive.

5 Conclusions
The paper proposes a combination method, which automatically decides the fixed
weights of different shape features. Based on the combined feature, the paper categorizes 3D models according to their shape. Experimental result shows that the proposed
method shows good performance not only in improving retrieval performance but also
in categorization. Future work will concentrate on the study of clustering ensemble to
achieve a much stable clustering result of 3D models.

Acknowledgements
This work is sponsored by Foundation for the Doctoral Program of the Chinese Ministry of Education under Grant No.20060183041 and the Natural Science Research
Foundation of Harbin Engineering University under the grant number HEUFT05007.

References
[1] T.Funkhouser, et al. A Search Engine for 3D Models. ACM Transactions on Graphics.22
(1), (2003) 85-105.
[2] Yubin Yang, Hui Li, Qing Zhu. Content-Based 3D Model Retrieval: A Survey. Chinese
Journal of Computer. (2004), Vol. 27, No. 10, Pages: 1298-1310.

104

T. Lv et al.

[3] Chenyang Cui, Jiaoying Shi. Analysis of Feature Extraction in 3D Model Retrieval.
Journal of Computer-Aided Design & Computer Graphics. Vol.16, No.7, July (2004).
pp. 882-889.
[4] Shilane P., Min P., Kazhdan M., Funkhouser T.. The Princeton Shape Benchmark. In
Proceedings of the Shape Modeling International 2004 (SMI'04), Genova, Italy, June
2004. pp. 388-399.
[5] Feature Combination and Relevance Feedback for 3D Model Retrieval. The 11th International Conference on Multi Media Modeling (MMM 2005), 12-14 January 2005, Melbourne, Australia. IEEE Computer Society 2005. pp. 334-339.
[6] Ryutarou Ohbuchi, Yushin Hata,Combining Multiresolution Shape Descriptors for Effective 3D Similarity Search Proc. WSCG 2006, Plzen, Czech Republic, (2006).
[7] Atmosukarto I., Wee Kheng Leow, Zhiyong Huang. Feature Combination and Relevance
Feedback for 3D Model Retrieval. Proceedings of the 11th International Multimedia
Modelling Conference, (2005).
[8] R. Baeza-Yates, B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley,
(1999).
[9] Dan Pelleg, Andrew Moore. X-means: Extending K-means with Efficient Estimation of
the Number of Clusters. In Proc. 2000 Int. Conf. on Data Mining. (2000).
[10] Tianyang Lv, etc. An Auto-Stopped Hierarchical Clustering Algorithm for Analyzing 3D
Model Database. The 9th European Conference on Principles and Practice of Knowledge
Discovery in Databases. In: Lecture Notes on Artificial Intelligent, Vol. 3801, pp.
601 – 608.
[11] M. Heczko, D. Keim, D. Saupe, and D. Vranic. Methods for similarity search on 3D databases. Datenbank-Spektrum, 2(2):54–63, (2002). In German.
[12] H. Blum. A transformation for extracting new descriptors of shape. In W. Wathen-Dunn,
editor, Proc. Models for the Perception of Speech and Visual Form, pages 362{380,
Cambridge, MA, November 1967. MIT Press.
[13] Kazhdan Michael , Funkhouser Thomas. Harmonic 3D shape matching [A]. In : Computer Graphics Proceedings Annual Conference Series , ACM SIGGRAPH Technical
Sketch , San Autonio , Texas , (2002)

