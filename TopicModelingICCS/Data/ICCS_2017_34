Available online at www.sciencedirect.com

ScienceDirect
Procedia
108CProcedia
(2017) 907–916
This space
isComputer
reservedScience
for the
header, do not use it

This space is reserved for the Procedia header, do not use it
This space is reserved for the Procedia header, do not use it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Agent-based Evolutionary and Memetic
Agent-based
and Memetic
Black-boxEvolutionary
Discrete Optimization
Agent-based
Evolutionary
and Memetic
Black-box
Discrete
Optimization
Michal Kowol, Kamil
Pietak, Marek
Kisiel-Dorohinicki,
and Aleksander Byrski
Black-box
Discrete
Optimization
Michal
Kowol,
Kamil
Pietak,
Kisiel-Dorohinicki,
and Aleksander
Byrski
AGH
University
of Science
and Marek
Technology,
Al. Mickiewicza 30, 30-059
Krakow, Poland
Michal Kowol,michal.kowol@gmail.com,{kpietak,doroh,olekb}@agh.edu.pl
Kamil Pietak, Marek Kisiel-Dorohinicki, and Aleksander Byrski
AGH University of Science and Technology, Al. Mickiewicza 30, 30-059 Krakow, Poland
AGH University
of Science and Technology, Al. Mickiewicza 30, 30-059 Krakow, Poland
michal.kowol@gmail.com,{kpietak,doroh,olekb}@agh.edu.pl
michal.kowol@gmail.com,{kpietak,doroh,olekb}@agh.edu.pl

Abstract
Hybridizing agent-based paradigm with evolutionary or memetic computation can enhance the
Abstract
field
of meta-heuristics in a significant way, giving to usually passive individuals autonomy
Abstract
Hybridizing agent-based paradigm with evolutionary or memetic computation can enhance the
and
capabilities
of perception
and with
interaction
with othermemetic
ones. Incomputation
the article, can
an evolutionary
Hybridizing
agent-based
paradigm
evolutionary
the
field
of meta-heuristics
in
a significant
way, giving or
to usually passive
individualsenhance
autonomy
multi-agent
system
(EMAS)
is
applied
to
solve
difficult
discrete
benchmark
problems
without
field capabilities
of meta-heuristics
in a significant
way, giving
to usually
passive
individuals
autonomy
and
of perception
and interaction
with other
ones. In
the article,
an evolutionary
any
domain-specific
knowledge—thus
they may
be other
calledones.
“black-box”
ones. As
a means for
and capabilities
of perception
interaction
the article,
an evolutionary
multi-agent
system
(EMAS) isand
applied
to solvewith
difficult
discreteIn
benchmark
problems
without
comparison,
a
parallel
evolutionary
algorithm
(constructed
along
with
Michalewicz
model)
vermulti-agent
system (EMAS)
is appliedthey
to solve
discrete
benchmark
without
any
domain-specific
knowledge—thus
maydifficult
be called
“black-box”
ones.problems
As a means
for
sus
evolutionary
and
memetic
versions
of
EMAS
are
used.
The
obtained
results
point
out
that
any domain-specific
they may
be called along
“black-box”
ones. As amodel)
meansverfor
comparison,
a parallelknowledge—thus
evolutionary algorithm
(constructed
with Michalewicz
EMAS
is significantly
more
efficient algorithm
than classical
evolutionary
algorithms
and also finds
better
comparison,
a parallel
evolutionary
(constructed
along
with Michalewicz
model)
versus
evolutionary
and memetic
versions of EMAS
are used. The
obtained
results point
out that
results
in the examined
problem
instances.
sus evolutionary
and memetic
versions
of classical
EMAS are
used. The algorithms
obtained results
point
out
that
EMAS
is significantly
more efficient
than
evolutionary
and also
finds
better
EMAS
is significantly
more
than
evolutionary
algorithms and
also finds
better
Keywords:
Agent-based
computing,
metaheuristics,
global optimization,
memetic
algorithms
©
2017 The
Authors.
Published
byefficient
Elsevier
B.V. classicaldiscrete
results
in
the
examined
problem
instances.
Peer-review
responsibility
of the scientific
committee of the International Conference on Computational Science
results in under
the examined
problem
instances.
Keywords: Agent-based computing, metaheuristics, discrete global optimization, memetic algorithms
Keywords: Agent-based computing, metaheuristics, discrete global optimization, memetic algorithms

1 Introduction
1
Introduction
Michalewicz
and Fogel in [21] have proposed several reasons why a certain optimization problem
1
Introduction
may be considered difficult. Firstly, the number of possible solutions may be too large to

Michalewicz and Fogel in [21] have proposed several reasons why a certain optimization problem
perform an exhaustive
for proposed
the best answer.
Or thewhy
problem
mayoptimization
be so complex that
Michalewicz
and Fogel
insearch
[21] have
several reasons
a certain
may be considered
difficult.
Firstly,
the number
of possible
solutions
may be too problem
large to
in
order
to
provide
any
feasible
answer,
a
simplified
model
must
be
used.
It also
may
happen
may
be considered
difficult.
the number
solutions
becomplex
too large
to
perform
an exhaustive
search Firstly,
for the best
answer. ofOrpossible
the problem
maymay
be so
that
that
the
evaluation
function
describing
the
quality
of
the
solutions
is
noisy
or
varies
with
perform
an
exhaustive
search
for
the
best
answer.
Or
the
problem
may
be
so
complex
that
in order to provide any feasible answer, a simplified model must be used. It also may happen
time
andtotherefore
solutions
are sought.
Certain search
problems,
which
fallmay
intohappen
one of
in
order
provide many
any
feasible
answer,
athe
simplified
be used.
It also
that
the evaluation
function
describing
quality model
of themust
solutions
is noisy
or varies
with
these
categories,
are
perceived
to
be
difficult
per
se,
because
their
domains
are
very
hard
or
that
the evaluation
function
describing
the quality
the solutions
is which
noisy fall
or varies
with
time and
therefore many
solutions
are sought.
Certainofsearch
problems,
into one
of
even
impossible
to
be
described
and
explored,
using
conventional
analytical
methods
(see,
e.g.
time
thereforearemany
solutions
aredifficult
sought. per
Certain
search problems,
which
intohard
one or
of
these and
categories,
perceived
to be
se, because
their domains
arefall
very
combinatorial
optimization
problems
[24]). The
setting
of such
problems
is sometimes
called
these
categories,
beexplored,
difficult
per
se,conventional
because
their
domains
are very(see,
hard
or
even impossible
toare
beperceived
describedto
and
using
analytical
methods
e.g.
“black-box
scenario”
even
impossible
to be[10].
described
and explored,
using
conventional
analyticalismethods
(see,
e.g.
combinatorial
optimization
problems
[24]). The
setting
of such problems
sometimes
called
In
the
cases
of such problems,
it is important to have ready one, or better more generalcombinatorial
optimization
“black-box scenario”
[10]. problems [24]). The setting of such problems is sometimes called
purpose
optimization
algorithms. Obviously, keeping in mind the famous no free lunch theorem
“black-box
scenario”
[10].
In the cases
of such
problems, it is important to have ready one, or better more general[26],Inone
can
be
sure
that
a certain,
evidently
reliable
solution,
to
all generalpossible
theoptimization
cases of such
problems,
it iseven
important
to in
have
ready
one, orapplied
better
more
purpose
algorithms.
Obviously,
keeping
mind
the famous
no
free lunch
theorem
problems,
yields
only
average
results.
Therefore
having
general-purpose
optimization
algorithms
purpose
Obviously,
keeping inreliable
mind the
famousapplied
no free to
lunch
theorem
[26], oneoptimization
can be sure algorithms.
that a certain,
even evidently
solution,
all possible
is
a good
idea,bebut
this
often
becomeseven
a starting
point for further
research,
e.g.totuning
them
[26],
one can
sure
that
a results.
certain,
evidently
solution,
applied
all
possible
problems,
yields only
average
Therefore
havingreliable
general-purpose
optimization
algorithms
problems,
yieldsbut
onlythis
average
Therefore
having
general-purpose
optimization
algorithms
is a good idea,
oftenresults.
becomes
a starting
point
for further research,
e.g. tuning
them
1
is a good idea, but this often becomes a starting point for further research, e.g. tuning them
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.173

1
1

908	

Agent-based Evolutionary and Michal
Memetic.
. . et al. / Procedia ComputerKowol,
Kisiel-Dorohinicki
and Byrski
Kowol
SciencePietak,
108C (2017)
907–916

Evolutionary island

individual
genotype

individual
genotype
fitness

fitness

individual
genotype

Evolutionary island
selection

energy

genotype

agent
genotype

crossover
mutation
individual
genotype
fitness

fitness

genotype

agent
energy

fitness

individual
genotype

agent

evaluation

individual
genotype
fitness

energy

agent
high energy:
reproduction

genotype

evaluation and
energy transfer

energy

genotype

agent

low energy:
death

energy

I
I

Evolutionary island
I
I
I
I
I
I

migrations

energy

(a) Parallel evolutionary algorithm (PEA)

Evolutionary island
A
A
A
A

A
A

energy

genotype

imigration

Evolutionary island
I
I
I
I

agent
genotype

agent

emigration

Evolutionary island
A
A
A
A
A
A

migrations

(b) Evol. multi-agent system (EMAS)

Figure 1: Schematic presentation of the algorithms discussed in the paper [18]
to solve particular problems, utilizing dedicated operators, data transformations etc. In the
domain of evolutionary computing, this means that one has to search for particular operators
and their parameters, keeping in mind intrinsic characteristics of the problem tackled.
In this contribution, a hybrid evolutionary-agent [16] approach to solving optimization problems, namely an Evolutionary Multi-Agent System (EMAS), is studied. For over 15 years, it
proved to be an efficient and effective technique for solving a variety of difficult optimization
problems [6]. Here we focus on applying its classical (purely evolutionary) and memetic variants
to difficult discrete problems that can be treated as black-box ones.
The paper is a follow-up of the paper [18], adding the memetic versions of the tested computing systems to the comparison and presents a more detailed study of the computing results.
After introduction and descriptions of the systems, the problems considered are briefly presented and the study of experimental results along with the discussion are given. Finally the
paper is concluded.

2

Evolutionary and memetic agent-based optimization

Evolutionary algorithms have already proved to be effective universal techniques for solving
optimization problems [2].
EMAS (evolutionary multi-agent system), may perceived as “proactive” alternative to classical evolutionary computation techniques [17], hoped by the authors to relieve the evolutionary
metaheuristics from several inconsistencies with the real-life evolution, such as e.g. lack of global
control, and asynchronous reproduction. In this system, solutions (genotypes) are entrusted
to agents, handling and improving their solution during realization of several types of actions
available to them. In this way agents can reproduce, die or migrate among the islands. The
selection mechanism is implemented using resources (agents compete for the resources, only a
rich agent can reproduce, the poor agent will die) [8]. During meetings, agent exchange the
resources (the worse one gives a part of its resource to the better one). For the schematic view
on EMAS one can refer to the Fig. 1b. It is to note, that correctness of the EMAS as global
universal optimizer has been formally proven using Markov Chain based models, inspired by the
theoretical works of Michael Vose [4, 5]. EMAS has also many extensions, e.g. immunological
2

	

Agent-based Evolutionary and Michal
Memetic.
. . et al. / Procedia ComputerKowol,
Kisiel-Dorohinicki
and Byrski
Kowol
SciencePietak,
108C (2017)
907–916

one [7] and was applied to solve different single and multi-criteria problems.
Evolutionary algorithms may be further enhanced, by hybridization with local-search methods. Such techniques are nowadays called memetic algorithms [23]. In these algorithms, two
kinds of search-enhancements are usually implemented:
• Baldwinian local search—based on Baldwin theory stating that predispositions may be
inherited during reproduction, implemented usually as hybridization of local search in
the course of evaluation process in. The evaluated individual receives the fitness function
value computed for one of its possible descendants (effects of local-search starting from
this individual).
• Lamarckian local search—based on Lamarck theory stating that characteristics of individuals acquired in the course of life may be inherited by their descendants, implemented
usually as hybridization of mutation operator. The search for a mutated individual is
based not only stochastic one-time sampling from the solution space, it may be a much
more complex process, being an outcome of a local search starting from this individual.
Although both theories turned-out to be false, the meta-heuristics based on them are effective
in many problems (see, e.g., [19]).
In the experiments presented in this paper, Lamarckian memetic operator was applied.

3

Experiments

In the experiments, two computationally hard problems (having practical applications) were
used, namely:
• Low Autocorrelation Binary Sequence problem (LABS), that has been under intensive
study since 1960s by Physics and Artificial Intelligence communities. It has many applications in telecommunication, digital signal processing, high-precision interplanetary
radar measurements and many others [15]. One of the reason of high complexity of problem is that in LABS all elements are correlated. The second problem is that, LABS has
only few global optima for most values of L [11]. The search space is dominated by local
optima. In [13] Halim compares search space to a “golf field”, where global optima are
deep, isolated and are spreaded just like “golf holes”.
• Optimal Golomb Ruler (OGR) Golomb Ruler (n-marks) is an ordered, distinct, nonnegative, increasing sequence of integer numbers (g1 , g2 , . . . , gn ) such that gi < gi+1 and all
distances gj −gi for 1  i < j  n are unique [3]. Usually the first element of the sequence
g1 equals 0, moreover the last element an is the length of the ruler. Correct solutions of
this problem may find various applications in radio communication (signal interference),
coding theory, X-ray crystallography and radio astronomy (see, e.g., [20]). Finding the
shortest n-marks Golomb ruler is a very hard combinatorial problem. The search space
is vast and growing exponentially when increasing the number of marks [25].
The EA (Michalewicz model [1]) and was selected for comparing to EMAS, as a relatively
similar, general-purpose optimization algorithm, not utilizing any agent-oriented features. The
parameters of both systems were made as similar, as it was possible (e.g. tournament selection
was used for EA as it is very similar to meeting mechanism present in EMAS). In the cases of
variation operators (crossover and mutation) the were of course retained completely the same
for both systems. The efficiency was measured with regard to time, instead of system steps
3

909

910	

Agent-based Evolutionary and Michal
Memetic.
. . et al. / Procedia ComputerKowol,
Kisiel-Dorohinicki
and Byrski
Kowol
SciencePietak,
108C (2017)
907–916

(as it is usually difficult to compare EMAS and PEA in this way, because one system step
means something completely different in these two systems: in EA one step processes the whole
generation, while in EMAS—one agent).
In this paper we used the following local search algorithms:
• Random Mutation Hill Climbing (RMHC) [22] – in finite loop: choose a random place to
change – if it leads to higher fitness, then change the solution; start again.
• Steepest Descent Local Search (SDLS) [15] – in finite loop: find the place that leads to
the highest fitness gain; change the solution; start again.
• Tabu Search (TS) [15, 14, 9] – in finite loop: find the place that leads to the highest
fitness gain and is not in the tabu list; change the solution; add the changed place to the
tabu list for n-iterations; start again.

3.1

Experimental setup

In EA and EMAS, tournament selection with (tournament size 2). For LABS problem, uniform
recombination was used, while for Golomb Ruler problem, one point crossover was applied.
Number of mutated elements is proportional to size of the problem. In EA and EMAS without
Local Search algorithm population size, mutation probability and recombination probability
are 50, 0.5, 0.75 for LABS and 100, 0.2, 0.8 for Golomb, respectively. For all configurations
of MA and EMAS with Local Search algorithm mutation and recombination probability was
equal to 0.9. EMAS agents count at the beginning, energy of reproduction, death and transfer
are: 50, 45, 0, 5, respectively, for both problems. Each experiment was repeated 60 times
with the same parameter set and standard deviation was presented in the graphs in addition
to the actual results. Total execution time is 300 seconds for both problems (constituting the
stopping condition). In this paper we presented mean values of fitness (so-called merit factor
introduced by Golay [12]) with standard deviations of the best-so-far solution. The fitness
results presented in figures were scaled to [0; 1] interval, according to known optimal values for
each case (minimization assumed), while in tables, the fitness values were not scaled at all.
After an exhaustive preliminary research the following local search algorithms were selected
for our computations. For LABS we used RMHC and SDLS, algorithms was set to 50 steps for
both problems in every execution. In Golomb Problem we used TS with 10 steps of iterations.
Getting results for LABS and Golomb Ruler problems presented in this paper took about
275 hours of computations on a workstation with Intel Core 2 Quad Q8300 2.5 Ghz (4 cores),
8 GB of DDR3 RAM and with Windows 7 x64.

3.2

Experimental results

The results presented in this section are partially cited from [18], however they are significantly
extended (e.g. one of the most important extensions consists in introducing memetic versions
of the tested computing systems to the comparison).
One of well known EMAS features is lower number of fitness function calls needed to attain
a similar or better result than classic systems, and this effect may be observed in the conducted
experiments (see Table 1). In LABS (L = 201) EMAS this number was 22 times less than in
the case of EA, and in 14-marks Golomb Ruler the differences are even bigger – EA executed
fitness 208 times more than EMAS. For memetic versions of EA and EMAS, the number of
fitness function calls was lower in the case of EMAS. In the case of Golomb problem, EMAS
computed fitness 6 times less than EA did. For LABS with EMAS and RMHC as local search
4

	

Agent-based Evolutionary and Michal
Memetic.
. . et al. / Procedia ComputerKowol,
Kisiel-Dorohinicki
and Byrski
Kowol
SciencePietak,
108C (2017)
907–916

fitness function was executed 1.3 times less then in MA approach. In case of LABS with SDLS
the results were quite similar.
In Figs. 2, 3 and Tables 2, 3, 4, 5, 6 results for 11 instances of LABS and OGR problems
were presented. In these figures fitness was scaled to [0; 1] interval. In tables we presented
exact results (“Best” column represents the best found solution in this paper). Better result
(in comparison of two approaches) was written in bold.
To sum up, the results obtained for LABS, SDLS local search allowed to obtain the best
results (see Fig. 2), while of course EMAS was better considering the computational cost (cf.
Table 1). In the case of OGR, the best results were obtained by EMAS with TS local search
(see Fig. 3).
In those figures 1 means optimum. For all the tackled problems better solutions for more
difficult instances were found less likely than for easier instances.
To sum up, the presented research revealed that for all considered setups, EMAS turned
out to be better for considered problems (keeping in mind of course the dispersion of the
observations). Not always the memetic versions prevailed over the classical versions, namely in
the more difficult instances of the problems, it was wise to use a more complex algorithm.
Global optima were not always approached with similar accuracy, however the examined
EMAS and its memetic variants showed their potential as universal optimization technique,
and further adaptation of particular parameters of the searches, will probably yield better
results for particular instances of the problems.
Table 1: Fitness count
No Local Search
RMHC
SDLS

EA
2.7 × 106 ± 1.2 × 106
4.1 × 105 ± 1.1 × 105
2.4 × 105 ± 7.7 × 104

EMAS
1.2 × 105 ± 2.9 × 103
3.3 × 105 ± 3.2 × 103
2.3 × 105 ± 4.2 × 104

EA
2.5 × 107 ± 1.7 × 106
6.1 × 104 ± 5.6 × 103

EMAS
1.2 × 105 ± 2.8 × 103
1.1 × 104 ± 3.3 × 102

(a) Fitness count for LABS problem (L = 201)

No Local Search
TS

(b) Fitness count for OGR problem (14-marks)

4

Conclusion

In this paper, following already obtained preliminary results in the field of discrete optimization,
using agent-based methods, new and more in-depth results were shown. We tried to compare
EMAS with as similar as possible not-agent-based algorithms. It was quite hard to find a
proper competitor for EMAS, since it is a unique, one-of-a-kind system. We considered several
algorithms and we found PEA the most suitable for our needs. We configured as much as
possible parameters to maximize similarity between two systems.
EMAS turned out to be significantly better in the means of obtained final fitness in most of
the conducted tests than EA (especially when equipped with memetic local-search operators).
An additional observation can be made, that EMAS was better in some of harder instances
of the tackled problems, while simpler technique, namely PEA, prevailed in less demanding
computing tasks.
5

911

1.0

0.8

0.8

instance size

0.8

0.8

201

181

161

181

201
201

141

121

109

85

73

201

181

161

0.0
141

0.0
121

0.2

109

0.2

60

0.4

50

0.4

0.6

40

0.6

85

181

0.8
distance to optimum

0.8

73

141

(d) EMASRM HC
1.0

60

161

(c) MARM HC

(e) MASDLS

121

instance size

1.0

instance size

161

instance size

109

40

201

181

161

141

121

109

85

73

0.0
60

0.0
50

0.2

40

0.2

85

0.4

73

0.4

0.6

60

0.6

50

distance to optimum

1.0

50

141

(b) EMAS

1.0

40

121

instance size

(a) EA

distance to optimum

85

40

201

181

161

141

121

85

109

0.0
73

0.0
60

0.2

50

0.2

109

0.4

73

0.4

0.6

60

0.6

50

distance to optimum

1.0

40

distance to optimum

Kowol
SciencePietak,
108C (2017)
907–916
Agent-based Evolutionary and Michal
Memetic.
. . et al. / Procedia ComputerKowol,
Kisiel-Dorohinicki
and Byrski

distance to optimum

912	

instance size

(f) EMASSDLS

Figure 2: Relative distance to optimum for EA, EMAS, MARM HC , EMASRM HC , MASDLS ,
EMASSDLS for LABS problem
6

	

Kowol
SciencePietak,
108C (2017)
907–916
Agent-based Evolutionary and Michal
Memetic.
. . et al. / Procedia ComputerKowol,
Kisiel-Dorohinicki
and Byrski

Table 2: Final results of LABS without Local Search
Instance
40
50
60
73
85
109
121
141
161
181
201

Best
6.67
4.72
4.35
3.97
3.47
3.33
3.19
3.00
3.11
2.94
2.77
(a) EA

Mean ± σ
5.26 ± 0.45
4.32 ± 0.20
3.83 ± 0.18
3.46 ± 0.15
3.23 ± 0.12
2.97 ± 0.12
2.85 ± 0.11
2.78 ± 0.10
2.71 ± 0.12
2.68 ± 0.08
2.62 ± 0.06

Instance
40
50
60
73
85
109
121
141
161
181
201

Best
6.45
5.56
6.04
5.08
5.12
5.17
4.69
4.78
4.79
4.99
4.57

Mean ± σ
4.79 ± 0.44
4.71 ± 0.39
4.78 ± 0.40
4.58 ± 0.24
4.56 ± 0.20
4.43 ± 0.31
4.28 ± 0.19
4.39 ± 0.22
4.27 ± 0.21
4.29 ± 0.19
4.23 ± 0.17

(b) EMAS

Table 3: Final results of LABS with RMHC as Local Search
Instance
40
50
60
73
85
109
121
141
161
181
201

Best
7.41
8.17
6.47
6.11
5.39
4.63
4.40
4.07
3.80
3.68
3.73

Mean ± σ
7.24 ± 0.26
6.50 ± 0.50
5.72 ± 0.30
5.10 ± 0.31
4.70 ± 0.22
4.15 ± 0.17
3.94 ± 0.14
3.70 ± 0.13
3.52 ± 0.12
3.38 ± 0.12
3.26 ± 0.12

(a) MARM HC

Instance
40
50
60
73
85
109
121
141
161
181
201

Best
7.41
7.40
6.87
6.34
6.21
5.61
5.40
5.17
5.31
5.07
4.96

Mean ± σ
6.49 ± 0.31
6.15 ± 0.38
5.90 ± 0.29
5.68 ± 0.25
5.45 ± 0.22
5.17 ± 0.18
5.06 ± 0.16
4.88 ± 0.12
4.81 ± 0.15
4.71 ± 0.13
4.66 ± 0.13

(b) EMASRM HC

One of the most important feature of EMAS was significantly lower computational cost,
measured both using time counted from the beginning of computation, and number of fitness
function calls. The advantages of the former feature is self-evident, while for the latter, it
will be much more visible, when complex fitness functions are employed. Some of preliminary
results applied to inverse problems were actually obtained (see [27]), however in the near future,
continuation of this topic is envisaged, as well as further experiments with other practical and
benchmark problems.

Acknowledgment
This research was supported by AGH University of Science and Technology, Statutory Project,
and by the Faculty of Computer Science, Electronics and Telecommunications Dean’s Grant
for Ph.D. Students and Young Researchers.
7

913

914	

Michal Kowol
SciencePietak,
108C (2017)
907–916
Agent-based Evolutionary and Memetic.
. . et al. / Procedia Computer
Kowol,
Kisiel-Dorohinicki
and Byrski

Table 4: Final results of LABS with SDLS as Local Search
Instance
40
50
60
73
85
109
121
141
161
181
201

Mean ± σ
7.41 ± 0.00
7.90 ± 0.35
7.16 ± 0.46
6.46 ± 0.27
6.13 ± 0.30
5.65 ± 0.17
5.49 ± 0.16
5.30 ± 0.15
5.07 ± 0.13
4.94 ± 0.14
4.81 ± 0.11

Best
7.41
8.17
8.26
7.48
7.25
6.18
5.79
5.80
5.39
5.52
5.15

Instance
40
50
60
73
85
109
121
141
161
181
201

(a) MASDLS

Best
6.90
7.06
7.20
6.73
6.43
5.86
5.65
5.84
5.43
5.41
5.19

Mean ± σ
6.38 ± 0.38
5.95 ± 0.34
5.89 ± 0.37
5.63 ± 0.26
5.57 ± 0.29
5.37 ± 0.18
5.26 ± 0.16
5.14 ± 0.15
5.00 ± 0.13
4.95 ± 0.14
4.87 ± 0.10

(b) EMASSDLS

Table 5: Final results of OGR without Local Search
Instance
7
8
9
10
11
12
13
14
15
16
17

Best
30
41
60
77
98
130
158
206
255
307
379

Mean ± σ
25.93 ± 1.31
37.23 ± 1.68
50.85 ± 2.74
68.45 ± 3.75
89.62 ± 4.22
114.13 ± 6.36
144.65 ± 7.35
180.88 ± 10.70
222.15 ± 15.67
275.64 ± 14.99
330.70 ± 17.39

(a) EA

Instance
7
8
9
10
11
12
13
14
15
16
17

Best
25
34
49
67
92
121
165
213
272
326
384

Mean ± σ
26.15 ± 0.96
35.20 ± 1.52
42.14 ± 2.44
56.27 ± 3.39
75.95 ± 5.70
99.89 ± 8.03
134.79 ± 12.83
178.79 ± 16.37
235.37 ± 18.46
280.19 ± 20.21
337.23 ± 20.78

(b) EMAS

References
[1] T. Bäck, D. Fogel, and Z. Michalewicz. Vol. 1, Evolutionary Computation: Basic Algorithms
and Operators, Vol. 2, Evolutionary Computation: Basic Algorithms and Operators Advanced
Algorithms and Operators. Institute of Physics Publishing, Bristol and Philadelphia, 2000.
[2] T. Back, U. Hammel, and H.-P. Schwefel. Evolutionary computation: Comments on the history
and current state. IEEE Trans. on Evolutionary Computation, 1(1), 1997.
[3] Gary S Bloom and Solomon W Golomb. Applications of numbered undirected graphs. Proceedings
of the IEEE, 65(4):562–570, 1977.
[4] A. Byrski and R. Schaefer. Formal model for agent-based asynchronous evolutionary computation.
In 2009 IEEE Congress on Evolutionary Computation, pages 78–85, May 2009.
[5] A. Byrski, R. Schaefer, M. Smolka, and C. Cotta. Asymptotic guarantee of success for multi-agent
memetic systems. Bulletin of the Polish Academy of Sciences: Technical Sciences, 61(1):257–278.
[6] Aleksander Byrski, Rafal Dreżewski, Leszek Siwik, and Marek Kisiel-Dorohinicki. Evolutionary
multi-agent systems. The Knowledge Engineering Review, 30(2):171–186, 2015.

8

1.0

0.8

0.8

instance size

15

16

17
17

13

12

11

10

17

16

15

14

0.0
13

0.0
12

0.2

11

0.2

9

0.4

8

0.4

0.6

7

0.6

10

16

0.8
distance to optimum

0.8

9

14

(b) EMAS
1.0

8

15

(a) EA

7

13

instance size

1.0

(c) MAT S

14

instance size

12

7

17

16

15

14

13

12

11

0.0
9

0.0
10

0.2

8

0.2

11

0.4

9

0.4

0.6

10

0.6

8

distance to optimum

1.0

7

distance to optimum

Michal Kowol
SciencePietak,
108C (2017)
907–916
Agent-based Evolutionary and Memetic.
. . et al. / Procedia Computer
Kowol,
Kisiel-Dorohinicki
and Byrski

distance to optimum

	

instance size

(d) EMAST S

Figure 3: Relative distance to optimum for EA, EMAS, MAT S and EMAST S for OGR problem
[7] Aleksander Byrski and Marek Kisiel-Dorohinicki. Agent-Based Evolutionary and Immunological
Optimization, pages 928–935. Springer Berlin Heidelberg, Berlin, Heidelberg, 2007.
[8] K. Cetnarowicz, M. Kisiel-Dorohinicki, and E. Nawarecki. The application of evolution process in
multi-agent world (MAW) to the prediction system. In M. Tokoro, editor, Proc. of the 2nd Int.
Conf. on Multi-Agent Systems (ICMAS’96). AAAI Press, 1996.
[9] Iván Dotú and Pascal Van Hentenryck. A simple hybrid evolutionary algorithm for finding golomb
rulers. In Evolutionary Computation, 2005. The 2005 IEEE Congress on, volume 3, pages 2018–
2023. IEEE, 2005.
[10] Stefan Droste, Thomas Jansen, and Ingo Wegener. Upper and lower bounds for randomized search
heuristics in black-box optimization. Theory of Computing Systems, 39:525–544, 2006.
[11] José E Gallardo, Carlos Cotta, and Antonio J Fernández. Finding low autocorrelation binary
sequences with memetic algorithms. Applied Soft Computing, 9(4):1252–1262, 2009.
[12] M.J.E. Golay. The merit factor of long low autocorrelation binary sequences. IEEE Transactions
on Information Theory, 28(3), 1982.
[13] Steven Halim, Roland HC Yap, and Felix Halim. Engineering stochastic local search for the low

9

915

916	

Kowol
SciencePietak,
108C (2017)
907–916
Agent-based Evolutionary and Michal
Memetic.
. . et al. / Procedia ComputerKowol,
Kisiel-Dorohinicki
and Byrski

Table 6: Final results of OGR with TabuSearch as Local Search
Instance
7
8
9
10
11
12
13
14
15
16
17

Best
25
37
48
66
89
113
148
185
227
282
345

Mean ± σ
25.00 ± 0.00
34.85 ± 0.63
45.93 ± 1.06
62.30 ± 2.08
82.72 ± 2.59
106.85 ± 3.28
136.47 ± 4.53
172.56 ± 6.60
213.23 ± 7.45
258.90 ± 9.44
309.15 ± 11.55

(a) MAT S

[14]
[15]
[16]

[17]
[18]

[19]

[20]
[21]
[22]
[23]
[24]
[25]
[26]
[27]

10

Instance
7
8
9
10
11
12
13
14
15
16
17

Best
26
37
50
67
88
113
146
176
213
258
306

Mean ± σ
25.05 ± 0.22
35.18 ± 0.70
47.37 ± 1.33
63.33 ± 1.80
83.52 ± 2.60
107.35 ± 3.01
134.97 ± 4.60
165.88 ± 4.56
203.56 ± 5.57
242.20 ± 7.50
288.41 ± 10.11

(b) EMAST S

autocorrelation binary sequence problem. In Principles and Practice of Constraint Programming,
pages 640–645. Springer, 2008.
Pascal Van Hentenryck Ivn Dot. A note on low autocorrelation binary sequences. Lecture Notes
in Computer Science, 4204, 2006.
Antonio J. Fernndez Jos E. Gallardo, Carlos Cotta. Finding low autocorrelation binary sequences
with memetic algorithms. Applied Soft Computing, 9, 2009.
Marek Kisiel-Dorohinicki, Grzegorz Dobrowolski, and Edward Nawarecki. Agent populations as
computational intelligence. In Leszek Rutkowski and Janusz Kacprzyk, editors, Neural Networks
and Soft Computing, Advances in Soft Computing. Physica-Verlag, 2003.
Marek Kisiel-Dorohinicki, Grzegorz Dobrowolski, and Edward Nawarecki. Agent Populations as
Computational Intelligence, pages 608–613. Physica-Verlag HD, Heidelberg, 2003.
Michal Kowol, Aleksander Byrski, and Marek Kisiel-Dorohinicki. Agent-based evolutionary computing for difficult discrete problems. Procedia Computer Science, 29(0):1039 – 1047, 2014. 2014
International Conference on Computational Science.
K.W.C Ku and M.W. Mak. Exploring the effects of lamarckian and baldwinian learning in evolving
recurrent neural networks. In Proc. of 1997 IEEE Int. Conf. on Evolutionary Computation. IEEE,
1997.
GD Martin. Optimal convolutional self-orthogonal codes with an application to digital radio. In
ICC’85; International Conference on Communications, volume 1, pages 1249–1253, 1985.
Z. Michalewicz and D.B. Fogel. How to Solve It: Modern Heuristics. Springer, 2004.
Melanie Mitchell. An Introduction to Genetic Algorithms. MIT Press, 1998.
Pablo Moscato. Memetic algorithms: a short introduction. In New ideas in optimization, pages
219–234, Maidenhead, UK, England, 1999. McGraw-Hill Ltd., UK.
C.H. Papadimitriou and K. Steiglitz. Combinatorial Optimization: Algorithms and Complexity.
Dover Publications, Inc., 1998.
James B Shearer. Some new optimum golomb rulers. Information Theory, IEEE Transactions on,
36(1):183–184, 1990.
David H. Wolpert and William G. Macready. No free lunch theorems for optimization. IEEE
Transactions on Evolutionary Computation, 1(1):67–82, 1997.
Krzysztof Wróbel, Pawel Torba, Maciej Paszyński, and Aleksander Byrski. Evolutionary multiagent computing in inverse problems. Computer Science (AGH), 14(3), 2013.

