AMEEPAR: Parallel Morphological Algorithm for
Hyperspectral Image Classification on Heterogeneous
Networks of Workstations
Antonio Plaza, Javier Plaza, and David Valencia
Department of Computer Science, University of Extremadura
Avda. de la Universidad s/n, E-10071 Caceres, Spain
{aplaza, jplaza, davaleco}@unex.es

Abstract. Hyperspectral imaging is a new technique in remote sensing that
generates hundreds of images corresponding to different wavelength channels
for the same area on the surface of the Earth. Most available techniques for hyperspectral image classification focus on analyzing the data without incorporating the spatial information; i.e. the data is treated not as an image but as an unordered listing of spectral measurements where the spatial coordinates can be
shuffled arbitrarily without affecting the final analysis. Despite the growing interest in the development of techniques for interpretation and classification of
such high-dimensional imagery, only a few efforts devoted to the design of parallel implementations exist in the open literature. In this paper, we describe
AMEEPAR, a parallel morphological algorithm that integrates the spatial and
spectral information. The algorithm has been specifically optimized in this work
for execution on heterogeneous networks of workstations. The parallel properties and classification accuracy of the proposed approach are evaluated using
four networks of workstations distributed among different locations, and a massively parallel Beowulf cluster at NASA’s Goddard Space Flight Center.

1 Introduction
The rapid development of space and computer technologies has made possible to
store a sheer volume of remotely sensed image data, collected from heterogeneous
sources. In particular, NASA is continuously gathering imagery data with hyperspectral Earth observing sensors such as Jet Propulsion Laboratory’s Airborne Visible/Infrared Imaging Spectrometer (AVIRIS)1, which covers the wavelength region
from 0.4 to 2.5 µm using 224 spectral channels at nominal spectral resolution of 10
nm (see Fig. 1). The incorporation of hyperspectral sensors on airborne/satellite platforms is currently producing a nearly continual stream of high spatial and spectral
resolution data, and this high data volume demands efficient and robust data analysis
techniques.
The underlying assumption governing most available techniques for hyperspectral
analysis is that each pixel vector measures the response of multiple underlying materials at each site. A hyperspectral image (sometimes referred to as “image cube”) is
often a combination of two situations: a few sites in a scene are pure macroscopic
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part III, LNCS 3993, pp. 24 – 31, 2006.
© Springer-Verlag Berlin Heidelberg 2006

AMEEPAR: Parallel Morphological Algorithm for Hyperspectral Image Classification

25

materials, e.g., soil or water, but many other are mixtures of materials. For instance,
the vegetation pixel in Fig. 1 may comprise a mixture of different types of vegetation,
soil, atmospheric interferers, etc. Further, most available techniques only use the spectral information available in the image data. Therefore, such techniques would yield
the same result for a data cube, and for the same data cube where the spatial positions
have been randomly permuted. By taking into account the complementary nature of
spatial and spectral information in simultaneous fashion, it is possible to alleviate the
problems related to each of them taken separately.

Fig. 1. Hyperspectral imaging. Each pixel is given by a vector of values or “spectral signature”.

While integrated spatial/spectral developments hold great promise, they also introduce new processing challenges. In turn, many applications require a quick response
(e.g., target detection for homeland defense/security purposes, risk/hazard prevention/response including wild land fire tracking, biological threat detection, monitoring
of oil spills and other types of chemical contamination). In recent years, several efforts have been focused on the incorporation of high-performance computing (HPC)
models in remote sensing applications. Unfortunately, only a few research efforts
devoted to HPC-based hyperspectral imaging exist in the open literature (which is
partly due to non-disclosure restrictions in some cases). This paper develops an efficient parallel algorithm for spatial/spectral analysis in heterogeneous computing environments2, which are expected to become a tool of choice in many on-going and
planned remote sensing missions. The method is a parallel version of the Automated
Morphological Endmember Extraction (AMEE) algorithm3, which integrates the
spatial and spectral information in the data. The paper is organized as follows. In the
following section, we introduce the AMEE algorithm and its parallel implementation.
The parallel algorithm is then evaluated using four networks of workstations and a
Beowulf cluster at NASA’s Goddard Space Flight Center. The paper concludes with
some remarks.

26

A. Plaza, J. Plaza, and D. Valencia

2 Parallel Algorithm for Hyperspectral Image Classification
The AMEEPAR algorithm is based on mathematical morphology3, a classic nonlinear
spatial processing technique that provides a remarkable framework to achieve the
desired integration of spatial and spectral responses. First, we provide an overview of
the AMEE algorithm. Then, we provide a description of its parallel implementation.
2.1 AMEE Algorithm
The AMEE algorithm relies on two basic morphological operations: erosion and dilation3. Let us denote by f (x, y ) the pixel vector at spatial coordinates (x, y ) of a hyperspectral scene., The erosion of f by B (a so-called “structuring element”) consists of
selecting the “minimum” pixel vector in the spatial neighborhood of f (x, y ) defined
by B. Similarly, the dilation of f by B consists of selecting the “maximum” pixel
vector (called endmember in hyperspectral analysis terminology). We provide below
a version of AMEE which is tuned for unsupervised classification of hyperspectral
data.
AMEE algorithm
Inputs: Image cube f , B , Number of iterations I max , Number of endmembers p.
Output: MEI image.
1.
2.

Set i = 1 and initialize MEI(x, y ) = 0 for each pixel.
Move B through all the pixels of f , defining a local spatial search area around
each f (x, y ) , and calculate the maximum and the minimum pixel at each Bneighborhood using morphological dilation and erosion, respectively, as follows:

( f ⊕ B )( x, y) = {f (x − s' , y − t'), (s' , t ') = arg max (s,t )∈Z 2 (B ){DB [ f (x − s, y − t )]}}
( f ΘB )( x, y) = {f (x + s' , y + t '), (s' , t ') = arg min (s ,t )∈Z 2 (B ){DB [ f (x + s, y + t )]}}

3.

4.
5.

6.

Update MEI(x, y ) at each pixel using MEI(x, y ) = SAD[( f ⊕ B )( x, y ), ( f ⊕ B )( x, y )] ,
where SAD is the spectral angle distance3, i.e., the arc cosine of the vector dot
product divided by the product of the norms.
Set i = i + 1 . If i = I max then go to step 4. Otherwise, set f = f ⊕ B and go to 2.
Select the set of p pixel vectors in f with higher associated score in the resulting MEI image (called endmember pixels) and form a unique spectral set of
q ≤ p pixels by calculating the SAD for all vector pairs. Estimate the fractional
abundance, α i (x, y ) , of those q signatures at f (x, y ) using a linear mixture model.
Obtain a classification label for each pixel f (x, y ) by assigning it to a class given
by the endmember with the highest fractional abundance score in that pixel. All
estimated abundance fractions {α1 (x, y ), α 2 (x, y ), ..., α q (x, y )} are compared, and the
one with the maximum value is found, say:
⎧
⎫
α i* (x, y ) , with i* = arg ⎨max{α i (x, y )}⎬ .
⎩1≤ i ≤ q
⎭

AMEEPAR: Parallel Morphological Algorithm for Hyperspectral Image Classification

27

2.2 AMEEPAR Algorithm
A major requirement for efficient parallel algorithms on distributed memory systems
is finding a data decomposition that minimizes the communication between the processors4. For that purpose, AMEEPAR adopts a spatial-domain partitioning approach,
in which the same pixel vector is never split among several processors (in spectraldomain parallel, the structuring element-based calculations made for each hyperspectral pixel need to originate from several processing elements, and thus require intensive inter-processor communication). A second important issue in the design of the
AMEEPAR is that redundant information (overlap borders) are added to local partitions to avoid accesses outside the partition domain when the structuring element
computation requires pixel vectors from other partitions5.
The algorithm has been implemented in the C++ programming language using
calls to message passing interface (MPI). It uses a master-slave paradigm in which the
master scatters hyperspectral data without creating partial data structures at the root.
For that purpose, we make use of MPI derived datatypes to directly scatter data structures, which may be stored non-contiguously in memory, in a single communication
step. In order to slice the available data into chunks, there is a need to balance the
workloads of k heterogeneous resources so that each processor Pi will accomplish a
share α i of the total workload, with αi ≥ 0 for 1 ≤ i ≤ k and

∑

k
i =1

αi =1.

AMEEPAR algorithm
Inputs: Image cube f , B , Number of iterations I max , Number of endmembers p.
Output: MEI image.
1.

Obtain necessary information about the heterogeneous system, including the
number of available processors, k, each processor’s identification number, {Pi }ik=1 ,
and processor cycle-times, {wi }ik=1 .

2.
3.
4.
5.

Determine the total volume of information, R, that needs to be replicated from the
original data volume, V, in accordance with the adopted border overlap strategy.
Let the total workload to be handled by the algorithm be given by W = V + R .
⎢
⎢
Set α i = ⎢
⎢
⎣

⎥
⎥
⎥ for all i ∈ {1,..., k } .
k
(
1 wi ) ⎥
i =1
⎦

(p

wi )

∑
For m = ∑ α
k

i =1

i

to (V + R ) find j ∈ {1,..., k } , so that w j ⋅ (α j + 1) = min{wi ⋅ (α i + 1)}ik=1

and set α k = α k + 1 .
6.

Use the resulting {α i }ik=1 to obtain a set of k spatial-domain heterogeneous parti-

7.
8.

tions of f , and send its corresponding partition to each processor along with B.
Broadcast B , I max , p to heterogeneous processors, and execute AMEE in parallel.
Collect all the individual classification results provided by each processor Pi ,
and merge them together to form a final classification image.

28

A. Plaza, J. Plaza, and D. Valencia

It should be noted that a homogeneous version of the AMEEPAR algorithm above
(called HomoAMEEPAR)5 can be obtained by rewriting step 4 as α i = p wi for all
i ∈ {1,..., k } , where wi is a constant communication speed between each processor pair.

3 Experimental Results
Before describing our results, we introduce the parallel computing architectures used
in experiments, which include four networks of workstations and a Beowulf cluster:
1.

Fully heterogeneous network. Consists of 16 different SGI, Solaris and Linux
workstations, and four communication segments. Table 1 shows the cycle-times
of the processors. The communication network consists of four communication
segments interconnected by three slower communication links with capacities
c (1,2 ) = 29.05 , c (2,3) = 48.31 , c (3,4 ) = 58.14 in milliseconds. Table 2 shows the capacity of all point-to-point communications, expressed as the time in milliseconds
to transfer a one-megabit message between each pair (Pi , Pj ) in the network.

2.

Fully homogeneous network. Consists of 16 identical Linux workstations with
processor cycle-time of w = 0.0131 seconds per megaflop, interconnected via a
homogeneous communication network with capacity c = 26.64 milliseconds.
Partially heterogeneous network. Formed by the set of 16 heterogeneous workstations in Table 1 but interconnected using the same homogeneous communication network with capacity c = 26.64 milliseconds.
Partially homogeneous network. Formed by 16 identical Linux workstations with
processor cycle-time of w = 0.0131 seconds per megaflop but interconnected using the heterogeneous communication network shown in Table 2.
Thunderhead Beowulf cluster. Formed by 256 identical 2.4 GHz Intel Xeon
nodes, each with 1 GB of memory and 80 GB of main memory (see
http://newton.gsf.nasa.gov/thunderhead).

3.

4.

5.

Table 1. Processor cycle-times (in seconds per megaflop) for the heterogeneous processors

P1

P2

P3

P4

P5

P6

P7

P8

P9

.005

.010

.020

.007

.010

.007

.007

.010

.007 .045

P10 P11 P12 P13 P14 P15 P16
.013

.013

.013

.013

.013

.013

According to a recent study2, the four networks of workstations above can be considered equivalent since they satisfy the following three principles: 1) they have the
same number of processors; 2) the average processor speed is the same in all cases;
and 3) the aggregate characteristics of the communication network are all the same.
At this point, we reiterate that the configuration of the four networks above was carefully designed to make sure that the three principles above were satisfied, and the
aggregate performance was the same.
The AMEEPAR algorithm (and its homogeneous version) were applied to a hyperspectral scene collected by the AVIRIS sensor, which consists of 2048x614 pixels,
224 spectral bands, and moderate spatial resolution (20-meter pixels). It was gathered
over the Indian Pines region in Indiana, and represents a challenging classification

AMEEPAR: Parallel Morphological Algorithm for Hyperspectral Image Classification

29

problem. Part of these 275 MB data set are available online, along with ground-truth,
from http://dynamo.ecn.purdue.edu/~biehl/MultiSpec. In experiments, the structuring
element size was fixed to B3x3 to reduce the amount of redundant computations3. The
number of iterations I max was increased from 1 to 5 (according to our implementation, increasing the value of I max is equivalent to considering a larger spatial context).
Finally, we set the number of endmembers to be extracted, p, to 16 after estimating
the intrinsic dimensionality of the data1.
Table 2. Capacity of links (measured by the time in milliseconds to transfer a one-megabit
message) for the heterogeneous communication network

P1
P2
P3
P4
P5
P6
P7
P8
P9
P10
P11
P12
P13
P14
P15
P16

P1

P2

P3

P4

P5

P6

P7

P8

P9 P10 P11 P12 P13 P14 P15 P16

19.2
19.2
19.2
48.3
48.3
48.3
48.3
96.6
96.6
154
154
154
154
154
154

19.2
19.2
19.2
48.3
48.3
48.3
48.3
96.6
96.6
154
154
154
154
154
154

19.2
19.2
19.2
48.3
48.3
48.3
48.3
96.6
96.6
154
154
154
154
154
154

19.2
19.2
19.2
48.3
48.3
48.3
48.3
96.6
96.6
154
154
154
154
154
154

48.3
48.3
48.3
48.3
17.6
17.6
17.6
48.3
48.3
106
106
106
106
106
106

48.3
48.3
48.3
48.3
17.6
17.6
17.6
48.3
48.3
106
106
106
106
106
106

48.3
48.3
48.3
48.3
17.6
17.6
17.6
48.3
48.3
106
106
106
106
106
106

48.3
48.3
48.3
48.3
17.6
17.6
17.6
48.3
48.3
106
106
106
106
106
106

96.6
96.6
96.6
96.6
48.3
48.3
48.3
48.3
16.3
58.1
58.1
58.1
58.1
58.1
58.1

96.6
96.6
96.6
96.6
48.3
48.3
48.3
48.3
16.3
58.1
58.1
58.1
58.1
58.1
58.1

154
154
154
154
106
106
106
106
58.1
58.1
14.2
14.2
14.2
14.2
14.2

154
154
154
154
106
106
106
106
58.1
58.1
14.2
14.2
14.2
14.2
14.2

154
154
154
154
106
106
106
106
58.1
58.1
14.2
14.2
14.2
14.2
14.2

154
154
154
154
106
106
106
106
58.1
58.1
14.2
14.2
14.2
14.2
14.2

154
154
154
154
106
106
106
106
58.1
58.1
14.2
14.2
14.2
14.2
14.2

154
154
154
154
106
106
106
106
58.1
58.1
14.2
14.2
14.2
14.2
14.2
-

Table 3. Execution times and classification accuracies on the four networks of workstations
Algorithm

I max
Fully heterogeneous network
Fully homogeneous network
Partially heterogeneous network
Partially homogeneous network
Classification accuracy (%)

AMEEPAR

HomoAMEEPAR

1

3

5

1

3

5

284
298
288
294
69.23

321
339
325
336
74.48

379
372
365
371
91.05

1456
281
1223
437
69.23

1528
317
1267
472
74.48

1589
355
1301
512
91.05

Table 3 shows the classification accuracies and execution times obtained by both
algorithms in the four considered networks of workstations. As expected, the execution times reported on Table 3 show that the heterogeneous algorithm was able to
adapt much better to fully (or partially) heterogeneous environments than the homogeneous version, which only performed satisfactorily on the fully homogeneous network. One can see that AMEEPAR was several times faster than its homogeneous
counterpart in the fully heterogeneous network, and also in both the partially

30

A. Plaza, J. Plaza, and D. Valencia

homogeneous and the partially heterogeneous networks. On the other hand, the HomoAMEEPAR algorithm only slightly outperformed its heterogeneous counterpart in
the fully homogeneous network. Table 3 also reveals that the performance of the
heterogeneous algorithm on the fully heterogeneous network was almost the same as
that evidenced by the homogeneous algorithm on the fully homogeneous network.
This reveals that the heterogeneous algorithm was very close to the optimal heterogeneous modification of the basic homogeneous one2.
In order to explore load balance of the two algorithms above on the four networks
of workstations, Table 4 shows the imbalance scores achieved by the different algorithms (implemented with I max set to 5 iterations). The imbalance is defined as
D = R max / R min , where R max and R min are the maxima and minima processor run
times, respectively. Therefore, perfect balance is achieved when D = 1 . In the table,
we report the imbalance considering all processors, D All , and also considering all
processors but the root, D Minus . In all cases, load balance was similar when the root
processor was not included, which means that the master node does not have high
computation load. It is also clear from Table 4 that the homogeneous algorithm executed on the heterogeneous network provided the highest values of D All and D Minus
(and hence the highest imbalance), while the heterogeneous algorithm always resulted
in values of D All and D Minus which were closer to 1, regardless of the platform where
it was run.
Table 4. Load balancing rates on the four networks of workstations
Algorithm

AMEEPAR

HomoAMEEPAR

Imbalance

D All

D Minus

D All

D Minus

Fully heterogeneous network
Fully homogeneous network
Partially heterogeneous network
Partially homogeneous network

1.09
1.16
1.11
1.13

1.02
1.07
1.03
1.05

1.51
1.08
1.44
1.33

1.47
1.02
1.41
1.26

Fig. 2. Scalability of AMEEPAR and HomoAMEEPAR on the Thunderhead Beowulf cluster

Finally, and with the ultimate goal of exploring issues of scalability and portability
of heterogeneous algorithms to existing massively parallel computing platforms (which
are mainly homogeneous in nature), we have also compared the performance of the

AMEEPAR: Parallel Morphological Algorithm for Hyperspectral Image Classification

31

two algorithms on the Thunderhead Beowulf cluster. Fig. 2 shows the speedups
achieved by AMEEPAR (and its homogeneous version) over a single-processor run of
the sequential AMEE algorithm on Thunderhead, all of them implemented with I max
set to 5. As Fig. 2 shows, the scalability of AMEEPAR was similar to that achieved by
its homogeneous prototype on the Beowulf cluster. Although AMEEPAR introduces
redundant calculations, which are expected to slow down the computation a priori, the
measured speedups tend to be higher for large structuring element sizes, a fact that
reveals that the proposed scheme scales better as the size of the problem increases. As
a result, the dominant issue in AMEEPAR is problem size, which makes the algorithm
particularly appealing for high-dimensional imaging applications. To conclude this
section, we must also note that AMEEPAR was able to provide near real-time classification performance in the Thunderhead cluster. The algorithm only required 8 seconds
to produce a result using 256 processors, and 30 seconds with 64 processors. This is a
relevant achievement, in particular, if we take into account that 1874 seconds were
required to process the entire data set using a single Thunderhead processor.

4 Conclusions
This paper provided an investigation of a parallel morphological technique to extract
relevant information from hyperspectral image data sets in heterogeneous computing
environments. Experimental results reveal that the proposed algorithm offers a simple,
yet highly scalable and relatively platform-independent solution in the context of hyperspectral image classification applications. Although many available approaches do
not take into account the spatial information explicitly (a fact that has been perceived
as an advantage for the development of parallel implementations), experimental results
in this paper suggest that spatial/spectral classification approaches may indeed be tuned
for “pleasingly parallel execution” due to the windowing nature of such algorithms,
and also because they can effectively balance the load in heterogeneous systems. The
proposed method seems ideally suitable for data mining applications, which previously
looked too computationally intensive due to the immense data archives common to
remote sensing problems. Combining the readily available computational power
offered by heterogeneous platforms with the new sensor instruments may introduce
major changes in the systems used for exploiting Earth and planetary data.

References
1. Green, R.O., et al.: Imaging Spectroscopy and the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS). Remote Sensing of Environment, 65 (1998) 227–248
2. Lastovetsky, A., Reddy, R.: On Performance Analysis of Heterogeneous Parallel Algorithms. Parallel Computing, 30 (2004) 1195–1216
3. Plaza, A., Martinez, P., Perez, R., Plaza, J.: Spatial/Spectral Endmember Extraction by Multidimensional Morphological Operations. IEEE Transactions on Geoscience and Remote
Sensing, 9 (2002) 2025–2041
4. Seinstra, F.J., Koelma, D., Geusebroek, J.M.: A Software Architecture for User Transparent
Parallel Image Processing. Parallel Computing 28 (2002) 967–993
5. Plaza, A., Valencia, D., Plaza, J.: Commodity Cluster-Based Parallel Processing of Hyperspectral Imagery. Journal of Parallel and Distributed Computing 66 (2006) 345–358

