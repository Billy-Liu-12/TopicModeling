Developing a Simulation Tool Box in MATLAB
and Using It for Non-linear Adaptive Filtering
Investigation
Oleg Gorokhov and Innokenti Semoushin
Ulyanovsk State University, 42 Leo Tolstoy Str., 432970 Ulyanovsk, Russia
gorohov@icbank.ru SemoushinIV@ulsu.ru http://staff.ulsu.ru/semoushin/

Abstract. In this paper we develop a special purpose tool box for complex computational tasks solution in the area of stochastic adaptive system design. The proposed tool box is used to analyze the inﬂuence of
diﬀerent factors on the quality of numerical algorithms.

1

Introduction

Modern system design requires high performance computational modelling tools.
MathCAD, MATLAB and Maple are examples. The complexity of problems in
the adaptive ﬁltering area often does not allow us to use the standard procedures
and tool boxes to analyze the problems even of small dimensions. The reason
lies in the amount of time necessary for computing while analyzing the inﬂuence
of a set of many factors on the algorithm performance. This raises the problem
of developing a special tool for complex system investigation.
The purpose of this paper is twofold. The ﬁrst goal is to develop an eﬃcient
tool box for speciﬁc problems in the ﬁeld of adaptive linear or non-linear ﬁltering.
The second part of the paper demonstrates the application of the designed tool
box and presents the simulations results. The core of the designed tool box is
implemented as a dynamic link library, and its interface part is made MATLABcompatible.

2

Adaptive Non-linear Filtering Problem

Consider the linear stochastic time-invariant discrete-time model
xt+1 = Φxt + Γ wt
zt = Hxt + vt

(1)

which is widely used in processing the experimental data for a state of dynamical
plants in stochastic environment. Here xt ∈ IRn is the state vector, zt ∈ IRm is the
This work was supported in part by the Russian Ministry of Education (grant
No. T02-03.2-3427).
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2658, pp. 436–445, 2003.
c Springer-Verlag Berlin Heidelberg 2003

Developing a Simulation Tool Box in MATLAB

437

measurement vector and {w0 , w1 , . . .} and {v1 , v2 , . . .} are zero-mean independent sequences of independent identically distributed random vectors wt ∈ IRq
and vt ∈ IRm with covariances Q and R respectively. Measurements are assumed
to be incomplete, i.e. m < n.
Classical approach to the state estimation for model (1) is that corresponding
to the Kalman ﬁltering. However, sometimes it is impossible to use the Kalman
ﬁlter if the system contains a predesigned part which is nonlinear by its nature.
When noise distributions are not Gaussian, optimal ﬁlter is not Kalman. In
these cases, the whole system should be characterized by nonlinear equations,
whose parameters are diﬃcult to optimize. For such situations, an adaptive (or
learning) approach seems to be the only possible way. It becomes absolutely
necessary if, for a variety of reasons, parameters of model (1) are not precisely
known and thus should be identiﬁed from experimental data [1], [2].
We assume that the initial time is placed at −∞ and adopt the non-restrictive
assumptions that R > 0, Q ≥ 0, and system (1) is stabilizable and completely
observable. Additionally, the spectral radius of Φ is assumed to be strictly less
than one to have all the processes in (1) wide-sense stationary. In the below
experiments, uncertainty inherent to (1) resides in Γ , Q and R only.
In the most case, the estimator yt ∈ IRn is given by a nonlinear functional
O(·) intended to generate a p-step-ahead (predicted) estimate of the state xt+p
using all available measurements zt−τ , 0 ≤ τ < ∞. Thus, we have
yt = O(zt−τ , 0 ≤ τ < ∞)
where each k-th component
series
m

ytk =

ytk

of yt is desribed by the discrete time Volterra

∞

∞

{

∞
(l)

(l)

hkld (τ1 , . . . , τd )zt−τ1 · · · zt−τd }

...

l=1 d=1 τ1 =0

(2)

τd =0

and where l = 1, 2, . . . , m denotes the component index in the vector of measurements zt , d is the order of nonlinearity of hkld (τ1 , . . . , τd ), the d-order kernel of
Volterra series. We assume the estimator to be stable so that {yt } is a wide-sense
stationary sequence.
Let the system error, original performance index and a problem to be solved
are as follows:
et = xt+p − yt ,
Jo = E{ et 2 } .
Problem 1. Given performance index Jo , formulate the auxiliary performance
index Ja depending on some available sequence εt so that
Ja = E{ εt 2 } = Jo + const

(3)

where const does not depend on set of the nonlinear estimator parameters, thus
performance indices Ja and Jo have the same optimal points on the set.
We use a new solution to the problem given in [3] with the following notations:
t
zt+1−s
∈ IRsm is a column vector composed of column vectors zt+1−s through
zt , s stands for the observability index, and T is the n × n observability matrix.

438

3

O. Gorokhov and I. Semoushin

Nonlinear Filtering and MATLAB Algorithm
Implementation

In this section we present the general computational algorithm for adaptive estimation of parameters. We also demonstrate how the adaptive ﬁltering algorithm
is implemented by the designed MATLAB tool box procedures. The MATLAB
object objExperiment (Fig. 1) includes all information and settings for numerical simulations such as stabilization ﬁlter time, signal noise ratio, initial
conditions.

objExperiment =struct(’Tmax’, ’TimeStab’, ’TimeSwitching’, ...
’Alpha’, ’Qbefore’, ’Qafter’, ’Rbefore’, ’Rafter’, ’PHIbefore’,...
’PHIafter’, ’P0’, ’AdaptiveProcedure’);

Fig. 1. Tool box experiment object structure

Assuming, for generality sake, that the uncertainty can reside in matrices Φ,
Γ and covariances Q and R, we denote the parameterized versions of these matrices as Φθ , Γθ , Qθ and Rθ respectively. The system (1) state generation procedure
consists of two parts: before change point in the system and after change. The
goal of the after-change algorithm is to identify the new parameter values. Tool
box function phiModel (Fig. 2) demonstrates the top-level programming code
without taking into consideration the details hidden in the low-level functions
phiModelInitialization, phiGenerateNoise and others.
The model state estimates are obtained as a result of nonlinear transformation Lθ {·} of the feedback suboptimal ﬁlter estimate
˜(t+
x
˜(t−
i+1 ) = Φθ0 x
i )
+
x
˜(ti ) = Lθ0 {˜
x(t−
i ) + Kθ0 ν(ti )}
ν(ti ) = z(ti ) − H x
˜(t−
i ) .

(4)

The gain Kθ is replaced by the result of each iteration (the whole identiﬁcation
process). The initial value for Kθ0 is set as some nominal value which is chosen
a’priori to satisfy the stability conditions. The corresponding implementation is
given at (Fig. 2) where the estimation of the system state vector is performed
via Kalman ﬁlter before reaching stabilization and when via stabilized ﬁlter.
The adaptive model is appended to this system and started with initial state
taken from the suboptimal ﬁlter (4). It has the following form
g˜(ti+1 ) = Aθ gˆ(ti )
gˆ(ti ) = Lθ {˜
g (ti ) + Dθ η(ti )}
η(ti ) = z(ti ) − H∗ g˜(ti )

(5)

Developing a Simulation Tool Box in MATLAB

439

function [objObject] = phiModel(objExperiment, objObject, t)
if (t == 0)
phiModelInitialization(objExperiment, objObject);
else
if (t < objExperiment.TimeSwitching)
objObject = phiBeforeSwitching(objObject,t);
else objObject = phiAfterSwitching(objObject,t);
end;
objObject = phiGenerateNoise(objExperiment, objObject,t);
objObject = phiGenerateDynamics(objExperiment, objObject,t);
end;
end;

Fig. 2. Tool box model object code generating state of the system at time t

where Aθ = Tθ Φθ Tθ−1 , H∗ = HTθ−1 and Tθ is the observability matrix deﬁned in
[3]. Let us assume that the collective parameter θ represents the set of adjustable
parameters in the model indexed accordingly (the Kalman gain Dθ , the matrix
Aθ and the nonlinear transformation Lθ {·}).

Fig. 3. Tool box ﬁlter implementation

i
Denote the stackable vector of [η(ti−s+1 ), . . . , η(ti )] as Hi−s+1
where s is the
maximal partial observability index. Then the model error between the adaptive
and suboptimal models can be written in the following form
i
ε(ti ) = N (Dθ )Hi−s+1

(6)

440

O. Gorokhov and I. Semoushin

where N (D) is the structure transformation of adaptive model gain D as deﬁned
in [3].

Fig. 4. Tool box adaptive ﬁlter implementation

The sensitivity model that reﬂects the inﬂuence of the adjustable parameters
on the model error (6) and in fact is the partial derivatives of vector ε(ti ) wrt.
vector θ, is deﬁned by three types of recursions according to the placement of
adjustable parameter. Let µ denote the sensitivity model state vector. We have
µ
˜j (ti ) = Aθ µ
ˆj (ti−1 )
θ
µ
ˆj (ti ) = ∂L
µj (ti ) +
∂x ((I − Dθ H∗ )˜

∂Dθ
∂θj η(ti ))

(7)

where θj is a parameter of vector Dθ . The second type of sensitivity equations
is deﬁned for parameters θj of transition matrix A:
µ
˜j (ti ) =
µ
ˆj (ti ) =

∂Aθ
ˆ(ti−1 ) + Aθ µ
ˆj (ti−1 )
∂θj g
∂Lθ
µj (ti ) .
∂x (I − Dθ H∗ )˜

(8)

The inﬂuence of the nonlinear estimator parameters on the error (6) are calculated as follows
µ
˜j (ti ) = Aθ µ
ˆj (ti−1 )
(9)
∂Lθ
θ
µ
ˆj (ti ) = ∂L
˜j (ti ) .
∂θj + ∂x µ
All recursions start with initial values µ
ˆj (t0 ) = 0 for each θj . Let vector ξj (ti )
i
be used to denote −H∗ µ
˜j (ti ). The history for vectors ξj (ti ) and Hi−s+1
should
be accumulated during the iterations (4)-(9) till s last values are re-calculated.

Developing a Simulation Tool Box in MATLAB

441

The sensitivity matrix S(ti ) is computed as follows
S(ti ) =

∂N (D) i
∂θj Hi−s+1

+ N (D)

∂Hii−s+1
∂θj

(10)

∂Hi

i−s+1
where ∂θ
is the stackable vector of the s last values ξj (tk ). Then the gradient
j
model is deﬁned as the product of transposed sensitivity matrix S(ti ) and ε(ti )

q(ti ) = S T (ti )ε(ti )
qˆ(ti ) = β qˆ(ti−1 ) + (1 − β)q(ti )

(11)

where β is the exponential smoothing factor, 0 ≤ β < 1.

Fig. 5. Tool box numerical simulation function

The suboptimal adaptation procedure (SAP) shown here as one of possible
variants, is deﬁned for each adjustable parameter θj through the recursion
i) 2
pj (ti+1 ) = pj (ti ) + ∂ε(t
∂θj
ˆ i ) − diag(pj (ti+1 ))−1 qˆ(ti ) .
π(ti ) = θ(t

(12)

ˆ i+1 )). The stability condition
(Here and below π(ti ) denotes a trial value for θ(t
of the linear part of estimator, ρ [(I − DH∗ )A] < 1, should be checked for trial
estimate π(ti ). Also, the constraints of the nonlinear estimator should be satisﬁed
ˆ i+1 ) = π(ti ).
for the next estimate θ(t

442

O. Gorokhov and I. Semoushin

The adaptive ﬁlter tool box function is depicted by Fig. 4. The renewal of
the adaptive ﬁlter parameters with the new calculated values occurs only at each
adaptive step, which is obtained by function phiAdaptiveStep.

4

Simulations Results

The integral percent error (IPE) will show the algorithm performance. The tool
box numerical simulations function (Fig. 5) depends on the possible range of
aspects to be evaluated. The extended experiment is planned to analyze the inﬂuence of a set of diﬀerent aspects on the IPE-characteristic of the algorithm, to
reveal some eﬀects during the identiﬁcation process and ﬁnally to illustrate the
applicability of the nonlinear ﬁltering algorithm and its MATLAB tool box implementation. The set of aspects includes signal-to-noise ratio (SNR deﬁned by
Q / R ), stability property of the object, the presence of nonlinear estimator,
the type of adaptation procedure (suboptimal, i.e. SAP, optimal, i.e. OAP, or
simple stochastic approximation, i.e. SSAP), a number of iterations, and initial
values for the estimates. Main user function (Fig. 5) is used to execute the algorithm for the ranges of analyzed aspects (phiSnrRange, phiStabilityRange),
to compare results (phiAnalyseResults) and to plot graphs (phiMakeGraphs).

[RANGES]
stabInterval=((0.01, 1.000); 0.0; 10.0);
snrInterval=((0.001, 100.0); 0.0; 10.0);
snrAdaptiveProcedure=SAP;
snrvsiterationsIpeLevel=10.0;
adjMaxAdapationTime=((10000, 10000000); 0.0; 10.0);
[SYSTEM]
PHI = [-0.8, 0.1];
Q = 0.04;
R = 0.06;
Gd = [0.0; 0.4];
H = [1.0, 0.0];

Fig. 6. Experiment settings

We investigate the properties of the proposed algorithm and deﬁne the IPE
as follows
∗
)−θ ∗∗
ρipe = θ (tθi ∗∗
(13)
where θ∗ (ti ) is the estimate of parameter θ obtained at time ti and θ∗∗ is the
optimal (i.e. true) value of θ.

Developing a Simulation Tool Box in MATLAB

443

We consider the following example of the second order model
0 1
0
x(ti ) +
wd (ti )
f1 f2
α
z(ti ) = Hx(ti ) + vd (ti )

x(ti+1 ) =

(14)

with unknown values of the state and measurement noise covariances Q and R
and α = 0.4, β = 0.0. The measurement matrix H is 0, 1 and parameters f1
and f2 are known and ﬁxed. Nonlinear estimator has the nonlinear state transformation function which is linear for small state values and constant outside the
linear area. The tangent of the linear part θ is unknown and should be identiﬁed.
In this experiment we simultaneously identify the parameters of adaptive ﬁlter
and the optimal tangent θ of the nonlinear estimator.
Integral percent error vs signal−noise ratio. Stability=0.1, Iterations=106

5

10

4

Nonlinear

10

3

Integral percent error

10

Linear

2

10

1

10

0

10

−1

10

−3

10

−2

10

−1

10

0

10
Signal−noise ratio

1

10

2

10

Fig. 7. IPE characteristic for linear and nonlinear problems, stability factor - 0.1

The experiment is a set of algorithm runs with chosen algorithm settings and
deﬁned values of modelling aspects. We distinguish the primary and secondary
modelling aspects of the experiment that corresponds to an interval of values
and single value accordingly. Experimental graphs depict the IPE-characteristic
behavior vs the primary aspect interval with the secondary aspects values chosen
arbitrarily. The experiment settings for considered example are set in tool box
conﬁguration ﬁle as shown in Fig. 6.
The primary modelling aspect is SNR, and we successively analyze the SNRinterval [1.0 · 10−3 , . . . , 1.0 · 102 ].

444

O. Gorokhov and I. Semoushin

Graphs of Fig. 7 and Fig. 8 represent the IPE behavior vs the time scale for
nonlinear estimation for diﬀerent stability factors. In all other cases the quality
of the estimates becomes better as the number of iterations grows.
6

Integral percent error vs signal−noise ratio. Stability=0.9, Iterations=10

5

10

Nonlinear
4

10

3

Linear

Integral percent error

10

2

10

1

10

0

10

−1

10

−3

10

−2

10

−1

10

0

10
Signal−noise ratio

1

10

2

10

Fig. 8. IPE characteristic for linear and nonlinear problems, stability factor - 0.9

The stability factor depends on location of the eigenvalues of matrix Φ and it
occurs that there exists an insensitivity area eﬀect of the considered nonlinearity.
This eﬀect entirely deﬁnes the shape of the IPE-graph while the SNR interval
[1, . . . , 102 ] does not inﬂuence on the quality of estimating process for stability
factor 0.9. However, as the number of iterations is increased, the IPE-quality
becomes better till the non-improvable level corresponding to the insensitivity
area, is attained. This eﬀect can be revealed on Fig. 9.

5

Conclusions

In this paper, we develop the special purpose MATLAB compatible tool box and
demonstrate its applicability to computational investigation of complex systems
described in terms of high-dimensional vector-matrix stochastic diﬀerence equations. This project was motivated by developing novel numerical algorithms for
adaptive identiﬁcation of a non-linear optimal discrete-time steady-state estimator intended to predict the state of the given stochastic system.
This is only one of the possible applications of the designed tool. Another
problem investigated with the tool box is iterative control design [4]. The tool

Developing a Simulation Tool Box in MATLAB

445

IPE behaviour, different stability factors

5

10

4

10

S=0.5
3

Integral percent error

10

S=0.9

2

10

1

10

0

10

S=0.1

−1

10

−3

10

−2

10

−1

10

0

10
Signal−noise ratio

1

10

2

10

Fig. 9. IPE characteristic for diﬀerent stability factors

box dramatically extends the capabilities of MATLAB as it makes computational
experiments far easier to conduct.

References
1. Landau, I.D. (ed.): Identiﬁcation des Systemes. Les Bases de l’Identiﬁcation des
Systemes. Hermes, Paris (2001)
2. Caines, P.: Linear Stochastic Systems. John Willey & Sons, New York Chichester
Brisbane Toronto Singapore (1988)
3. Semoushin, I.V., Tsyganova, J.V.: Indirect error control for adaptive ﬁltering. In:
Neittaanmaki, P., Tiihonen, T., Tarvainen, P. (eds.): Proc. of the 3rd European
Conference on Numerical Mathematics and Advanced Applications. World Scientiﬁc, Singapore New Jersey London Hong Kong (2000) 333–340
4. Semoushin, I., Gorokhov, O.: Computational processes in iterative control design.
In: Sloot, P.M.A., Kenneth Tan, C.J., Dongarra, J.J., Hoekstra, A.G. (eds.): Computational Science – ICCS 2002. Lecture Notes in Computer Science, Vol. 2329.
Springer-Verlag, Berlin Heidelberg New York Barcelona Hong Kong London Milan
Paris Tokyo (2002) 186–195

