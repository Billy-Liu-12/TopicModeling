Procedia Computer Science
Volume 29, 2014, Pages 84–94
ICCS 2014. 14th International Conference on Computational Science

A CUDA Based Solution to the Multidimensional
Knapsack Problem Using the Ant Colony Optimization∗
Henrique Fingler1 , Edson N. C´aceres1 , Henrique Mongelli1 , and Siang W. Song2
1

Universidade Federal do Mato Grosso do Sul
Campo Grande, MS, Brazil
caceresen,henrique.fingler,hmongelli@gmail.com
2
Universidade de S˜
ao Paulo
S˜
ao Paulo, SP, Brazil
song@ime.usp.br

Abstract
The Multidimensional Knapsack Problem (MKP) is a generalization of the basic Knapsack
Problem, with two or more constraints. It is an important optimization problem with many reallife applications. To solve this NP-hard problem we use a metaheuristic algorithm based on ant
colony optimization (ACO). Since several steps of the algorithm can be carried out concurrently,
we propose a parallel implementation under the GPGPU paradigm (General Purpose Graphics
Processing Units) using CUDA. To use the algorithm presented in this paper, it is necessary
to balance the number of ants, number of rounds used, and whether local search is used or
not, depending on the quality of the solution desired. In other words, there is a compromise
between time and quality of solution. We obtained very promising experimental results and we
compared our implementation with those in the literature. The results obtained show that ant
colony optimization is a viable approach to solve MKP eﬃciently, even for large instances, with
the parallel approach.
Keywords: parallel programing, gpgpu, ant colony optimization, multidimensional knapsack problem

1

Introduction

The Multidimensional Knapsack Problem, or MKP [18], is an important optimization problem
with many real-life applications. It has been studied for decades because there are many
variations all of which can be proven to be NP-hard [13].
Informally, we can state the KP as follows. A traveller has a knapsack with a certain
capacity. This knapsack must be ﬁlled with diﬀerent kinds of objects that will be useful during
the trip. Each object takes some amount of space and has a certain value to the traveller.
Given a collection of objects, which ones should he put in the knapsack? In KP, there is only
∗ Partially

84

supported by CNPq grant no. 30.1652/09-0

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.008

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

one constraint, namely, the total space of the selected objects should not exceed that of the
knapsack capacity.
The multidimensional knapsack problem (MKP) is a generalization of the knapsack problem,
in the sense that there are m > 1 constraints.
Finding optimal solutions for MKP may be intractable and approximation algorithms and
heuristic algorithms have been used to obtain approximate solutions [22]. One of the most
common heuristic methods used is the metaheuristic algorithm that iteratively search for sufﬁciently good solutions. In this paper we use a metaheuristic algorithm based on ant colony
optimization (ACO) [10]. Since several steps of the algorithm can be carried out concurrently,
we propose a parallel implementation under the GPGPU paradigm (General Purpose Graphics
Processing Units), where the GPU (Graphics Processing Unit) computing power is utilized for
general-purpose computing.
The ant colony metaheuristic attempts to imitate the behavior of ants leaving an anthill
looking for food. The nearer the food source is from the anthill the better. Initially, while an ant
walks randomly, it deposits pheromone along the path it takes. The deposited pheromone will
guide it to return to the anthill, and also will help other ants to the path taken. This pheromone
evaporates with time, therefore, a path taken by many ants will have more pheromone than
that taken by less ants. When an ant ﬁnds a food source, it returns to the anthill. If this food
source is far away from the anthill, a greater amount of pheromone will have evaporated. On
the other hand, if it is near the anthill, there will still be a good amount of pheromone on the
return path. Paths to food sources nearby implies less round trip time and thus will have more
pheromone than more distant food sources. The more pheromone on a given path, the more
likely it will be taken. The analogy is that the food sources are solutions for the problem. The
nearer the food source is from the anthill, the better is the solution. It is through the deposited
pheromone that ants communicate with each other, thus sharing information acquired towards
a good solution.
A sequential algorithm based on the ant colony optimization approach to solve the MKP
has been presented by Ke et al. [17]. Since the work carried out by each ant is independent,
it is simple to parallelize an ant colony optimization algorithm. It suﬃces to allocate the work
of each ant to a processor. In fact, we have shown the success of the parallel approach in a
previous work, where we produced a GPGPU solution for solving the Quadratic Assignment
Problem [5]. Furthermore, it has been shown that, through a diﬀerent organization, where the
work of each ant is assigned to more than one processor, the results are even better [6]. In this
paper, we chose this second approach and implemented the ACO algorithm to solve MKP on
a GPGPU, using CUDA, and obtained promising results. The results obtained show that ant
colony optimization is a viable approach to solve MKP eﬃciently, even for large instances, with
the parallel approach.

2

Ant Colony Optimization

Inspired by the behavior of ants previously explained, Dorigo proposed the Ant System (AS)
algorithm, an implementation of the ACO, to solve the shortest path problem [10]. The initial
results were good. However, they did not surpass the results of other techniques for large graphs.
Nevertheless, the results were important in the sense that variations of AS were studied and
proposed.
ACO can be described as a metaheuristic in which artiﬁcial ants communicate with each
other through pheromone trails, that work as probabilistic functions to construct or modify
solutions. During the execution of the algorithm, information is adapted and updated to re85

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

ﬂect the experience of each ant in search of new solutions. Initialization and update of such
information are the most important steps of the ACO algorithm.
Besides the work of the ants, there are two other steps: pheromone evaporation and global
actions. Pheromone evaporation is a process of updating the entire pheromone table, where
the quantity is reduced by an amount deﬁned by a function. This update attempts to avoid
the convergence of several ants toward a suboptimal local solution, and thereby allows ants
to explore new paths. The global actions step is used to carry out centralized actions that
cannot be executed by each ant individually, such as to initiate a local search process or to
collect information on solutions constructed by all the ants, to update the pheromone table
favoring the local optimal solutions. The ACO approach has been used with good results in
several problems, such as the traveling salesman problem (TSP) [25], the quadratic assignment
problem [24], the classiﬁcation problem [20], the vehicle routing problem [9], among others.

Figure 1: Example of trails between ant Nest and Food source [8].
Figure 1 shows an example. Initially (1) an ant leaves N and, by any path a tries to ﬁnd
a food source. Returning to N through path b, a pheromone trail is deposited by it, so that
other ants can follow its path. Due to evaporation of pheromone, shorter trails will have more
pheromone (2) and attract more ants. After a certain amount of time (3), the paths used by
ants tend to converge to the shortest. Even with such convergence, some ants can still follow
trails with few pheromone, due to is probabilistic characteristic.

3

The multidimensional 0-1 knapsack problem (MKP)

In the Binary Knapsack Problem (KP) [18] there is only one constraint, namely, the total space
of the selected objects. When ﬁlling the knapsack the total space of objects should not exceed
the knapsack capacity. The multidimensional knapsack problem (MKP) is a generalization of
the knapsack problem, in the sense that there are m > 1 constraints, called dimensions from
now on.
Consider m capacities bi , 1 ≤ i ≤ m. Consider a set of n objects {1, 2, . . . , n}, where object j
has value cj and has weights aij , 1 ≤ i ≤ m. Let xj ∈ {0, 1}, 1 ≤ j ≤ n. The multidimensional
knapsack problem (MKP) can be deﬁned as follows.
86

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

n

max z =

c j xj ,
j=1
n

(1)
aij xj ≤ bi , ∀i = 1, ..., m

subject to
j=1

Each object j has weights aij on dimension i and presents a value of cj if included. The
objective is to ﬁnd a subset of objects that maximizes the total value, without exceeding the
capacity of each dimension. We assume, without loss of generality, that cj > 0 for each object,
n
and bi > 0 for each dimension. We assume also j=1 aij > bi , for all 1 ≤ i ≤ m, so that we
cannot pick all the objects.

3.1

Ant colony optimization for the MKP

In this section we present the ACO algorithm to solve MKP using GPU/CUDA. With some
modiﬁcations due to the use of CUDA, it is based on the algorithm of Solnon and Bridge
[23]. Algorithm 1 presents the high-level pseudo-code of the implemented algorithm. In all
the algorithms shown, c represents the number of colonies, a is the total number of ants (ants
per colony times c), n is the number of objects that can be added and m is the number of
dimensions of the problem. We will now explain the ideas.
Algorithm 1 ACO Algorithm for the Multidimensional Knapsack Problem.
1: Initialize each position of the pheromone table as tmax
2: for i from 1 to the maximum number of rounds do
3:
for each ant k = 1, . . . , m do
4:
Add a random object to the knapsack.
5:
Add objects to the knapsack until no more objects can be added, using the desirability
formula and I-Roulette [6] to choose the objects.
6:
end for
7:
Adjust the best solution of each colony.
8:
Update the table using the best solution of the colony and the best solution generated in
this round by the colony.
9: end for
Instead of representing each ant as a thread, which is the simplest and most intuitive model,
our implementation represents an ant as a block when the code of the ants are being executed.
When global steps such as the update and initialization are being executed, each block will no
longer represent an ant, but rather an ant colony.
In most ant colony systems, there is only one colony, consisting of a set of ants, a table
of pheromone and, possibly, variables to control the behavior of the ants. This is because the
majority of the algorithms are implemented sequentially. If two colonies were implemented, the
running time would be doubled. With the use of GPGPU, however, there are abundant parallel
resources to use. Instead of creating many ants that use only one pheromone table, they can be
divided into multiple colonies. Because the pheromone update is elitist (only the colony’s best
solution is used), if many ants use the same table most of their work will not be used, therefore
it is better to divide the ants into more colonies.
The pheromone table is an array of n positions, one for each object, and uses the min-max
concept. There is a minimum value, called tmin , and a maximum value, called tmax for each
87

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

position of the table. At the beginning of the algorithm, all the positions are initialized as tmax ,
thus each object has the same pheromone amount.
The desirability of an object is expressed by a value that represents how good the object is
for a certain knapsack. The higher the desirability value of an object, the more likely it will be
inserted into the knapsack. We denote by Sk the state of the algorithm. This state contains all
the data used in the execution, such as the value and weights of each object, the pheromone
table, etc. The desirability of an object is computed in the following way.
Di = τf actor (i, Sk )α + ηf actor (i, Sk )β

(2)

where τf actor (i, Sk ) is the pheromone factor of an object (its position in the pheromone table)
and ηf actor (i, Sk ) is the heuristic factor of the object, a measure of its cost-beneﬁt value, and
is calculated using Equation 3. The values of α and β are parameters that indicate the relative
weight of each factor.
The heuristic factor is calculated as follows.
m

ηf actor (i, Sk ) = pi /

(wij /crj )

(3)

j=1

where pi is the value of object i, wij is the weight of object i on dimension j and crj is the
remaining capacity of the knapsack on dimension j. By computing the heuristic factor of an
object, each ant veriﬁes if this object ﬁts in the knapsack (an object does not ﬁt if wij > crj
for any j) or if it is already in the knapsack. If the object does not ﬁt or is already inside, its
desirability value becomes 0, since it is no longer able to add it.
To add an object to the knapsack, the ant should compute the desirability of the n objects
and choose one of them. To do this, each ant, represented by a block, launches t threads, where
t ≤ n. However, each block has a limited number of threads that can be launched. This limit is
512 for GPUs with compute capability up to 2.0, and 1024 for GPUS 2.0 or more. If this limit
is reached each thread takes responsibility of n/t objects.
Each one of the t threads computes the desirability of approximately n/t objects and multiplies by a random number between 0 and 1. The largest computed value is then obtained by
parallel binary reduction and is the object chosen to be added. With m threads and an array
of m elements, a parallel binary reduction can ﬁnd the largest value in O(log m) time. This
method is called I-Roulette [6].
If n is much larger than t, and t is equal to the the maximum amount of threads, each
thread must calculate n/t desirabilities, and only the highest of them is considered. This will
not be discussed or shown in the algorithms as it did not happen in the instances shown in this
paper and is an implementation detail.
The update of the pheromone table starts with all positions multiplied by 1 − ev where ev
is the evaporation factor. If the evaporation factor is 1, then all the pheromone evaporates
and the algorithm becomes a generator of random solutions. If ev is zero, then no pheromone
evaporates. Then the table positions of the objects in the best solution generated are increased
by a factor seen in Equation 4, where Best is the value of the best solution generated by the
colony since the start of the algorithm and Roundbest is the best value generated in the current
round.
1.0/(1.0 + Best − Roundbest)

(4)

The essential execution step of the algorithm is as follows. For the maximum number of
rounds, each ant’s selected objects, total proﬁt, capacities and other round based variables are
88

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

reset, then a random object is added (pseudo-code is shown in Algorithm 2). Then objects are
added according to their desirability. Since reading from the GPU’s memory is very slow, the
algorithm does not keep checking if all knapsacks are full, instead we execute the code to add
an object n times. The pseudo-code that adds an object is shown in Algorithm 3. After this
step each colony has to ﬁnd the best solution generated in this round and may have to update
the best solution found since the start of the execution. This step is shown in Algorithm 4. At
the end of the round the pheromone table has to be updated as in Algorithm 5.
Algorithm 2 Kernel to add a random object to each ant’s knapsack. Launched as 1 block and
a threads.
1: Call cuRAND to get a random (0, 1] number R.
2: Add object (R ∗ n) − 1 to the ant’s knapsack.
3: Set the current knapsack’s proﬁt as the selected object’s proﬁt.
4: Set the selected object’s index in the selected objects array as 1.
5: Set the remaining capacity of each dimension as the maximum capacity minus the object’s
cost.

Algorithm 3 Kernel to add an object to the knapsack. Launched as a blocks and n threads.
If n is not a power of 2, it is set as the next closest power of 2. The number of threads has to
be a power of 2 because of the reduction.
1: Get which colony the ant belongs to and which object it is responsible for (thread index).
2: Reset the shared memory at its index.
3: Synchronize all threads to make sure every position of the shared memory was reset.
4: Check if the object ﬁts in the knapsack for all dimensions.
5: Calculate the desirability of the object.
6: Check if object is already in the knapsack, if it is, set its desirability as 0 since it cannot be
chosen.
7: If this object’s probability is higher than that of the previous object or it is the ﬁrst desirability this thread computes, store in the shared memory its desirability and number.
8:
9:

Do a reduction to get the highest desirability stored in the shared memory.
If the desirability is not 0, add this object to the knapsack, updating each dimension’s
capacity, total knapsack proﬁt and the selected objects array.

Algorithm 4 Kernel to ﬁnd the best solutions of each colony generated this round. Launched
as c blocks and a/c threads.
1: Store this ant’s generated solution in the shared memory.
2: Do a reduction to get the highest generated solution in the shared memory.
3: One ant per colony - one thread per block - checks if this solution is better than best solution
found since the start of the execution, if it is, update it.

3.2

Experimental results

The ant colony algorithm for MKP uses a set of input parameters that modiﬁes the execution
behavior. Several conﬁgurations were tested and the best is shown in the results.
89

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

Algorithm 5 Kernel to update the pheromone trail. Launched as c blocks and n threads.
Each thread is responsible for one cell (object index) in the matrix
1: Calculate the amount of pheromone that may be deposited.
2: Evaporate the pheromone in its cell.
3: If the cell’s index is in the knapsack, add the amount pheromone calculated previously.
4: Check and update if the positions violate the maximum/minimum amount possible.

The pairs of number of ants/number of colonies tested were: 32/2, 128/4 and 256/8. The
weights α and β that produced the best results were 4 and 1, respectively and the best evaporation factor found was 0.1. Varying the tmin and tmax parameters did not alter signiﬁcantly
the average running times.
The MKP instances used were from the OR library [2], a collection of integer programming
problems that contain MKP instances, among others. There are two MKP problem sets in the
OR library, the ﬁrst contains instances from Fr´eville and Plateau [11]. However, since this set
is not frequently used, the results are not shown.
For the second set, the number of dimensions m is 5, 10 and 30, and the number of objects
n is 100, 250, and 500. For each combination thirty instances were generated, ten for each
tightness factor. The tightness factor of an instance determines the amount of objects the
optimal knapsack contains, the smaller the tightness factor, the less number of objects the
optimal knapsack contains. More information on the OR library can be found in [12].
When an instance does not present a proven optimum value, the best known solution was
considered.
The time shown in the tables are in milliseconds and was obtained as the average of ten
executions for each instance. To measure how good the solutions generated are, an average gap
is considered. How this value is computed is shown in Equation 5, the smaller the gap, the
better. If the gap is zero, the optimum solution was found in the ten executions. The number of
executions where the optimum solution was found was also recorded. This value is represented
under column OPT. Tables 1 to 2 show the obtained results. The results using 32 ants in two
colonies are not shown because they were not used in the comparisons.
100 ∗ (value of obtained solution − value of the optimum solution)
value of the optimum solution

(5)

To compare the results of this work with those in the literature ([1], [3], [4] and [14]) we
have chosen the conﬁguration of 256 ants and 100 rounds, since it has compatible quality and
time consumed. This conﬁgurations will be denoted ACO conﬁguration.
Tables 3 and 4 show the data of the ACO conﬁguration. Only the second set will be
compared, since it is the most used set and possesses more diﬃcult instances. Table positions
containing “-” are those where data were not informed in the literature.
In the column representing time in Table 4, we used a correction factor that takes into
account the processor frequency. This factor is computed by dividing the clock frequency of the
work in the literature by the clock frequency of this work (3.3GHz). The time shown in the
table is the product of this factor and original time of each work. This factor is not completely
fair, since the implementation in CUDA does not use the clock of the main processor, and there
is estimate of the time consumed by a sequential code if it were run on a GPGPU, since this
depends on the implementation and the characteristics of the algorithm.
The results of [3] are not shown in the tables since that work implements an exact method
based on branch-and-bound with resolution search. Thus, its running time is hundreds times
90

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

Table 1: Execution results for the instances of the second set of 128 ants in four colonies.
10 rounds
100 rounds

n

m

α

Time (ms)

Average Gap

OPT

Time (ms)

Average Gap

OPT

100

5

250

5

500

5

100

10

250

10

500

10

100

30

250

30

500

30

0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75

17
24
30
88
126
164
308
439
567
17
25
33
92
138
184
323
485
647
22
36
50
113
185
261
406
667
928

1.0839
0.4798
0.2130
0.6766
0.3192
0.1496
0.3664
0.1659
0.0921
2.6951
1.2395
0.5866
1.4070
0.7796
0.3253
0.7062
0.3680
0.2079
3.9973
2.5919
1.1659
3.3037
1.8060
0.8503
2.2872
1.0776
0.6165

0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

174
239
304
898
1277
1656
3101
4409
5737
179
258
334
943
1402
1862
3262
4856
6463
223
361
507
1148
1873
2627
4088
6689
9283

0.6104
0.2313
0.1185
0.4617
0.2238
0.0940
0.2883
0.1257
0.0670
2.0092
0.9198
0.4281
1.1747
0.6298
0.2514
0.5699
0.3039
0.1713
3.1965
2.1541
0.9684
2.9607
1.6096
0.7522
2.0467
0.9784
0.5539

6
5
14
0
0
0
0
0
0
0
0
6
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

greater in any instance.
In [4] the authors consider a hybrid dynamic programming method (HDP) with an improvement in lower bounds computation (LBC). Considering the table with correction factor, notice
that HDP+LBC obtains the best results for all the instances, except in the smallest instance
(100 × 5), where the diﬀerence in solution quality is signiﬁcant (0.26 versus 0.57). The time
diﬀerence is however very small.
A kernel search algorithm (KS) was implemented in [1]. Comparing the results, we notice
that the quality of the solutions obtained by KS is extremely high, 0.062 in the worst case that
are the largest instances, with size 500 × 30. The time consumed, however, is also high, around
148 times that of ACO for these large instances and up to 575 times larger for instances of size
250 × 30. Thus KS ﬁnds very good solutions, near the optimum, for all the instances executed,
with the price of very long execution time.
Hill, Cho and Moore [4] compare several heuristic methods and implement a new method
using problem reduction (NP(R)). The heuristics compared include HDP [4] and a genetic
algorithm (GA) [7]. No running times are informed in that paper, thus we only compare the
quality of solutions. ACO encountered better solutions for three instance sizes: 100 × 5, 250 × 5
and 100 × 10. However, since time is not shown, we cannot conclude which algorithm is better
in each case.
91

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

Table 2: Execution results for the instances of the second set of 256 ants in eight colonies.
10 rounds
100 rounds

n

m

α

Time (ms)

Average Gap

OPT

Time (ms)

Average Gap

OPT

100

5

250

5

500

5

100

10

250

10

500

10

100

30

250

30

500

30

0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75
0.25
0.50
0.75

26
36
46
149
212
277
557
787
1020
28
41
53
156
235
314
589
876
1162
35
58
82
193
320
450
736
1203
1666

0.9442
0.3980
0.1775
0.6090
0.2872
0.1368
0.3450
0.1517
0.0824
2.5208
1.0806
0.5413
1.3337
0.7251
0.3129
0.6553
0.3482
0.1995
3.7178
2.4294
1.1367
3.2283
1.7218
0.7946
2.1792
1.0448
0.5971

0
1
3
0
0
0
0
0
0
0
0
3
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

267
365
461
1500
2135
2787
5598
7909
10225
284
415
540
1571
2364
3157
5920
8790
11673
356
583
824
1943
3218
4527
7401
12059
16730

0.5119
0.1915
0.0903
0.4369
0.1974
0.0816
0.2664
0.1164
0.0635
1.8316
0.8114
0.3838
1.0753
0.5811
0.2388
0.5355
0.2865
0.1580
3.0288
2.0567
0.9297
2.8289
1.5595
0.7258
1.9765
0.9600
0.5325

8
5
18
0
0
0
0
0
0
0
0
10
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

Table 3: Comparison of the average gap and running time between the conﬁguration of 256
ants and 8 colonies with local search and data found in the literature for the second set.
256-8

HDP+LBC [4]

Kernel Search [1]

NP(R) [14]

n

m

Time (ms)

Average Gap

Time (ms)

Average Gap

Time (ms)

Average Gap

Time (ms)

Average Gap

100
250
500
100
250
500
100
250
500

5
5
5
10
10
10
30
30
30

364
2140
7910
413
2364
8794
587
3229
12063

0.2645
0.2386
0.1487
1.0089
0.6317
0.3266
2.005
1.7047
1.1563

600
1000
1130
1000
970
4030
3970
21200
93370

0.57
0.16
0.07
0.95
0.32
0.16
1.81
0.77
0.42

196000
1088000
1465000
1579000
2189000
2100000

0.0
0.002
0.001
0.019
0.013
0.062

-

0.53
0.24
0.08
1.10
0.48
0.19
1.45
0.80
0.49

4

Conclusion

When approximate solutions for MKP are suﬃcient, a heuristic solution such as ACO can be
used, for it can ﬁnd good solutions and does not require much time. To use the algorithm
presented in this paper, it is necessary to balance the number of ants and the number of rounds
used. In other words, there is a compromise between time and quality of solution: better the
solution desired, longer the time required. If there is no exact algorithm for the problem and
a solution very close to the optimum is desired, we can conﬁgure the algorithm to use a large
number of ants and colonies in several rounds.
92

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

Table 4: Comparison of the average gap and running time between the conﬁguration of 256
ants and 8 colonies with local search and data found in the literature for the second set with
time correction factor.
256-8

HDP+LBC [4]

Kernel Search [1]

NP(R) [14]

n

m

Time (ms)

Average Gap

Time (ms)

Average Gap

Time (ms)

Average Gap

Time (ms)

Average Gap

100
250
500
100
250
500
100
250
500

5
5
5
10
10
10
30
30
30

364
2140
7910
413
2364
8794
587
3229
12063

0.2645
0.2386
0.1487
1.0089
0.6317
0.3266
2.005
1.7047
1.1563

291
484
548
485
470
1954
1925
10278
45266

0.57
0.16
0.07
0.95
0.32
0.16
1.81
0.77
0.42

166286
923059
1242906
1339623
1857147
1781640

0.0
0.002
0.001
0.019
0.013
0.062

-

0.53
0.24
0.08
1.10
0.48
0.19
1.45
0.80
0.49

The hybrid dynamic programming method for MKP with lower bounds computation
(HDP+LBC) [4] obtained better results (better quality and less time) than the proposed algorithm, for almost all instances for the second data set of the OR library. Our algorithm
compare favorably with respect to the other algorithms. The kernel search method [1] obtains
very high quality solution, close to the optimum. However, the time consumed if up to 575
times longer than that of this work. The exact branch-and-bound method [3] illustrates the
diﬃculty to obtain an optimum solution. Even for a not too large instance (250 × 10), it may
require ten hours. Finally, several metaheuristic solutions [14] were compared and a heuristic
of problem reduction is proposed. Since there are no data on the running times, we have no
conclusive comments on these algorithms.
As future works, we will implement and compare the ACO method with other parallel
solutions, mainly with those using GPGPUs. As examples of such methods, we can mention
the multi-start algorithms [21], genetic algorithms [15, 16], and particle swarm optimization
algorithms [19].

References
[1] Enrico Angelelli, Renata Mansini, and M. Grazia Speranza. Kernel search: A general heuristic for
the multi-dimensional knapsack problem. Computers & Operations Research, 37(11):2017 – 2026,
2010.
[2] J. E. Beasley. OR-Library: distributing test problems by electronic mail. Journal of the Operational
Research Society, 41(11):1069–1072, 1990.
[3] Sylvain Boussier, Michel Vasquez, Yannick Vimont, Sa¨ıd Hanaﬁ, and Philippe Michelon. A multilevel search strategy for the 0-1 multidimensional knapsack problem. Discrete Applied Mathematics, 158(2):97 – 109, 2010.
[4] V. Boyer, M. Elkihel, and D. El Baz. Heuristics for the 0-1 multidimensional knapsack problem.
European Journal of Operational Research, 199(3):658–664, December 2009.
[5] E.N. C´
aceres, H. Fingler, H. Mongelli, and S.W. Song. Ant colony system based solutions to the
quadratic assignment problem on gpgpu. In Parallel Processing Workshops (ICPPW), 2012 41st
International Conference on, pages 314 –322, sept. 2012.
[6] Jos M. Cecilia, Jos´e M. Garc´ıa, Andy Nisbet, Martyn Amos, and Manuel Ujaldˆ
un. Enhancing data
parallelism for ant colony optimization on gpus. Journal of Parallel and Distributed Computing,
(0):–, 2012.

93

A CUDA Solution to the Multidimensional Knapsack Problem

Fingler, C´
aceres, Mongelli and Song

[7] P.C. Chu and J.E. Beasley. A genetic algorithm for the multidimensional knapsack problem.
Journal of Heuristics, 4:63–86, 1998.
[8] Ringo Doe. File:aco branches.svg, may 2006.
[9] Alberto V. Donati, Roberto Montemanni, Norman Casagrande, Andrea E. Rizzoli, and Luca M.
Gambardella. Time dependent vehicle routing problem with a multi ant colony system. European
Journal of Operational Research, 185(3):1174 – 1191, 2008.
[10] M. Dorigo. Optimization, Learning and Natural Algorithms. PhD thesis, Politecnico di Milano,
Italy, 1992.
[11] A. Freville and G. Plateau. Hard 0-1 multiknapsack test problems for size reduction methods.
Investigation Operativa, 1:251–270, 1990.
[12] Arnaud Fr´eville. The multidimensional 0-1 knapsack problem: An overview. European Journal of
Operational Research, 155(1):1 – 21, 2004.
[13] Michael R. Garey and David S. Johnson. Computers and Intractability; A Guide to the Theory of
NP-Completeness. W. H. Freeman & Co., New York, NY, USA, 1990.
[14] Raymond R. Hill, Yong Kun Cho, and James T. Moore. Problem reduction heuristic for the 0-1
multidimensional knapsack problem. Comput. Oper. Res., 39(1):19–26, January 2012.
[15] John H. Holland. Outline for a logical theory of adaptive systems. J. ACM, 9(3):297–314, July
1962.
[16] John H. Holland. Adaptation in natural and artiﬁcial systems. MIT Press, Cambridge, MA, USA,
1992.
[17] Liangjun Ke, Zuren Feng, Zhigang Ren, and Xiaoliang Wei. An ant colony optimization approach
for the multidimensional knapsack problem. Journal of Heuristics, 16(1):65–83, February 2010.
[18] H. Kellerer, U. Pferschy, and D. Pisinger. Knapsack problems. Springer, 2004.
[19] J. Kennedy and R. Eberhart. Particle swarm optimization. In Neural Networks, 1995. Proceedings.,
IEEE International Conference on, volume 4, pages 1942 –1948 vol.4, nov/dec 1995.
[20] D. Martens, M. De Backer, R. Haesen, J. Vanthienen, M. Snoeck, and B. Baesens. Classiﬁcation
with ant colony optimization. Evolutionary Computation, IEEE Transactions on, 11(5):651 –665,
oct. 2007.
[21] Rafael Mart, Mauricio G.C. Resende, and Celso C. Ribeiro. Multi-start methods for combinatorial
optimization. European Journal of Operational Research, 226(1):1 – 8, 2013.
[22] Jakob Puchinger, G¨
unther R. Raidl, and Ulrich Pferschy. The multidimensional knapsack problem:
Structure and algorithms. INFORMS J. on Computing, 22(2):250–265, April 2010.
[23] Christine Solnon and Derek Bridge. An ant colony optimization meta-heuristic for subset selection
problems. In N. Nedjah and L. M. Mourelle, editors, Systems Engineering using Swarm Particle
Optimization, pages 7–29. Nova Science Publishers, 2006.
[24] Thomas St¨
utzle. Max-min ant system for quadratic assignment problems, 1997.
[25] Thomas St¨
utzle and Marco Dorigo. Aco algorithms for the traveling salesman problem, 1999.

94

