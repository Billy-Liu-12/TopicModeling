Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 2213 – 2222

2013 Internationall Conference on Computational Science

Workflow-based Collabborative Decision Support for Flood
F
Mannagement Systems
Sergey V. Ivanova, Sergey V.
V Kovalchuka, Alexander V. Boukhanovskya*
a

National Research University of Information Technollogies, Mechanics and Optics, Birzhevaya line 4, 199034 Saint-Peteersburg, Russia

Abstract
Simulation-based decision making is the one off prospective applications of computational sciences whicch is central to
advances in many scientific fields. The compplexity and interdisciplinarity of scientific problems leaad to the new
technologies of simulation software implementaation based on cloud computing, workflow tools and close interaction
between experts and decision-makers. The impoortant challenge in this field is to combine simulation scenarios, expert
decisions and distributed environment to solve thhe complex interdisciplinary problems. In this paper, we desscribe a way to
organize the collaborative decision support on thee basis of e-Science platform CLAVIRE with the emphasis on urgency. A
case study on decision making is the gates manneuvering for the flood prevention in Saint-Petersburg as a part of flood
management system.
Keywords: urgent computing; collaborative decision suppport; workflow systems; expertise, analytic hierarchy process

1. Introduction
ms (DSS) is considered as a computer-based system
m that aids the
Traditionally, the decision support system
process of decision-making [1]. If the problem is relatively simple the DSS can be implementeed as a single
application with deterministic reasoning or even information support for the decision maker. Thhe process of
decision-making may involve resolving a problem through information exchange, discussion annd negotiation
d
process with several experts throughh information
among stakeholders [2]. By facilitating a decision-making
exchange with conflicts resolutions and redduction of uncertainty a concept of collaborative deccision support
(ɋDS) is proposed [3-4]. The specificity of modern problems for decision making is a complexiity of domain
mputer simulation in nearly all areas of engineering and in many
area. This has resulted in a wide use of com

* Corresponding author. Tel.: +7-812-337-6492
E-mail address: svivanov@mail.ifmo.ru

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.392

2214

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

branches of science [5]. Eventually this led to multi-scale, multiscience simulation systems which comprise not
only one application or information system, but constitute the special management environment for the
execution of related processes which normally in scientific areas represent the computational packages.
Nowadays the most common way of these processes orchestration is to use a workflow system which defines
the policies and service levels for automation of processes execution. The representation of computational
process in the form of workflow makes it possible to solve extremely complex problems, where analytical
approaches are not available and single-domain simulation is insufficient [6]. In general, some steps of the
workflow process may require human intervention. Workflow for CDS may include indirect control or direct
participation of the expert in the final decision. This compounds the problem of embedding the experts as one
of the step in workflow system. The main technical problem is a control of the expert’s availability and thus the
estimation of workflow execution time. In general the experts may be remote and in some case it requires
special collaborative technologies (for interaction between experts or expert and decision maker) that are
rapidly evolving. These technologies are based on the specific environment for data sharing, publication and
preservation, and a common user interface. These environments establish a common infrastructure where
members can access and contribute data, middleware, computational tools, and launch and manage
computations through their user spaces under generic governance rules [7,15].
The specific of decision support in critical situations (like flooding) is a rare occurrence of such events. As a
consequence the expert should be notified about necessity to open the program or web-site with operational
data. After that a curtain time is required for the analysis and assessment of alternatives. The estimation of this
time is an important issue because the time for decision making in critical situations is limited. If workflow
consists of computational steps only, the estimation of computational time may be done using time models as
functions of input parameters and hardware performance [8]. In case of decision making by experts the model
of time for data analysis and assessment becomes more uncertain and complicated. These models for workflow
execution time are the main basis for the planning of workflow steps in distributed environment.
The workflow-based CDS may be efficiently implemented with collaborative eScience platforms which are
increasingly becoming popular [7]. The eScience platforms provide the execution of workflow and handle
common crosscutting concerns [9], including invocation of the services, optimization and monitoring of the
execution, data handling, logging and security.
This paper aims to show principals of workflow-based CDS-approach which can be implemented on the
basis of eScience platform CLAVIRE. Some implementation features are shown in the example of flood
control management system to protect St. Petersburg from surge floods.
2. Multiple experts decision models
Decision making is a procedure resulting in the selection of a course of actions among several alternative
scenarios. The standard procedure of decision making includes establishment of objectives, development of
alternatives, evaluation of the alternatives against all the objectives and ranking them according to the certain
rules. Collaborative decision making is distinguished by a specific interaction between stakeholders with at
least partially conflicting interests and its decisions affect each other. An expert with its own specific
qualification and experience may be considered as a usual stakeholder or its representative. The danger (or
criticality) of the situation makes the detailed analysis of raw data and manual development of alternatives
impossible. In case of emergency the solution should be reasonably automated and the total time of decision
making should be guaranteed. The natural way to implement the total process of decision making is to collect
as computational as human dependent steps of decision-making procedure into one sequence on the basis of
workflow system. The options of the model of decision making by a group of experts are shown in Fig 1.

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

2215

Fig. 1. Models of simulation-based group decision making (a) the decision is made by experts through direct interaction; (b) each expert
makes an assessment according to all criteria; (c) each expert makes an assessment according to one criteria; (d) each expert works with
distinct scenario

The most common way of simulation-based group (collaborative) decision making is to use the simulation
pattern (simulation workflow, WF S ) for the preparation of different scenarios which are the alternatives of the
course of action and to let the experts E1.. N (or just decision makers) to choose an optimal one through
information exchange, discussion and negotiation (Fig 1a). The result of this procedure is an agreed decision
D(k1 , k 2 ...k M ) which is somewhat optimal according to criteria K 1.. M . As WF S is a simulation pattern which may be
launched with different input data or parameters, the group of experts is able to simulate its own scenarios
using existing workflows. This pattern is the most popular for the simulation-based decision support systems
(including flood management) as a strict separation of simulation and decision making without obligatory
expertise is considered as the most reliable from the point of view of system implementation. On the other
hand, this pattern has no mechanism for additional quality verification. An expert can be included to the whole
workflow-based procedure of decision making as an integral step. This procedure of decision making should
guarantee to obtain a final decision, so the level of automation should provide the potential skipping of expert’s
steps with the reasonable lost of quality. The main goal of this approach is to make the final decision more
reliable in real situations. This is very important for critical situations since a potential impact of wrong
decision is great. The use of workflow and related infrastructure gives an additional advantage, as the expert
can work independently and collaborate with each other directly through existing tools or indirectly through the
influence on final decision. If an expert becomes a part of workflow, the total procedure (see Fig 1b) of
decision making can be divided into three steps: (a) the shared part of simulation ( WF S ) based on a certain
dataset and parameters with the preparation of different scenarios and its preliminary assessments; (b) the work

2216

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

of experts with scenarios using specific software tools integrated to the workflow as integral steps, each expert
makes an assessment according to all criteria and generates an intermediate solution (decision D' ); (c)
aggregation of all the intermediate solution to one final decision that requires a special technique. The last step
may be considered as an additional step or even supplementary aggregation workflow ( WF Ⱥ ). The aggregation
of standardized and formalized expert’s solutions is well-studied area [10] and thus the main task of workflow
development is to adopt one of the existing models. Implementation of all three steps which are common for all
four models (a-d) can be done through its integration to one decision workflow. An alternate version of
decision workflow is to collect solutions from a narrow expert who can make a qualified assessment according
to one criterion only (see Fig 1c). This can lead to inhomogeneous assessments of different scenarios and
requires an individual development of decision aggregation procedure. Technically this kind of workflow is
very close to model (b) but the distinctive feature of model (c) is a specific procedure of decision aggregation
which cannot be simply borrowed from the model (b). Patterns (b) and (c) are considered to be the most natural
way for implementation of workflow-based decision support systems for flood management systems as the
most processes (including obligatory expertise) may be automated through e-Science platform. The last model
(see Fig 1d) of group decision making on the basis of workflow refers to the option where the experts are able
not to work on existing patterns only, but also able to generate its own scenarios by manipulation of original
data or even the structure of the workflow. In this case, the main goal of decision workflow developer is to
retain the ability to compare different scenarios through automated analysis. This option is less suitable for
flood management systems due to the high complexity.
3. Collaborative decision support for flood management
3.1. Decision Making Procedure on barrier gates maneuvering in Saint-Petersburg
The storm surge may lead to inundation of large living areas in St. Petersburg and immense economic
losses. To provide active flood protection the building of the barrier was begun in 1979 and completed in 2010.
The barrier consists of eleven separate dams measuring 25 kilometers across the Gulf of Finland and may
prevent the flood up to 5 meters [14]. Flood protection is provided by the gates maneuvering. The plan of gates
maneuvering is based on the forecast data and should provide (arranged according to priority): (a) protection of
the city from the flood (reliability); (b) maintenance of the structures’ consistency (safety); (c) minimization of
the time when devices are in closed position (economic efficiency). The final decision on gates maneuvering is
made by Decision Making Group (DMG). The key problems of decision making on the gates maneuvering are
the enormous number of options in multidisciplinary domain, the strong dependence on forecast accuracy, the
needs to take into account the conflicting requirements and limits on the decision making time. The number of
options may be limited by a number of scenarios prepared by numerical models. To help DMG to develop an
optimal plan of gate maneuvering a Collaborative Decision Making procedure is proposed. It includes the
following steps: (a) Automated analysis of different scenarios based on forecast data for the maneuvering plans
with different times of closing; (b) Ranking of the prepared plans according to certain criteria; (c) Sending the
raw data and ranked plans to remote experts. Every expert can change the pre-calculated assessment or propose
its own plan; (d) The special procedure of processing the expert decisions selects a plan with the best
assessments on the certain criteria. The efficient implementation of proposed procedure is not possible without
e-Science platform which support workflow management and urgent computing mode.
3.2. e-Science platform for workflow management and urgent computing
The choice of platform for case study on workflow-based collaborative decision support should take into
account the usual features of e-Science platforms (like remote services invocation, monitoring of the execution,

2217

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

performance optimization etc.) as well as possibility to launch GUI applications inside the workflow and
execute task in an urgent mode. For that reason the e-Science platform CLAVIRE (CLoud Applications
VIRtual Environment) [8] is used. CLAVIRE is targeted for a data-driving computing and it supports the highlevel abstract description of computational processes in terms of composite applications (workflows), using a
set of domain specific software and distributed data sources available within the service-oriented distributed
computational environment. One of CLAVIRE’s distinctive features is a support of urgent computing mode.
Urgent computing (UC) is a paradigm of utilization of high-performance resources for the needs of decision
making during critical emergencies. The main technological side of UC is an optimization procedure of loadbalancing for the urgent workflows, which implies the selection of computational resources sufficient to solve a
problem within the time limit. The optimization procedure for UC planning is based on the knowledge about
(a) overheads, (b) working time of computational steps as functions of input parameters and hardware
performance; and (c) network bandwidth. Decision workflows mentioned above include human dependent
steps and which execution time cannot be expressed as a deterministic function of input parameters. To predict
the response time of remote experts a special techniques is required.
3.3. Features of urgent computing for decision workflows
Execution planning for urgent decision workflow is faced with the problem of expert response time
estimation. An expert (or operator of critical system) response time is one of the key task of Human Cognitive
Reliability (HCR) analysis [11]. HCR models are relying on the frequency distribution of the response times
influenced by the factors which are called the performance shaping factors (PSFs) e.g. the operators stress
level, and the potential for misdiagnosis. The underlying assumption of the models is that the response time is
represented by one single crisp value and could be found using specific probability distribution. In practice the
uncertain effects of PSFs cause uncertainty in calculation of the response time. In the study [12] a fuzzy linear
function is assumed to be a model of the fuzzy structure of the response times. The linear model for the
response time Y has the following form:
N

Y = A0 + ¦ Ai X i ,

(1)

i=0

where Y denotes response times represented by fuzzy numbers, X i – PSFs by real numbers, Ⱥi – parameters
of PSFs by fuzzy numbers. Performance shaping factors may include age, experience inside and outside a
control room, education and others. Here it is assumed that the response times can be represented by fuzzy
numbers which have symmetrical possibility distributions around the observed values. Like the model (1), the
other well known approximation of response times based on normal or lognormal distribution may be used for
the assessing expert’s response time and to assess the total time of decision workflow execution. The
identification of the expert’s response time model requires the measured operator response times during
unexpected accidents. As those events are quite rare and the technical solution may lie in physical restriction of
time in expert’s application. Decision workflow in one of the forms shown in Fig 1 can be considered as
parallel algorithm with random input and synchronization barrier since the final step can be done only after
finishing of all previous steps. With the somewhat exception of model (c) decision workflow implements the
model of concurrent processes, where all parallel tasks carry out the same work, but with different input data.
All the computational results and its expert’s assessment should be aggregated in one terminal step which
produces the final decision. The total time of decision workflow execution can be expressed as a sum of
overhead T0 and nTc , where the Tc is a computational time per operation, n is a random coefficient which
depends on resource performance distribution (equal hardware performance for all the branches of workflow
cannot be guaranteed). In case of large number of computational resources and multistep workflow the form of

2218

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

distribution for n should tend to normal distribution. The total execution time of decision workflow has the
following form:
T p = max[T0 + niTc ] = T0 + Tc ⋅ max[ni ] ,
i =1, p

(2)

i =1, p

where operation “maximum” corresponds to the presence of the barrier. Definition (2) allows looking for the
distribution of T p in the frame of random sequences and processes extremes theory [13]. In particular, if the
distribution of parameter ni is normal, then the distribution of decision workflow execution time on p parallel
resources may be described with the first asymptotic distribution (Gumbel or Fisher–Tippett distribution) with
the probability density function, where distribution parameters depend on the number of parallel resources p :
ª
º
fn
( x) = a p exp ª − a p ( x − b p )º exp «− expª − a p ( x − b p )º » ,
¼» ¼
¬«
¼»
¬«
¬
max

(3)

ª
ln(ln( p )) + ln( 4π ) º
»σ n + mn .
b p = « 2 ln( p ) −
«¬
»¼
2 2 ln( p )

(4)

ap =

2 ln( p )

σn

,

Thus, e-Science platform CLAVIRE is able to deliver time execution model for every step of decision
workflow and model (3) may be used for forecasting the total execution time of workflowWorkflow-based
Decision making for flood management in Saint-Petersburg
3.4. Implementation of decision workflow

The general scheme of the collaborative decision workflow and its implementation in CLAVIRE
environment is shown in the Fig 2. The high level of the workflow comprises the information resources related
to the flood forecasting, including the measured data and atmospheric forecast. The quality of the input data is
verified by a special statistical model which is able to recover missed values and correct suspicious. The
generating process of initial flood forecasting includes: sea waves forecast, assimilation procedure and water
currents and level calculations.

Fig. 2. Urgent decision workflow for operational forecasting and decision support of gates maneuvering: (a)
algorithmic representation; (b) graphical representation of abstract workflow inside CLAVIRE

2219

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

Decision workflow helps the experts and members of DMG to make correct assessments of the plans’
quality and to rank plans according to the certain criteria. As the experts work not only with raw data but
basically with automatically prepared scenarios, they may simply confirm the result of automated analysis or,
on the contrary with that, fully reject it and propose its own. It may lead to conflict decisions in assessments of
different scenarios as qualification, experience and goals of different experts differ. For example, the most
reliable plan for flood protection may be the most dangerous for the structures’ consistency. At the same time
the most cost-effective plan may be not sufficiently safe. In current implementation the expert's decisions
conflicts are resolved automatically by means of the technique of analytic hierarchy process (see 4.3). The type
of this decision workflow corresponds to the pattern (b) from Fig 1.
3.5. Computational models and expert workspace

For the implementation of decision workflow the following packages are used: (a) LevelStatControl is an
applied package of statistical control of input data, (b) BalticSeaModel is a model designed for simulation of
synoptic variability of sea level and currents under the specific atmospheric conditions, (c) PlanMaker is a
package for simulation of different scenarios according to the set of maneuvering plans, (d) AutomatedRanking
is a package of automatic assessment of plan's quality according to the certain criteria, (e) BSMExpert is a GUI
application which helps experts to make assessments of incoming plans, (f) PlanSelector is a package of the
automated plan’s selection with the best assessments on the certain criteria.
LevelStatControl, BalticSeaModel and PlanMaker are the domain-specific models which nevertheless do not
have the specifics with respect to the decision-making. The implementation of the package AutomatedRanking
is closely related with the problem of decision making, as it makes the experts work on the next step of
workflow much less uncertain. The main idea is to make the automated assessments of plan's quality according
to criteria of reliability, safety and economic efficiency. The reliability of i-th plans is assumed to be as follows:
­
§
Li max − Lover min
°6 + 4¨ 1 −
over
¨
°°
L max − Lover min
©
Reliability = ®
§
°
S i max − S over min
°1 + 4¨¨ 1 − over
over
S
max − S
min
©
¯°

·
¸, if Li max < FloodLevel
¸
¹
·
¸, if Li max > FloodLevel
¸
¹

,

(5)

where Li max is the maximum value of water level for i-th maneuvering plan, Lover max and Lover min are the
maximum and minimum value of water level within all the plans, where the value Li max is less than FloodLevel ,
S i max is the cumulative water excess (over the flood level) for i-th plan, S over max , S over min are the maximum and
minimum value the cumulative water excess within all the plans. According to the equation (5) the index of
reliability for the plans with the maximum value of water below FloodLevel ranges from 6 to 10 and above
FloodLevel from 1 to 5. The following equation safety index is used:
­
§
Risk i − Risk min
°1 + 9 ¨¨ 1 −
Safety = ®
Risk max − Risk min
©
°
¯10 , if Risk i = 0

·
¸ , if Risk i > 0
¸
¹

,

(6)

where Risk i is a risk level (possibility to be destroyed under severe flood) for i-th plan, Riskmax ɢ Riskmin are the
maximum and minimum value of risk level within all the plans. Thus, the safety index ranges from 1 to 10.
An assessment of economic efficiency is related to the minimization of the time when devices are in closed
position and is assumed to be as follows:

2220

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222
§
TInClose i − TInClose min
EcoEff = 1 + 9 ¨¨ 1 −
TInClose max − TInClose min
©

·
¸
¸
¹

,

(7)

where TInClose i is the time when devices are in closed position for i-th plan, TInClose max and TInClosemin are the
maximum and minimum value of the time when devices are in closed position within all the plans. Thus, the
economic efficiency index ranges from 1 to 10 as well.
Those indices may be efficiently visualized by BSMExpert application, which helps an expert to compare
different plans and make its own assessments (see Fig 3ɚ). This application handles XML with plans’
description including graphical representation. The plans’ descriptions, as well as individual information about
experts are required. It includes expert ID and expert name. An expert can choose one of the prepared plans
form drop-down list. This leads to the automatic update of main image and assessment indices. For the
convenience of plans’ comparison in the right part of the screen, a sorted list of plans is shown. Plans are sorted
by the overall quality index and colored according to this index from green for reliable, safe and economical
efficient plans to red for plans with very low indices. At the end of the course the expert sends the result to the
system for further processing. As an expert decision time is limited an application shows the remaining time. If
the expert cannot make assessments in time, the application will be closed automatically and the result will be
sent without fail.

Fig. 3. Ⱥ remote expert workspace (a) and post decision analysis (b)

3.6. Analytic hierarchy process for expert decisions aggregation

The last step of decision workflow is an aggregation of expert’s decision. Despite of the evolution of the
expert systems and underlying algorithms a common approach for expert’s decision aggregations is still an
issue. In this case a popular analytic hierarchy process is adopted. The structure of hierarchy is relatively
simple (see Fig 4ɚ). Some additional coefficients which make the reasoning more flexible are used during the
analysis. These include (a) weighted coefficients of the relative importance of each criteria (safety − K s ,
reliability − K r , economic efficiency − K c ) its sum should be equal to one, (b)The coefficients the competence
of experts in each criteria ( K s,i , K r ,i , K c,i for i-th expert). It ranges from 0 to 1 and thus opinions of affiliated
experts may be ignored, (c) the coefficients of overall confidence to the expert ( K e,i for i-th expert). It ranges
from 0 (not trust) to 1 (full trust). A following equation for a plan’s assessment is used:

2221

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

S{s,r ,c} =

S{s,r ,c},i ⋅ K {s,r ,c},i ⋅ K e,i

¦
¦ K{s,r,c}, j ⋅ K e, j
i

,

,

(8)

j

where S = K s ⋅ S s + K r ⋅ S r + K c ⋅ S c is an overall plan’s assessment, S s , S r , S c are the overall assessments of
plans according to certain criteria , S s,i , S r ,i , S c,i are the assessments of safety, reliability and economical
efficiency made by i-th expert. The main output of expert’s decisions aggregation is a maneuvering plan,
which is recognized as the best (highest overall plan’s assessment). Additional information which helps
reasoning the final solution is shown to the decision maker (see Fig 4b).

Fig. 4. (a) The structure of the hierarchy in the analysis of expert assessments with sample values; (b) sorted assessments of maneuvering
plans for the reasoning of the decision

The information presented in Fig 4b demonstrates the proximity in assessments of different plans and gives
to the decision maker an ability to make a substantiated change in the final decision according to the nonformalizable logic. For example, if overall assessments of two plans are close enough the decision, a maker can
choose a safer plan as he has information about potential problems with the structures consistency.
3.7. Decision quality evaluation

The result of decision making examined in this paper corresponds to the flooding that occurred 29 of
December 2003 00 hours (Moscow time), when the maximum level in gauge point was registered at 196 cm.
This flooding had occurred before the completion of Flood Prevention Facility Complex and the real
maneuvering hadn’t been performed, but this example could be used for the verification of the Flood
Management System. The comparison of the optimal plan (with highest overall index) and measurements was
shown in Fig. 3b and the good agreement between measurements and simulated level outside the potential
maneuvering time windows allows to expect the successful work of system in other cases.
4. Conclusions
Workflow-based decision making for complex and interdisciplinary problems like flood management can be
efficiently implemented with the use of modern e-Science platform with the support of urgent computing. The
solution should combine simulation scenarios, expert decisions and distributed environment for the reliable and

2222

Sergey V. Ivanov et al. / Procedia Computer Science 18 (2013) 2213 – 2222

efficient decision workflow execution. An example of decision making on gates maneuvering for the flood
prevention in Saint-Petersburg was implemented and demonstrated its effectiveness on real data.

Acknowledgements
This Research was sponsored by a grant from the Leading Scientist Program of the Government of the
Russian Federation, under contract 11.G34.31.0019.

References
[1] Finlay, P. N. (1994). Introducing decision support systems. Oxford, UK Cambridge, Mass., NCC Blackwell; Blackwell Publishers.
[2] Wang L., Cheng Q. Web-based Collaborative Decision Support Services: Concept, Challenges and Application // International
Archives of Photogrammetry, Remote Sensing, and Spatial Information Sciences (ISPRS) Technical Commission II Symposium, Vienna,
12-14 July 2006 (http://www.isprs.org/commission2/proceedings06/pdf/wang.pdf)
[3] Zha F.X., Sriram R.D., Fernandez M.G, Mistree F. // Knowledge-intensive collaborative decision support for design processes: A
hybrid decision support model and agent. Comput. Ind. 59, 9 (December 2008), 905-922.
DOI=10.1016/j.compind.2008.07.009http://dx.doi.org/10.1016/j.compind.2008.07.009
[4] Pohl J.G. Collaborative decision-support and the human-machine relationship // In Proceedings of the 1999 ONR Decision-Support
Workshop Series: A Decision-Making Tools Workshop, pages 21–46, 1999.
[5] P.K. Davis, A. Henninger, Analysis, Analysis Practices, and Implications for Modeling and Simulation, RAND Corporation, 2007.
[6] Karmani F. Simulation-based Optimization and Decision Making with Imperfect Information // Doctoral Thesis, Stockholm, Sweden
2011, ISBN 978-91-7501-151-6.
[7] I. Altintas; M.K. Anand; T. Vuong; S. Bowers; B. Ludäscher and Sloot,P.M.A.: A Data Model for Analyzing User Collaborations in
Workflow-Driven eScience, The International Journal of Computers and Their Applications (IJCA), 2011. VOLUME 18, NO. 3,
December, 2011 , pages 160-180
[8] Sergey Kovalchuk, Aleksey Larchenko, Alexander Boukhanovsky, Knowledge-Based Resource Management for Distributed Problem
Solving // Knowledge Engineering and Management Advances in Intelligent and Soft Computing Volume 123, 2012, pp 121-128
[9] D. De Roure, C. Goble, and R. Stevens, The Design and Realisation of the myExperiment Virtual Research Environment for Social
Sharing of Workflows, Future Gen. Comput. Syst. vol. 25, pp. 561–567, 2009, doi: 10.1016/j.future.2008.06.010.
[10] Giarratano J., Riley G. Expert systems – principles and programming, PWS Publishing Company, Boston, 1999
[11] Worledge, D. M., Joksimovich, V. & Spurgin, A. J., Interim results and conclusions of the EPRI operator reliability experiments
program. In Proc. IEEE 4th Conf. Human Factors and Power Plants, 5-9 June 1988, Monterey, CA, USA, pp. 315-322
[12] B. Kim, R.R. Bishu, On assessing operator response time in human reliability analysis (HRA) using a possibilistic fuzzy regression
model // Reliability Engineering & System Safety. Vol. 52. Issue 1. 1996. P. 27–34.
[13] M. R. Leadbetter, Georg Lindgren, Holger Rootzén, Extremes and related properties of random sequences and processes, SpringerVerlag, 1983 - Mathematics - 336 pages
[14] Saint Petersburg Flood Prevention Facility Complex. http://dambaspb.ru (in Russian)
[15] V.V. Krzhizhanovskaya, G.S. Shirshov, N.B. Melnikova, R.G. Belleman, F.I. Rusadi, B.J. Broekhuijsen, B.P. Gouldby, J. Lhomme,
B. Balis, M. Bubak, A.L. Pyayt, I.I. Mokhov, A.V. Ozhigin, B. Lang, R.J. Meijer. Flood early warning system: design,
implementation and computational modules. Procedia Computer Science, V. 4, pp. 106-115, 2011.
http://dx.doi.org/10.1016/j.procs.2011.04.012

