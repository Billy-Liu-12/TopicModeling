A Permutation-Based Diﬀerential Evolution
Algorithm Incorporating Simulated Annealing
for Multiprocessor Scheduling with
Communication Delays
Xiaohong Kong1,2 , Wenbo Xu1 , and Jing Liu1
1

School of Information Technology, Southern Yangtze University,
Wuxi 214122, China
nancykong@hist.edu.cn, xwb@sytu.edu.cn
2
Henan Institute Of Science and Technology,
Xinxiang, Henan 453003,China

Abstract. Employing a diﬀerential evolution (DE) algorithm, we present a novel permutation-based search technique in list scheduling for
parallel program. By encoding a vector as a scheduling list and diﬀerential variation as s swap operator, the DE algorithm can generate high
quality solutions in a short time. In standard diﬀerential evolution algorithm, while constructing the next generation, a greedy strategy is
used which maybe lead to convergence to a local optimum. In order to
avoid the above problem, we combine diﬀerential evolution algorithm
with simulated annealing algorithm which relaxes the criterion selecting
the next generation. We also use stochastic topological sorting algorithm
(STS) to generate an initial scheduling list. The results demonstrate that
the hybrid diﬀerential evolution generates better solutions even optimal
solutions in most cases and simultaneously meet scalability.

1

Introduction

Given parallel program modelled by a directed acyclic graph (DAG), the objective of scheduling the tasks to multiprocessors is minimizing the completion time
or makespan while satisfying the precedence constraints. The problem is NPhard even simpliﬁed model with some assumptions and becomes more complex
under realistic application such as arbitrary task execution and communication
times. Due to the intractability, many classical heuristics have been proposed
to ﬁnd out sub-optimal solution of the problem, the idea behind these heuristic
algorithms is to tradeoﬀs the solution quality and the complexity [1-5]. Recently
meta-heuristics search approaches have also made some accomplishment on solving the problem [1][2][3].
Since DE was ﬁrst introduced to minimizing possibly nonlinear and nondiﬀerentiable continuous space functions [6], it has been successfully applied
in a variety of applications [7]. In this paper, we exploit a hybrid diﬀerential
evolution algorithm to construct the solution for parallel program scheduling
with the permutation-based solution presentation.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 514–521, 2006.
c Springer-Verlag Berlin Heidelberg 2006

A Permutation-Based DE Algorithm Incorporating Simulated Annealing

2

515

The Multiprocessor Scheduling with Communication
Delays

It is popular to model the multiprocessor scheduling using a directed acyclic
graph (DAG), which can be deﬁned by a tuple G = (V, E, C, W ), where V =
{nj , j = 1 : v} is the set of task nodes and v = |V | is the number of nodes, E is
the set of communication edges and e = |E| is the number of edges,C is the set
of edge communication costs, and W is the set of node computation costs. The
value c(ni , nj ) ∈ C corresponds to the communication cost incurred while the
task ni and nj are scheduled to diﬀerent processors, which is zero if both nodes
are assigned on the same processor. The value w(ni ) ∈ W is the execution time
of the node ni ∈ V . The edge ei,j = (ni , nj ) ∈ E represents the partial order
between tasks ni and nj , which dictate that a task cannot be executed unless
all its predecessors have been completed their execution.
The target system M is consisted of m identical or homogeneous processors with local memory connected by an interconnection network with a certain topology. When scheduling tasks to machines, we assume every task of a
parallel program can be executed on any processor and only on one processor non-preemptively and the system executes computation and communication
simultaneously.
Scheduling the graph G to M is to ﬁnd out pairs of (task, processor) which
optimize the scheduling length or completion time. Most scheduling algorithms
are based on the so-called list scheduling strategy. The basic idea of list scheduling is to make a scheduling list (a sequence of nodes for scheduling) by assigning
them some priorities, and then assign the tasks to processor according to some
rule such as the earliest start time ﬁrst.

3

Diﬀerential Evolution Algorithm

Diﬀerential evolution (DE) is one of the latest evolutionary optimization methods proposed by Storn and Price [6]. Like other evolution algorithms, mutant
operator, Crossover operator, selection operator are introduced to generate a
next generation, but DE has its advantages such as simple concept, immediately
accessible for practical applications, simple structure, ease of use, speed to get
the solutions, and robustness, parallel direct search method [6].
At the heart of the DE method is the strategy that the weighted diﬀerence
between two vectors selected randomly is exerted on the perturbed vector to generate a trial vector, then the trial vector and the assigning vector exchange some
elements according to probability, better individuals are selected as members of
the generation G+1.
For example, one version DE/rand/2 updates according to the following
formulates:
(1) Initial population,Xi,G , i = 0, 1, 2, · · · , N P − 1, N P is the number of population.
(2) Evolution operation, for every Xi,G , denote running vector.

516

X. Kong, W. Xu, and J. Liu

Mutation
A mutation vector v is generated according to
Vi,G+1 = Xr1,G + F 1 ∗ (Xr2,G − Xr3,G ) + F2 ∗ (Xr4,G − Xr5,G )

(1)

r1,r2,r3,r4 and r5 ∈ [0, N P − 1] re mutually diﬀerent integer and diﬀerent
from running index i; F1 , F2 ∈ [0, 2] are constant factor which controls the
ampliﬁcation of the diﬀerential variation (Xr2,G − Xr3,G ) and (Xr4,G − Xr5,G ).
Crossover
The trial vector is formed,
Ui,G+1 = (u0i,G+1 , u1i,G+1 , . . . , u(D−1)i,G+1 )
where , uji =

vji,G+1 j =< n >D , < n + 1 >D , . . . , < n + L − 1 >D
xji,G otherwise

(2)
(3)

where <>D denote the modulo function with modulus D. The starting index n
in (2) is a randomly chosen integer from the interval [0, D − 1]. The integer L is
drawn from the interval [0, D − 1] with the probability
P r(L = v) = (CR)v

(4)

CR ∈ [0, 1] is the crossover probability and constitutes a control variable for the
DE scheme. The values of both n, D and L can refer to literature [6].
Selection
In order to determine whichever of Ui,G+1 and Xi,G is transferred into the next
generation, the ﬁtness values of the two are comparedand the better is preserved.
(3) Stop Criterion
This process is repeated until a convergence occurs.

4

Applying DE Heuristic to Scheduling Problem

The DE algorithm with few control variables is robust, easy to use and lends
itself very well to parallel computation [6]. However, the continuous nature of
the algorithm limited DE to apply to combinatorial optimization problems. In
order to use it in parallel program scheduling problem, we must re-deﬁne the
operations in following way as to take into account the precedence relations
between tasks.
4.1

Redeﬁning the DE

Deﬁning the vector: Every vector in diﬀerential evolution algorithm is represented by a feasible permutation of tasks, a tasks list satisfying topology order.
Deﬁning of diﬀerential variation: In our proposed algorithm, the diﬀerential
variations (Xr2,G − Xr3, G) and (Xr4,G − Xr5,G ) is deﬁned as a set of Swap

A Permutation-Based DE Algorithm Incorporating Simulated Annealing

517

Operator on task nodes in scheduling list[8]. Consider a normal solution sequence of multiprocessor scheduling with n nodes, here we deﬁne Swap Operator
SO(ni , nj ) as exchanging node ni and node nj in scheduling list. Then we deﬁne
S = S + SO(ni , nj ) as a new solution on which operator SO(ni , nj ) acts. For
example,
{n1 , n2 , n3 , n4 , n5 , n6 } + SO(n1 , n3 ) = {n3 , n2 , n1 , n4 , n5 , n6 }

(5)

Plus operation between two SOs: Swap Set SS is a set of Swap Operators.
SS = (SO1 , SO2 , SO3 , · · · , SOn )

(6)

When Swap Set acts on a solution, all the Swap Operators of the swap Set act
on the solution in order. i.e.
SS = {(nki , nkj ), i, j ∈ {1, 2, · · · , N }, k ∈ {1, 2, · · · , }}

(7)

which represents that node nki and nkj are swapped ﬁrstly, and n2i and n2j are
swapped secondly, and so forth. Deﬁne plus operation between SO1 and SO2 as
the union of the two swap operators, denote
SO1 + SO2

(8)

so Swap Set operation can be described by the following formula[8]:
S = S + SS = S + (SO1 , SO2 , SO3 , · · · , SOn )
= ((SO1 , SO · · ·) + SO2 ) + . . . + SOn

(9)

The plus sign “+” above means continuous swap operations on one solution.
Plus operation between two SSs: If several Swap Sets have the same results as
a single Swap Set acting on one solution, we deﬁne the operator “⊕” as merging
several Swap Sets into a new swap Set[8]. For instance, there is two Swap Sets
SS1 and SS2 , SS1 and SS2 act on one solutionS in order, and there is another
Swap Set S S acting on the same solution S, then get the same solution S, call
that S S is equivalent to SS1 ⊕ SS2 .
Minus operation between two vectors: Suppose there are two vectors, A and
B, a Swap Set SS which can act on B to get vector A, i.e. we can swap the
nodes in B according to A from left to right to get SS. So there must be an
equation A = B + SS. We deﬁne the minus operation between vectors A and B
as a SS, that is. A = B + SS ⇔ A − B = SS.
Updating: On the basis of above, Formula (1) has already no longer been
suitable for the scheduling problem. We update it as follows:
Vi,G+1 = Xr1,G + (Xr2,G − Xr3,G ) ⊕ (Xr4,G − Xr5,G )
4.2

(10)

Stochastic Topological Sorting Algorithm

On the basis of above, the initial vectors, initial scheduling list, must satisfy
the precedence constrains. The topological sorting algorithm (TS) can serve the

518

X. Kong, W. Xu, and J. Liu

purpose, but the TS has two fatal disadvantages, one of which is that it is based
on the depth-ﬁrst search so that the topological orders generated by the TS
algorithm cannot cover the whole feasible solutions, the other of which is that
the topological order is ﬁxed because it is subject to the storage structure of the
DAG in the computer. In [9], we devise a novel sorting algorithm, a stochastic
topological sorting algorithm (STS). The STS algorithm will be used in this
paper to generate an initialized population.
4.3

Crossover Operation

In our algorithm, crossover operators adopted do not exchange the values of
the elements but the order the elements appear in vectors to avoid permutation
infeasibility when using permutation-based DE for the scheduling. We lend this
idea from partially mapped crossover (PMX) [10], so that the order the activities
appear in the multidimensional vectors other than the values of the elements are
changed during updating process. The strategy of PMX that performs swapping
elements is illustrated in Fig.1.
Here, the mutation vector and the running vector, respectively, resemble parent 1 and parent 2 in PMX, except that the two vectors should not be incorporated into a vector. Element(called element 1) of mutation vector will be
determined according to formula(3) to see if the activity represented by the element will be moved to another placement or if the element will be swapped
with another one (called element 2), which is the element that element 1 maps
in the running vector[11]. When the placements of the two elements satisfy the
predecessors-successors constraints, the crossover operation takes place.

{n1 , n2 , · · · , ni , · · · , nk , · · · , nj , · · · , nN }
mutation vector

✻

❄

◗
◗
s
◗

✑
✸
✑
✑

{n1 , n2 , · · · , ni , · · · , nj , · · · , nk , · · · , nN}
trial vector

{n1 , n2 , · · · , nk , · · · , nj , · · · , ni , · · · , nN }
running vector

Fig. 1. An example of the partially mapped crossover operator in DE vectors

4.4

Simulated Annealing Selection Operation

Once a new solution is generated, a decision must be made whether or not to
accept the newly derived vector as next generation. In standard DE, a greedy
strategy is utilized to determine trial and running vector, which means the better
of ﬁtness of the two survive into next generation. The greedy criterion can converge fairly fast, but it runs the risk of becoming trapped by a local minimum[6].

A Permutation-Based DE Algorithm Incorporating Simulated Annealing

519

The mechanism of Simulated Annealing is introduced into DE[12], which eﬀectively optimize the objective function while moving both uphill and downhill.
According to SA algorithm, selection strategy not only accepts better solutions
(decreasing scheduling length) but also some worse solutions(increasing scheduling length). The Metropolis criterion decides on acceptance probability of worse
solutions[12].

5

Experiment Results

Benchmark instances from website (http://www.mi.sanu.ac.yu/ tanjad/) are
used to test the validity of our approach with three diﬀerent selection strategies. In order to demonstrate the eﬃciency of the SA select operation, we
test the benchmark instances using three strategies, SA selection operation
(DE+SA), standard DE(STDE), the trial vector directing into next generation(DE+RAND) respectively.
In our experiments, we select the ogra100 problem with diﬀerent edge densities
, which is deﬁned as the number of edges divided by the number of edges of a
completely connected graph with the same number of nodes [5]. For each density,
the mean deviations from the optimal schedule for 10 runs are recorded in Table1
for DE with and without SA selection strategy respectively. DE with SA always
has comparable performance on the results of DE without SA whether using
diﬀerent processors or diﬀerent densities.
Table 1. Results of the DE algorithm with diﬀerent selection strategies compared
against optimal solutions (% deviations) for the random task graphs with three densities using 2, 4, 6, and 8 processors.( ampliﬁcation factor F1=F2=1, Iteration number
equals 20).

Graph density
60
70
80
90
Avg. Dev.

2
3.75
2.75
1.63
1.00
2.28

STDE
4
6
8.00 9.25
6.38 7.25
5.00 7.63
1.12 5.48
5.12 7.40

8
10.88
7.25
4.63
5.50
7.06

No. of processors
DE+RAND
2
4
6
8
2.88 7.13 12.88 11.25
2.63 8.50 12.13 9.38
1.38 8.13 10.25 7.38
1.13 3.50 5.50 5.50
2.00 6.81 10.18 8.38

2
2.88
1.63
1.00
0.50
1.50

DE+SA
4
6
6.75 8.63
6.75 6.79
4.00 4.75
1.63 4.00
4.78 6.04

8
6.79
6.75
4.75
4.00
5.57

At the same time, we also investigate how the density of graphs aﬀects the
scheduling results. Because the lengths of optimal schedules are given depend onlyon task number, it appears that dense graphs spent less communication costs.
Fig.2 is the result. Based on same tasks number and processors, less deviation
is achieved for dense-task graphs.
Finally, we test the average deviation under diﬀerent task numbers, and the
result is illustrated in Fig.3. With the tasks number increasing, the communication cost between tasks assigned to diﬀerent processors has a vital proportion to

X. Kong, W. Xu, and J. Liu

average deviations from optima

520

10
STDE
DE+RAND
DE+SA

8
6
4
2
0
20

40

60
80
density of graph

100

average deviations from optima

Fig. 2. The average % deviations from the optimal of the solutions generated by the
DE algorithm for the random task graphs with diﬀerent densities using 2 processors

6
STDE
DE+RAND
DE+SA

5
4
3
2
1
0
50

100

150
200
number of task

250

300

Fig. 3. The average % deviations from the optimal of the solutions generated by the
DE algorithm for the random task graphs with diﬀerent tasks using 4 processors

the overall cost. A conclusion can be observed that the DE algorithm with SA
selection strategy for scheduling has a good scalability.
From the values above it is evident that a hybrid strategy of DE incorporating
temperature-based acceptance criterion of SA is preferable to greedily selecting
manipulation because the use of probability acceptance to inferior solutions in SA
enhances the solution diversity in search process. The eﬀect is always desirable
due to the advantage of the DE with SA to avoid the local optima.

6

Summary

We have presented a diﬀerential evolution algorithm for multiprocessor DAG
scheduling. As can be see from the previous results of the performance-testing
experiment, in most cases the permutation-based DE method can ﬁnd nearoptimal schedule, especially the DE method with SA selection technique. In

A Permutation-Based DE Algorithm Incorporating Simulated Annealing

521

practice, we combine the DE technique of searching in global space with the SA
capacity to jump out of local optimum in selecting an optimal scheduling list.

References
1. I. Ahmad, M. K. Dhodhi: Multiprocessor Scheduling in a Genetic Paradigm. Parallel Computing,Vol. 22 (1996) 395-406
2. Y.-K. Kwok, I. Ahmad: Eﬃcient Scheduling of Arbitrary Task Graphs to Multiprocessors Using a Parallel Genetic Algorithm. J. Parallel and Distributed Computing,Vol 47,(1997) 58-77
3. T. Davidovic, P. Hansen, N. Mladenovic: Permutation Based Genetic, Tabu and
Variable Neighborhood Search Heuristics for Multiprocessor Scheduling with Communication Delays. Asia-Paciﬁc Journal of Operational Research,Vol. 22, (2005)
297-326
4. T. Davidovic, T. G. Crainic: New Benchmarks for Static Task Scheduling on Homogeneous Multiprocessor Systems with Communication Delays. Publication CRT2003-04, Centre de Recherche sur les Transports, Universite de Montreal (2003)
5. T. Davidovic, P. Hansen, N. Mladenovic: Variable Neighborhood Search for Multiprocessor Scheduling Problem with Communication Delays. Proc. MIC2001, 4th
Metaheuristic International Conference, J. P. de Sous, Porto, Portugal (2001)
6. R. Storn, K. Price: Diﬀerential Evolution-a Simple and Eﬃcient Heuristic for
Global Optimization over Continuous Space. Journal of Global Optimization, Vol.
11,(1997) 341-359
7. R. Storn: System Design by Constraint Adaptation and Diﬀerential Evolution.
IEEE Transaction on Evolutionary Computation,vol. 3 (1999) 22-34
8. KANG-PING WANG, LAN HUANG,CHUN-GUANG ZHOU,WE1 PANG: Particle Swarm Optimization for Traveling Salesman Problem. Proceedings of the Second International Conference on Machine Learning and Cybernetics,vol. 5 (2003)
1583-1585
9. Wenbo Xu, Jun Sun: Eﬃcient Scheduling of Task Graphs to Multiprocessors
Using a Simulated Annealing Algorithm. DCABES 2004 Proceedings,Vol .1 (2004)
435-439
10. D.E. Goldberg: Genetic Algorithms in Search, Optimization, and Matching
Learning. Addison-Wesley Publishing Company, Inc.,Reading (1989)
11. Hong Zhang, Xiaodong Li, Heng Li: Particle Swarm Optimization-Based Schemes
for Resource-Constrained Project Scheduling. Automation in Construction,Vol.
14 (2005) 393-404
12. S.Kirkpatrick, C.Gelatt, M.Vecchi: Optimization by Simulated Annealing.
Science,vol. 220 (1983) 671-680

