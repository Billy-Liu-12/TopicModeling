Application of the Confidence Measure in Knowledge
Acquisition Process
Michal Wozniak
Chair of Systems and Computer Networks, Wroclaw University of Technology, Poland
The Higher Vocational State School in Legnica, Poland
wozniak@zssk.pwr.wroc.pl

Abstract. Paper deals with the knowledge acquisition process. Different experts
formulate the rules for decision support systems. We assume they have different
knowledge about the problem and therefore obtained rules have different qualities. We will formulate the proposition of the confidence measure and its application to the decision process based on Bayes formulae. We will propose how
calculate the value of measure under consideration for typical statistical learning process. On the base on the proposed measure of the knowledge quality we
propose the procedure of the contradictions elimination for the set of logical
rules.

1

Introduction

Machine learning is the attractive approach for building decision support systems [9].
For this type of software, the quality of the knowledge base plays the key-role. In
many cases we can meet following problems:
• the experts can not formulate the rules for decision problem, because they might
not have the knowledge needed to develop effective algorithms, but we can get the
learning data from databases and experts only classify each record to the correct
class,
• the knowledge given by experts is uncompleted or qualities of experts (knowledge
sources) are different for each of them.
For the first problem machine learning algorithms can give us the set of rules (hypothesis) on the base on the learning set, but we have to answer following questions:
1. Who made the object descriptions? (Can we trust the operator?)
2. Who confirmed the diagnosis and what was the expert quality?
In the second problem we get the rules from different experts and their qualities are
different. This problems was partly described for the induction learning [2,3,7] and
for the concept description [1]. The following paper concerns on the quality of rule
for the probabilistic reasoning, but the proposed measure can be modified to acquisition process for another form of rule.
The content of the work is as follow: Section 2 introduces necessary background
and provides the probabilistic decision problem statement. Next section presents the
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2659, pp. 635–643, 2003.

© Springer-Verlag Berlin Heidelberg 2003

636

M. Wozniak

form of rule for the probabilistic expert systems and proposes the rule-based algorithm. Section 4 defines statistical confidence measure of the knowledge and shows
how modify knowledge base according to confidence measure of rules. In this section
we also presents the interpretation of proposed measure for the estimation process
based on the typical statistical model. Section 5 proposes the procedure of contradictions elimination for the set of rules obtained from different sources. The last section
concluded the paper.

2

Decision Problem Statement

Among the different concepts and methods of using "uncertain" information in pattern
recognition, an attractive from the theoretical point of view and efficient approach is
through the Bayes decision theory. This approach consists of assumption [5] that the
feature vector x = ( x (1) , x ( 2) ,..., x ( d ) ) (describing the object being under recognition)

and number of class j ∈ {1,2..., M } (the object belonged to) are the realization of the
pair of the random variables X, J . For example in medical diagnosis X describes the
result of patient examinations and J denotes the patient state. Random variable J is
described by the prior probability p j , where

p j = P(J = j ) .

(1)

X has probability density function
f (X = x J = j ) = f j (x )

(2)

for each j which is named conditional density function. These parameters can be used
to enumerating posterior probability according to Bayes formulae:
p( j x ) =

p j f j (x )

(3)

M

∑ p j f j (x )

k =1

The formalisation of the recognition in the case under consideration implies the
setting of a optimal Bayes decision algorithm (x ) , which minimizes probability of
misclassification for 0-1 loss function[4]:

(x ) = i

if p(i x ) =

max

k∈{1, ..., M }

p (k x ) .

(4)

In the real situation the prior probabilities and the conditional density functions are
usually unknown. Furthermore we often have no reason to decide that the prior probability is different for each of the decisions. Instead of them we can used the rules
and/or the learning set for the constructing decision algorithms [12,13].

Application of the Confidence Measure in Knowledge Acquisition Process

3

637

Rule-Based Decision Algorithm

Rules as the form of learning information is the most popular model for the logical
decision support systems. For systems we consider the rules given by experts have
rather the statistical interpretation than logical one.
The form of rule for the probabilistic decision support system[6] is usually as follow
if A then B with the probability β,

where β is interpreted as the estimator of the posterior probability, given by the following formulae:
β = P (B A)
(5)
More precisely, in the case of the human knowledge acquisition process, experts are
not disposed to formulate the exact value of the β, but he (or she) rather prefers to
give the interval for its value
β ≤β ≤β .
(6)
The analysis of different practical examples leads to the following form of rule ri(k ) :
IF x ∈ Di(k )
THEN state of object is i

WITH posterior probability β i(k ) greater than β (k ) and less than β i(k ) ,
i
where

β (jk ) =

∫( )p(i x )dx

(7)

Di k

The graphical interpretation of the posterior probability estimator for the decision
area given by rule is depicted on Fig. 1.

Fig. 1. Graphical interpretation of the posterior probability estimator given by the expert rule

638

M. Wozniak

For that form of knowledge we can formulate the decision algorithm
R

(x ) = i

R

(x )

if pˆ (i x ) = max pˆ k (i x ) ,

(8)

k

where pˆ (i x ) is the posterior probability estimator obtained from the rule set.
The knowledge about probabilities given by expert estimates the average posterior
probability for the whole decision area. As we see for decision making we are interested in the exact value of the posterior probability for given observation.
Lets note the rule estimator will be more precise if:
• rule decision region will be smaller,
• differences between upper and lower bound of the probability given by expert
will be smaller.
For the problem under consideration definition of the relation “more specific” between the probabilistic rules pointed at the same classes is very useful.

Definition
Rule ri( k ) is “more specific” than rule ri(l ) if
 dx 


(k )

(k )
(l )
( k )  Di
(l )
βi − β

 < βi − β i
i
 dx 
 X 



(

)

∫

(

∫

 dx 


 Di( l ) 

.
 dx 
 X 



)

∫

(9)

∫

Hence the proposition of the posterior probability estimator pˆ (i x ) is as follow.

}

}

From subset of rules Ri (x ) = ri(k ) : x ∈ Di(k ) choose the “most specific” rule ri(m ) .

(
β ( ) − β ( ))
pˆ (i k ) =
m

m

i

i

∫( dx
)

Di m

4

Proposition of Knowledge Confidence Measure

4.1

Definition

This estimator pˆ (i x ) is obtained under the following assumption:

− learning set is noise free (or expert tell us always true),
− target concept contained in the set of class number}1, ..., M },
− the prior probabilities of classes are unknown.

(10)

Application of the Confidence Measure in Knowledge Acquisition Process

639

We consider decision under the first assumption given by the following formulae:
P(If A then B with probability β ) = 1 .
During the expert system designing process the rules are obtained from different
sources and the sources have the different confidence. For the knowledge given by
experts we can not assume that expert tell us true or/and if the rule set is generated by
the machine learning algorithms we can not assume the learning set is noise free.
Therefore we postulate that we have not to trust all information we got or the believe
on it only with the γ factor, proposed as the confidence (quality) measure. It can be
formulated as [14]

P(If A then B with probability β ) = γ ≤ 1 .
Lets as γ i(k ) denote the value of the confidence measure of rule ri(k ) .

4.2

Using Confidence Measure for Rule Base Modification

We defined confidence measure. Now, lets us show how it can be utilized for the
modification the set of rules. For the form of rule we described in section 3 we propose the following procedure, which should be started after the acquisition process:
for i:=1 to M
for each rule ri( k ) pointed at class i:

)

(

β i(k ) = 1 − 1 − β i(k ) γ i(k ) ;
β (k ) = β (k ) γ (k )
i

i

i

endfor.
endfor.

The proposition of the application of the confidence measure for the set of the logical
rules will be shown in the next section.
4.3

Confidence Measure for the Statistical Estimation

The central problem of our proposition is how to calculate the confidence measure.
For human experts the values for their rules is fixed arbitrary according to the quality
of creator. The presented problem we can also find in the typical statistical estimation
of unknown parameter β , where we assume the significant level[12]. The significant
level can be interpreted as the confidence measure. Each rule gives the index of the
class. If the feature vector value belongs to the decision area given by the rule, the
decision depends on the previous state and on the applied therapy. While constructing
the artificial rule set, we have to define somehow the decision areas for the new rule
set. For example we can want to obtain for each rule posterior probability estimator,
which is not less than a fixed value or in the practice we can use the one of very well
known machine learning algorithms like AQ,CN2 [9].

640

M. Wozniak

For each of the given intervals k we have to obtain the estimator of the posterior
probability.
We use the following statistical model [11]:
− the learning set is selected randomly from a population and there exists two class
of points: marked (point at the class i ∈}1, ..., M }) and unmarked (point at the
class l, where l ∈}1, ..., M }and l ≠ i ),

− the expected value for the population is p,
− the best estimator of p is

pˆ =

(11)

m
,
n

where n means the sample size and m - the number of the marked elements.
Let us concentrate on two cases
Small Sample ( n ≤ 100 )

t=

pˆ − p
s

(12)

n

has the Student’s t-distribution. We want to estimate one parameter - the expected
value, therefore we use t-distribution with n-1 degree of freedom.
For the fixed significance level α we get

P (t < µ α ) = 1 − α

(13)

using the short-cut formula

s2 =

∑ (xi − pˆ )2
(n − 1)

≈

∑

xi 2 +

(∑ xi )2

(14)

n

we obtain


m
P − µ α
n



m m
1 − 
m
n
n
< p < + µα
n
n

m  m  
1 − 
n
n
 ≤ 1−α
n




(15)

The µα is the value of the t-distribution on n-1 degrees of freedom and for the sig-

nificance level α. In this case we get rule ri(k ) , for which confidence measure of rule

γ i(k ) is given by the following equation

γ i(k ) = 1 − α ,

(16)

Application of the Confidence Measure in Knowledge Acquisition Process

β i(k ) =

m m
1 − 
m
n
n
and β i(k ) = + µα
n
n

m
− µα
n

m m
1 − 
n
n
n

641

(17)

Big Sample (n> 100)
For the big sample, the distribution is similar to the normal distribution. We thus have
the equation of the same for as (15), but in this case µ α is the value of normal stan-

dardized N(0, 1) distribution for the significance level α.

5

Contradictions Elimination Algorithm

As we have mentioned the proposed method of the quality management can be applied to the logical knowledge representation (where “if-then” means logical implication). E.g. for the unordered set [2,9] of logical rules acquisition process we can attribute the value of confidence to each of rule. It could be used in the case if the contradiction in the set of rules would be detected.
First we note the set of rule R consists of the M subsets
R = R1 ∪ R2 ∪ ... ∪ RM ,
where Ri denote subset of rule pointed at the i-th class.
For this form of rule the two of them contradict each other if
∃ x ∈ X ∧ ∃ k , l ∈}1, 2, ..., M }, k ≠ l ∧ ∃ i, j
x ∈ D (k ) ∧ x ∈ D (l )
i

(18)

(19)

j

where i, j denote the number of rule.
The equation (19) means that we can find observation, which belongs to the decision
area of the rule pointed at class i ( Ri(k ) ) and decision areas of the rule pointed at different class j ( R (jl ) ).

Let us propose the idea of the contradictions elimination algorithm.
//for each class number

for i:= 1 to M:
//for each rule in

Ri

for k:=1 to Ri
//for each class number bigger than i

for j:= i to M:
//for each rule in

Rj

for l:= 1 to R j :
//if

ri(k ) and r j(l ) contradict each other

642

M. Wozniak

if Di(k ) ∩ D (jl ) ≠ ∅
then
//if confidence of
//confidence of

r j(l )

ri(k ) is higher then

if γ i(k ) ≥ γ (jl )
then
//remove the common part from decision
(l )
//area of rule r j
D (jl ) := D (jl ) \ D (jl ) ∩ Di(k )

(

)

else
//remove the common part from decision
(l )
//area of rule r j

(

Di(k ) := Di(k ) \ D (jl ) ∩ Di(k )

)

fi
fi
endfor
endfor
endfor
endfor

6

Conclusion

The paper concerned probabilistic reasoning and the proposition of the quality measure for that formulated decision problems. We proposed the idea of the contradiction
detection and elimination method for the logical representation of experts’ knowledge
too. We hope this idea of confidence management can be helpful for other problems
whose can be met during the knowledge acquisition process from different sources.
Presented ideas need the analytical and simulation researches. Let us draw some future works under the concept of the information quality:
1. developing the method how to judge the expert quality (we formulated only the
method of counting the confidence measure for rules obtained via machine learning algorithms but we propose arbitrary judgment for rule given by experts),
2. applying proposed method to the real medical decision problems (work in progress),
3. analytical researches into proposed method properties,
4. performing simulation experiments on computer generated data to estimate the
dependencies between the size of the decision area and the data quality versus correctness of classification,
5. developing the software for the contradictions elimination algorithm.

Application of the Confidence Measure in Knowledge Acquisition Process

643

References
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

Bergadano F., Matwin S., Michalski R.S., Zhang J., Measuring of Quality Concept Derd
scriptions, Proc. Of the 3 European Working Session on Learning, Aberdeen, Scotland,
1988.
Bruha I., Kockova S., Quality of decision rules: Empirical and statistical approaches,
Informatica, no 17.
Dean P., Famili A., Comparative Performance of Rule Quality Measures in an Inductive
Systems, Applied Intelligence, no 7, 1997.
Devijver P.A., Kittler J., Pattern Recognition: A Statistical Approach, Prentice Hall, London 1982.
Duda R.O., Hart P.E., Pattern Classification and Scene Analysis, John Wiley and Sons,
New York, 1973
Giakoumakis E., Papakonstantiou G., Skordalakis E., Rule-based systems and pattern
recognition, Pattern Recognition Letters, No 5, 1987.
Gur-Ali O., Wallance W.A., Induction of rules subject to a quality constraint: probabilistic
inductive learning, IEEE Transaction on Knowledge and Data Engeineering, vol. 5, no 3,
1993.
Kurzynski M., Wozniak M.: Rule-based algorithms with learning for sequential recognition problem, Proceedings of the Third International Conference on Information Fusion
“Fusion 2000”. Paris, July 10–13, 2000.
Mitchell T., Machine Learning, McGraw Hill, 1997.
Pearl J., Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference,
Morgan Kaufmann Pub. Inc., San Francisco, California, 1991.
Sachs L., Applied Statistic. A Handbook of Techniques, Springer-Verlag, New York Berlin
Heideberg Tokyo, 1984.
Wozniak M., Blinowska A., Unification of the information as the way of recognition the
controlled Markov chains, Proc. of the Congress on Information Processing and Management of Uncertainty in Knowledge Based Systems, Granada, Spain 1996.
Wozniak M., Jackowski K., Rule-based contextual pattern recognition algorithm – parametric case. Proceedings of International Symposium on Pattern Recognition, Royal Military Academy. Brussels, February 12, 1999.
Wozniak M., Idea of Knowledge Acquisition for the Probabilistic Expert Systems,
Proceedings of the International Conference on Computational Intelligence for Modeling,
Control and Automation, Vienna (Austria), 12–14 February 2003 (be published).

