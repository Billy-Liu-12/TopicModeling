Fault Point Detection with the Bank of
Competitive Kalman Filters
Innokenti Semoushin, Julia Tsyganova, and Maria Kulikova
Ulyanovsk State University, 42 L. Tolstoy Str., 432970 Ulyanovsk, Russia
{SemoushinIV, TsyganovaJuV, KulikovaMV}@ulsu.ru
http://staff.ulsu.ru/semousin/

Abstract. The problem of fault point detection in the linear stochastic
discrete systems is considered. To solve this problem the algorithm with
the ﬁnite size of the Bank of competitive Kalman ﬁlters is suggested.
Theoretical results are conﬁrmed by numerical experiments.

1

Introduction

The fault point detection problem has been discussed in many papers (see, for
example [1], [2], [3]). One of the possible solutions to this problem is to use
the Bank of competitive Kalman ﬁlters and some hypotheses testing algorithm.
However, there is the problem of practical implementation of the Bank due to
the increase in the number of Kalman ﬁlters in direct proportion with the length
of testing interval. This causes large computational expenses.
To avoid this drawback, a new algorithm with the Bank of bounded number
of Kalman ﬁlters is suggested in this paper. The authors multiple numerical
experiments indicate the eﬃciency of this new algorithm for the fault point
detection.

2

The SPRT for the Problem of Fault Detection

Consider the problem of detecting whether a stochastic discrete time system has
one set of parameters or another.
Let the system be characterized by the following equations:
xt+1 = Φt xt + Bt ut + Γt wt

(1)

zt = Ht xt + vt

(2)

where xt is the n-dimensional state vector, zt is the m-dimensional system output, ut is the control input, and {w0 , w1 , . . .} and {v1 , v2 , . . .} are mutually independent zero-mean Gaussian sequences of independent vectors. Without loss of
This work was supported in part by the Russian Ministry of Education (grant
No. T02-03.2-3427).
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2658, pp. 417–426, 2003.
c Springer-Verlag Berlin Heidelberg 2003

418

I. Semoushin, J. Tsyganova, and M. Kulikova

generality, their covariances Q and R are assumed to be reduced to identity matrices: Q = I and R = I. This can be easily done by normalizing input noise in
(1) and measurements in (2). The sequences are considered independent of Gaussian initial x0 with mean x
¯0 and P0 . At any time t, we need to be ascertained, by
performing a test on the sequence of measurements Zt = {z1 , z2 , . . . , zt }, which
of the following two hypotheses is true.
Hypothesis H0 :
system parameters are Φt0 , Bt0 , Γt0 , and Ht0 .
system parameters are Φt1 , Bt1 , Γt1 , and Ht1 .
Hypothesis H1 :
Consider two Kalman competitive ﬁlters designed, correspondingly, under
the assumption of hypothesis H0 or H1 . Let subscript i denote the hypothesis
number, i.e. ﬁlter number, then the ﬁlter equations are:
Time propagation
x
ˆ−
ˆ+
ti = Φti x
t−1,i + Bti ut ,

+
ΦTti + Γti ΓtiT .
Pti− = Φti Pt−1,i

Vector measurement update
T
T
(Hti Pti− Hti
+ I)−1 ,
Kti = Pti− Hti
−
νti = zt − Hti x
ˆti ,

(3)
Pti+
x
ˆ+
ti

Kti Hti )Pti−

= (I −
=x
ˆ−
ti + Kti νti .

Each of the following sequences
Nt0 = {ν10 , ν20 , . . . , νt0 } and Nt1 = {ν11 , ν21 , . . . , νt1 }

(4)

consists of mutually independent entries ντ i = zτ − Hτ i x
ˆ−
τ i , τ = 1, 2, . . . , t,
subject to the condition that the corresponding hypothesis, i = 0 or i = 1, is
true.
The Wald sequential probability ratio test contains the following recursive
algorithm to evaluate the likelihood ratio λt = ln p{Nt1 |H1 }/p{Nt0 |H0 }:
λt = λt−1 + µt ,
where

t≥1

−1
−1
T
T
2µt = log det Σt0 − log det Σt1 + νt0
Σt0
νt0 − νt1
Σt1
νt1 .

(5)

The mean and variance of sequences (4) for ﬁlters i = 0, 1 are given by
E{νti } = 0,

T
T −
E{νti νti
} = Σti = Hti
Pti Hti + I .

The value of λt is then tested against two threshold levels A and B (where
A > B):

the test is terminated with the choice of H0 .
 if λt ≤ B,
if λt ≥ A,
the test is terminated with the choice of H1 .

if A > λt > B, the test is repeated.
The thresholds A and B are chosen in the following way. Let α be the probability of choosing H1 when H0 is true, and β be the probability of choosing H0
when H1 is true. Then
A = log

1−β
α

and

B = log

β
.
1−α

Fault Point Detection

419

The initial value of the test is λ0 = log{P1 /P0 }, where P0 and P1 are a’priori
probabilities of occurrence of hypotheses H0 and H1 . If P0 = P1 = 12 (i.e.
hypotheses H0 and H1 are equiprobable), then it is clear that the initial value
λ0 = 0.
The SPRT requires the computation of likelihood ratio function λt at each
moment t. There was suggested an eﬃcient algorithm to compute a likelihood
function for any competitive ﬁlter [4]. The basis for this algorithm is the Conventional Kalman Filter with scalar measurement update. The authors obtained two
equivalent proofs of the equivalence between two methods of likelihood function
evaluation: the vector method with the help of equations (3)–(5) and the scalar
method according to the suggested algorithm [4]. The ﬁrst proof is based on the
Information form of Kalman Filter [4], and the second one is algebraic [5]. In the
same manner as the Conventional Kalman Filter, one can modify [4] the other
data processing algorithms that are described in [6] and based on the covariance
factorization: Potter Square Root; Bierman LD-Covariance Factorization; and
Carlson Triangular Covariance Square Root.

3

Competitive Fault Point Detection Using a Bank of
Kalman Filters

In this section, we solve the problem of fault point detection. The fault point is
the time instant at which the parameters of system (1), (2) were changed.
Suppose that hypothesis H0 describes the nominal mode of system operation,
i.e. the fault-free mode.
3.1

The Exact Solution to the Problem of Fault Point Detection

Consider that a ratio test is started at time t = t0 , but the point of fault
occurrence t01 ∈ [t0 , tN ], (where ti ∈ [t0 , tN ] is a testing interval) is unknown.
Therefore, in addition to the main hypothesis H0 , N − 1 alternative hypotheses
Hj are added instead of one alternative hypothesis H1 . Each Hj means that
at the moment tj , the system parameters are changed from {Φt0 , Bt0 , Γt0 , and
Ht0 } to {Φt1 , Bt1 , Γt1 , and Ht1 }.
Taking into account these prior assumptions, we can write down the expression for the likelihood ratio function:
λj0
t = log

j
j
P {νj1
, . . . , νt1
|Hj }
j0
= λj0
t−1 + µt ,
P {νj0 , . . . , νt0 |H0 }

t≥1

(6)

where
T

−1 j
νt1

j
j
j
−1
T
2µj0
t = log det Σt0 − log det Σt1 + νt0 Σt0 νt0 − (νt1 ) (Σt1 )

.

(7)

The value λj0
t needs to be calculated at the moment t = t0 + j, where t ∈
[t0 , tN ].

420

I. Semoushin, J. Tsyganova, and M. Kulikova

In Sect. 2, two Kalman ﬁlters were required, one based on the assumption of
hypothesis H0 and the other on assumption of H1 . In the present case, we need
one Kalman ﬁlter per hypothesis, that is, N + 1 ﬁlters.
Let us denote the Kalman ﬁlter based on H0 by F0 and the Kalman ﬁlters
j
is a residual with the covaribased on Hj by Fj , j = 1, . . . , N . Then in (7), νt1
j
ance Σt1 , obtained from the Kalman ﬁlter Fj . So we have the Bank of N + 1
competitive Kalman ﬁlters.
The ratio test for system fault point detection is as follows [3]:


1. If ∀t < tN λj0

t ≤ B, the test is terminated with the choice of H0



(the system fault point was not detected on the testing interval).



 2. If ∃! j : λj0

t ≥ A, the test is terminated with the choice of Hj


 (the system fault point was detected at the moment t0 + j).



 3. If ∀j : B < λj0 ≤ A, the test is repeated for t + 1.

t


i0
4. If ∃i = j : λj0
t ≥ A and λt ≥ A, the test is terminated with

the choice of “leading” hypothesis Hl , for which the value of like

j0

i0

lihood function is maximum, that is λl0

t = max{λt , λt } (the



system fault point was detected at the moment t0 + l).



i0

5.
If ∀i, j λj0

t ≤ B and B < λt < A, the hypothesis Hj is excluded



from the set of the considered hypothesis and the test is repeated


 for t + 1 .

(8)

Now we can describe the testing algorithm:
The test is performed on the testing interval [t0 , tN ]; from the beginning of
the test at each subsequent moment t = j, the Kalman ﬁlter Fj based on Hj is
included into the contest of ﬁlters (into the Bank of Kalman ﬁlters).
Thus, after processing N measurements N + 1 ﬁlters are added to the Bank,
moreover each ﬁlter Fj , j = 1, . . . , N matches likelihood against ﬁlter F0 .
If all hypotheses Hj , j = 0, . . . , N , are equiprobable, then the initial value of
each likelihood ratio function λj0
t equals zero. When a’priori probabilities of all
hypotheses are given, the initial condition for the functioning of ﬁlter Fj is the
value λj0
0 = log{Pj /P0 }, where Pj is an a’priori probability of hypothesis Hj .
So, the value λj0
t begins to change at Step j of the test at the moment of ﬁlter
Fj connection. For all t < t0 + j, λj0
t = 0, that corresponds with the condition
that the ﬁlter is disconnected.
It is clear that according to the suggested algorithm, the number of competitive ﬁlters grows at each step of the test. This, in turn, leads to the growth of
necessary calculations of likelihood ratio function at each step of the test. The realization of such algorithm in an ideal case will require unlimited computational
resources (machine time and an enormous memory size for the data storing).
Therefore in spite of the simplicity of the suggested algorithm and the guaranteed solution to the problem, there is the essential drawback that the algorithm
is not practically realizable for the solving of real life problems because of the
unbounded growth of computations at each step of the test.

Fault Point Detection

421

In the next section, we solve the problem of elimination of such obvious
drawback of the obtained solution, i.e. the unbounded growth of the number of
competitive ﬁlters.
3.2

The New Algorithm of Fault Point Detection with the Bank of
Finite Number of Filters

From the previous topic, there follows the necessity to ﬁnd the solution to the
problem of Fault Point Detection with the Bank of ﬁnite Number of Kalman
ﬁlters. In other words, the problem to evaluate the necessary number of competitive Kalman ﬁlters is posed.
We need to determine the average sample numbers required for decision making between the two hypotheses H1 and H0 . We ﬁrst need to know the average
values of the increment in the probability ratio λt at each stage in the test.
In other words, we need to obtain expressions for
1 T −1
−1
T
Σt0 νt0 − νt1
Σt1
νt1 }|H1
µ1 = E log(det Σt0 )1/2 − log(det Σt1 )1/2 + {νt0
2
1 T −1
−1
T
µ0 = E log(det Σt0 )1/2 − log(det Σt1 )1/2 + {νt0
Σt0 νt0 − νt1
Σt1
νt1 }|H0
2
at time t = n.
Let the system and ﬁlter equations be given by (1), (2), and (3), and all
system parameters not depend on time (i. e. Φti = Φi , Hti = Hi , Bti = Bi ,
Γti = Γi ).
Suppose that in ﬁlter equations we use system parameters Φ1 , H1 , B1 , Γ1
corresponding to the change in the characteristics (i.e. hypothesis H1 ) instead
of true values of matrix parameters Φ0 , H0 , B0 , Γ0 (i.e. hypothesis H0 ). In this
case, in order to determine the values of µ0 and µ1 , we need to know the actual
¯t0 = E{νt0 ν T }. In the case of optimal Kalman
correlation matrix of residuals Σ
t0
ﬁlter, the residuals ν(t) have zero mean and covariance matrix Σt0 .
¯t0 as
Let us write Σ
T
T
¯t0 = E{νt0 ν T } = E{(H0 xt − H1 x
Σ
ˆ−
x−
t )(H0 xt − H1 (ˆ
t ) )} + I .
t0

(9)

After the expansion, we obtain the formula for calculation of correlation matrix
of residuals
T
T
¯t0 = H0 E{xt xT }H T − H0 E{xt (ˆ
Σ
x−
t ) }H1
t
0
− − T
− T
T
+H1 E{ˆ
xt (ˆ
xt ) }H1 − H1 E{ˆ
xt xt }H0T + I .

(10)

For its calculation, we need to ﬁrst solve the following diﬀerence equations:
E{xt xTt } = Φ0 E{xt−1 xTt−1 }ΦT0 + Γ0 Γ0T + B0 ut−1 E{xTt−1 }ΦT0
+Φ0 E{xt−1 }uTt−1 B0T + B0 ut−1 uTt−1 B0T
T
x−
E{xt (ˆ
t ) }

=

T
T
Φ0 E{xt−1 (ˆ
x+
t−1 ) }Φ1

+

Φ0 E{xt−1 }uTt−1 B1T

(11)

422

I. Semoushin, J. Tsyganova, and M. Kulikova

T
x+
E{xt (ˆ
t ) }
T
E{ˆ
x−
x−
t (ˆ
t ) }
T
E{ˆ
x+
x+
t (ˆ
t ) }

=
=
=

E{ˆ
x+
t } =
−
E{ˆ
xt } =

+B0 ut−1 E{(ˆ
xt−1 )T }ΦT1 + B0 ut−1 uTt−1 B1T

(12)

T
T
T
T
E{xt (ˆ
x−
t ) }(I − H1 Kt ) + E{xt xt }H0 Kt
T
T
T
T
Φ1 E{ˆ
x+
x+
x+
t−1 (ˆ
t−1 ) }Φ1 + Φ1 E{ˆ
t−1 }ut−1 B1
T
T
T
T
x+
+B1 ut−1 E{(ˆ
t−1 ) }Φ1 + B1 ut−1 ut−1 B1
T
T
T
(I − Kt H1 )E{ˆ
x−
x−
t (ˆ
t ) }(I − H1 Kt )
T
T
T
+(I − Kt H1 )E{ˆ
x−
t xt }H0 Kt
T
T
T
+Kt H0 E{xt (ˆ
x−
t ) }(I − H1 K1 )
+Kt H0 E{xt xTt }H0T KtT + Kt KtT
(I − Kt H1 )E{ˆ
x−
t } + Kt H0 E{xt }
+
Φ1 E{ˆ
xt−1 } + B1 ut−1

(13)

E{xt } = Φ0 E{xt−1 } + B0 ut−1

(14)

(15)
(16)
(17)
(18)

satisfying the initial conditions
T
T
E{x0 xT0 } = E{x0 (ˆ
x+
x+
x+
¯0 x
¯T0
0 ) } = E{ˆ
0 (ˆ
0 ) } = P0 + x

E{x0 } = E{ˆ
x+
¯0 .
0}=x

(19)

¯t1 when true values of matrix
Similarly, we can obtain the formula for Σ
parameters are Φ1 , H1 , B1 , Γ1 (this corresponds to hypothesis H1 ), but in ﬁlter
equations parameters Φ0 , H0 , B0 , Γ0 are used.
Consider the equilibrium solutions
Σ0 = lim Σt0 ,
t→∞

Σ1 = lim Σt1 ,
t→∞
0
¯0 = lim Σ
¯t0 = [¯
σij
],
Σ
t→∞

−1
0
Σt0
= [σij
]

−1
1
Σt1
= [σij
]
1
¯
¯t1 = [¯
Σ1 = lim Σ
σij
] .

Then
2µ1 = log det Σ0 − log det Σ1 +
2µ0 = log det Σ0 − log det Σ1 −

(20)

t→∞

m
i,j=1
m
i,j=1

0 0
(¯
σij
σij ) − m
1 1
(¯
σij
σij ) + m .

(21)

Now we can ﬁnd the average sample numbers:
¯B is the average number of samples required to reach any threshold from the
N
start of the test, assuming H0 is true;
¯A is the average number of samples required to reach any threshold from the
N
start of the test, assuming H1 is true.
These sample numbers are given by
¯B = [αA + (1 − α)B]/µ0
N
¯A = [(1 − β)A + βB]/µ1 .
N

(22)

Fault Point Detection

423

Let M be the necessary number of samples for decision making in the fault
point detection problem. We evaluate M as
¯B ) .
¯A , N
M = max(N

(23)

That means that on the testing interval [t0 , tN ] at each time moment only M + 1
Kalman ﬁlters can work simultaneously, and each Kalman ﬁlter is based on the
corresponding hypothesis.
From the beginning of the test through the ﬁrst M steps, ﬁlters Fi , i =
1, . . . , M , enter the Bank. They match the Filter F0 corresponding the hypothesis
H0 which means that “the fault point was not detected on the M steps of the
test”.
The ratio test for system fault point detection is the same as (8).
The only diﬀerence is that competitive ﬁlters make a queue, moreover each
ﬁlter works for only a limited number of steps (in our case, M steps). At the
(M + 1)-th step of the test, the ﬁlter Fi , which was in the Bank during M steps
and has not made the decision (this corresponds to condition B < λ1i 0 < A), is
excluded from the Bank. Instead, the new ﬁlter FM +1 is based on the hypothesis
HM +1 which means that “the system fault occurred on the (M + 1)-th step of
the test”, that is, immediately after moment t = t0 + M + 1.
This algorithm allows us to solve the fault point detection problem with less
computational resources consumption.
However, such algorithm is more complex due to the necessity of obtaining
the value M . This requires us to solve equations (9)–(19). Moreover, if estimate
of M is found incorrectly, and it is less than the real number of samples required
for decision making, then according to the suggested algorithm the solution may
not be found.

4

Numerical Example

To show how the algorithms of the previous sections may be used to detect the
parameter change point for linear dynamical systems, we consider the following
example taken from the inertial navigation [7]:




0.75 −1.74 −0.3
0.0 −0.15
0.0 0.0 0.0
 0.09 0.91
 0.0 0.0 0.0 
−0.0005 0.0 −0.008 








0.95
0.0 0.0
xt+1 =  0.0 0.0
 xt +  24.64 0.0 0.0  wt
 0.0 0.0


0.0
0.55 0.0
0.0 0.835 0.0 
0.0 0.0
0.0
0.0 0.905
0.0 0.0 1.83
zt =

1−e 0
0 0
1−f
xt + vt ,
0
1−g 0 1−h 0

e, f, g, h = {0, 1}

{wt } and {vt } are zero-mean white Gaussian sequences with covariances Qt = I3 ,
and Rt = I2 (In is the n-dimensional identity matrix). These equations describe
the damped Shuler loop driven by the exponentially correlated 3-dimensional
noise wt [7].

424

I. Semoushin, J. Tsyganova, and M. Kulikova

The program for numerical experiments was written in Pascal.
Let us describe the numerical experiments for the problem of fault point
detection. Consider the previous example and two hypotheses: H0 which means
the nominal mode of the system (the system parameters are Φ0 = Φ(ti ), Γ0 =
Γ (ti ), B0 = B(ti ), H0 = H(ti ), where [e, f, g, h] = [0, 0, 0, 0]; and H1 which
means the fault mode of the system (the system parameters are Φ1 = Φ(ti ), Γ1 =
Γ (ti ), B1 = B(ti ), H1 = H(ti ), where {[e, f, g, h]|e, f, g, h ∈ {0, 1}}\{[0, 0, 0, 0]}.
So, there are 16 types of system faults. All experiments are conducted, provided
that the system fault point is random.
Table 1. Detection of the fault point in the system. The type of possible fault is
[0, 0, 1, 0]. The algorithm with the increasing KFB size.
Experiment
number
1
2
3
4
5
6
7

LF at the moment The fault Detected fault Delay in
of detection
point
point
detection
16.715688
39
39
0
12.159357
21
22
1
66.411028
36
36
0
12.822501
33
33
0
22.600478
11
25
14
96.973967
41
41
0
16
0
67.016929
16
Mean delay in detection: 2 iterations

Accepted
hypothesis
H1
H1
H1
H1
H1
H1
H1

KFB
size
44
22
36
35
26
41
16

Let us demonstrate the eﬃciency of fault point detection algorithms considered in Sect. 3.1 and Sect. 3.2.
We conducted a series of experiments for the problem of fault point detection. The conditions of experiments are: the error probabilities α = 0.00001,
β = 0.00001, two thresholds A = 11.512915 and B = −11.512915; the point
of possible system fault is unknown and random for each experiment. For all
experiments, the system fault really takes place. That means that it is necessary
to conﬁrm the hypothesis H1 and to detect the fault point by using the available measurements. The experiments are conducted for the faults of two types:
[e, f, g, h] = [0, 0, 1, 0] and [e, f, g, h] = [0, 0, 0, 1].
The eﬃciency of the testing algorithm described in Sect. 3.1, can be evaluated
according to the data of Table 1. The testing interval here is [1, 50], the number
of experiments equals 7, and the series of 500 experiments were also conducted.
According to the experimental data, we conclude that the algorithm with
increasing size of the Kalman Filters Bank (KFB) provides a guaranteed solution
of the fault point detection problem, but it has one obvious drawback. Since the
maximum number of Kalman Filters in the Bank tends to the length of testing
interval, the algorithm can not be practically applied to the real life problems.
Now we will try to evaluate the eﬃciency of the algorithm with the Bank of
ﬁnite number of competitive Kalman Filters, described in Sect. 3.2.

Fault Point Detection

425

The results of numerical experiments are shown in Table 2. For the realization
of a ratio test before testing, we need to evaluate the necessary parameter M
(that is the KFB size) by using the equations (9)–(19). It is clear that this
estimate will diﬀer in diﬀerent types of system faults. Table 2 shows the testing
results for the system fault [0, 0, 1, 0] and the testing interval [1, 100]. Given the
error probabilities α and β and the type of system fault, the maximum number
of simultaneously competitive ﬁlters needed for the decision making equals 27.
Table 2. Detection of the fault point in the system. The type of possible fault is
[0, 0, 1, 0]. The algorithm with the ﬁnite KFB.
Experiment
number
1
2
3
4
5
6
7
8
9

LF at the moment The fault Detected fault Delay in
of detection
point
point
detection
24.242963
48
49
1
39.596861
55
55
0
18.171810
5
5
0
41.172073
40
40
0
19.113414
12
17
5
15.477792
31
31
0
35.373164
11
11
0
41.409267
76
77
1
18.612180
19
19
0
Mean delay in detection: 1 iteration

Accepted
hypothesis
H1
H1
H1
H1
H1
H1
H1
H1
H1

KFB
size
9
24
7
6
27
19
6
12
8

Table 3. Detection of the fault point in the system. The type of possible fault is
[0, 0, 1, 0]. The algorithm with the ﬁnite KFB.
Experiment
number
1
2
3
4
5
6
7
8
9

LF at the moment
of detection
24.242963
—
18.171810
41.172073
—
—
35.373164
41.409267
18.612180

The fault
point
48
55
5
40
75
67
11
76
19

Detected fault
point
49
—
5
40
—
—
11
77
19

Delay in
detection
1
—
0
0
—
—
0
1
0

Accepted
hypothesis
H1
—
H1
H1
—
—
H1
H1
H1

KFB
size
9
—
7
6
—
—
6
12
8

According to the data in Table 2, the algorithm with the ﬁnite number of
Kalman ﬁlters is eﬃcient for solving the fault point detection problem. So, we
have practically veriﬁed the correctness of the theoretical estimate for the KFB

426

I. Semoushin, J. Tsyganova, and M. Kulikova

size, because all the experiments required that the real number of competitive
ﬁlters be less or equal to 27.
The eﬃciency of such algorithm essentially depends on the correct choice of
the KFB size. If parameter M is incorrect, and is less (but not greater) than
the real number of required Kalman ﬁlters, then the solution may not be found.
Such case is conﬁrmed by the data of Table 3. Here the value of M was chosen
to be 10, but really it must be 27. According to Table 3, in 50% of cases the
fault point was not detected on all testing interval [1, 100] (dash corresponds to
these cases).

5

Conclusion

The concept of the Bank of Competitive Kalman Filters is applicable to the
problem of fault point detection in stochastic system behavior.
The algorithm with increasing number of Kalman ﬁlters provides a guaranteed solution to the fault point detection problem, but it has an essential
drawback: it can not be practically realized for the real life problems.
To avoid this drawback, another algorithm with the ﬁnite size of Kalman
Filters Bank was considered in this paper. The authors suggest a method to ﬁnd
the estimate of required size of Kalman Filters Bank. All theoretical results are
conﬁrmed by multiple numerical experiments.

References
1. Newbold, P., M. and Ho Yu-Chi: Detection of Changes in the Characteristics of a
Gauss-Markov Process. IEEE Trans. on Aerosp. and Electron. Systems, Vol. AES4(5) (1968) 707–718
2. Hanlon, P., D., Maybeck, P., S.: Equivalent Kalman Filter Bank Structure for
Multiple Model Adaptive Estimation (MMAE) and Generalized Likelihood Ratio
(GLR) Failure Detection. Proc. of the 36th Conference on Decision & Control: San
Diego California USA 5 (1997) 4312–4317
3. Semoushin, I., V.: The Quickest in the Mean Manoeuvre Detection with the
Guaranteed Probability Error (Methods). Shipbuilding: Computing Techniques 26
(1990) 3–7 [In Russian]
4. Semoushin, I., V., Tsyganova, J., V.: An Eﬃcient Way to Evaluate Likelihood
Functions in Terms of Kalman Filter Variables. In: Murgu, A. and Lasker, G., E.
(eds.): Adaptive, Cooperative and Competitive Processes in Systems Modelling,
Design and Analysis. The International Institute for Advanced Studies in Systems
Research & Cybernetics: University of Windsor Windsor Ontario Canada (2001)
67–74
5. Semoushin, I., V., Tsyganova, J., V., Kulikova, M., V.: On Computation of the
Likelihood Ratio Function for Gaussian Markov Signals. In: Andreev, A., C.
(ed.): Basic problems of mathematics and mechanics: Ulyanovsk State University
Ulyanovsk Russia 2(7) (2000) 93–100 [In Russian]
6. Bierman, G., J.: Factorization Methods for Discrete Sequential Estimation. Academic Press, New-York (1977)
7. Stratton, A.: Combination of Inertial Navigation and Radio Systems. In Borisov,
N., I. (ed.): Problems of Inertial Navigation, Mashinostroienie, (1961) [In Russian]

