A Dynamic Data Driven Computational
Infrastructure for Reliable Computer
Simulations
J.T. Oden1 , J.C. Browne1 , I. Babuˇska1 , C. Bajaj1 , L.F. Demkowicz1 ,
L. Gray2 , J. Bass1 , Y. Feng1 , S. Prudhomme1 , F. Nobile1 , and R. Tempone1
1

Institute for Computational Engineering and Sciences,
The University of Texas at Austin, U.S.A.
2
Department of Otolaryngology - Head and Neck Surgery, University of Texas
Medical School, University of Texas Health Science Center at Houston, U.S.A.

Abstract. The paper presents an initial study on designing a Dynamic
Data Driven (DDD) computational environment to enable reliable and
eﬃcient determination of Head Related Transfer Functions (HRTF) for
patients with reconstructed ears. The determination involves a synthesis
of coordinated experiments and large scale, parallel computer simulations. Time limits (one working day), cost of MRI scans, and parallelism
in experimental and computer simulations impose the need for a DDD
enabling fast and reliable results.

1

Introduction: Dynamic Data Driven Application
Systems

Traditional application simulations are conducted with static data inputs. In
context of Finite Element (FE) simulations, this means deﬁning geometry of the
domain of computations, physical coeﬃcients and parameters and source and
boundary data. Once the data are speciﬁed, the FE codes are run, possibly in an
adaptive loop, to assure discretization error control. Any change in data implies
restarting the codes from the beginning. In a Dynamic Data Driven Application
System [14], an initial set of data is deposited in a depository, but, during the simulation process that follows, the data may evolve or be updated as a result of new
measurements, or a feedback mechanism resulting from comparing simulations
with experiments. A classical example is a weather prediction system where current simulation results may be updated as new measurements become available
“online”. Incoming extra information may be incomplete for simply restarting
the simulations and more sophisticated “matching mechanisms” are necessary.
Veriﬁcation and Validation (V and V). The systematic study of reliability of
computer simulations of physical phenomena is generally divided into two basic
processes, Veriﬁcation and Validation (V and V). As a scientiﬁc discipline, V
and V is in its very early stages of development. Veriﬁcation is the process of
determining the accuracy with which a given mathematical model of physics is
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3038, pp. 756–763, 2004.
c Springer-Verlag Berlin Heidelberg 2004

A Dynamic Data Driven Computational Infrastructure

757

solved; validation is the process of determining that the mathematical model
represents the actual physical system with suﬃcient accuracy. Here veriﬁcation
does not include software engineering issues of the logical correctness of the
program which implements the simulations (this is so-called code veriﬁcation).
Veriﬁcation is thus concerned with estimating and controlling numerical approximation error. In recent years, signiﬁcant progress has been made in this area.
The idea of developing an adaptive control system for implementing V and V
was made possible by the discovery of the concept of hierarchical modeling and
“goal-oriented” adaptive methods based on a posteriori estimates of modeling
error [7] and approximation error [1,2]. These error estimates techniques are crucial to the success of any adaptive control paradigm that must react to dynamic
data management, and to adapting the models used in simulations.
Uncertainties in Data. Another source of error relevant to validation is due to
the randomness of the material and geometry data. There are several approaches
available to quantify this error. One direct approach is provided by the perturbation method described in [6]. If it is possible to develop statistical information
on the material data to determine the probability density function (PDF), the
material coeﬃcients can be represented as a sum of a deterministic average and
a stochastic perturbation. A similar decomposition holds then for the solution
to the problem. Bounds on the stochastic perturbation of the solution can then
be calculated and used as an additional measure of the modeling . The second approach is based on the theory of stochastic functions characterized by
Karhunen-Lo`eve expansion (see [4]). Similar methodologies can be used for estimating uncertainties in geometry data, although the problem is tackled in the
literature much less frequently.
This paper presents an initial study on designing a Dynamic Data Driven
(DDD) computational environment to enable reliable and eﬃcient determination
of Head Related Transfer Functions1 (HRTF) for patients with reconstructed
ears. The proposed project brings together specialists from Otolaryngology Research Laboratory at the University of Texas Houston Health Science Center,
and researchers at the Institute for Computational Engineering and Sciences, at
the University of Texas at Austin.

2

Analysis of the Eﬀect of the Exterior Geometry of the
Human Head on Human Hearing

Historically, many scientiﬁc investigations of important physical systems have
been purely experimental, out of necessity since the complexities of the systems
have been beyond the capability of numerical simulation. An illustrative example
of such a system is the human auditory system. A purely empirical approach has
placed limitations upon determining basic mechanisms of the sense of hearing, as
1

Pressure on the ear drum expressed as a function of frequency and direction of an
incoming plane wave

758

J.T. Oden et al.

well as the development of hearing-aid technology for the hearing-impaired, and
hearing protection for those working in noisy environments. Application of experimental tools to characterize human hearing have tended to be idiosyncratic
to the subject, expensive and time-consuming in application, and dependent
upon subjective feedback of the subject being tested. The latter issue is particularly problematic in extremely young patients who lack the ability to fully or
productively participate in many testing procedures [5,13].
We describe how a new approach based on DDDAS in which the numerical modeling capabilities of geometry reconstruction and visualization schemes,
and parallel hp boundary element method, developed at ICES, are linked to
experimental data obtained at the UT Health Science Center in Houston. The
project includes means for controlling modeling and discretization errors. While
the technique has a myriad of potential application areas, initial studies are
planned to apply the technique to the investigation of the eﬀect of external ear
reconstruction in patients born with only one external ear. The sounds that
stimulate the ear, and the ability of a subject to localize sound, is dependent
in large part on the ﬁltering and ampliﬁcation characteristics of the external
ear, as well as the brain’s ability to interpret the person’s own HRTF. The work
enables the study of sensitivity on the variation of geometry from one external
ear, to a surgically-constructed ear, to a normally formed ear and the eﬀects of
the variation upon the resultant HRTF. Potential for application of the coupled
modeling and experimental technique to other hearing-related issues, and the
pursuit of sponsoring of future research are also under investigation.

3

Geometry Reconstruction from MRI Scans

In many applications, including the current one, the geometry is too complicated
to be modeled by standard CAD systems, and only a linear scan obtained by
MRI or CT techniques is available. In the CAD supported case, generation of
higher order meshes is possible simply by interpolating the surface parametrization provided by the CAD modeler. In the case of scans, the generation of higher
order meshes is not straightforward, since, a priori, only a linear triangulation is
available. A number of diﬀerent procedures are available that will produce higher
order meshes from linear triangulations, including element clustering, decimation schemes, etc. A C 1 surface reconstruction has many advantages from the
viewpoint of scattering problems in acoustics, including the elimination element
clustering around artiﬁcial C 0 edges, and a lowering of the order of singularities
in the integral kernels. One approach for generating a C 1 representation from a
linear triangulation has been given by Bajaj, Xu, [3].
The C 1 geometry reconstruction, done within a Geometrical Modeling Package, a small CAD system developed at ICES that interfaces with the boundary
element codes, is discussed next, and allows for an initial mesh generation as
well automatic geometry updates during mesh reﬁnements.

A Dynamic Data Driven Computational Infrastructure

4

759

Modeling of Human Head Acoustics

The acoustics of the human head is modeled with a comparatively simple linear acoustics model which, in the frequency domain, reduces to solving the
Helmholtz equation in the domain exterior to the human head (but including the ear channel), accompanied by Sommerfeld radiation condition at inﬁnity, and impedance boundary conditions. The material data are represented by
impedance, usually assumed to be piecewise constant, with diﬀerent values for
the head, ear channel, and the ear drum. The values may depend (mildly) on the
patient, i.e. the impedance of the head may reﬂect the amount of patient’s hair.

5

Parallel hp-Adaptive Boundary Elements

Major components of the parallel hp BEM code developed to solve the acoustics
problem, are given below.
Burton-Miller Integral Equation (BMIE). The Helmholtz equation is replaced
with an equivalent Burton-Miller integral equation deﬁned on the surface of the
head, including the ear channel and the ear drum. The formulation is uniformly
stable in frequency. The integral equation is formulated in a variational form,
allowing for reduction of singularities to weak singularities only. This facilitates
and accelerates the integration of element matrices.
hp-discretizations. The integral equation, in its variational form, is discretized
then using Galerkin approximation and hp ﬁnite element meshes in which element size h and polynomial order p may be varied locally to minimize the error
per given problem size. If done properly, the hp discretizations have the potential
of delivering exponential convergence and superaccurate results.
Goal-oriented adaptivity. The adaptivity is driven by minimizing the error in
a speciﬁc quantity of interest, in our case - the average pressure on the ear
drum. The algorithm requires solving simultaneously both the original and dual
problems [11]. The error in pressure is then represented in terms of a functional
involving both solutions, and serves as a starting point to determine optimal hp
mesh reﬁnements. The algorithm produces a sequence of meshes of increasing
size and complexity with corresponding solutions, i.e. the pressure distribution
on the head. The problem involves multiple loads as one mesh serves all (typically
sixty) directions of the incoming plane wave. The problem can thus be very time
consuming, and even with a parallel implementation, attaining a 1 percent accuracy, may require at this point many CPU hours. During the mesh optimization
process, the code deposits intermediate meshes and corresponding (multiple)
solutions on the disk from which the results may be accessed and visualized.

760

J.T. Oden et al.

Parallel implementation. The parallel implementation has been done within
PLAPACK [10]. This includes integration of element matrices, a dense linear
solver based on LU decomposition, and a posteriori error estimation done in
parallel. The problem does not involve any domain decomposition; a copy of
data structure supporting the geometry, mesh and solution, is maintained on
each processor.
Error control. At present, the code includes only an a-posteriori error control
of the discretization error. Neither modeling nor geometry induces errors are
being estimated. Sensitivity of the solution with respect to the geometry is
critical in the case of frequencies corresponding to resonating modes (concha or
ear channel modes).

6

A DDDAS for Modeling Acoustics of Human Head

A DDD adaptive control system is under study in which scanned images of
external ears (both premature and reconstructed) is to be provided from remote
repository at the UT Health Sciences Center at Houston. The team in Austin
constructs mathematical models of sound propagation into the ear canals of
speciﬁc patients. The computed HRTF’s are then to be reported back to Houston
to allow for a comparison with those obtained experimentally.
Existing computational methodology are being upgraded to a fully dynamic
system enabling a continuous exchange of data between Houston and Austin, and
a critical comparison of the computational and experimental results. A typical
patient visit to the Houston facility lasts one day (eight working hours), and the
targeted mode of operation is to complete the patient analysis within that time.
A schematic mode of operation is presented in Fig. 1. All software including
visualization will be run in a client/server mode, with the actual codes being
executed at ICES platforms. A common depository will be established with a
new directory opened for each new patient. At any time during the operation,
the depository may include the following ﬁles.
MRIscan1. The ﬁrst MRI scan of the patient head and ear channel.
MRIscan2. The second MRI scan, done later, if the geometry reconstruction
code fails to deliver acceptable results.
head geometry. Patient head reconstructed geometry, based on one or two
MRI scans.
Results of computation. A sequence of optimal meshes with corresponding
pressure distributions and computed HRTFs.
Error estimates. Results of sensitivity analysis providing error bounds for obtained numerical results (for each mesh and each frequency), as well as possible results of comparison of measured and computed HRTFs.
The following is a possible scenario. A patient arrives at the Houston facility
early in the morning, the ﬁrst MRI scan ($1,000 each) is made and deposited in

A Dynamic Data Driven Computational Infrastructure

761

UTHC Houston

MRI scan1
MRI scan 2
measured_HRTF

head model
pressure_ results
computed_HRTF

Depository

results
measured_HRTF
computed_HRTF

V and V group

errof estimates

MRI scan1
MRI scan 2

head_geometry

results

head_geometry

Geometry
Reconstruction Visulization
Group

HPC group

Fig. 1. A schematic idea of the proposed DDD computational environment

the depository. The initiation of a new patient case includes also specifying the
corresponding impedance data.
The geometry of the patient is reconstructed in the form of a ﬁne, unstructured linear mesh and stored in the depository. The reality of the geometry reconstruction schemes is that, in presence of noisy data, they produce many artifacts.
Such discrepancies prove to be critical in highly accurate computer simulation
of acoustics resulting in erroneous results. The model has to be “cleaned” interactively. The corrections will be done in communication between Houston and
the geometry reconstruction group at Austin. The process may result in the necessity of taking another MRI scan and producing a better resolution geometry
representation based on both sets of data.
The initial, “dirty” image is still suﬃcient to start the solution process and begin the mesh optimization process. As new, cleaner data arrive in the depository,
the geometry input will be upgraded in the ongoing numerical simulations. One
should emphasize that several 2 copies of the code will be executed in parallel.
The moment ﬁrst meshes are generated and results are computed and stored
in the depository, the Validation and Veriﬁcation group begins analyzing sensitivity of the results with respect to geometry and impedance data, as well
as more thorough (and expensive) discretization error estimates are computed
(initial, rough estimates are provided by mesh optimization algorithms).
In meantime, the team in Houston completes determining HRTFs experimentally and the results are communicated to the V&V group for a ﬁnal, quantitative
2

The HRTFs are usually determined for 6-10 diﬀerent frequencies

762

J.T. Oden et al.

2.34436
2.20923
2.07409
1.93895
1.80381
1.66868
1.53354
1.3984
1.26326
1.12813
0.992988
0.85785
0.722713
0.587575
0.452437

Fig. 2. Pressure distribution on a model of human head

error analysis. Dependently upon results of the sensitivity analysis, the group at
Houston may decide to change the impedance data, as well.
A new methodology for comparing the experiments with simulations is
needed. This will involve comparing not only the measured and computed
HRTF’s but also designing experiments that may verify the computed data in an
“inverse mode”. For example, we can test the accuracy of vertical and horizontal sound localization using established ”auditory virtual reality” techniques. To
do this we use the calculated HRTF’s from reconstructed ears to make special
stereo sounds and determine if localization under headphones is accurate.

7

Conclusions

The project described is an excellent example of an important DDDAS. The system builds on collaborations of medical researchers, computer scientists, computational scientists, engineers, and mathematicians in Houston and Austin. On top
of necessary improvements of existing methodologies, the main challenges are:
– to build an environment allowing for a dynamic data transfer and simultaneous visualization of results by the three involved parties (experiment,
geometry reconstruction and visualization, modeling), and,

A Dynamic Data Driven Computational Infrastructure

763

– to develop algorithms for estimating sensitivity of the simulated results with
respect to reconstructed geometry and material data,
– to establish a mathematically sound methodology that would allow for comparing the experiments and simulations with a feedback and a dynamic modiﬁcation of data on both sides.
Acknowledgment. The authors gratefully acknowledge support of the NSF
under grant 0205181.

References
1. Ainsworth, M., and Oden, J.T.: A Posteriori Error Estimation in Finite Element
Analysis. John Wiley & Sons, New York, (2000)
2. Babuˇska, I., Strouboulis, T.: Finite Element Method and its Reliability. Oxford
Univ. Press (2001)
3. Bajaj, C., Chen, J., and Xu, G.: Modeling with cubic A-patches, ACM Transactions
on Graphics, 14 (2) (1995) 103–133.
4. Deb, D.K., Babuˇska, I., Oden, J.T.: Solution of Stochastic Partial Diﬀerential
Equations Using Galerkin Finite Element Techniques. Comput. Methods Appl.
Mech. Eng. 190 (2001), 6359–6372
5. Jahrsdoerfer, R.A., Yeakley, J.W., Aguilar, E.A., Cole, R.A., and Gray, L.C.: A
grading system for the selection of patients with congenital aural atresia. American
Journal of Otolology 13 (1992) 6–12
6. Kleiber, M., Hien, T.D.: The Stochastic Finite Element Method: Basic Perturbation Technique and Computer Implementation. John Wiley & Sons, (1992)
7. Oden, J.T., Prudhomme, S., Estimation of modeling error in computational mechanics. J. Comput. Phys., 182 (2002), 496–515
8. Oden, J.T., Babuska, I., Nobile, F., Feng, Y., and Tempone, R.: Theory and
methodology for estimation and control of errors due to modeling, approximiation, and uncertainty. Computer Methods in Applied Mechanics and Engineering,
MAFELAP 2003 Special issue (to appear)
9. Oden, J.T., Browne, J.C., Babuska, I., Liechti K.M., Demkowicz, L., Bass J., Feng,
Y., Prudhomme, S., Nobile, F., Tempone, R.: A computational infrastructure for
reliable computer simulations. In F. Darema (ed.) Dynamic Data Driven Application Systems, Kluver Academic Publishers (to appear)
10. van de Geijn, R.A.: Using PLAPACK, The MIT Press (1997)
11. Walsh, T., Demkowicz, ,L.: hp Boundary element modeling of the external human
auditory system - goal oriented adaptivity with multiple load vectors, Computer
Methods in Applied Mechanics and Engineering, 192 (2003) 125–146
12. Walsh, T., Demkowicz, L, Charles, R.: Boundary element modeling of the external
human auditory system, JASA (to appear)
13. Wilmington, D., and Gray, L., Jahrsdoerfer, R.: Binaural processing after corrected
congenital unilateral conductive hearing loss. Hearing Research, 74 (1994) 99–114
14. NSF Workshop (2000) http://www.cise.nsf.gov/dddas

