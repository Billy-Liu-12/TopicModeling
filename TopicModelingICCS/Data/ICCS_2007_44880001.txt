Resolving Occlusion Method of Virtual Object in
Simulation Using Snake and Picking Algorithm
JeongHee Cha, GyeYoung Kim, and HyungIl Choi
Information and media institute, School of Computing, School of Media,
Soongsil University , Sangdo 5 Dong , DongJak Gu, Seoul, Korea
pelly@vision.ssu.ac.kr, {gykim1,hic}@ssu.ac.kr

Abstract. For realistic simulation, it is essential to register the two worlds,
calculate the occlusion realm between the real world and the virtual object, and
determine the location of the virtual object based on the calculation. However,
if the constructed map is not accurate or the density is not sufficient to estimate
the occlusion boundary, it is very difficult to determine the occlusion realm. In
order to solve this problem, this paper proposes a new method for calculating
the occlusion realm using the snake and picking algorithm. First, the wireframe
generated by the CCD image and DEM was mapped using the visual clues to
acquire 3D information in the experimental realm, and the 3D information was
calculated at the point where occlusion problem for a moving target. The
validity of the proposed approach under the environment in which partial
occlusion occurs has been provided by an experiment.
Keywords: Occlusion, Snake, Picking, DEM, Augmented Reality, Simulation.

1 Introduction
Augmented reality is an area of technology that has originated in virtual reality. While
virtual reality offers a virtual world in which users are completely immersed,
augmented reality offers virtual objects on the basis of real world images. At present,
augmented reality technology is being researched and applied to various areas
including the military, medicine, education, construction, game, and broadcasting.
This paper studied on the development of a realistic simulated training model through
the display of virtual targets in the input images of CCD camera mounted in a tank
and the determination of occlusion areas generated from the creation and movement
of virtual objects through a movement path according to a scenario. Augmented
reality has three general characteristics: image registration, interaction, and real
time[1]. Image registration refers to the matching of the locations of the real world
object that users watch and the related virtual object, real time refers to the real time
image registration and interaction. Interaction implies that the combination of virtual
objects and the objects in real images must be harmonized with surrounding
environment in a realistic manner, and refers to the determination of occlusion areas
according to the changed location or line of sight of the observer or the re-rendering
of virtual objects after detection of collisions. However, to solve the problems of
Y. Shi et al. (Eds.): ICCS 2007, Part II, LNCS 4488, pp. 1 – 8, 2007.
© Springer-Verlag Berlin Heidelberg 2007

2

J. Cha, G. Kim, and H. Choi

occlusion such as the hiding of farther virtual objects by closer objects and the
covering of objects in real images by other objects, the two worlds must be accurately
coordinated and then the depth of the actual scene must be compared with the depth
of virtual objects[2][3]. But if the accuracy or density of the created map is
insufficient to estimate the boundary of occlusion area, it is difficult to determine the
occlusion area. To solve this problem, first, we created a 3D wireframe using the
DEM of the experiment area and then coordinate this using CCD camera images and
visual clues. Second, to solve the problem of occlusion by accurately estimating the
boundary regardless of the density of map, this paper also proposed a method to
obtain the reference 3D information of the occlusion points using the Snake algorithm
and the Picking algorithm and then to infer the 3D information of other boundaries
using the proportional relations between 2D and 3D DEMs. Third, for improving
processing speed, we suggest a method by comparing the MER(Minimum Enclosing
Rectangle) area of the object in the camera’s angle of vision and the MER of the
virtual target. Fig. 1 shows the proposed system framework.

Fig. 1. Proposed System Framework

2 Methodology
2.1 Formation of Wireframe Using DEM and Registration with Real Images
Using Visual Clues
The topographical information DEM (Digital Elevation Model) is used to map the
real world coordinates to each point of the 2D CCD image. DEM has information on
the latitude and longitude coordinates expressed in X and Y and heights in fixed
interval. The DEM used for this experiment is a grid-type DEM which had been
produced to have the height information for 2D coordinates in 1M interval for the
limited experiment area of 300 m x 300 m. The DEM data are read to create a mesh

Resolving Occlusion Method of Virtual Object in Simulation

3

with the vertexes of each rectangle and a wireframe with 3D depth information as
Fig. 2[4][5]. This is overlaid on the sensor image to check the coordination, and visual
clues are used to move the image to up, down, left or right as shown in Fig. 3, thus
reducing error. Based on this initial coordinated location, the location changes by
movement of vehicles were frequently updated using GPS (Global Positioning
System) and INS (Inertial Navigation System).

Fig. 2. Wireframe Creation using DEM

Fig. 3. Registration of Two Worlds using Visual Clues

2.2 Extracting the Outline of Objects and Acquiring 3D Information
The Snake algorithm[6][7] is a method of finding the outline of an object by
repeatedly moving to the direction of minimizing energy function from the snake
vertex input by user. The energy function is shown in Expression [1]. As the energy
function is calculated for a discrete space, the parameters of each energy function
become the coordinates of each vertex in the image. In Expression [1], v (s ) is the

()

snake point, and v( s ) = ( x ( s ), y ( s )) , where x s and y (s ) refer to the positions
of x and y in the image of the snake point. Also, α , β and γ are weights, and this

paper gave α = 1 , β = 0.4 , and
1

γ = 2.0 , respectively.

Esnake = ∫ (αEcont (v( s )) + βEcurve (v( s )) + γEimage (v( s )))ds
0

(1)

4

J. Cha, G. Kim, and H. Choi

The first term is the energy function that represents the continuity of the snake
vertexes surrounding the occlusion area and the second term is the energy function
that controls the smoothness of the curve forming the snake, of which the value
increases along with the curvature, enabling the detection of corner points. Lastly,
Eimage is a image feature function. All energy functions are normalized to have a
value between 1 and 0. As shown in Table 1, this algorithm extracts the outline by
repeatedly performing the energy minimization algorithm which sets a 3 pixels x3
pixels window at each vertex v(i ) , finds positions where energy is minimized in
consideration of the continuity between previous and next vertexes, curvature, and
edge strength, and then moves the vertexes to the positions.
Table 1. Snake Algorithm

2.3 Acquisition of 3D Information Using the Picking Algorithm
In order to acquire the 3D information of the extracted vertexes, this paper used the
Picking algorithm which is a well-known 3D graphics technique[8]. It finds the
collision point with the 3D wireframe created by DEM that corresponds to the points
in 2D image and provides the 3D information of the points. The picking search point
is the lowest point of the vertexes of the objects extracted from the 2D image. The
screen coordinate system that is a rectangular area indicating a figure that has been
projection transformed in the 3D image rendering process must be converted to the
viewport coordinate system in which the actual 3D topography exists to pick the
coordinate system where the mouse is actually present. First, the conversion matrix to
convert viewport to screen is used to obtain the conversion formula from 2D screen to
3D projection window, and then the ray of light is lengthened gradually from the
projection window to the ground surface to obtain the collision point between the
point to search and the ground surface. Fig. 4 is an example of picking the collision
point between the ray of light and DEM. The lowest point of the occlusion area
indicated by an arrow is the reference point to search, and this becomes the actual
position value of 2D image in a 3D space.

Resolving Occlusion Method of Virtual Object in Simulation

5

(a)occlusion candidate (b)matching ref.point and DEM (c)3D information extraction
Fig. 4. 3D information Extraction using Collision point of Ray and DEM

2.4 Creation of 3D Information Using Proportional Relational Expression
The collision point, or reference point, has 3D coordinates in DEM, but other vertexes
of the snake indicated as object outline cannot obtain 3D coordinates because they
don’t have a collision point. Therefore, this paper suggested obtaining a proportional
relation between 2D image and 3D DEM using the collision reference point and then
obtaining the 3D coordinates of another vertex. Fig. 5 shows the proportional relation
between 2D and 3D vertexes. In Fig. 5, S m is center of screen, S B is reference point
of snake vertex (lowest point),
point,

ΔS B = (ΔS xB , ΔS yB ) , S k is a point except reference

ΔS k = (ΔS xk , ΔS yk ) . Pm is projection point of straight line of PB in 3D,

which is through the center of screen.

ΔPB = (ΔPxB , ΔPy B , ΔPzB ),

Pk

is

PB is 3D correspondence point of S B ,
a

point

except

reference

point,

ΔPk = (ΔPxk , ΔPyk , ΔPzk ) , t = Po PB , t m = Po Pm , θ B : ∠tt , φ B : ∠t t m . t ' is
projected vector of t to xz plane.
'

'

Fig. 5. Proportional Relation of the Vertex in 2D and 3D

pm that passes the center of the screen using the coordinates of the
'
reference point obtained above, t must be obtained first. As the t value is given by
To get

6

J. Cha, G. Kim, and H. Choi

the picking ray, the given
this

θB

t value and y B are used to get θ B and t ' is obtained using

in Expression (2).

θ B = sin −1 (
To get
tm,

ΔPyB
t

), t ' = t B cos (θ B )

t' = t'

(2)

t m , φB is obtained from Expression (2) which is the angle between t’ and

t m can be obtained using φB from Expression (3).

φB = tan −1 (
Because t m

ΔPxB
t'

), t ' = t m cos (φB ) , t m =

t'
cos (φB )

tm = t m

(3)

= p zm , Pm = (0,0, t m ) .

Now, we can present the relation between the 2D screen view in Fig. 5 and the 3D
space coordinates, and this can be used to get pk , which corresponds to the 2D snake
vertex.

ΔS B : ΔPB = ΔS k : ΔPk , ΔS xB : ΔPxB = ΔS xk : ΔPxk ,
ΔPxk =

ΔPxB × ΔS xk
ΔS xB

, ΔS yB

Consequently, we can get

: ΔPyB ΔS yk : ΔPyk , ΔPyk =

ΔPyB × ΔS yk

(4)

ΔS yB

ΔPk = (ΔPxk , ΔPyk ) , which is the 3D space point

corresponding to each snake vertex to search.
2.5 Creation of Virtual Target Path and Selection of Candidate Occlusion
Objects Using MER (Minimum Enclosing Rectangle)
To test the proposed occlusion-resolving algorithm, we created the movement path of
a virtual target, and determined the changes of the direction and shape of the target as
well as the 3D position of the target. First, the beginning and end points of the target
set by instructor were saved and the angle of these two points was calculated, and the
direction and shape of the target were updated in accordance with the change of the
angle. Further, the remaining distance was calculated using the speed and time of the
target, and the 3D coordinates corresponding to the position after movements were
determined. We also suggest a method of improving processing speed by comparing
the MER (Minimum Enclosing Rectangle) area of the object in the camera’s angle of
vision and the MER of the virtual target because the relational operations between all
objects extracted from the image for occlusion processing and the virtual target take
much time. The MER (Minimum Enclosing Rectangle) of an object refers to the

Resolving Occlusion Method of Virtual Object in Simulation

7

minimum rectangle that can enclose the object and determines the object that has an
overlapping area by comparing the objects in the camera image and the MER of the
virtual target. In addition, the distance between object and virtual target is obtained
using the fact that the determined object and virtual target are placed more or less in a
straight line from the camera, and this value was used to determine whether there
exists an object between the virtual target and the camera.

3 Experimental Results
Fig. 6(left) shows movement path of the virtual target which trainee sets. Also, (right)
shows the various virtual targets created to display the targets changing with
movement on the image.

Fig. 6.

Moving Route Creation(left) and Appearance of Virtual Object as it Moved(right)

Fig. 7 shows the virtual images moving along the path by frame. We can see that as
the frames increase, it is occluded between the tank and the object.

Fig. 7. Experimental Results of Moving and Occlusion

Table 2 compares between the case of using snake vertexes to select objects in the
image to compare with virtual targets and the case of using the proposed MER. With
the proposed method, the processing speed decreased by 1.671, which contributed to
performance improvement.

8

J. Cha, G. Kim, and H. Choi
Table 2. Speed Comparison

Method
Snake vertexes
MER(proposed)

Total frame
301
301

Used object
10
10

Speed(sec)
112
67…

Frame per sec.
2.687
4.492

4 Conclusions
To efficiently solve the problem of occlusion that occurs when virtual targets are
moved along the specified path over an actual image, we created 3D virtual world
using DEM and coordinated this using camera images and visual clues. Moreover, the
Snake algorithm and the Picking algorithm were used to extract an object that is close
to the original shape to determine the 3D information of the point to be occluded. To
increase the occlusion processing speed, this paper also used the method of using the
3D information of the MER area of the object, and proved the validity of the proposed
method through experiment. In the future, more research is required on a more
accurate extracting method for occlusion area that is robust against illumination as
well as on the improvement of operation speed.

Acknowledgement
This work was supported by the Korea Research Foundation Grant funded by the
Korean Government(MOEHRD)(KRF-2006-005-J03801).

References
[1] Bimber, O. and Raskar, R.,Spatial Augmented Reality: A Modern Approach to Augmented
Reality, Siggraph 2005, Los Angeles USA
[2] J. Yong Noh and U. Neumann. Expression cloning. In SIGGRAPH'01, pages 277-288,
2001.
[3] E. Chen. Quicktime VR-an image-based approach to virtual environment navigation. Proc.
of SIGGRAPH, 1995.
[4] Lilian Ji, Hong Yan, "Attractable snakes based on the greedy algorithm for contour
extraction", Pattern Recognition 35, pp.791-806 (2002)
[5] Charles C. H. Lean, Alex K. B. See, S. Anandan Shanmugam, "An Enhanced Method for
the Snake Algorithm," icicic, pp. 240-243, First International Conference on Innovative
Computing, Information and Control - Volume I (ICICIC'06), 2006
[6] Wu, S.-T., Abrantes, M., Tost, D., and Batagelo, H. C. 2003. Picking and snapping for 3d
input devices. In Proceedings of SIBGRAPI 2003, 140-147.

