Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 1909 – 1918

International Conference on Computational Science, ICCS 2013

Dynamic sensor network conﬁguration in InfoSymbiotic systems
using model singular vectors
Adrian Sandua , Alexandru Cioacaa , Vishwas Raoa
a Computational Science Laboratory,
Department of Computer Science, Virginia Tech,
2202 Kraft Drive, Blacksburg,VA 24060, USA

Abstract
Data assimilation is an important data-driven application (DDDAS) where measurements of the real system are used to constrain simulation results. This paper describes a methodology for dynamically conﬁguring sensor networks in data assimilation
systems based on numerical models of time-evolving diﬀerential equations. The proposed methodology uses the dominant
model singular vectors, which reveal the directions of maximal error growth. New sensors are dynamically placed such as to
minimize an estimation error energy norm. A shallow water test problem is used to illustrate our approach.
Keywords: Dynamic data driven applications, model singular vectors, sensor network conﬁguration.

1. Introduction
Data assimilation is an important application of data-driven application systems (DDDAS, or InfoSymbiotic
systems) where measurements of the real system are used to constrain simulation results. Speciﬁcally, data assimilation is the process that combines prior information, numerical model predictions, observational data, and
the corresponding error statistics, to produce a better estimate of the state of a physical system [1, 2]. The fourdimensional variational (4D-Var) approach is formulated as a nonlinear optimization problem constrained by the
numerical model. The initial conditions (as well as boundary conditions, forcings, or model parameters) are adjusted such as to minimize the discrepancy between the model trajectory and a set of time-distributed observations.
In real-time operations, the analysis is performed in cycles: observations within an assimilation time window are
used to obtain an optimal trajectory, which provides the initial condition for the next time window, and the process
is repeated.
Since data assimilation is a cyclic process, we are interested to improve the eﬃciency of next assimilation
windows by analyzing the previous ones. This paper describes a methodology for dynamically conﬁguring sensor
networks in 4D-Var data assimilation applications. At the end of each assimilation window the areas of maximum
energy impact are estimated using Hessian singular vectors. New sensors dynamically placed in those areas will
improve the quality of the results for the next assimilation window. Speciﬁcally, they provide a maximal reduction
of the L2 norm of the assimilation error.
∗ Corresponding

author. Tel.: +1-540-231-2193 ; fax: +1-540-231-6075 .
E-mail address: {sandu, alexgc, visrao}@cs.vt.edu.

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.360

1910

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918

The singular vector method searches for the error structures in the analysis ﬁeld at current time which, propagated by the forecast model, achieve maximum growth at the veriﬁcation time tv . Singular vectors (SVs) are the
directions of fastest error growth over a ﬁnite time interval [3, 4, 5, 6]. Buizza and Montani [7] showed that SVs
can identify the most sensitive regions of the atmosphere for targeted observations. They are useful as long as the
linearity assumption of error propagation holds [8]. Majumdar et al.[9] compare the SV approach for observation
targeting to the ensemble transform Kalman ﬁlter. Palmer et al. [10] argue that for predictability studies an appropriate metric is the perturbation energy. Daescu and Navon [11, 12] discuss the adaptive observation problem
in the context of 4D-Var data assimilation. Estimation of the optimal placement of adaptive observations is also
discussed in [13, 14]. Leutbecher [15] derives optimal locations of observations by minimizing the variance of the
assimilated ﬁeld; a computationally tractable problem is obtained by projecting the covariance on the subspace of
the dominant singular vectors.
Observations can be dynamically placed in well-chosen locations such as to reduce the initial condition uncertainties and decrease forecast errors. A number of methods were proposed to “target observations”, i.e. to select
areas where additional observations are expected to improve considerably the skill of a given forecast. Singular
vectors identify sensitive regions of the atmospheric ﬂow and can be used to optimally conﬁgure the observational
network.
2. Data assimilation
Data assimilation produces improved estimates of the true state xtrue of a physical system by combining information from three diﬀerent sources: the physical and chemical laws of evolution (encapsulated in the model),
the reality (as captured by the observations), and the current best estimate of the distribution of pollutants in the
atmosphere (encapsulated in the prior) – all with associated errors [16].
The background (prior) probability density encapsulates our current knowledge of the tracer distribution. A
∈ N xb0 , B0 , where xb0 ∈ Rn is the background
typical assumption is that this is a normal probability density, xtrue
0
n×n
initial state and B0 ∈ R is the background error covariance matrix.
The model encapsulates our knowledge about physical and chemical laws that govern the evolution of the
physical system. It evolves an initial state x0 ∈ Rn at time t0 to future state values xi ∈ Rn at future times ti ,
xi = Mt0 →ti (x0 ) .

(1)

Perturbations (small errors) evolve according to the tangent linear model (TLM)
δx(tF ) = Mt0 →tF δx(t0 ) ,

(2)

where M = M is the linearized model solution operator. Adjoint variables evolve according to the adjoint model
λ(t0 ) = M∗tF →t0 λ(tF ) .

(3)

Here M∗tF →t0 = MTt0 →tF denotes the adjoint of the linearized solution operator M. The state error covariance matrix
is propagated from t0 to tF according to
P(tF ) = Mt0 →tF P(t0 ) M∗tF →t0 + Q .

(4)

The additional term Q represents the covariance of the model errors.
Observations are sparse and noisy snapshots of reality available at several discrete time moments. Speciﬁcally,
measurements yi ∈ Rm of the physical state are taken at times ti , i = 1, · · · , N. In order to relate the model state to
observations we consider the relation
yi = H xtrue
,
− εobs
i
i

i = 1, · · · , N ,

(5)

the observation errors, assumed to be normally distributed, εobs
∈
where H is the observation operator, and εobs
i
i
obs
and
ε
for
i
j)
are
assumed
to
be
independent.
N (0, Ri ). Observation errors at diﬀerent times (εobs
i
j

1911

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918

Based on these three sources of information data assimilation computes the analysis (posterior) probability
density. The best estimate xa of the true state obtained from analysis distribution is called the aposteriori, or the
analysis state. The strongly-constrained 4D-Var data assimilation looks for the maximum a posteriori (MAP)
estimate xa0 of the true initial conditions by solving the optimization problem:
subject to: xi = Mt0 →ti (x0 ) , i = 1, · · · , N ,

xa0 = arg min J (x0 )
where
J (x0 ) =

1
x0 − xb0
2

T

x0 − xb0 +
B−1
0

1
2

N

(H(xi ) − yi )T R−1
i (H(xi ) − yi ) .

(6)

(7)

i=1

The gradient of (7) reads
∇x0 J (x0 ) = B−1
x0 − xb0 +
0

N

M∗ti →t0 HTi R−1
i (H(xi ) − yi ) .

(8)

i=1

The Hessian of (7) is obtained by diﬀerentiating (8)
∇2x0 ,x0 J (x0 )

=

B−1
0 +

N

M∗ti →t0 HTi R−1
i Hi Mt0 →ti +

i=1

N
i=1

d
M∗
HTi R−1
i (H(xi ) − yi ) .
d x0 ti →t0

The Gauss-Newton Hessian approximation discards the last term containing second derivatives of the model solution operator times the residual. The second order adjoint (SOA) of the chemical transport model [17, 18]
computes matrix vector products between the Hessian and user-supplied vectors. The SOA model provides information about the aposteriori error via the observation that the Hessian inverse approximates the posterior error
covariance [19]
−1
A0 ≈ ∇2x0 ,x0 J(xa0 )
.
3. Model singular vectors
Singular vectors (SVs) determine the most rapidly growing perturbations in the atmosphere. The magnitude
of the perturbation at the initial time t0 is measured in the L2 (“energy”) norm deﬁned by a symmetric positive
deﬁnite matrix E
δx(t0 ) 2E = δx(t0 ) , E δx(t0 ) .
(9)
Similarly, the perturbation magnitude at the veriﬁcation time tv is measured in a norm deﬁned by a positive deﬁnite
matrix F
δx(tv ) 2F = δx(tv ) , F δx(tv ) .
(10)
We call the norms (9) and (10) squared the “perturbation energies”.
Our main interest is to minimize the forecast uncertainty over a well deﬁned area (the “veriﬁcation domain”
Ωv ⊂ Ω) at a well deﬁned time (the “veriﬁcation time” tv ). We deﬁne a spatial projection operator Π from the
whole model domain to the veriﬁcation domain:
Π : Ω ⊂ Rn −→ Ωv ⊂ Rnv .

(11)

The ratio between perturbation energies at tv (over the veriﬁcation domain) and at t0 (over the entire domain)
oﬀers a measure of error growth:
σ =
2

Π δx(tv )
δx(t0 )

2
E

2
F

=

δx(t0 ), M∗tv →t0 Π∗ F Π Mt0 →tv δx(t0 )
δx(t0 ), E δx(t0 )

.

(12)

Model singular vectors (SVs) are deﬁned as the directions of maximal error growth, i.e. the vectors sk (t0 ) that
maximize the ratio σ2 in equation (12). These directions are the solutions of the generalized eigenvalue problem
M∗tv →t0 Π∗ F Π Mt0 →tv sk (t0 ) = σ2k E sk (t0 ) .

(13)

1912

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918

Using the square root of the the symmetric positive deﬁnite matrix E the generalized eigenvalue problem (13) can
be reduced to a simple eigenvalue problem
E− 2 M∗tv →t0 Π∗ FΠ Mt0 →tv E− 2 vk = σ2k vk (t0 ) ,
1

1

1

vk = E 2 sk (t0 ) .

(14)

The eigenvalue problem (14) can be solved eﬃciently using the software package ARPACK [20]. Furthermore,
vk (t0 ) are the left singular vectors in the singular value decomposition
F 2 Π Mt0 →tv E− 2 = U · Σ · V T
1

1

Σ = diagk {σk } ,

where

1

σk uk = F 2 Π sk (tF ) .

(15)

The SVs sk are E-orthogonal at t0 and F-orthogonal at tF
sk (t0 ), Es j (t0 ) = 0

Πsk (tF ), FΠs j (tF ) = 0

and

for

j

k.

(16)

The equations (15) and (16) justify the name of “total energy singular vectors”. The singular value decomposition
of the linear operator Mt0 →tv , with the E scalar product at t0 and the F scalar product at tF , has the left singular
vectors sk (t0 ) and the right singular vectors sk (tF ). The singular values σk are the error ampliﬁcation factors along
each direction sk .
A special set of energy norms is provided by the choice F = Π = I and E = A−1
0 . In this case the resulting
singular vectors sk (t0 ) evolve into the leading eigenvectors sk (tv ) of the forecast error covariance matrix P f (tv ).
The eigenvectors sk (tF ) are called “Hessian singular vectors” (HSVs) associated with the cost functional J [21].
Since the leading eigenvectors of P f (tv ) are the directions of maximum variance of forecast error, HSVs deﬁne the
directions along which we must do a good job of analysis in order to minimize the forecast error at tv . We assume
that the model error is negligible over the period [t0 , tv ]. From equation (13) it follows that Hessian singular
vectors are the solutions of the following generalized eigenvalue problem
2
2
M∗tv →t0 Mt0 →tv sk (t0 ) = σ2k A−1
0 sk (t0 ) = σk ∇x0 ,x0 J sk (t0 ) .

(17)

The second relation comes from the fact that the inverse of the analysis covariance matrix is equal to the Hessian
matrix of the analysis cost function J in the variational analysis system. This motivates the name Hessian singular
vectors for the solutions sk (t0 ) of the generalized eigenproblem (17).
The eigenvalue problem (17) is solved in the time interval [t0 , tv ] for each target using an iterative method
that require only matrix–vector products [20, 22]. In [23] we have computed the total energy singular vectors
for CTMs. To the best of our knowledge this is the ﬁrst work that attempts the computation of Hessian singular
vectors for CTMs. In [24] we have used Hessian singular vectors for the purpose of observation targeting.
The singular vectors associated with the largest m singular values,
Vm (t0 ) = s1 (t0 ), · · · , sm (t0 ) ,

(18)

span a subspace of the state space which will have the maximum inﬂuence on the veriﬁcation area at the veriﬁcation time.
4. Dynamic Conﬁguration of the Sensor network
We now determine those locations where perturbations have the largest energy impact over the veriﬁcation
area. For this, consider an initial perturbation vector δk equal to zero everywhere, except for one component at a
given location where its value is 1. The index k spans all variables and all grid points in the model, and represents
one independent observation of one variable. The vector can be written in terms of the singular vectors
δk =

αm sm (t0 ) ,
m

where the expansion coeﬃcients can be obtained by the orthogonality relations of the singular vectors
αm = δk , E sm (t0 ) = (E sm (t0 ))k .

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918

1913

The vector of perturbations at the ﬁnal time is
αm Mt0 →tv sm (t0 ) =

δx(tF ) =
m

αm σm sm (tF ) .
m

Using the orthogonality of the singular vectors at the ﬁnal time in the F-norm we have that the total perturbation
energy is
σ2m α2m =
σ2m ((E sm (t0 ))k )2 .
Ek = Πδx(tF ) , FΠδx(tF ) =
m

m

A vector which has each component equal to the energy impact of the corresponding delta initial perturbation is
therefore:
σ2m (E sm (t0 ))2 =
ζm2 .
(19)
E=
m

m

The squares of the vectors are considered in an element by element sense. This sum can be approximated by the
ﬁrst several terms which correspond to the dominant singular values.
The best observations should be located at those points where the energetic impact over the veriﬁcation area
is the largest. These points are easily identiﬁed as they are the largest entries of the E vector.
5. Numerical Experiments
5.1. The shallow water equations
We apply this computational methodology to the shallow-water equations (SWE), which approximate ﬂuid
ﬂow inside a shallow basin. Consider the following two-dimensional PDE system:
∂
∂
∂
h + (uh) + (vh) = 0
∂t
∂x
∂y
∂
1
∂
∂
(uh) + (u2 h + gh2 ) + (uvh) = 0
∂t
∂x
2
∂y
1
∂
∂
∂ 2
(vh) + (uvh) + (v h + gh2 ) = 0 .
∂t
∂x
∂y
2
A numerical model was built to compute the solution of these equations. The space discretization was performed
using a ﬁnite volume-type scheme and the time discretization using fourth-order Runge-Kutta. This method was
introduced by Liska and Wendroﬀ in [25].
The spatial domain is square shaped (Ω = [−3, 3]2 ), and the integration window is t0 = 0 ≤ t ≤ t F = 0.1. Here
h(t, x, y) denotes the ﬂuid layer thickness, and u(t, x, y), v(t, x, y) are the components of the velocity ﬁeld. g is the
standard value of the gravitational acceleration. The boundary conditions are periodic in both directions.
For more advanced applications, such as nonlinear optimization and sensitivity analysis, we need to compute
derivatives of the model states and parameters. This can be accomplished using the methodology of adjoint models
[26, 27]. A distinction is made between continuous adjoints, obtained by linearizing the diﬀerential equations, and
discrete adjoints, obtained by linearizing the numerical method. The resulting adjoint equations are then solved
numerically through time integration.
We build the adjoint models associated with our SWE model through automatic diﬀerentiation [28] using
the TAMC tool [29]. The tangent-linear model (TLM) propagates perturbations forward in time. The ﬁrst-order
adjoint model (FOA) propagates perturbations backwards in time and can be used to compute the gradients of a
scalar cost function deﬁned on the model trajectory. Second-order adjoint models (SOA) compute the product
between the Hessian of f and a vector. Second-order adjoint models are considered to be the best approach
to compute Hessian-vector products, but have yet to become popular in practice because of their computational
demands. When one does not have access to the second-order adjoint, Hessian-vector products can be computed
through various approximations, such as ﬁnite diﬀerence with gradients or the Gauss-Newton approximation.
The overhead of running adjoint models is a crucial aspect of the computational strategy. For our particular
implementation, one full SOA integration is about 3.5 times more expensive than a single ﬁrst-order adjoint run,

1914

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918

Fig. 1. The evolution of the height of the ﬂow with time. Superimpoposed are the ﬂow velocity vectors. Six diﬀerent time instances
(corresponding to 0, 20, 40, 60, 80, and 100 model time steps) are shown.

while the FOA takes 3.7 times longer than the forward run. However, this ratio depends on the numerical methods
used to solve the diﬀerential equations or the automatic diﬀerentiation tool employed. For certain numerical
methods used to solve the forward model, it is possible to develop smart strategies of reusing computation which
lead to adjoint models that take less time to run than the forward model. An example can be found in [30] where
the adjoint equations of this very SWE system are derived by hand and then implemented as numerical models.
5.2. Data assimilation scenario
We apply our computational framework to two data assimilation scenarios with SWE. These two scenarios
have very similar setting, the only diﬀerence being the amount of observations we assimilate. The resolution of
the 2D computational grid on which the models operate is 40 grid points on both directions (1600 in total). Thus,
the model has 4800 variables. The size of the timestep is set at 1e − 3 and the models are conﬁgured to run for
1 − e1 seconds (N = 100 discrete steps of time). The reference solution is synthesized for h as a Gaussian pulse
of amplitude A = 30 centered on the grid. The u/v ﬁelds are made consistent with h with the help of the forecast
model. The background solution xb is generated by applying a correlated perturbation on the reference solution for
h, u and v. The background error covariance B was generated for a standard deviation of 5% with a nondiagonal
structure and correlation distance of 5 grid points. This will help the 4D-Var method to spread the information
for each grid point to its neighbors. The model is ran starting from the reference solution in order to generate
the synthetic observations. The observation frequency is set to once every 20 time steps. In order to simulate the
eﬀect of noise over observations, we apply a normal random perturbation to the perfect synthetic observations.
The observation error covariance R is a diagonal matrix, based on the assumption that the observational errors are
uncorrelated. The standard deviation of these errors was set to 1% of the largest absolute value of the observations
for each variable. The observation operator H is conﬁgured to select observations for each variable at each point
of the grid (observations are dense in space). In a realistic setting, the operator H is enforced by the structure of
the observational network. The diﬀerence between the two experiments:
1. REG100. Observations are available for h, u and v at every other fourth grid point on horizontal and vertical.
This leads to 100 observations for each variable and 300 in total, as shown in ﬁgure 2(a).

1915

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918
40

40

35

35

30

30

25

25

20

20

15

15

10

10

5

5

0
0

10

20

30

40

0
0

10

20

30

40

(a) Sensor Locations for the REG100 case (b) Sensor Locations for the SEL10 case
Fig. 2. Sensor locations for two diﬀerent scenarios.

2. SEL10. Observations are available for h, u and v at 10 selected locations, as shown in ﬁgure 2(b).
In Figure 1 we present 6 snapshots of the model trajectory, as started from the background solution and taken at
every 20 time steps. These correspond to the assimilation times.
To minimize the 4D-Var cost function, we use the L-BFGS-B solver [31]. Since the SWE model does not
represent a signiﬁcant computational burden, we allowed the solver to run for 500 iterations, or until the gradient
of the 4D-Var cost function was reduced from a magnitude of 1e + 2 to 1e − 4.
5.3. Numerical results
The minimizer of the 4D-Var cost function as provided by L-BFGS-B represents an improved estimate of
the initial state of the model assimilating the available observations. The next step is to compute the singular
vectors as described in Section 3. This requires the solution of a generalized eigenvalue problem. The main
computational constraint consists in circumventing the fact that we do not have access to the full Jacobian (and its
transpose) of the model states or to the 4D-Var Hessian. Instead, we can compute their action on a vector by using
adjoint models. Jacobian-vector products can be computed by running the TLM initialized with said vector, and
the transpose-Jacobian-vector products by running the FOA backwards in time, initialized with the seed vector.
4D-Var Hessian vector-products can be obtained using the second-order adjoint model.
Generalized eigenvalue problems can be solved iteratively when we only have access to matrix-vector products. Classic algorithms such as Arnoldi [32] or Lanczos [33] compute the eigenvectors associated with the m
largest or smallest eigenvalues, where m corresponds to the number of matrix-vector products to be evaluated and
is speciﬁed by the user. For our scenario, we compute 100 leading eigenvectors and then compute the perturbation
energy associated with them following equation (19). We use an iterative algorithm to compute the eigenvectors
associated with the largest 100 eigenvalues for our two test scenarios, whose values are plotted in ﬁgures 3(a) and
4(a). We notice there is a signiﬁcant cutoﬀ after the ﬁrst 50 eigenvalues so we keep only these eigenvectors for
computing the energy norm E. Figures 3 and 4 show the plot of the perturbation energy of h (3(b) and 4(b)), u (3(c)
and 4(c)) and v (3(d) and 4(d)) on the computational grid, for REG100 and SEL10, respectively. We notice similar
features across both cases. The proﬁle of the perturbation energy for h, the height of the ﬂow, reveals areas of high
uncertainty in the four corners of the computational grid. Meanwhile, the perturbation energy of the wind vector
components u and v is considerably larger on the opposite edges of the grid which correspond to the direction represented by the vector component: East-West for u and North-South for v. For the u and v variables there can also
be noticed visible features in the middle of the grid that are similar between the two cases. This is to be expected,
since both cases operate on the same forecast scenario. The magnitude of the perturbation energies reﬂects the
fact that one of the scenario (REG100) assimilates more information than the other (SEL10). For the former case,
the perturbation energies have values of order 104 which can be associated with a reanalysis of smaller uncertainty
than for other case, where magnitudes are of order 106 . Also, the areas of high uncertainty in h for the REG100
case are smaller than their equivalents for the SEL10 case. This is a clear indication that the forecast started from

1916

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918
6

2

x 10

6

x 10

40

8

1.8

35
7

1.6

30

Y−Direction

Eigenvalues

6

1.4
1.2
1

25
5

20
4

15
3

0.8

10

0.6

5

2

1

0.4
0

20

40

60

80

0
0

100

(a) Generalized eigenvalues

5

10

15

20
25
X−Direction

30

35

40

(b) Perturbation energies for the height ﬁeld
10

10

x 10

40

x 10

40

4.5

35
4

25
3.5

20
3

15

Y−Direction

Y−Direction

30

35

4

30

3.5

25

3

20

2.5

15

10

2.5

2

10
1.5

5

5
2

0
0

5

10

15

20
25
X−Direction

30

35

40

1

0
0

5

10

15

20
25
X−Direction

30

35

40

(c) Perturbation energies for the U velocity (d) Perturbation energies for the V velocity
ﬁeld component
ﬁeld component
Fig. 3. Perturbation energies for the variables in the REG100 case. Higher energies correspond to better virtual locations of the sensors.

the reanalysis obtained from assimilating more information (REG100) is less likely to be aﬀected by perturbations
situated along the principal directions of error growth. These directions of error growth constitute the left-hand
side of the generalized eigenvalue problem and are the same for any data assimilation scenario. The diﬀerence
between various scenarios is found on the right-hand side in the matrix norm, the 4D-Var Hessian, which gives us
a meaningful measure for the perturbation energy that reﬂects the particular data assimilation setting used. The
4D-Var Hessian approximates the inverse of the covariance matrix of the errors in the reanalysis, so it can be
interpreted as a measure of trust in the reanalysis. In order to improve the quality of the reanalysis forecast, we
need to target for observation (and subsequently, assimilation) those areas where the perturbation energy is large.
This means we have to install additional sensors in the corners of the grid and on the borders.
6. Conclusions
This paper describes a methodology for dynamically conﬁguring sensor network in dynamic data driven applications. The methodology uses Hessian singular vectors computed in the context of 4D-Var data assimilation.
At the end of each assimilation window the areas of maximum energy impact are estimated; new sensors placed
in those areas will provide a maximal reduction of the L2 norm of the assimilation error.
The singular vectors of the tangent linear model are a powerful tool for analyzing the directions of maximum
error growth in the forecast. When the forecast error is measured in the norm given by the 4D-Var Hessian at
the reanalysis, these singular vectors are named “Hessian singular vectors”. They are tailored to the particular

1917

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918
4

5.5

x 10

4

x 10

40

5

35

4.5

30

6

Y−Direction

Eigenvalues

5

4

3.5

4

25
20

3

15
2

3
10

1

2.5

5

2
0

20

40

60

80

0
0

100

(a) Generalized Eigenvalues

5

10

15

20
25
X−Direction

30

35

40

(b) Perturbation energies for the height ﬁeld
7

7

x 10

40

x 10

40

3.5

3.5

35

35
3

3

30

25

2.5

20
2

15

Y−Direction

Y−Direction

30

25

2.5

20
2

15
1.5
1.5

10
5

10
1

5
1

0
0

5

10

15

20
25
X−Direction

30

35

40

0
0

5

10

15

20
25
X−Direction

30

35

40

(c) Perturbation energies for the U velocity (d) Perturbation energies for the V velocity
ﬁeld component
ﬁeld component
Fig. 4. Perturbation energies for the variables in the SEL10 case. Higher energies correspond to better virtual locations of the sensors.

data assimilation process through the Hessian matrix and reveal the areas of high uncertainty for the reanalyzed
forecast under the constraint given by the 4D-Var setting, including available observations.
Computing Hessian singular vectors has the advantage of being feasible in practice. They do not need the full
expression of the 4D-Var Hessian or the model tangent linear and adjoint operators. Instead, they can be computed
through algorithms that work with matrix-vector products, which can be obtained by running tangent linear, and
ﬁrst and second order adjoint models. Also, since one only needs to compute the leading singular vectors, they
can be computed within a budget of model runs suitable for large real-time operations. When a higher accuracy is
required, more model runs can be allocated.
We perform experiments with a data assimilation system for the shallow water equations, in two settings
diﬀerentiated by the number and location of available observations. The dominant 50 dominant singular vectors
are used to approximate the perturbation energy. When assimilating more observations, the perturbation energy is
smaller, indicating a lower uncertainty. The proﬁle of the perturbation energy reveals that additional observations
in areas situated on the borders of the computational grid would improve the quality of the analysis and the forecast
accuracy.
Acknowledgements
This work was supported by AFOSR DDDAS program through the awards FA9550–12–1–0293–DEF and
AFOSR 12-2640-06, managed by Dr. Frederica Darema.

1918

Adrian Sandu et al. / Procedia Computer Science 18 (2013) 1909 – 1918

References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]

[21]
[22]
[23]
[24]
[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]
[33]

R. Daley., Atmospheric data analysis, Cambridge University Press, Cambridge, 1991.
E. Kalnay., Atmospheric modeling, data assimilation and predictability, Cambridge University Press, Cambridge, 2002.
E. Lorenz, A study of the predictability of a 28 variable atmospheric model, Tellus 17 (1965) 321–333.
F. Molteni, T. Palmer, Predictability and ﬁnite-time instability of the northern winter circulation, Quarterly Journal of the Royal Meteorological Society 119 (1993) 269–298.
R. Mureau, F. Molteni, T. Palmer, Ensemble prediction using dynamically-conditioned perturbations, Quarterly Journal of the Royal
Meteorological Society 119 (1993) 299–323.
Z. Li, I. Navon, M. Hussaini, Analysis of the singular vectors of the full-physics fsu global spectral model, Tellus accepted.
R. Buizza, A. Montani, Targeting observations using singular vectors, Journal of the Atmospheric Sciences 56 (1999) 2965–2985.
J. Hansen, A. Smith, The role of operational constraints in selecting supplementary observations, Journal of the Atmospheric Sciences
57 (2000) 2859–2871.
S. Majumdar, C. Bishop, R. Buizza, R. Gelaro, A comparison of ensemble transform Kalman ﬁlter targeting guidance with ecmwf and
nrl total-energy singular vector guidance, Quarterly Journal of the Royal Meteorological Society 128 (585) (2002) 2527–2549.
T. Palmer, R. Gelaro, J. Barkmeijer, R. Buizza, Singular vectors, metrics, and adaptive observations, Journal of the Atmospheric Sciences
55 (4) (1998) 633–653.
D. Daescu, G. Carmichael, An adjoint sensitivity method for the adaptive location of the observations in air quality modeling, Journal of
the Atmospheric Sciences 60 (2) (2003) 434–450.
D. Daescu, I. Navon, Adaptive observations in the context of 4D-Var data assimilation, Meteorology and Atmospheric Physics 84 (4)
(2004) 205–226.
R. Gelaro, R. Buizza, T. N. Palmer, E. Klinker, Sensitivity analysis of forecast errors and the construction of optimal perturbations using
singular vectors, Journal of the Atmospheric Sciences 55 (6) (1998) 1012–1037.
E. Lorenz, K. Emanuel, Optimal sites for supplementary observations: simulation with a small model, Journal of the Atmospheric
Sciences 55 (1998) 399–414.
T. P. M. Leutbecher, J. Barkmeijer, A. Thorpe, Potential improvement of forecasts of two severe storms using targeted observations,
Quarterly Journal of the Royal Meteorological Society 128 (583) (2002) 1641–1670.
G. Carmichael, T. Chai, A. Sandu, E. Constantinescu, D. Daescu, Predicting air quality: improvements through advanced methods to
integrate models and measurements, Journal of Computational Physics 227 (7) (2008) 3540–3571.
A. Sandu, L. Zhang, Discrete second order adjoints in atmospheric chemical transport modeling, Jurnal of Computational Physics
227 (12) (2008) 5949–5983. doi:10.1016/j.jcp.2008.02.011.
A. Cioaca, M. Alexe, A. Sandu, Second order adjoints for solving PDE-constrained optimization problems, Optimization Methods and
Software 27 (4–5) (2012) 625–653.
F. LeDimet, V. Shutyaev, J. Gejadze, Analysis error via Hessian in variational data assimilation, in: ARIMA Journal, CARI06, Cotonou,
Benin, 2006.
R. Lehoucq, K. Maschhoﬀ, D. Sorensen, C. Yang, ARPACK software (parallel and serial), http://www.caam.rice.edu/software/
ARPACK [cited 2012].
URL http://www.caam.rice.edu/software/ARPACK
J. Barkmeijer, M. van Gijzen, F. Bouttier, Singular vectors and estimates of the analysis error covariance metric, Quarterly Journal of the
Royal Meteorological Society 124 (549) (1998) 1695–1713.
K. Maschhoﬀ, D. Sorensen, Parallel ARPACK home page, http://www.caam.rice.edu/~kristyn/parpack_home.html.
URL http://www.caam.rice.edu/~kristyn/parpack_home.html
W. Liao, A. Sandu, T. Chai, G. Carmichael, Total energy singular vector analysis for atmospheric chemical transport models, Monthly
Weather Review 134 (9) (2006) 2443–2465.
A. Sandu, Targeted observations for atmospheric chemistry and transport models, in: V. A. et al. (Ed.), International Conference on
Computational Science (ICCS 2006), Vol. 3991 of Lecture Notes in Computer Science, 2006, pp. 712–719.
R. Liska, B. Wendroﬀ., Composite schemes for conservation laws, SIAM J. Numer. Anal. 35 (6) (1998) 2250–2271.
F. L. Z. Wang, I.M. Navon, X. Zou., The second order adjoint analysis: theory and applications, Met. and Atm. Phys. 50 (1-3) (1992)
3–20.
A. Sandu, L. Zhang., Discrete second order adjoints in atmospheric chemical transport modeling, J. Comput. Phys. 227 (12) (2008)
5949–5983.
A. Griewank, et al., On automatic diﬀerentiation, Mathematical Programming: recent developments and applications 6 (1989) 83–107.
R. Giering, T. Kaminski., Recipes for adjoint code construction, ACM Trans. Math. Software 24 (4) (1998) 437–474.
A. S. A. Cioaca, M. Alexe., Second-order adjoints for solving PDE-constrained optimization problems, Optim. Meth. Softw. 27 (4-5)
(2011) 625–653.
C. Zhu, R. Byrd, P. Lu, J. Nocedal, L-BFGS-B: a limited memory fortran code for solving bound constrained optimization problems,
Dept. of Electrical Engineering and Computer Science, Northwestern Univ., TR NAM-11, Evanston, IL.
W. Arnoldi, The principle of minimized iterations in the solution of the matrix eigenvalue problem, Quart. Appl. Math 9 (1) (1951)
17–29.
C. Lanczos, An iteration method for the solution of the eigenvalue problem of linear diﬀerential and integral operators, United States
Governm. Press Oﬃce, 1950.

