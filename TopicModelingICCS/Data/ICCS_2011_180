Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1708–1715

International Conference on Computational Science, ICCS 2011

Monte Carlo scalable algorithms for Computational Finance
V. N. Alexandrova , Christian Gonz´alez Martelb , J. Straßburg
a ICREA

and Barcelona Supercomputing Centre, C/ Jordi Girona, 29, Ediﬁci Nexus II, E-08034 Barcelona, Spain
de M´etodos Cuantitativos en Econom´ıa y Gesti´on, University of Las Palmas, Las Palmas, Spain

b Departamento

Abstract
With the latest developments in the area of advanced computer architectures, we are already seeing large scale
machines at petascale level and we are faced with the exascale computing challenge. All these require scalability
at system, algorithmic and mathematical model level. In particular, eﬃcient scalable algorithms are required to
bridge the performance gap. In this paper, examples of various approaches of designing scalable algorithms for such
advanced architectures will be given. We will brieﬂy present our approach to Monte Carlo scalable algorithms for
Linear Algebra and explain how these approaches are extended to the ﬁeld of Computational Finance. Implementation
examples will be presented using Linear Algebra Problems and problems from Computational Finance. Furthermore,
the corresponding properties of these algorithms will be outlined and discussed.
Keywords: Scalable Algorithms, Computational Finance, Monte Carlo

1. Introduction
Due to the progress in the high performance computing environment during the last few years, we are now having
large-scale machines at petaﬂop level. Furthermore, the more recent development towards multi-core and many-core
architectures adds extra dimensions of parallelism to scientiﬁc computing that have to be tackled. One of the crucial
tasks in this new environment is the development of scalable algorithms that are able to run eﬃciently on such a
variety of advanced architectures, and make the best possible use of the provided hardware. These algorithms have to
be able to
• bridge the Performance Gap,
• be scalable and fault-tolerant,
• run eﬃciently on various advanced architectures and
• eﬃciently tackle large-scale Grand Challenges types of problems.
Email addresses: vassil.alexandrov@bsc.es (V. N. Alexandrov), cgonzalez@dmc.ulpgc.es (Christian Gonz´alez Martel),
j.strassburg@reading.ac.uk (J. Straßburg)

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.185

1709

V. N. Alexandrov et al. / Procedia Computer Science 4 (2011) 1708–1715

Monte Carlo methods are probabilistic algorithms which use random numbers to either simulate a stochastic
behaviour or to estimate the solution of a problem. Monte Carlo algorithms are good candidates for parallelisation
because of the fact that many independent samples are used to estimate the solution. These independent samples can
be gathered in parallel and thereby speed up the solution ﬁnding process. We propose and develop parallel Monte
Carlo methods with the following main generic properties:
• eﬃcient distribution of the compute data,
• minimum communication while computing,
• increased precision achieved by adding extra computations,
• fault-tolerance being introduced by adding extra computations and continuing the computation without restarting.
Consideration of all these properties naturally leads to scalable algorithms.
Section 2 discusses examples of the use of scalable Monte Carlo methods for Linear Algebra, backed by examples
that are taken from real life problems that make use of such algorithms. Section 3 presents tests on a popular problem
from Computational Finance, demonstrating the eﬃciency and fault-tolerance of our approach. The last section
concludes and gives an outlook on future work.
2. Monte Carlo Algorithms for Linear Algebra
Solving systems of linear algebraic equations (SLAE) in the form of Ax = b or inverting a real matrix A is of
unquestionable importance in many scientiﬁc and engineering applications. In the last decade, there were several key
advances in parallel Monte Carlo methods for solving such problems [1, 2, 3, 4, 5, 6, 7, 8].
2.1. Algorithms
Let us outline the two Monte Carlo algorithms considered: at ﬁrst, a Monte Carlo method with relaxation parameter for solving SLAE:
Step1. Input : A, b, ε, γ ∈ (0, 1], and N.
Step2. Preprocessing : Compute L, f, and l sum :
⎧
⎪
⎪
bi
⎨1 − γ when i = j
n
{li j }i, j=1 = ⎪
⎪−γ ai j when i j fi = γ aii l sum (i) =
⎩
aii

n

|li j |
j=1

Step3. MC : For i = 1, 2, . . . , n do :
1 : For k = 1, 2, . . . , N do :
1.1 : Set i0 = i, Xk = 0 , and W = 1 and calculate Xk = Xk + W fi0
j0

1.2 : Generate r.n. ξ ∈ (0, 1) and ﬁnd smallest integer j0 with ξ <

pi0 j
j=1

1.3 : Let W = W × sign(li0 j0 ) × l sum (i0 ) and calculate Xk = Xk + W f j0
1.4 : If |W| < ε then end trajectory (i.e. if k = N goto Step 3 − 2;
else increment k and goto Step 3 − 1.1)
1.5 : Set i0 = j and goto Step 3 − 1.2
2 : Let xi =

1
N

N

Xj
j=1

1710

V. N. Alexandrov et al. / Procedia Computer Science 4 (2011) 1708–1715

Secondly, the resolvent Monte Carlo method for Matrix Inversion (MI) is described:
Step1. Input : A, ε, N, m, and a
Step2. Calculate L = I − A and P matrices
Step3. MC : Calculate matrix C , by MC on L and P. For i = 1 to n
1.1 : For j = 1 to N
⎧
⎪
⎪
⎨1 if i = k
1.1.1 : Set W0 = 1 point = i , and S U M[k] = ⎪
⎪0 if i k
⎩
1.1.2 : For t = 1 to m
Select a nextpoint , based on the transition probabilities in P
L[point][nextpoint]
Compute W j = W j−1
P[point][nextpoint]
Set S U M[nextpoint] = S U M[nextpoint] + g(t, m) ∗ W j
S U M[k]
for k = 1, 2, . . . , n
1.2 : Then cik =
N

2.2. Implementation and Experimental Results
The algorithms were implemented by Dr Simon Branford on an IBM JS21 Bladecenter with 700 nodes equipped
with 2800 2.5GHz processors and 5.6 Terabyte main memory, 20 TFLOP sustained performance, Myrinet high-speed,
low latency cluster interconnect and 60 Terabytes storage subsystem.
We run the sparse SLAE with relaxation parameters 0.5 and 0.9. The results are given below and show close to
optimal speedup for large matrices. The results show that the algorithms scale really well as shown in Figure 1.

Figure 1: Speedup of sparse SLAE on IBM PPC JS21 Cluster using Myrinet

Further, the same algorithms were run on Intel Quad-Core Xeon CPU Harpertown with Dual-die dual-core CPU,
45nm, x86-64 architecture, 3 GHz Clock speed, 2 x 6 MB L2 cache and 1600 MHz FSB. The cluster used has 16
Intel quad-core Harpertown nodes, 16 GByte main memory each, Double Data Rate Inﬁniband network, Intel C and
FORTRAN compilers with OpenMPI.
Again we run the sparse SLAE with relaxation parameter of 0.5 or 0.9 and 10−1 accuracy, the results are shown in
Figure 2 left hand side.
As can be seen further in Figure 2 right hand side, we run the resolvent Monte Carlo for dense MI with the
parameters given below. The results show very close to the optimal speedup.

V. N. Alexandrov et al. / Procedia Computer Science 4 (2011) 1708–1715

1711

Figure 2: Speedup of sparse (left) and dense (right) SLAE on Intel Xeon Cluster using Inﬁniband

λ = ψ(α) =

4aα
(1 − α)2

α∗ = 1 + 2a − 2 a(1 + a)
m
j
2t−1
(4a)t Ct+
j−1 α∗

g(t, m) =
j=t

Figure 3: Speedup of UNI-DEM code using scalable MC algorithm

The scalable algorithms approach and some of the algorithms implemented were used in enhancing the Air Pollution code UNI-DEM[9] developed in collaboration with the Danish Environmental Research Institute. In fact,
implementing this approach, we were able to obtain substantial improvement of the speedup from the initial case,
shown on the left hand side of Figure 3 , achieving very good speedup as shown below on the right hand side of the
ﬁgure.
3. Monte Carlo Algorithms for Computational Finance
In this paper we consider as an example the Black-Merton-Scholes formula, ﬁrst introduced in [10], which is
widely used for the assessment of options using an argument based on the dynamic coverage of the option in question, and under the condition of no arbitrage opportunity. It describes ﬁnancial markets and investment instruments

1712

V. N. Alexandrov et al. / Procedia Computer Science 4 (2011) 1708–1715

mathematically, however, it is obtained under very strict assumptions. The Black-Merton-Scholes model has led to a
great advance of option pricing techniques like binomial trees and ﬁnite diﬀerence methods.
Monte Carlo methods are also used in Computational Finance for various applications. They have proven to be
especially useful for matrix inversions in computational ﬁnance[11, 12] and applied to general problems[13, 14].
They can be advantageous with increasing sources of uncertainty of the problem. The diﬀerence between a binomial
tree and a Monte Carlo process is that the binomial tree requires a discrete probability measure and is a less accurate
approximation of the real underlying movement [15]. On the other side the ﬁnite diﬀerence methods do not possess the
scalability properties outlined in this paper as well as fault-tolerance properties which Monte Carlo methods inherently
possess.
Therefore in this paper, we experiment with Monte Carlo methods to solve the valuation of American-style options
as well as the techniques to achieve scalability applied already to linear algebra problems. We also test the simulation
on market data (CBOE).
3.1. Algorithm
A sequential algorithm using the Monte Carlo technique to calculate the Black-Scholes pricing model is applied.
As an input, it will be given a number of trials M. Usually, with Monte Carlo calculations, the higher this value is,
the more accurate the answer becomes. Pseudo code for a sequential algorithm for this problem and descriptions of
additional variables are taken from [16] and given below:
• S: asset value function
• E: exercise price
• r: continuously compounded interest rate
• sigma: volatility of the asset
• T: expiry time
A sequential Monte Carlo simulation of the Black-Scholes model
for i = 0 to M 1 do
t := S exp((r 1/2*sigma^2)*T+sigma*sqrt(T)*randomNumber()); t is a temporary variable
trials [ i ] := exp(r * T) * max{t E, 0}
end for
mean := mean( trials )
stddev := stddev( trials ,mean)
confwidth := 1.96 * stddev/sqrt(M)
confmin := mean confwidth
confmax := mean + confwidth
The pseudo code also uses several internal variables:
• trials : array of size M, each element of which is an independent trial (iteration of the Black-Scholes Monte
Carlo method)
• mean: arithmetic mean of the M entries in the trials array
• randomNumber(), when called, returns successive (pseudo)random numbers chosen from a Gaussian distribution.
• mean(a) computes the arithmetic mean of the values in an array a

V. N. Alexandrov et al. / Procedia Computer Science 4 (2011) 1708–1715

1713

• stddev(a, mu) computes the standard deviation of the values in an array a whose arithmetic mean is mu.
• confwidth: width of conﬁdence interval
• confmin: lower bound of conﬁdence interval
• confmax: upper bound of conﬁdence interval
We will be presenting experiments with a parallel Monte Carlo implementation of this Black-Scholes algorithm.
The speciﬁc problem of the Black-Scholes option pricing in combination with Monte Carlo simulations has been
proven to be highly optimizable and parallelizable on accelerator architectures [17]. Particularly the random number
generation and the calculation of option prices at maturity date are strong candidates. In contrast to previous research,
the aim of this work is to show the inﬂuence of failures occurring during the computation on the precision and runtime
of the program as well as apply some of the techniques already proved to give good results in solving Linear Algebra
Problems by parallel Monte Carlo. Therefore, the main focus is put on investigating the change in runtime when
employing more calculations to compensate for expected faults.
Due to the nature of supercomputers, consisting of hundreds and thousands of single nodes, there are ubiquitous
opportunities for failures. It is pointed out in [18], [19] and [20] that failures are already occurring frequently in
large scale supercomputers and independent of the type of machine, failures are inevitable and it can be assumed that
advancements in technology will not provide signiﬁcantly reduced occurrences. It can be expected that this is getting
more signiﬁcant within exascale systems.
3.2. Implementation and Experimental Results
The scalable algorithms techniques described above will be now implemented to problems from Computational
Finance and in addition be equipped with a fault compensation.
Tests were run with a parallel version of the algorithm, varying the parameters of the exercise price E and the
number of trials M. Changing the exercise price E leads to a diﬀerent result for the price of the option and an increased
number of trials yields a better precision of the forecast. In the event of a failure, like a failing node or an undelivered
intermediate result, the calculations that would have gone into the ﬁnal result need to be computed again. Neglecting
those results will lead to not attaining the required accuracy of the overall result.
Tests were run varying the trials from 10.000 iterations up to 10 million and exercise prices ranging from 50 to
150. Extra iterations were added in a second run to compensate for a simulated loss of calculations, denoted by EF.
The eﬀect on the run time of the application was noted and expected, as this lead to reaching the required precision in
the case of faults. The results are presented below.
The testing environment was comprised of a small evaluation cluster, the nodes are equipped with a 2.4 GHz
Pentium 4 CPU and 1GB of RAM and a Gigabit Ethernet network interconnect is used.
It can be seen from the results that, as expected, those runs with added computation are generally taking longer to
complete. In the event of failures that are less or equal to the anticipated ﬁve percent loss of calculations, the results
will be within the same or even higher accuracy as the original, uninterrupted program run. This is due to the added
computation being performed irrespective of the occurrence of failures. If no calculations are lost during the process,
the additional trials will yield a higher accuracy.
Due to the fact that the original time spent on the computation is only in the range of seconds, the added overhead
is quite small and in the range of less than one second most of the time. The spreading of the results for small
numbers of trials can be attributed to the short runtime of the program itself with these parameters, and the start-up
and distribution of the MPI processes within the cluster.
Generally the scalability techniques applied to Monte Carlo for Linear Algebra hold also for Monte Carlo for some
key problems in Computational Finance. Further experiments with a wider set of problems are required to generalise
the approach.
4. Conclusions and Future Work
This work proposed implementations of parallel Monte Carlo algorithms and demonstrated their huge potential
regarding speedup, fault-tolerance and scalability on a variety of applications. Future research will, for example, investigate next generation algorithms for resilience and fault-tolerance in large-scale systems. The set of problems in

1714

V. N. Alexandrov et al. / Procedia Computer Science 4 (2011) 1708–1715

Table 1: Run times in seconds for variations of E and EF (with fault compensation) with iteration steps M
E50
EF50
E60
EF60
E70
EF70
E80
EF80
E90
EF90
E100
EF100
E110
EF110
E120
EF120
E130
EF130
E140
EF140
E150
EF150

10.000
3.77056
4.55893
4.68665
3.87671
3.45833
3.21089
3.84381
3.24067
2.2177
4.262
4.99725
3.10941
3.52138
4.67585
6.31492
5.53575
2.2378
6.14156
6.01531
3.13005
2.85644
6.09631

100.000
4.28255
3.70061
4.82718
3.09753
5.63154
2.88391
2.91779
3.5594
4.27977
3.62725
3.65717
3.53172
3.14091
3.47931
3.40484
3.53023
3.71929
3.27441
3.76313
3.51938
5.67123
6.39945

250.000
3.83181
4.91774
2.70984
3.15204
2.7841
3.28898
4.12512
7.94018
3.95315
2.83434
3.38637
3.83671
3.38107
4.08166
4.9212
3.75329
3.81444
3.15603
6.21083
4.35346
3.19541
3.28985

500.000
4.24072
3.94506
3.73494
3.85227
2.9254
4.79233
3.86331
4.99563
3.24223
5.34775
3.33407
3.44388
3.15211
3.42368
3.67683
4.44144
4.30967
3.71774
4.10008
4.49038
4.41669
6.24081

1.000.000
4.93652
5.02608
4.40937
5.15328
4.20641
3.99403
7.6853
4.23744
3.7801
3.67845
3.42959
4.04824
4.79127
4.32622
3.49395
3.52435
5.10708
5.82318
4.68093
3.60356
4.12377
3.47276

10.000.000
12.6536
13.8116
10.0447
12.5408
11.862
11.4622
11.4914
11.7068
11.1071
10.8413
10.3924
15.1738
10.2223
10.833
10.7852
11.6694
10.3381
11.3865
11.9251
11.6385
12.8309
13.0059

100.000.000
147.559
151.403
132.549
142.083
76.7643
139.711
77.628
80.2234
77.8116
80.5829
76.1439
78.5382
74.9308
79.6305
75.3807
78.7072
74.5276
78.1216
75.6448
78.5835
74.982
83.5233

Computational Finance will be expanded in order to generalise the approach. With ever increasing numbers of processors and machines, traditional ways of treating faults are not viable any more, as they impose too many constraints
and too much overhead when employed in larger systems. Furthermore, additional fault tolerance techniques will be
examined in response to deterministic and non-deterministic failure occurrence.
About the Authors
Professor Vassil Alexandrov, ICREA Research Professor at Barcelona Supercomputing Centre, Barcelona, Spain.
Dr. Christian Gonz´alez Martel is Professor at Departamento de M´etodos Cuantitativos en Econom´ıa y Gesti´on,
University of Las Palmas, Las Palmas, Spain
Janko Straßburg, PhD Student, MSc, Dipl-Ing (FH), University of Reading, UK, Visiting Researcher, Barcelona
Supercomputing Centre
References
[1] I. Dimov, T. Dimov, T. Gurov, A new iterative monte carlo approach for inverse matrix problem, Journal of Computational and Applied
Mathematics 92 (1998) 15–35.
[2] I. Dimov, V. Alexandrov, A new highly convergent monte carlo method for matrix computations, Mathematics and Computers in Simulation
47 (1998) 165–181.
[3] S. Branford, C. Weihrauch, V. Alexandrov, A sparse parallel hybrid monte carlo algorithm for matrix computations 3516 (2005) 743–751.
[4] V. Alexandrov, E. Atanassov, I. Dimov, S. Branford, A. Thandavan, C. Weihrauch, Parallel hybrid monte carlo algorithms for matrix computations, in: Computational Science - ICCS 2005, Vol. 3516, Springer-Verlag, 2005, pp. 752–759.
[5] C. Weihrauch, I. Dimov, S. Branford, V. Alexandrov, Comparison of the computational cost of a monte carlo and deterministic algorithm for
computing bilinear forms of matrix powers, in: Computational Science - ICCS 2006, Vol. 3993, Springer-Verlag, 2006, pp. 640–647.
[6] I. Dimov, V. Alexandrov, S. Branford, C. Weihrauch, Error analysis of a monte carlo algorithm for computing bilinear forms of matrix powers,
in: Computational Science - ICCS 2006, Vol. 3993, Springer-Verlag, 2006, pp. 632–639.
[7] I. Dimov, A. Vassil, P. Rumyana, C. Weihrauch, Monte carlo numerical treatment of large linear algebra problems, in: Computational Science
(Y. Shi et al. Eds.): ICCS 2007, Part I, Lecture Notes in Computing Sciences, Vol. 4487, Springer-Verlag, Berlin Heidelberg, 2007, pp.
747–754.
[8] S. Branford, C. Sahin, A. Thandavan, C. Weihrauch, V. Alexandrov, I. Dimov, Monte carlo methods for matrix computations on the grid, in:
Future Generation Computer Systems, Vol. 24, 2007, pp. 605–612.
[9] V. N. Alexandrov, Z. Zlatev, Using parallel monte carlo methods in large air pollution modeling, in: Lecture Notes in Computer Science, Vol.
3039, Springer-Verlag GmbH, 2004, pp. 491–498.
[10] F. Black, M. Scholes, The pricing of options and corporate liabilities, The Journal of Political Economy 81 (3) (1973) 637–654.
[11] K. L. Judd, Numerical methods in economics, Cambridge, Mass. : MIT Press, 1998.
[12] M. J. Miranda, P. L. Fackler, Applied computational economics and ﬁnance, Cambridge, Mass. : MIT Press, 2002.
[13] C. Weihrauch, Analysis of monte carlo algorithms for linear algebra problems, Ph.D. thesis, School of Systems Engineering, University of
Reading (2008).

V. N. Alexandrov et al. / Procedia Computer Science 4 (2011) 1708–1715

1715

[14] S. Branford, Hybrid monte carlo methods for linear algebra problems, Ph.D. thesis, School of Systems Engineering, University of Reading
(2008).
[15] F. de Weer, Exotic Options Trading, John Wiley and Sons, UK, 2008.
[16] K. Yelick, Parallel programming for multicore.
[17] G. Schwarz, J. Kreutz, Black-scholes and monte carlo simulation on accelerator architectures, in: Para 2010: State of the Art in Scientiﬁc and
Parallel Computing, School of Engineering and Natural Sciences, University of Iceland, 2010.
URL vefir.hi.is/para10/extab/para10-paper-48.pdf
[18] B. Schroeder, G. A. Gibson, A large-scale study of failures in high-performance computing systems, Dependable Systems and Networks,
International Conference on 0 (2006) 249–258. doi:http://doi.ieeecomputersociety.org/10.1109/DSN.2006.5.
[19] B. Schroeder, G. A. Gibson, Understanding failures in petascale computers, Journal of Physics Conference Series 78 (2007) 2022–2032.
doi:10.1088/1742-6596/78/1/012022.
URL http://iopscience.iop.org/1742-6596/78/1/012022
[20] G. Gibson, B. Schroeder, J. Digney, Failure tolerance in petascale computers, CTWatch Quarterly Volume 3, Number 4.
URL http://www.pdsi-scidac.org/publications/papers/ctwatchquarterly1107.pdf

