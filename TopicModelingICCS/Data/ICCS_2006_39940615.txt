Neural Network Based MOS Transistor Geometry
Decision for TSMC 0.18μ Process Technology
Mutlu Avci1 and Tulay Yildirim2
1

Cukurova University, Computer Engineering Department,
01330 Adana, Turkey
mavci@cu.edu.tr
2 Yildiz Technical University,
Electronics and Communication Engineering Dept.,
34349 Besiktas Istanbul, Turkey
tulay@yildiz.edu.tr

Abstract. In sub-micron technologies MOSFETs are modeled by complex
nonlinear equations. These equations include many process parameters, terminal voltages of the transistor and also the transistor geometries; channel width
(W) and length (L) parameters. The designers have to choose the most suitable
transistor geometries considering the critical parameters, which determine the
DC and AC characteristics of the circuit. Due to the difficulty of solving these
complex nonlinear equations, the choice of appropriate geometry parameters
depends on designer’s knowledge and experience. This work aims to develop a
neural network based MOSFET model to find the most suitable channel parameters for TSMC 0.18μ technology, chosen by the circuit designer. The proposed model is able to find the channel parameters using the input information,
which are terminal voltages and the drain current. The training data are obtained
by various simulations in the HSPICE design environment with TSMC 0.18μm
process nominal parameters. The neural network structure is developed and
trained in the MATLAB 6.0 program. To observe the utility of proposed
MOSFET neural network model it is tested through two basic integrated circuit
blocks.

1 Introduction
The MOSFET channel length and channel width parameters directly affect the current
driving capability of the transistor depending on the node voltages. It is difficult to
choose the appropriate channel parameters since the MOSFETs are modeled by complex nonlinear equations with many dependent and independent parameters [1].
In [1] a neural network based method for MOSFET channel length and width
parameters are introduced and applied to YITAL 1.5μ process technology. In [2] a
neural network based model for YITAL 1.5μ is developed. The main difference between these two papers is; in [1] consideration of drain-source voltage change is also
included into the neural network model. In [2], inputs are gate-source voltage and the
drain current. The drain-source voltage is kept constant at 5 V.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 615 – 622, 2006.
© Springer-Verlag Berlin Heidelberg 2006

616

M. Avci and T. Yildirim

Other existing applications are generally modeling s-parameters for RF transistors
using neural networks. In [3], [4], [5] and [6] frequency attitude of a microwave transistor is modeled using Multi Layer Perceptron (MLP) neural networks.
In [7] Operational Transconductance Amplifier (OTA) circuits by being complete
systems are modeled using neural networks. In [8], transistor arrays modeled using
genetic algorithms.
In this work the same fundamental approach with [1] implemented for YITAL 1.5μ
technology is implemented for 0.18μ TSMC process technology. However, the neural
network structures and developed transistor models between these two approaches are
different. In this work BSIM3 MOS transistor model is used where as in [1] MOSFET
Level 3 model is used for developing the neural networks.
The proposed model in this work aims to find the channel parameters with the
given drain current and the input node voltages of a MOSFET for a submicron process technology. The model is based on a MLP neural network structure since it is a
good choice for modeling applications due to the ability of function approximation.
The inputs of neural network model are the input gate-source voltage (VGS), drainsource voltage (VDS) and the drain current (ID) of MOSFET. The bulk-source voltage
(VBS) is assumed to be zero for the simplicity of the model. The training data for the
neural network are obtained using the HSPICE simulation environment. The
MOSFET is simulated with TSMC 0.18μm process parameters [9]. The neural network models are trained with the MATLAB 6.0 program.
After the completion of the training process for the proposed neural network models of n- and p- type MOSFETs both models are tested with random data. During the
test process MOSFET models are simulated with randomly chosen VGS, VDS and ID
values. Then, the channel parameters, responding to test data, are simulated with VGS
and VDS test values on MOSFET in HSPICE to observe the approximation between
desired and simulated ID values.

2 The Multi Layer Perceptron Neural Networks
Multilayer Perceptron (MLP) is the most common neural network model, consisting
of successive linear transformations followed by processing with non-linear activation
functions. MLP represents a generalisation of the single layer perceptron, which is
only capable to construct linear decision boundaries and simple logic functions. However, by cascading perceptrons in layers complex decision boundaries and arbitrary
Boolean expressions can be implemented. MLP is also capable to implement nonlinear transformations for function approximations. [10], [11].
The network consists of a set of sensory units (source nodes) that constitute the input layer, one or more hidden layers of computation nodes, and an output layer. Each
layer computes the activation function of a weighted sum of the layer's inputs. The
input signal propagates through the network in a forward direction, on a layer-bylayer basis. The learning algorithm for multilayer perceptrons can be expressed using
generalised Delta Rule and gradient descent since they have non-linear activation
functions [14]. In the general form of an MLP network, the xi inputs are fed into the
first layer of xh,1 hidden units. The input units are simply 'fan-out' units: no processing

Neural Network Based MOS Transistor Geometry Decision

617

takes place in these units. The activation of a hidden unit (neuron j) is a function fj of
the weighted inputs plus a bias, as given in equation (1).

x pj = f j (

∑w

ji

x p i + θ j ) = f j ( y pj ) .

(1)

i

Where wji is the weight of input i to neuron j, xpi is input i, that is, output i from the
previous layer, for input pattern p and θj is the threshold value. The output of the
hidden units is distributed over the next layer of xh,2 hidden units until the last layer of
hidden units, of which the outputs are fed into a layer of xo output units [1].

3 Development of Neural Network Transistor Models
To find the most appropriate channel parameters for different voltage and current
values, MOSFET has to be simulated in a large region of input voltages. It is essential
for a successful approximation. The variable parameters for simulations are W, L
channel parameters and VGS, VDS node voltages. Adding the output value ID of the
simulations, the data files are created in HSPICE environment to train the neural network in MATLAB 6.0 program. Fig. 1 shows the n- and p-channel MOSFET circuit
connections to obtain the training and test data for single transistors.

Fig. 1. MOSFET circuits for producing training data: a) n-channel, b) p-channel

The MOSFETs were modeled between 1 V to 3.3 V range. The neural network
structure shown in Fig.2 was used to model different operation regions. The MLP
network consists of three inputs, three hidden layers and two output neurons. Activation functions of hidden units were tangent hyperbolic sigmoid and output was purelinear. The model has three separate training datasets between 1V and 3.3V input
voltage range since the MOSFET cannot be accurately modeled in a wide input gatesource voltage range.
Gate-source potential VGS, drain-source potential VDS and drain current ID were applied to the inputs of MLPs. The outputs of the MLPs were channel width W and

618

M. Avci and T. Yildirim

effective channel length L. Both channel length and width were varied between 0.18μ
to 7μ. In this range, training data were obtained with different step sizes for each
channel parameter. Once again using different step sizes for gate-source and drainsource voltages between 1V to 3.3V depending on the interval, the training is
occurred. The test data were obtained randomly in the same range and they were different from the training data. Over 200K data points were obtained from HSPICE
simulations. The simulation of the neural network was performed in the MATLAB
6.0 program. 100 randomly chosen test data were applied for testing.

Fig. 2. The MLP neural network used for the implementation

Fig. 3. The drain current (μΑ) vs. test data for n-channel MOSFET

Neural Network Based MOS Transistor Geometry Decision

619

After the gate-source, drain-source voltages and required drain currents were applied to the neural networks, the estimated aspect ratios were simulated in HSPICE to
check the validity of drain currents at the same input voltages.
The neural network size in Fig. 2 was obtained by trial and error. Different network
architectures were trained and tested. Finally, architecture shown in Fig. 2 gave the
best overall performans.
The figures illustrate that the estimated and required drain currents are very close
to each other with a maximum error of 8.3%. Since the channel parameters might
increase with the half of the resolution steps, error reached the given value. However,
the neural network output channel parameters were more accurate with respect to this
error, estimated channel parameters were applied with the suitable resolution values.
This proves the success of the neural network estimation. Performances of the test data
for n-channel and p-channel MOSFETs were shown in Fig.3 and 4. For all figures the
vertical axis is the amplitude of the drain current and the horizontal one represents the
test data. The sign showing current direction is not considered. The dotted black lines
in all figures represent the drain current with estimated aspect ratio and the solid grey
lines show the desired drain currents.

Fig. 4. The drain current (μΑ) vs. test data for p-channel MOSFET

4 The Implementation Circuits
The developed neural network was applied to some main building blocks of analog
integrated circuit design. These are the basic current mirror circuit and a differential
amplifier which are very essential for most analog circuits. Each transistor in the
circuit blocks assumed as a single transistor and designer decided the gate-source,
drain-source voltages and drain current. This flexibility of design is supported by the
neural network.

620

M. Avci and T. Yildirim

4.1 The Basic Current Mirror Circuit
The circuit in Fig. 5 is designed using the developed neural network. The node voltages for each numbered node are shown in Table 1. The required current, estimated
current, estimated channel length (L) and width (W) values for the current mirror
circuit are given in Table 2.

Fig. 5. The Basic Current Mirror Circuit

Table 1. The voltage values of the nodes in te basic current mirror circuit
N(1)
Vdes (V)
3.30
3.30
3.30

N(2)
Vsim (V)
3.30
3.30
3.30

Vdes (V)
1.50
1.00
1.30

N(3)
Vsim (V)
1.49
1.01
1.29

Vdes (V)
1.50
2.00
2.20

Vsim (V)
1.50
2.00
2.20

Table 2. The desired and simulation current values, estimated channel width and length
M1

M2

M3

Ides
(µA)

Isim
(µA)

W
(µm)

L
(µm)

Ides
(µA)

Isim
(µA)

W
(µm)

L
(µm)

Ides
(µA)

Isim
(µA)

W
(µm)

L
(µm)

150
100
50

148.0
102.6
50.4

0.69
1.37
0.33

0.49
0.50
0.54

300
30
900

294.3
31.8
895.3

1.38
0.38
2.40

0.49
0.54
0.22

150
100
50

148.0
102.6
50.4

1.68
2.49
1.98

0.52
0.51
0.52

4.2 The Basic Differential Amplifier Circuit
The circuit in Fig.6 is designed using the developed neural network. The node voltages for each numbered node are shown in Table 3. The required current, estimated
current, estimated channel length and width values for the differential amplifier
circuit are shown in Table 4.

Neural Network Based MOS Transistor Geometry Decision

621

Fig. 6. The Basic Differential Amplifier Circuit
Table 3. The voltage values of the nodes in differential amplifier circuit

N(1)
Vdes (V)
3.30
3.30
3.30

N(2)
Vsim (V)
3.30
3.30
3.30

Vdes (V)
2.30
2.00
2.00

Vsim (V)
0.70
0.78
0.75

Vdes (V)
1.70
1.80
1.60

N(4)
Vdes (V)
0.70
0.80
0.75

N(3)
Vsim (V)
2.31
1.93
2.02

Vdes (V)
2.30
2.00
2.00

Vsim (V)
1.70
1.80
1.60

Vdes (V)
1.00
1.30
0.90

N(5)

Vsim (V)
2.31
1.93
2.02
N(6)
Vsim (V)
1.00
1.30
0.90

Table 4. The desired and simulation current values, estimated channel width and length
M1

M2

M3

Ides
(µA)

Isim
(µA)

W
(µm)

L
(µm)

Ides
(µA)

Isim
(µA)

W
(µm)

L
(µm)

140
375
25

139
402
24.1

1.94
2.53
0.59

0.49
140
0.20
375
0.52
25
M4

139
402
24.1

1.94
2.53
0.59

0.49
0.20
0.52
M5

L
(µm)
0.34
0.31
0.53

Ides
(µA)
280
750
50

Ides
(µA)
140
375
25

Isim
(µA)
139
402
24.1

W
(µm)
4.96
5.11
0.61

Isim
(µA)
278
805
48.3

Ides
(µ
A)
140
375
25

Isim
(µA)

W
(µm)

L
(µm)

139
402
24.1

4.96
5.11
0.61

0.34
0.31
0.53

W
(µm)
2.33
2.69
0.96

L
(µm)
0.25
0.18
0.50

622

M. Avci and T. Yildirim

5 Conclusion
The test results prove that the proposed MOSFET neural network model can decide
channel width and length values accurately. The network has a very close function
approximation for the MOSFET with TSMC 0.18μ process technology parameters.
The applications of analog circuit design blocks show that the model can find the
appropriate channel parameters which must be determined by the designer with his
experience and knowledge. That is a very important step forward for complex analog
and digital VLSI design process. Adding new input parameters to the neural network
structure and obtaining more training data, the model can produce more accurate
results in a wider range, which can make the model an important tool for designers
during the analog and digital integrated circuit design process.

Acknowledgements
This research has been supported by Yildiz Technical University Scientific Projects
Coordination Department. Project Number: 24-04-03-02.

References
1. Avci, M., Babac, M. Y., Yildirim, T.,: Neural Network Based MOSFET Channel Length
and Width Decision Method for Analogue Integrated Circuits, International Journal of
Electronics, Vol. 92, No. 5, May 2005, 281-293
2. Avci, M., Babac, M. Y., Yildirim, T.,: Neural Network Based Transistor Modeling and
Aspect Ratio Estimation for YITAL 1.5 process, ELECO 2003, International Conference
Proceedings, Bursa, Turkey, 2003, pp. 54-57
3. Gunes, F., Gurgen, F., Torpi, H.: Signal-Noise Neural Network Model for Active Microwave Devices, Circuits Devices and Systems, Vol. 143. IEE Proceedings (1996) 1-8
4. Gunes, F., Torpi, H., Gurgen, F.: Multidimensional Signal-Noise Neural Network Model,
Circuits Devices and Systems, Vol. 145. IEE Proceedings (1998) 111-117
5. Yildirim, T., Torpi, H., Özyilmaz, L.: Modelling of Active Microwave Transistors Using
Artificial Neural Networks, Proceedings of IJCNN’99 Int. Joint Conf. on Neural Networks, Vol. 6. IEEE publication, Washington (1999) 3988–3991
6. Gunes, F., Torpi, H., Çetiner, B.A.: Neural Network Modeling of Active Devices for Use
in MMIC Design, Artificial Intelligence in Engineering, Vol. 13. Elsevier (1999) 385–392
7. Kothapalli, G. M.,: Artificial Neural Networks as Aid in Circuit Design, Microelectronics
Journal, 26, 1995, 569-578
8. Langenheine, J., Folling, S., Meier, K., Schemmel, J.: Towards a Silicon Primordial Soup:
A Fast Approach to Hardware Evaluation with a VLSI Transistor Array, ICES 2000,
LNCS 1801, 2000, 123-132
9. www.mosis.org : for TSMC 0.18μ technology parameters. (2003)
10. Hush, D., R., Horne, B., G.: Progress in Supervised Neural Networks, IEEE Signal Processing Magazine, January (1993), 8-39
11. Geva, S., Sitte, J.: A Constructive Method for Multivariate Function Approximation by
Multilayer Perceptrons, IEEE Transactions on Neural Networks, Vol. 3 (4) (1992) 623-624

