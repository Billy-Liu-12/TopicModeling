Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 206–215

International Conference on Computational Science, ICCS 2011

Higher Order Numerical Discretization Methods with Sobolev
Norm Minimization
S. Chandrasekarana , K. R. Jayaramana,∗, M. Gub , H. N. Mhaskarc , J. Moﬃtta
a Dept.

of Electrical and Computer Engineering, University of California, Santa Barbara
b Dept. of Mathematics, University of California, Berkeley
c Dept. of Mathematics, California State University, Los Angeles

Abstract
This paper presents a method of producing higher order discretization weights for linear diﬀerential and integral
operators using the Minimum Sobolev Norm idea[1][2] in arbitrary geometry and grid conﬁgurations. The weight
computation involves solving a severely ill-conditioned weighted least-squares system. A method of solving this
system to very high-accuracy is also presented, based on the theory of Vavasis et al [3]. An end-to-end planar partial
diﬀerential equation solver is developed based on the described method and results are presented. Results presented
include the solution error, discretization error, condition number and time taken to solve several classes of equations
on various geometries. These results are then compared with those obtained using the Matlab’s FEM based PDE
Solver as well as Dealii[4].
Keywords: PDE Solver, Numerical Discretization, Sobolev Norm, Higher Order, Finite Diﬀerence, weighted least
squares, parallelism, Python

1. Introduction
This paper introduces a higher order ﬁnite diﬀerence scheme for solving two dimensional elliptic PDEs based
on Minimum Sobolev Norm (MSN) interpolation[1][2]. The MSN scheme is a higher order interpolation idea, that
suppresses Runge Oscillations by minimizing an appropriately set up Sobolev Norm of the interpolant. We extend the
idea to setup a weighted least squares problem for weights that approximate linear diﬀerential and integral operators.
The ill-conditioned system that arises in the process is solved using a Complete Orthogonal Decomposition method.
We present a simple, yet eﬀective orthogonal decomposition method that we call CODA. With a method to approximate diﬀerential operators in hand, we present a local Finite Diﬀerence like method to solve planar elliptic PDEs. The
method described in this paper is fairly generic, basis independent and extends to variable coeﬃcient, higher order
and higher dimensional problems easily.
∗ Corresponding

author
Email addresses: shiv@ece.ucsb.edu (S. Chandrasekaran), jrk@ece.ucsb.edu (K. R. Jayaraman), mgu@math.berkeley.edu (M. Gu),
hmhaska@gmail.com (H. N. Mhaskar), jmoffitt@umail.ucsb.edu (J. Moﬃtt)
URL: http://scg.ece.ucsb.edu (S. Chandrasekaran)

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.022

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

207

The underlying solution is assumed to be discretized at prescribed grid points. At each interior grid point, we
consider a local neighborhood of grid points. We then use sample values at these points to approximate the underlying
diﬀerential operator using Minimum Sobolev Norm weights. We believe that the order of the method depends on the
number of neighbors chosen. A sparse banded matrix corresponding to the discretization of the PDE is assembled,
and solved. Appropriate balancing is applied to control the condition number of the resulting matrix. The obvious
motivation for a higher order method is that it needs a coarser grid to solve the PDE at hand to a given accuracy than
a lower order method. We believe that the ﬁneness of discretization required beyond the Nyquist rate to resolve the
solution underlying a PDE to a given accuracy reduces as the order of the method increases.
The question of whether a higher order method is faster to get to a given accuracy remains though, as a higher
order method may lead to a signiﬁcant increase in computational complexity. The simplest manifestation of this could
be the fact that we have a denser system to solve, since we use more weights to approximate an operator in the vicinity
of a point. We assume that the cost of weight computation is amortized by the sparse system solve cost. For regular
grids, one could exploit the regularity of the stencils to avoid computations. Also the weight computations are easily
parallelizable even in absence of regularity and are reusable for a given geometry/grid. Let the ﬁnal sparse system to
be solved be
AN×N x = b,
where A is the sparse matrix discretizing the PDE, x is the solution vector, and b is the appropriate right hand side.
If we use L2 weights per row at maximum to approximate some operator through A then A is still suﬃciently sparse
N. Assuming that we consider appropriate reordering for optimality, we believe that the time taken
as long as L2
to solve the system is O(L3 N 1.5 ). In the maximal case, we can have an N point neighborhood, and so each equation
would have N weights, giving us the dense compute time O(N 3 ).
We hypothesize that the order of the method is given by k = L+1
2 for a regular grid using an L point, centered,
square neighborhood. Since the numerical instability in computing the weights increases with L, we believe that there
is a maximum order beyond which the numerical accuracy begins to diminish. Also, considering the asymptotic cost
of solving the ﬁnal system, we see that, the system becomes more and more dense, and a sparse solver continues to
lose its eﬃciency. Under our assumption above, we can see that the ﬂops required to solve an N × N sparse system
arising out of a kth order method would then be O((2k − 1)3 N 1.5 ). The accuracy achieved with a kth order method with
an N 0.5 × N 0.5 grid is O(N −k/2 ). Therefore, to get to an accuracy of req ,
req

= N −k/2 ⇒ N =

The ﬂops needed with a kth order method to get to

req

1
req

2
k

.

digits of accuracy would then be

O((2k − 1)3 (

req )

−3/k

).

From Figure 1, it may be inferred that the computational advantage of the higher order method diminishes beyond an
order of about 10.
Section 2, brieﬂy introduces the MSN interpolation idea, and sets up the weighted LS problem corresponding to
the approximation of linear operators. It then discusses the CODA method to solve the ill-conditioned WLS problem
accurately using recursive singular value decompositions. Results indicating the success of CODA are presented.
Section 4 discusses the discretization method to setup a local Finite Diﬀerence like system, and the related issues.
Section 5 presents a host of results obtained using the PDE solver over various problems and geometries. Each of
these problems and geometries are solved using varying neighborhood sizes corresponding to varying orders. The
associated sparse matrix bandwidth and sparse solve time are also discussed. Section 6 provides conclusions and
possible extensions. The Python and Matlab based PDE Solvers will be made available through our group website
[5]. The proof that the local discretization of the PDE converges is presented in [6].
Related closely to our work is the work of Wright and Fornberg [7] which describes a compact ﬁnite diﬀerence
formulation using radial basis functions. [7] pays particular attention to the basis function, and interest is exhibited
in retrieving standard FD weights. Also, [7] uses Hermite interpolation ideas in computing the weights to improve
the discretization accuracy. Furthermore, their method is a “mesh free” method, where in scattered data stencils
in the locality of collocation points are selected for accuracy. Our method is basis independent, and provides for the

208

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215
Flops Vs Order

50

10

req =1e-2
req =1e-4
req =1e-8
req =1e-12
req =1e-16

40

10

30

Flops

10

20

10

10

10

0

10

0

10

20

Order

30

40

Figure 1: FLOPS vs Order of method for

req

50

= 10−16

possibility of adaptive gridding and selective neighborhood selection as well. For convenience we use a square window
and regular grids on arbitrary geometry to solve PDEs. Comparable Higer Order methods in the FEM paradigm are
the Deal II [4] and the Hermes [8] projects.
2. MSN Discretization
The MSN interpolation scheme computes an interpolating polynomial of order higher than the number of interpolating nodes, whose sobolev norm is minimum [1][2]. Traditional lagrange interpolation uses a polynomial of order
equal to the number of interpolating nodes. It is known that, except under particular circumstances, such interpolation
schemes produce divergent interpolants [9][10]. The MSN scheme produces a polynomial of order much larger than
the number of interpolating points. Of course, there are inﬁnitely many such polynomials since the linear system set
up to solve for the interpolant would be under-determined. We use the additional degrees of freedom to pick that
interpolant whose sobolev norm is minimum. Let V refer to a Vandermonde matrix with a Chebyshev basis, f the N
vector corresponding to N equi-spaced sample values, a the M
N vector of spectral coeﬃcients, s the parameter
corresponding to the Sobolev space containing the interpolant, and D s an appropriate diagonal matrix. M depends on
the minimum spacing between the samples and the number of samples. Then, MSN interpolation corresponds to the
optimization problem
M−1

arg min a
Va= f

2
s

= Ds a

2
2

=

( m

2
2

+ 1) s/2 |a|2 .

(1)

m=0

Here m is a multi-index depending on the dimensionality of the problem. Intuitively speaking, MSN ﬁnds an interpolant that has minimum energy in higher frequencies. This in turn corresponds to the smoothest interpolant in the
sense of the above sobolev norm. It has been shown that there exists a unique solution to (1) [1]. It is also shown
that the interpolant converges point-wise to the underlying function in the vicinity of the samples, provided the right
Sobolev space is chosen. Note that this convergence result is independent of the underlying sample distribution and
illustrates the local convergence property of MSN interpolants.
3. Stabilizing MSN Computation:CODA
While (1) is setup and solved as an under-constrained problem for which we ﬁnd the minimum norm solution,
a corresponding dual Weighted Least Squares (WLS) problem can be speciﬁed as follows. We compute the MSN
weights wl such that
T
T
wl = arg min D−1
s (VN×Π(M) w − V1×Π(M) (xl )) 2 ,
w

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

209

N
where V is the Chebyshev Vandermonde matrix at (xi )i=1
, an N point neighborhood of xl . Note that
N

f (xl ) =

wl (i) f (xi ).
i=1

The MSN interpolation problem becomes ill-conditioned with increasing problem size N and the Sobolev parameter s. For a local interpolation, N does not need to be too large; as mentioned in the introduction, there is no
signiﬁcant computational advantage beyond a 10th order method. As per [3], for a diagonal ill-conditioned positive
matrix scaling an otherwise well conditioned LS system, the solution can be computed stably. We present a poor
man’s complete orthogonal decomposition based on SVDs to solve such a system. Consider any general weighted LS
problem of the form
arg min W(Ax − b) .
x

Let y be the computed solution, and let yˆ be the true solution. Then, the goal is an algorithm that achieves a ﬂoating
point accuracy bounded independent of W as below.
y − yˆ ≤

mach f (A)

b ,

where f (A) is a function of A independent of W. Unpivoted QR factorization of such ill-conditioned WLS systems are
seen to suﬀer from numerical inaccuracies[3]. Hough and Vavasis proposed the complete orthogonal decomposition
idea which uses a QR factorization with column pivoting which converts the given LS problem to one that is well
conditioned up to a column scaling. Traditional algorithms do well to solve such systems to good ﬂoating point
accuracies, and so an error bound of the form above is achieved. The key idea here is to change the ill-conditioned
row-scaling into an ill-conditioned column scaling. Instead of a QR factorization with column pivoting as proposed
by Hough and Vavasis, we use the SVD. The theory by Vavasis et al. also seeks that the weights be ordered; this is
taken care by an a priori permutation.
We assume in this description that the factor W has been multiplied into the equation. Consider a singular value
decomposition
A = UΣV H .
Then,
AV = UΣ.
If we now solve for the modiﬁed LS problem
UΣ xˆ =LS b,
where xˆ = V H x, then a traditional LS algorithm works well under ﬂoating point errors as well. However, the SVD
algorithms achieve only backward error stability. Hence, we use a recursive SVD reﬁnement approach in order to
produce a numerically accurate complete orthogonal decomposition. This SVD based technique is described below.
We require a numerical threshold η = O(1) that speciﬁes the reﬁnement. We assume that A has full column rank
and well conditioned. This assumption is indeed valid for the MSN method assuming the underlying grid points that
produce the Chebyshev Vandermonde matrix are themselves well spaced.
We ﬁrst compute the SVD
A = UΣV H
and apply V to A, to get Aˆ = AV. Let Ao , Vo be empty matrices to accumulate results.Also, let
k = arg min σl <
l

σ0
.
η

If such a k exists, then we split Aˆ as
Aˆ = [ A1

A2 ]

where A1 is the ﬁrst k − 1 columns of A. We also split V as
V = [ V1

V2 ]

210

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

where V1 has the ﬁrst k − 1 columns of V. We then reﬁne A2 by computing its SVD again as
A2 = Uˆ Σˆ Vˆ H
ˆ V2 Vˆ as above. We accumulate Ao = [ Ao A1 ]. We also accumulate Vo = [ Vo V1 ]. The
and try to split A2 V,
iteration stops when no such k exists as described above. At the end of the iterations, we compute the orthogonal
decomposition Ao = QR. Now Q, R, Vo specify a complete orthogonal decomposition.
In order to test the above algorithm we assume a known random solution to the 2D MSN system of size 784 × 49
and solve this system using the factorization developed above. The threshold η used for CODA reﬁnement was 10.
The algorithm was observed to be sensitive to the ordering of the weights in the ill-condition system. To this eﬀect,
permutations corresponding to ascending and descending order of weights in D were employed to test the solver.
Figure 2 summarizes the results obtained with various orderings. In Figure 2, we compare three pairs of results. A QR
based least squares solver in MATLAB is taken as the reference for comparison. The ﬁrst pair compares unordered
weights between QR and CODA. The second pair compares them with the weights sorted in ascending order, while
the third pair compares them with the weights in descending order. It is clearly evident that the CODA algorithm
with descending order of weights outperforms all other methods considered. Our experiments seem to indicate that
descending order works best.

 !"#  '"$%"" "# %(#$





&$#

	$#
	#$#

		#$#
#$#

	#$#



'$%"" "











































#

Figure 2: Results of CODA and variants to solve the 2D MSN system

Figure 3: The stencils used for discretization in the vicinity of points

4. Discretization of two dimensional Elliptic PDEs using the MSN Scheme
Consider a general 2nd order elliptic PDE, given by:
∇.A∇u + bT ∇u + cu = f

(2)

We wish to solve (2) in a compact region Ω ⊂ R2 subject to the boundary condition
eT ∇u + du = g

(3)

on the boundary ∂Ω. We consider a discretization of (2) at NI points {xik } ∈ Ωo , k = 1, 2, ...NI . We call these the
interior points. We also consider a discretization of (3) on ∂Ω at NB boundary points, {xbk }, k = 1, 2, ...NB . We wish to
solve (2) for u(xik ) and perhaps u(xbk ) depending on the boundary conditions. At each {xik }, we consider a neighborhood
of size corresponding to some order d of local approximation. For a square stencil and equi-sampling, we consider
a square of side (2d − 1)h, where h is the sampling distance. Figure (3) depicts these neighborhood stencils at a far
interior stencil (not involving any boundary point) as well as in the vicinity of the boundary.

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

211

We generalize the PDE problem and construct local approximation weights in a manner below. Let Ω ⊂ R2 be a
compact region, L be a diﬀerential operator on the interior of Ω , B be another suitable boundary operator. Then we
wish to solve the boundary value problem,
Lu = f : Ωo , Bu = g : ∂Ω

(4)

Let C be a ﬁnite collection of “grid points” in Ω, δ > 0. Let
B(x, δ) = {y ∈ R2 : y − x

∞

≤ δ}

We ﬁx some x∗ , and consider the set
x − x∗
δ

C (x∗ ) =

∞

: x ∈ C ∩ B(x∗ , δ)

Let {φk } be an orthonormal set on [−1, 1]2 , M = M(x∗ ) be the cardinality of {φk }, where M is computed to be the
mesh norm[1] of C (x∗ ) = {y0 , y1 , ...yN−1 }. Let N be the cardinality of C (x∗ ), M > N.
We ﬁnd weights such that
⎧
⎛N−1
⎞2 ⎫
⎪
M
⎪
⎪
⎜⎜⎜
⎟⎟⎟ ⎪
⎪
⎪
⎨
∗
2 −s/2 ⎜
⎟⎟⎟ ⎬
⎜
w(x ) = arg minN ⎪
(1 + l 2 )
w
φ
(y
)
−
L{φ
}(0)
(5)
⎪
⎜
k
l
k
l
⎪
⎪
⎝
⎠
⎪
w∈R ⎪
⎩ l=1
⎭
k=0
In order to discretize (2) and (3) at a point x∗ , we place a stencil B(x∗ , (2d − 1)h), and at C (x∗ ) we evaluate the
Chebyshev Vandermonde Matrix V. The operator L is applied to V(0) since x∗ , the stencil center is mapped to the
origin. Then, the above minimization problem problem becomes
arg min D s V T w − L(V T (0))
w

2

where D s is the diagonal matrix with weights (1 + l 22 )−s/2 . We solve this equation using the CODA method as
described in Section 3.The solution w to the minimization problem speciﬁes the linear combination of u(C (x∗ )) that
approximates L(u)(x∗ ).
Let N = NI + NB . Let F2 be the NI × N sparse matrix that contains the weights corresponding to ∇.A∇u. The
lth row of F2 contains the weights that approximate ∇.A∇u(xil ) using u(C (xil )). Let F xi , Fyi correspond to the NI × N
∂ ∂
matrices that contain the weights for ∂x
, ∂y respectively. Then (2) becomes
(F2 + B1 F xi + B2 Fyi + I i )u = fNI , Bl = bl (x), x ∈ {xik }.

(6)

(E1 F xb + E2 Fyb + I b )u = gNB ,

(7)

Similarly, (3) becomes
∂ ∂
where F xb , Fyb are NB × N sparse matrices that represent the operators ∂x
, ∂y , at the boundary points. Let C i , Db
represent appropriately sized diagonal matrices representing coeﬃcients c, d in (2) and (3) respectively. The grand
system that we solve is now setup as follows.

Fu =

F2 + B1 F xi + B2 Fyi + C i
E1 F xb + E2 Fyb + Db

u=

f NI
gNB

(8)

To reduce the condition number of F, we perform a row 2-norm scaling. Full scale equilibration experiments are
yet to be explored since the simple scaling seems satisfactory in controlling the condition number. Let this diagonal
scaling be represented by D1 . Then we have a system
D1 Fu = D1

f NI
gNB

(9)

212

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

Since fN I and gN B are at scales O(h2 ) and O(1) respectively, we setup and solve for two separate systems of the
form:
0
f NI
D1 F u1 u2 = D1
(10)
0 gNB
The overall solution is then reconstructed as u = u1 + u2 . If the condition number induced by the operator is high, as
with the Bi-Harmonic operator, or singularly perturbed operators, we need to resort to iterative reﬁnement. The proof
that the local discretization of the PDE converges with a high order follows from the fact that the local interpolant
converges with a high order as well and is presented in [6].
5. Numerical Results
In order to test the above approach, we consider PDEs in various geometries. Starting with a square region, we
morph the boundary points using the transformation in (11) to produce a family of boundary curves corresponding to
varying values of 1 ≤ p ≤ 20. For our purposes we choose p = 1, 2, 20, corresponding to the geometries shown in
Figure 5.

Figure 4: Various geometries generated using a transformation from the Square geometry

xmorphed = x

x p
,x
x2

0

(11)

We equi-sample these geometries and interior points closer to the boundary points than 0.5h are discarded, where h is
the interior sample spacing.
0 ∞
Results below include the maximum relative error in the solution denoted as e ∞ = u−u
u0 ∞ . We measure the

∞
relative residue as Fu−g
where F denotes the assembled FD matrix, prior to scaling. g denotes the appropriate right
g ∞
hand side. The maximum number of weights used is denoted as L2 . To measure the condition number, we use the
ˆ
statistical estimation method of Laub and Kenney [11]. The condition number thus estimated is denoted as κ(F),
ˆ
where F denotes the FD matrix after scaling. We compare our results with the Matlab FEM Toolbox (PDETool) [12]
and Deal II [4].

5.1. High-Frequency Helmholtz
We ﬁrst consider a Helmholtz equation with a high wave number. Results of solving this problem with the MSNFD
method and the Matlab FEM Toolbox (PDETool) are presented in Figures 5 through 8. This being a stiﬀ problem,
PDETool is seen to have a lower convergence rate compared to the MSNFD. Considering the minimum time taken to
get to a given accuracy, we see that unless the expected accuracy is less than 2 digits, we see that the MSNFD outperforms the FEM approach. We extrapolate the time take by FEM to get to the given accuracy. This extrapolation was
necessary since the FEM method could not be run on our computer with the given amount of memory. For p = 2 this
minimum sampling rate for the solution to begin to converge is observed to be about 100 × 100. While the condition
number scales similar to the FEM method, there is a large constant scaling it.
∇2 u + 10000u = f

213

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

Maximum solution error with p = 2

Maximum solution error , with p = 1
Condition Number , with p = 1






9 × 9 window
11 × 11 window
13 × 13 window
15 × 15 window

FEM



























9 × 9 window









1
h















Figure 5: Error and Condition number to equation in section 5.1, p = 1
Minimum time taken to get to ﬁxed accuracy with p = 2

	







FEM









1
h













1
h





Maximum solution error with p = 20
Condition Number , with p = 20






9 × 9 window
9 × 9 window
11 × 11 window
11 × 11 window
13 × 13 window
13 × 13 window


FEM
FEM



MSNFD
FEM

MSNFD





Figure 6: Error and Condition number to equation in section 5.1, p = 2

Minimum grid size to get to ﬁxed accuracy with p = 2



15 × 15 window





FEM


1
h

11 × 11 window









9 × 9 window
13 × 13 window

15 × 15 window
FEM













13 × 13 window











11 × 11 window














Condition Number





	







u −u 0 ∞
u0 ∞

Condition Number

u −u 0 ∞
u0 ∞












Condition Number , with p = 2







9 × 9 window
11 × 11 window
13 × 13 window
FEM















Condition Number











u −u 0 ∞
u0 ∞

1
h m in

t m in







































	












log

1














r eq




log

1











r eq














1
h













1
h





Figure 7: Minimum Time taken to solve the Sparse System from equation
Figure 8: Error and Condition number to equation in section 5.1, p = 20
in section 5.1 to a given accuracy

Figure 9: Front View of u

Figure 10: Top View of u

214

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

Ω : [−0.5, 0.5]2 ⇒ p
u=

1
1
1
1
+
+
+
1 + 1000(x2 + y − 0.3)2 1 + 1000(x + y − 0.4)2 1 + 1000(x + y2 − 0.5)2 1 + 1000(x2 + y2 − 0.25)2

5.2. Positive Deﬁnite Helmholtz - comparison with dealii
In this section, we compare the result of solving an example problem provided by the Deal II [4] package. It
considers a positive deﬁnite Helmholtz equation with mixed boundary conditions. f is obtained by using u in the
equation below.
−∇2 u + u = f
Ω : [−1.0, 1.0]2
3

u=

e

x−xk 2
σ2

, {xk }3k=1 = {(−0.5, 0.5), (−0.5, 0.5), (0.5, −0.5)}

k=1

Let Γ1 = {x = 1} ∩ Ω ∪ {y = 1} ∩ Ω and Γ2 be the remaining two sides of the square deﬁned by Ω. We use dirichlet
boundary conditions on Γ1 given by u, and neumann boundary conditions on Γ2 given by the normal derivatives to u.
Figure 12 plots the maximum error in the solution as a function of the grid density. The graph provides convergence
results for varying window sizes for MSNFD and varying element orders for dealii.

30
100
200
300
500
30
100
200
300
500
30
100
200
300
500

1e+00
3e-02
4e-03
2e-03
9e-01
4e-02
2e-03
5e-04
9e-01
4e-02
7e-04
1e-04

ˆ
κ(F)
8e+07
1e+06
1e+07
4e+07
2e+08
3e+05
1e+06
1e+07
6e+07
3e+08
5e+05
1e+06
1e+07
6e+07
4e+08

L2
9
9
9
9
12
25
25
25
25
30
49
49
49
49
49

1
h

u−u0 ∞
u0 ∞

30
100
200
30
100
200
30
100
30
100
30
100

6e-08
6e-11
6e-12
2e-08
2e-11
5e-11
3e-09
4e-11
4e-09
3e-11
3e-10
9e-11

Fu−g
g ∞

ˆ
κ(F)
2e+05
8e+05
1e+06
1e+05
1e+07
4e+07
7e+04
2e+07
1e+06
1e+07
3e+05
3e+07

∞

1e-05
1e-07
2e-08
1e-05
8e-09
7e-09
4e-07
9e-09
4e-07
7e-09
8e-08
1e-08

Table 1: Numerical results for the Multiscale problem in section 5.4, reinterpolated Table 2: Numerical results for the problem
on a 600 × 600 grid
in section5.3, p = 1

L2
64
88
90
92
127
130
120
136
151
184
168
238

MSNFD Vs deal-ii





5 × 5 window
7 × 7 window
9 × 9 window
11 × 11 window
13 × 13 window
dealii - Q2
dealii - Q3
dealii - Q4
dealii - Q5





∞

u−u0 ∞
u0 ∞

e

1
h



















Figure 12: Plot of e
Figure 11: Numerical results for problems 5.4 and 5.3



density

1
h


1
h

∞

=

u−u0 ∞
u0 ∞





Vs the grid

5.3. Region with a hole
We consider a region as described below. Table 2 in Figure 11 shows that the MSNFD approach provides very
good results for the considered smooth solution. It may also be observed that our simple heuristic of removing interior
points too close to the boundary points alleviates the geometry induced ill-conditioning.
∇2 u − u = f
Ω : [−0.5, 0.5]2 \[−0.25, 0.25]2 ⇒ p
u=

1
1 + x 2 + y2

S. Chandrasekaran et al. / Procedia Computer Science 4 (2011) 206–215

215

5.4. Multi Scale
We ﬁnally consider a Multiscale problem as investigated by Shu et al. [13]. In their work a multiscale discontinuous Galerkin method was setup to solve this problem and convergence results were obtained with a spectral method
as the reference. In our case, as in Table 1 in Figure 11, the error measured at a grid density i is the error between
the solution at density i and density i − 1 when interpolated to the new set of high density grid points, relative to the
solution generated by the grid at density i − 1. These errors were measured by reinterpolating on a 600x600 grid. It
may be observed that there is convergence and the solution is consistent as observed to about 4 digits. Increasing rate
of convergence is also observed with increasing stencil sizes.
∇.A∇u = x + y, Ω : [−1, 1]2 , u = 0 : ∂Ω
A=

1
4+x+sin(x/0.01)

0

0
1
4+y+sin(y/0.01)

6. Conclusions and Extensions
A Higher Order numerical method to solve elliptic PDEs in two dimensions was presented. Comparison with
Matlab FEM Toolbox (PDETool) as well as Deal II were presented. The MSNFD approach performed better and
exhibited higher order of convergence than the FEM methods for problems considered. We believe that a higher
order method would be very useful to get to accuracies which we believe may be hard and perhaps even impossible
with lower order methods. Several additional problems and the corresponding results will be available at our website
[5] in the technical report [6]. We believe adaptive gridding to be important and this currently work in progress.
A comparable Finite Element approach together with the application of MSNFD to the BiHarmonic Type equations
as well as Exterior problems would be presented in our future work [14]. A similar discretization of the integral
equation of the PDE and a fast solution of the resulting dense matrix is possible as well. We acknowledge National
Science Foundation (Grants 0830604, DMS-0908037), U.S.Army Research Oﬃce (grant W911NF-09-1-0465), the
NSF Teragrid project, the SDSC Triton Supercomputing resource. Out thanks to Stefan Borieu, Super Computing
Consultant, UCSB.
7. References
[1] S. Chandrasekaran, H. N. Mhaskar, A construction of linear bounded interpolatory operators on the torus, ArXiv e-printsarXiv:1011.5448.
[2] S. Chandrasekaran, K. R. Jayaraman, J. Moﬃtt, H. N. Mhaskar, S. Pauli, Minimum sobolev norm schemes and applications in image processing, Vol. 7535, SPIE, 2010, p. 753507. doi:10.1117/12.842734.
URL http://link.aip.org/link/?PSI/7535/753507/1
[3] P. Hough, S. A. Vavasis, Complete orthogonal decomposition for weighted least squares, SIAM J. Matrix Anal. Appl 18 (1995) 369–392.
[4] W. Bangerth, R. Hartmann, G. Kanschat, deal.ii a general-purpose object-oriented ﬁnite element library, ACM Trans. Math. Softw. 33.
URL http://doi.acm.org/10.1145/1268776.1268779
[5] Scientiﬁc computing group website.
URL http://scg.ece.ucsb.edu
[6] S. Chandrasekaran, K. R. Jayaraman, J. Moﬃtt, M. Gu, H. N. Mhaskar, Msnfd : A higher order ﬁnite diﬀerence method for solving elliptic
pdes on scattered points, Technical Report.
[7] G. B. Wright, B. Fornberg, Scattered node compact ﬁnite diﬀerence-type formulas generated from radial basis functions, J. Comput. Phys.
212 (2006) 99–123. doi:http://dx.doi.org/10.1016/j.jcp.2005.05.030.
URL http://dx.doi.org/10.1016/j.jcp.2005.05.030
ˇ ın, M. Z´ıtka, Modular hp-fem system hermes and its application to maxwell’s equations, Math. Comput. Simul. 76
[8] T. Vejchodsk´y, P. Sol´
(2007) 223–228. doi:10.1016/j.matcom.2007.02.001.
URL http://portal.acm.org/citation.cfm?id=1294378.1294672
[9] P. J. Davis, Interpolation and Approximation, Blaisdell, New York, 1963.
[10] J. Szabados, P. Vertesi, Interpolation of functions, World Scientiﬁc, Singapore ; Teaneck, N.J., 1990.
[11] C. S. Kenney, A. J. Laub, M. S. Reese, Statistical condition estimation for linear systems, SIAM J. Sci. Comput. 19 (1998) 566–583.
doi:10.1137/S1064827595282519.
URL http://portal.acm.org/citation.cfm?id=289762.289838
[12] The mathworks natick ma.
URL http://www.mathworks.com
[13] W. Wang, J. Guzm´an, C. Shu, The multiscale discontinuous galerkin method for solving a class of second order elliptic problems with rough
coeﬃcients, International Journal of Numerical Analysis and Modeling v8 (2011) 28–47.
[14] S. Chandrasekaran, K. R. Jayaraman, J. Moﬃtt, H. N. Mhaskar, Minimum sobolev norm methods for bi-harmonic type equations, FEMTEC,
2011.

