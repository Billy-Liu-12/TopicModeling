Alternate Methods in Reservoir Simulation
Guadalupe I. Janoski and Andrew H. Sung
silfalco@cs.nmt.edu, sung@cs.nmt.edu
Department of Computer Science
New Mexico Institute of Mining and Technology
Socorro, New Mexico 87801

Abstract. As time progresses, more and more oil fields and reservoirs are
reaching maturity; consequently, secondary and tertiary methods of oil recovery
have become increasingly important in the petroleum industry.
This
significance has added to the industry’s interest in using simulation as a tool for
reservoir evaluation and management to minimize costs and increase efficiency.
This paper presents results of several experiments using soft computing
algorithms and techniques to perform history matching, a well-known important
simulation task usually performed to calibrate reservoir simulators.

1 Introduction
An important step in calibrating a petroleum reservoir simulator for modeling a
particular reservoir or oil field is to perform history matching, where the simulation
engineer attempts to match the simulator-generated production curves (consisting of
the output of oil, gas, and water) against the reservoir’s actual production over a
period of time. Once properly calibrated, the simulator can be used to predict future
production and perform other tasks for reservoir evaluation.
Since the reservoir physics is well understood in the small scale (See Janoski et al,
2000 for more information) history matching appears to be fairly simple. In actuality,
however, satisfactory results for history matching are usually difficult to achieve, and
have mostly been obtained by the use of ad hoc methods. A typical method involves a
petroleum simulation engineer familiar with the reservoir running the simulator with
tentative input values; manually inspecting results after each run, and adjusting the
input parameters according to their knowledge or experience; and repeating the
simulation�adjustment process until satisfactory results are obtained; at which point
the final set of input values is adopted to “calibrate” the simulator. This results in
high costs in machine usage, labor, and time.
For example, while in this study of our version of the problem we are only
attempting a history match with a small 8 production well section, we must deal with
12954
different possible solutions even under a greatly
a search space of over 2
simplified version of the reservoir model for simulation. The reason for this large
solution space is that we must include 17 wells in the surrounding area for
environmental data, and use a multi-layer gridded cube consisting of 7 layers, each
layer having 256 grid blocks, with each grid block having over 32 parameters with

V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2074, pp. 253–262, 2001.
© Springer-Verlag Berlin Heidelberg 2001

254

G.I. Janoski and A.H. Sung

real number ranges. This is illustrated with the single level map in Fig. 1 of the well
layout (Chang & Grigg, 1998).
In short, three compounding factors contribute to the difficulty of history matching:
problem size, inadequate resources, and the necessity for human intervention in the
simulation process.
25
24
23
22
21

20
19

18
17

16

15
14

13
12

11

9
8

7
6

Well to be matched
10
5

Production well

4
3

Injection well

2
1

Fig. 1. A well map of the simulation area. The interior 8 production wells {7, 8, 9, 12, 14, 17,
18, 19} were the wells to be matched, while the remaining wells were provided for
environmental data.

1.1 Problem Size
We have an enormous data space in which to locate the best solution; the shear size
makes finding the optimal solution a true “grand challenge” problem. Needless to say
it is impossible to try each solution, and some intelligent search algorithm must be
used. Since the simulation is based on a highly simplified model of the reservoir to
make the computation tractable, we aim to search for optimal solutions as exact
solutions may never be located.
1.2 Inadequate Resources
The second problem originates directly from the first, in that even supercomputers
would be hard pressed to find solutions in a history matching problem, except in the
most trivial cases. Further, the high cost of supercomputers would preclude the
smaller oil companies from performing history matching, while in fact the smaller
companies�the majority of them operating on mature fields�may benefit the most
from doing it. This makes the idea of developing smart algorithms for searching the
data space even more appealing.
1.3 Human Intervention
This problem is the hardest to deal with since it is not apparent how one can automate
the handling of the inter-simulation parameter adjustment without any human
intervention. We show, however, that several soft computing based methods can be
used to inspect the simulation results and perform parameter adjustment with
satisfactory results.

Alternate Methods in Reservoir Simulation

255

2 The Reservoir
The historical data was acquired from the East Vacuum Grayburg/San Andres Unit
(EVGSAU) reservoir, which is owned and operated by the Phillips Petroleum
Company. The reservoir covers 7025 acres in Lea County, New Mexico.
The data gathered from this reservoir includes three phases: primary depletion
from 1959-1979, secondary depletion that consisted of water-flood injection from
1980-1985, and finally a tertiary phase which applied a CO2-flood WAG (water
alternating gas) injection, from 1985-1992.
In 1990 a pilot area of the EVGSAU reservoir was selected as a site for a foam
field trial to comprehensively evaluate the use of foam for improving the
effectiveness of CO2 injection projects, so as to advance the CO2-foam technology for
improved oil recovery. Specifically, the prime directive of the foam field trial was to
prove that a foam could be generated and that it could aid in suppressing the rapid
CO2 breakthrough by reducing the mobility of CO2 in the reservoir. Operation of the
foam field trial began in 1991 and ended in 1993. The response from the foam field
trial was very positive; it successfully demonstrated (Martin, et al., 1995) that a strong
foam could be formed in situ at reservoir conditions and that the diversion of CO2 to
previously bypassed zones/areas due to foam resulted in increased oil production and
dramatically decreased CO2 production. This foam trial period formed the tertiary
period of the reservoir.

3 The Simulator
As part of the CO2 project, the multi-component pseudo-miscible simulator MASTER
(Miscible Applied Simulation Techniques for Energy Recovery), which was
developed by the U.S. Department of Energy, was modified by incorporating a foam
model and used to conduct a history match study on the pilot area at EVGSAU to
understand the process mechanisms and sensitive parameters. The ultimate purpose
was to establish a foam predictive model for CO2-foam processes. Details of a
manually performed history match and results are reported in (Chang & Grigg, 1998).
In doing our experiments a modified version of the simulator was used. The most
important modification was a simplification of the simulator input data. Instead of the
dozens of input parameters required, we used only permeability and relative
permeability values. A secondary modification was also made as we decided that
input values for only a single reservoir layer will be specified, and proportional
adjustment will be used to give the inputs for the remaining layers. These
modifications brought our simulation input parameters down to 32 parameters,
consisting of 25 permeability parameters and 7 relative permeability parameters. This
leaves us with a simpler, but still nearly untenable problem.

256

G.I. Janoski and A.H. Sung

4 Expert System and Fuzzy Control
Building a simple expert system and fuzzy controller proved to be of invaluable use in
understanding the complex well interactions as permeability values were adjusted on
the well map during the simulation process.
4.1 Expert System
Our initial studies began with the construction of a simple expert system (ES) for
parameter adjustment, which would later form the basis of the fuzzy controller. The
rules of the controller were formulated empirically from a study of more than 200
simulation runs that formed an initial parameter study. The ES was composed of 25
IF-THEN rule groups, one for each well. These rules used a combination of actual
well error values and predicted well error values. See Fig. 2 for an example. For ease
of use the error values were divided into one of nine ranges: {EL Extremely Low, VL
Very Low, L Low, SL Slightly Low, K within tolerance, SH Slightly High, H High,
VH Very High, EH Extremely High}. Each rule set was run in sequence and the
resulting predicted set passed to the next rule to be used as an actual set.
The ES proved very useful as it allowed for rapid prototyping, and quick reduction
of error in the match. The primary problem was the granularity induced by having
only 9 error ranges. Standardized parameter alteration values tended to cause
oscillation as error ranges would tend to bounce between two opposing sets (such as
H to L, and L to H), in later runs. Refer to Fig. 3. Due to the fact that wells 8 and 12
tended to work inversely of each other, oscillation tended to occur, i.e., as the match
of one well improves, the other’s would worsen. Despite this, reductions in error by
over 800% by the fourth or fifth iteration of the ES were not uncommon.
If well error value for well 8 is SH Slightly High and
well error value for well 12 is SL Slightly Low then
decrease parameter 3 by 30. Change predicted set for
well 8 and 12 to K.
Fig. 2. A partial IF-THEN rule for well 3. The underlined denotes well error ranges.

Fig. 3. Results of a match on the primary depletion period, for wells 8 and 12. As can be seen,
initial error of the match decreases rapidly, towards the case being matched (actual historical
data in this simulation).

Alternate Methods in Reservoir Simulation

257

4.2 Fuzzy Controller
This section describes a fuzzy controller for automatic parameter adjustment in using
MASTER for history matching. The purpose of a controller is to carry out the
parameter adjustment automatically and thus eliminate human intervention. The
benefits of fuzzy control in this application are the ability to get around the problems
of complexity in formulating exact rules and to deal with situations where there are
multiple meta rules that may be applicable under similar circumstances. For example,
consideration of fluid flow physics leads to the development of three “meta-rules” for
permeability adjustment:
1.
If both wells’ outputs are too high, then choose those blocks whose reduction
in permeability leads to lower outputs.
2.
If wells’ outputs are too low, then choose those blocks whose increase in
permeability leads to higher outputs.
3.
If one well’s output is too high and the other’s is too low, then choose those
blocks whose alteration in permeability leads to proportional, corrective shifts of
outputs.
Rules of the third type are most difficult to obtain, even for experts or simulation
engineers familiar with the reservoir, since many factors need to be considered before
a decision is made regarding which blocks’ permeabilities to increase and which
blocks’ to decrease; thus the need for developing the rules empirically.
The fuzzy controller consists of sections:
1.
Fuzzification Module: Accepts condition/Input and calculated
membership grades to express measurement uncertainties.
2.
Fuzzy Inference Engine: Uses the fuzzified measurements and the rules
in the rule base to evaluate the measurements.
2.
Fuzzy Rule Base: contains the list of fuzzy rules.
3.
Defuzzification Module: converts the conclusion reached by the inference
engine, into a single real number answer
The primary benefits of using fuzzy control is that it is easy to design and tune, and
it avoids the difficulty of formulating exact rules for control actions. The fuzzy
controller’s rules are empirically obtained, based on a parameter study in which a
single well’s permeability value was altered while the rest of the 24 permeability
values were held constant. The fuzzy controller (Klir and Yuan, 1995; Jang et al.,
1997) implemented for permeability adjustment is of the simplest kind in that
percentage errors and control actions are fuzzified, but only rarely will more than one
rule fire. The control action applied is thus usually only scaled by the membership
grade of the percentage error in the error fuzzy set. The adaptive controller works as
follows.
Fuzzification is accomplished by usage of membership functions. After a
simulation is run, an error calculation is made from the simulated and the synthetic
case or historical data based on a percent error formula. This value is then used to
determine error values membership in each fuzzy set: {EL Extremely Low, VL Very
Low, L Low, SL Slightly Low, K within tolerance, SH Slightly High, H High, VH
Very High, EH Extremely High}. The corresponding fuzzy set values are -4, -3, -2, 1, 0, 1, 2, 3, 4, respectively.
Inference begins once the membership grades are calculated. It assigns the fuzzy
set with the highest membership value for each well. If an equilibrium condition is
reached between two sets, the set value closest to K is chosen.

258

G.I. Janoski and A.H. Sung

Rule Firing is our next step. Within the fuzzy rule base there are 3 types of rules: I
(increase production rules), D (decrease production rules), and P (shift production
from one well to another). Based on the fuzzy set assigned to each well, we can
decide the rule type that needs to be applied.. Based on the fuzzy set value assigned to
each well, we can calculate the average set distance from K and decide the change
degree (firing strength) of a rule that needs to be applied.
The final step is application of the control action. The action taken depends on the
chosen rule type and the degree change needed. The parameters for the next
simulation run are now altered.
Many experiments have been conducted (Janoski, 2000). The fuzzy controller’s
performance depends, naturally, on the definition of fuzzy sets for error and the
definition of the fuzzy sets for control actions; therefore, the rule base needs to be fine
tuned for optimal performance. Since the rules must be based on empirical
observations, other factors, such as scaling factors of the controller (Palm, 1995), may
not be quite as critical. The basic idea of using a fuzzy controller for automatic
parameter adjustment in history matching, however, has been validated by using a
specific controller with crisp control actions. In this case we were able to obtain very
good matches within 5 iterations for the two wells over their primary production
period of 18 years. Previously, with manual adjustment, such close matches would
easily take several weeks to achieve.

5 Neural Networks
The neural network method we chose uses a group of predicted oil production output
as training data. The data was acquired by running the MASTER simulator with a set
of ranged values so as to cover the hypothetical case’s production output curve. This
resulted in a set of curves, which bracketed the synthetic case. We found that it was
necessary for the training data to cover the synthetic case history so to restrict the
range of the problems. The figure below shows a very small set of cases that cover
the history. The solid line in is the synthetic case history.
File Name: p813cover.csv
No. of Curves: 10

Max: P10=8 Series 2
Min: P12=64 Series 4
Field: Series 10
Near: P12=32 Series 5

600

500

400

300

200

100

0
1960

1965

1970

1975

1980

1985

Oil Curves for P8

Fig. 4. The bracketing curves for the synthetic case (solid line).
Once the network is well trained, we feed the network with the historical data to
get 25 permeability parameters and 7 relative permeability parameters. We then feed
these parameters into the MASTER simulator to check if these parameters are
acceptable and to create an estimate of the errors for these parameters.

Alternate Methods in Reservoir Simulation

259

The Network we built for this study is a three-layer feedforward network, with 27
input units (historical data), 30 hidden units and 32 outputs (permeabilities). The
scaled conjugate descent learning algorithm (Möller, 1993) is used in training. Fig. 5
shows the comparisons between the desired output and the output from a trained
network. We can see good matches between predicted value and desired value except
for one pair; however, this mismatch can likely be attributed to the fact that certain
permeability values have little effect on the output history. (For example, during the
first 20 years, the 25th permeability value causes less than a 1% change across its
complete value range.) Furthermore, Fig. 5 shows an experimental result in using the
neural network to match the chosen hypothetical case, displaying a very close match.
Currently the training data and testing data are all simulation results from MASTER
simulator. In future experiments real historical data will be used as the number of
parameters are increased.
File Name: 2CasesResult.xls
No. of Curves: 2

Oil Production for P8

Max: RP7=1.33056 Series 2
Min: Base Series 1

500

400

300

Hypothetical Production
200

Predicted Production
100

0
1960

1965

1970

1975

1980

1985

Fig. 5. Synthetic case match using the neural network.

6 Genetic Algorithms
Initial genetic algorithm (GA) trials were run using differing crossover methods.
These studies proved interesting in that little information was needed in creating the
GA system, but at the same time proved to have a huge drawback. As simulation
times could range up to 45 minutes on even a 600MHz PC, creating initial
populations and simulating future generations became extremely costly. As a result
smaller populations for initial testing were used, thus limiting the GA, as large
degrees of similarity occurred between population members in succeeding
generations.
In doing these studies we worked with a data vector composed of the parameter
set. Primary studies were done using multipoint crossover. Population improvement
tended toward only a 1-3% change in the initial few generations. In using standard
crossover the best results were found using a complete generational replacement
scheme with small random number of crossover points for each new child.

260

G.I. Janoski and A.H. Sung

7 Hybrid Systems: A Classifier System
ARIA (Automatic Recombinant Input Approach) uses a non-standard genetic based
learning machine (GBML) to create a set of rules that may be used for atom rule
creation for control in the history matching.
Each rule consists of a set of atom-like subsections. For example in rule 1 below
each line is an atom section that we work with:
Rule 1:
Error Environment Match:
Error Well X=range
Actions:
Change Parameter N by X
Statistics:
Age, Uses, Accuracy

Classifier 1:
Error Calculations:
Error for well N= Error
Parameter List:
Parameter N=pN

Fig. 6. ARIA example rule and classifier.

ARIA consists of rule populations that are tested using actual application data, and
are tracked based on their effectiveness, in altering a well parameter set. It uses a
standard genetic algorithm classifier messaging system. The system consists of four
parts:
1.
Part one is the error reception part (environmental interface) in which a
parameter set to be adjusted is received.
2.
Part two is the rule base of previously composed rules.
3.
Part three is a genetic algorithm with fuzzy control section that creates new
rules when a rule is not available from the database.
4.
The final part is the messaging system that tracks a rule’s effectiveness,
matches a rule to a parameter set and takes relevant action.
The first part of the ARIA, the environmental interface, creates error estimates
from the actual historical production data. This error calculation is done by using a
Sum Squared Error (SSE) calculation between the predicted output of each well and
its historical values. Once the SSE has been calculated for each well, these 8 values
become the environmental pattern (classifier) that will be used in the messaging
system for rule matching. Fig. 6. is an example of an environmental classifier. It has
two parts the error calculations, and the list of parameters that belonged to the
simulation data.
These error values in the classifier are then matched based on a set of fuzzy rules in
the messaging system to appropriate action rules. The fuzzy control in this section is
very basic and consists of simplistic rules that determine if a rule exists within range,
a tolerance factor, and rates each rule by its statistical information, and then
determines which is the most appropriate rule. This is done by attempting to find a
rule whose Error Environmental Match ranges for each well bracket the classifiers
error calculations. Since there do exist 8 error calculations the idea of a tolerance
factor was introduced, in which not all 8 error calculations must be in range. This
calculation is done by using an averaging function to calculate how out of range the
error set is. If an adequate rule is found, it is then used and statistical success or
failure data of its use on the simulation parameters is average together. On the other

Alternate Methods in Reservoir Simulation

261

hand, if an appropriate rule cannot be located the ARIA system invokes the genetic
fuzzy logic creation algorithm to create a new rule, which is then used.
This method has shown some promise in application, and is merely an extension
off of the previous work for the MASTER WEB project in which fuzzy control was
applied resulting in convergence and error control within ten generation, and 200%
error ranges, proving to be a very quick and accurate system. Currently the system
has been running small numbers of iterations, as tests are being run to determine the
best initial rule population. Currently small numbers of changes, that rely on being
able to affect parameters within the lower third of their value ranges, without causing
parameters to go out side of their allowed values, have shown the most successful
ability to converge to a solution. They have been able to come within a 30 to 70%
error within approximately 15 iterations.
The size of the rule base has also been shown to have a significant effect on the
number of iterations, as the larger the size the more likely an appropriate rule will be
found. Created rules have are extremely dependent on the genetic algorithm used, as
wells have complex interactions.

8 Conclusion
In this paper, we have proposed several soft computing based methods to assist in the
challenging task of reservoir simulation and presented experimental results.
While simulation experts have traditionally preformed history matching semiautomatically, soft computing algorithms offer a great deal of promise in the field of
reservoir simulation, particularly history matching. These algorithms have performed
very well in our experiments in minimizing human intervention in the simulation
process, thereby resulting in great savings.
Preliminary results indicate that the soft-computing-enhanced simulation on the
EVGSAU reservoir is capable of producing satisfactory matches within hours. These
results would have taken weeks to achieve previously. We believe, therefore, that the
potential of our approach is clearly demonstrated and further research and
development efforts are warranted to achieve a cost effective and fully automatic
history matching.

8 Acknowledgement
We would like to gratefully acknowledge that support for this research was received
from Sandia National Laboratories and the State of New Mexico. Dr. Eric Chang
(previously with the Computer Science Department of New Mexico Tech) and Dr.
Reid Grigg (of the Petroleum Recovery Research Center of New Mexico Tech)
initiated our interest in this project and made invaluable contributions during its
development.
Mr. F.S Li helped perform many neural network modeling
experiments.

262

G.I. Janoski and A.H. Sung

References
1.
2.
3.
4.
5.

6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.

Ammer, J.R., Brummert, A.C., and Sams, W.N. “Miscible Applied Simulation Techniques
for Energy Recovery – Version 2.0.” Report to U.S. Department of Energy, Contract No.
DOE/BC–91/2/SP, February 1991.
Aziz, K., and A. Settari. Petroleum Reservoir Simulation. London: Applied Science,
1979.
Chang, S. -H. and Grigg, R. B. “History Matching and Modeling the CO2-Foam Pilot Test
at EVGSAU.” Paper SPE 39793 presented at the 1998 SPE Permian Basin Oil and Gas
Recovery Conference, Midland, Texas.
Jang, J.-S. R., Sun, C.-T., and Mizutani, E. Neural-Fuzzy and Soft Computing. New
Jersey: Prentice-Hall, 1997.
Janoski, G., Pietrzyk, M., Sung, A. H., Chang, S.-H., Grigg, R. B. “MASTER Web: A
Petroleum Reservoir Simulation Tool.” Proceedings of the International Conference on
Web-Based Modeling and Simulation & Virtual Worlds and Simulation Conference. San
Diego: Simulation Councils Inc., 2000.
G.J. Klir, and B. Yuan. Fuzzy Sets and Fuzzy Logic: Theory and Applications. New
Jersey: Prentice Hall, 1995.
Janoski, G., Pietrzyk, M., Sung, A. H., Chang, S.-H., Grigg, R. B. “Advanced Reservoir
Simulation Using Soft Computing.” Intelligent Problem Solving: Methodologies and
Approaches, Lecture Notes in Artificial Intelligence 1821, (2000): 623-628.
Kosko B. Fuzzy Engineering. New Jersey: Prentice Hall, 1997.
Li, H.J., Li, F.S., Sung, A.H., and Weiss, W.W. “A Fuzzy Inference Algorithm for
Lithology Analysis in Formation Evaluation.” Intelligent Problem Solving: Methodologies
and Approaches, Lecture Notes in Artificial Intelligence 1821, (2000): 623-628.
Martin, F.D., Stevens, J.E., and Harpole, K.J. “CO2-Foam Field Test at the East Vacuum
Grayburg/San Andres Unit.” SPERE (Nov. 1995) 266.
Möller M.F. “A Scaled Conjugate Gradient Algorithm for Fast Learning.” Neural
Networks, 6, (1993): 525-533.
Nghiern, L. “An Integral Approach for Discretizing the Reservoir Flow Equations.” SPE
Reservoir Engineering 3 no. 2(May 1988):685-690.
Palm R. “Scaling of Fuzzy Controllers Using the Cross-Correlation.” IEEE Tran. Fuzzy
Systems 3, no. 1, (1995) : 116-123.
Peaceman, D. W. Fundamentals of Numerical Reservoir Simulation. New York: Elsevier,
1977.
Pruess, K., and G. S. Bodvarsson. “A Seven-Point Finite Difference Method for Improved
Grid Orientation Performance in Pattern Steamfloods.” SPE Paper 12252. Richardson,
Texas: Society of Petroleum Engineers. 1983.
Xiong, et al. “An Investigation into the Application of Fuzzy Logic to Well Stimulation
Treatment Design.” SPE 27672. SPE Computer Applications. Texas: Society of Petroleum
Engineers. Feb. 1995.

