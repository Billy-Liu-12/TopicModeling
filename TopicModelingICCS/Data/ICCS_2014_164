Procedia Computer Science
Volume 29, 2014, Pages 888–896
ICCS 2014. 14th International Conference on Computational Science

An out-of-core GPU approach for accelerating geostatistical
interpolation
Victor Allombert12 , David Michea2 , Fabrice Dupros2 , Christian Bellier2 ,
Bernard Bourgine2 , Hideo Aochi2 , and Sylvain Jubertie3
1

2

LACL, Universit de Paris-Est, France
BRGM, BP 6009, 45060 Orlans Cedex 2, France
3
LIFO, Universit d’Orlans, France

Abstract
Geostatistical methods provide a powerful tool to understand the complexity of data arising
from Earth sciences. Since the mid 70’s, this numerical approach is widely used to understand
the spatial variation of natural phenomena in various domains like Oil and Gas, Mining or
Environmental Industries. Considering the huge amount of data available, standard implementations of these numerical methods are not eﬃcient enough to tackle current challenges
in geosciences. Moreover, most of the software packages available for geostatisticians are designed for a usage on a desktop computer due to the trial and error procedure used during the
interpolation. The Geological Data Management (GDM ) software package developed by the
French geological survey (BRGM) is widely used to build reliable three-dimensional geological
models that require a large amount of memory and computing resources. Considering the most
time-consuming phase of kriging methodology, we introduce an eﬃcient out-of-core algorithm
that fully beneﬁts from graphics cards acceleration on desktop computer. This way we are able
to accelerate kriging on GPU with data 4 times bigger than a classical in-core GPU algorithm,
with a limited loss of performances.
Keywords: Geostatistics, Graphic processing units (GPU), Linear algebra, Out-of-core, Geological Data
Management (GDM)

1

Introduction

Spatial interpolation plays a signiﬁcant role in various domains of Earth sciences. One of
the main objectives of geostatistics is to help researchers to build reliable model that take
into account the spatial variation of the phenomena under study. This method oﬀers many
advantages such as the spatial structure of the phenomenon, the correlation between many
variables, and a measure of uncertainty. A survey describing geostatistical interpolation can
be found in [5, 10]. Lying at the heart of this numerical method, several costly linear algebra
operations slow down the computation. Indeed, a linear system of size (N ∗ V )2 (with N the
888

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.080

Accelerating Kriging using GPUs

V.Allombert et al.

number of data and V the number of correlated variables in the interpolation) must be solved
which is an important limitation for large problems. Moreover, as the problem under study
is three-dimensional, the amount of data required to build the interpolation and the limited
amount of memory available to process them constitute another bottleneck.
Indeed, the majority of the software packages used for spatial interpolation and threedimensional geological modeling are strongly limited by the resources available on standard
desktop machines. This is mainly due to the way geostatistical models are built. The overall
procedure relies on a trial and error strategy that strongly involves the researcher in the overall
treatment. This induces a huge constraint on the ressources both in terms of memory available
but also in terms of computing power. For instance, the GDM 1 software package that is
developed by the French geological survey (BRGM) runs on desktop machines in order to
process large scale three-dimensional domains.
Several references underline that GPU represents a promising way for kriging and very good
speedups are described for instance in [4, 1]. Moreover, these computing resources of several
Teraﬂops are available at the desktop computer level. Unfortunately, one of the bottlenecks
remains, as a trade-oﬀ needs to be found between the opportunity to speed up the computation
on the GPU and the limited amount of memory available on such accelerators.
In this paper, we design an algorithm to reduce the complexity of kriging methods on big
data sets with respect to the constraint on the memory and computing ressources available on
a desktop computer. In the ﬁrst part, we will detail the standard geostatistical method and
introduce the particular decomposition we have used in order to exhibit simple linear algebra
operations. In the second part, we will call back the Cholesky factorization, then we will
describe our approach on the out-of-core GPU Cholesky algorithm used to tackle the previous
decomposition. We will mainly focus on the eﬃciency of this approach in terms of trade-oﬀ
between the memory consumption and the overall speedup.

2

Kriging method

2.1

Numerical approach

In this paper we consider universal kriging, referenced as the best linear unbiased estimator,
that has been formalized by Georges Matheron in 1963 [5]. As detailed in [9], this method
allows to compute the estimation variance, which is a characterization of estimation error, a
fundamental concept in geostatistics.
The variable of interest is denoted Z and its value at the point x is denoted Z(x). It is
considered as the sum of the mathematical expectation m(x) and a residual Y (x) that is a
random function on the covariance σ(x, x ). Thus, we obtain the following equation: Z(x) =
m(x) + Y (x). In our case, we are interested in the kriging of a unique point. Let’s call Z ∗ (x0 )
the estimator of this point of interest. The mathematical expression of kriging a system is:
Z ∗ (x0 ) =

N

λα Z(xα )

(1)

α=1

Where Z(xα ) are values for each points xα , λα are unknown weights of points xα and N the
number of data.

1 Geological

Data Management : http://gdm.brgm.fr

889

Accelerating Kriging using GPUs

V.Allombert et al.

Minimizing the estimation variance results in the following kriging system:
⎧
⎪
⎪
⎨
⎪
⎪
⎩

β

β

λβ σαβ +

l

μl f l (xα ) = σα0 for α = 1, . . . , N
(2)

λβ f l (xβ ) = f l (x0 )

for l = 0, . . . , L

With f l (xα ) representing the value of the base point function xα (1 in this case), μl the Lagrange
parameters and σαβ the covariance between Z(xα ) and Z(xβ ).

2.2

Matrix expression of kriging

An interesting property of the kriging algorithm is the easiness of transforming it into matrix
operations [2] :
Σ
F

F
λ
σ
.
= 0
f0
μ
0

(3)

With Σ the covariance matrix, F the base function matrix, λ the weights, μ the Lagrange
parameters, σ0 the vector of covariance between data and kriged points and f0 the vector of
base functions of the kriged point. This leads to solve a system of linear equations:
A . X = B

(4)

It is well known that the time complexity of solving such a system of linear equations using
a regular Gaussian elimination is O(n3 ). To avoid the direct resolution, we choose to split the
system of equations into two sub-systems in order to reduce the size of the system to solve.
The original system (3) can be split using the following transformations:
Σ . λ + F . μ = σ0
F

. λ = f0

(A)
(B)

By transforming (A) such as: λ = Σ−1 . σ0 − Σ−1 . F . μ .
Let: λKS = Σ−1 . σ0 and w1 = Σ−1 . F .
So, (A) can be written: λ = λKS − w1 . μ .
Then, we need to substitute the result λ in (B) in order to obtain:
F
Let: R = F

. λKS − F

. w1 . μ = f0 .

. λKS − f0 and Q = F

. w1 .

Then, equation (B) became: Q . μ = R .
Resolving the last system allows us to obtain [μ] and then compute λ = λKS − w1 . μ .
890

Accelerating Kriging using GPUs

2.3

V.Allombert et al.

Resolution method

The covariance matrix Σ is composed by coeﬃcients related to the distance between points
and a coeﬃcient deﬁned by a variogram. Since d(xa , xb ) = d(xb , xa ) and since these distances
are positive, Σ is a positive symmetric deﬁnite matrix.
⎤
⎡
σ11 σ12 σ13 . . . σ1n
⎢ σ21 σ22 σ23 . . . σ2n ⎥
⎥
⎢
⎢ σ31 σ32 σ33 . . . σ3n ⎥
(5)
⎥
⎢
⎢ ..
..
..
.. ⎥
..
⎦
⎣ .
.
.
.
.
σn1 σn2 σn3 . . . σnn
Therefore, we are able to solve this particular system using Cholesky factorization, which is
a optimized method for this kind of symmetric matrices [11], to resolve Σ . λKS = σ0 and
Σ . w1 = F . As explain in [6], the numerical stability of this method does not introduce
errors in our interpolation. During the kriging, the solving of this particular operation is the
most expensive part of the process in terms of time and memory needs. This is the reason why
we will only focus on the Cholesky factorization, even if others GPU accelerated functions are
used during the kriging algorithm.

3

GPU algorithm

The main idea of this algorithm is to use as much as possible the computing capacities of
GPUs, even in their low-end versions. In order to allow users to use this GPU optimized
algorithm, we chose CUDA compatible GPUs that oﬀer to use the CuBLAS library2 . The main
idea is to deﬁne an out-of-core GPU algorithm able to run even if the whole data can not ﬁt
into the available memory.

3.1

Cholesky Algorithm

⎧
⎪
⎪
⎪
⎨ Lj,j =

Aj,j −

j−1
k=1

L2j,k

j−1
⎪
1
⎪
⎪
(Ai,j −
Li,k Lj,k )
⎩ Li,j =
Lj,j
k=1

(6)

We discuss the Cholesky factorization such as: A = L LT with A a symmetric positive
deﬁnite matrix and L a lower triangular matrix. The algorithm can be described by a formula
and resolved using the “line by line” Cholesky-Crout algorithm. We can also achieve the factorization using the well-known blocked algorithm [3] which is implemented into many linear
algebra libraries. We select a pivoted Cholesky algorithm [8] that is more eﬃcient in terms of
GPU computations and memory bandwidth. Considering A, a block partitioned matrix, this
algorithm will compute the current column using previously computed blocks with no needs of
updating the trailing matrix.

2 https://developer.nvidia.com/cuBLAS

891

Accelerating Kriging using GPUs

V.Allombert et al.

⎡

So, at the k th

(k−1)

L
⎢ 11
step, we have:⎣L(k−1)
21
(k−1)
L31

(0)

L12
(0)
L22
(0)
L32

⎤
(0)
L13
(0) ⎥
L23 ⎦
(0)
L33

With L0ij = Aij and Lkij is the of value L at the k th iteration. So, according to the blocked
numeration, for each step k we have:
(k)

(0)

(k−1)

L22 = L22 − L21

(k−1)T

L21

(k)

(k)

L22 = Cholesky(L22 )
(k)

(0)

(k−1)

L32 = L32 − L31
(k)

(k)

(8)

(k−1)

L21

(7)

T

(k)

L32 = Resolve(X.L22 = L32 )

(9)
(10)

Obviously, these computations can be translated into some basic linear algebra subroutines such as DSYRK (rank-k update), DPOTR2 (Cholesky factorization of a single block),
DGEMM (standard matrix multiplication) and DTRSM (solver of matrix equations). In terms
of complexity, this algorithm is similar to the original blocked version which runs in O(n3 ) as
explained in [11].

3.2

Out-of-core GPU algorithm

Most of the generic linear algebra subroutines are provided by NVIDIA in the CuBLAS library.
Using them in such an algorithm is a good choice in terms of performance and easiness of
implementation. We only need to implement DPOTR2 on GPU in order to compute the
Cholesky factorization of a single block.
The main idea of this algorithm is to load the maximum amount of data in the GPU’s
memory, to perform the computation, then to unload results. By using a tiling method we can
iterate through the data and achieve the whole computation by splitting the given matrix into
major sub-matrices. To achieve the best performance, we need to maximize the memory usage
in order to minimize the load/unload steps.
According to the pivoted algorithm, we will deﬁne a work tile to specify the amount of data
needed for each step. Thus, we are able to determine the size of each step and also the number
of tiles which will ﬁt into the GPU memory. In order to obtain the best performance let
BlockDim, the size of a block, be constraint by the quantity of shared memory available on the
GPU. Let BlockSize be the number of elements of a block (BlockDim2 ), N the dimension of
the given matrix, and N bBlocks the total number of blocks (N bBlocks = N/BlocDim) then
BlocSize ∗ (k + 1) ∗ (N bBlocs − k) corresponds to the quantity of elements needed at the k th
step. So, a work tile consists of the maximal number of steps that can be loaded on GPU’s
memory. As kshown in Figure 1, the computation is split into several work tiles which are
successively computed at each step.
The main constraint of this algorithm is given by the biggest step of computation. The
computation that requires the more data is reached when k equals (N bBlocks − 1)/2. Indeed,
we must be able to store this greedy step on the GPU in order to compute the factorization.
Otherwise, the entry is too big and we can not go any further. It is possible to exceed this
limitation by using an out-of-core GPU matrix multiplication, but this issue is out of the scope
of this paper.
892

Accelerating Kriging using GPUs

V.Allombert et al.

Figure 1: Work tiles (Grey) over several steps
The pseudo-code of the proposed out-of-core GPU pivoted Cholesky algorithm could be
described as follows:
Algorithm 1: Out-of-core GPU Cholesky factorization
Data: A : Input matrix
Result: L : Cholesky factorization of A
while Computation not ﬁnished do
Deﬁne a work tile
Load data on GPU
foreach column do
DSYRK
DPOTF2
DGEMM
DTRSM
end
Unload data from GPU
end
We can observe that this algorithm is not using a streaming method in order to overlap
memory transfers and computations. As this algorithm has many data dependencies, using
smaller data blocks and reordering them with asynchronous streams may not be as fast as
the synchronous version. Thanks to its out-of-core capability, this algorithm allows us to run
a GPU accelerated version of kriging on various conﬁguration of memory or power without
manual tuning and regardless of the amount of data.

4

Experimental results

We detail the results obtained with our out-of-core algorithm in this section. We focus on
memory footprint reduction as the speedups obtained with respect to standard GPU implementations have already been extensively discussed in several others related works [1, 4, 7]. We
consider several matrices arising from various application domains. The matrices are in doubleprecision and positive-deﬁnite. Table 1 summarizes their characteristics with N representing
the number of lines for each square matrix. A standard NVIDIA Quadro K4000 graphics card
has been used to run the experiments. This card represents the mid-range graphics card for a
desktop machine dedicated to 3D processing. The NVIDIA Quadro K4000 has 768 cores and
3 gigabytes of DDR5 memory. The bandwidth for the memory transfers is 135 gigabytes per
second.
We artiﬁcially reduce the memory available on the graphics card (from 2.5 GB to 800 MB) in
893

Accelerating Kriging using GPUs

V.Allombert et al.

Name
Matrix
Matrix
Matrix
Matrix
Matrix
Matrix
Matrix

1
2
3
4
5
6
7

N
14016
15520
20032
23040
24522
26048
27552

size (GB)
1.46
1.79
2.98
3.95
4.48
5.05
5.65

Table 1: Characteristics of the matrices used for the experiments.

Figure 2: Performance of the out-of-core GPU algorithm. We represent the performance loss (%)
in comparison with the use of all the memory available on graphics card.
order to evaluate the eﬃciency of our out-of-core algorithm. Figure 2 represents the performance loss (%) in comparison with the use of all the memory available on the graphics card.
For example: with Matrix 3, we can see that computations are respectively 32%, 6% and 3%
slower with 800, 1000 and 1200 Mb of memory, compared to the reference time reached when
all the data can ﬁt into the memory. The Cholesky decomposition could only be performed
for the ﬁrst three matrices for all memory conﬁgurations (until 2.98 GB of memory consumption considering a minimum of 800 MB of allocatable space on the graphics device). For larger
matrices, the remaining memory space is not large enough to store the minimum amount of
blocks required during the out-of-core procedure. In terms of memory consumption reduction,
894

Accelerating Kriging using GPUs

V.Allombert et al.

the best result correspond to the larger matrix (Matrix 7) that could be decomposed with a
reduction of a factor 3.78 of the standard amount of memory required for such a factorization.
At this stage, it is important to remind that our algorithm relies on a tradeoﬀ between the
reduction of the memory consumption and a limited increase of the total elapsed time. Indeed,
as we reduce the amount of memory available, the elapsed time is increasing for all problem
sizes. This loss of performance is rather limited, the worst result is obtained with a matrix of
size 2.98 GB that is decomposed using 800 MB of memory. In this case, the loss of performance
is close to 34%. The average loss measured during the experiments with various problem sizes
is 10%. These results appear pretty good in comparison with the tremendous gain coming from
the use of GPU as accelerators for computational geostatistics on desktop machines.

5

Conclusion

Geological Data Management (GDM ) is a commercial software package stemming from the
French Geological Survey (BRGM) know-how in three-dimensional geological modeling. Limitations at the algorithmic level prevent the use of GDM for large scale problems arising in Earth
sciences. The modiﬁcation of the kriging method in order to obtain two sub-systems allows us
to decrease the complexity of the algorithm. We also adapt the Cholesky algorithm on NVIDIA
graphics cards to accelerate the computations during the kriging. This version of the algorithm
also allows us to check the error of estimation during the computation: an essential issue for
geostatistical interpolation. Finally, thanks to a controlled out-of-core strategy, we are able
to tackle 4 times larger problems with a limited loss of performance. This approach relies on
NVIDIA CUDA architecture but can be easily extended to the OpenCL programming model.
We are also interested in approximated methods, like the incomplete Cholesky factorization,
to reduce the system size in order to display real-time interpolations. These features will be
added in the next release of GDM.

Acknowledgements
This work is partially funded by the European FP7 IRSES project HPC-GA (High-Performance
Computing for Geophysics Applications). The authors thank Franois Courteille, Senior Solution
Architect at NVIDIA, for advices on the implementation.

References
[1] Tangpei Cheng. Accelerating universal kriging interpolation algorithm using CUDA-enabled GPU.
Computers and Geosciences, 54:178–183, 2013.
[2] Jean Paul Chils and Pierre Delﬁner. Geostatistics: Modeling Spatial Uncertainty. Wiley, 2 edition,
2012.
[3] Jaeyoung Choi, Jack J. Dongarra, L. Susan Ostrouchovn, Antoine Petitet, David Walker, and
Clint Whaley. Design and implementation of the scalapack LU, QR an Cholesky factorization
routines. Scientiﬁc Programming, 1994.
[4] E. Gutirrez de Rav, F.J. Jimnez-Hornero, A.B. Ariza-Villaverde, and J.M. Gmez-Lpez. Using
general-purpose computing on graphics processing units (GPGPU) to accelerate the ordinary
kriging algorithm. Computers and Geosciences, 2014.
[5] Matheron Georges. Principles of geostatistics, volume 58. Economic geology, 1963.

895

Accelerating Kriging using GPUs

V.Allombert et al.

[6] Nicholas J. Higham. Accuracy and Stability of Numerical Algorithms. Society for Industrial and
Applied Mathematics, 2002.
[7] Hatem Ltaief, Stanimire Tomov, Rajib Nath, and Jack Dongarra. Hybrid multicore cholesky factorization with multiple GPU accelerators. IEEE Transaction on Parallel and Distributed Computing,
2010.
[8] Craig Lucas. Lapack-style codes for level 2 and 3 pivoted cholesky factorizations. Numerical
Analysis Report, 2004.
[9] Georges Matheron. The Theory of Regionalized Variables and Its Applications. cole national
suprieure des mines, 1971.
[10] M.A. Oliver and R. Webster. A tutorial guide to geostatistics: Computing and modelling variograms and kriging. CATENA, pages 56 – 69, 2014.
[11] Lloyd N. Trefethen and David Bau. Numerical Linear Algebra. SIAM: Society for Industrial and
Applied Mathematics, 1997.

896

