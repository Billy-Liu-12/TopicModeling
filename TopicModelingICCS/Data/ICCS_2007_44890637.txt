Support Vector Machine Detection of
Peer-to-Peer Traﬃc in High-Performance
Routers with Packet Sampling: Nonlinear Kernel
Approach
1
´
F.J. Gonz´
alez-Casta˜
no1, P.S. Rodr´ıguez-Hern´andez1, R.P. Mart´ınez-Alvarez
,
2
and A. G´
omez-Tato
1

Departamento de Ingenier´ıa Telem´
atica, Univ. de Vigo, Spain
2
CESGA, Spain
{javier,pedro,rmartinez}@det.uvigo.es,agomez@cesga.es

Abstract. In this paper, we apply nonlinear support vector machines
to identify peer-to-peer (p2p) traﬃc in high-performance routers with
packet sampling. Due to their high port rates, those routers cannot extract the headers of all the packets that traverse them, but only a sample.
The results in this paper suggest that nonlinear support vector machines
are highly successful and outperform recent approaches like [1,2].
Keywords: support vector machines, detection, p2p.

1

Introduction

In this paper, we apply nonlinear support vector machines [3,4] to detect peer-topeer (p2p) traﬃc in high-performance routers with packet sampling. User behavior in research networks has changed radically with the advent of p2p multimedia
ﬁle transfers: many users take advantage of the huge bandwidth to exchange
movies and the like. This behavior may have a deep impact on research network utilization. We have identiﬁed similar concerns in other research networks
(http://security.uchicago.edu/peer-to-peer/no fileshare.shtml).
The increasing usage of p2p software in the last three years has raised the
need of p2p detection tools. There are some related initiatives. Among them, in
[5], the authors describe a methodology to identify p2p ﬂows at the transport
layer, based on connection patterns of p2p ﬂows, regardless of packet payloads.
The authors point that these patterns are more diﬃcult to conceal than explicit
ﬂow-conveyed information. In [6], the authors propose to detect p2p traﬃc by
identifying protocol-dependent signatures (key strings) in TCP packet payloads.
This is unfeasible in high-performance routers that sample packet headers. However, it may be valid for low-to-medium performance routers. In [1], the authors
present a Bayesian classiﬁer of protocols. Although the mean classiﬁcation accuracy (across all application types) is quite good, the results for p2p traﬃc are
quite poor (an accuracy of 56%).
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 637–644, 2007.
c Springer-Verlag Berlin Heidelberg 2007

638

F.J. Gonz´
alez-Casta˜
no et al.

The MOLDEIP p2p detection tool we have developed fulﬁls the following
goals: (i) it is independent from router performance, (ii) it is transparent to the
users and (iii) it works with sampled packet headers1 . It does not consider individual ﬂows but the average activity of individual IP addresses. Consequently,
there is no short-term technological dependence. Recent network activity is taken
from CISCO netﬂow ﬁles, and thus we do not consider packet payloads (unlike
the approach in [6]). As in [5], the system is transparent to network users because it does not scan their machines. It works with packet headers, and it does
not check them all, but only a sample.
Oﬀ-line analysis is feasible because p2p traﬃc is a nuisance, but it does not
disable the network. Thus, a 24-hour decision delay is acceptable.
MOLDEIP employs support vector machines (SVM). Reference [7] also uses
SVMs to detect anomalous traﬃc, but it focuses on intrusion attacks instead of
p2p traﬃc identiﬁcation. In [2] we demonstrated that linear support vector machine detection of p2p traﬃc in high-performance routers with packet sampling
is highly successful and outperforms recent approaches like [1]. In this paper we
evaluate nonlinear support vector machines for the same purpose.
Speciﬁcally, we consider the problem of constructing SVM classiﬁers based on
a given classiﬁcation of m training vectors (points) in the n-dimensional space
IRn , represented by the m × n matrix D, given the membership of each IP
point Di , i = 1, . . . , m in one of two classes -“innocent” or “guilty”-. Each point
Di ∈ IRn is a vector representing an IP address within the Galician RECETGA
network, whose components codify the behavior of that IP address.
For this problem, in [2] we followed the linear programming model in [10]:
min e y + e z

w,z,γ,y

such that C(Dw − eγ) + α1 y ≥ e
−z ≤ w ≤ z, y ≥ 0, z ≥ 0,

(1)

where w is a vector of separator coeﬃcients, y is a vector of slack variables, γ
is an oﬀset, α is an error penalty, C is a m × m diagonal matrix with plus ones
or minus ones depending on the class of the points represented by D rows, and
e stands for a vector of ones of appropriate dimension. This model allows us to
employ state-of-the art linear programming solvers. If we compare (1) with the
original quadratic model in [3], we see that it tries to minimize the 1-norm of the
w parameters instead of their 2-norm (the 2-norm maximizes the margin w2w
between the bounding planes x w = γ ± 1 in the standard formulation).
We brieﬂy comment our notation: Capital Latin letters are sets or matrices
depending on the context. Lower case Latin letters denote vectors in IRn , except
for the range i, . . . , q that denotes integers. Lower case Greek letters are real
scalars. Subindices are diﬀerent components, i.e., xi is the i-th component of the
n
n-component vector x and a b is the inner product i=1 ai bi . For any vector, a
K subindex denotes a subvector whose components have indices belonging to the
set K. For any matrix B, Bi is its i-th row, and BK is the submatrix composed
of all Bi such that i ∈ K. For any entity, a superindex is an iteration index.
1

MOLDEIP project, Xunta de Galicia grant PGIDIT03TIC00101CT.

Support Vector Machine Detection of Peer-to-Peer Traﬃc

639

We seek (i) a high classiﬁcation accuracy, (ii) few nonzero classiﬁer components (for fast operation and identiﬁcation of statistically relevant information),
(iii) few active constraints at the solution of problem (1). The corresponding set
DK of support vectors represents problem (1), i.e. the solution does not change
if we drop the remaining vectors. When updating classiﬁers, it is interesting to
add to the next problem as few representatives of previous training datasets as
possible -i.e. their support vector sets-.
The rest of this paper is organized as follows: in section 2 we model p2p detection. In section 3 we evaluate detection with full monitoring of packet headers.
In section 4 we evaluate detection from sampled packet headers, the main goal
of this work. Finally, section 5 concludes the paper.

2

Problem Modeling

At the time this paper was written, all RECETGA network traﬃc of the Vigo
Campus traversed both a CISCO 7206 router and a Juniper M10 router. The
former produced binary netﬂow ﬁles comprising the headers of all traversing
packets (origin and destination IP addresses, port identiﬁers, protocol identiﬁers,
etc), whereas the latter only extracted the information of 0.1% packets.
We deﬁne a new problem each 24-hour slot, from a netﬂow data batch compiled in the previous slot. First, we convert the netﬂow ﬁles to ASCII format
with Flow-tools (http://www.splintered.net/sw/ﬂow-tools/). The resulting 24hour ﬁles occupy 2 GB for the CISCO 7206 and 50 MB for the Juniper M10.
Each line in these ﬁles corresponds to a single end-to-end transfer, with the
following ﬁelds: unix time, number of transferred packets, transfer size in bytes,
origin IP address, destination IP address, origin port, destination port and transport protocol (TCP or UDP).
Note that there is no ﬂow nor session information: for a given IP address
within RECETGA range, there may be thousands of end-to-end IP transfers
that appear in the ASCII ﬁle as independent entries. Basically, our preprocessor
generates a dataset with a single entry per RECETGA IP address.
Remark 1: The ﬁelds in each dataset entry match the current high-level metrics
in RECETGA graphic analysis tools.
Previous analyses [11] have identiﬁed the block sizes and packet formats of most
popular p2p protocols nowadays. However, We do not consider explicit p2p protocol information (which can be concealed or encrypted). Our parameters comprise diﬀerent aggregation levels (day time, night time, 5-minute time slots and
1-hour time slots), to consider temporal behavior.
Let x be a RECETGA IP address. Its dataset entry has the following ﬁelds:
p1: number of different IP addresses x sets connections to, day time
p2: number of different IP addresses x admits connections from, day time
p3: number of different ports in x external IP addresses access, day time
p4: number of different ports x opens, day time
p5: total traffic x generates, day time (MB)
p6: total traffic x receives, day time (MB)
p7 − p12: same as p1-p6, night time

640

F.J. Gonz´
alez-Casta˜
no et al.

p13: average number of different IP addresses x sets connections to, day time, measured in
5-minute slots
p14: same as p13, standard deviation
p15: same as p13, maximum
p16: average number of different IP addresses x admits connections from, day time, meas. in
5-minute slots
p17: same as p16, standard deviation
p18: same as p16, maximum
p19: average number of different ports in x external IP addresses access, day time, meas. in
5-minute slots
p20: same as p19, standard deviation
p21: same as p19, maximum
p22: average number of different ports x opens, day time, meas. in 5-minute slots
p23: same as p22, standard deviation
p24: same as p22, maximum
p25: average traffic x generates in a 5-minute slot, day time (MB)
p26: same as p25, standard deviation
p27: same as p25, maximum
p28: average traffic x receives in a 5-minute slot, day time (MB)
p29: same as p28, standard deviation
p30: same as p28, maximum
p31 − p48: same as p13-p30, night time
p49 − p66: same as p13-p30, 1-hour measurement slots
p67 − p84: same as p49-p66, night time

3

Performance Evaluation, CISCO 7206

We selected a representative netﬂow ﬁle for the evaluations in this section, corresponding to all RECETGA traﬃc March 28 2003. This ﬁle contained a typical
RECETGA behavior without unusual events.
Remark 2: As previously said, at the time this paper was written, all Vigo
Campus traﬃc traversed both the CISCO 7206 and the Juniper M10. Since
the CISCO 7206 monitored all traﬃc, we analyzed its logs (i) to determine the
eﬀectiveness of SVMs for p2p oﬀ-line detection and (ii) to determine statistically
relevant parameter classes. The main goal of this work is p2p detection from
sampled data, as imposed by the Juniper M10. We study that case in section 4.
3.1

Training and Testing Sets

First, we applied two ﬁlters to the problem:
1. The preprocessor only generated entries for IP addresses belonging to Universidad
de Vigo: 6141 IP addresses passed this ﬁlter.
2. The preprocessor only generated entries for IPs exchanging over 1000 KB/day
(threshold parameter): 614 IP addresses passed both ﬁlters.

The preprocessing times on a Pentium IV (2.4 GHz, 512 MB DDR) are 17.5
hours for p1-p12, 1.25 hours for p13-p48 and 7.25 hours for p49-p84. There are
three types of parameters: IP parameters, such as p1 and p2, port parameters,
such as p3 and p4 and traﬃc parameters, such as p5 and p6.
Once we obtained the dataset, we labeled it as follows to train the classiﬁer:
1. “Guilty” entries: those satisfying any of the following conditions:
(1.1.) using TCP ports of well-known P2P protocols.
(1.2.) large night downloads: p12 > 100 × threshold

Support Vector Machine Detection of Peer-to-Peer Traﬃc

641

(1.3.) relatively large uploads: ((p5 > 10 × threshold) AND (p5 > p6)) OR ((p11 >
10 × threshold) AND (p11 > p12))
2. “Innocent” entries: otherwise.

Remark 3: RECETGA labeling criteria may vary with network regulations.
Remark 4: for further validation of labeling criteria 1-2, we checked the IP addresses in the dataset that established connections with well-known p2p servers.
We detected 29 such addresses, which we had correctly labeled as “guilty” ones.
Finally, 456 “innocent” and 158 “guilty” IP addresses resulted. We divided the
labeled dataset into one hundred random partitions of training and testing subsets (90% and 10% points, respectively). Let p be the percentage of “guilty”
points (in this case, p = 0.26). Rather than applying the same factor 1/α to all
error variables in (1), we weighted them diﬀerently depending on point class:
1/pα for “innocent” points and 1/(1 − p)α for “guilty” ones.
3.2

Parameter Options in SVM Training

We solved problem (1) on each training subset, and then tested the resulting
classiﬁer on the corresponding testing subset. Table 1 shows average results
(across the 100 experiments) for parameter options A and B below (note: we
tuned α in (1) in preliminary trials; Nw is the average number of nonzero classiﬁer
coeﬃcients at the solution; Nsv is the average number of support vectors at the
solution; ag and ai are average blind testing accuracies on the testing subsets
for “guilty” and “innocent” IP addresses, respectively).
In option A, all parameters participate in the model. In option B, only daytime port parameters participate. This choice is motivated by three facts: ﬁrst,
malicious users may decide to hide behind the bulk of day-time traﬃc. Second,
the parameters that depend on the number of IP addresses will be unfeasible
with the advent of the huge IPv6 addressing range. Third, the size of “normal”
data transfers keeps growing with the capacity of servers and links. For example,
soon all p2p movie exchanges will consist of full DVD contents. Thus, traﬃc
parameters have a strong short-term technological dependence. Note that the
labeling criteria in section 3.1 are useless as detection criteria with option B.
Table 1. Average SVM results, options A and B, α = 10
Option
A
B

Nw
44
11

Nsv
25%
42.4%

ag
74.1%
65.9%

ai
92.9%
93.4%

For option B, the testing accuracy for “guilty” points is low (∼ 66%), and the
testing accuracy for “innocent” points is high (∼93%). However, the latter is less
important for RECETGA managers than the performance for “guilty” points.
As it could be expected, the number of points that support the classiﬁer (Nsv )

642

F.J. Gonz´
alez-Casta˜
no et al.

grows when limiting the number of parameters. In any case, even with option
B it is possible to discard 60% of them. The number of statistically signiﬁcant
parameters is surprisingly low for option B, for a similar performance.
In general, option B seems better than option A. However, in principle, it is
not valid due to its low testing accuracy for “guilty” points. In the following
subsection we propose a ﬁrst strategy to correct this problem.
3.3

γ Shift

In [2] we proposed a simple strategy to balance ag and ai . “Guilty” points tend
to form a “small” cloud at the edge of the “innocent” region in parameter space.
Consequently, once the classiﬁer was available, we “tuned” it by shifting γ (we
refer the reader to [2] for an exact description of this procedure).
The resulting average accuracies of the tuned classiﬁers are well balanced. For
option A, ag =90.2% and ai =87.1%. For option B, ag =79% and ai =78.7%. We
observe that the testing accuracy for “guilty” points grows to ∼80% for option
B, which is much better than the results in [1].
For RECETGA managers, a high detection accuracy for “guilty” points is extremely important. In other networks, avoiding false positives may be preferable.
Note that γ-shift is a parameterizable process that can be adjusted accordingly.
3.4

Faster Preprocessing Stage

Solving (1) with CPLEX took few seconds in all tests, so preprocessing is dominant in solution time. From the experience of RECETGA managers, port parameters are signiﬁcant. Thus, in order to decrease preprocessing time, we deﬁned
two new parameter options C and D. Option C consists of day-time port parameters, aggregation levels of 1 hour and 5 minutes. Option D consists of day-time
port parameters, aggregation level of 5 minutes.
Table 2. Average SVM results with γ shift, options B-D, α = 10
Option
B
C
D

Nw
11
10
6

Nsv
42.4%
44.3%
47.2%

ag
79%
78.3%
81.6%

ai
78.7%
78.1%
81.4%

Table 2 shows the performance of trainer (1) with γ shift for these options.
We observe that, although the average number of support vectors grows slightly,
restricting parameters to 5-minute aggregation also yields the following:
1. Although all parameters in option D are signiﬁcant, there are only 6 such
parameters: p19-p24. In the training scenarios, these parameters appear frequently at the solution with nonzero weights: p19 in 100% scenarios, p20 in
99%, p21 in 99%, p22 in 87%, p23 in 87% and p24 in 100%.

Support Vector Machine Detection of Peer-to-Peer Traﬃc

643

2. An average testing accuracy ag of 81.6%. In other words, only 2-3 guilty
IP addresses escape in each scenario, on average. Apparently, a 5-minute
aggregation level captures the evolution of user behavior along the day.
If we preprocess the netﬂow ﬁles with the parameter options so far, the following preprocessing times result: 26 hours for option A, 7.75 hours for option
B and 3.25 hours for option C. For option D, we only need ∼34 min of Pentium
IV CPU to preprocess 24 hours of RECETGA monitoring data.
3.5

Nonlinear Kernel Approach

Although γ-shift balances classiﬁcation performance, it has no theoretical support. Therefore, we decided to apply a nonlinear kernel to the best scenario so
far –option D– as follows: we extracted a kernel subset of 30 innocent and guilty
points (15+15). From the original dataset in option D we generated a new one by
9
1
(u/||u|| · v/||v|| + 1) ,
applying the degree 9 polynomial kernel in [8] K(u, v) = 512
6
where u is an original point and v is a point in the kernel subset (both in IR ).
This polynomial kernel has been highly successful in text recognition. Therefore,
each original point is mapped into a new one in IR30 . We only allow a subset
of the original points in the kernel subset because this strategy produced good
results in [9], for a low increase in computing load.
We ran 100 experiments (reserving 10% points in each case for testing) with
α =0.01, and obtained the following results for option D: Nw =15 (11 guilty
points and 4 innocent points in the kernel subset), Nsv =45.9%, ag =80.8%,
ai =83.6%. Thus, the nonlinear support vector machine and the linear one with
γ-shift behave similarly for the CISCO 7206.

4

Performance Evaluation, Juniper M10

In this section we evaluate the impact of packet sampling on p2p detection
accuracy. The Juniper M10 (M10 in the sequel) cannot store all traversing packet
headers. In RECETGA, the M10 samples 0.1% of them. As a result, we relaxed
M10 labeling, by setting threshold to 1 KB/day.
Remark 5: this obvious change is the only design decision to admit sampled
data, i.e. we use exactly the same programs and methodologies in section 3, but
we feed them with the sampled headers of the M10.
Table 3 shows SVM detection performance March 28 2003, when RECETGA
traﬃc traversed both the CISCO 7206 and the M10. Full preprocessing was much
faster on M10 sampled data: it took less than 30 seconds. So there is no advantage
in deﬁning diﬀerent aggregation levels, in terms of preprocessing time.
Note that the methodologies in section 3 improve on M10 data. If we apply γshift, for less signiﬁcant port parameters (3 versus 6) and a comparable average
number of support vectors, the average testing accuracy for “guilty” points is
practically 90%. In all experiments, the three signiﬁcant parameters in option D
with γ-shift are p19, p21 and p24.

644

F.J. Gonz´
alez-Casta˜
no et al.
Table 3. Average SVM results. Option D, Juniper M10 dataset
Method
Linear w. γ-shift
Nonlinear

α
10
0.1

Nw
3
6

Nsv
50.3%
28.3%

ag
89.3%
91.6%

ai
83.2%
90.5%

If we apply the nonlinear kernel in section 3, only 6 points in the kernel subset
are signiﬁcant at the solution: 2 guilty points and 4 innocent points, on average.
The average number of support vectors drops to 28% and the average testing
accuracies (for innocent and guilty points) are well balanced and exceed 90%

5

Conclusions

High performance routers cannot monitor all the packet headers, due to their
high line rates. As a consequence, techniques such as [5] are unfeasible. Nonlinear
support vector machine detection of sampled p2p traﬃc achieves classiﬁcation
accuracies above 90%. It also outperforms the γ-shift procedure in [2] in average
number of support vectors. The kernel in our experiments was quite small, with
as few as six signiﬁcant points.

References
1. Moore, A. W. and D. Zuev. Internet Traﬃc Classiﬁcation Using Bayesian Analysis
Techniques. In Proc. ACM Sigmetrics 2005.
´
2. Gonz´
alez-Casta˜
no, F.J., P.S. Rodr´ıguez-Hern´
andez, R. P. Mart´ınez-Alvarez
and
A. G´
omez-Tato. Support vector machine detection of peer-to-peer traﬃc in highperformance routers with packet sampling. In Proc. ICANNGA 2007.
3. Vapnik, V. N. The nature of statistical learning theory. Springer, New York, 1995.
4. Cristianini, N. and J. Shawe-Taylor. An introduction to support vector machines.
Cambridge University Press, 2000.
5. Karagiannis, T., A. Broido, M. Faloutsos and K.C. Claﬀy. Transport Layer Identiﬁcation of P2P Traﬃc. In Proc. ACM IMC 2004.
6. Sen, S., O. Spatscheck and D. Wang. Accurate, Scalable In-Network Identiﬁcation
of P2P Traﬃc Using Application Signatures. In Proc. 13th International Conference on World Wide Web, 2004.
7. Tran, Q.A., H. Duan and X. Li. One-Class Support Vector Machine for Anomaly
Network Traﬃc Detection. 2nd Network Research Workshop, 18th APAN, 2004.
8. DeCoste, D. and B. Schoelkopf. Training Invariant Support Vector Machines.
Machine Learning, 46:161-190, 2002.
9. Gonz´
alez-Casta˜
no, F.J., U. M. Garc´ıa Palomares and R. R. Meyer. Projection
Support Vector Machine Generators. Machine Learning, 54-1:33-44, 2004
10. Bradley, P.S., O. L. Mangasarian and D. R. Musicant. Optimization Methods in
Massive Datasets. In Handbook of Massive Datasets, J. Abello, P. M. Pardalos and
M. G. C. Resende, Editors, Kluwer Publishing, 439-472, 2002.
11. Karagiannis, T., A. Broido, N. Brownlee, K.C. Claﬀy and M. Faloutsos. Filesharing in the Internet: A characterization of P2P traﬃc in the backbone. Technical report, Department of Computer Science, University of California, Riverside.
http://www.cs.ucr.edu/∼tkarag/papers/tech.pdf, 2003.

