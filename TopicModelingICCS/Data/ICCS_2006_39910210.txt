An Implicit Riemannian Trust-Region Method
for the Symmetric Generalized Eigenproblem
C.G. Baker1,2, P.-A. Absil3,4 , and K.A. Gallivan1
1

School of Computational Science, Florida State University, Tallahassee, FL, USA
2
Computational Mathematics & Algorithms, Sandia National Laboratories,
Albuquerque, NM, USA
3
D´epartement d’ing´enierie math´ematique, Universit´e catholique de Louvain,
1348 Louvain-la-Neuve, Belgium
4
Peterhouse, University of Cambridge, UK

Abstract. The recently proposed Riemannian Trust-Region method
can be applied to the problem of computing extreme eigenpairs of a matrix pencil, with strong global convergence and local convergence properties. This paper addresses inherent ineﬃciencies of an explicit trustregion mechanism. We propose a new algorithm, the Implicit Riemannian
Trust-Region method for extreme eigenpair computation, which seeks to
overcome these ineﬃciencies while still retaining the favorable convergence properties.

1

Introduction

Consider n × n symmetric matrices A and B, with B positive deﬁnite. The
generalized eigenvalue problem
Ax = λBx
is known to admit n real eigenvalues λ1 ≤ . . . ≤ λn , along with associated Borthonormal eigenvectors v1 , . . . , vn (see [1]). We seek here to compute the p leftmost eigenvectors of the pencil (A, B). It is known that the leftmost eigenspace
U = colsp(v1 , . . . , vp ) of (A, B) is the column space of any minimizer of the
generalized Rayleigh quotient
f : Rn×p
→ R : Y → trace (Y T BY )−1 (Y T AY ) ,
∗

(1)

denotes the set of full-rank n × p matrices.
where Rn×p
∗
This result underpins a number of methods based on ﬁnding the extreme
points of the generalized Rayleigh quotient (see [2, 3, 4, 5, 6, 7] and references
This work was supported by NSF Grant ACI0324944. The ﬁrst author was in part
supported by the CSRI, Sandia National Laboratories. Sandia is a multiprogram
laboratory operated by Sandia Corporation, a Lockheed Martin Company, for the
United States Department of Energy; contract/grant number: DE-AC04-94AL85000.
The second author was partially supported by Microsoft Research through a Research Fellowship at Peterhouse, Cambridge.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 210–217, 2006.
c Springer-Verlag Berlin Heidelberg 2006

An Implicit RTR Method for the Symmetric Generalized Eigenproblem

211

therein). Here, we consider the recently proposed [8, 9] Riemannian Trust-Region
(RTR) method. This method formulates the eigenvalue problem as an optimization problem on a Riemannian manifold, utilizing a trust-region mechanism to
ﬁnd a solution. Similar to Euclidean trust-region methods [10, 11], the RTR
method ensures strong global convergence properties while allowing superlinear
convergence near the solution. However, the classical trust-region mechanism
has some inherent ineﬃciencies. When the trust-region radius is too large, valuable time may be spent computing an update that may be rejected. When the
trust-region radius is too small, we may reject good updates lying outside the
trust-region. A second problem with the RTR method is typical of methods
where the outer stopping criterion is evaluated only after exiting the inner iteration: in almost all cases, the last call to the inner iteration will perform more
work than necessary to satisfy the outer stopping criterion.
In the current paper, we explore solutions to both of the problems described
above. We present an analysis providing us knowledge of the model ﬁdelity at
every step of the inner iteration, allowing our trust-region to be based directly
on the trustworthiness of the model. We propose a new algorithm, the Implicit
Riemannian Trust-Region (IRTR) method, exploiting this analysis.

2

Riemannian Trust-Region Method with Newton Model

The RTR method can be used to minimize the generalized Rayleigh quotient (1).
The right-hand side of this function depends only on colsp(Y ), so that f induces
a real-valued function on the set of p-dimensional subspaces of Rn . (This set is
known as the Grassmann manifold, which can be endowed with a Riemannian
structure [4, 12].) The RTR method iteratively computes the minimizer of f
by (approximately) minimizing successive models of f . The minimization of the
models is done via an iterative process, which is referred to as the inner iteration,
to distinguish it with the principal outer iteration. We present here the process
in a way that does not require a background in diﬀerential geometry; we refer
to [13] for the mathematical foundations of the technique.
Let Y be a full-rank, n × p matrix. We desire a correction S of Y such that
f (Y + S) < f (Y ). A diﬃculty is that corrections of Y that do not modify its
column space do not aﬀect the value of the cost function. This situation leads to
unpleasant degeneracy if it is not addressed. Therefore, we require S to satisfy
some complementarity condition with respect to the space VY := {Y M : M ∈
Rp×p }. Here, in order to simplify later developments, we impose complementarity
via B-orthogonality, namely S ∈ HY where
HY = {Z ∈ Rn×p : Y T BZ = 0}.
Consequently, the task is to minimize the function
fˆY (S) := trace ((Y + S)T B(Y + S))−1 ((Y + S)T A(Y + S)) ,

S ∈ HY .

The RTR method constructs a model mY of fˆY and computes an update S
which approximately minimizes mY , so that the inner iteration attempts to solve
the following problem:

212

C.G. Baker, P.-A. Absil, and K.A. Gallivan

min mY (S),

S ∈ HY ,

S

2

≤ Δ,

where Δ (the trust-region radius) denotes the region in which we trust mY to
approximate fˆY . The next iterate and trust-region radius are determined by the
performance of mY with respect to fˆY . This performance ratio is measured by
the quotient:
fˆY (0) − fˆY (S)
ρY (S) =
.
mY (0) − mY (S)
Low values of ρY (S) (close to zero) indicate that the model mY at S is not a
good approximation to fˆY . In this scenario, the trust-region radius is reduced
and the update Y + S is rejected. Higher values of ρY (S) allow the acceptance
of Y + S as the next iterate, and a value of ρY (S) close to one suggests good
approximation of fˆY by mY , allowing the trust-region radius to be enlarged.
Usually, the model mY is chosen as a quadratic function approximating fˆY .
In the sequel, in contrast to [9] where the quadratic term of the model was unspeciﬁed, we assume that mY is the Newton model, i.e., the quadratic expansion
of fˆY at S = 0. Then, assuming from here on that Y T BY = Ip , we have
mY (S) = trace Y T AY + 2trace S T AY + trace S T AS − BS(Y T AY )
1
= fˆY (0) + trace S T ∇fˆY + trace S T HY [S] ,
2
where the gradient and the eﬀect of the Hessian of fˆY are identiﬁed as
∇fˆY = 2PBY AY

HY [S] = 2PBY AS − BS(Y T AY ) ,

and where PBY = I − BY (Y T BBY )−1 Y T B is the orthogonal projector on the
space perpendicular to the column space of BY .
Simple manipulation shows the following:
fˆY (0) − fˆY (S) = trace Y T AY − (I + S T BS)−1 (Y + S)T A(Y + S)
= trace (I + S T BS)−1 (S T BS(Y T AY ) − 2S T AY − S T AS) .
Consider the case where p = 1. The above equation simpliﬁes to
fˆy (0) − fˆy (s) = (1 + sT Bs)−1 sT Bsy T Ay − 2sT Ay − sT As
= (1 + sT Bs)−1 (my (0) − my (s)) ,
so that
ρy (s) =

1
fˆy (0) − fˆy (s)
=
.
my (0) − my (s)
1 + sT Bs

(2)

This allows the model performance ratio ρy to be constantly evaluated as the
model minimization progresses, simply by tracking the B-norm of the current
update vector.

An Implicit RTR Method for the Symmetric Generalized Eigenproblem

3

213

Implicit Riemannian Trust-Region Method

In this section, we explore the possibility of selecting the trust-region as a sublevel
set of the performance ratio ρY . We dub this approach the Implicit Riemannian
Trust-Region method.
3.1

Case p = 1

The analysis of ρ in the previous section shows that for the generalized Rayleigh
quotient with p = 1, the performance of the model decreases as the iterate moves
away from zero. However, in the case of the p = 1 generalized Rayleigh quotient,
ρy (s) has a simple relationship with s B . Therefore, by monitoring the B-norm
of the inner iterate, we can easily determine the value of ρ for a given inner
iterate. Furthermore, the relationship between ρ and the B-norm of a vector,
allows us to move along a search direction to a speciﬁc value of ρ. These two
things, combined, enable us to redeﬁne the trust-region based instead on the
value of ρ.
The truncated conjugate gradient proposed in [9] for use in the simple RTR
algorithm seeks to minimize the model mY within a trust-region deﬁned explicitly as {s : s 2 ≤ Δ}. Here, we change the deﬁnition of the trust-region to
{s : ρy (s) ≥ ρ }, for some ρ ∈ (0, 1). The necessary modiﬁcations to this algorithm are very simple. The deﬁnition of the trust-region occurs in three places:
when detecting whether the trust-region has been breached; when constraining
the update vector in the case that the trust-region was breached; and when
constraining the update vector in the case that we have detected a direction of
negative curvature. The new inner iteration is listed in Algorithm 1, with the
diﬀerences highlighted.
Having stated the deﬁnition of the implicit trust-region, based on ρ, we need
a mechanism for following a search direction to the edge of the trust-region.
That is, at some outer step k and given sj and a search direction dj , we wish to
compute s = sj + τ dj such that ρyk (s) = ρ . Given ρ and denoting
Δρ =

1
− 1,
ρ

(3)

the desired value of τ is given by

τ=

−dTj Bsj +

(dTj Bsj )2 + dTj Bdj (Δ2ρ − sTj Bsj )
dTj Bdj

.

(4)

A careful implementation precludes the need for any more matrix multiplications
against B than are necessary to perform the iterations.
Another enhancement in Algorithm 1 is that the outer stopping criterion is
tested during the inner iteration. This technique is not novel in the context
of eigensolvers with inner iterations, having been proposed by Notay [14]. Our
motivation for introducing this test is that, when it is absent, the ﬁnal outer

214

C.G. Baker, P.-A. Absil, and K.A. Gallivan

Algorithm 1 (Preconditioned Truncated CG (IRTR))
Data: A,B symmetric, B positive deﬁnite, ρ ∈ (0, 1), preconditioner M
Input: Iterate y, y T By = 1
Set s0 = 0, r0 = ∇fˆy , z0 = M −1 r0 , d0 = −z0
for j = 0, 1, 2, . . .
Check κ/θ stopping¨ criterion
©
if rj 2 ≤ r0 2 min κ, r0 θ2
return sj
Check curvature of current search direction
if dTj Hy [dj ] ≤ 0
Compute τ such that s = sj + τ dj satisﬁes ρy (s) = ρ
return s
Set αj = (zjT rj )/(dTj Hy [dj ])
Generate next inner iterate
Set sj+1 = sj + αj dj
Check implicit trust-region
if ρy (sj+1 ) < ρ
Compute τ ≥ 0 such that s = sj + τ dj satisﬁes ρy (s) = ρ
return s
Use CG recurrences to update residual and search direction
Set rj+1 = rj + αj Hy [dj ]
Set zj+1 = M −1 rj+1
T
Set βj+1 = (zj+1
rj+1 )/(zjT rj )
Set dj+1 = −zj+1 + βj+1 dj
Check outer stopping criterion
Compute ∇fˆy+s
2 and test
j+1

end for.

step may reach a much higher accuracy than speciﬁed by the outer stopping
criterion, resulting in a waste of computational eﬀort. Also, while Notay proposed
a formula for the inexpensive evaluation of the outer norm based on the inner
iteration, we must rely on a slightly more expensive, but less frequent, explicit
evaluation of the outer stopping criterion.
The product of this iteration is an update vector sj which is guaranteed to
lie inside of the ρ-based trust-region. The result is that the ρ value of the new
iterate need not be explicitly computed, the new iterate can be automatically
accepted, with an update vector constrained by model ﬁdelity instead of a discretely chosen trust-region radius based on the performance of the last iterate.
An updated outer iteration is presented in Algorithm 2, which also features an
optional subspace acceleration enhancement `a la Davidson [15].

An Implicit RTR Method for the Symmetric Generalized Eigenproblem

215

Algorithm 2 (Implicit Riemannian Trust-Region Algorithm)
Data: A,B symmetric, B positive deﬁnite, ρ ∈ (0, 1)
Input: Initial subspace W0
for k = 0, 1, 2, . . .
Model-based Minimization
Generate yk using a Rayleigh-Ritz procedure on Wk
Compute ∇fˆyk and check ∇fˆyk 2
Compute sk to approximately minimize myk such that ρ(sk ) ≥ ρ (Algorithm 1)
Generate next subspace
if performing subspace acceleration
Compute new acceleration subspace Wk+1 from Wk and sk
else
Set Wk+1 = colsp(yk + sk )
end
end for.

3.2

A Block Algorithm

The analysis of Section 2 seems to preclude a simple formula for ρ in the case
that p > 1. We wish, however, to have a block algorithm. The solution is to
decouple the block Rayleigh quotient into the sum of p separate rank-1 Rayleigh
quotients, which can then be addressed individually using the IRTR strategy.
This is done as follows.
Assume that our iterates satisfy Y T AY = Σ = diag(σ1 , . . . , σp ), in addition to
T
Y BY = Ip . In fact, this is a natural consequence of the Rayleigh-Ritz process.
Then given Y = y1 . . . yp , the model mY can be rewritten:
mY (S) = trace Σ + 2S T AY + S T (AS − BSΣ)
p

p

σi + 2sTi Ayi + sTi (A − σi B)si =

=
i=1

myi (si ).
i=1

It should be noted that the update vectors for the decoupled minimizations
must have the original orthogonality constraints in place. That is, instead of
requiring only that yiT Bsi = 0, we require that Y T Bsi = 0 for each si . This is
necessary to guarantee that the next iterate, Y + S, has full rank, so that the
Rayleigh quotient is deﬁned.
As for the truncated conjugate gradient, the p individual IRTR subproblems
should be solved simultaneously, with the inner iteration stopped as soon as any
of the iterations satisfy one of the inner stopping criteria (exceeded trust-region
or detected negative curvature). If only a subset of iterations are allowed to
continue, then the κ/θ inner stopping criterion may not be feasible.
The described method attempts to improve on the RTR, while retaining the
strong global and local convergence properties of the RTR. The model ﬁdelity
guaranteed by the implicit trust-region mechanism allows for a straightforward

216

C.G. Baker, P.-A. Absil, and K.A. Gallivan
IRTR vs. RTR: Precond + SA

IRTR vs. RTR: Precond
RTR
ITR .50
ITR .75
ITR .90
ITR .99

10

norm(grad)

norm(grad)

10

5

10

RTR
ITR .50
ITR .75
ITR .90
ITR .99

10

10

5

10

0

0

10

10

0

50

100
# matvecs (A*x)

150

200

0

50

100
# matvecs (A*x)

150

Fig. 1. Figures illustrating the eﬃciency of RTR vs. IRTR for diﬀerent values of ρ

proof of global convergence. Related work [16] presents the proofs of global convergence, along with a discussion regarding the consequences of early termination of the inner iteration due to testing the outer stopping criterion and an
exploration of the RTR method in light of the ρ analysis presented here.

4

Numerical Results

The IRTR method seeks to overcome the ineﬃciencies of the RTR method, such
as the rejection of computed updates and the limitations due to the discrete
nature of the trust-region radius. We compare the performance of the IRTR
with that of the classical RTR. The following experiments were performed in
MATLAB (R14) under Mac OSX. Figure 1 considers a generalized eigenvalue
problem with a preconditioned inner iteration. The matrices A and B are from
the Harwell-Boeing collection BCSST24. The problem is of size n = 3562 and we
are seeking the leftmost p = 5 eigenvalues. The inner iteration is preconditioned
using an exact factorization of A. Two experiments are run: with and without
subspace acceleration. When in eﬀect, the subspace acceleration strategy occurs
over the 10-dimensional subspace colsp([Yk , Sk ]). The RTR is tested with a value
of ρ = 0.1, while the IRTR is run for multiple values of ρ . These experiments
demonstrate that the IRTR method is able to achieve a greater eﬃciency than
the RTR method.

5

Conclusion

This paper presents an optimization-based analysis of the symmetric, generalized
eigenvalue problem which explores the relationship between the inner and outer
iterations. The paper proposes the Implicit Riemannian Trust-Region method,
which seeks to alleviate ineﬃciencies resulting from the inner/outer divide, while
still preserving the strong convergence properties of the RTR method. This

An Implicit RTR Method for the Symmetric Generalized Eigenproblem

217

algorithm was shown in numerical experiments to be capable of greater eﬃciency
than the RTR method.
Acknowledgments. Useful discussions with Andreas Stathopoulos, Rich
Lehoucq and Ulrich Hetmaniuk are gratefully acknowledged.

References
1. Stewart, G.W.: Matrix algorithms, Vol II: Eigensystems. Society for Industrial
and Applied Mathematics, Philadelphia (2001)
2. Sameh, A.H., Wisniewski, J.A.: A trace minimization algorithm for the generalized
eigenvalue problem. SIAM J. Numer. Anal. 19(6) (1982) 1243–1259
3. Smith, S.T.: Optimization techniques on Riemannian manifolds. In: Hamiltonian
and gradient ﬂows, algorithms and control. Volume 3 of Fields Inst. Commun.
Amer. Math. Soc., Providence, RI (1994) 113–136
4. Edelman, A., Arias, T.A., Smith, S.T.: The geometry of algorithms with orthogonality constraints. SIAM J. Matrix Anal. Appl. 20(2) (1998) 303–353
5. Mongeau, M., Torki, M.: Computing eigenelements of real symmetric matrices via
optimization. Comput. Optim. Appl. 29(3) (2004) 263–287
6. Sameh, A., Tong, Z.: The trace minimization method for the symmetric generalized
eigenvalue problem. J. Comput. Appl. Math. 123 (2000) 155–175
7. Knyazev, A.V.: Toward the optimal preconditioned eigensolver: locally optimal
block preconditioned conjugate gradient method. SIAM J. Sci. Comput. 23(2)
(2001) 517–541
8. Absil, P.-A., Baker, C.G., Gallivan, K.A.: Trust-region methods on Riemannian
manifolds with applications in numerical linear algebra. In: Proceedings of the
16th International Symposium on Mathematical Theory of Networks and Systems
(MTNS2004), Leuven, Belgium, 5–9 July 2004. (2004)
9. Absil, P.A., Baker, C.G., Gallivan, K.A.: A truncated-CG style method for symmetric generalized eigenvalue problems. J. Comput. Appl. Math. 189(1–2) (2006)
274–285
10. Mor´e, J.J., Sorensen, D.C.: Newton’s method. In: Studies in numerical analysis.
Volume 24 of MAA Stud. Math. Math. Assoc. America, Washington, DC (1984)
29–82
11. Nocedal, J., Wright, S.J.: Numerical Optimization. Springer Series in Operations
Research. Springer-Verlag, New York (1999)
12. Absil, P.-A., Mahony, R., Sepulchre, R.: Riemannian geometry of Grassmann
manifolds with a view on algorithmic computation. Acta Appl. Math. 80(2) (2004)
199–220
13. Absil, P.-A., Baker, C.G., Gallivan, K.A.: Trust-region methods on Riemannian
manifolds. submitted (2005)
14. Notay, Y.: Combination of Jacobi-Davidson and conjugate gradients for the partial
symmetric eigenproblem. Numer. Linear Algebra Appl. 9(1) (2002) 21–44
15. Sleijpen, G.L.G., Van der Vorst, H.A.: A Jacobi-Davidson iteration method for
linear eigenvalue problems. SIAM J. Matrix Anal. Appl. 17(2) (1996) 401–425
16. Baker, C.G., Absil, P.-A., Gallivan, K.A.: An implicit Riemannian trust-region
method for the symmetric generalized eigenproblem. Technical Report FSUSCS-2006-152, School of Computational Science, Florida State University (2006)
http://scseprints.scs.fsu.edu.

