Procedia Computer Science
Volume 80, 2016, Pages 19–29
ICCS 2016. The International Conference on Computational
Science

Portable Application-level Checkpointing for Hybrid
MPI-OpenMP Applications
Nuria Losada, Mar´ıa J. Mart´ın, Gabriel Rodr´ıguez, and Patricia Gonz´alez
{nuria.losada, mariam, grodriguez, patricia.gonzalez}@udc.es
Grupo de Arquitectura de Computadores, Universidade da Coru˜
na, Spain

Abstract
As parallel machines increase their number of processors, so does the failure rate of the global
system, thus, long-running applications will need to make use of fault tolerance techniques to
ensure the successful execution completion. Most of current HPC systems are built as clusters of
multicores. The hybrid MPI-OpenMP paradigm provides numerous beneﬁts on these systems.
This paper presents a checkpointing solution for hybrid MPI-OpenMP applications, in which
checkpoint consistency is guaranteed by using a coordination protocol intra-node, while no internode coordination is needed. The proposal reduces network utilization and storage resources in
order to optimize the I/O cost of fault tolerance, while minimizing the checkpointing overhead.
Besides, the portability of the solution and the dynamic parallelism provided by OpenMP
enable the restart of the applications using machines with diﬀerent architectures, operating
systems and/or number of cores, adapting the number of running OpenMP threads for the
best exploitation of the available resources. Extensive evaluation using hybrid MPI-OpenMP
applications from the ASC Sequoia Benchmark Codes and NERSC-8/Trinity benchmarks is
presented, showing the eﬀectiveness and eﬃciency of the approach.
Keywords: Multicore Clusters, Hybrid MPI-OpenMP, Fault Tolerance, Checkpointing

1

Introduction

Current High Performance Computing (HPC) systems are clusters of multicore nodes that
can beneﬁt from the use of a hybrid programming model, in which MPI (Message Passing Interface) [18] is used for the inter-node communications while a shared memory programming
model, such as OpenMP [13], is used intra-node [17, 7]. Even though programming using a hybrid MPI-OpenMP model requires some eﬀort from application developers, this model provides
several advantages such as reducing the communications needs and memory consumption, as
well as improving load balance and numerical convergence [15, 7].
As parallel machines increase their number of processors, so does the failure rate of the global
system. This is not a problem while the mean time to complete the execution of an application
remains well under the mean time to failure of the underlying hardware. However that is not
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.294

19

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

always possible on applications with long runs, where users and programmers need to make
use of fault tolerance techniques to ensure that not all computation done is lost on machine
failures. Checkpointing is a widely used fault tolerance technique, in which the computation
state is saved periodically to disk into checkpoint ﬁles, allowing the recovery of the application
when a failure occurs.
Although a number of checkpointing solutions for parallel applications have been proposed [5, 8, 14, 3, 1], to our best knowledge, only Martsinkevich et al. [11] have focused on
hybrid message-passing and shared memory applications. However, they only tackle transient
errors and focus on hybrid MPI-OmpSs programs. In this work, CPPC (ComPiler for Portable
Checkpointing), a portable and transparent checkpointing infrastructure for MPI and OpenMP
parallel applications, is extended to cope with fail-stop failures in hybrid MPI-OpenMP applications. The main contribution of this work is the proposal of an application-level checkpointing
solution for hybrid programs, in which checkpoint consistency is guaranteed by using a coordination protocol intra-node, while no inter-node coordination is needed. This approach ensures
data consistency and allows the user to specify an adequate checkpointing frequency, while
performance is not penalized by global coordination. The experimental results section shows
the low overhead introduced by the proposal. Additionally, the choice of an application-level
approach and the portability of the checkpoint ﬁles allows building adaptable applications, that
is, applications that are able to be restarted in a diﬀerent resource architecture and/or number
of cores. This feature will be specially useful on heterogeneous clusters, allowing the adaptation
of the application to the available resources.
This paper is structured as follows. Section 2 introduces the CPPC tool. Section 3 describes
how CPPC is modiﬁed and extended to cope with hybrid MPI-OpenMP codes. Section 4
presents the experimental evaluation of the proposal. Finally, Section 5 concludes this paper.

2

CPPC overview

CPPC is an open-source checkpointing tool for MPI [16] and OpenMP [9] applications available
at http://cppc.des.udc.es under GNU general public license (GPL). It is implemented at
the application level, and, thus, it is independent of the MPI or OpenMP implementation, the
operating system, and any lower-level framework used.
At compile time the CPPC source-to-source compiler automatically transforms a parallel
code into an equivalent fault-tolerant version instrumented with calls to the CPPC library, as
exempliﬁed in Figure 1. This instrumentation includes calls to the CPPC Register() and the
CPPC Do checkpoint() routines. The CPPC Register() routine marks the relevant variables
for their inclusion in the checkpoint ﬁles. The CPPC Do checkpoint() function allows each
process or thread to generate a checkpoint ﬁle every N calls to this function (being N the
user-deﬁned checkpointing frequency).
The CPPC compiler identiﬁes the most expensive loops in the application by using a heuristic evaluation of computational cost. Checkpoint calls are placed in the most expensive loops
in the application, allowing users to specify an adequate checkpointing frequency. Checkpoint
consistency is guaranteed by locating the CPPC Do checkpoint() routine in the ﬁrst safe point
of these loops. In MPI applications, the CPPC compiler performs a static analysis of interprocess communications and identiﬁes safe points as code locations where it is guaranteed that
no inconsistencies due to messages may occur. This way, processes are implicitly coordinated
and no inter-process communications or runtime synchronization are necessary when checkpointing, because processes checkpoint at the same selected safe locations and at the same
relative moments (according to the checkpointing frequency). We have called this technique
20

Portable ALC for Hybrid MPI-OpenMP Applications

(a) CPPC global ﬂow.

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

(b) Instrumentation example.

Figure 1: CPPC operation
spatial coordination [16]. On the other hand, safe points in OpenMP applications correspond
with code locations outside or inside of an OpenMP parallel region, as long as they are reachable by all running threads. In OpenMP applications the checkpointed variables can be private
to each thread or shared among all of them. Therefore, a coordinated checkpointing protocol is
needed to ensure data consistency. All threads must checkpoint at the same time, guaranteeing
that none of them modify the shared state when it is being saved, ensuring that both private
and shared variables are consistently checkpointed, and allowing the recovery of a consistent
global state. When a thread determines that a checkpoint ﬁle must be generated (according
to the user-deﬁned checkpointing frequency) it forces all the other threads to do so in the
next CPPC Do checkpoint() call. This call does not have to be necessarily placed in the same
relative point of the code nor in the same iteration of the loop.
CPPC implements several optimizations to reduce the checkpointing overhead. The checkpoint ﬁle sizes are reduced by using a liveness analysis to save only those user variables indispensable for the application recovery; and by using the zero-blocks exclusion [4] technique,
which avoids the storage of memory blocks that contain only zeros. Besides, a multithreaded
dumping overlaps the checkpoint ﬁle dumping to disk with the computation of the application.
Finally, in OpenMP applications, only a copy of the shared variables is dumped to disk. Moreover, a heuristic analysis is used to distribute CPPC management of the shared variables among
the running threads, notably improving the performance of the checkpoint operation [10].
One of CPPC main features is portability. Applications can be restarted on machines
with diﬀerent architectures and/or operating systems than those in which the checkpoint ﬁles
were generated. Checkpoint ﬁles are portable because of the use of a portable storage format
(HDF5 [6]) and the exclusion of architecture-dependent state from checkpoint ﬁles. Such nonportable state is recovered through the re-execution of the code responsible for its creation in
the original execution. This is specially useful in heterogeneous clusters, where this feature
enables the completion of the applications even when those resources that were being used are
no longer available or the waiting time to access them is prohibitive.
Upon failure, the restart phase is comprised of three fundamental parts: identifying the most
recent valid recovery line formed by the newest checkpoint ﬁle available simultaneously to all
processes/threads, reading the checkpoint data into memory, and reconstructing the application
21

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

state. The reconstruction of the application state is achieved through the ordered execution
of certain blocks of code of the application. These blocks of code move the recovered data
to its proper memory location, re-create the non-portable state, and position the application
control ﬂow in the point in which the checkpoint ﬁles were generated, so that the execution can
continue. The compiler inserts control ﬂow code (labels and conditional jumps), as shown in
Figure 1b, to ensure an ordered re-execution.

3

Extending CPPC for hybrid MPI-OpenMP applications

This section covers the modiﬁcations performed in CPPC to cope with hybrid MPI-OpenMP
applications. Hybrid applications are based on the use of MPI for the inter-node communications while OpenMP is used intra-node. During the execution, each MPI process creates one
team of OpenMP threads.
In hybrid MPI-OpenMP applications, checkpoints can be located inside or outside an
OpenMP parallel region. Many hybrid codes present the optimal checkpoint location outside
an OpenMP parallel region, and thus, they can be adequately checkpointed just by treating
them as regular MPI programs. This is the case of those hybrid applications in which the most
expensive loop contains several OpenMP parallel regions, allowing the checkpoint call to be
placed between two of them. However, there are hybrid codes that do not follow this pattern,
and their most expensive loops, in which a checkpoint should be located to meet an adequate
checkpoint frequency, are inside an OpenMP parallel region. Thus, these codes can not be
treated as regular MPI or OpenMP programs. To obtain the most general solution for the
hybrid MPI-OpenMP programming model, its speciﬁc characteristics have to be studied.
As in OpenMP and MPI applications, in hybrid MPI-OpenMP programs checkpoints must
be located at safe points. These safe points correspond with code locations that verify the
conditions applied both for MPI and OpenMP applications. Firstly, safe points must be code
locations where it is guaranteed that no inconsistencies due to MPI messages may occur. Secondly, safe points placed inside an OpenMP parallel region must be reachable by all the threads
in the team. The CPPC compiler automatically detects the most costly loops and inserts a
checkpoint call in the ﬁrst safe point of these loops. Both the relevant shared and private
variables in the application are identiﬁed by the CPPC liveness analysis for their inclusion in
the checkpoint ﬁles. Besides, shared variables are distributed among the running threads for
minimizing the checkpointing overhead.
To ensure data consistency when checkpointing hybrid applications, all threads in the same
team must checkpoint at the same time, so that none of them modify the shared state when it is
being saved and ensuring that both private and shared variables are consistently checkpointed.
Thus, a coordination protocol must be used. From the perspective of MPI communications,
consistency is guaranteed by the spatial coordination between teams of threads obtained by the
use of safe points. However, the use of the OpenMP coordination protocol in hybrid applications
can transform a safe point into an unsafe one. This is the case of the example code in Figure 2a,
in which MPI communications are performed by the master threads of each process. Supposing
a checkpointing frequency of 4 (a checkpoint ﬁle will be generated every four checkpoint calls),
it is possible to reach the situation shown in Figure 2b, in which the fastest thread in the
team forces the other ones to take a checkpoint, breaking the spatial coordination among
the diﬀerent teams of threads. In this case, if the application is recovered from checkpoint
ﬁles in recovery line RL1, the master thread of process 0 will expect to receive a message from
22

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

(b) Coordination protocol for OpenMP applications is not
adequate.

(a) Example code.

(c) New coordination protocol for hybrid applications.

Figure 2: New coordination protocol for hybrid MPI-OpenMP applications.

Figure 3: CPPC on hybrid MPI-OpenMP applications: coordinated checkpointing across
OpenMP threads and uncoordinated across MPI processes.

process 1 that will never be sent, leading to an inconsistent global state. Therefore, to guarantee
global consistency when checkpointing hybrid MPI-OpenMP applications, a new coordination
protocol is implemented. In this protocol, instead of bringing forward the checkpointing by
the fastest thread in the team, it is postponed. When the fastest thread determines that a
checkpoint ﬁle must be generated, it waits within the CPPC Do checkpoint() routine until
all other threads in the same team also determine that a checkpoint ﬁle must be generated,
according to the checkpointing frequency (as shown in Figure 2c). Therefore, the proposed
solution, as illustrated in Figure 3, applies a coordinated checkpointing among the threads in
the same OpenMP team, while an uncoordinated checkpointing is applied between diﬀerent
23

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

teams of threads. This strategy may appear costly for those applications in which the threads
from the same team run asynchronously, because of the stalls in the fastest threads when
checkpointing. However, in many occasions these stalls will not introduce extra overhead in the
application, as they only bring forward further synchronizations in the execution.
This proposal enhances the portability features of CPPC. Not only applications can be
restarted in machines with diﬀerent architectures and/or operating systems, but also this approach allows building adaptable applications. Thanks to the application-level checkpointing
and the portability of the state ﬁles, the restart process can adapt the number of OpenMP
running threads for the best exploitation of the available resources. The CPPC instrumentation only maintains the original number of OpenMP threads in the parallel region in which
the checkpoint ﬁles were generated (necessary for the recovery of the application state), while
further parallel regions run with the updated number of OpenMP threads. This feature will
be specially useful on heterogeneous clusters, allowing the adaptation of the application to the
available resources.

4

Experimental evaluation

The experimental evaluation of the proposed solution with hybrid MPI-OpenMP applications
was performed at CESGA (Galicia Supercomputing Center, Spain) in the FinisTerrae-II supercomputer, comprised of nodes with two Intel Xeon E5-2680 v3 @ 2.50GHz processors, with
12 cores per processor and 128 GB of RAM, interconnected to an InﬁniBand FDR 56Gb/s.
The experiments were run spawning one MPI process per node and a team of 24 OpenMP
threads per MPI process, therefore, using one thread per core. Tests were performed storing
the checkpoint ﬁles in remote disk (using Lustre over InﬁniBand) or in the local storage of the
nodes (1TB SATA3 disk). OpenMPI v1.10.1 and GNU compilers v5.3 were used. Applications
were compiled with optimization level O3. The average runtimes of 5 executions are reported
(the standard deviation is always below 3.5% of the original runtimes).
The application testbed used is comprised of two diﬀerent programs. The ASC Sequoia
Benchmark SPhot [2] is a physics package that implements a Monte Carlo Scalar PHOTon
transport code. It was run setting the parameter NRUNS to 3 × 216 . SNAP is a proxy application
from the NERSC-8/Trinity benchmarks [12] to model the performance of a modern discrete
ordinates neutral particle transport application. SNAP was run processing 219 cells, 32 groups
and 400 angles.
Figure 4 presents the runtimes without checkpointing (but including the instrumentation
overhead) and the runtimes when generating a checkpoint ﬁle in the remote and in the local disk
of the nodes for diﬀerent number of cores. The aggregated checkpoint ﬁle sizes (the addition of
the checkpoint ﬁle sizes of each thread) are also represented in the ﬁgure. In the experiments
generating a checkpoint ﬁle, the checkpointing frequency is set for each application so that only
one checkpoint ﬁle is generated when the 75% of the computation is completed. Note that
the multithreaded dumping implemented by CPPC is being used, thus, the checkpointed data
is dumped to disk in background. Both the instrumentation and checkpointing overheads are
low. The instrumentation overhead is always below 0.7%. The maximum relative checkpointing
overhead is 1.1% when checkpointing in the remote disk, and 0.8% when using the local storage.
Figure 5 shows the average and standard deviation of the absolute overheads (in seconds),
that is, the diﬀerence between the original parallel runtimes and the parallel runtimes of each
scenario presented in Figure 4. Note that, when increasing the number of cores, the overheads
do not increase and the variability of the results decreases. This proves the scalability of the
proposal, which applies a massively parallel checkpointing at software and hardware level: a
24

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

Figure 4: Runtimes for the testbed applications varying the number of cores.

Figure 5: Absolute overheads varying the number of cores.

large number of threads checkpoint small contexts and checkpointing is now spread over several
processors/nodes/networks/switches/disks. In some experiments, the overhead takes negative
values. The CPPC instrumentation modiﬁes the application code, thus, the optimizations
applied by the compiler (and their beneﬁt) may diﬀer.
Figure 6 presents the times of the CPPC operations performed when checkpointing: the
coordination protocol, the checkpoint preparation, and the background dumping. Firstly, the
coordination protocol times measure the time spent by the synchronization between the threads
created by each process to guarantee checkpoint consistency, and they are highly tight to the
applications. For SNAP these times are negligible. On the other hand, tests using a small
number of processes in SPhot show higher protocol times, due to the synchronization patterns
between threads used in this application. However, note that threads in hybrid MPI-OpenMP
applications present synchronizations at some point of their execution. In SPhot, the coordination protocol brings forward synchronizations already present in the original application code,
and therefore, protocol time is not translated into overhead. Moreover, in this application, the
synchronization times decrease as more cores are used because the distribution of work among
the processes and threads is more balanced when scaling out. Secondly, the checkpoint prepa25

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

Figure 6: CPPC operation times varying the number of cores.

ration disposes the checkpointed data for its dumping to disk, including the copy in memory
of the data and the creation of the auxiliary threads for the data background dumping. The
checkpoint preparation times are consistent with the checkpoint ﬁles sizes. For SPhot, the
aggregated checkpoint ﬁle size increases with the number of processes because the checkpoint
ﬁle size of each individual process is constant, no matter how many processes run the application. Thus, the checkpoint preparation times remains constant for SPhot. On the other hand,
for SNAP, the application data is distributed among the processes. As such, the aggregated
checkpoint ﬁle size remains almost constant, and each individual checkpoint ﬁle size decreases
as more processes run the application. Therefore, the checkpoint preparation times for SNAP
decrease with the number of processes, as each one of them manages less data. Finally, the
checkpointed data is dumped to disk in background by the auxiliary threads. The background
dumping times are also explained by the checkpoint ﬁle sizes. The use of the multithreaded
dumping implemented by CPPC contributes to hide almost completely these dumping times.
With regard to the restart times, Figure 7 shows the reading and reconstructing times
when restarting from the checkpoint ﬁles generated previously. The reading phase includes
identifying the most recent valid recovery line and reading the checkpoint data into memory.
The reconstructing phase includes all the necessary operations to restore the application state
and to position the application control ﬂow in the point in which the checkpoint ﬁles were
generated. Both reading and reconstructing times depend on the aggregated checkpoint ﬁle
size. For SPhot, the aggregated checkpoint ﬁle size increases with the number of processes, and
thus both the reading and reconstructing times slightly increase as more processes execute the
applications. On the other hand, the aggregated checkpoint ﬁle size for SNAP remains almost
constant when varying the number of running processes. Thus, as more processes are used,
reading and reconstructing times decrease.
Note that the reconstructing times for SPhot are similar, even lager in some cases, to those
of SNAP. However, the aggregated checkpoint ﬁle sizes in these applications present relevant
diﬀerences. These results are explained by the use of the zero-blocks exclusion technique [4].
This technique avoids the dumping to disk of the memory blocks containing only zeros. However,
upon restart, these zero-blocks must be rebuilt. In SPhot, the zero-blocks exclusion technique
reduces the aggregated checkpoint ﬁle size from several tens of gigabytes to less than 3 GB.
Therefore, the reconstructing times are higher because of the reconstruction of the zero-blocks.
26

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

Figure 7: Restart times for the testbed applications, varying the number of cores.

HARDWARE PLATFORM DETAILS
NODES #0 (16CORES)

2x Intel E5-2660
2.20GHz, 8 cores, 64GB memory
NODES #1 (6CORES)

1x Intel X5650 Westmere-EP
2.66, 6 cores, 12GB memory

Figure 8: Restart times varying the computation nodes.

4.1

Portability beneﬁts

The independence between the CPPC checkpoint ﬁles and the MPI or OpenMP implementation,
the operating system, and the machine architecture allows for restarting the execution on
diﬀerent machines. Furthermore, the application-level approach, enables hybrid MPI-OpenMP
applications to be restarted varying the number of threads per process for the best exploitation
of the available resources. CPPC only maintains the original number of threads during the
reading and reconstructing phases, i.e., in the parallel region in which the checkpoint ﬁles
were generated. On heterogeneous clusters, applications can be started in the available set of
resources, to later continue their execution using a more appropriate or powerful set of resources.
The experimental study of the restart on diﬀerent machines was carried out in a heterogeneous system. Figure 8 presents the computation nodes used and the restart runtimes in both
conﬁgurations. Tests were performed using the optimal number of threads for each compute
node (as many threads as cores) and the maximum number of nodes available, i.e., 4 computation nodes. The checkpoint ﬁles used for restarting were generated on NODES#1 when the
75% of the computation was completed in an NFS mounted directory. The restart runtimes
include the full restart execution, that is, the restart process (reading and reconstructing the
application state), and the computation from the restart point to the end (the 25% of the total
execution in these experiments). SPhot was run setting the parameter NRUNS to 214 and
27

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

SNAP processing 215 cells, 24 groups and 192 angles. For SPhot, restarting in NODES#0 instead
of using NODES#1 shows an improvement of 7.5%. This improvement is low because most of the
computation in this application is performed within the parallel region in which the checkpoint
is located, and thus CPPC maintains the original number of threads in that parallel region.
However, this is not the case for SNAP, which can be fully adapted to the restart nodes and
presents an improvement of 43% when changing from NODES#1 to NODES#0.

5

Concluding remarks

This paper presents the extension of the CPPC checkpointing tool to cope with hybrid MPIOpenMP applications in supercomputing clusters. The proposal provides a general applicationlevel checkpointing approach for hybrid codes. Checkpoint consistency is guaranteed by using
an intra-node coordination protocol, while inter-node coordination is avoided by performing an
static analysis of communications. The experimental evaluation, using up to 6144 cores, shows
the scalability of the proposed approach with a negligible instrumentation overhead (<0.7%),
and a low checkpointing overhead (below 1.1% when checkpointing in an remote disk and less
than 0.8% when using the local storage of the computation nodes). The restart experiments
using a diﬀerent system architecture with a diﬀerent number of cores conﬁrm the portability
and adaptability of the proposal. This characteristic will allow to improve the use of available
resources in heterogeneous cluster supercomputers.

Acknowledgements
This work has been supported by the Ministry of Economy and Competitiveness of Spain and
FEDER funds of the EU (project TIN2013-42148-P and predoctoral grant of Nuria Losada
ref. BES-2014-068066) and by the Galician Government (Xunta de Galicia) under the Consolidation Program of Competitive Research Units, cofunded by FEDER funds of the EU (Ref.
GRC2013/055). We gratefully thank CESGA (Galicia Supercomputing Center, Santiago de
Compostela, Spain) for providing access to the FinisTerrae-II supercomputer.

References
[1] J. Ansel, K. Arya, and G. Cooperman. DMTCP: Transparent Checkpointing for Cluster Computations and the Desktop. In Proceedings of the 23rd IEEE International Parallel and Distributed
Processing Symposium, pages 1–12, 2009.
[2] ASC Sequoia Benchmark Codes: https://asc.llnl.gov/sequoia/benchmarks/. Last accessed: March
2016.
[3] G. Bronevetsky, D. Marques, K. Pingali, P. Szwed, and M. Schulz. Application-level Checkpointing
for Shared Memory Programs. In Proceedings of the 11th International Conference on Architectural
Support for Programming Languages and Operating Systems, pages 235–247, 2004.
[4] I. Cores, G. Rodr´ıguez, M. J. Mart´ın, P. Gonz´
alez, and R. R. Osorio. Improving Scalability of
Application-Level Checkpoint-Recovery by Reducing Checkpoint Sizes. New Generation Computing, 31(3):163–185, 2013.
[5] P. H. Hargrove and J. C. Duell. Berkeley Lab Checkpoint/Restart (BCLR) for Linux Clusters. In
Journal of Physics: Conference Series, volume 46, page 494, 2006.
[6] HDF5 website: http://www.hdfgroup.org/HDF5/. Last accessed: March 2016.

28

Portable ALC for Hybrid MPI-OpenMP Applications

Losada, Mart´ın, Rodr´ıguez and Gonz´
alez

[7] H. Jin, D. Jespersen, P. Mehrotra, R. Biswas, L. Huang, and B. Chapman. High Performance
Computing using MPI and OpenMP on Multi-core Parallel Systems. Parallel Computing, 37(9):562
– 575, 2011.
[8] C.-C. J. Li and W. K. Fuchs. CATCH – Compiler-Assisted Techniques for Checkpointing. In
Proceedings of the 20th Annual International Symposium on Fault–Tolerant Computing, pages
74–81, 1990.
[9] N. Losada, M. J. Mart´ın, G. Rodr´ıguez, and P. Gonz´
alez. Extending an Application-Level Checkpointing Tool to Provide Fault Tolerance Support to OpenMP Applications. Journal of Universal
Computer Science, 20(9):1352–1372, 2014.
[10] N. Losada, M. J. Mart´ın, G. Rodr´ıguez, and P. Gonz´
alez. I/O Optimization in the Checkpointing
of OpenMP Parallel Applications. In Proceedings of the 23rd Euromicro International Conference
on Parallel, Distributed and Network-Based Processing, pages 222–229, 2015.
[11] T. Martsinkevich, O. Subasi, O. Unsal, F. Cappello, and J. Labarta. Fault-Tolerant Protocol for
Hybrid Task-Parallel Message-Passing Applications. In IEEE International Conference on Cluster
Computing, pages 563–570, 2015.
[12] NERSC-8 / Trinity Benchmarks website:
https://www.nersc.gov/users/computationalsystems/cori/nersc-8-procurement/trinity-nersc-8-rfp/nersc-8-trinity-benchmarks/. Last accessed:
March 2016.
[13] OpenMP website: http://openmp.org/. Last accessed: March 2016.
[14] J. S. Plank, M. Beck, and G. Kingsley. Compiler-Assisted Memory Exclusion for Fast Checkpointing. IEEE Technical Committee on Operating Systems and Application Environments, 7(4):10–14,
1995.
[15] R. Rabenseifner, G. Hager, and G. Jost. Hybrid MPI/OpenMP Parallel Programming on Clusters
of Multi-Core SMP Nodes. In 17th Euromicro International Conference on Parallel, Distributed
and Network-based Processing, pages 427–436, 2009.
[16] G. Rodr´ıguez, M. J. Mart´ın, P. Gonz´
alez, and J. Touri˜
no. A Heuristic Approach for the Automatic
Insertion of Checkpoints in Message-Passing Codes. Journal of Universal Computer Science,
15(14):2894–2911, 2009.
[17] R. Thakur, P. Balaji, D. Buntinas, D. Goodell, W. Gropp, T. Hoeﬂer, S. Kumar, E. Lusk, and
J. L. Tr¨
aﬀ. MPI at Exascale. Proceedings of Scientiﬁc Discovery through Advanced Computing, 2,
2010.
[18] D. W. Walker and J. J. Dongarra. MPI: a Standard Message Passing Interface. Supercomputer,
12:56–68, 1996.

29

