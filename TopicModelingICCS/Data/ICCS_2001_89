PC-Based System for Calibration, Reconstruction,
Processing, and Visualization of 3D Ultrasound Data
Based on a Magnetic-Field Position and Orientation
Sensing System
Emad Boctor1, 2, A. Saad2, Dar-Jen Chang2, K. Kamel2, and A. M. Youssef1
1

Biomedical Engineering Department, Cairo University Cairo, Egypt
eboctor@ieee.org
2
CECS Department, University of Louisville KY, USA
{eboctor, ashraf, kamel, chang}@louisville.edu

Abstract. 3D-ultrasound can become a new, fast, non-radiative, noninvasive, and inexpensive tomographic medical imaging technique with
unique advantages for the localization of vessels and tumors in soft tissue
(spleen, kidneys, liver, breast etc.). In general, unlike the usual 2Dultrasound, in the 3D-case a complete volume is covered with a whole
series of cuts, which would enable a 3D reconstruction and visualization.
In the last two decades, many researchers have attempted to produce
systems that would allow the construction and visualization of threedimensional (3-D) images from ultrasound data. There is a general
agreement that this development represents a positive step forward in
medical imaging, and clinical applications have been suggested in many
different areas. However, it is clear that 3-D ultrasound has not yet gained
widespread clinical acceptance, and that there are still important problems
to solve before it becomes a common tool.

1. Introduction
Conventional diagnostic ultrasound imaging is performed with a hand-held probe,
which transmits ultrasound pulses into the body and receives the echoes. The
magnitude and timing of the echoes are used to create a 2D gray scale image (B-scan)
of a cross-section of the body in the scan plane.
Conventional freehand 3D ultrasound is a multi-stage process [1, 2, 3]. First,
the clinician scans the anatomical organ of interest. Next, the ultrasound data is used
to construct a 3D voxel array, which can then be visualized by, for example, arbitraryplane slicing. A 3D freehand examination can be broken into three stages: scanning,
reconstruction and visualization.

V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2074, pp. 13–22, 2001.
© Springer-Verlag Berlin Heidelberg 2001

14

E. Boctor et al.

Before scanning, some sort of position sensor is attached to the probe. This is
typically the receiver of an electromagnetic position sensor [4, 5, 6, 7, 8], as
illustrated in Figure 1, although alternatives include acoustic spark gaps [9],
mechanical arms [10] and optical sensors [11, 12]. Measurements from the
electromagnetic position sensor are used to determine the positions and orientations of
the B-scans with respect to a fixed datum, usually the transmitter of the
electromagnetic position sensor.
In the next stage, the set of acquired B-scans and their relative positions are
used to fill a regular voxel array. Finally, this voxel array is visualized using, for
example, arbitrary-plane slicing, volume rendering or surface rendering (after 3D
segmentation).
Freehand systems can be used to obtain arbitrary volumes of data, since the
motion of the ultrasound probe is unconstrained. They are also cheap, requiring only
existing, conventional ultrasound systems and relatively inexpensive additional
components. For these reasons, research into freehand systems is very active.
1.1 Advantages of 3D Ultrasound System Over Conventional 2D Ultrasound
There will be many advantages for developing 3D Ultrasound systems in comparison
with usual 2D-imaging some of the suggested advantages are:
- The conventional 2D Ultrasound exam is subjective, i.e. it depends on the
experience and knowledge of the diagnostician to manipulate the ultrasound
transducer, mentally transform the 2D images into 3D tissue structures and make the
diagnosis. While 3D Ultrasound systems will standardize the diagnosis procedure and
minimize the dependence on diagnostician experience.
- 2D Ultrasound-guided therapeutic procedures are particularly affected because the
process of quantifying and monitoring small changes during the procedure or over the
course of time is severely limited by the 2D restrictions of the conventional exam.
This practice is time consuming and inefficient and may lead to incorrect decisions
regarding diagnosis and staging, and during surgery. The goal of 3D Ultrasound
imaging is to provide an imaging technique that reduces the variability of the
conventional technique, and it seems to play an important role in surgical planning.
- It is difficult to localize the thin 2D Ultrasound image plane in the organ, and
difficult to reproduce a particular image location at a later time making the
conventional 2D exam a poor modality for quantitative prospective or follow-up
studies, while 3D Ultrasound imaging modality will overcome these restrictions.
- In 2D Ultrasound imaging calculating distances and volumes depends on formulas
that approximate the body organs to regular geometrical shapes and also depends on
the 2D view that the sonographer calculates the needed distance or volume for a more
accurate measurement of distances and volumes.
- Sometimes patient’s anatomy or orientation restricts the image angle, resulting in
inaccessibility of the optimal image plane necessary for diagnosis. 3D Ultrasound
imaging will facilitate an arbitrary selection of a cutting plane and the possibility of
reconstructing a 3D-image from the data with several visualization tools.

PC-Based System for Calibration, Reconstruction, Processing, and Visualization

15

Fig. 1: Conventional freehand 3D ultrasound imaging. This is a multi-stage process, involving
scanning, reconstruction and visualization. The figure illustrates an examination of a gall
bladder
1.2 3D Ultrasound vs. Other 3D Imaging Modalities: MRI, CT
Recently, tomographic techniques such as CT, MRI, nuclear medicine, etc.,
experienced a breakthrough in several domains of diagnostic medical imaging.
3D ultrasound tomography is probably one of the most interesting
applications within this area. Several attempts in the past have shown that 3Dultrasound images usually cannot be volume rendered as a 3D-model by using
methods known from CT and MRI datasets. The main difficulties originate in:
- The significant amount of noise and speckle in Ultrasound images.
- The regions representing boundaries are not sharp but show a width of several
pixels.
- Intensity fluctuations resulting from surface curvature and orientation.
- Self-shadowing of deeper structures.
But in order to gain acceptance, 3-D ultrasound must have clear advantages
over the other imaging modalities, e.g. computed x-ray tomography (CT), magnetic
resonance imaging (MRI), positron emission tomography (PET) or conventional Bmode and Doppler 2D ultrasound. The main advantages that have been suggested for
3D ultrasound can be grouped into five categories: 1. Ultrasound is a real time imaging modality, and 3D Ultrasound has the potential for
displaying information in near real time too.
2. Extension of ultrasound to 3D provides new images, which would be impossible to
visualize otherwise.
3. The reconstruction of 3D Ultrasound by computer potentially brings greater
standardization and repeatability to conventional examinations.

16

E. Boctor et al.

2. Current State of Knowledge and Different Schools of 3D
Ultrasound Research
Various forms of 3D ultrasound echography have been developed in the past. Among
recent examples, several companies, including Tomographic Technologies, Inc. and
Acoustic Imaging, Inc., have been working to bring commercial products to market.
They acquire 3D echography images by mechanically moving 2D echography slices
over periods of seconds to minutes. They then visualize the acquired datasets using
volume visualization and other visualization methods.
A real-time 3D ultrasound echography acquisition system is coming close to
reality. At Duke University, a prototype, which employs such a parallel processing
technique for a real-time 3D echography acquisition system, has been developed[35,
36].
Until now, too many universities and institutes have been working in 3D
Ultrasound research area but the most powerful and promising systems exist in the
following universities: - University of Cambridge, Department of Engineering: This team has developed
“Stradx freehand 3D Ultrasound system” [20]. The most important features of this
system are: Acquisition System: they use electromagnetic position sensors attached to the
conventional ultrasound probe to label each B-scan image with its relative position
and orientation, Stradx system is characterized in its well-calibrated acquisition
system [15, 16]. Stradx uses a novel, state-of-the-art spatial calibration technique [17].
Visualization Tools: Stradx provides two visualization tools, both of which are
available immediately after the data has been acquired, without having to wait for a
voxel array to be constructed.
- University of North Carolina at Chapel Hill, Department of computer science: The
team at North Carolina has been concentrating on two areas:
I- Real-time 3D ultrasound system: they have been working toward an ultimate 3D
ultrasound system, which acquires and displays 3D volume data in real time [21].
Real-time display can be crucial for applications such as cardiac diagnosis, which
need to detect certain kinetic features.
II- Augmented reality systems: with see-through head-mounted displays. They
explored possibilities for in-place, real-time 3D ultrasound visualization.
- Fraunhofer Institute for Computer Graphics, Germany: The team there developed
the first commercial 3D Ultrasound visualization package “In ViVo”. It’s an
interactive system for the fast visualization of 3D Ultrasound datasets on generalpurpose platforms [22]. “In ViVo” supports many visualization tools like:
� Iso-surfaces
� Contour wire frames
� Gradient shading
� Semi-transparent gels
� Max. Intensity projections
� Oblique cuts

PC-Based System for Calibration, Reconstruction, Processing, and Visualization

17

3. Our Proposed Free Hand 3D Ultrasound System
We started our research in 3D Ultrasound imaging about 3 years ago. At the first
stage we made a survey over nearly all the existing schools working in 3D
Ultrasound, we recognize that 3D Ultrasound system is a multi-phase system starts
with choosing the hardware suitable for the intended application and ends with the
best visualization technique that fits the required target see Figure 3. We found that
every research group in this field concentrates on some areas but none of them intends
to achieve a whole system for 3D Ultrasound imaging that is suitable to be clinically
applied, every school has its own points of power and also has some lag in some
phases, for example at UNC Chapel Hill they concentrate to build the whole system
for augmented reality environment but they are not concerning with construction and
visualization techniques for this system, also at Cambridge University they applied
the simplest visualization methods although they have the best calibrated acquisition
system for 3D Ultrasound.

Fig. 3: 3D Ultrasound different systems, Data processing and display
The cost and flexibility of free-hand imaging ensure that it will remain a
popular choice for 3D Ultrasound systems. For these reasons, we decided to focus on

18

E. Boctor et al.

building the infrastructure for a free-hand 3D Ultrasound system. In the next section
we will discuss the infrastructure we built in details to indicate the current state of our
project.
3.1 Infrastructure Prototype for 3D Ultrasound System
Hardware Setup: The following is a list of hardware components that constitute our
prototype free hand 3D Ultrasound system:
1- Pentium 200 MHz PC with 128 Mbytes RAM, 4 GBytes SCSI Hard Disk.
2- An electromagnetic position tracker “miniBIRD”, see Figure 4, that is a six degree
of freedom measuring device that is used to measure the position and orientation of a
small receiver with respect to a transmitter.
3 - A digitizer card “Matrox Card” which is real time frame grabber capable of
virtually capturing 25 frames/sec.

Fig. 4: a system block diagram (left) and miniBIRD electromagnetic position tracker (right)
Operating Platform: We developed our system under “Windows NT” platform,
which seems to be a promising choice for the future to develop a system working on a
PC under Windows Operating System.
Acquisition System: The first step in the project was to implement a real time
acquisition system to capture a set of randomly oriented images guided by their
orientation data acquired from the spatial locator. To achieve these goals we followed
the next steps:
1- we manufactured a plastic holder that fits over the probe of the ultrasound machine
and has a holding position for the receiver of the spatial locator. Some precautions
had to be taken as:
-The material of the holder was chosen so that it would not affect the
performance of the spatial locator i.e. it should contain no conducting
materials.

PC-Based System for Calibration, Reconstruction, Processing, and Visualization

19

- The design should not obstacle the free hand movement of the ultrasound
probe as the physician was used before.
- The local axes of the receiver should not be in a special orientation with the
local axis of the 2D ultrasound image like a perpendicular or parallel case,
this condition is necessary for proper calibration of the spatial locator as will
be indicated later.
- When removing the holder and reinstalling it again over the probe it
should stay in the same location, this condition is also necessary for
proper calibration of the spatial locator as will be indicated later.
2 - A key requirement of all free-hand imaging systems is the calibration of the spatial
locator, there are two sources of errors in the readings of the electromagnetic tracker
that should be taken into account to improve the registration of the free hand 2D
slices.
- The first error in the readings comes from the effect of the proximity of
metallic objects and induced noise from power cables exist in the ultrasound
clinic’s environment, we applied a look-up table technique to calibrate both
position and orientation readings.
- The second error originates from the fact that the readings representing the
position and orientation of the receiver’s center relative to the center of the
transmitter (reference point) are not the actual readings that we need, which
are the readings representing the position and orientation of the corner of the
B-scans relative to the center of the transmitter.
A typical calibration process, which often needs repeating every time a sensor is
mounted on a probe, takes several hours for a skilled technician to perform. At
Cambridge University, they presented a novel calibration technique which can be
performed in a few minutes with a very good accuracy, but they invent a special
phantom for this purpose which will add cost to the system and would not be
available everywhere. We applied a novel technique to calibrate the spatial locator in
a few minutes with a very good accuracy, but we used a very popular phantom for
that purpose, which is the “AIUM Tissue Cyst Phantom”.
Our technique is based on imaging the phantom from several orientations
then entering this images into a program that automatically detect the coordinates of
the phantom reflectors, this program was implemented by the authors in a previous
project concerning calibration of ultrasound machines [18, 19].
3 - After performing the spatial locator calibration, we implemented the acquisition
phase of the program that interfaces the digitizer card and the locator (via the serial
interface) to the PC. A time synchronization process has been developed to achieve a
minimal delay between the acquired 2D- ultrasound images and the associated
orientation data.
Compounding and Reconstruction Techniques: The acquired B-images are
randomly oriented so we applied a compounding technique that fits the images into an
empty volume of voxels, the resolution of the voxel dataset could be changed upon
user interface, then we applied different reconstruction techniques that translate the
irregular voxel volume into a regular one, that is suitable for visualization algorithms.
The reconstruction algorithms, we chose, have the following properties:

20

E. Boctor et al.

1- they are local so that their computational cost can be bounded,
2- they produce approximations (not interpolations) so that the noise in
samples can be suppressed,
3- they produce smooth approximation results, so that the visualization
results are also smooth without noisy artifacts,
4- they are insensitive to the order in which the samples arrive, so that the
reconstruction results of identical objects are identical regardless of different
paths of sweep upon acquisition.
Image Processing Library: Due to the speckle nature of ultrasound images, the
visualization techniques that are valid for CT and MRI cannot be directly applied to
3D Ultrasound datasets. Image preprocessing algorithms should be applied first to the
reconstructed datasets before visualization. While implementing this phase we put in
our mind some goals to achieve:
- The main target of applying image processing routines is to suppress noise
and speckle in the volume in conjunction with preserving the edges of the
target organ.
- The applied algorithms should be very fast to achieve the global
requirement of implementing an interactive system suitable for routine
clinical times.
- These algorithms should not alter the dimensions and shape of the organs
so that a quantitative analysis could be performed later on the volume.
- These algorithms should be applied to 3D volumes, not repeatedly applied
to a
set of 2D images, so that continuity is achieved in all the three
dimensions.
Visualization Techniques: We have implemented some visualization techniques as
follows:
- We have implemented "Z shading" technique to visualize iso-valued surfaces
after performing filtering algorithms necessary for depicting meaningful isovalued surfaces from ultrasound data. Figure 6 shows a rendered scene using "Z
shading" for the gall bladder of one of the authors. The main drawback of this
method is its limitation for imaging particular structures.
- After that we took the direction of "Volume Rendering", We implemented a
Volume Rendering pipeline using "Voxelator Library" which is a prototype
volume rendering software as an extension to the OpenGL library. Figure 6
shows a screen of a rendered image by Voxelator library. The main drawback of
using OpenGL library for volume rendering is the time consumed to update the
rendered scene.
- Finally we have implemented a fast volume rendering technique, developed by
Philippe Lacroute at Stanford University. This technique uses a Shear-Warp
Factorization of the viewing transformation to accelerate the rendering process.
Figure 6 shows a rendered scene for the hepatic veins belonging to one of the
authors using this technique.

PC-Based System for Calibration, Reconstruction, Processing, and Visualization

a

b

c

d

e

21

f

Fig. 6: From the left: Z shading using iso-surfaces for the Gall Bladder of One of the authors a)
Without Image Processing. b) With Image Processing. c) Volume rendered scene for the
forehead part of a fetus using OpenGL Library. d) A cross section of the forehead of the fetus.
e) and f) Two different views of volume rendered Hepatic veins of the author Using Fast
Volume Rendering Algorithm.

4. Conclusion
In this paper, we have developed a prototype free-hand 3D ultrasound system that is
capable of acquiring, constructing, and visualizing 3D ultrasound data sets. The main
goal was to achieve high quality rendered images for anatomical structures within a
reasonable time compared to the conventional ultrasound diagnostic time. The future
research directions of the authors will be targeted on extracting useful quantitative
information from the acquired 3D data, which could include 3D segmentation techniques
and voxel classification methods.

References
[1] J. Deng, J. E. Gardener, C. H. Rodeck, and W. R. Lees. Fetal echocardiography in 3dimensions and 4-dimensions. Ultrasound in Medicine and Biology, 22(8):979--986, 1996.
[2] R. N. Rankin, A. Fenster, D. Downey, P. L. Munk, M. F. Levin, and A. D. Vellet. Threedimensional sonographic reconstruction: techniques and diagnostic applications. American J. of
Roentgenology, 161(4):695-702, 1993.
[3] H. Steiner, A. Staudach, D. Spitzer, and H. Schaffer. Three-dimensional ultrasound in
obstetrics and gynaecology: technique, possibilities and limitations. Human Reproduction,
9(9):1773--1778, 1994.
[4] C. Barry, C. Allot, N. John, P. M. Mellor, P. Arundel, D. Thomson, and J. C. Waterton.
Three-dimensional freehand ultrasound: Image reconstruction and volume analysis. Ultrasound
in Medicine and Biology, 23(8):1209--1224, 1997.
[5] P. R. Detmer, G. Bashein, T. Hodges, K. W. Beach, E. P. Filer, D. H. Burns, and D.E.
Strandness Jr. 3D ultrasonic image feature localization based on magnetic scan- head tracking:
in vitro calibration and validation. Ultrasound in Medicine and Biology, 20(9):923--936, 1994.
[6] S. W. Hughes, T. J. D’Arcy, D. J. Maxwell, W. Chiu, A. Milner, J. E. Saunders, and R. J.
Sheppard. Volume estimation from multiplanar 2D ultrasound images using a remote
electromagnetic position and orientation sensor. Ultrasound in Medicine and Biology,
22(5):561--572, 1996.
[7] D. F. Leotta, P. R. Detmer, and R. W. Martin. Performance of a miniature magnetic position
sensor for three-dimensional ultrasound imaging. Ultrasound in Medicine and Biology,
24(4):597--609, 1997.
[8] T. R. Nelson and T. T. Elvins. Visualization of 3D ultrasound data. IEEE Computer
Graphics and Applications, pages 50--57, November 1993.

22

E. Boctor et al.

[9] D. L. King, D. L. King Jr., and M. Y. Shao. Evaluation of in vitro measurement accuracy of
a three-dimensional ultrasound scanner. Journal of Ultrasound in Medicine, 10:77--82, 1991.
[10] R. Ohbuchi, D. Chen, and H. Fuchs. Incremental volume reconstruction and rendering for
3D ultrasound imaging. Proceedings of SPIE --- The International Society for Optical
Engineering, pages 312--323, 1992.
[11] A. State, D. T. Chen, C. Tector, A. Brandt, H. Chen, R. Ohbuchi, M. Bajura, and H. Fuchs.
Case study: Observing a volume rendered fetus within a pregnant patient. In Proc. IEEE
Visualization, 1994, pages 364--368, 1994.
[12] J. W. Trobaugh, D. J. Trobaugh, and W. D. Richard. Three-dimensional imaging with
stereotactic ultrasonography. Computerized Medical Imaging and Graphics, 18(5):315-- 323,
1994.
[13] Shattuck, D. P., Weishenker, M.D., Smith, S.W., and von Ramm, O.T. ‘‘Explososcan: A
Parallel Processing Technique for High Speed Ultrasound Imaging with Linear Phased Arrays.’’
JASA. 75(4): 1273-1282.
[14] Smith, S. W., Pavy, Jr., S.G., and von Ramm, O.T.‘‘High-Speed Ultrasound Volumetric
Imaging System - Part I: Transducer Design and Beam Steering.’’ IEEE Transaction on
Ultrasonics, Ferro., and Freq. Control. 38(2): 100-108.
[15] P. R. Detmer, G. Bashein, T. Hodges, K. W. Beach, E. P. Filer, D. H. Burns, and D.E.
Strandness Jr. 3D ultrasonic image feature localization based on magnetic scanhead tracking: in
vitro calibration and validation. Ultrasound in Medicine and Biology, 20(9):923-936, 1994.
[16] D. F. Leotta, P. R. Detmer, and R. W. Martin. Performance of a miniature magnetic
position sensor for three-dimensional ultrasound imaging. Ultrasound in Medicine and Biology,
24(4):597--609, 1997.
[17] R. W. Prager, R. Rohling, A. Gee, and L. Berman. Rapid calibration for 3-D freehand
ultrasound. Ultrasound in Medicine and Biology, in press.
[18] Emad M. Boctor, Ashraf A. Saad, Prof A. M. Youseef, and Prof James Graham
“Heuristic Based Approach For Extracting Calibration Parameters of Ultrasound
Equipment ”, presented in the ISCA International Conference, June 11-13, 1997, Boston,
Massachusetts, USA.
[19] Ashraf A. Saad, Emad M. Boctor and Prof Abo Bakr Youssef(PhD/MD), “Statistical
Based Automated Ultrasound Imaging Quality Control and Procedure ”, presented in the
Fourth IEEE International Conference on Electronics, Circuits, and Systems ICECS’97,
December 15-18, 1997, Cairo, Egypt.
[20] R. W. Prager, A. Gee, and L. Berman. STRADX: Real-Time Acquisition and
Visualization of Free-Hand 3D Ultrasound CUED/F-INFENG/TR 319, Cambridge University
Department of Engineering, April 1998.
[21] R. Ohbuchi, D. Chen, and H. Fuchs. Incremental volume reconstruction and rendering for
3D ultrasound imaging. Proceedings of SPIE - The International Society for Optical
Engineering, 1808:312-323, 1992.
[22] G. Sakas, L-A. Schreyer, and M. Grimm. Preprocessing and volume rendering of 3D
ultrasonic data. IEEE Computer Graphics and Applications, 15(4):47--54, July 1995.

