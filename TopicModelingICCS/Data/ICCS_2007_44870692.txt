An Extended R-Tree Indexing Method
Using Selective Prefetching in Main Memory
Hong-Koo Kang, Joung-Joon Kim, Dong-Oh Kim, and Ki-Joon Han
School of Computer Science & Engineering, Konkuk University,
1, Hwayang-Dong, Gwangjin-Gu, Seoul 143-701, Korea
{hkkang,jjkim9,dokim,kjhan}@db.konkuk.ac.kr

Abstract. Recently, researches have been performed on a general method that
can improve the cache performance of the R-Tree in the main memory to reduce the size of an entry so that a node can store more entries. However, this
method generally requires additional processes to reduce information of entries.
In addition, the cache miss always occurs on moving between a parent node and
a child node. To solve these problems, this paper proposes the SPR-Tree (Selective Prefetching R-Tree), which is an extended R-Tree indexing method using
selective prefetching according to node size in the main memory. The SPR-Tree
can produce wider nodes to optimize prefetching without additional modifications on the R-Tree. Moreover, the SPR-Tree can reduce the cache miss that can
occur in the R-Tree. In our simulation, the search, insert, and delete performance of the SPR-Tree improved up to 40%, 10%, 30% respectively, compared
with the R-Tree.
Keywords: SPR-Tree, Extended R-Tree, Cache Performance, Cache Miss,
Main Memory.

1 Introduction
Recently, with the speed gap being broader between the processor and the main memory, how effectively to use the cache memory in the main memory-based index is
making a critical impact on the performance of the entire system[1,5]. The R-Tree is
similar to the B-Tree, but is used for spatial access methods for indexing multidimensional data[2]. Since the R-Tree is originally designed to reduce disk I/O effectively for the disk-based index, the node size is optimized for disk block.
However, the R-Tree is not suitable for the cache memory with a small block. Delay time caused by cache miss accounts for a significant part of the entire performance time[10]. Especially, when the R-Tree, as in a main memory DBMS, resides in
the main memory, disk I/O does not affects the entire performance seriously. Consequently, studies on the index structure and algorithms with the improved cache performance are being carried out by numerous researchers in many ways[3,5-8].
Rao and Ross pointed out the importance of the cache performance in designing a
main memory index and proposed the CSS-Tree(Cache-Sensitive Search Tree) which
has a faster search performance than the Binary Search Tree or the T-Tree in the
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 692 – 699, 2007.
© Springer-Verlag Berlin Heidelberg 2007

An Extended R-Tree Indexing Method

693

read-only OLAP environment[6]. They also proposed the CSB+-Tree which is an
extension of the CSS-Tree and can improve the cache performance of the B+-Tree[7].
Sitzmann and Stuckey proposed the pR-Tree(partial R-Tree), which adjusts the
size of the R-Tree node to that of cache block and deletes unnecessary information
within MBR(Minimum Bounding Rectangle) to store more information in a node[8].
Kim and Cha proposed the CR-Tree(Cache-conscious R-Tree) which compresses
MBR of an entry to include more entries in a node[3]. The typical approach for cache
performance improvement is to minimize cache misses by reducing the size of the
entry to increase the fanout and storing more entries in a node. But, in this approach,
the update performance is generally lowered due to additional operations to recover
the compressed entry information and cache miss occurring when moving between
nodes still results in the lowered performance of the entire system.
In order to solve the above problems, this paper proposes the SPR-Tree(Selective
Prefetching R-Tree), an extended R-Tree indexing method, which applies the selective prefetching to the R-Tree in the main memory. The SPR-Tree loads the child
node onto the cache memory in advance to extend the size of the node to be optimized
for prefetching without transforming the R-Tree radically and reduce cache misses
occurring when moving between nodes. The performance improvement of the SPRTree using selective prefetching is in proportion to the size and the number of the
nodes to access. Therefore, it is more effective in the range query than in the point
query.
The rest of this paper is organized as follows. Chapter 2 introduces selective prefetching and then analyzes the existing cache conscious index methods. Chapter 3
explains the structure of the SPR-Tree and algorithms for the SPR-Tree. In Chapter 4,
the performance of the SPR-Tree is analyzed and the results of the SPR-Tree evaluation are presented. Finally, the conclusion is provided in Chapter 5.

2 Related Works
This chapter will introduce selective prefetching and analyze the various existing
cache conscious index methods.
2.1 Selective Prefetching
The cache memory is used to provide data to the processor in a fast way. Located
between the main memory and the processor, the cache memory generally consists of
2 layers; L1 cache and L2 cache. L1 cache is located between the register and L2
cache, while L2 cache is located between L1 cache and the main memory[4]. When
the processor is accessing data, if the data is present in the cache memory, it is called
"cache hit" and if the data is not present, it is called "cache miss".
The cache block is the basic transfer unit between the cache memory and the main
memory. The current systems tend to have bigger size of the cache block and largercapacity of the cache memory. Typical cache block size ranges from 32 bytes to 128
bytes. Generally, the data cache follows the basic principle of the data locality. A tree

694

H.-K. Kang et al.

structure has the low data locality as data to refer to is accessed through the pointer.
Therefore, in order to improve the cache performance in the tree structure, the amount
of data to access should be reduced or selective prefetching should be executed.
The selective prefetching is a technique to selectively load data into the cache
memory in advance to accelerate the program execution. Especially, the selective
prefetching can reduce cache misses by loading data which does not exist in the cache
memory before the processor requests it. In order to reduce cache misses in the RTree, the selective prefetching should be used to reduce memory delay occurring
when accessing nodes overall. The selective prefetching is controlled in two ways; the
hardware-based prefetching where the prefetching is automatically carried out by the
processor and the software-based prefetching where a prefetching command is inserted into the program source code[9].
2.2 Cache Conscious Index Methods
The CSB+-Tree is a variant of the B+-Tree, removing all child node pointers except
the first child node pointer to store child nodes consecutively in order to reduce cache
misses in the B+-Tree[7]. But, this method of eliminating pointers is not so effective
in the R-Tree where pointers account for a relatively small part. And since child nodes
are consecutively stored in the CSB+-Tree, every update operation requires reorganization of consecutively arranged child nodes.
The pR-Tree is a variant of the R-Tree, removing child MBR's coordinate values
overlapped with those of parent MBR to reduce cache misses in the R-Tree[8]. This
method also eliminates the pointers, like in the CSB+-Tree, and shows better
performance when the number of entries is small. However, this method has worse
performance as the number of entries increases, since the number of child MBR's
coordinate values overlapped with those of parent MBR is decreased. In addition, due
to the elimination of overlapped child MBR's coordinate values, additional operations
are needed for reorganization of the eliminated coordinate values, which lowers the
update performance.
The CR-Tree is a kind of the R-Tree that compresses MBR, which accounts for
most of indexes, and uses the compressed MBR as a key[3]. In the CR-Tree, MBR is
compressed according to the following procedure; MBR of the child node is represented in relative coordinates to MBR of the parent node and it is quantized so that it
can be represented in definite bits. However while compressing MBR in the CR-Tree,
a small error can occur and this may produce a wrong result(i.e., false hit). Moreover,
additional operations for reorganization of the compressed MBR in the update operation can lower the update performance.

3 SPR-Tree
This chapter will describe the SPR-Tree, a main memory-based R-Tree using selective prefetching. First, the structure and characteristics of the SPR-Tree will be given
and then the algorithms used in the SPR-Tree also will be suggested.

An Extended R-Tree Indexing Method

695

3.1 Structure
The SPR-Tree, similar to the R-Tree, has the root node, the intermediate node, and the
leaf node. All operations on the SPR-Tree start from the root node and the references
to real data objects exist only in the leaf node. Figure 1 illustrates the node structure
of the SPR-Tree. The SPR-Tree uses a rectangle, which is a rectilinear shape that can
completely contain other rectangles or data objects.

Fig. 1. Node Structure of the SPR-Tree

In Figure 1(a), P and N represent the node level and the number of entries in a
node, respectively. Each of E1, E2, … , En (n=3+5k, k 0) represents an entry which
has two types, that is, an entry for the root node or the intermediate node and an entry
for the leaf node. Figure 1(b) shows the entry for the root node or the intermediate
node, where RECT is a rectangle which completely contains all rectangles in the child
node’s entries and p is an address of a child node. Figure 1(c) represents the entry for
the leaf node, where RECT is a rectangle which completely contains a data object and
oid refers to the data object.
Since the SPR-Tree nodes adjust the number of entries suited to the cache block;
the SPR-Tree decides the node size in proportion to the cache block size. Generally,
the cache block size can be 32 or 64 bytes. If the cache block size is 32 bytes, the
node size becomes 64+160k (k 0) bytes and if it is 64 bytes, the node size becomes
64+320k (k 0).
Figure 2 shows an example of the SPR-Tree. As the Figure 2 shows, rectangles can
enclose a single data object or one or more rectangles. For example, rectangle R8,
which is at the leaf level of the SPR-Tree, contains data object O. Rectangle R3,
which is at the intermediate level of the SPR-Tree, contains rectangles R8, R9, and
R13. Rectangle R1, which is at the root level, contains rectangles R3 and R4. In Figure 2, a prefetching node group enclosed by a dotted line is determined according to
the node size.

≥

≥

≥

3.2 Algorithms
This section will describe the search, node split insert, and delete algorithms of the
SPR-Tree in detail.

696

H.-K. Kang et al.

Fig. 2. Example of the SPR-Tree

3.2.1 Insert Algorithm
The insert operation repeats, from the root node down to the leaf node, a process of
using lower node's rectangle information contained in entries of each node to determine whether the size expansion of the node can be minimized or not when an object
is inserted into the leaf node. At this time, if the leaf node becomes full, then a node
split occurs. In the insert algorithm of the SPR-Tree, prefetching is carried out while
looking for the leaf node to insert an entry. Figure 3 shows the insert algorithm of the
SPR-Tree.
3.2.2 Delete Algorithm
The delete operation repeats, from the root node down to the leaf node, a process of
using lower node's rectangle information contained in entries of each node to determine whether a query region is contained or overlapped in the lower nodes. At this
time, if an entry is deleted and the number of remaining entries is below the minimum
number of entries in the leaf node, then the leaf node is deleted and its remaining
entries are reinserted into the SPR-Tree. The delete algorithm of the SPR-Tree uses a
prefetching command based on the node size. The child node to be accessed is prefetched after the current node according to the node size. Figure 4 shows the delete
algorithm of the SPR-Tree.
3.2.3 Search Algorithm
The search operation descends the SPR-Tree from the root node to the leaf node. And,
it repeats a process of using lower node's rectangle information contained in entries of
each node to determine whether the lower node contains or overlaps a query region or
not. If the lower node is contained or overlapped with the query region, the search
operation follows the lower node as the root node until it reaches the leaf node. The
search algorithm of the SPR-Tree uses a prefetch command to prefetch a child node to
be accessed after the current node. If the node has few entries, the SPR-Tree makes a
prefetching node group using some nodes at the same level and prefetches it. While
the node has many entries, it prefetches only a child node to be accessed into the
cache memory. Figure 5 shows the search algorithm of the SPR-Tree.

An Extended R-Tree Indexing Method

Fig. 3. Insert Algorithm

697

Fig. 4. Delete Algorithm

3.2.4 Node Split Algorithm
When a leaf node is full during the execution of an insert operation in the SPR-Tree,
the node split operation must be executed. First, the entries in the node are divided
into two nodes with minimum rectangle expansion. If the number of entries in the
parent node exceeds the maximum number of entries in the parent node due to the
node split, the parent node also must be split. The node split algorithm prefetches the
current node before split and creates two new nodes to distribute the entries of the
current node. Figure 6 shows the node split algorithm of the SPR-Tree.

Fig. 5. Search Algorithm

Fig. 6. Node Split Algorithm

4 Performance Evaluation
The system used in the performance evaluation was equipped with Intel Pentium III
1GHz, 1GB main memory, and L1 and L2 caches whose block size is 32 bytes. As a
test data, we created 10,000 objects, a square with side length of 0.0001 on the average, uniformly distributed in a square with side length of 1 as the whole area.

698

H.-K. Kang et al.

Figure 7 shows the performance results of the search operation. The query region
was supposed to occupy 30%~70% of the whole area. In Figure 7, the SPR-Tree has
better search performance than the R-Tree and improvement through prefetching
appears more consistent, as memory delay is reduced while accessing nodes. The
search performance of the SPR-Tree was improved up to 35% over the R-Tree.
Figure 8 shows the performance results of the search operation in a skewed data
set. As shown in Figure 8, the larger the node size is, the better search performance it
has. This is because there is more reduced memory delay time due to prefetching, as
the spatial objects are skewed, which increases overlapping between nodes and the
number of nodes to access. The search performance of the SPR-Tree was improved
up to 40% over the R-Tree for skewed data set.

Fig. 7. Performance of Search Operations

Fig. 8. Performance of Search Operations in
Skewed Data Set

Figure 9 shows the performance results of the insert operation. The spatial objects
were inserted and the side length of the objects was 0.0001 on the average. As shown
in Figure 9, when the node size is larger, the insert time increases, but we can see that
the performance improvement rate increases due to prefetching. This is because when
prefetching is used, larger node size brings higher performance. The insert performance of the SPR-Tree showed up to 10% improvement over the R-Tree.
Figure 10 shows the performance results of the delete operation. We deleted objects involved in the region whose side length was 0.001 on the average. In Figure 10,
the larger node size generally leads to the better performance of the delete operation
and the performance improvement through prefetching is consistent, as memory delay

Fig. 9. Performance of Insert Operations

Fig. 10. Performance of Delete Operations

An Extended R-Tree Indexing Method

699

time reduced by prefetching is consistent while accessing nodes. In the evaluation, the
delete performance of the SPR-Tree was improved up to 30% over the R-Tree.

5 Conclusion
Recently an approach that can improve the main memory-based R-Tree index structure by reducing the node size was proposed. However, in this approach, the update
performance is lowered due to additional operations to recover the compressed entry
information and, still, cache misses occurring when moving between nodes contributes to the lowered performance of the entire system.
In order to solve the above problems, this paper proposes the SPR-Tree which applies
the selective prefetching to the R-Tree to reduce cache misses as well as eliminate additional cost in the update operation. The SPR-Tree optimizes the node size for prefetching
and minimizes cache misses by prefetching child nodes when moving between nodes. In
the performance evaluation, the SPR-Tree was improved up to 40% in the search operation,
up to 10% in the insert operation, and up to 30% in the delete operation over the R-Tree.

Acknowledgements
This research was supported by the MIC(Ministry of Information and Communication), Korea, under the ITRC(Information Technology Research Center) support
program supervised by the IITA(Institute of Information Technology Assessment).

References
1. Chen, S., Gibbons, P. B., Mowry, T. C., Valentin, G.: Fractal Prefetching B+-Trees : Optimizing Both Cache and Disk Performances. Proceedings of ACM SIGMOD Conference
(2002) 157-168.
2. Guttman, A.: R-Trees: a Dynamic Index Structure for Spatial Searching. Proceedings of
ACM SIGMOD Conference (1984) 47-54.
3. Kim, K. H., Cha, S. K., Kwon, K. J.: Optimizing Multidimensional Index Tree for Main
Memory Access. Proceedings of ACM SIGMOD Conference (2001) 139-150.
4. Mowry, T. C., Lam, M. S., Gupta, A.: Design and Evaluation of a Compiler Algorithm for
Prefetching. Proceedings of International Conference on Architectural Support for Programming Languages and Operating Systems (1992) 62-73.
5. Park, M. S., Lee, S. H.: A Cache Optimized Multidimensional Index in Disk-Based Environments. IEICE Transactions on Information and Systems, Vol.E88-D (2005) 1940-1947.
6. Rao, J., Ross, K. A.: Cache Conscious Indexing for Decision-Support in Main Memory.
Proceedings of International Conference on VLDB (1999) 78-89.
7. Rao, J., Ross, K. A.: Making B+-Trees Cache Conscious in Main Memory. Proceedings of
ACM SIGMOD Conference (2000) 475-486.
8. Sitzmann, I., Stuckey, P. J.: Compacting Discriminator Information for Spatial Trees. Proceedings of Australasian Database Conference (2002) 167-176.
9. VanderWiel, S. P., Lilja, D. J.: Data Prefetch Mechanisms. ACM Computing Surveys,
Vol.32 (2000) 174-199.
10. Zhou, J., Ross, K. A.: Buffering Accesses of Memory-Resident Index Structures. Proceedings of International Conference on VLDB (2003) 405-416.

