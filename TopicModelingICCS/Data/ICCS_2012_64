Available online at www.sciencedirect.com

Procedia Computer Science 9 (2012) 1283 – 1291

International Conference on Computational Science, ICCS 2012

Multicriteria decision making approach for cluster validation
Yi Penga, Yong Zhanga, Gang Koua,*, Jun Lia, Yong Shib,c
a

School of Management and Economics, University of Electronic Science and Technology of China, Chengdu, 610054, P. R. China
b
CAS Research Center on Fictitious Economy and Data Sciences, Beijing,100080, China
c
College of Information Science & Technology, University of Nebraska at Omaha, Omaha, NE 68182, USA

Abstract
This paper proposes a multiple criteria decision making (MCDM)-based framework to address two fundamental issues in cluster validation: 1)
evaluation of clustering algorithms and 2) estimation of the optimal cluster number for a given data set. Since both issues involve more than
one criterion, they can be modeled as multiple criteria decision making (MCDM) problems. The proposed framework is examined by an
experimental study. The results suggest that MCDM methods are practical tools for the evaluation of clustering algorithms. In addition, the
selected MCDM method, PROMETHEE II can estimate the optimal numbers of clusters for ten out of fifteen datasets by adjusting the weights
of criteria.

Keywords: clustering algorithm; cluster validation; multiple criteria decision making (MCDM)

1. Introduction
As an essential step in cluster analysis, cluster validation has been an active research area. Many validity measures have been
proposed and can be classified into three categories: external, internal, and relative [1]. Extensive reviews of cluster validation
techniques can be found in [1-3]. Two fundamental issues that need to be addressed in cluster validation are: 1) evaluating
clustering algorithms and 2) estimating an optimal cluster number[4].
Since the evaluation of clustering algorithms and the determination of the number of clusters normally involve more than one
criterion, they can be modeled as multiple criteria decision making (MCDM) problems [5,6] and solved by MCDM methods.
This paper develops a framework to choose an appropriate clustering algorithm and estimate the optimal number of clusters for a
given data set using MCDM methods. The proposed framework is examined by an experimental study using fifteen publicdomain UCI data sets.
The rest of the paper is organized as follows. Section 2 describes the proposed framework, the selected MCDM method, the
clustering algorithms, the validity measures, and the correlation analysis. Section 3 presents details of the experimental study and
analyzes the results. Section 4 summarizes the paper.
2. Research methods
2.1. Proposed framework
The proposed MCDM-based cluster validation framework consists of two major parts (see Figure 1). The left portion of the
framework is designed to assess the performances of clustering algorithms. This study chooses external measures because they
correspond to error measurement and perform well in predicting the clustering error in previous studies [7]. Highly ranked

* Corresponding author. Tel.: 86-15982498501.
E-mail address: kougang@yahoo.com.

1877-0509 © 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
doi:10.1016/j.procs.2012.04.140

1284

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291

clustering algorithms are then recommended to data sets that share similar structures but have no class labels. The right portion
of the framework utilizes relative validity measures and MCDM methods to estimate the number of clusters in a data set. For
each data set, different numbers of clusters are considered as alternatives by MCDM methods. The performances of the best
clustering algorithm, which is determined in the previous step, on the relative measures with different numbers of clusters
represent criteria in MCDM methods. The result of this analysis is a rank of numbers of clusters, which evaluates the
appropriateness of different numbers of clusters for a given data set.
Correlation analysis

Domain Experts
Weights

External Measures

Relative Measures

Datasets
with labels

Optimal Clustering
Algorithm

Datasets
without labels

Optimal
Cluster Number

MCDM

General
Datasets

Weights

Fig.1. A MCDM-based framework for cluster validation

2.2. Preference Ranking Organisation METHod for Enrichment of Evaluations (PROMETHEE)
This section introduces the selected MCDM method, PROMETHEE II and explains how it is used to rank clustering
algorithms and estimate the optimal number of clusters for a given data set.
Brans [8]proposed the PROMETHEE I and PROMETHEE II, which use pairwise comparisons and outranking relationships
to choose the best alternative. The final selection is based on the positive and negative preference flows of each alternative. The
positive preference flow indicates how an alternative is outranking all the other alternatives and the negative preference flow
indicates how an alternative is outranked by all the other alternatives [9]. This study utilizes PROMETHEE II in the
experimental study, which is presented by Brans and Mareschal (2005) [9] and described in the following:
Step 1: define aggregated preference indices.
Let a, b A, and let:
( a, b)

k

p j ( a, b) w j ,

j 1

(b, a)

k

(1)

p j (b, a) w j .

j 1

where A is a finite set of possible alternatives {a1, a2, , an}, k represents the number of evaluation criteria and wj is the
weight of each criterion.
Step 2: calculate (a, b) and (b, a) for each pair of alternatives of A. There are six types of preference functions and the
decision-maker needs to choose one type of the preference functions for each criterion and the values of the corresponding
parameters [10]. The usual preference function, which requires no input parameter, is used for all criteria in the experiment.
Step 3: define the positive and the negative outranking flow as follows:
The positive outranking flow:
(2)
1
( a)
( a, x),
n 1x A
The negative outranking flow:
(3)
1
( a)
( x, a).
n 1x A
Step 4: compute the net outranking flow for each alternative as follows:
( a)
( a)
(a).
(4)
When (a) 0, a is more outranking all the alternatives on all the evaluation criteria. When (a) 0, a is more outranked.

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291

1285

2.3. Clustering algorithms
The notations summarized in Table 1 are used throughout this paper.
Table 1. Table of notations
Notation

Description

n

The number of objects in a data set.

nk

The number of objects in the kth cluster.

K

The number of clusters.

Ci

The ith cluster, i

C

The set of clusters, C={C1,C2, ,CK}.

xi

An object, i

vi

The center of cluster Ci, i {1,2,

m

The number of true classes in a data set.

X

A data set.

{1,2,

{1,2,

,K}.

,n}
,K}.

Seven algorithms are chosen for the empirical study. They are the k-means, the expectation-maximization (EM), the
COBWEB, the density-based cluster, the farthest-first traversal algorithm, the agglomerative hierarchical clustering algorithm,
and the fuzzy c-means. The fuzzy c-means algorithm is implemented by KNIME (Konstanz Information Miner), an open source
data analytics platform [11]. Other six algorithms are implemented using WEKA (Waikato Environment for Knowledge
Analysis), a free machine learning software [12].
The k-means algorithm, the most well-known partitioning method, is an iterative distance-based technique [13]. The
input parameter k predefines the number of clusters. First, k objects are randomly chosen to be the centers of these clusters. All
objects are then partitioned into k clusters based on the minimum squared-error criterion, which measures the distance between
an object and the cluster center. The new mean of each cluster is calculated and the whole process iterates until the cluster
centers remain the same [14,15]. The expectation-maximization (EM) algorithm [16,17] can be considered an extension of the kmeans algorithm. The EM algorithm determines the membership of each data object according to a probability. It consists of two
main steps. The expectation step calculates the cluster probability of each object and the maximization step calculates the
distribution parameters that maximize the likelihood of the distributions given the data [15,18]. COBWEB is an incremental
conceptual clustering system introduced by (Fisher 1987) [19] for nominal attributes and extended by Gennari et al. (1989)[20]
for numeric attributes. Objects are organized into a classification tree, where each node contains a probabilistic description of a
concept. A classification tree is built using four basic operators, including placing an object in an existing class, creating a new
node/class, merging two nodes, and splitting a node [19]. The density-based method considered in this study is developed in
WEKA. The algorithm is called MakeDensityBasedClusterer, a meta-clusterer which wraps a clustering algorithm to return a
probability distribution and density [14]. The base clustering algorithm used in the experiment is k-means. The farthest-first
traversal algorithm is a simple approximation algorithm for the k-center problem [21]. It starts with a random data point and then
chooses the point furthest from it. The process continues to find the point furthest from the selected set until k points are acquired.
The distance of a point x from a set S is the min{d(x, y): y S}. These k points are used as cluster centers and other points are
assigned to the closet center [22]. FarthestFirst (FF) function of Weka implements the farthest-first traversal algorithm. The
agglomerative hierarchical clustering algorithm used in this study chooses default options provided by the HierarchicalCluster
(HC) function of Weka, which uses Euclidean distance and single linkage. The fuzzy c-means (FCM) algorithm is a derivative of
the k-means algorithm [23]. Any data point x is associated with every cluster using a set of coefficients, which represent the
degree of memberships to the clusters for each data point. Similar to the k-means algorithm, the number of clusters and
coefficients are assigned randomly at the beginning. The fuzzy c-means algorithm is implemented by KNIME.
2.4. Clustering validity measures
This study chooses seven external and ten relative measures for the experiment, namely, purity, entropy, F-measure [24], rand
statistic, normalized
index [25], adjusted rand index [26], Jaccard coefficient [27], Fowlkes and Mallows index [28],
[29,30], the Dunn s index [31], the Davies-Bouldin index [32], the CS measure [33], the SD index[2,3], the S_Dbw
index[2,3], the silhouette index [34], PBM [35], and the C-index [29]. Due to the space limitation, validity measures are not
described in this paper. The details of cluster validation measures can be found in [1].
2.5. Correlation analysis
Most MCDM methods require the decision-maker to assign weights of relative importance of the criteria [9]. This study uses
the Pearson correlation coefficient to measure the dependence between two validity indices and provides this information to
domain experts as a reference for determining the weights of the criteria. The Pearson correlation coefficient measures the linear

1286

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291

dependence between two random variables X and Y is defined as follows [36,37]:
n

rxy

( xi

x )( yi

y)

i 1
n

( xi

x)

2

i 1

n

(5)

( yi

y)

2

i 1

where n is the number of measurements of X and Y, and x and y are the mean of variable X and Y, respectively.
3. Experiment
3.1. Data sets
A total of fifteen data sets are used in the experiment. They are provided by UCI machine learning repository
(http://archive.ics.uci.edu/ml/) [38]. Table 2 summarizes the characteristics of the data sets.
Table 2. Data set structures
Data Set

Number of Records

Number of Classes

Breast cancer

699

2

Breast tissue

106

6

Acute inflammations

120

2

Ecoli

336

8

214

6

306

2

Ionosphere

351

2

Iris

150

3

Parkinsons

197

2

Pima Indians diabetes

768

2

Sonar

208

2

Transfusion

748

2

Wine

178

3

Wine quality (red)

1599

6

Yeast

1484

10

Glass
H

s survival

3.2. Experimental design
The experiment is carried out according to the following process:
Input: fifteen UCI machine learning data sets
Output: Ranking of clustering algorithms and estimation of appropriate number of clusters for each data set
Step 1 Prepare the data sets: remove class labels from the data sets.
Step 2 Upload the data sets to Weka 3.6 and KNIME to get clustering solutions using the seven clustering algorithms
described in Section 2.3 and compute the values of the external and relative indices for each partition.
Step 3 Compute the Pearson correlation for the external and relative indices. The correlation coefficients are used as
references by domain experts in Step 4 to assign weights for each validity index.
Step 4 Obtain weights of criteria (i.e., validity indices). Each external index gets one score, which is assigned by twelve
domain experts according their experiences and the correlation coefficients, and each relative index gets fifteen scores, which are
assigned by the same group of domain experts based on their experiences and the results of correlation analysis for every data set.
The score ranges from 0 to 10 with increasing importance.
Step 5 For each data set, calculate the seven external measures for each clustering algorithm using MATLAB 7.0 (Matlab
2005). The result is a 7 8 matrix for each data set.
Step 6 Generate the ranking of clustering algorithms using PROMETHEE II for each data set. PROMETHEE II was
implemented by the MCDM software D-Sight.
Step 7 Generate the rankings of different numbers of clusters using the MCDM methods for all the data sets. For each data set,

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291

1287

the clustering algorithm ranked as the best from step 6 is used to compute relative indices nine times, each time with a different
number of clusters (i.e., from 2 to 10). The weights of relative indices from step 4 are inputs to the MCDM methods.
END
The 0-10 scale used by domain experts indicates increasing importance of criteria. Number 0 indicates that the domain expert
is not interested in that criterion and number 10 indicates that the domain expert considers the criterion extremely important.
When the top-ranked clustering algorithms have very close scores, the decision-maker should be noticed.
3.3. Results and discussion
Table 3 shows the correlation coefficients of seven external measures, which are the average correlation coefficients across all
the data sets.
Table 3. Correlation coefficients of external measures
Purity EntropyF-measureRand Adjusted RandJaccardFM
Purity

1.0000

Entropy

-0.94171.0000

F-measure

0.8728 -0.8033 1.0000

Rand

0.7631 -0.7023 0.9401

1.0000

Adjusted Rand0.8148 -0.7518 0.8269

0.79471.0000

Jaccard

0.8456 -0.8678 0.9419

0.89150.7341

1.0000

FM

0.8478 -0.8788 0.9269

0.85140.7097

0.9930 1.0000

For relative measures, one set of correlation coefficients are calculated for each data set. Table 4 summarizes the correlation
coefficients of the ten relative measures for the wine data set as an example.
Table 4. Correlation coefficients of relative measures for the wine data set

Hubert
Hubert
Normalized
Hubert

Normalized
Hubert

Dunn DB

SD

S_Dbw CS

SilhouettePBM C-index

1.0000
0.9978 1.0000

Dunn

-0.9727-0.9570

1.0000

DB

0.7897 0.7545

-0.89641.0000

SD

0.8801 0.8908

-0.82770.5329 1.0000

S_Dbw

-0.0610-0.0972

-0.06530.3681 -0.40611.0000

CS

0.8863 0.8849

-0.88700.6955 0.9622 -0.26431.0000

Silhouette -0.8828-0.8913

0.8331 -0.5389-0.96620.3352 -0.91141.0000

PBM

-0.6679-0.6904

0.6050 -0.3005-0.92820.5821 -0.88840.8494

C-index

0.4227 0.3675

-0.61530.8375 0.2577 0.3851 0.4754 -0.2374 -0.11231.0000

1.0000

Twelve domain experts are asked to assign a score, which is a number between 0 and 10 with increasing importance, to each
validity measure based on their experiences and the correlation coefficient. The averaged and normalized scores are weights of
validity measures. Each external measure obtains one weight and each relative measure gets fifteen weights, one for each data set.
Table 5 and 6 represent the respective weights of external and relative measures.
Table 5. Weights of external measures
Purity F-measure Rand Adjusted Rand Jaccard FM
0.162 0.119

0.171 0.118

0.134

Entropy

0.138 0.158

Table 6. Weights of relative measures

Hubert

Normalized
Hubert

Dunn DB SD S_DbwCS

SilhouettePBM C-index

Breast cancer

0.057 0.060

0.1320.1190.1020.083 0.1280.120

0.0810.118

Breast tissue

0.066 0.067

0.1110.0840.1000.132 0.0700.100

0.1150.154

1288

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291
Acute inflammations 0.071 0.069

0.1010.0660.1090.103 0.1260.090

0.1070.157

Ecoli

0.077 0.080

0.1040.0870.1130.084 0.1270.087

0.0900.151

Glass

0.065 0.070

0.1030.1050.1080.089 0.1000.076

0.1540.131

s survival 0.085 0.092

0.0790.0720.0950.105 0.1640.102

0.1230.082

Ionosphere

0.069 0.067

0.0830.1050.0970.106 0.1170.105

0.0970.153

Iris

0.070 0.072

0.0690.0960.0950.159 0.0890.085

0.1270.137

Parkinsons

0.069 0.069

0.1470.1260.1160.060 0.1410.090

0.0830.101

Pima Indians diabetes0.063 0.062

0.1280.1400.0940.059 0.1380.098

0.1400.077

Sonar

0.061 0.065

0.1100.1400.1100.118 0.1220.101

0.0960.077

Transfusion

0.062 0.068

0.1140.0980.1110.111 0.1310.110

0.1310.063

Wine

0.054 0.064

0.1340.1400.1180.078 0.1370.085

0.1350.055

Wine quality (red)

0.068 0.063

0.1020.1020.1050.105 0.1220.119

0.1460.067

Yeast

0.075 0.094

0.1290.0750.1180.109 0.1070.067

0.1490.077

H

3.3.1. Ranking of clustering algorithms by PROMETHEE II
Table 7 shows the scores and rankings of clustering algorithms generated by PROMETHEE II. The top-ranked algorithms are
highlighted in boldface and italic.
Table 7. Rankings of PROMETHEE II for the data sets

CobwebEM Farthest-first

Hierarchical
Cluster

k-means

DensityFuzzy
based c-means

Breast cancer

-0.44

0.00 -0.56

-1.00

0.72

0.89

0.39

Breast tissue

0.23

0.45 0.51

-0.36

-0.57

0.06

-0.32

Acute inflammations 0.89

-0.26 -1.00

-0.47

0.77

-0.26

0.33

Ecoli

0.28

0.36 -0.14

-0.22

-0.49

0.50

-0.27

Glass

0.19

-0.48 0.33

-0.09

0.36

-0.42

0.11

-0.21

0.30 0.09

0.96

-0.51

-0.13

-0.51

Ionosphere

-0.89

0.47 -0.59

0.37

-0.29

0.05

0.89

Parkinsons

-0.53

-0.28 0.32

0.80

0.17

-0.39

-0.09

Pima Indians diabetes-0.65

0.06 0.44

-0.24

-0.23

0.05

0.57

Sonar

0.34

-0.74 0.02

0.52

-0.40

-0.28

0.54

Transfusion

-0.32

-0.24 0.54

0.54

-0.02

-0.37

-0.14

Iris

-1.00

1.00 -0.39

-0.51

-0.05

0.67

0.28

Wine quality (red)

0.17

-0.03 0.17

0.50

-0.40

-0.15

-0.26

Wine

-0.903 1

-0.443

-0.387 0.667 0.121

Yeast

0.22

0.17

-0.20

-0.054

-0.05 0.09

0.37

-0.60

3.3.2. Estimating the optimal number of clusters by MCDM methods
Table 8 summarizes the best ranked numbers of clusters for the data sets produced by PROMETHEE II. The optimal
clustering algorithm determined by PROMETHEE II was applied to the corresponding data set nine times with the number of
clusters range from 2 to 10 to get nine sets of relative measures. The number of clusters with the highest value for each data set is
listed in the third column in Table 8. The last column shows the number of classes provided by UCI machine learning repository.
Table 8. PROMETHEE II rankings of the optimal numbers of clusters
Data set

Optimal Algorithm

# Cluster

# Class

Breast cancer

Density-based

2a

2

Breast tissue

Farthest-first

2c

6

Acute inflammations

Cobweb

4b

2

Ecoli

Density-based

3c

8

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291
Glass

k-means

4b

6

Hierarchical Cluster

2a

2

Ionosphere

Fuzzy c-means

3b

2

Iris

EM

2c

3

Parkinsons

Hierarchical Cluster

4b

2

Pima Indians diabetes

Fuzzy c-means

4b

2

Sonar

Fuzzy c-means

7b

2

Transfusion

Hierarchical Cluster

2a

2

Wine quality (red)

Hierarchical Cluster

4b

6

Wine

EM

3c

10

Yeast

Density-based

9c

10

1289

The PROMETHEE results can be classified into three situations. In the first situation, the optimal number of clusters is equal
to the known number of classes in the data set. Three data sets belong to this situation and indicated by the exponent number a.
In the second situation, the optimal number of clusters estimated by PROMETHEE is not equal to the known number of classes.
However, these two can be equal by changing the weights of relative measures. Seven data sets are in this category and indicated
by the exponent number b. The PROMETHEE-GAIA (Geometrical Analysis for Interactive Assistance) methodology [9] can be
used to graphically display the best solution when the weights of criteria are modified. The alternatives are represented by points
and the criteria by axes. The weights vector is also projected to the GAIA plane as the decision axis. The ranking of alternatives
can then be determined by the relative positions of the projections of all the alternatives on the decision axis. By modifying the
weights of criteria, the ranking of alternatives is changed accordingly.
Take the acute inflammation data set as an example. Before the modification of weights of relative measures, k=4 is the best
alternative. Figure 2 shows the GAIA plane with adjusted weights of relative measures. This time two number of clusters (k=2)
becomes the best alternative and it equals to the known number of classes in the data set. In the third situation, the optimal
number of clusters produced by PROMETHEE is not equal to the known number of classes and this situation can not be adjusted
by changing the weights. Four data sets are in this situation and indicated by the exponent number c.

Fig.2. PROMETHEE-GAIA ranking for the acute inflammation data set with adjusted weights

A number of observations can be made based on the experimental study. First, MCDM methods are practical tools for
clustering algorithm evaluation. They can evaluate clustering algorithms using a combination of validity indices. Second, the
proposed approach is useful in estimating the optimal number of clusters. PROMETHEE II can estimate the optimal numbers of
clusters for three datasets without adjusting the weights of criteria and can estimate the correct numbers of clusters for seven
datasets with adjusted weights.
4. Conclusion remarks
This paper proposed a MCDM-based cluster validation framework to address two fundamental issues in clustering analysis: 1)
evaluation of the performances of clustering algorithms and 2) estimation of the optimal number of clusters presented in a data
set. Both issues involve multiple criteria and thus can be modeled as multi-criteria decision making problems. Clustering
algorithms are evaluated using PROMETHEE II. The performances of top-ranked clustering algorithm on the relative measures
for a given data are then used to estimate the optimal number of clusters by PROMETHEE II.
There are three major steps in the proposed approach. The first step determines the weights of external and relative measures.
Domain experts are asked to assign scores to validity measures based on their experiences and the results of correlation analysis.

1290

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291

The second step uses PROMETHEE II to rank clustering algorithms according to their performances on a selection of external
measures and the weights of external measures determined in the first step. The best clustering algorithm ranked by
PROMETHEE II in the second step is applied to the same data set to decide the appropriate number of clusters in the third step.
The performances of the best clustering algorithm on a set of relative measures and the weights of relative measures provided by
the first step are inputs to the PROMETHEE II to rank different numbers of clusters for the data set. An experiment is designed
to examine the proposed framework using seven clustering algorithms, seventeen validity measures, and fifteen public-domain
UCI machine learning data sets. The results suggest that MCDM methods are practical tools for the evaluation of clustering
algorithms and the estimation of the number of clusters.
Acknowledgements
This research has been partially supported by grants from the National Natural Science Foundation of China (#70901011 and
#71173028 for Yi Peng, #70901015 for Gang Kou, and #70921061 for Yong Shi).
References
1. Jain A K, Murty M N, Flynn P J. Data Clustering: a Review. ACM Computing Surveys 1999; 31(3): 264-323.
2. Halkidi M, Batistakis Y, Vazirgiannis M. Cluster validity methods: part I. ACM SIGMOD Record 2002a; 31(2). .
3. Halkidi M, Batistakis Y, Vazirgiannis M. Cluster validity methods: part II. ACM SIGMOD Record 2002b; 31(3). .
4. Tan P, Steinbach M, Kumar V. Introduction to Data Mining. Addison-Wesley, 2005. ISBN : 0321321367.
5. Rokach L. Ensemble-based classifiers. Artificial Intelligence Review 2010; 33(1-2): 1-39.
6.Peng Y, Kou G, Wang G, Shi Y. FAMCDM: A Fusion Approach of MCDM Methods to Rank Multiclass Classification Algorithms. Omega 2011; 39(6):
677-689, DOI:10.1016/j.omega.2011.01.009.
7. Brun M, Sima C, Hua J, Lowey J, Carroll B, Suh E, Dougherty E R. Model-based evaluation of clustering validation measures. Pattern Recognition 2007;
40(3).
Landry M, editors,

8.
183 213.

9. Brans J P, Mareschal B. PROMETHEE methods. In Multiple Criteria Decision Analysis: State of the Art Surveys, Figueira J, Mousseau V and Roy B
(eds.), Springer, New York 2005. p. 163-195.
10. Brans J.P., Vincke, P. A Preference Ranking Organisation Method: (The PROMETHEE Method for Multiple Criteria Decision-Making). Management
Science, Vol. 31, No. 6 (June 1985). 647-656.
11. Berthold M R, Cebron N, Dill F, Gabriel T R, Kotter T, Meinl T, Ohl P, Sieb C, Thiel K, Wiswedel B. KNIME: The Konstaz Information Miner, in the
Series Studies in Classification. Data Analysis, and Knowledge Organization, Spinger 2007; ISSN: 1431-8814.
12. Hall M, Frank E, Holmes G, Pfahringer B, Reutemann P, Witten I H. The WEKA Data Mining Software: An Update; SIGKDD Explorations 2009;11(1):
10-18.
13. MacQueen J B. Some Methods for classification and Analysis of Multivariate Observations. Proceedings of 5th Berkeley Symposium on Mathematical
Statistics and Probability. University of California Press; 1967. p. 281 297.
14. Witten I H, Frank E. Data Mining: Practical machine learning tools and techniques, 2nd Edition. Morgan Kaufmann, San Francisco; 2005.
15. Han J, Kamber M. Data Mining: Concepts and Techniques. 2nd edition. Morgan Kaufmann; 2006.
16. Dempster A P, Laird N M, Rubin D B. Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society. Series
B (Methodological) 1977;39 (1): 1 38.
17. McLachlan G, Krishnan T. The EM algorithm and extensions (Second edition). Wiley-Interscience; 2008.
18. Witten I H, Frank E. Data Mining: Practical machine learning tools and techniques, 2nd Edition. Morgan Kaufmann, San Francisco; 2005.
19. Fisher D H. Knowledge acquisition via incremental conceptual clustering. Machine Learning 1987;2: 139 172.
20. Gennari J H, Langley Patrick W, Fisher Douglas H. Models of incremental concept formation. Artificial Intelligence 1989;40:11 61.
21. Hochbaum D S, Shmoys D B. A best possible heuristic for the k-center problem. Mathematics of Operations Research 1985; 10(2):180-184.
22. Dasgupta S, Long P M. Performance guarantees for hierarchical clustering. Journal of Computer and System Sciences 2005; 70(4).
23. Bezdek J. Pattern recognition with fuzzy objective function algorithms. New York: Plenum Press; 1981.
24. Larsen B, Aone C. Fast and Effective Text Mining Using Linear-time Document Clustering. KDD-99. San Diego, California 1999. p. 16-22.
25. Rand W M. Objective criteria for the evaluation of clustering methods. Journal of the American Statistical Association (American Statistical Association)
1971; 66 (336): 846 850.
26. Hubert L, Arabie P. Comparing partitions. Journal of Classification 1985; 2(1): 193 218.
27. Vendramin L, Campello R, Hruschka E. Relative Clustering Validity Criteria: A Comparative Overview. Statistical Analysis and Data Mining 2010; 3(4):
209-235.
28. Fowlkes E B, Mallows C L. A method for comparing two hierarchical clustering. Journal of the American Statistical Association 1983; 78(383): 553 569.
29. Hubert L J, Levin J R. A general statistical framework for assessing categorical clustering in free recall. Psychological Bulletin 1976; 83(6): 1072 1080.
30. Hubert L, Arabie P. Comparing partitions. Journal of Classification 1985; 2(1): 193 218.
31. Dunn J C. A Fuzzy Relative of the ISODATA Process and Its Use in Detecting Compact Well-Separated Clusters. Journal of Cybernetics; 1973:3(3): 32-

Yi Peng et al. / Procedia Computer Science 9 (2012) 1283 – 1291

1291

57.
32. Davies D L, Bouldin D W. A cluster separation measure. IEEE Transactions on Pattern Analysis and Machine Intelligence 1979; 1(2): 224 227.
33. Chou C H, Su M C, Lai E. A new cluster validity measure and its application to image compression. Pattern Analysis Applications 2004; 7(2): 205-220.
34. Rousseeuw P J. Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis. Journal of Computational and Applied Mathematics
1987; 20: 53 65.
35. Pakhira M K, Bandyopadhyay S, Maulik U. Validity index for crisp and fuzzy clusters. Pattern Recognit 2004; 37:487 501.
36. Pearson, K. (1895). "Note on regression and inheritance in the case of two parents", Proceedings of the Royal Society, 58, 240 242
37. Rodgers, J.L. and Nicewander, A.W. (1988) Thirteen Ways to Look at the Correlation Coefficient, The American Statistician, Vol. 42, No. 1. (1988), pp.
59-66.
38. Frank A, Asuncion A. UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and
Computer Science 2010.

