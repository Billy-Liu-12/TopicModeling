Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 499–507

Procedia Computer
Science

Procedia Computer Science 00 (2011) 1–9

International Conference on Computational Science, ICCS 2011

QoS Support in Event Detection in WSN through Optimal
k-Coverage
Kh Mahmudul Alam, Joarder Kamruzzaman, Gour Karmakar, Manzur Murshed, A K M Azad
Gippsland School of Information Technology, Monash University, Churchill VIC-3842, Australia

Abstract
Wireless sensor networks promise to guarantee accurate, fault tolerant and timely detection of events in large scale
sensor fields. To achieve this the notion of k-coverage is widely employed in WSNs where significant redundancy
is introduced in deployment as an event is expected to be sensed by at least k sensors in the neighborhood. As
sensor density increases significantly with k, it is imperative to find the optimal k for the underlying event detection
system. In this work, we consider the detection probability, fault tolerance and latency as the Quality of Service
(QoS) metrics of an event detection system employing k-coverage and present a probabilistic model to guarantee
given QoS support with the minimum degree of coverage taking into account the noise related measurement error,
communication interference and sensor fault probability. This work eventually resolves the problem of over or under
deployment of sensors, increases scalability and provides a well defined mechanism to tune the degree of coverage
according to performance needs.
Keywords: WSN, event detection, k-coverage, accuracy

1. Introduction
Features such as random deployment over large inaccessible terrain and decentralized collaborative nature make
wireless sensor networks (WSNs) apt for a wide range of applications, ranging from smart home system to space
station surveillance [1, 2]. Although earlier WSNs concentrated mostly on data gathering for monitoring purposes,
recently however, more attention is shifted towards event detection which is crucial for many applications, such as
disaster management, pollution detection, industrial monitoring, fault detection [1] etc.
In most WSN-based applications, sensor nodes are expected to be low cost error prone and deployed in adverse
terrain and harsh condition, hence the probability of node malfunction is significantly higher in WSNs compared
to traditional networks such as TCP/IP and cellular networks. Usually, communication is more vulnerable to the
environmental noise in WSNs due to the relatively low signal strength used by sensors to preserve energy. Many
event based services, like fire monitoring, require immediate detection, that is the average time elapsed between event
occurrence and its detection by the system is very short, which makes the timeliness very crucial in event detection .
Overall, the issues that should be addressed for event detection in WSNs are: i) reliable detection of events with high
Email address: kh.mahmudul.alam@monash.edu (Kh Mahmudul Alam )

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.052

500 	

Kh Mahmudul Alam et al. / Procedia Computer Science 4 (2011) 499–507
Kh Mahmudul Alam / Procedia Computer Science 00 (2011) 1–9

2

accuracy, ii) robust event detection against sensor fault and environmental noise, and iii) timeliness of detection.
Traditional WSN based event detection models, where each location within the network is covered by only a single
sensor, are not reliable due to noise, and sensor faults and/or measurement errors. Therefore, recent studies advocate
the introduction of redundant nodes in the network so that every possible event location can be monitored by multiple
nodes and the individual detection decisions can be aggregated to rule out inaccuracies. This idea brought the notion
of k-coverage in WSNs. A WSN is called k-covered if every point in the network is within the sensing range of at least
k nodes, k (≥1) being the degree of coverage. In k-coverage event detection models, the decision on the occurrence of
an event is made in collaboration among the k sensors detecting the event. While increasing the degree of coverage
k will enhance the detection performance metrics such as detection probability, fault tolerance and latency at the cost
of higher network traﬃc, energy consumption and deployment cost; lowering k would exhibit degraded accuracy
and loss of robustness. Therefore, an optimal coverage is of paramount importance to attain a trade-oﬀ among the
aforementioned opposing factors. To the best of our knowledge no prior work exists in the literature that provides an
analytical solution to determine the degree of coverage i.e. value of k in WSN-based event detection. To address this
issue in this paper we make following contributions:
• Event detection probability is modelled considering sensing noises, communication interferences and sensor
malfunctions.
• An analytical measure is formulated for event detection latency for the k-coverage WSN model.
• Finally, a lower bound on k is obtained that probabilistically guarantees the required performance metrics such
as event detection accuracy, fault tolerance and latency.
2. Related Works
There are two types of event detection schemes that have been proposed in the literature: i) centralized scheme
that requires a sensor node to send its observation directly to the base station for decision and ii) decentralized scheme
where each sensor makes local decision independently and these decisions are combined in a local fusion centre to
make the final decision. Since sensor nodes are constrained with low power, the centralized detection schemes requiring each node to transmit its measurement directly to the base station are not suitable. This makes decentralized
schemes more popular in event detection paradigm. One of the first works on distributed fault tolerant event detection was presented in [3]. It considered the spatial correlation in event measurement and proposed Bayesian decision
fusion to detect an event in collaboration among the neighboring sensors. But this work assumed known constant
decision error probability for every node which is not realistic and it provides no indication on determining suitable
degree of coverage.
In [4], Luo et al. presented a fault tolerant energy eﬃcient event detection mechanism. To disambiguate events
from noise and sensor faults, the authors suggested that the above factors are likely to be spatially uncorrelated while
event measurements are correlated spatially. They formulated event detection as a binary hypothesis test problem
and individual decisions were fused taking measurements from nodes in a neighborhood. While this work gave an
indication of suitable neighborhood size from energy eﬃciency point of view, it did not deal with introducing redundancy to cope up with faults and noise, rendering this work inapplicable in k-coverage context. The idea of k-watched
event detection was formalized in [6] from energy eﬃciency and bounded delay point of view, though binary decision
fusion technique similar to [3], [4] is used. They extended the detection scheme for composite event and considered
detection delay. This scheme achieved fault tolerance by having each point in the sensor field being monitored by k
nodes and takes an event as detected even when k-1 nodes concurrently fail. This was somewhat unrealistic from the
accuracy point of view because occurrence of an event unnoticed by k-1 nodes but reported by only one, may indicate
sensor fault. This work lacks in the analysis of achieved accuracy or closed form for delay in their model. Zhu and
Zheng [12] studied the event detection delay in WSN and they quantified the detection performance of a distributed
event detection WSN by deriving the closed forms of detection delay and detectability.
Wang et al. [11] analyzed detection latency using a probabilistic approach for k-sensor detection model and considered latency as a performance metric for detection. Zhu and Ni [13] first formalized the QoS provisioning problem in
event detection applications in WSNs. They presented detection latency and detection probability as the two key performance metrics for event detection systems and proposed a probabilistic approach to provisioning QoS. Although
their work formalized the concept of provisioning QoS for event detection system, it did not consider the k-coverage

501
3

Kh Mahmudul Alam et al. / Procedia Computer Science 4 (2011) 499–507
Kh Mahmudul Alam / Procedia Computer Science 00 (2011) 1–9

detection model. None of the works discussed so far has taken the contention in medium access control (MAC) layer
in consideration that may incur additional delay in k-coverage event detection. To address that issue, we have explored
the sensor specific MAC protocols [9] such as S-MAC, B-MAC, Sift and Z-MAC in detail and incorporated the MAC
introduced delay in our model.
3. System Model and Problem Statement
3.1. The Network and Event Detection Model
We consider a WSN consisting of a set of sensor nodes deployed randomly over the network area, where the number of sensors deployed is suﬃcient enough to achieve k-coverage. We assume that the transmission range of each sensor is suﬃcient enough to maintain the sensor connectivity across the network. Moreover, the sensing area of a sensor
follows the disc model i.e.
the sensing range is a circle centred at that node.
In our approach, we divide time into a series of periodic sensing cycles where at each
cycle, a sensor senses its surrounding environment and the information acquired thereby
is used to decide on event occurrence. The event detection model is binary, i.e. each
node compares its local measurement with some threshold and takes a one bit decision
whether an event has occurred or not, and the decision is sent to a local fusion centre. For
example, in Fig. 1 the event is sensed by four sensors (k=4), each node sensing a circular
area, and their sensing decision is sent to a node (marked by a dotted circle) which acts
as a sensing node as well as a local fusion centre. The local fusion centre may be selected
in a round robin fashion. A distributed decision fusion scheme like majority voting in
[14] can be employed to take the final decision at the local fusion centre aggregating
the decisions sent from the k sensors monitoring the event point. This decision is then
sent to a base station (BS). Unlike [14], we consider ‘n out of k’ rule for decision fusion
which is more generic and oﬀers more flexibility. Considering real life incident such as
fire, chemical pollution or natural disaster, events are usually persistent and stationary.
Then it can be safely assumed that the average event lifetime, denoted by T , is greater
than the sensing cycle, denoted by τ, i.e. , T  τ.
Figure 1: k-coverage detection

3.2. The Fault and Noise Model
A decision error in an individual sensor may arise from three diﬀerent sources: i)
noisy measurement by the sensor due to environmental interference referred to as the sensing noise, ii) sensor malfunction or physical damage referred to as fault, and iii) alteration of a sensor decision due to the noise present in the
communication channel during transmission to the local fusion centre referred to as the communication noise. In the
following, we formally model each of the above impairments:
• Sensing noise: Let S = {s1 , s2 , ..., sk } be the set of k sensors monitoring an event and u be the expected measure
of the physical data sensed by a sensor in the absence of any sensing noise. But due to the sensing noise, sensed
data may not exactly be u. Moreover, sensing noise at diﬀerent sensors might vary, and consequently their
observation data. Such sensing noise can be modelled using Gaussian distribution [5]. Let the sensing noise at
the i-th sensor be ni which follows a Gaussian distribution with µ s mean and σ2s variance ℵ(µ s , σ2s ). Let {yi }ki=1
be the set of observations of the k sensors monitoring the event, where
y i = u + ni .

(1)

• Fault probability: Sensor fault may arise from many sources, such as manufacturing fault, physical damage
during deployment, energy depletion with time, circuit malfunctioning due to environment impact or aging, etc.
While some of these factors are dependent on the surrounding conditions where the sensor is located, some are
independent of sensor location. For simplicity we take the mean of the fault probability over the entire sensor
field to be individual node’s fault probability which is denoted by P f .

502 	

Kh Mahmudul Alam et al. / Procedia Computer Science 4 (2011) 499–507
Kh Mahmudul Alam / Procedia Computer Science 00 (2011) 1–9

4

• Communication noise: Let the binary decision taken by a sensor is sent to the local fusion centre via a communication channel, which is subject to an additive white Gaussian noise (AWGN) with zero mean and σ2c
variance. Since we are concerned about sending a binary decision, a communication error event can alter a
single bit decision with the probability, Pb , which is the bit error probability of the channel. Given the AWGN
model ℵ(0, σ2c ), the approximated bit error probability, as obtained in [8], has the following form,



αM
γb β M 



Q
Pb = Pr (γb ) =
log2 M  log2 M 

(2)

where, Q denotes the standard tail probability of the standard Gaussian distribution, M, α M and β M depend
on the type of approximation and modulation type, and γb is called the SNR per bit which can be calculated
from σ2c . While this is more of a generic form, diﬀerent other models have also been proposed in literature for
channel specific characteristic that calculate the bit error probability as a function of SNR [10].
3.3. Problem Statement
As discussed in Section 1, the performance of an event detection system such as detection probability, fault
tolerance and latency are dependent on the degree of coverage k. Our goal is to determine the minimum k so that
the QoS requirements are satisfied and can be formulated as the following optimization problem: minimize k,
s.t.,



Pk,n ≥ α




(3)
P f ≤ β and,





Lk,n ≤ λ

where α, β and λ are the QoS requirements for an application corresponding to the detection accuracy, fault tolerance
and latency, respectively. Pk,n and Lk,n are the event detection probability and latency respectively when an event is
monitored by k sensors and ‘n out of k’ rule is applied for decision fusion.
4. Optimal Degree of Coverage
To derive the optimal degree of coverage, we first estimate the errors due to diﬀerent types of impairments in the
detection environment as presented below.
Decision error due to sensing noise: Due to sensing noise , a sensor si ∈ S generates data yi instead of actual event
measure u. A sensor makes a binary decision, event occurrence (1) or non-event (0), by comparing its generated data
yi with the threshold value γ that characterizes the occurrence of an event. The threshold value is application specific
and pre-calculated based on domain knowledge [14]. The noise may deviate the sensed reading in either direction,
i.e., it may drive a non-event to an event occurrence resulting in a false detection, or it may drive an event occurrence
to a non-event situation missing an actual event. Therefore having knowledge on sensing noise that may exist in the
sensor field, it is possible to estimate the tolerable noise margin (nmax ) without causing any decision error which is
given by
(4)
nmax = |γ − u|.
Then with reference to (1) the probability of decision error (P s ) at a sensor due to the sensing noise can be calculated
as follows:
Ps

=
=

Pr(|n
 i | > nmax ) 
nmax −µ s
1
√
.
2 1 − erf σ 2

(5)

s

Decision error due to communication noise: Let {xi }ki=1 be the set of individual binary decisions made by k sensors
monitoring the event, where



1, if yi ≥ γ,
(6)
xi = 

0, otherwise.

Kh Mahmudul Alam et al. / Procedia Computer Science 4 (2011) 499–507
Kh Mahmudul Alam / Procedia Computer Science 00 (2011) 1–9

503
5

Once each individual sensor makes its decision, each sends its decision to the local fusion centre through a communication channel whose noise model is given by (2). Due to channel noise the fusion centre may receive an altered
decision. Let { xˆi }ki=1 be the set of decisions received at the fusion centre corresponding to the set {xi }ki=1 . Since each
decision is a 1-bit binary value, the probability of error being introduced during transmission from a sensor to the
fusion centre can be expressed as
Pr(xi  xˆi ) = Pb .
Probability of detection: We assume that the observations are independent and identically distributed, and sensor
faults and communication noise are also independent of the observations. Also a sensor will cause sensing error only
if it is not faulty, otherwise a sensor generating erroneous data is faulty with probability P f . Then considering error
probabilities from all types of error, the probability that a sensor would correctly detect an event and its decision
would reach error free at the fusion centre is given by,
Pd = (1 − Pb )(1 − P f )(1 − P s ).

(7)

Now, the decisions { xˆi }ki=1 from k sensors at the fusion centre can be considered as a series of independent Bernoulli
random variables with success probability Pd . The fusion centre employing the ‘n out of k’ rule will decide the
hypothesis as correct provided that at least n nodes successfully detect the true event situation. The individual decision
from each of k sensors at the fusion centre can be given by k conditionally independent and identically distributed
Bernoulli random variables. The probability for successful detection of an event at the fusion centre employing ‘n out
of k’ rule is then given by,
k  

k i
Pk,n =
(8)
Pd (1 − Pd )k−i .
i
i=n

For a given detection probability Pd and fixed n, Pk,n is an increasing function of k. As argued in Section 1, in
addition to detection accuracy, latency is also a crucial QoS parameter. So an important WSN design issue would be
to determine the value k to satisfy a given latency constraint.
The delay incurred has two components - the time required to detect the event by at least n diﬀerent sensors and
the time required to transmit the results to the fusion centre considering MAC layer contention. Let Ldet (k, n) be the
time required for the event to be successfully detected by n or more sensors and Lmac (n, k) be the delay incurred due
to contention in the transmission medium. In this regard we have the following proposition:
Proposition 1. The expected latency Ldet (k, n) for successful detection of an event for ‘n out of k’ rule is,


 2 + P  − 2 + P 2 −
rep
rep

Ldet (k, n) = 

2Prep

8nPrep
kPdet




 τ.


(9)



Figure 2: Timing illustration of sensing cycles and event lifetime.

Proof. Let us consider an event occurring in the sensor field. Let T be the lifetime for which the eﬀect of an event
persists and remains detectable as shown in Fig. 2 and τ be the point in time when the first sensing cycle starts after
the event begins. It is assumed that the sensors are time synchronized.
In ‘n out of k’ rule the fusion centre can declare the event as detected once at least n sensors send positive result.
Let m be the expected number of sensing cycles required to detect the event by more than n sensors. The detection
probability at individual sensor in a given cycle is Pdet = (1 − P f )(1 − P s ) and the detection of the event by the sensors
is independent in each cycle. The expected number of sensors detecting the event in a given cycle is then kPd . But
a portion of this kPd sensors may already have detected the event in any previous cycle, so it is counted only once

504 	

Kh Mahmudul Alam et al. / Procedia Computer Science 4 (2011) 499–507
Kh Mahmudul Alam / Procedia Computer Science 00 (2011) 1–9

6

towards the calculation of n. Let the probability that a node detects the event repeatedly in two or more cycles be Prep .
Then the number of distinct nodes νi detecting the event upto i-th cycle can be given by,
νi

=
=



kPdet + kPdet (1 − Prep ) + ... + kPdet 1 − (i − 1)Prep
  i(i−1) 

kPdet i − 2 Prep .

Solving νi ≥ n will give the expected number of cycles required for n detections, leading to
 


i(i − 1)
kPdet i −
Prep ≥ n
2
 
2 8nP

2 + Prep − kPdetrep
2 + Prep −
⇒i≥
2Prep
According to our definition,
m=

 
2
2 + Prep −
2 + Prep −



8nPrep
kPdet

2Prep

.

(10)




rep
 (2+Prep )− (2+Prep )2 − 8nP

kPdet 
Therefore, Ldet (k, n) = 
 τ, which completes the proof.
2Prep

Now, all nodes detecting the event within m cycles may not be able to transmit the data to the fusion centre due to
contention in Medium Access Control layer. Let Pmac denotes the probability of successful transmission of a node in
one time slot in the contention window. The duration of a slot is given by td and one sensing cycle consists of c slots,
that is, τ = ctd . Let πi be the expected number of unique nodes that detect and transmit successfully upto i-th cycle.
π1
π2

= cν1 Pmac
= π1 + c(ν2 − π1 )Pmac
= cν1 Pmac (1 − cPmac ) + cν2 Pmac .

Proceeding this way, we get,
πm = cPmac

m

i=1

νi (1 − cPmac )m−i .

(11)

Even after n detections among k sensors, we still may have (νm − πm ) nodes still waiting to send their detection
decisions due to contention. Let ρ be the additional number of transmission slots that will be required to transmit
these outstanding decisions. Then,


νm − πm
Lmac (k, n) = ρtd =
td .
Pmac
The overall expected delay before at least n distinct nodes can detect and transmit their results to the fusion centre is
given by,
Lk,n = Ldet (k, n) + Lmac (k, n).
(12)

The term Pmac depends on the sensor specific MAC protocol and the number of competing stations. It is practical to
assume that a sensor detecting the event more than once will send the result only once in the current cycle even if the
result from any previous cycle is still unsent, i.e. it will send the most recent data only. For simplicity, the average
number of competing stations can be assumed to be kPd .
Finding the Optimal Degree of Coverage: We are interested in finding the minimum value of k that satisfies the
given performance metrics. (7) indicates that Pd decreases with increasing sensor fault probability P f . According to
the given constraint in (3) the maximum allowable fault tolerance limit is β, so to satisfy this we can replace P f by β
in (7). This yields following expression for the probability of successful detection of an event by an individual sensor
at the fusion centre that satisfies a given fault tolerance,
Pd = (1 − Pb )(1 − β)(1 − P s ).

(13)

Kh Mahmudul Alam et al. / Procedia Computer Science 4 (2011) 499–507

505

Kh Mahmudul Alam / Procedia Computer Science 00 (2011) 1–9

7

(a) Impact of sensing noise on sensed temparature

(b) k vs. fault tolerance and detection probability

(c) k vs. detection probability

(d) k vs. fault tolerance

(e) Detection probability vs. fault Tolerance.

(f) Expected delay vs. k (for B-MAC)

Figure 3: Comparison of analytical and simulation results depicting the relationship among k, detection probability, fault tolerance and detection
delay.

Using the above expression in (8) gives an estimate of the detection probability Pk,n , that satisfies a given fault
tolerance β. Therefore, the minimum value of k that satisfies required fault tolerance and detection probability can be

506 	

KhMahmudul
MahmudulAlam
Alam/ Procedia
et al. / Procedia
Computer
4 (2011)
Kh
Computer
ScienceScience
00 (2011)
1–9 499–507

expressed as,
kα,β


 k  

 k i
k−i

= arg min 
Pd (1 − Pd ) > α .
k
i
i=n

8

(14)

The above kα,β can be calculated in a simple iterative fashion. From (12) latency Lk,n is an increasing function of k
for a given n. Let kλ be the maximum number of node coverage that satisfies the given latency constraint λ. kλ can be
determined by solving,



 2 + P  − 2 + P 2 −
rep
rep



2Prep

8nPrep
kPdet





ν − πi
 ctd + i
td ≤ λ.

Pmac

(15)

Now, two diﬀerent cases are possible - i) kα,β > kλ and ii) kα,β ≤ kλ . In the first case, it is not possible to satisfy all
three performance metric concommitantly, because setting kmin = kλ will not meet the degree of coverage requirement
for accuracy and fault tolerance. Therefore, either latency (kmin = kλ ) or the other two (kmin = kα,β ) can be met. In the
latter case, the solution is feasible. Combining the results from (14) and (15), the expression for the minimum degree
of coverage k with a ‘n out of k’ fusion rule satisfying all three QoS related constraints leads to the solution of the
optimization defined in (3) as, kmin = min(kα,β , kλ ).
Finally, we pose one validation check on the result to ensure minimizing false alarm. When no event occurs, the
n
> (1 − Pd ) needs to be
number of nodes that will erroneously detect an event is kmin (1 − Pd ). So, the condition kmin
satisfied to reduce the number of false alarms.

5. Simulation Result and discussion
We designed and developed a custom simulator in Matlab and conducted extensive experiments to validate our analytical model. For experiments, we randomly deployed sensors in a 400m×400m square sensor field and the number
of nodes, N required for k-coverage was determined according to [7], for diﬀerent values of k. Each sensor is assumed
to have a sensing range of 10m and a communication range twice the sensing range. A set of temparature data were
taken from [15] to generate events after imposing noise and events were uniformly distributed over the sensor field.
We measured the accuracy of detection for diﬀerent values of fault tolerance, β and k. We used Z-MAC, S-MAC
and B-MAC [9] for simulation and all of them showed similar trends. Due to space limitation we only presented the
results generated using B-MAC. ‘4 out of k’ rule is employed in all cases unless otherwise specified in legend. In each
case 1000 trials were repeated and their average was reported. The findings are presented in Fig. 3.
Fig. 3(a) shows how the simulated noise aﬀects real data causing missed detection, B and a false alarm, A. Fig.
3(b) represents the combined eﬀect of given detection probability and fault tolerance on the degree of coverage k, in a
surface plot. This helps to visualize the inherent relation of k with detection probability and fault tolerance. The figure
illustrates that higher degree of coverage is required if either required detection probability (α) or fault tolerance (β)
is increased. In Fig. 3(c) the experimental value of k is compared with the one obtained from Eqn. (14). The graph
represents close match with the theoretical solution and validates our analytically calculated k being the minimum. It
shows that at lower value of α, increasing k increases detection accuracy sharply, however, when accuracy approaches
very high value, increasing k does not bring any added advantage. Similarly Fig. 3(d) plots the relation between
optimal k and fault tolerance for a fixed detection probability. This also shows a closer match between theory and
simulation. This is because, while observing the eﬀect of k on fault tolerance (Fig. 3(d)), the detection probability (α)
is kept constant and the noises are drawn from the same distribution, i.e., the average noise components are constant.
But in case of k vs. detection probability with fixed fault tolerance, we let the noise components (sensing and communication noise) vary that makes it more sensitive to noise hence exhibits more change. It is also interesting to note
from Fig. 3(c) that the theoritical result matches simulation results more closely as k attains higher value. This means
very high accuracy at higher k ruling out inaccuracies and noise spikes in a more robust way.
Fig. 3(e) illustrates the trade-oﬀ between fault tolerance and detection probability. It shows that one has to be
sacrificed to achieve more of the other. Thus in case of coverage constraint, our model gives a clear assessment of
the trade-oﬀ between QoS parameters which will be useful to applications for deployment purpose. The figure also
shows that ‘3 out of 8’ rule has a better tolerance against fault than ‘5 out of 8’ rule. That is as the rule gets stricter ,
the robustness comes at the cost of compromising fault tolerance. Fig. 3(f) shows the eﬀect of degree of coverage k

Kh Mahmudul Alam et al. / Procedia Computer Science 4 (2011) 499–507
Kh Mahmudul Alam / Procedia Computer Science 00 (2011) 1–9

507
9

on latency. Increasing k yields higher latency. The reason is that, not all the sensors are able to send the data as soon
as they detect the event due to the contention condition. So the delay incurred due to the contention in MAC layer
is increased as k increases because of more competing nodes. The simulation shows slight deviation from theoritical
result as k gets higher (specially for k ≥ 10). This is because our simulation setup is dependent on the probabilistic
model presented in [7] that determines the required number of nodes to provide k-coverage and in that model the
probability of full coverage drops as k goes higher. So in simulation it can not guarantee full k coverage as k increases
and that is why the experimental latency deviates from the theoritical value as k is increased. This deviation is not
significant though, because in most real case scenarios, more than 10-coverage is not practical.

6. Conclusion
In this paper, we have presented a model for event detection WSNs to analytically determine the minimum kcoverage required to probabilistically guarantee a given set of QoS metrics, namely detection accuracy, fault tolerance
and latency taking the environmental noise, sensor faults, communication impairments and MAC induced delay into
consideration. Simulation results have revealed a close match between our theoritical model and the experimental
results. Adoption of this model will be useful in designing WSNs by determining appropriate deployment strategy
that satisfies QoS requirement of the application.
Since this is a deployment time method and changes in environment may necessitate changes in the required degree of coverage with time, our model may not provide adaptability which remains the focus of our future work. On
the other hand, being a design phase algorithm allows the flexibility of using high power oﬄine processing method
for modelling the deployment strategy.
References
[1] Carlos F., Pablo H., Joaquin G., and Jess A. “Wireless Sensor Networks and Applications: A Survey,” International Journal of Computer
Science and Network Security, 2007.
[2] Manolakos S, Logaras E and Paschos F, “Wireless Sensor Network Application for Fire Hazard Detection and Monitoring,” Springer Berlin
Heidelberg, ISBN:78-3-642-11869-2, pp 1-15, Feb. 16, 2010.
[3] Krishnamachari B., and Iyengar S. “Distributed Bayesian Algorithms for Fault-Tolerant Event Region Detection in Wireless Sensor Networks,” IEEE Transaction on Computers, vol. 53, no. 3, pp. 241-250, Mar. 2004.
[4] Luo X., Dong M., and Huang Y. “On Distributed Fault-Tolerant Detection in Wireless Sensor Networks,” IEEE Transaction on Computers,
vol. 55, no. 1, pp. 58-70, Jan. 2006.
[5] Fang J. and Li .,“Distributed Event Region Detection in Wireless Sensor Networks,” EURASIP Journal on Advances in Signal Processing,
2008.
[6] Li Y, Ai C, Vu C, Pan Y, and Beyah R , “Delay Bounded and Energy Eﬃcient Composite Event Monitoring in Heterogeneous Wireless Sensor
Networks,” IEEE Transactions on Parallel and Distributed Systems, vol. 21, no.9, pp. 1373-1385, 2010.
[7] Zaidi S. A., Hafeez M., McLernon D. C., and Ghogho M. “A probabilistic model of k-coverage in minimum cost wireless sensor networks,”
Proceedings of the ACM CoNEXT Conference, Dec. 09 - 12, 2008.
[8] Goldsmith, A. “Wireless Communications,” Cambridge University Press, ISBN-13: 9780521837163, pp. 172-180.
[9] Rhee I. , Warrier A., Aia M., Min J., Sichitiu M.L., “Z-MAC: A Hybrid MAC for Wireless Sensor Networks” ACM Transaction on Networking, vol.16, no.3, pp. 511-524, Jun. 2008.
[10] Zhou G., He T., Krishnamurthy S., and Stankovic J. A. “Models and solutions for radio irregularity in wireless sensor networks.” ACM
Transaction on Sensor Network, vol. 2, pp. 221262, 2006.
[11] Wang Y., Cheng K., and Tseng Y. “Using event detection latency to evaluate the coverage of a wireless sensor network,” Computer Communication, vol. 30, no. 14-15 , pp. 2699-2707, Oct. 2007.
[12] Zhu Y., Liu Y., Ni L.M., and Zheng Z., “Low-Power Distributed Event Detection in Wireless Sensor Networks,” 26th IEEE International
Conference on Computer Communications, pp.2401-2405, May 2007.
[13] Zhu Y., and Ni L.M. “Probabilistic Approach to Provisioning Guaranteed QoS for Distributed Event Detection,” The 27th IEEE International
Conference on Computer Communications, pp. 592-600, Apr. 2008.
[14] J T., Wang Y., Chang L. Y. , Duh D.R. , and Wu J. Y. , “Fault-tolerant decision fusion via collaborative sensor fault detection in wireless
sensor networks,” IEEE Transaction on Wireless Communication, Feb. 2008.
[15] Cortez P., and Morais. A., “A Data Mining Approach to Predict Forest Fires using Meteorological Data,” Proceedings of the 13th EPIA 2007
- Portuguese Conference on Artificial Intelligence, pp. 512-523, Dec. 2007.

