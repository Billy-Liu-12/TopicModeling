Procedia Computer Science
Volume 29, 2014, Pages 509–522
ICCS 2014. 14th International Conference on Computational Science

A comparative study of scheduling algorithms for the
multiple deadline-constrained workflows in
heterogeneous computing systems with time windows
1

Klavdiya Bochenina1
ITMO University, St. Petersburg, Russia
k.bochenina@gmail.com

Abstract
Scheduling tasks with precedence constraints on a set of resources with different performances is a
well-known NP-co mplete problem, and a nu mber of effective heuristics has been proposed to solve it.
If the start time and the deadline for each specific workflow are known (for example, if a workflow
starts execution according to periodic data coming fro m the sensors, and its execution should be
completed before data acquisition), the problem of mu ltip le deadline -constrained workflows
scheduling arises. Taking into account that resource providers can give only restricted access to their
computational capabilities, we consider the case when resources are partially available for workflow
execution. To address the problem described above, we study the scheduling of deadline -constrained
scientific wo rkflo ws in non-dedicated heterogeneous environment. In this paper, we introduce three
scheduling algorith ms for mapping the tasks of mu ltiple workflows with different deadlines on the
static set of resources with previously known free t ime windows. Simu lation experiments show that
scheduling strategies based on a proposed staged scheme give better results than merge -based
approach considering all workflows at once.
Keywords: deadline-constrained workflows, workflow scheduling, time windows

1 Introduction
Over the past decade, the problem of scheduling interrelated tasks in heterogeneous distributed
systems (such as grids and clouds) has gained particular attention due to the increased use of scientific
workflows in a variety of subject areas in conditions of continuous growth of available co mputing
power. Today there are a lot of static and dynamic scheduling approaches designed for different
combinations of workflows and resources properties (e.g., parallelism level, graph shape, data
interchange intensity, arrival patterns of tasks, homogeneity of processors’ performance and
communicat ion speed, on-demand resources accessibility). Goals of scheduling process are

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.046

509

A comparative study of scheduling algorithms...

Klavdiya Bochenina

determined based on both the selected infrastructure architectural concepts [1] (possibilities given by
resource providers) and customers’ requirements (QoS limitations).
In general, modern workflo w management systems operate under conditions of high
unpredictability both of workload and resource accessibility, which leads to the necessity to use
dynamic scheduling algorithms for virtualized environ ments. However, for problems in wh ich we
have good estimates of tasks’ execution times, exactly know the information about resource set
compound, available times of resources and mo ments when workflo ws start, it is advisable to use
static scheduling methods which can provide better schedules than dynamic ones due to taking into
account a workflow structure. The shining example of such a problem is a regular operating process of
an urgent computing system when periodically inco ming pieces of data should be processed using
workflow mechanis m without violating user defined deadline [2] (which can coincide with the
mo ment of receiving next chunk of data). For instance, this scheme is common ly used in urban flood
decision support systems [3], [4]. Typical modeling workflow consists of 5-25 tasks and can include
stages of meteorological data processing, simulat ion and prediction of sea level and wave parameters,
and various decision support scenarios. New instance of regular operating process is started every
several hours to obtain up-to-date forecast based on a recent data. Non-violat ing the deadline of th is
process guarantees a relevance of the results which is crucial for an effective flood prevention.
In normal operation mode the regular processes often use a specific static set of resources which
can be non-dedicated to workflows execution. At the same time, informat ion about available CPU
time windows can be provided in advance, i.e. if one reserves computational capacities for scientific or
educational purposes. Also, periodical nature of regular calcu lating process provides an opportunity to
gather a co mprehensive statistics about execution times of single tasks. In case of several processes
(each with its own data inco ming frequency and its own maximu m makespan) the scheduling problem
is to find a mapping of tasks to processors maximizing the efficiency of resource utilizat ion while
meeting all workflows deadlines (and maybe some other users ’ constraints).
The contributions of this paper are as follows: 1) fo rmulat ion of the scheduling problem (shortly
described above); 2) development of three algorith ms for scheduling of multip le deadline-constrained
workflows in heterogeneous platforms with time windows; 3) simulat ion experiments on the sets of
synthetic workflo ws to compare the effect iveness of these algorithms according to the proposed
metrics.

2 Related works
Over the past decade, there have been proposed a lot of algorithms in the area of single deadline constrained workflow scheduling. Most of these algorithms are designed to solve the problem of
minimizing the workflow execution cost/makespan while respecting their service level agreements
(SLAs) to ensure the QoS co mpliance, and moreover they are focused on dynamic resource allocation
using virtual machines. Bossche et al.[5] and Genez et al. [6] described the formu lation of th is
problem in terms o f integer linear programming and proposed a set of heuristics to solve it. Similar
problem statement can be found in [7], where authors introduced an SCB (Server Count Bound)
heuristic to find the minimu m resource count which is required to execute workflow without violating
the deadline. Yu et al. [8] studied single workflow scheduling with time and cost constraints and
proposed a genetic algorith m based on heuristic for minimizing execution t ime while meeting user’s
budget constraints. Zheng and Sakellariou [9] proposed a heuristic BHEFT as an extension of HEFT
algorith m for market -oriented environ ments with non-dedicated resources. In the paper [10] authors
introduced a novel single wo rkflo w scheduling algorithm PEFT wh ich outperforms well-known listbased heuristics in terms of makespan, efficiency and frequency of best results.
Many researchers use the idea of assigning sub-deadlines to individual tasks (if we meet all the
sub-deadlines, we will automat ically meet the whole workflow deadline). Yu et al. [11] and Yuan et

510

A comparative study of scheduling algorithms...

Klavdiya Bochenina

al. [12] suggested to group the tasks according to their level (i.e., path length fro m the input task) and
to find a schedule meeting group deadlines ( Deadline Top Level, DTL and Deadline Bottom Level,
DBL algorith ms). Scheduling method proposed in [13] is also based on tasks grouping. Wang et al.
[14] developed a heuristic algorithm Deadline Early Tree (DET), where tasks of critical path are
scheduled using dynamic programming. Determination of the certain tasks deadlines is usually
produced using one of two approaches: 1) providing the earliest starting time and latest finish time
using the network planning methods , 2) setting the deadlines proportional to the computational
complexity o f tasks. Thus, the Partial Critical Path (PCP) algorithm [15] in itially finds the deadlines
for the critical path tasks, and then uses a recursive procedure to set other tasks’ deadlines. Later two
modifications, IC-PCP and IC-PCPD2, has been developed in [16].
Only few studies have considered mu ltip le workflo ws scheduling problem. As showed in [17],
there are two main approaches to schedule a set of workflo ws: 1) merging the tasks of all workflo ws
into a single composite workflo w and applying any single workflow sched uling algorith m (e.g., SOT
(Serve on Time algorithm)[18]); 2) ordering single workflows according to some metric and then
scheduling it consequently (e.g., FPFT/FPCT (Fairness Policy based on Fin ishing/Concurrent Time)
algorith ms [19]). Mao et al. [20] proposed an algorithm to minimize the multip le workflows’
execution cost while meeting the deadlines, intended for scalable virtualized co mputational
environment. In [21] there is proposed an approach to cost- and deadline-constrained scheduling of
ensembles of inter-related workflows in ‘resources-on-demand’ cloud environment.
For scientific workflow scheduling on partially available resources with preliminary reserved time
windows, Luo et al. [22] proposed three algorith ms for single data-parallel workflo ws (exact branchand-cut based and two heuristics, MHEFT-RSV and MHEFT-RSV-BD).
To the author’s best knowledge, develop ment of mu ltiple deadline-constrained workflows’
scheduling algorith m on heterogeneous platforms with predefined time windows is still an open
research problem, and no conclusive results have been reported in the literature on this topic.

3 Multiple deadline-constrained workflows scheduling with
time windows: problem formulation
Scientific workflows typically use two types of parallelis m which can be exp loited to get a higher
benefit fro m the large computing power [23]: task parallelism (when different tasks of a particular
workflow can be executed concurrently) and data parallelism (when each task can be executed on
more than one processor at the time). Task-parallel workflows are usually represented as DA G
(Directed Acyclic Graph) while mixed (task and data parallel) applicat ions use PTG (Parallel Task
Graph) model. In this paper we consider DA G representation of wor kflows with non-preemptive tasks,
so one task can be executed only on one processor without suspending and migrating to other
processor. Thus, each workflow in the set WFSet can be represented as a graph

Vi , Ei , i

1, NWF where NWF – number of workflows in WFSet , Vi ^1,...,Npi ` – indexes of
tasks of i -th workflo w, Nti – number of tasks of i -th workflow, Ei eij | i, j Vi uVi – a set of
WFi

^

`

edges representing links between workflow tasks. WFSet is a set of tasks Taskij , i 1, NWF , j
Each task can be executed on some set of resource types RTijk , k

1, Nrtij

1, Nti .

( Nrtij is number of

resource types for j -th task of i -th workflow). Also, estimates of execution times

tijk are known for

each possible comb ination of task and resource type. This estimates can be obtained by preliminary
profiling, handling data fro m p revious runs or using parametric performance models of particular tasks

511

A comparative study of scheduling algorithms...

Klavdiya Bochenina

[24]. If performances of particular resources (in FLOPS) and FLOP count for each task are specified,
we can use this information to calculate approximate estimates.
Given a co mputer platform that consists of N R resources related to different N T resource types
(where NRi , i 1, NT – number of resources of i -th resource type). Different resources are assigned to
one resource type, if they have the same technical characteristics (processors/cores count, RAM size)
and there is a high-speed network connection between them. In this work we assume that given
workflows are not communication-intensive, so we can neglect a data transfer time.
Let T be the length of planning period. All workflows have the known start times

tbegini ,0 d tbegini d T and deadlines deadlinei , tbegini d deadlinei d T where i 1, NWF . The simp lest
way to measure the efficiency of resources utilization is to find a ratio of time occupied by scheduled
tasks to initially available t ime. In this case, time intervals with the same length have the same value
of objective function regardless of these placements. We consider more sophisticated case when
effectiveness of resource usage is characterized by utility function g W  which reflects preferred

t
 >0;1@ – normalized time). If we assume that the maximu m resource utilization
T
level is equal to 1, and all resources have the same utility function, then
loading time ( W
1

1

³ g W dW

NR

¦ Nproc

0

,

(3.1)

i

i 1

where Nproci – number of processors for i -th resource type. Total efficiency of resource

utilization for resource type Ri in the period >W 1 ;W 2 @ is
e
Nproci Intij W ijk

¦ ¦ ³ g W dW ,

W Ri ,W 1 ,W 2 

(3.2)

j 1 k 1Wb

ijk

Int ij W 1 ,W 2  – number of intervals occupied by scheduled tasks for j -th processor of

where Int ij

b
e
,W ijk
i -th resource type in the period >W 1 ;W 2 @ , W ijk
– beginning and end of the k -th interval.

In this work we use a simple decreasing linear function as utility function:
2
g W  R
 1  W  .
i

¦ Nproc

(3.3)

i

i 1

So, for the same resource type, the earlier is the start time of a particu lar task, the greater is the
corresponding resource utilization.
The goal of scheduling is to maximize the overall resource utilizat ion level for a given period
>0; T @ without violating deadlines of workflo ws ( tend i is a fin ishing time for i -th workflo w in the
obtained schedule):
Nr

W

¦W R ,0,1 o max ,
i

(3.4)

i 1

Wfi , i 1, NWF tend i d deadlinei .

512

(3.5)

A comparative study of scheduling algorithms...

Klavdiya Bochenina

4 Considered scheduling algorithms
As we mentioned before, there are t wo main approaches to multiple wo rkflo ws scheduling (the one
is based on merg ing all tasks into a big workflow, and the other takes into account affiliat ion of tasks
to workflows). Our hypothesis is that in the case of deadline-constrained workflows the second
approach should give better results since it becomes possible to consider the particular deadlines. To
check it, we have developed algorithms imp lementing merge-based and workflow-based approaches.
Note that they both should use some additional algorithm for a single workflow scheduling.

4.1 Single deadline-constrained workflow scheduling algorithm for
heterogeneous resources with time windows
Since violat ion of the deadline is undesirable, the purpose of an algorithm is to maximize the time
between actual workflow co mp letion and its deadline (on the other hand, increasing this marg in allo ws
to increase the possibility of meeting the deadline if some tasks finish their execution later than
planned). More formally, the scheduling goal for a g iven Wfi , i 1, NWF is to maximize



  where tend Pij  is the fin ishing time of

deadlinei  max tend Pij
j

j -th task. There are a lot of well-

known and efficient algorithms for min imizing the makespan of workflow execution on a set of
heterogeneous resources (such as HEFT and PEFT[10]). In this work we propose list-based heuristic
SimpleSched which is similar to those algorithms due to basic steps (prioritizing and assigning tasks to
workers). The main d ifference is that we use the value of deadline while building a queue of tasks. It is
crucial to consider the deadlines of particular workflo ws in the algorith m because our merge-based
approach is based on scheduling tasks from d ifferent workflows at once, and priority of the task
should reflect accu mu lated execution time (or co mputational cost) as well as required finishing time of
the workflow.
Then, SimpleSched heuristic consists of the following steps:
1) Determination of a tentative latest finishing time (sub-deadline) for each task;
2) Creation of a priority queue of tasks considering sub-deadlines and tasks’ precedence
constraints;
3) Mapping each task fro m queue to the resource which provides the earliest finishing time for its
execution.
If estimation times t ijk are g iven, evaluation of latest fin ishing times can be done by network
analysis methods (note that if the minimu m earliest fin ishing time is greater than the given deadline,
workflow cannot be finished in time). Consider the case when we have information about resources
performance and FLOP count for each task.
Let LFT i  be the latest finishing time of i -th task of a given workflow, calci  – computational
cost of i -th task (in FLOP), amount i  – maximu m accu mu lated computational cost from initial task

to i -th task (including its own cost), ini  and out i  – sets of input/output indexes of tasks for i -th
task. Then defining the sub-deadlines for all tasks can be described as follows ( used is a set of task
indexes with already calculated values of amount , linked is a list of tasks for which at least one of its
input tasks is in used set, linked used  ). The description of the algorith m fo r calculating the subdeadlines for all tasks of a single workflow is given in Table 1.
1. used ^i : ini  ` , linked ^ j : i  used , j  out i ` .
2. i  used amount i  calci  .
3. While linked z  repeat steps 4-6.
4. current linked 0 .

513

A comparative study of scheduling algorithms...

5. linked m linked \ current .
6. If incurrent   used , amount i 

Klavdiya Bochenina

max

amount  j   calci  ,

jincurrent

used m used  current ,

i  out current  , i  linked linked m linked  i . Else linked m linked  current .



7. Find i * such that j  used amount i * t amount  j  .



8. LFT i *

deadline .

9. i  used , i z i * LFT i 

amount i 

   deadline .

amount i *

Table 1. Algorithm for calculating the sub-deadlines of workflow tasks by their computational costs

When the latest finishing times are calculated, tasks are placed in priority queue in ascending order
of its sub-deadlines (it is also necessary to take into account that package should not be scheduled
before any of its input packages). After construction the queue packages are ma pped consequently.
Let EST Taskij max tend pred Taskij be the earliest possible start time of i -th task of the j -



>





@



th workflo w as a maximu m finishing time of its already scheduled predecessors, and
EST Taskij , Rk t EST Taskij – the earliest start time of this task on the k -th resource type









considering actual busy time windows. The task assigns to the resource Rk * which provides earlier



finishing time for it ( Rk* : EFT Taskij , Rk*



> 



@

min EST Taskij , Rk  tijk ).
k

In fact, the merge-based algorithm is SimpleSched heuristic (described above) applied to workflo w
constructed from all available packages. Since packages belonging to different workflo ws are not
lin ked, one can calculate sub-deadlines independently for each particular workflow, and then merge all
packages into queue. So, merge-based algorithm imp licit ly takes into account workflo w deadlines by
primarily scheduling tasks with earlier sub-deadlines, but in a situation when several tasks of different
workflows have similar LFTs and compete for resources (due to their lack) it provides no guarantees
that resources will be given to packages which workflow has earlier deadline.
To illustrate previously mentioned statement about necessity of taking into account the deadlines
while prioritizing the tasks of multiple workflows at once, we consider the example listed below.

Figure 1. Test example (2 workflows). Notation: a/b (c),
a - time of execution on R1, b - time of execution on R2, с - average execution time

514

A comparative study of scheduling algorithms...

Klavdiya Bochenina

Assume that we have two workflows as shown at Figure 1, and a set of 3 resources (1 resource of
type 1 (R1), and 2 resources of type 2 (R2)). Let’s co mpare the results of HEFT (without taking into
account the communication costs) and SimpleSched algorithms.
Table 1 shows the ranks of tasks according to HEFT algorith m an d LFTs of tasks according to
SimpleSched. The ranks for HEFT are calculated using the formula:

rank Taski  wi 

where wi

max

jsuccTaski 





rank Task j ,

(4.1)

ai  bi
– an average execution time of i -th task.
2

Task index
Workflow 1
1
2
3
4
Workflow 2
5
6
7

Rank (HEFT)

LFT (SimpleSched)

20.5
15
16.5
9

3.9
9.7
11.2
20

15
10
3

4.3
10.4
13

Table 1. Values of prioritization criteria for HEFT and S impleS ched

Due to Tab le 1, the o rder o f assigning the tasks to processors will be: i) for HEFT: 1, 3, 5, 2, 6, 4,
7; ii) for SimpleSched – 1, 5, 2, 6, 3, 7, 4.
The results of assigning the tasks to processors with earliest finishing time for each task are
summarized on Figure 2.

Figure 2. S impleS ched vs HEFT for the sets of deadline-constrained workflows

For the test examp le HEFT p rovides the schedule where Task6 and Task7 vio late the deadline, and
Simp leSched gives the schedule without violating the deadline. At the same t ime, makespan for
workflow 1 increases in case of SimpleSched only by 1 time unit wh ile workflow 2 reduces its
makespan by 4 time units in comparison with HEFT.
If we suppose that overall nu mber of workflows is n , and each workflow contains m tasks, the
computational complexity of SimpleSched will be Om  n  .

515

A comparative study of scheduling algorithms...

Klavdiya Bochenina

4.2 Stage-based approach to a multiple deadline-constrained workflow
scheduling with time windows
The main idea of the second approach is to consider workflow deadlines as much as possible. If
one is going to schedule mult iple workflows consequently, one should know the order in which
workflows will take access to resources selection (in other words, it is necessary to prioritize
workflows). The most obvious solution of the problem is to assign priorit ies according to its deadlines.
This approach does not seem to be the best for several reasons including possible presence of multip le
workflows with the same or similar deadlines which have considerably different computational
complexities and/or starting times.
Suppose that we are given prioritization criteria, i.e. a certain metric applicable to workflo w
schedule which extreme value is used to choose a workflow fo r resource allocation. The main concept
of stage-based approach is that scheduling procedure consists of several steps (by number of
workflows), and each step involves a choice of one workflow in accordance with prio rit ization criteria,
scheduling it and fixing busy time windows on selected resources. In ordered scheme, a particular
workflow can be scheduled with any algorithm for minimizing makespan of a single workflow (i.e.,
HEFT). There is only one restriction that selected algorithm s hould assign the tasks to the processors
with consideration of reserved time windows.
Let Scheduled be the set of workflo ws’ numbers that were already scheduled, Unscheduled – the
set of workflo ws’ nu mbers that require scheduling, Intervals – current set of resources’ busy
intervals, Schedulei Intervals  – schedule for i -th workflow taken by single workflow scheduling

algorith m for current time windows, PrioritySchedulei  – value of prio rit ization criteria of Schedulei
. Assume that workflo w selection is carried out according to minimu m priorit ization criteria value.
Then an algorithm imp lementing stage-based approach (it is denoted as StagedScheme) can be
described as follows.
1. Scheduled  , Unscheduled  , Intervals m Intervals init , where Intervals init is in itial
busy time windows.
2. For all Wfi , i 1, NWF Unscheduled m Unscheduled  i .

3. For all i Unscheduled get the schedule Schedulei Intervals  .

4.Find i

*

^i : i z j PrioritySchedulei  d PrioritySchedule j ` where i, j Unscheduled .

5. Scheduled m Scheduled  i * , Unschedule d m Unschedule d \ i* .
6. Intervals m Intervals  Schedulei* .
7. Repeat steps 3-6 while Unscheduled z  .
Table 2. The StagedS cheme algorithm for a multiple deadline-constrained workflows scheduling with
time windows

If we suppose that computational co mplexity of scheduling one workflow of m packages is Om ,
and we should schedule n workflows of m packages, the computational complexity of StagedScheme
is Om  n  Om  n  1  ... Om 1 Om 

n

¦i
i 1

516

Om 

n  n  1
~ O m  n2 .
2





A comparative study of scheduling algorithms...

Klavdiya Bochenina

5 Simulation technique
To study the effectiveness of proposed scheduling algorithms we have generated synthetic test data
which parameters and values are summarized in Tab le 3. The goal of the simulation was to compare
the merge-based and ordered schemes under the circumstances of wide variance of number of
workflows and tasks on the static set of resources. This approach can show us the main tendencies in
behavior of studied algorithms by fixing the parameters of resources and varying the amount of
computations and the partition of these computations into workflows and tasks.
Workflows’ test examples were obtained with DA GGEN workflow generator wh ich allows us to
generate random graphs of tasks with different shapes of graphs. The most important parameters
affecting the shape of the graph are width (maximu m nu mber of tasks that can be executed
concurrently), density (number of dependencies between tasks of consecutive graph levels), regularity
(regularity of the d istribution of tasks between the d ifferent levels) and ju mp (maximu m nu mber of
levels spanned by task communicat ions). Obtained test examp les were supplemented with the values
of package co mputational cost wh ich were chosen so that on a particular set of resources one package
has execution time in the range of 300-43200 sec. To receive test examples of resources we
implemented a resource generator which provides sets of non-dedicated resources with heterogeneous
processors performances. We’ ve chosen so high level of heterogeneity of resources (ten times
difference as a maximu m) because modern systems often include not only CPUs but GPUs as
computing devices, and inequality of performance parameters of these devices can be significant.
Parameter name
Workflows parameters
Workflows count
Task computational cost (GFLOP)
Number of tasks per workflow
Width of the DAG
DAG density
DAG regularity
DAG jump
Resources parameters
Processor performance (GFLOPS)
Part of non-dedicated time per processor
Non-dedicated intervals count per processor
Number of resources types
Number of resources per resource type
Number of processor per resource

Possible values
25; 50; 75; …; 400
15000-216000
5; 20; 50
0.1; 0.2; 0.8
0.2; 0.8
0.2; 0.8
1, 2, 4
5-50
0.25; 0.5; 0.75
0-3
1; 2; 4; 8
1; 2; 4; 8; 16
1; 2; 4

Table 3. Parameters of S ynthetic Test Data

Estimation of comparative efficiency of algorithms was made by the calculation of several metrics:
1. Average reserved time
N WF

¦ reserve _ time

i

Rtime

i 1

NWF

where reserve _ timei

,

(5.1)

­0, deadlinei d tend i
.
®
¯deadlinei  tend i , deadlinei ! tend i

2. Violated deadlines per number of workflows in the set.
3 Loading efficiency

517

A comparative study of scheduling algorithms...

Eff


,
W Intervals free 

W Intervals busy

Klavdiya Bochenina

(5.2)

where Intervals busy – time windows used by workflows, Intervals free – initial free time windows.
4. The execution time of algorithm.
Each set of experiments was carried out for a specific number of tasks per workflow (fo r examp le,
20) and different number of workflows (fro m 25 to 400). Each workflow set included appro ximately
the same number of workflo ws for d ifferent DA G widths. Deadlines of all workflo ws were equal to
the end of planning period. All experiments were performed on the same set of resources (8 resource
types, 16 resources per type, 4 processors per resource, part of non -dedicated time per processor –
0.25) to get the most precise estimates of execution times of the algorithms.
Each experiment was carried out twice for t wo different planning periods. First length of the period
(denoted as ‘wide’ makespan) has been selected so that all workflows in maximu m set (i. e. 400
workflows) could finish execution without violating the deadlines. To limit a wide makespan, we
suppose that loading efficiency should be at least 0.8 for the maximu m workflo ws’ set. Experiments
with wide makespan were used to estimate average reserved times and loading efficiencies. Secon d
planning length of the period (denoted as ‘tight’ makespan) was taken as 75% fro m wide makespan. It
has been used to estimate the part of violated deadlines per workflow count.

6 Simulation results
We denote the studied algorith ms as follows: 1) Merge-based – an algorith m imp lementing mergebased approach; 2) MaxReserved – an algorith m imp lementing the staged scheme and using maximu m
reserved time as a priorit ization criteria; 3) MinEff – an algorith m imp lementing the staged scheme
and using minimu m efficiency as a prioritizat ion criteria. All three algorith ms use SimpleSched for a
single workflo w scheduling. Since a single set of experiments was carried out for a particular number
of tasks per workflow, we use this value to denote the set (for example, MaxReserved 20).
In Figure 3 we show a ratio o f the average reserved time (wh ich was calcu lated using (5.1)) to the
makespan. Note that in all cases MinEff provides better reserved times than two other algorith ms,
especially for the set of 5-tasks workflo ws where its maximu m advantage is up to 13%. Merge-based
algorith m shows the lowest values and faster decrease of reserved time than stage-based algorithms in
all sets of experiments.

Figure 3. Ratio of the average reserved time to makespan

518

A comparative study of scheduling algorithms...

Klavdiya Bochenina

Figure 2 shows the efficiencies taken for a wide makespan. Staged -based algorithms demonstrate
near efficiencies for all experiments (except M inEff 5). Maximu m advantages for MaxReserved
algorith m in co mparison with Merge-based is respectively 6,79% for 5-tasks sets, 6.36% for 20- tasks
sets and 14.91% for 50- tasks sets. Note that on both figures described above maximu m d ifferences
between algorithms appear for experiments with number o f workflo ws more than 200. It can be
explained by the fact that the increase of number of workflows (with the same resource set) leads to
the increase of competition for resources.

Figure 4. Efficiencies for wide makespan

Figure 5 shows the ratio of v iolated deadlines to wo rkflo ws count for a 50- tasks test set for a t ight
makespan. Merge-based algorithm demonstrates absolutely the worst results with maximu m
disadvantage equal to 32,8% and average disadvantages equal to 19,28% for MaxReserved and 15,2%
for MinEff. Efficiency estimates have shown that loading for 275 workflows (and higher) was more
than 95% for staged-based algorithms. It explains a sharp rise of the metric beginning at that point
(there were no mo re available time slots). We should note that loading efficiency of Merge-Based was
in average 10% less than of both MaxReserved and MinEff (despite the fact that it had more
unscheduled tasks).

Figure 5. Ratio of violated deadlines to number of workflows for a tight makespan

519

A comparative study of scheduling algorithms...

Klavdiya Bochenina

Finally, Figure 4 shows the comparison of algorith ms runtimes. Our experiments confirmed the
estimates of computational complexity given in Section 4. Maximum execution times are:
for 400 5-tasks workflows: Merge-Based – 0.272 sec; average stage-based – 16,33 sec;
for 400 20-tasks workflows: Merge-Based – 1.338 sec; average stage-based – 55,75 sec;
for 400 50-tasks workflows: Merge-Based – 5.148 sec; average stage-based – 223,56 sec.

Figure 6. Execution times of algorithms

7 Conclusions and future work
In this paper we introduced an algorithm for a single deadline-constrained workflo w scheduling for
heterogeneous platforms with time windows and a staged scheme for a mu ltip le deadline -constrained
workflow scheduling. We run a series of experiments based on synthetic test examples in order to
analyze and compare three proposed scheduling strategies in accordance with four metrics.
Simu lation results indicate that the staged-based approach shows better results than merge-based
for all schedule quality criteria (average reserved time, efficiency and meet ing the deadlines).
However, when co mputing environment is relat ively free, we can use a merged -based algorithm due to
its linear computational complexity and close to stage-based results.
Future work in this area might include the improvement of propo sed scheduling formulat ion and
algorith ms considering the account costs of data transfer between the resource types and presence of
data-parallel tasks. We aim to work out a fast rescheduling algorithm which should be applied in case
of delay and tasks’ fa ilu res, as well as to study the influence of the chosen prioritization criteria on the
quality of obtained schedules. Also, the authors plan to embed the developed algorith ms in a
scheduling system of CLAVIRE [25] e-Science infrastructure platform.
This work was financially supported by Government of Russian Federation, Grant 074-U01.

References
[1] S. V. Kovalchuk, P. A. Smirnov, S. V. Maryin, T. N. Tchurov, and V. A. Karbovskiy, “Dead line driven Resource Management within Urgent Co mputing Cyberinfrastructure,” Procedia Comput.
Sci., vol. 18, pp. 2203–2212, Jan. 2013.

520

A comparative study of scheduling algorithms...

Klavdiya Bochenina

[2] A. V. Boukhanovsky and S. V. Ivanov, “Urgent Co mputing for Operat ional Storm Surge
Forecasting in Saint-Petersburg,” Procedia Comput. Sci., vol. 9, pp. 1704–1712, Jan. 2012.
[3] V.V. Krzhizhanovskaya, N.B. Meln ikova, A.M. Chirkin, S.V. Ivanov, A.V. Boukhanovsky,
P.M.A. Sloot. "Distributed simulat ion of city inundation by coupled surface and subsurface
porous flow for u rban flood decision support system". Procedia Computer Science, V. 18, pp.
1046-1056, 2013. http://dx.doi.org/10.1016/j.procs.2013.05.270
[4] S. V. Ivanov, S. S. Kosukhin, A. V. Kalu zhnaya, and A. V. Boukhanovsky, “Simu lation -based
collaborative decision support for surge floods prevention in St. Petersburg,” J. Co mput. Sci., vol.
3, no. 6, pp. 450–455, Nov. 2012.
[5] R. Van den Bossche, K. Van mechelen, and J. Broeckhove, “Cost -Optimal Scheduling in Hybrid
IaaS Clouds for Dead line Constrained Workloads,” 2010 IEEE 3rd Int. Conf. Cloud Comput., pp.
228–235, Jul. 2010.
[6] T. A. L. Genez, L. F. Bittencourt, and E. R. M . Madeira, “Workflow scheduling for SaaS / PaaS
cloud providers considering two SLA levels,” 2012 IEEE Network Operations and Management
Symposium. Ieee, pp. 906–912, 2012.
[7] H. Moens, K. Handekyn, and F. De Turck, “Cost-Aware Scheduling of Deadline-Constrained
Task Workflows in Public Cloud Environ ments,” in Integrated Network Management, 2013, pp.
68–75.
[8] J. Y. J. Yu and R. Buyya, “A budget constrained scheduling of workflow applications on utility
Grids using genetic algorithms,” 2006 Work. Work. Support Large-Scale Sci., pp. 1–10, 2006.
[9] W. Zheng and R. Sakellariou, “Budget-Deadline Constrained Workflow Planning for Ad mission
Control,” J. Grid Comput., vol. 11, no. 4, pp. 633–651, May 2013.
[10] H. A rabnejad and J. G. Barbosa, “List Scheduling Algorith m for Heterogeneous Systems by an
Optimistic Cost Table,” IEEE Trans. Parallel Distrib. Syst., vol. 25, no. 3, pp. 682–694, Mar.
2014.
[11] J. Yu, R. Buyya, and C. K. Tham, “Cost-based Scheduling of Scientific Workflow Applicat ions
on Utility Grids,” in Proceedings of the First IEEE International Conference on e-Science and
Grid Computing, 2005, pp. 140–147.
[12] Y. Yuan, X. Li, Q. Wang, and Y. Zhang, “Bottom Level Based He uristic for Workflow
Scheduling in Grids,” Chinese J. Comput., no. 31, pp. 282–290, 2008.
[13] A. Verma and S. Kaushal, “Deadline and Budget Distribution based Cost - Time Opt imization
Workflow Scheduling Algorith m for Cloud,” in International Conference on Recent Advances
and Future Trends in Information Technology2, 2012, pp. 1–4.
[14] Q. Wang, X. Zhu, X. Li, and Y. Yuan, “Dead line d ivision-based heuristic for cost optimization in
workflow scheduling,” Inf. Sci. (Ny)., vol. 179, no. 15, pp. 2562–2575, Jul. 2009.
[15] M. Naghibzadeh and S. Abrishami, “Deadline-constrained workflo w scheduling in software as a
service Cloud,” Sci. Iran., vol. 19, no. 3, pp. 680–689, Jun. 2012.
[16] D. H. J. Epema, M . Naghibzadeh, and S. Abrishami, “Deadline-constrained workflow scheduling
algorith ms for In frastructure as a Service Clouds,” Futur. Gener. Comput. Syst., vol. 29, no. 1,
pp. 158–169, Jan. 2013.
[17] A. Hirales-Carbajal, A. Tchernykh, R. Yahyapour, J. L. Gon zález-García, T. Röblitz, and J. M.
Ramírez-Alcaraz, “Mult iple Workflow Scheduling Strategies with User Run Time Estimates on a
Grid,” J. Grid Comput., vol. 10, no. 2, pp. 325–346, Mar. 2012.
[18] L. Zhu, Z. Sun, W. Guo, Y. Jin, W. Sun, and W. Hu, “Dynamic mu lti DA G scheduling algorithm
for optical grid environment,” in Network Architect, 2007, vol. 6784, p. 67841F–67841F–11.
[19] H. Zhao and R. Sakellariou, “Scheduling Mult iple DA Gs onto Heterogeneous Systems,” in
Parallel and Distributing Processing Simposium, IPDPS’06 , 2006, p. 14.
[20] M. Mao and M. Humphrey, “Auto-scaling to minimize cost and meet application deadlines in
cloud workflows,” Proc. 2011 Int. Conf. High Perform. Co mput. Networking, Storage Anal. - SC
’11, p. 1, 2011.

521

A comparative study of scheduling algorithms...

Klavdiya Bochenina

[21] M. Malawski, G. Juve, E. Deelman, and J. Nabrzyski, “Cost- and deadline-constrained
provisioning for scientific workflow ensembles in IaaS clouds,” 2012 Int. Conf. High Perform.
Comput. Networking, Storage Anal., pp. 1–11, Nov. 2012.
[22] J. Luo, F. Dong, and J. Zhang, “Scheduling of Scientific Workflow in Non -dedicated
Heterogeneous Multicluster Platform,” J. Syst. Softw., vol. 86, no. 7, pp. 1806–1818, Jul. 2012.
[23] T. N’Takpe, F. Suter, and H. Casanova, “A Co mparison of Scheduling Approaches for M ixed Parallel Applications on Heterogeneous Platforms,” in Sixth International Symposium on Parallel
and Distributed Computing (ISPDC’07) , 2007, pp. 35–35.
[24] S. V Kovalchuk, P. A. Smirnov, K. V Knyazkov, A. S. Zagarskikh, and A. V Boukhanovsky,
“Knowledge-based Exp ressive Technologies within Cloud Co mputing Environ ments,” in 8th
International Conference on Intelligent Systems and Knowledge Engineering (ISKE2013) , 2013,
pp. 1–10.
[25] K. V. Knyazkov, S. V. Kovalchuk, T. N. Tchurov, S. V. Mary in, and A. V. Boukhanovsky,
“CLA VIRE: e-Science infrastructure for data-driven co mputing,” J. Comput. Sci., vol. 3, no. 6,
pp. 504–510, Nov. 2012.

522

