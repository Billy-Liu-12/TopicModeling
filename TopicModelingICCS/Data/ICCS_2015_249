Procedia Computer Science
Volume 51, 2015, Pages 954–963
ICCS 2015 International Conference On Computational Science

Multi-pheromone ant colony optimization for
socio-cognitive simulation purposes
Mateusz Sekara1 , Michal Kowalski1 , Aleksander Byrski1 , Bipin Indurkhya1
Marek Kisiel-Dorohinicki1 , Dana Samson2 , Tom Lenaerts3
1

AGH University of Science and Technology, Faculty of Computer Science, Electronics and
Telecommunications, Al. Mickiewicza 30, 30-962, Krakow, Poland
{sekara,mkowalsk}@student.agh.edu.pl, {olekb,bipin,doroh}@agh.edu.pl
2
Catholic University of Louvain, IPSY, Place Cardinal Mercier 10 bte L3.05.01 `
a 1348
Louvain-la-Neuve, Belgium, dana.samson@uclouvain.be
3
Universit´e Libre de Bruxelles, Campus de la Plaine, ULB CP212,
boulevard du Triomphe, 1050 Bruxelles, tlenaert@ulb.ac.be

Abstract
We present an application of Ant Colony Optimisation (ACO) to simulate socio-cognitive features of a population. We incorporated perspective taking ability to generate three diﬀerent
proportions of ant colonies: Control Sample, High Altercentricity Sample, and Low Altercentricity Sample. We simulated their performances on the Travelling Salesman Problem and
compared them with the classic ACO. Results show that all three ’cognitively enabled’ ant
colonies require less time than the classic ACO. Also, though the best solution is found by the
classic ACO, the Control Sample ﬁnds almost as good a solution but much faster. This study
is oﬀered as an example to illustrate an easy way of deﬁning inter-individual interactions based
on stigmergic features of the environment.
Keywords: Ant Colony Optimization, Metaheuristics, Psychology, Cognition

1

Introduction

Empathy is considered to be the warp across which the fabric of human society is woven [11].
One mechanism underlying empathy is being able to view a situation from another agents
perspective, which is termed as perspective taking. If we can model how perspective taking
inﬂuences individual agents’ behaviours in a society, and how macro-level social phenomena
emerge from their interaction, it would help us understand why some societies seem harmonious whereas others are conﬂict ridden. It can further help us devise strategies to reduce
conﬂicts. These models may also provide us in developing new optimisation strategies for
traditional computational problems, based on the assumption, that diversiﬁcation of computational agents and their behaviour, can lead to better exploration of the search space (similar
954

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.234

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

to such solutions as multi-deme and coevolutionary algorithms). At the same time, we aim
to experiment with diﬀerent computational models of perspective taking to study what sort of
macro-level behaviours emerge from them, and then seek to verify these behaviours through
psychological experiments in order to validate the models.
In recent years there has been an increasing synergetic interaction between biological and
cognitive systems on one hand and computational systems on the other. In one direction, for
instance, ant colonies, bird ﬂocks, bee swarms, hippocampus of a rat, and so on, have inspired
innovative computational algorithms. In the other direction, computational techniques have
been applied to understand and model how macro phenomena emerge through micro-level
interactions of individuals in a large group. The research being carried out by our group
straddles both these aspects.
Optimization heuristics, particularly biologically-inspired techniques, have been gaining attention for over 20 years. These approaches are supposed to be universal, though critics point
out high computation time and complexity of the algorithms. However, diﬃcult problems posing challenges to deterministic approaches call for alternative strategies of solving [18], and
these may justify the above-mentioned costs.
Ant systems have proven to be a popular tool for solving many discrete optimization problems, e.g. TSP (Traveling Salesman Problem), QAD (Quadratic Assignment Problem), VRP
(Vehicle Routing Problem), GCP (Graph Coloring Problem) and others [9]. In this paper, we
consider the ant system as a way to express socio-cognitive behaviours of a population of ants,
diﬀerentiating them into species and deﬁning their stigmergic interactions. Our main goal is
to simulate perspective taking during decision making, with the decision-making moment in
the world of ants being connected to choosing the subsequent path while standing in one of
the graph nodes. Thus, the ant system becomes a framework for analysing socio-cognitive interactions by introducing diﬀerent types of pheromones left by diﬀerent species, and deﬁning
particular behaviours of ants based on their detection of the concentrations of these diﬀerent
types of pheromone on the paths to be selected from. It is to note that besides ACO, other
stigmergic or quasi-stigmergic systems as Particle Swarm Optimization can be considered as a
starting point for simulations, and the objects of enhancement using proposed socio-cognitive
features.
The rest of the paper is organized as follows. First ACO and its selected variants are
shortly discussed, then socio-cognitive aspects relevant for simulations are shown. Then their
incorporation into ACO system is presented, experimental results are discussed and the paper
is concluded.

2

Ant Colony Optimization:
proaches

Classical and novel ap-

Ant System, introduced in 1991, applied to solve TSP, is considered to be a progenitor of
all ant colony optimization (ACO) algorithms [7]. Because the action of a certain ant during
one iteration is completely independent of the actions of other ants during any iteration, the
sequential ant algorithm can be easily parallelized.
The ACO algorithm is an iterative process during which certain number of ants (agents)
gradually create a solution [8, 9]. The problem being solved is usually depicted as a graph,
and the main goal of ants is to cross this graph somehow in an optimal way. Each move of
an ant consists in choosing a subsequent component of the solution (graph edge) with certain
probability. This decision may be aﬀected by the interaction among the ants based on the
955

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

existence of pheromones (according to stigmergy—i.e. communication using the environmental
properties for mediation among individuals instead of direct contact—rules proposed in [7])
that may be deposited into the environment (on the edges of the graph) and perceived by the
agents. The iteration process is ﬁnished when a feasible solution is created by all ants.
However, recently new interesting modiﬁcations of ACO-related techniques have been introduced, namely multi-type ACO [13, 17], allowing many species of ants and deﬁning their
stigmergic interactions (e.g. based on attraction to the pheromone of the same species and
repulsion from the other pheromones). Such algorithms were successfully applied to such problems as edge disjoint path problem [13] or light path protection [17].
There are other modiﬁcations of the classic ACO, such as hierarchical ACO, where additional
means of control are introduced to manage the output of particular ants (or ant species) [14].
In another approach, ants are endowed with diﬀerent skills (e.g. sight, speed) in order to
realize global path planning for a mobile robot [12]. In a successfull approach to solve TSP,
the authors propose to use two types of ants: classic and exploratory (creating “short routes”,
moving according to some predeﬁned conditions, e.g. near some selected cities, etc.) [10].
In [5], the authors introduce diﬀerent ant sensitivity to pheromones such that ants with
higher sensitivity follow stronger pheromone trails, while ants with lower sensitivity behave
more randomly. This model strives to sustain a balance between exploration and exploitation.
Taking inspiration from these approaches, especially the ones proposed by Now´e et al. [13]
(many species of ants with detailed stigmergic interactions) and by Chira et al. (diﬀerent
sensivity of the ants to the pheromones) [5] we propose a novel method of simulation and
analysis of socio-cognitive properties of individuals of a certain population. The population of
ants (and its application to TSP) is presented only an example to illustrate an easy way of
deﬁning inter-individual interactions based on stigmergic features of the environment.

3

Incorporating social and cognitive aspects

Two factors have contributed most to a rapid growth in this ﬁeld of social and cognitive simulations in recent years. One is the exponential increase in the computing power, which makes it
possible to simulate very large-scale multi-agent systems in reasonable time. The other is the
availability of a huge amount of quantitative data that traces the activities of individuals and
their interaction patterns in a society [6, 4]. For example, two recent active areas of research
are how norms [1] and fairness emerge in a society [15, 16].
We focus here on perspective taking, which refers to the ability of an agent to take another
agent’s point of view. Typically, this is taken to be a one-dimensional ability: the degree to
which an agent can take another one’s perspective. But some recent research has explored a
two-dimensional approach [2], where one distinguishes between the ability of an agent to handle
conﬂict between its own and the other agent’s perspectives, and the relative priority given to
these two perspectives. Experimental research has suggested that these two dimensions might
be independent; and factors such as guilt or shame aﬀect each of these dimensions individually.
Let us consider the following types of the individuals and their possible interactions:
• Egocentric individuals: they focus on their own perspective and can become creative by
ﬁnding their own new solutions to a given task. They do not get inspired by others’
actions (or the inspirations do not become a main factor of their work).
• Altercentric individuals: they focus on the perspective of others and thus follow the mass
of others. They are less creative but do end up supporting good solutions by simply
following them.
956

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

• Good-at-conﬂict-handling individuals: they get inspired in a complex way by the actions
of other individuals by considering the diﬀerent perspectives and choosing the best.
• Bad-at-conﬂict-handling individuals: they act purely randomly, following sometimes one
perspective, sometimes another without any inner logic.
The characterisation of the individuals within a population was based on realistic proportions of perspective taking proﬁles in humans. In recent work, it has been shown that the
proportion of altercentric, egocentric, good and bad perspective conﬂict handlers can ﬂuctuate
depending on situational factors. We choose three types of proportions found in humans: one
representing the proportion of perspective-taking proﬁles in a baseline condition (without manipulation of situational factors) and two types of proportion corresponding the eﬀects of two
situational factors with conﬂicting eﬀects on perspective taking, i.e. the eﬀects of guilt and
anger, which heightens and lowers, respectively, the proportion of altercentric individuals [3]:
• Control Sample (baseline proportions of diﬀerent types of perspective takers found in a
human sample): here the good conﬂict handlers are the major elements with a roughly
similar proportion of the three other types of perspective takers. Note that this is also
the sample with the highest proportion of egocentric individuals.
• Increased Good Conﬂict Handling Sample (proportions inspired from a sample of humans
induced to feel anger): here the proportion of good conﬂict handlers is further increased
compared to the control sample at the expenses of the altercentric and egocentric individuals whose proportion is now signiﬁcantly decreased compared to both other samples.
• Increased Altercentricity Sample (proportions inspired from a sample of humans induced
to feel guilt): the proportion of good conﬂict handlers and egocentric individuals is signiﬁcantly decreased and is compensated by a higher proportion of altercentric individuals
and to a lesser extent a higher proportion of bad conﬂict handlers.
The samples described do not exhaust all interesting possibilities and should be treated as a
starting point for further research.

4

Socio-cognitive ant colony optimization

Starting from the deﬁnition of classic ACO, one should consider optimization of a combinatorial
problem (e.g. to ﬁnd a Hamiltonian cycle in a graph as in Travelling Salesman Problem). The
method is based on agents, namely ants, that roam along the edges of the graph, ﬁnding the
exemplary cycles and leaving trails of pheromones behind them.

4.1

Classic ACO

In the classical ACO algorithm, the ants are deployed in a graph consisting of vertices V =
i, j, . . . ; i, j ∈ N and edges E, where each edge is associated with a cost of moving through
it. Each ant gets a randomly chosen starting graph node. Beginning from this node, the ant
constructs its cycle in step-by-step manner, by moving from one node to another, choosing the
next one and not coming back. While considering nodes to choose from, an ant has to compute
attractiveness for all possible paths that can be taken from the present node. The attractiveness
957

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

nij of the edge ij starting from a node i ant is standing on is transformed into probability by
a simple normalization:
nij
(1)
μij =
j nij
where j is computed only for the nodes that have not yet been visited by the ant.
Note that the exact values of nij being the attractivenesses computed for the next edges
constituting the constructed path will be given in details in the next paragraphs.
Finally, the ant randomly selects a path based on previously computed probability – paths
with higher attractiveness are more likely to be chosen. After visiting all nodes exactly once,
the ant ﬁnishes its trip and returns the found cycle as a proposed solution, and then retreats
depositing certain amount of pheromone on the path belonging to its current cycle. The amount
of pheromone deposited in an edge eij is denoted by πij and the deposition algorithm of ant ak
retreating along cycle cak is as follows:
πij ← πij +

πd
e∈ca cost(e)

(2)

k

where the default pheromone deposit πd is 1, and x means the x after assigning the new value,
eij denotes edge in the cycle and cost(eij ) : E → R is a certain function assignign the cost to
the edges.
However, the pheromone evaporates in each iteration (in each edge of the graph) according
to this formula:
πij = (1 − πe ) · πij
(3)
Default pheromone evaporation coeﬃcient πe is 0.01.
Classic ants consider both pheromone and distance while choosing their directions (by computing path attractiveness) in order to complete the cycle. So an ant standing at node i will
choose the next edge with a uniform probability, proportional to the following estimate:
nij =

(

eik ,k∈V (i) \{i}

cost(eik ))α

cost(eij )β

(4)

Default factors are, pheromone inﬂuence α = 2.0, distance inﬂuence β = 3.0, V (i) does not
include the vertices already visited by the ant when reaching the vertice i.

4.2

Multi-pheromone ACO

In socio-cognitive ACO, the idea of multiple pheromones is implemented by introducing diﬀerent ‘species’ of ants and enabling their interactions (similar to the approach presented in e.g.
[13]). The interaction is considered as a partial inspiration, or even perspective taking, realized
by a particular ant reacting to the decisions taken by the ants belonging to other species. This
is made possible by having the ants of diﬀerent species leave diﬀerent ‘smells’ (see Fig. 1).
Diﬀerent ants use diﬀerent rules (consider diﬀerent path’s properties) for computing attractiveness; and looking for inspirations or perspective taking, they utilize the smells of pheromones
left by other species in a predeﬁned way. Therefore diﬀerent species may be treated as organisms with selective smelling capabilities (subject to diﬀerent combinations of the present
smells).
Therefore, we divide the set of ants into following sub-species
958

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

vk
jk

(Y)

as

vl
(X)
ij =ij +

(Y)
 ij
(X)

ar

?

 jk

 jl

jl

vj

(X)

ij

(Y)

vi

ij

Figure 1: Multi-pheromone ACO setting
• EC – egocentric ants that are supposed to be creative in ﬁnding new solutions,
• AC – altercentric ants that simply follow the mass of other agents,
• GC – good-at-conﬂict-handling ants that get inspired by the actions of other ants,
• BC – bad-at-conﬂict-handling ants, that act randomly.
Moreover, diﬀerent ant species leave pheromones that ‘smell’ diﬀerent, so the pheromone left
at a particular edge is described as a sum of the following components:
(EC)

πij = πij

(AC)

+ πij

(GC)

+ πij

(BC)

+ πij

(5)

Therefore other ants may react to diﬀerent combinations of all the pheromones. Of course,
more species (and more pheromones) may be introduced into the system.
Now, based on this framework, details of the actions undertaken by various ant species are
formulated below.
Egocentric ants (elements of the EC set), are creative in trying to ﬁnd a new solution and
ﬁnding their own way. They are less caring for others and for pheromone trail. Thus, they
focus mostly on the distance as a way to determine their next directions. So an ant standing
at node i will choose the next edge with an uniform probability, proportionally to the following
fraction:
1
(6)
cost(eij )β
Default distance inﬂuence β = 3.0, again.
Altercentric ants (elements of the AC set), follow the mass of other ants (thus they focus
on the pheromone, not caring for the distance). So an ant standing at node i will choose the
next edge with a uniform probability, proportionally to the following expression:
α
πij

(7)

Default pheromone inﬂuence α = 2.0.
959

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

Good-at-conﬂict-handling ants (elements of the GC set) will wait and observe the others.
Thus, they care for all existing pheromones (the particular weights are to be determined experimentally). So an ant standing at node i will choose the next edge with a uniform probability,
proportionally to the following expression:
(EC)

14 · πij

(AC)

+ 2 · πij

(GC)

+ 2.5 · πij

(BC)

+ 0.5 · πij

α

(8)

Default pheromone inﬂuence α = 2.0.
Bad-at-conﬂict-handling ants behave impulsively (in eﬀect randomly), irrespective of the
pheromone or the distance. So an ant at node i will choose the next edge with a uniform
probability, proportionally to the following expression:
1

(9)

eik ,k∈V \{i}

5

Experimental results

The experimental results were obtained based on a dedicated software developed in Python1 ,
run on a typical desktop PC. We considered the Travelling Salesman Problem: based on ﬁnding
a Hamiltonian in a graph deﬁned by a network of cities, the goal is to look for a cycle with
minimum cost (distance). The particular instance tackled was taken from TSPLIB library2 .
During the experiments, the following compositions of the simulated populations regarding
the involvement of particular ants’ species were considered:
• Classic Ant Population: only ants acting as in classic ACO.
• Human-inspired sample populations:
– Control Sample Population: 22% egocentric, 15% altercentric, 45% good at conﬂict
handling, 18% bad at conﬂict handling.
– Increased Altercentricity Sample Population: 3% egocentric, 46% altercentric, 23%
good at conﬂict handling, 28% bad at conﬂict handling.
– Increased Good Conﬂict Handling Sample Population: 6% egocentric, 6% altercentric, 63% good at conﬂict handling, 25% bad at conﬂict handling.
These proportions were inspired by psycho-cognitive features observed in human populations.
In the future we plan also to identify optimal set of parameters for solving the given problem
(e.g. TSP).
The TSP instance considered was berlin52 (52 cities, best known solution: 7542).Each
simulation was repeated 12 times and average results with standard deviation were presented.
All computations were realized for 100 iterations of the algorithm using default input parameters
(described in section 4.2).
Fig. 2 shows the average ﬁtness (with standard deviations) obtained in subsequent iterations of the algorithm for diﬀerent population conﬁgurations considered (TSPLIB means the
1 www.python.org

2 http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/

960

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

best known solution of the problem). It is easy to see that though the classic ACO produces the
best solution, the Control Sample populations gives almost as good a result and much earlier
(even after about 10 iterations). The other interesting observation is the apparent premature
convergence of the other populations considered: both Conﬂict Handling and Altercentric conditioned populations are unable to move from some local extremum found during ﬁrst several
iterations. On some reﬂection, this is be expected, because in the Control Sample setting,
	
		

 
!"
!
#$%

	























	
















Figure 2: Average ﬁtness for diﬀerent populations, berlin52, 100 ants, 100 iterations
the major forces are good-at-conﬂict-handling ants and egocentric ants. The former ones take
the perspective of the latter ones, while the latter ones are specialized in solving the problem,
thereby leading to the observed result.
The results shown in Fig. 2 are summarized in Table 1 for diﬀerent numbers of ants considered. An interesting feature is that when the number of ants in a population is low (like
20), again the Control Sample population becomes the best. When there are more ants, other
populations prevail (mostly classic ACO).
Table 1: The best distances found by diﬀerent populations, berlin52, 100 iterations

Population
Classic Ants
Control Sample
Increased Conﬂict Handling
Increased Altercentricity

Path distance
20 ants 50 ants
8803.57 7902.11
7749.21 7958.52
9090.96 9361.58
9271.01 9934.18

100 ants
7628.06
7805.49
9390.11
9901.01

Best known
7542

In Table 2 a summary of the simulation times are given. It is easy to see that all ‘cognitive
enabled’ populations require less computing time than classic ACO. The reason for this is the
inclusion into these populations, ants that rely on perceiving other ants (e.g. altercentric ants
that compute their attractivenes very easily by following other ants, or bad-at-conﬂict-handling
ants that act purely randomly).
Some ﬁnal observations can be made looking at Fig. 3 that shows the best ﬁtnesses averaged
for Control Sample population. Bad-at-conﬂict-handling ants (acting purely randomly) turn
out to be the worst at solving of the problem; the egocentric ants are signiﬁcantly better,; but
good-at-conﬂict-handling ants are similar in their eﬃciency as the altercentric ones.
961

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

Table 2: Summary of computation times or diﬀerent populations, berlin52, 100 iterations
Computation time[s]
20 ants
50 ants
Avg Stdev
Best
Avg
50.88
0.64 120.07 123.09
41.98
0.35 101.07 103.98
42.91
0.42
95.03
97.18
39.96
0.40
89.61
93.08

Population
Classic Ants
Control Sample
Increase Conﬂict Handling
Increased Altercentricity

Best
51.85
41.49
42.50
39.40

Stdev
1.03
0.61
0.44
0.54

Best
232.64
196.00
189.22
178.43

100 ants
Avg Std
248.73
2.5
204.69
1.5
192.00
1.3
184.20
1.2

	
		






























	










Figure 3: Average ﬁtness for diﬀerent ant species in Control Sample

6

Conclusion

Diﬃcult problems require novel metaheuristics, so the search for new inspirations continues. Effective methods of computation may be conceived by observing socio-cognitive relations among
individuals: this was the inspiration for the research presented here. Surprisingly, our ﬁrst
research goal, namely the simulation of socio-cognitive phenomena in a population of computing ants, turned out to have an interesting side-eﬀect, namely eﬃcient handling of the tackled
problem in certain conﬁgurations. Our main result, namely prevailing of the Control Sample
population, can be considered as somewhat expected from the socio-cognitive point of view,
as in this setting the good-at-conﬂict-handling individuals mostly take the perspective of the
egocentric ants (which are quite good in solving the problem as it was perceived when observing
the eﬃciency of the work of diﬀerent species of ants) to get to the optimal solution. In the
future, we plan to expand the experiments by exploring diﬀerent parameters conﬁgurations,
keeping in mind how these parameters relate with the real-world socio-cognitive phenomena.
We plan to make the constructed environment publicly available, and further extend it to focus
on a more detailed simulation of perspective taking among agents.

Acknowledgments
This research received partial support from Polish-Belgian Joint Research Project (2015-2017),
under agreement between the PAN and FNRS: ,,Modelling the emergence of social inequality
962

Multi-pheromone ant colony optimization. . .

M. Kowalski et al.

in multi-agent systems” and from AGH University of Science and Technology statutory project
(no. 11.11.230.124).

References
[1] G. Andrighetto and R. Conte. Cognitive dynamics of norm compliance. from norm adoption to
ﬂexible automated conformity. Artiﬁcial Intelligence and Law, 20(4):359–381, 2012.
[2] H.B. Bukowski. What Inﬂuences Perspective Taking. PhD thesis, Catholic University of Louvain,
2014.
[3] H.B. Bukowski and D. Samson. Can emotions aﬀect level 1 visual perspective taking?
[4] L.-E. Cederman, R. Conte, D. Helbing, A. Nowak, F. Schweitzer, and A. Vespignani. Exploratory
of society. The European Physical Journal Special Topics, 214(1):347–360, 2012.
[5] C. Chira, D. Dumitrescu, and C.M. Pintea. Heterogeneous sensitive ant model for combinatorial optimization. In Proceedings of the 10th Annual Conference on Genetic and Evolutionary
Computation, GECCO ’08, pages 163–164, New York, NY, USA, 2008. ACM.
[6] R. Conte, N. Gilbert, G. Bonelli, C. Cioﬃ-Revilla, G. Deﬀuant, J. Kertesz, V. Loreto, S. Moat,
J.-P. Nadal, A. Sanchez, A. Nowak, A. Flache, M. San Miguel, and D. Helbing. Manifesto of
computational social science. The European Physical Journal Special Topics, 214(1):325–346,
2012.
[7] M. Dorigo and T. St¨
utzle. Ant Colony Optimization. Bradford Books, 2004.
[8] G. Di Caro Dorigo M. The ant colony optimization meta-heuristic. In D. Corne, M. Dorigo, F.
Glover, editors, New Ideas in Optimization, McGraw-Hill, 11-32., 1999.
[9] G. Di Caro & L. M. Gambardella Dorigo M. Ant algorithms for discrete optimization. Technical
report, IRIDIA/98-10, Universit Libre de Bruxelles, Belgium, 1999.
[10] A. Hara, S. Matsushima, T. Ichimura, and T. Takahama. Ant colony optimization using exploratory ants for constructing partial solutions. In Evolutionary Computation (CEC), 2010 IEEE
Congress on, pages 1–7, July 2010.
[11] M. Hoﬀmann. Empathy and moral development: The implications for caring and justice. Cambridge University Press, 2000.
[12] J.-W. Lee and Ju-Jang Lee. Novel ant colony optimization algorithm with path crossover and
heterogeneous ants for path planning. In Industrial Technology (ICIT), 2010 IEEE International
Conference on, pages 559–564, March 2010.
[13] A. Now´e, K. Verbeeck, and P. Vrancx. Multi-type ant colony: The edge disjoint paths problem.
In Marco et al. Dorigo, editor, Ant Colony Optimization and Swarm Intelligence, pages 202–213.
Springer, 2004.
[14] M. Rusin and E. Zaitseva. Hierarchical heterogeneous ant colony optimization. In Proc. of Federated Conference on Computer Science and Information Systems. 2012.
[15] S. Van Segbroeck, J.M. Pacheco, T. Lenaerts, and F.C. Santos. Emergence of fairness in repeated
group interactions. Physical Review Letters, 108.
[16] S. Van Segbroeck, J.M. Pacheco, T. Lenaerts, and F.C. Santos. Evolution of fairness and conditional cooperation in public goods dilemmas. In T. et al. Gilbert, editor, Pro. of the European
Conference on Complex Systems 2012, pages 827–830. Springer International Publishing, 2013.
[17] Peter Vrancx, Ann Now, and Kris Steenhaut. Multi-type aco for light path protection. In Karl
Tuyls, PieterJant Hoen, Katja Verbeeck, and Sandip Sen, editors, Learning and Adaption in MultiAgent Systems, volume 3898 of Lecture Notes in Computer Science, pages 207–215. Springer Berlin
Heidelberg, 2006.
[18] David H. Wolpert and William G. Macready. No free lunch theorems for optimization. IEEE
Transactions on Evolutionary Computation, 1(1):67–82, 1997.

963

