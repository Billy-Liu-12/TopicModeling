Using Sequential Debugging Techniques with Massively
Parallel Programs
Christian Schaubschl¨ager, Dieter Kranzlm¨uller, and Jens Volkert
GUP, Joh. Kepler University Linz
Altenbergerstr. 69
A-4040 Linz, Austria, Europe
schaubschlaeger@gup.uni-linz.ac.at

Abstract. Debugging is a crucial part of the software development process. Especially massively-parallel programs impose huge difficulties to program analyis
and debugging due to their higher complexity compared to sequential programs.
For debugging and analysing parallel programs there are several tools available,
but many of these fail in case of massively-parallel programs with potentially
thousands of processes.
In this work we introduce the single process debugging strategy, a scalable debugging strategy for massively-parallel programs. The goal of this strategy is to
make debugging large scale programs as simple and straight-forward as debugging sequential programs. This is achieved by adapting and combining several
techniques which are well known from sequential debugging. In combination,
these techniques give the user the possibility to execute and investigate small
fractions of a possibly huge parallel program, without having to (re-)execute the
entire program.

1 Introduction
In the past years we can see a drastic increase of hardware and software complexity,
especially in the field of high performance computing. In order to satisfy the steadily
increasing needs of the supercomputing community, computer manufacturers try to increase the degree of parallelism of the hardware. This can be observed on several system
layers, starting at processor level. With the integration of more than one processor core
on one CPU very compact SMP systems with a relatively high number of processor
cores can be built.
Since scalability of SMP systems is limited to several dozens of processor cores,
NUMA systems or clustering techniques are used to increase the number of processor
cores further. NUMA systems scale well up to a few thousand of processor cores. Using
cluster computing techniques, SMPs or NUMAs are connected to larger systems with
possibly more than a hundredthousand processor cores.
In recent years we see also software-sided approaches to build systems which exceed
the borders of large clusters. Such ideas evolved originally from distributed computing,
where distributed resources were used to solve a given problem, like in the SETI@home
Project or in the GIMPS Project, just to name two popular. Researchers work on advanced middleware to build so called GRID Systems [1]. Such systems improve and
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part II, LNCS 3992, pp. 557–564, 2006.
c Springer-Verlag Berlin Heidelberg 2006

558

C. Schaubschl¨ager, D. Kranzlm¨uller, and J. Volkert

extend the idea of distributed computing in terms of resource allocation, scheduling,
security, and many others. One goal is to build a possibly global metacomputer with
hundreds of thousands of processors.
With the increase of the available computing power, one can also observe an increase
of software complexity. To utilise the hardware resources on such large scale computers
as good as possible, usually massively-parallel programs are used. Due to their size (in
terms of number of processes, memory consumption, disk space, etc.) such programs
impose big problems especially when it comes to program analysis and debugging.
Most of the available tools in that area cannot handle such huge programs well enough.
A common approach is to debug not the full scale program, but try to work on a smaller
problem size, use less processors, etc. However, this approach does not work always,
since some errors occur only in the full scale case. Therfore there is a strong need for
new strategies in program analysis and debugging of massively-parallel programs. In
this paper we propose a novel strategy, which tries to hide the high complexity of the
program under analysis from the user, thus making it easier to handle.
The rest of the paper is organised as follows. In section 2 we describe important
aspects of program analysis in general and problems of analysing massively-parallel
program in particular. In section 2.3 we give a brief overview about related work in this
area. In section 3 the single process debugging strategy is introduced and described.
Section 4 concludes the paper.

2 Program Analysis
2.1 Debugging Techniques
Program analysis is an important part of the software life-cycle, because an effective
analysis and proper use of analysis results can reduce the costs of software development
and maintainance enormously. Three main aspects of program analysis are performance
analysis, testing, and error debugging. In our work the focus lies on debugging, and
debugging strategies respectively.
Many well known techniques and methods for program debugging have been developed originally for debugging sequential programs. Amongst others we mention the following, which are important for our debugging strategy: Single-step debugging, Cyclic
debugging, Checkpointing, Breakpointing, and Control flow analysis and Program slicing. The reasons why these techniques cannot be applied to parallel or massively parallel
programs, respectively, ad-hoc, and why such programs impose enormous difficulties
on the debugging process, is described in the following sections.
2.2 Massively Parallel Programs
The difficulties in debugging massively parallel programs stem from their sheer size,
both in execution time, as well as in space (number of processes, memory consumption,
etc). A common practice to get information about a program’s execution is to instrument
the program, i.e. to insert additional monitoring code, which collects information during
execution. This data is subject to analysis, either post-mortem or online.
This approach works well for small and medium-size programs, but it becomes impractical for large programs, since the amount of collected data is too big. There are hardly

Using Sequential Debugging Techniques with Massively Parallel Programs

559

any analysis techniques to extract useful information, and even more important, there are
almost no proper techniques to visualize such big programs in a meaningful way.
Another obstacle in debugging parallel programs is introduced by nondeterminism,
which plays a bigger role in the parallel case than in sequential programs. This is due to
the fact that in addition to the sources of nondeterminism that we know from sequential
programs, there are several nondeterministic program constructs that are specific to parallel programs. Examples are wild-card receive function calls in message passing programs or unordered access to shared data in shared memory programs. The problems
that arise from nondeterministic behaviour during the debugging process are severe,
and are usually subsummed as probe effect, completeness problem, and irreproducibility effect [2]. For debugging the irreproducibility effect is the more problematic, since
it inhibits cyclic debugging. For this reason several methods have been developed to
enable deterministic re-executions, one of the first being the instant replay mechanism
proposed by LeBlanc and Mellor-Crummey [3]. In principle all these replay approaches
work in two phases. In the record phase, information about what happened during the
program’s execution is recorded and saved to stable memory. This information, the socalled trace of the program, is used in the second phase, the replay phase, where the
program is re-executed under the control of a replay system. The recorded information is used to enforce the same decisions at nondeterministic events as in the original
program run, hence permitting any number of equivalent re-executions of the program.
2.3 Related Work
Many existing debugging tools, commercial and non-commercail, for sequential and
parallel programs, support some or all of the above described techniques. Well known
examples for sequential debuggers are gdb and dbx, all with similar and mature functionality. In the parallel case the situation is more wide-spread. Some approaches extend
the sequential case and use multiple instances of a sequential debugger like gdb simultaneously [4, 5]. This class of parallel debugger does not scale very well, and they do
not address the pitfalls of nondeterminism. Therfore they are useful only for small deterministic programs.
Another class of parallel debuggers uses the record&replay approach. Such debuggers can handle nondeterminism and hence can provide cyclic debugging. Some provide
distributed checkpoints and breakpoints, which is useful for long running programs. Examples are [6, 7, 8]. Unfortunately they don’t scale well on the process axes, i.e. they
are difficult to use for massively parallel programs.
Our approach is in some sense similar to program slicing in general [9] and the work
of Dusterwald et al. on slicing distributed programs in particular [10]. However, their
work is based on control flow analysis and the distributed dependence graph, while
we use the event graph (as described below) as fundament. Also, they don’t support
breakpoints and checkpoints, which is a big drawback for long running programs.

3 Single Process Debugging
In this section we describe our debugging strategy, which we call single-process debugging. The target applications of our work are massively-parallel message-passing

560

C. Schaubschl¨ager, D. Kranzlm¨uller, and J. Volkert

programs. Without loss of generality we confine ourselves to SPMD message-passing
programs written in the C programming language. For inter-process communication we
use only two functions defined in the MPI-Standard [11], namely MPI Send for sending, and MPI Recv for receiving data.
There are several prerequisites which must be met for our approach to work. Firstly,
we need to be able to replay parallel programs deterministically. We can do this in a
very efficient manner using our Record&Replay approach called RON. Furthermore we
describe how we can isolate a process (or a group of processes) from a parallel program,
in a sense, that we can (re-)execute this process stand-alone, without having to execute
the entire parallel program. We use checkpoints as well as breakpoints; both techniques
have to be adapted to work in the case of parallel programs. Finally we describe how
we combine these techniques to the single process debugging strategy.
3.1 Modelling Program Executions
For analysis of the recorded trace data we need a formalism in order to be able to apply
mathematical methods like graph operations on the data. As a formal representation of
a program’s execution we use the event graph model:
Definition Event Graph [12]. An event graph is a directed graph G = (E, →) , where
E is the non-empty set of events e ∈ E, while → is a relation connecting events, such
that x → y means that there is an edge from event x to event y in G with the ”tail” at
event x and the ”head” at event y.
The events e ∈ E are the recorded events observed during a program’s execution, like
for example send or receive events. The relation connecting the events of an event graph
is the so called happened-before relation [13].
3.2 Deterministic Replay
A crucial aspect of any monitoring or Record&Replay approach, respectively, is to
keep the influence of the monitoring system on the program as low as possibe. Given
the fact, that in MPI non-overtaking communication is guaranteed, one can show that
it is sufficcient to record only the process-id of the corresponding sending process for
every nondeterministic call to MPI Recv. This can be done with very little effort during
program execution and results in very small tracefiles. In subsequent replay iterations
equivalent program runs are guaranteed by replacing every occurance of a wild-card
receive with a deterministic receive, where the process-id of the message source is read
from the previously recorded tracefiles. Once the execution path is fixed one can extend
the amount of recorded data without running the risk to perturb the order of message
reception. This Record&Replay mechanism has been implemented in the monitoring
tool NOPE [14], which is part of the DeWiz debugging environment [15].
With deterministic replay we are now able to do cyclic debugging. However, as stated
before, due to the size of massively-parallel programs, cyclic debugging is by far not
sufficient as debugging strategy. The next step is therefore to reduce the amount of
analysis data. We can do this by narrowing the investigated parts of the program in two
dimensions, namely along the process axes using process isolation, as well as along the
time axes using breakpoints and checkpoints.

Using Sequential Debugging Techniques with Massively Parallel Programs

561

3.3 Process Isolation
During debugging of a massively-parallel program the user might get the suspicion that
there is a bug on a certain process. At this point, one would start the program again,
possibly several times, paying special attention on that particular process. During all
these debugging iterations the whole program, which consists of many processes, must
be executed all the times, although the user focuses only on one or a few processes. This
has many disadvantages, it wastes CPU time, which is a cost issue, unneccessary trace
data is generated (and possibly analysed in vain), and so on. Therefore we use the idea
of process isolation, where we ”isolate” one process (or a group of processes) from the
rest of the parallel program, making them executable stand-alone.
Isolating process Pi from its context requires three steps:
1. Initial execution of the entire program: generation of trace data.
2. Build the event graph.
3. Isolation step: re-execute process Pi and all (directly or indirectly) dependent processes. Save the contents of all incoming messages on process Pi .
During subsequent isolated executions of Pi incoming messages are not received
by MPI Recv, but the contents of the message is read from the previously generated
tracefiles. The number of processes that have to be re-executed in step 3 is not fixed, but
depends on the program being analysed. Based on the event graph we use a recursive
algorithm to determine which processes have to be re-executed.
3.4 Breakpoints in Parallel Programs
Distributed breakpoints (and checkpoints) are used to reduce the program’s complexity
along the time axis. A distributed breakpoint is a set of sequential breakpoints, one on
each process of the parallel program: Bi = (Si,0 , ..., Si,(n−1) ), with n being the number
of processes in the parallel program. In our approach we give the user two possibilities
to define a distributed breakpoint: manually, by modifying the source code, or semiautomatically, based on the event graph.
Using the manual approach the user can instert special breakpoint code at any position in the source code. However, in this case it lies in the responsibility of the user that
this code is placed properly so that the sequential breakpoints are reached by every process during program execution (which of course is crucial for a distributed breakpoint
to be useful).
The second possibility to specify a distributed breakpoint is situated on a higher
level of abstraction (or program representation) compared to the source code level. A
recorded program run, or rather the event graph, can be visualized as space-time diagram, where - amongst others - there are send and receive events as nodes in the graph,
which are pairwise connected by arcs. The user can select any event ei,p (the ith event
on process p) in the graph by simply clicking on it; this event will be the origin of the
distributed breakpoint. After selection of such an event, we can automatically determine which events on all other processes have to be part of the distributed breakpoint,
by using the happened-before relation.

562

C. Schaubschl¨ager, D. Kranzlm¨uller, and J. Volkert
C0

C1

C2

P0
S1

P1

M2

R1

P2
P3

Erroneous calculation
(Timestamp t1)

Crash
(Timestamp t2)

Fig. 1. Example debugging scenario

3.5 Checkpoints in Parallel Programs
Another approach to reduce the cycle time of the debugging iterations is to use checkpointing. Similar to a distributed breakpoint a distributed checkpoint consists of one
sequential checkpoint for each process of the parallel program, which form a so called
checkpoint line. An important aspect is the placement of checkpoints, which can be
done either semi-automatically or automatically. The semi-automatic approach is done
via the visual representation of the event graph of the parallel program. To place a
checkpoint the user can select any arbitrary point on one process, the corresponding
checkpoints on the remaining processes are calculated automatically, based on the event
graph. During the next replay of the program at all user specified checkpoint locations
the current state of the process is saved to stable storage.
The semi-automatic approach has several disadvantages, namely placing checkpoints
on a regular base would become a tedious task. Therefore we have the possibility to
place checkpoints automatically. In principle each process saves it’s state periodically
to stable storage. However, several requirements must be met to ensure so-called consistent checkpoints, e.g. one must take care of messages that would cross a checkpoint
line, and others. Details on that can be found in [16].
3.6 Putting It All Together
All these techniques have been applied in debugging programs, sequential and parallel
as well. Due to the difficulties introduced by massively-parallel programs as described
in section 2.2 these techniques are limited to relatively small parallel programs. Therefore we have tried to combine them in a proper way, giving the user the possibility to
handle even the biggest parallel programs.
The two main ideas are to keep the user’s focus only on relevant parts of the program
on the one hand, i.e. on parts where errors are suspected, and on the other hand to save
computing resources during debugging, which is often an important cost factor. We can
achieve this by re-executing only small parts of the massively parallel program during
the debugging cycles. The following simple scenario in Figure 1 illustrates the idea.
1. A small parallel program consisting of four processes P0 to P3 was executed and
crashed after a while, the user starts a debugging session. Unless the initial execution was not monitored, the user would initiate a monitored re-execution in order to
permit deterministic re-executions and to generate trace data. Also checkpoints are
generated periodically.

Using Sequential Debugging Techniques with Massively Parallel Programs

563

2. The event graph of the previous execution is generated and visualized as space-time
diagram, as displayed in Figure 1. We see message exchanges indicated by arrows,
and three distributed checkpoints C0 to C2 .
3. The user suspects a crash on P2 at timestamp t2 (based on various indications, eg.
error messages from the MPI environment, or - in our example - by the fact that
message M2 is pending, etc.), therefore debugging starts on P2 . The cause of the
crash is an erroneous calculation on process P1 at timestamp t1 , which of course is
unknown to the user at that time.
4. In a first step only a small part of P2 is selected and debugged: P2 is isolated starting
at the closest checkpoint to t2 , in our case C2 . The small section [C2 : t2 ] can now
be re-executed and inspected any arbitrary number of times stand alone.
5. Since the cause of the crash could not be found in section [C2 : t2 ], the investigated
interval is extended to [C1 : t2 ], again using process isolation, etc. Here the user
finds that an erroneous value is received at receive event R1 . Therefore the debugging session is continued on process P1 in the interval [C1 : C2 ], since this is the
location of the corresponding send event S1 . For that purpose process P1 must be
isolated and re-executed in the mentioned interval.
6. Finally the user finds the location of the erroneous calculation on process P1 at
timestamp t1 , which caused the crash later on P2 .
It is important to note that all steps necessary for process isolation, all transitions
from one process to another, etc. can be performed automatically and transparently in
the background. The user simply selects a (small) region on a process for debugging,
and this section is isolated automatically. In case of the reception of an erroneous value
as in the example above, the user just initiates a switch to the sending process; which
section (or checkpointing interval, respectively) on the sending process has to be isolated can be calculated automatically using the relations in the event graph.

4 Conclusion and Future Work
We have presented a scalable debugging strategy for massively parallel programs. The
main idea is to narrow the range of the investigated parts of the program during debugging in an intelligent way, both in time and in space. This keeps the focus of the user
on the relevant parts of the program, and, since re-execution during debugging is much
less ressource intensive, may actually save money.
We are working on several improvements of this approach. For example, the integration of control flow analysis could improve the understanding of error propagation
in the program, hence making the tracking of errors more efficient. Several work has
been done in this field, for example the work on slicing parallel programs described in
[10]. Also an extension to shared memory programs and distributed programs in general
seems useful and will be investigated further.

References
1. Foster, I., Kesselman, C., Tuecke, S.: The anatomy of the grid: Enabling scalable virtual
organizations. The International Journal of High Performance Computing Applications 15
(2001) 200–222

564

C. Schaubschl¨ager, D. Kranzlm¨uller, and J. Volkert

2. Schaubschl¨ager, C.: Automatic testing of nondeterministic programs in message passing systems. Masters Thesis, GUP, Johannes Kepler University, Linz, Austria. http://www.gup.unilinz.ac.at/˜cs/thesis (2000)
3. LeBlanc, T.J., Mellor-Crummey, J.M.: Debugging parallel programs with instant replay.
IEEE Trans. Comput. 36 (1987) 471–482
4. Balle, S.M., Brett, B.R., Chen, C.P., LaFrance-Linden, D.: Extending a traditional debugger
to debug massively parallel programs. Journal of Parallel and Distributed Computing 64
(2004) 617–628
5. Cunha, J., Lourenco, J., Antao, T.: A debugging engine for parallel and distributed environment (1996)
6. Kacsuk, P.: Systematic macrostep debugging of message passing parallel programs. Future
Gener. Comput. Syst. 16 (2000) 609–624
7. Etnus: Totalview debugger. http://www.etnus.com/ (2005)
8. Absoft, Corp.: DDT - Distributed Debugging Tool (2005)
9. Weiser, M.: Program slicing. In: ICSE ’81: Proceedings of the 5th international conference
on Software engineering, Piscataway, NJ, USA, IEEE Press (1981) 439–449
10. Duesterwald, E., Gupta, R., Soffa, M.L.: Distributed Slicing and Partial Re-execution
for Distributed Programs. In: Languages and Compilers for Parallel Computing. (1992)
497–511
11. Message Passing Interface Forum: MPI: A Message-Passing Interface Standard - Verion 1.1.
http://www.mcs.anl.gov/mpi/ (1995)
12. Kranzlm¨uller, D.: Event graph analysis for debugging massively parallel programs. PhD
thesis, GUP, Joh. Kepler Univ. Linz. http://www.gup.uni-linz.ac.at/˜dk/thesis (2000)
13. Lamport, L.: Time, clocks, and the ordering of events in a distributed system. In: Communications of the ACM, Vol. 21, No. 7. (1978) 558–565
14. Kranzlm¨uller, D., Volkert, J.: Nope: A nondeterministic program evaluator. In: Proc. of
ACPC99, 4th Intl. ACPC Conference, LNCS, Vol. 1557. (1999) 490–499
15. Kobler, R., Schaubschl¨ager, C., Aichinger, B., Kranzlmller, D., Volkert, J.: Examples of monitoring and program analysis activities with dewiz. In: Proc. DAPSYS 2004 (5th AustrianHungarian Workshop On Distributed And Parallel Systems). (2004)
16. Thoai, N.: Checkpointing techniques for minimizing the waiting time during debugging
long-running parallel programs. PhD. Thesis, GUP, Johannes Kepler University, Linz, Austria (2003)

