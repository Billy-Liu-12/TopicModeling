Procedia Computer Science
Volume 80, 2016, Pages 461–471
ICCS 2016. The International Conference on Computational
Science

Improving Multivariate Data Streams Clustering
Christian C. Bones1 , Luciana A. S. Romani2 , and Elaine P. M. de Sousa1∗
1

University of S˜
ao Paulo, S˜
ao Carlos, SP, Brazil. {chris, parros}@icmc.usp.br
2
Embrapa Agricultural Informatics, Campinas, SP, Brazil.
luciana.romani@embrapa.br

Abstract
Clustering data streams is an important task in data mining research. Recently, some algorithms have been proposed to cluster data streams as a whole, but just few of them deal with
multivariate data streams. Even so, these algorithms merely aggregate the attributes without
touching upon the correlation among them. In order to overcome this issue, we propose a new
framework to cluster multivariate data streams based on their evolving behavior over time,
exploring the correlations among their attributes by computing the fractal dimension. Experimental results with climate data streams show that the clusters’ quality and compactness can
be improved compared to the competing method, leading to the thoughtfulness that attributes
correlations cannot be put aside. In fact, the clusters’ compactness are 7 to 25 times better
using our method. Our framework also proves to be an useful tool to assist meteorologists in
understanding the climate behavior along a period of time.
Keywords: Clustering, Data Streams, Data Mining, Fractal

1

Introduction

Extracting valid and useful knowledge from data streams is an important and costly task for
many environmental science ﬁelds such as ecology, geology, atmospheric science, to name a few.
An increasing number of devices and sensors have generated a huge amount of data incessantly,
leading to new challenges and applications. For instance, sensors have been used to monitor
the pollution in cities, the level of rivers and the meteorological conditions. Extracting valuable
information from these ﬂows of data could be helpful to avoid disasters, such as ﬂooding or the
extinction of fragile plants due to sudden changes in temperature.
In this scenario, clustering of data streams becomes an active research topic [2, 12, 7, 5, 18,
14, 17] with applications in several contexts. Clustering aims to group in the same cluster data
streams that have similar properties and behavior over time, whereas data streams of diﬀerent
clusters must present dissimilar characteristics. For illustration, clustering techniques could be
applied to cluster meteorological data stream sensors that have similar behavior along a period
of time.
∗ The

authors are grateful to CAPES, CNPQ and FAPESP for their ﬁnancial support.

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.325

461

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

However, clustering data streams requires appropriate solutions for challenging issues,
mainly: to capture and represent data evolution along the time; to deal with all the attributes
of each stream, i.e., multivariate data streams; to take into account the correlation among the
attributes; to read data only once; to provide answers as soon as the user demands them; to deal
with outlier data streams. Therefore, in the past few years some methods have been proposed
to process and analyze ﬂows of data in real time [15, 14, 18, 17, 8, 16, 1], aiming to overcome
some of these challenges. However, only few of them try to pull out valuable information and
group the entire data streams based on their similar behavior over the time [14, 17, 8, 16]. Furthermore, most of these methods either do not support multivariate data streams [14, 17, 16]
or only consider the similarity of attributes independently [15, 13, 8].
In this paper, we propose a new approach to cluster multivariate data streams, taking
into account the entire data streams and their (dis)similar behavior along the time, bearing
in mind the data streams evolution. Our approach also considers the correlation among the
attributes of each data stream, aiming to improve the clusters’ quality. We thus propose the
framework eFCDS - Evolving Fractal-based Clustering of Data Streams. Its main module is a
novel algorithm for clustering multivariate data streams, based on the continuous calculation
of the attributes correlation by the fractal dimension. Also, it tracks the evolution of the
data streams by checking cluster membership whenever a new value of fractal dimension is
obtained. In other words, our method checks whether the data stream still belongs to the
same cluster or it should be allocated in another one that better describes its behavior in that
period of time. Another module of eFCDS checks whether an outlier data stream could be
associated to one of the regular clusters without disrupt the clusters’ formation rules. It also
detects overlapping between the generated clusters and merge them when their union does not
extrapolate a maximum standard deviation.
Finally, we apply our framework to climate data streams from meteorological sensors, which
usually have more than one attribute (e.g. temperature and precipitation) and presumably
there are some correlations among them. We conducted an experimental study on data from
diﬀerent Brazilian regions, provided by Agritempo1 . Our results not only indicated that our
approach can be useful to assist specialists in analyzing large amounts of climate data, which is
relevant to current climate research, but also helps to identify regions with the same behavior
along the time.
The rest of this paper is organized as follows. Section 2 presents background concepts and
related work. Section 3 describes our approach to cluster data streams. Experimental results
are discussed in Section 4 and Section 5 presents ﬁnal remarks and future work.

2

Background and Related Work

In order to be considered a data stream the data collection must be generated continuously by
one or more sources, i.e, d1 , d2 , ... [11]. Moreover, each di could have more than one attribute,
characterizing it as a multivariate data stream. Formally, let S = {S1 , . . . , Sn } be a set of data
streams sources where each Si = d1 , . . . , d∞ is a multivariate data stream. Also, each Si is
assumed to contain f attributes such that di = [a1 , . . . , af ] is the set of attributes.
Clustering in a data stream environment can be very costly [11], due to some basic requirements that must be presented in the algorithms [3]: (i) Representation of compact size; (ii)
Quickly and incremental processing of new data items; (iii) Traceability of changes in groups;
(iv) Quick and clear identiﬁcation of outliers.
1 www.agritempo.gov.br

462

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

Methods that aim to overcome those challenges usually fall into two main categories, namely:
Clustering by example, in which all data points are clustered independently, regardless of the
data sources these data points are from; Clustering by variable or Clustering the entire data
stream, in which sensor data streams are compared with each other and clustered according to
their similarity in the analyzed time interval. The general idea of clustering the entire data
stream is illustrated in Fig. 1. Notice that clusters can evolve over time (T 1 to T 3), i.e. data
streams can move from one cluster to another, clusters can disappear or new clusters can be
created. In this work we address the clustering by variable problem.

2.1

Clustering by Variable

In the literature, there are few methods which aim to cluster the entire multivariate data streams
[8, 15, 13]. But they do not consider the correlation among attributes to cluster the data streams.
Instead, attributes are analyzed individually such that two data streams are placed together in
the same cluster only if all their related attributes are similar. This approach leads to results
that may not correspond to the general behavior of the data streams along the time.
In general, algorithms to cluster data streams fall into one of two main categories: partitioning methods, such as ECM [17] and POD-Clus [8], and hierarchical methods, such as TS-Stream
[14] and ODAC [16]. All these methods deal with evolving data streams but, to the best of our
knowledge, only POD-Clus supports multivariate data streams. Therefore, POD-Clus is closely
related to our work, due to it partitioning strategy and multivariate support.
The POD-Clus algorithm (Probability and Distribution-based Clustering) [8] seeks to maintain summaries and discard detailed information of the data points, using normal distributions
for this purpose. Each POD-Clus’ cluster k receives n data points from each incoming data
stream and stores some average statistics: such as the average μ, standard deviation σ and the
updated covariance matrix, whenever new data arrives. These statistics are used to measure the
similarity between data streams considering each attribute or feature independently according
to the equation 1.
F

2

DSC =
f =1

(μSf − μCf )
,
2
σSf

(1)

Sensors
S1
S2
S3
S4
S5
S6

Multivariate
Data Streams

Clustering
Algorithm

where S denotes a data stream, C denotes a cluster, f denotes a data feature (attribute), μSf
is the mean of data stream S’s feature f , σSf is the standard deviation of data streams S’s
feature f , and μCf is the mean of the cluster C’s feature f .
Although POD-Clus supports multivariate data streams, Equation 1 shows it does not
consider the correlation among the data stream attributes to build the clusters. POD-Clus
adds a data stream to a cluster only if all its attributes f are similar to the C’s features f ,
regardless of attribute correlations. Thus, as real data usually present correlated attributes, we

C2
S3
S6
C1
S2

C3
S1
S4 S5
(T1)

C2
S3
S6 S5

C1
S1

S2
S4
(T2)

C2
S5
S6

C3

C1
S2

C4
S4 S3

S1

(T3)

Figure 1: Main idea of clustering multivariate data streams with cluster evolution.
463

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

propose a fractal-based approach to improve clustering of entire data streams by considering
such correlations and the general behavior of the data streams (see Section 3).

2.2

Fractal Dimension

A fractal is characterized by the self-similarity property, i.e., it is an object that presents
roughly the same characteristics when analyzed over a large range of scales. From the Fractal
Theory, the Correlation Fractal Dimension D2 is particularly useful for data analysis, since it
can be applied to estimate the intrinsic dimension of real datasets that exhibit fractal behavior,
i.e., exactly or statistically self-similar datasets [4]. The Correlation Fractal Dimension D2
measures the non-uniform behavior of real data considering both linear and nonlinear attribute
correlations [9]. Therefore, D2 represents the dimensionality of the dataset regardless of the
dimension of the space deﬁned by its attributes.
Sousa et al. [10] proposed a technique to detect changes in multivariate, evolving data
streams based on the information of intrinsic behavior provided by the fractal dimension D2 .
The authors also presented the algorithm SID-meter to continuously measure D2 over time
aimed at monitoring the evolving behavior of the data, such that signiﬁcant variations in successive measures of D2 can indicate changes in the intrinsic characteristics of the data and in
the attribute correlations as well. In this paper, we apply a similar approach to calculate the
fractal dimension D2 of the incoming data streams in order to capture their evolving behavior.
We then measure the similarity between data streams based on this behavior aiming for better
clusters results.

3

Evolving Fractal-based Clustering Framework

We propose the framework Evolving Fractal-based Clustering of Data Streams, eFCDS for
short. A preliminary, naive version of our approach was introduced in [6]. Here, we describe a
substantially improved framework, including new solutions to overlapping identiﬁcation, merge
of clusters and outlier detection.
The eFCDS aims to segment a set of data streams S in a collection P = {C1 , . . . , Cm } of
m dissociated clusters. P is built using the fractal dimension analysis of each Si whilst the
related methods employ the raw data points. In other words, the eFCDS groups data streams
with similar behavior in an interval of time Ti taking into consideration the correlation among
the attributes measured by the fractal dimension D2 . Inside eFCDS, a data stream source Si
will be placed into a cluster C only if the cluster’ standard deviation, computed from values of
D2 , does not exceed an user-deﬁned threshold σmax . Our method also follows the evolution of
the data streams enabling clusters to disappear or be created. After processing every Si on Ti ,
the eFCDS detects clusters overlap by identifying data streams sensors that could be member
of more than one cluster. If so, the eFCDS tries to merge the clusters or rearrange the sensors
in more suitable clusters.
The eFCDS process follows the idea of clustering data streams depicted in Fig. 1. The
data stream sources (e.g. sensors) generate new data continuously and send them to eFCDS,
which produces evolutionary clusters. Notice that for each interval of time Ti , the gathered
data are clustered following the fractal dimension of the available data. As new data arrives,
the clusters are created or rearranged to ensure the similarity among their elements along the
time. For instance, the cluster disappearance illustrated from period T1 to T2 could occur when
all members of a cluster are redistributed to others clusters or due to the new merge process
explained latter.
464

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

Figure 2: Method of clustering data streams and (ii) sliding window of a sensor, counting
periods t = 4, events e = 3.
The main components of our framework work as follows. Data produced by a number of
incoming data stream sources are directly forwarded to the eFCDS framework in order to be
processed, as shown in Fig. 2.
The ﬁrst component of the eFCDS is the Sliding Window Module, which receives the data
streams and bounds their data in a sliding window fashion. The sliding window (w) speciﬁes
the amount of data buﬀered for the fractal dimensional calculation. The window is divided
into counting periods (t), and each period has a deﬁned number of events (e) such that event
correspond to a d data point. Therefore, t × e deﬁnes the size of the window (l) and e represents
its movement step. The size of the window is a user-deﬁned parameter which usually depends
on domain expertise. However, it is possible to explore diﬀerent values of l to evaluate clustering
results under distinct temporal granularities. Fig. 2(ii ) shows the sliding windows wi of size l
= 12, that means four counting periods t where each t has three events.
As soon as there are enough data fulﬁlling w, those data can now be processed, i.e., the
fractal dimension F D related to wi is obtained. In such case, the sliding window is shifted
forward in e units, releasing memory previously occupied by the oldest e data points in order
to buﬀer the continuous incoming data.
The Fractal Dimension Analyzer is based on the SID-Meter [10] approach to perform the
incremental calculus of D2 . Unlike the clustering methods already proposed in the literature,
the use of D2 enables to iterate over data containing more than one attribute, transforming a
piece of a multivariate data stream into exactly one value of fractal dimension, summarizing the
amount of data inside the window and the correlation among the data stream attributes. Our
intuition is that using a technique which capture the correlations among the involved attributes
along the time leads to a better recognition of similar data stream sources than using the raw
values of the attributes.
Subsequently, the reduced amount of fractal dimension points is sent to the data mining step.
The Mining Module is the main component of the eFCDS framework and aims at clustering
the fractal dimension points according to their similarity and a user-deﬁned maximum standard
deviation (σM AX ), that could be a percentage of the number of attributes. In order to detail
the clustering step, let us introduce the Algorithm 1.
465

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

Algorithm 1: Evolving Fractal-based Clustering of Data Streams (eFCDS)
Input: The set X containing pairs of streams Si and its fractal dimension f d;
The partition P of clusters;
The maximum standard deviation σM AX .
Output: The partition P of clusters with similar data streams.
1 foreach x ∈ X do
2
if x.Si is in a cluster Cj ∈ P then
3
if updateCluster(Cj , x, σM AX ) = false then
4
if findCluster(x, σM AX ) = false then
5
Cnew ← createNewCluster (x);
6
rearrangeCluster(Cj , Cnew );
7
8
9
10
11
12

else
if findCluster(x, σM AX ) = false then
Cnew ← createNewCluster (x);
rearrangeOutlier (C, σM AX );
mergeCluster (C, σM AX );
return P ;

The Algorithm 1 iterates over the set X comprising the points of fractal correlation (f d) such
that each point is labeled with its respective data stream Si . Initially, it is veriﬁed whether or not
the data stream source Si already belongs to some existing cluster Cj composing the partition P
(line 2). Supposing Si was not clustered yet, it is necessary to ﬁnd for a cluster to insert Si into.
For this purpose, for each cluster C ∈ P , the boolean procedure findCluster (line 8) looks for
the cluster Cj with the lowest diﬀerence between the centroid of Cj and the analyzed point x.
This process follows the model introduced in Equation 2, where C = {c1 , . . . , ck , . . . , cn }, the
quantity of clusters generated so far.
Δ(C, x) =

1
n

n

ck .f d

− x.f d

(2)

k=1

Once the cluster C which minimizes the Equation 2 regarding to the element x is obtained,
x is assigned to C if the condition expressed in Equation 3 holds. Otherwise, the new cluster
Cnew containing the element x is created (line 9) and included in the partition P .
⎛
1 ⎝
x.f d −
n+1

n

1
cp .f d
n p=1

2

n

n

ck .f d −

+
k=1

1
cp .f d
n p=1

2

⎞
⎠ ≤ σM AX

(3)

Considering the data stream source Si is already part of some cluster, it is necessary to check
whether or not Si remains in the previous assigned cluster. In order to employ such veriﬁcation
(line 3), the Mining module re-execute the calculus of Equation 3 regarding to the new value
of the fractal dimension x.f d. If so, the statistic (function Δ) of the considered cluster Cj is
updated. In the case where the left-hand side of Equation 3 exceeds the user-deﬁned maximum
standard deviation σM AX , the algorithm tries to reallocate the element x in an existing cluster
466

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

Ck so as to minimize the value computed in Equation 2 (line 4) and also hold the condition
deﬁned in Equation 3. If there is not such cluster Ck satisfying both conditions, a new one
(Cnew ) is created to include the element x (line 5). Now, when creating a new cluster, the
elements already present in Cj are checked if they are better included in Cnew , minimizing
Equation 2 (line 6). Notice that the rearrangeCluster procedure is able to suppress existing
(empty) clusters if all of their elements are moved.
After that, the eFCDS iterates over the clusters to identify those with single data streams,
i.e., potential outliers. If anyone is found the eFCDS tries to rearrange it on one of the non
outlier clusters following the aforementioned criteria. The last step is to check if there is
overlapping between clusters (line 11) and merge them according to the Merge Cluster algorithm
(Alg. 2). It checks whether or not there are some data streams that could be associated to more
than one cluster (Alg. 2:line 1). If so, then the respective clusters will be merged if their union
does not exceed the maximum standard deviation (Alg. 2:line 3). Otherwise, it is found the
bounds of both clusters i and j (Alg. 2:line 4) by getting the Si that is closest to the Cj centroid
and the Sj that is closest to Ci centroid. Both Si and Sj will be attached to a new cluster ij
(Alg. 2:line 5) and all the remain data streams in Ci and Cj will be checked if they stay in their
own clusters or if they will be associated to the new cluster Cij (Alg. 2:line 6).
Thus, at the end of one iteration over the set X, the partition P is composed of clusters
containing the similar data streams sources in relation to the fractal dimension (line 12). As the
sources are continuously generating measures, the sliding window shifts forward and, as soon
as there are enough data to repeat the process, the Mining module is re-invoked. Therefore,
the obtained clusters evolves to reﬂect the changes in the gathered data along the time.
Algorithm 2: Merge Cluster
Input: The partition P of clusters;
The maximum standard deviation σM AX .
Output: The partition P of clusters with similar data streams.
1 ov[] ← findOverlap(P );
2 foreach pair(i, j) ∈ ov do
3
if merge(i, j) ≤ σM AX then
4
findMargin(i, j);
5
Cnew ← createNewCluster (ij);
6
checkReAlloc(Ci , Cj , Cij ) ;
7

4

return P ;

Experimental Evaluation

In order to evaluate our framework, we employed the following methodology: 1) examining the
performance of our approach using a real dataset; 2) using Silhouette measure to assess the
clusters’ quality; 3) comparing eFCDS’ results with the competing method (POD-Clus) previously described in Section 2.1. The goal of this methodology was to analyze three fundamental
points: (i) the eFCDS’ ability to capture similar data streams behavior along the time, (ii) the
clusters’ partition cohesion obtained, (iii) the clusters’ quality.
The real dataset is composed of 145 data streams generated by the same number of climate
sensors, each one collecting 3 distinct daily measures (minimum maximum temperature and
467

11
10
9
8
7
6
5
4
3
2

eFCDS
POD-Cluss

0

2

4

6

8

10

Bones, Romani and Sousa

% of Standard Deviation

# Clusters

Improving Multivariate Data Streams Clustering

12

300
250
200

eFCDS
POD-Clus TMin
POD-Clus TMax
POD-Clus Precipitation

150
100
50
0

0

2

Iteraction

4

6

8

10

12

Iteraction

(a) Quantity of clusters generated

(b) Standard deviation percentage

Figure 3: Comparative main results
precipitation) from January 1990 to December 1994 in diﬀerent regions of Brazil2 . The measures
measures of this dataset belong, mainly, to the South and Southeast Brazilian regions with
diﬀerent climatic conditions, making it suitable for this type of evaluation. As the country
has continental proportions, it is important to automate analysis as proposed by the eFCDS
algorithm.
To test our method with the climate sensors dataset, many values of parameter were empirically tested and the best ones were chosen. The sliding window was set with 4 counting periods
(t) of 365 events (e) which represent 4 year of data, the maximum standard deviation σM AX
was set to 0.05 that is, a small percentage of 3 (the maximum fractal dimension that could be
obtained when the attributes are not correlated with each other). In fact, σM AX greater than
10% of the maximum fractal dimension generally leads to single cluster.
In order to measure clusters’ quality, we applied the well-known Silhouette, which is commonly employed to evaluate how well the elements are disposed in their respective clusters.
The values of Silhouette range from -1 to 1, such that clusters with measures above 0.5 are
considered of good quality.
Ultimately, the eFCDS results were compared against the related method POD-Clus (Section 2.1). POD-Clus was chosen because it aims to build clusters with compact representation,
fast data processing, traceability of changes and maintenance of clusters’ evolution. As already
stated in Section 2.1, POD-Clus supports multivariate data streams, but it does not consider
the attributes’ correlation. The parameters of POD-Clus were also empirically determined: the
sliding windows size equal to 365 with shift of 90 days; three streams are needed to turn an
outlier group into a cluster; the cluster merge threshold was 0.3; and all the others parameters
were set with default values.
The main results are depicted in Fig. 3. Fig. 3(a) presents the amount of clusters generated
by each method in every iteration and the Fig. 3(b) shows the average percentage of the standard
deviations for POD-Clus’ features and eFCDS fractal dimension. Recall that eFCDS deals with
fractal dimension values and the POD-Clus deals with the original measures of temperature
(min & max) and precipitation, then to determine the cohesion of the obtained clusters we
calculated the percent of standard deviation over the mean of the clusters on each iteration.
Thus, it is possible to notice that the percentage of standard deviation obtained by eFCDS
was less than 1% indicating a very high clusters cohesion. On the other hand, the cluster cohesion obtained by POD-Clus ranges from 7% to 25% on minimum and maximum temperature,
respectively. Also notice that standard deviation of precipitation was 3 times higher than the
mean of the data points. It is due to the particular characteristics of the rainfall in Brazil
2 Data

468

provided by Agritempo (www.agritempo.gov.br)

Bones, Romani and Sousa

1

1

0.5

0.5

Silhouette

Silhouette

Improving Multivariate Data Streams Clustering

0
-0.5
-1

0

20

40

60

80 100
Streams

120

140

160

0
-0.5
-1

180

1

1

0.5

0.5

0
-0.5
-1

0

20

40

60

80
100
Streams

120

140

(c) POD-Clus’ Silhouette at ﬁrst iteration

20

40

60

80
100
Streams

120

140

160

(b) eFCDS’ Silhouette at last iteration

Silhouette

Silhouette

(a) eFCDS’ Silhouette at ﬁrst iteration

0

0
-0.5
-1

160

0

20

40

60

80
100
Streams

120

140

160

(d) POD-Clus’ Silhouette at last iteration

Figure 4: Comparative Silhouette results
Southeast, where the rain vary from 1200 to 1500 millimeters a year. As POD-Clus considers
the attributes individually (see Equation 1), the higher the standard deviation of the attribute
the smaller its inﬂuence on the distance measure, aﬀecting the quality of the ﬁnal clusters.
Fig. 4(a) and (b) show the Silhouette results obtained by the eFCDS in the ﬁrst and last
iteration, respectively. The eFCDS built clusters with 67,3% of the data streams Silhouette
measures upper to 0.5, in the average. As the ﬁgures reveal, the great majority of the data
streams were well clustered using eFCDS.
Fig. 4(c) and (d) show the Silhouette values to the clusters generated using the PODClus . Diﬀerently from eFCDS, the POD-Clus obtained the average of 25.8% considering all
iterations. The best result obtained by POD-Clus appears in the ﬁrst iteration (Fig 4(c)),
because as the process goes on, the quality of the clusters decreases with only 10% of the data
streams Silhouette upper to 0.5 on the last iteration (Fig 4(d)).
In our experimental evaluation, the eFCDS framework better represented the behavior of
diﬀerent data streams along the time. And, as showed, the POD-Clus distance measure does
not deal properly with the precipitation feature, because the rainfall season, in the South and
Southeast of Brazil, occurs from October to March and the dry season from July to September,
that means a great precipitation variation that POD-Clus was unable to deal with it. Our
approach based on fractals achieved promising results to deal with multivariate data streams,
helping to capture the behavior of climate streams over time and obtaining clusters with good
quality.

5

Conclusion and Future Work

Clustering of data streams is one of the most employed approach to analyze evolving data
streams. Nevertheless, the literature provides few methods for clustering the entire data streams
and most of them deal with data streams composed of a single attribute or do not apply
469

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

appropriate strategies for multivariate ﬂows.
In this paper we described the eFCDS framework to cluster a set of multivariate data streams
considering the correlations among their attributes and complying the basic requirements to
cluster data streams, namely: to read data only once, to provide answers as soon as the user
demands them, to deal with multivariate data streams, to take into account the correlation
among the attributes, to capture and represent data evolution along the time, to deal with
outlier data streams. It also takes into account the behavior of distinct streams along the
time. The proposed framework is composed of minor modules, each one responsible for a
speciﬁc processing of the data. The core of the eFCDS framework lies in the computation of
the fractal dimension of a piece of the data stream and its subsequent clustering. Also, our
framework performs the clustering of multivariate data streams supporting their evolution in an
incremental way helping to improve the clusters quality. To the best of our knowledge, there is
no other clustering method that support multivariate, evolving data streams and clusters them
considering attribute correlation.
We performed a set of experimental evaluation of the eFCDS framework and compared it
against POD-Clus, in order to verify the capacity of representing similar data streams behavior
along the time and keeping the quality of the produced clusters. As the results showed, the
use of the fractal dimension allowed to better identify the correlation among the attributes of
the data streams and consequently lead better clusters than the POD-Clus did. The eFCDS
performed 2.6 times better than the POD-Clus in relation to the cohesion of the clusters,
measured by the Silhouette. The eFCDS not only follows the evolution of the data streams
identifying new clusters and their disappearance, but also identiﬁes outlier data streams and
merge clusters based on a maximum standard deviation.
Our framework also proves to be an useful tool to assist meteorologists in understanding
the climate behavior along a period of time without the necessity to analyze the entire dataset
manually. They were able to identify the transposition of a sensor from one cluster to another
and thus detect those with unpredictable behavior. Then the meteorologists can check if those
sensors were aﬀected by extreme weather events, in the analyzed period, that could have changed
their expected behavior, such as severe droughts or heat waves.

References
[1] Charu C. Aggarwal, Jiawei Han, Jianyong Wang, and Philip S. Yu. On clustering massive data
streams: Summarization paradigm. In Charu C. Aggarwal, editor, Data Streams - Models and
Algorithms, volume 31 of Advances in Database Systems, chapter 2, pages 169–208. Springer,
Yorktown Heights, NY, USA, 2007.
[2] Argenis A Aroche-Villarruel, Jos´e Fco Mart´ınez-Trinidad, Jes´
us Ariel Carrasco-Ochoa, and Airel
P´erez-Su´
arez. A diﬀerent approach for pruning micro-clusters in data stream clustering. In Pattern
Recognition, pages 33–43. Springer, 2015.
[3] Daniel Barbar´
a. Requirements for clustering data streams. ACM SIGKDD Explorations Newsletter, 3(2):23–27, January 2002.
[4] Alberto Belussi and Christos Faloutsos. Estimating the selectivity of spatial queries using the
correlation fractal dimension. In VLDB’95, Proceedings of 21th International Conference on Very
Large Data Bases, September 11-15, 1995, Zurich, Switzerland., pages 299–310, 1995.
[5] A. Bifet and G. De Francisci Morales. Big data stream learning with samoa. In 2014 IEEE Int.
Conf on Data Mining Workshop, pages 1199–1202, Dec 2014.
[6] Christian C. Bones, Luciana A. S. Romani, and Elaine P. M. de Sousa. Clustering multivariate
climate data streams using fractal dimension. In Vanessa Braganholo, editor, The 30th Brazilian
Symposium on Databases, volume 30, pages 41–52, Petropolis, RJ, Brazil, October 2015. SBC.

470

Improving Multivariate Data Streams Clustering

Bones, Romani and Sousa

[7] Rattanapong Chairukwattana, Thanapat Kangkachit, Thanawin Rakthanmanon, and Kitsana
Waiyamai. Se-stream: Dimension projection for evolution-based clustering of high dimensional
data streams. In Van Nam Huynh, Thierry Denoeux, Dang Hung Tran, Anh Cuong Le, and
Son Bao Pham, editors, Knowledge and Systems Engineering, volume 245 of Advances in Intelligent
Systems and Computing, pages 365–376. Springer, 2014.
[8] Pimwadee Chaovalit and Aryya Gangopadhyay. A method for clustering transient data streams.
In Proc. ACM SAC ’09, pages 1518–1519, New York, NY, USA, 2009. ACM.
[9] Elaine P.M. de Sousa, Caetano Traina Jr, Agma J.M. Traina, Leejay Wu, and Christos Faloutsos.
A fast and eﬀective method to ﬁnd correlations among attributes in databases. Data Mining and
Knowledge Discovery, 14(3):367–407, 2007.
[10] Elaine P.M. de Sousa, Agma J.M. Traina, Caetano Traina Jr, and Christos Faloutsos. Measuring
evolving data streams behavior through their intrinsic dimension. New Generation Computing,
25(1):33–60, 2007.
[11] Sudipto Guha, Adam Meyerson, Nina Mishra, Rajeev Motwani, and Liadan O’Callaghan. Clustering data streams: Theory and practice. IEEE TKDE, 15(3):515–528, 2003.
[12] Edwin Lughofer and Moamar Sayed-Mouchaweh. Autonomous data stream clustering implementing split-and-merge concepts–towards a plug-and-play approach. Information Sciences, 304:54–79,
2015.
[13] Zachary Miller, Brian Dickinson, William Deitrick, Wei Hu, and Alex Hai Wang. Twitter spammer
detection using data stream clustering. Information Sciences, 260:64–73, 2014.
[14] C´
assio M. M. Pereira and Rodrigo F. de Mello. Ts-stream: clustering time series on data streams.
Journal of Intelligent Information Systems, 42(3):531–566, 2014.
[15] Muhammad Z. Rehman, Tianrui Li, Yan Yang, and Hongjun Wang. Hyper-ellipsoidal clustering
technique for evolving data stream. Knowledge-Based Systems, 70(0):3–14, 2014.
[16] Pedro P. Rodrigues, Joao Gama, and Joao P. Pedroso. Hierarchical clustering of time-series data
streams. IEEE TKDE, 20(5):615–627, 2008.
[17] Harya Widiputra, Russel Pears, and Nikola Kasabov. Multiple time-series prediction through multiple time-series relationships proﬁling and clustered recurring trends. In Joshua Huang, Longbing
Cao, and Jaideep Srivastava, editors, Advances in Knowledge Discovery and Data Mining, pages
161–172. Springer, Shenzhen, China, 2011.
[18] Xiangliang Zhang, C. Furtlehner, C. Germain-Renaud, and M. Sebag. Data stream clustering with
aﬃnity propagation. IEEE TKDE, 26(7):1644–1656, July 2014.

471

