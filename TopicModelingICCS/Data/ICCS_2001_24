Parallel Methods in Time Dependent
Approaches to Reactive Scattering Calculations
Valentina Piermarini1 , Leonardo Paciﬁci1 , Stefano Crocchianti1 ,
Antonio Laganà1 , Giuseppina D’Agosto2 , and Sergio Tasso2
1

Dipartimento di Chimica, Università di Perugia, Via Elce di Sotto, 8,
06123 Perugia, Italy
2
Centro Ateneo Servizi Informatici, Università di Perugia,
06123 Perugia, Italy

Abstract. The possibility of implementing a suitable model to parallelize time-dependent approaches to the calculation of quantum reactive
probabilities of elementary atom diatom processes based on collocation
methods is investigated. Problems arising when adopting a coarse grain
model by distributing ﬁxed total angular momentum quantum number J
calculations are discussed. A comparison is made with ﬁner grain models
based either on a domain decomposition due to the distribution of the
various projections Λ of J or to a partitioning of the collocation matrices
among the available processors.
Measurements performed indicate that a ﬁner grain parallelism is a
proper solution if the communications can be conﬁned into reasonable
limits. Otherwhise, ﬁne grain parallelism is only an ”extrema ratio” for
dealing with problems based on matrix representations too large to be
dealt by a single processor.

1

Introduction

Parallelization of computer codes devoted to the calculation of the properties of
reacting chemical systems has received increasing attention in recent years [1].
This is motivated by the need for building realistic molecular simulations of several processes of interest for environmental monitoring and control, technology
and material research and development, drug and enzyme design.
Up to now this has been the realm of molecular mechanics and classical dynamics that is of approaches based upon the assumption that atoms behave as
mass points or microscopic solids moving on a potential energy surface according to the laws of classical mechanics. More recently, especially for a few atom
systems, progress has been made in building computational tools based on the
more rigorous quantum mechanical assumption that atoms and molecules need
to be represented by wavefunctions.
Quantum mechanical calculations, however, are more diﬃcult to carry out
than classical ones. They, in fact, require large memories to store the information
about the basis set (and related integrals, eigenvalues, eigenvectors, etc.) in which
the wavefunction of the molecular system being considered has been expanded.
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2073, pp. 567–575, 2001.
c Springer-Verlag Berlin Heidelberg 2001
�

568

V. Piermarini et al.

This technique is largely preferred in time independent quantum approaches.
As an alternative, the wavefunction of the molecular system can be represented
as values on a grid (collocation methods). This technique is preferred for time
dependent quantum approaches. In this case, larger memories are needed to store
the values of the wavefunction at the chosen grid points.
In collaboration with other laboratories, we have developed computational
procedures able to describe reactions and calculate related observables. These
procedures are highly time consuming and have been analysed for parallelization.
Extensive work has been carried out to parallelize computer codes based on time
independent quantum approaches. In particular, both task farm and pipe-line
models have been considered for the implementation of full [2] and reduced
dimensionality[3] computational procedures on parallel architectures.
On the contrary, only limited work has been performed for parallelizing time
dependent approaches. Aim of this paper is to describe the implementation of
some parallel models for computer codes based on time dependent methods. In
section 2 a brief description of the time dependent approach is given. In section
3 a coarse grain parallelization scheme is discussed. In section 4 progress towards
a ﬁne grain parallelization scheme is illustrated.

2

The Quantum Time Dependent Computational
Procedure

The case considered in this paper is the atom-diatom reaction:
A + BC(v, j) −→ AB(v � , j � ) + C

(1)

where the reactant diatomic molecule BC is in its vibrotational (vj) state and
the product diatomic molecule AB or AC is in its vibrotational (v � j � ) state (we
use primed quantities for products, unprimed for reactants). The time-dependent
method used in this work makes use of a grid representation of the wavepacket
for distance coordinates and a basis set expansion for the angular coordinate.
The propagation in time of the wave packet considers only its real part [4,5].
At the very beginning (t = 0), for a given value of the total angular momentum quantum number J and its projection Λ on the z axis of a body ﬁxed frame,
the system wavefunction Ψ JΛ is deﬁned as
�
Ψ

JΛ

(R, r, Θ; t) =

8α
π

� 14

e−α(R−R0 )

Λ
· e−ik(R−R0 ) · ϕBC
vj (r) · Pj (Θ).

2

(2)

where R, r and Θ are the Jacobi internal coordinates of the reactant atom
diatom system. In eq. 2, e−ik(R−R0 ) is a phase factor which gives the initial
wave packet a relative kinetic energy towards the interaction region, ϕ BC
vj (r)
is the initial diatomic molecule BC wavefunction (for the vibrational state v
and the rotational state j) expressed in the Jacobi coordinates of the reactant
arrangement, PjΛ (Θ) is the normalised associated Legendre polynomial and k

Parallel Methods in Time Dependent Approaches

569

is the wavevector which determines the relative kinetic energy of the collisional
partners [4]. In this way, the wavefunction is deﬁned for a given accessible state
of the reactants and a given collisional energy range.
To move the wavepacket out of the reactant region, the integration in time
of the time-dependent Schrödinger equation
ih̄

∂ JΛ
Ψ (R, r, Θ; t) = ĤΨ JΛ (R, r, Θ; t)
∂t

(3)

is performed. The hamiltonian Ĥ consists of a kinetic part (T̂ ) and a potential part (V ) which are multiplicative in the momentum and in the coordinate
space, respectively. To exploit this property the application of Ĥ on Ψ is performed by switching from the coordinate to the momentum space and viceversa
for each coordinate. This is the most demanding part of the code in terms of
computing time. In fact, this requires that a back and forth Fourier trasform of
the wavefunction for all the coordinates involved is repeated at each time step.
As an alternative, one can apply a discrete variable (DVR) method for which
there is no need to perform the fast Fourier transform although interaction of
neighbouring elements of the wave function need to be considered.
In order to analyse the dynamics of the reactive process we require the wavefunction to be expanded in terms of the ﬁnal diatomic molecule AB wavefunction
�
�
�
�
(ϕAB
v � j � (r ) where r , R and Θ are the Jacobi coordinates of the product arrangement). From the cut of the wavepacket at the analysis line located far away in the
J
asymptotic region, one can evaluate the time dependent coeﬃcients CvjΛ,v
� j � Λ� (t)
of the expansion. By half Fourier transforming the time-dependent coeﬃcients
J
CvjΛ,v
� j � Λ� (t) one obtains a set of energy-dependent coeﬃcients whose square
modulus is the reaction probability.
The computer code performing the propagation in time of the wavepacket is
TIDEP. It carries out iteratively the propagation of the real part of the waveJ
function and stores at each time step the value of the CvjΛ,v
� j � Λ� (t) coeﬃcients.
The analysis of the coeﬃcients to work out reaction probabilities is performed
oﬀ line by another program called TIDAN.

3

The Coarse Grain Parallelization

Parallelization eﬀorts were concentrated on TIDEP since this program is the
most time consuming component of the computational procedure (the propagation step has to be iterated for about 104 ÷ 105 times). The structure of TIDEP
is:
Read input data: v, j, k, masses, ...
Perform preliminary calculations
LOOP on J
LOOP on t
LOOP on Λ

570

V. Piermarini et al.

Perform time step integration
Perform the asymptotic analysis
Store C(t) coeﬃcients
END loop on Λ
END loop on t
END loop on J
Calculate ﬁnal quantities
Print outputs
As can be seen from the scheme given above, calculations are performed at
a given range of energy, at a ﬁxed value of the vibrotational quantum number
(vj) of the reactant diatom and a single value of the total angular momentum
quantum number J. Therefore, the coarsest grain of parallelism that can be
adopted is the one distributing the calculation for a given vibrotational state,
a given interval of translational energy and a ﬁxed value of J. In this case, the
characteristics of the various tasks are so diﬀerent that a task farm dynamically
assigning the computational workload can be adopted. This very coarse grain
approach was fruitfully implemented on a cluster of powerful workstations.
To carry out the calculations the value of the physical parameters was chosen to be that of the O(1 D)+HCl atom diatom reaction[5]. Accordingly, the
mass values were chosen to be 15.9949 amu for O, 1.00783 amu for H atom and
34.96885 amu for Cl. The energy range covered by the calculation was approximately 1 eV, the initial vibrotational state used for the test was v = 0 and j =
0. The potential energy surface used for the calculations is described in ref. [5]
where other details are also given. Two types of gridsize were used for R � and r�
(the angular part was in both cases expanded over 80 basis functions): (a) 127
× 119 points; (b) 251 × 143 points. Time propagation iterates for about 40000
steps to properly diﬀuse the wavepacket at J = 0. Production runs take about
3 weeks on a Sylicon Graphics PowerChallenge supercomputer. This means also
that to calculate a state to state cross section or, even worse, a state to state rate
coeﬃcient, the amount of time needed to perform the calculation goes beyond
any acceptable limit if simpliﬁcations are not introduced. In fact, to evaluate a
vibrational state selected rate coeﬃcient, the calculation needs to be for all the
reactant rotational states j populated at the temperature considered. In addition, the calculations need to be converged with J and convergence is usually
reached only at J > 100. This increases enormously the computational load not
only because calculations have to be repeated for all J values but also because
the dimension of the matrices to be handled in a single J calculation is J + 1
times larger than that of J = 0. As a matter of fact, the computing time, that
depends on the third power of the matrix dimension, rapidly becomes exceedingly large even at small J values. This makes the calculation unfeasible on
the machines presently available for academic use at the large scale computing
facilities in Europe.
For the same reason this parallel model is even less applicable to four or more
atom reactions.

Parallel Methods in Time Dependent Approaches

4

571

The Finer Coarse Grain Parallelization

A next lower level of parallelization is the one based on the combined distribution
of ﬁxed J and ﬁxed Λ calculations. As it has been already shown above, there
is no problem in distributing ﬁxed J calculations: J is a good quantum number
(i.e. calculations for diﬀerent J values are fully decoupled) and, accordingly, the
parallelization on J is natural. On the contrary, the decoupling of Λ is not natural
since one has to introduce physical constraints of the centrifugal sudden type
(i.e. the projection of J on the z axis of the body ﬁxed frame remains constant
during the collision). This allows to perform separately the step-propagation of
the wavepacket for blocks of ﬁxed Λ values and the recombination of the various
contributions only at the end of the propagation step. This is a key feature of the
adopted computational scheme since it allows a decomposition of the domain of
the wavepacket that otherwhise would lead to a drastic increase of the demand
for memory when J increases.
Such a parallel model was ﬁrst tested [6] on the Cray T3E of EPCC (Edinburgh, UK) for the simplest case of J = 0 and J = 1. In this case, only three
pairs of J and Λ values needed to be considered and only three nodes were
used (this is the smallest non zero J calculation allowing an investigation of the
model proposed). To further save on computing time the integration process was
truncated after a few steps (computing time depends linearly on the number of
propagation steps and their reduction leads only to a slight underestimate of
the speedup). Measured speedups are 2.6 and 2.5 for propagation grids (a) and
(b), respectively. This clearly indicates that the proposed model is quite eﬀective in reducing computing times. However, for this parallel model I/O is a real
bottleneck, since as reported in ref. [6], it accounts for about 1/5 of the overall
computing time. Moreover, I/O times of node zero (through which all I/O is
channeled) are four order of magnitude larger than those of the workers. This
clearly indicates that there is still room for improvement. In fact, by entirely
conveying I/O through the master node, one has the advantage of simplifying
I/O operations at the expenses of overloading the master node.
Accordingly, when generalizing the model to higher J values node zero was
exclusively dedicated to acting as a master and the centralized management
of I/O was abandoned. On the contrary, the feature of carrying out ﬁxed J
calculations in pairs (including all the J + 1 component of Λ) was kept. The
fact that the parallelization is performed on J sets some limits to the maximum
value of the total angular momentum quantum number that can be handled by
the program. Using this model, in fact, the maximum value of J has to be 3
units lower than the number of processors. In addition, in order to keep all the
processors busy, the pairs of J values simultaneously running have to sum up to
the maximum allowed value. As an example, for a 16 node machine the maximum
allowed value of J is 13. In this case, in fact, one node acts as a master, at least
one node is reserved to the smaller J calculation and the remaining ones to the
larger J calculation. Their values are chosen so as to make the sum equal to 13
(the number of Λ values is J + 1 since it varies from 0 to J). The looping on
J starts from the pair J = 0 (one Λ value) and J = 13 (fourteen Λ values) and

572

V. Piermarini et al.

then it continues by rising the lower J value and lowering the higher one until
the ascending and descending sequences converge.
To evaluate the performances of the model, the calculations were performed
on the Origin 3800 of Cineca (Bologna, I) using the same set of parameters
adopted for the tests described above (grid (a)) and reducing the basis set expansion for the angular part to 10. Measured times are shown in Table 1 where
the average node computing time (in second) is given for diﬀerent J values.
Table 1. Execution time in seconds
J

0

time/s

1

2

3

4

5

6

7

8

9

10

11

12

13

4400 4440 4480 4540 4680 4680 4760 5080 5160 5120 5240 5280 5360 5400

As clearly shown by the results reported in the Table, the computing time per
node (averaged over the various values of Λ) increases with J. This indicates that
the increase of communication time associated with an increase in the number of
allowed Λ values penalizes the eﬃciency of the code. However, its entity is small
and the model shows to be quite eﬀective in reducing the overall computing
time.

5

Fine Grain Parallelization

Further attempts have been made to evaluate the possibility of pushing the
parallelization to a very ﬁne granularity. This turns out to be useful either when
a speciﬁc J value calculation needs to be carried out or when the dimensionality
of the problem becomes so large (like in the case of polyatomic reactions) that
it does not ﬁt into the individual node memory. This particularly applies when
computer center policies set severe limitations on memory and on the amount
of computing time assigned to individual jobs.
To work out a ﬁner grain parallel model the ﬁxed angle version of the code
making use of the DVR technique to perform the propagation was used. Related
operations are performed inside the routine av. Inside av two matrix times vector
and one vector times vector operations are performed according to the following
computational scheme:
LOOP of iv from 1 to nv
LOOP of ir from 1 to nr
a(ir,iv) = 0
END loop of ir
END loop of iv
LOOP of iv from 1 to nv
LOOP of i from 1 to nr

Parallel Methods in Time Dependent Approaches

573

LOOP of ip from 1 to nr
a(i,iv) = a(i,iv) + b(i,ip)*c(ip,iv)
END loop of ip
END loop of i
END loop of iv
LOOP of i from 1 to nr
LOOP of iv from 1 to nv
LOOP of ivp from 1 to nv
a(i,iv) = a(i,iv) + s(iv,ivp)*c(i,ivp)
END loop of ivp
END loop of iv
END loop of i
LOOP of iv from 1 to nv
LOOP of i from 1 to nr
a(i,iv) = a(i,iv) + v(i,iv)*c(i,iv)
END loop of i
END loop of iv
When all the matrices involved are distributed per (groups of) columns
among a certain number of nodes, all the operations sketched above imply a
quite signiﬁcant amount of communication to allow the nodes have the updated
version of the matrices involved. Test runs were performed on the IBM SP2 of
the computer Center of the University of Perugia. For the measurements use
was made of 5 processors of which one acts as a master and runs the main program, transfers the information from and to the nodes, combines the pieces of
information arriving from the nodes in a form suitable for redistribution and
further manipulation. The ratio s/p between measured sequential (single node)
and parallel (ﬁve nodes) execution times is given in Table 2 for diﬀerent values
of the collocation matrix dimension. The Table clearly shows that the parallel
Table 2. Ratio of sequential/parallel execution time

Dimension 80 400 500 600
s/p

9.5 1.2 1.0 0.98

code is outperformed by the sequential one for small dimensions of the matrices.
Break even occurs at dimension 500 for which the two versions of the code take
the same amount of time. For larger dimensions the parallel code outperforms
the sequential one. This means that, according to measurements performed here,
there is no advantage in parallelizing the code at this ﬁne level of granularity
unless further investigations and deep restructuring or, possibly, the use of clever

574

V. Piermarini et al.

parallelization tools [7] allow a signiﬁcant reduction in communication time. The
only convenience can be found in the fact that a ﬁne grain parallelism allows to
deal with matrices too large to be dealt by a single processor memory.

6

Conclusions

The investigation of suitable models for the parallelization quantum time dependent approaches to the calculation of reactive probabilities of elementary
atom diatom processes has been carried out for approaches based on collocation
methods. The various models investigated show that in order to make the computing time manageable the parallelization has to be pushed to a fairly low level.
This has been exploited for time dependent approaches to chemical reactivity by
distributing the propagation on time of the ﬁxed angular momentum and ﬁxed
angular momentum projection wavepacket and regaining the coupling after each
integration step. The model was found to be quite eﬃcient and to break the calculation into a computational grain small enough to make the program run on a
reasonable amount of time. On the contrary, when the parallelization is pushed
to a lower level and the computational grain is made ﬁner, the overhead due to
communications has shown to be so heavy to make the eﬃciency of the parallel
computational procedure very poor. The choice of such a ﬁne grain parallelism is
only justiﬁed by the need of tackling a problem having a matrix representation
too large to be dealt by a single processor.

References
1. Laganà, A. : Innovative computing and detailed properties of elementary reactions
using time independent approaches. Comp. Phys. Comm. 116 (1999) 1–16; Laganà,
A., Crocchianti, S., Bolloni, A., Piermarini, V., Baraglia, R., Ferrini, R., Laforenza,
D. : Computational granularity and parallel models to scale up reactive scattering
calculations. Comp. Phys. Comm. 128 (2000) 295-314
2. Laganà, A., Crocchianti, S., Ochoa de Aspuru, G., Gargano, R., Parker, G.A.:
Parallel time independent quantum calculations of atom diatom reactivity. Lecture
Notes in Computer Science Vol. 1041. Springer-Verlag, Berlin Heidelberg New York
(1995) 361-370; (1995) 361-370; Bolloni, A., Riganelli, A., Crocchianti, S., Laganà,
A.: Parallel quantum scattering calculations applied to the dynamics of elementary
reactions. Lecture Notes in Computer Science Vol. 1497. Springer-Verlag, Berlin
Heidelberg New York (1998) 331-339
3. Baraglia, R., Laforenza, D., Laganà, A.: Parallelization strategies for a reduced
dimensionality calculation of quantum reactive scattering cross sections on a hypercube machine. Lecture Notes in Computer Science Vol. 919. Springer-Verlag,
Berlin Heidelberg New York (1995) 554–561
4. Balint-Kurti, G. G.: Time dependent quantum approaches to chemical reactivity.
Lecture Notes in Chemistry Vol. 75. Springer-Verlag, Berlin Heidelberg New York
(2000) 74–87

Parallel Methods in Time Dependent Approaches

575

5. Balint-Kurti, G.G., Dixon, R. N., Marston. C. C.: Grid methods for solving
the Shrödinger equation and time dependent quantum dynamics of molecular
photofragmentation and reactive scattering processes. International Reviews in
Physical Chemistry 111 (1992) 317–344; V. Piermarini, V., Balint-Kurti, G.G.,
Gray, S., Gogtas, F., Hernandez, M.L., Laganà, A.: Wavepacket calculation of
cross sections, product state distributions and branching ratios for the O( 1 D)+
HCl reaction. J. Phys. Chem (in the press)
6. Piermarini, V., Laganà, A., Smith, L., Balint-Kurti, G. G., Allan, R. J.: Parallelism
and granularity in time dependent approaches to reactive scattering calculations.
PDPTA 5 (2000) 2879–2884
7. Vanneschi, M.: Heterogeneous High Performance Computing environment. Lecture
Notes in Computer Science Vol. 1470.Springer-Verlag, Berlin Heidelberg New York
(1998) 21-34

