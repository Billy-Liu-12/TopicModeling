Parallel Resolution with Newton
Algorithms of the Inverse Non-symmetric
Eigenvalue Problem
Pedro V. Alberti1,2 , Victor M. Garc√≠a1 , and Antonio M. Vidal1
1

Universidad Polit√©cnica de Valencia,
Camino de Vera s/n, Valencia Espa√±a
{palberti, vmgarcia, avidal}@dsic.upv.es
2
Universidad de Magallanes,
Av. Bulnes 01855, Punta Arenas Chile

Abstract. In this work, we describe two sequential algorithms to solve

the Inverse Non-Symmetric Eigenvalue Problem. Both approaches have
been based on Newton's iteration. The second one has been parallelized
by using parallel standard public domain libraries. Good performance
has been obtained in a cluster of PC's.

1

Introduction

An Inverse Eigenvalue Problem (IEP) is the reconstruction of a matrix from its
spectrum, possibly forcing some structure characteristics in the resulting matrix.
The goal of the work described in this paper is to solve a kind of inverse problem, the Inverse Additive Non-Symmetric Eigenvalue Problem (IANSEP). This
problem appears in several areas of Science and Engineering, such as Seismic Tomography, Pole Assignment Problems, Geophysics and many more [1, 4, 6, 7, 10].
The state of the art of the problem (see, for example, [6]) shows that the
vast majority of algorithms proposed are restricted to the symmetric case. Some
authors like [6, 8] review the IANSEP in a quite general form, but we have not
found any proposal for resolution of this problem; the present paper intends to
ll this gap.
This paper presents two iterative algorithms based on Newton's method. A
parallel version of the second one is also presented.
In section 2 a description of the problem is given, discussing the existence
of solutions of the IANSEP. In section 3 a sequential resolution algorithm is
proposed. It is based on a full statement of the problem as a nonlinear problem,
and gives rise to large linear and nonlinear systems; we call it a 'Brute Force'
approach. In section 4, another approach is taken, in which the nonlinear system
is written only with the dierences between the desired eigenvalues and the
'actual' ones. We call it a Restricted Newton method. In that case, the Jacobian
matrix is approximated through nite dierences. This algorithm is very suitable
for parallel processing, and we describe as well the parallel implementation.
Finally, some conclusions are given in section 5.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3514, pp. 229236, 2005.
c Springer-Verlag Berlin Heidelberg 2005

230

2

P.V. Alberti, V.M. Garc√≠a, and A.M. Vidal

The IANSEP : Description and Existence of Solution

The problem can be stated as follows:
Given n + 1 real, n √ó n matrices, A0 , A1 , ...An and a set of real numbers Œª‚àó1 ‚â§
‚àó
Œª2 ‚â§ ... ‚â§ Œª‚àón , nd d ‚àà n such that the eigenvalues Œª1 (d) ‚â§ Œª2 (d) ‚â§ ... ‚â§ Œªn (d)
of
n

A(d) := A0 +

dk Ak

(1)

k=1

fulll Œªi (d) = Œª‚àói for i = 1, ..., n.
Of course, the main problem that arises if Ai are non-symmetric matrices is
that the matrix A0 + ni=1 di Ai can have non real eigenvalues. In our work, we
shall assume that the matrices Ai , the vector d and the desired eigenvalues Œª‚àói
are real.
This sets a double existence problem. First, it should be determined when the
matrices A(d) have real eigenvalues. Second, it should be determined whether
given a vector, œÅ ‚àà n (the desired spectrum), ‚àÉd ‚àà n such that the spectrum
of A(d) (eig(A(d)) is œÅ.
As far as we know, there are no theorem which can answer to these questions.
The study of the 2 √ó 2 case can help us to determine under which circumstances
will the algorithms work (or fail). A similar analysis can be found in [5] for the
symmetric case.
Let us consider A0 , A1 , ...An ‚àà 2√ó2 and d ‚àà 2 , and let us try to nd out
how are the eigenvalues of A(d) = A0 + ni=1 di Ai .
In this case
n
Œ±(d) Œ≤(d)
A0 +
(2)
di Ai =
,
Œ≥(d) Œ¥(d)
i=1

and, therefore, the eigenvalues of A(d) are the solutions of the equation Œª2 ‚àí
S(d)Œª + det(d) = 0, with S(d) = Œ±(d) + Œ¥(d) and det(d) = Œ±(d)Œ¥(d) ‚àí Œ≥(d)Œ≤(d) .
The eigenvalues of A(d) shall be either real or complex depending on the
value of the discriminant: (d) = (Œ±(d) ‚àí Œ¥(d))2 + 4Œ≤(d)Œ≥(d).
If (d) < 0, ‚àÄ d, then the matrix A(d) will always have non real eigenvalues,
which means that our problem (that is, to nd d ‚àà 2 such that eig(A(d)) =
œÅ ‚àà 2 ) does not have 'real' solution. Trivial numerical examples can be formed
but we have avoided them for the sake of simplicity.
If (d) ‚â• 0, ‚àÄ d, then the matrix A(d) always have real eigenvalues, which
means that there can exist a 'real' solution of the problem.
Finally, it can happen that (d) < 0 for some d and (d) ‚â• 0 for other values
of d. This means that the problem can have solution, but during the iterative
search the algorithm may enter regions where (d) < 0. This should be avoided
or treated with special care.
If we consider now the case in which (d) ‚â• 0 (and therefore it is possible a
real solution) we might ask whether given a œÅ‚àó ‚àà 2 , there exists always a d ‚àà 2
such that eig (A(d)) = œÅ‚àó . Clearly, this will not happen always, for example, in
the case where (d) < 0.

Parallel Resolution with Newton Algorithms of the INEP

231

Let us try to express d as a function of Œª‚àó . Let us set the system of equations:
Œ±(d)Œ¥(d) = Œª‚àó1 + Œª‚àó2
Œ±(d)Œ¥(d) ‚àí Œ≥(d)Œ≤(d) = Œª‚àó1 Œª‚àó2 ,

(3)

which is equivalent (in the 2 √ó 2 case) to force that eig(A(d)) are Œª‚àó1 , Œª‚àó2 , and
let us solve it for d:
d2 = 1 d1 + 2
(4)
Œ∏1 d21 + Œ∏2 d1 + Œ∏3 = 0,
being Œ∏1 , Œ∏2 , Œ∏3 , 1 , 2 functions of the entries of matrices A0 , A1 , A2 and of
Œª‚àó1 , Œª‚àó2 which can be easily formed. Clearly, if Œ∏22 ‚àí 4Œ∏1 Œ∏3 < 0 the problem does
not have 'real' solution.
This shows again that the real solution of IANSEP does not always exist.
The results found can be extrapolated to n √ó n matrices. Therefore, the
situation when Ai ‚àà n√ón and, for a given set of given eigenvalues œÅ‚àó ‚àà n it is
desired to nd d ‚àà n such that eig (A(d)) = œÅ‚àó , is the following:
It may happen that for all d ‚àà n the matrix A(d) has non real eigenvalues.
In this case the problem will not have real solution.
It also may happen that for all d ‚àà n all the eigenvalues of A(d) are real.
In this case, it might happen that for some œÅ‚àó ‚àà n does not exist any d ‚àà n
such that eig(A(d)) = œÅ‚àó .
Finally, it can happen that the eigenvalues of A(d), are real for some d ‚àà n
and complex for other values of d ‚àà n .
This leads us to consider the working hypothesis of the algorithms forIANSEP,
in the same way in which it is considered for the resolution of nonlinear system.
Let us suppose that our problem, IANSEP, has a solution d‚àó ‚àà n . From the
properties of continuity of eigenvalues it can be stated that there exists a (small
enough) region comprising d‚àó ‚àà n in which the eigenvalues of any matrix of
the form A0 + ni=1 di Ai are also real. If a Newton-like method is used to nd
d‚àó , the initial guess should be taken inside this region; since Newton methods
are locally convergent, if the region is small enough, quadratic convergence can
be achieved.

3

`Brute Force' Method

As a rst approach, we will try to rewrite the IANSEP as a system of nonlinear
equations.
If the system has real solution œÅ‚àó = (Œª‚àó1 , Œª‚àó2 ¬∑ ¬∑ ¬∑ , Œª‚àón ) must satisfy
n

di Ai = QTÀúQT ,

A0 +

(5)

i=1

where the elements of main diagonal of the upper triangular matrix TÀú are (Œª‚àó1 ‚â§
Œª‚àó2 ‚â§ ... ‚â§ Œª‚àón ) and

232

P.V. Alberti, V.M. Garc√≠a, and A.M. Vidal

QQT = I

(6)

equations
So , we can set up the nonlinear system F (v) = 0, with n2 + n(n+1)
2
and unknowns:
qiT qj ‚àí Œ¥ij = 0
n
A0 + k=1 dk Ak

F (v) =

ij

‚àí qiT TÀúqj = 0

with i = 1, 2, ..., n and j = i, ..., n
with i = 1, 2, ..., n and j = 1, ..., n,

whose unknowns are
v = [q1,1 , q2,1 , ¬∑ ¬∑ ¬∑ , qn,1 , ¬∑ ¬∑ ¬∑ , qn,2 , ¬∑ ¬∑ ¬∑ , qn,n ,
t12 , t1,3 , ¬∑ ¬∑ ¬∑ , t1,n , t2,3 ¬∑ ¬∑ ¬∑ , t2,n ¬∑ ¬∑ ¬∑ , t(n‚àí1),n ¬∑ ¬∑ ¬∑ , d1 , d2 , ¬∑ ¬∑ ¬∑ , dn ].
This nonlinear system can be tackled with Newton's method, through the
iteration v (i+1) = v (i) ‚àíJ ‚àí1 (v (i) )F (v (i) ) = v (i) +s(i) , with J(v (i) )s(i) = ‚àíF (v (i) ).
The Jacobian matrix J has the form
Ô£Æ
Ô£π
J1,1 J1,2 J1,3
‚àÇFi (v (k) )
Ô£ª,
=Ô£∞
(7)
J = [Jij ] =
(k)
‚àÇvj
J2,1 J2,2 J2,3
with:
J1,1 ‚àà
J1,2 ‚àà
J1,3 ‚àà
J2,1 ‚àà
(k)

‚àÇFi (v )
(k)
‚àÇvj

n(n+1)
√ón
2

where

n(n‚àí1)
n(n+1)
√ó
2
2
n(n+1)
√ón
2

n√ón

‚àÇFi (v (k) )
(k)
‚àÇvj

where

where

where

= Œ¥i,s qr,j + Œ¥j,s qr,i .

‚àÇFi (v (k) )
(k)
‚àÇvj
(k)

‚àÇFi (v )
(k)
‚àÇvj

= 0.

= 0.

= ‚àíŒª‚àós qj,s Œ¥i,r ‚àí Œª‚àós qi,s Œ¥j,r ‚àí Œ¥j,r
‚àí
n(n‚àí1)
2

J2,2 ‚àà

n√ó

J2,3 ‚àà

n√ón

n
z=1 qi,z

where

where

n
k=s+1 ts.k qj,k

n
k=z+1 tz,k Œ¥j,r Œ¥k,s .
n
‚àÇFi (v (k) )
= ‚àí z=1 qi,z
(k)
‚àÇvj

‚àÇFi (v (k) )
(k)
‚àÇvj

n
k=z+1 qj,z Œ¥ r,z Œ¥s,k

.

= (Ar )i,j .

The solutions of the system of equations J(v (i) )s(i) = ‚àíF (v (i) ) has computational complexity of O(n6 ) which makes this algorithm very expensive. This
algorithm, as other Newton-like algorithm in inverse problems, has serious problems of convergence unless the initial guess is close enough to the solution. To
alleviate this problem, the algorithm has been implemented including a wellknown globalization technique, Armijo's rule [9].

3.1

Experimental Results

The algorithm has been developed in C language, by using BLAS and LAPACK
libraries [2]. Experimental results and validations have been carried out in a PC
with Intel Xeon processor, at 2GHz. and 1GB. of RAM.
It has been tested using random matrices with known eigenvalues. The initial
guess has been chosen by perturbating the solution, v (0) = v ‚àó + Œ¥ , with a small
Œ¥ = 0.1. The execution time of the algorithm can be divided in two parts, the initialization phase and iterative phase; gure 1 shows (for dierent problem sizes)

Parallel Resolution with Newton Algorithms of the INEP

233

number of iterations

0,01
0,18
0,01
0,45
0,01
8,53
0,01
52,31
0,01 198,19
0,02 1147,38

2
2
3
5
5
7

Time of process

8
10
20
30
40
50

Iteration time

initial time

the time for the initial phase, the iteration time and the number of iterations to
reach the solution.
The algorithm needs large memory resources, since it needs to create very
large Jacobians matrices. As an example, for a problem of size of 210 √ó 210 the
Jacobian matrix would have a size of 132405 √ó 132405. As a consequence, it can
be applied only to small problems
200,00

initial time

180,00

Iteration time

160,00
140,00
120,00
100,00
80,00
60,00
40,00
20,00
0,00
8

10

20

30

40

50

Size

Fig. 1. Time in seconds for `Brute Force' algorithm

4

Restricted Newton's Method

A dierent approach to the problem is to solve the nonlinear system
Fi (d(k) ) = Œªi (d(k) ) ‚àí Œª‚àói = 0 i = 1, ..., n.

(8)

Newton`s method can be applied as well to this system, through the iteration:
d(k+1) = d(k) ‚àíJ(d(k) )‚àí1 F (d(k) ) = d(k) +s(k) with J(d(k) )s(k) = ‚àíF (d(k) ), where
d ‚àà n , J ‚àà n√ón A similar idea is used in [8] for the symmetric case. In this
work, we have approximated the Jacobian matrix through Finite Dierences:
J=

‚àÇFi (d)
‚àÇdj

‚àº
=

Fi (d + ej h) ‚àí Fi (d)
h

=

eig(A(d) + hAj )i ‚àí eig(A(d))i
h

(9)

The main cost of this algorithm is the computation of the Jacobian matrix,
since it is needed to compute (n+1) times the eigenvalues of an n√ón matrix, that
is, the complexity is O(n4 ). The resolution of the linear system J(d(k) )s(k) =
‚àíF (d(k) ) has only a cost of O(n3 ). As in the former section, the algorithm was
implemented using Armijo's rule.

4.1

Experimental Results: Sequential Implementation

Figure 2 is analogous to gure 1 in the former section, reecting the costs of the
start-up phase, of the iterating phase and the number of iterations.
Matrices and initial guesses were chosen as in the former section. It is quite
clear that the execution times of this algorithm are lower than the Brute Force
algorithm ones.
However, it can still be improved through parallel computing techniques; this
is discussed in the next section.

234

P.V. Alberti, V.M. Garc√≠a, and A.M. Vidal
initial time

8
10
20
30
40
50

0,01
0,01
0,01
0,01
0,06
2,56
0,18 11,93
0,42 36,85
0,83 175,91

1
1
2
2
2
4

Iteration time

1200

time of process

number of iterations

Iteration time

initial time

1400

1000
800

600
400
200
0

8

10

20

30

40

50

Size

Fig. 2. Restricted Newton: Execution times (s.) and number of iterations

4.2

Parallelization of the Restricted Newton Method

The parallelization was carried out with the standard ScaLAPACK [3] approach,
that is, distributing in a 2-D processors mesh the data of the problem; in this case,
the matrices A0 , A1 , A2 , ¬∑ ¬∑ ¬∑ , An , the initial guess d(0) = [d1 , d2 , d3 , ¬∑ ¬∑ ¬∑ , dn ]T
and the desired eigenvalues œÅ‚àó = [Œª‚àó1 , Œª‚àó2 , Œª‚àó3 , ¬∑ ¬∑ ¬∑ , Œª‚àón ]T .
A C language subroutine was written to create the Jacobian matrix:
(k)
eig (A(d)+hAj )‚àíeigi (A(d))
i = 1, 2, ¬∑ ¬∑ ¬∑ , n; j = 1, 2, , n .
Jij = i
h
An obvious parallelization possibility was to assign each column of the Jacobian matrix (solution of a single eigenvalue problem) to each processor. The
second option was to perform each dierent eigenvalue problem by using all
the processors, making use of the SCALAPACK 2-D distribution. This second
option was chosen to take full advantage of the parallel SCALAPACK routines.
All the other steps in the algorithm correspond to calls to BLACS, PBLAS
or ScaLAPACK.

4.3

Numerical Experiments

The code was tested in a cluster of PC's with up to 7 processors. As before,
the matrices have random values and have known eigenvalues, and the times
of the initial part (T-ini) and of the iterative part (T-iter) have been recorded
separately. So, the speed-up can be expressed as a function of the number of
iterations k to reach convergence and of the number of processors, p:
Sp =

Tini 1 + k Titer 1
.
Tini p + k Titer p

(10)

In gure 3 it is shown the execution time for several sizes, of both the initial part
and the iterative part as a function of the number of processors. The speed-up
as a function of the number of processors is shown in gure 4.
It can be noted the inuence of the dimensions of the 2-D mesh used in
the ScaLAPACK. Thus, for square logical 2-D meshes (i.e. p = 4) eciency is
optimum.
It can be seen that the algorithm works quite well for large problem sizes.

Parallel Resolution with Newton Algorithms of the INEP
T-ini

512

120000

300,000

896

100000

250,000

1000

300
512
896
1000

80000

200,000

Time

Time

T-iter

300

350,000

235

150,000

60000

100,000

40000

50,000

20000

0,000

0

1

2

3

4

5

6

7

1

2

3

processor

4
5
processor

6

7

Fig. 3. Execution time of the initial phase (T-ini) and iterative phase (T-iter)
300

3,0

896

5,0

896

2,5

1000

1000

4,0
3,0
2,0
1,0

T-iter

512

512

Speed Up

Speed Up

3,5

T-ini

300

6,0

2,0
1,5
1,0
0,5

0,0

0,0
2

3

4

5

6

7

2

Processor

3

4
5
Processor

6

7

Fig. 4. Experimental Speed Up

5

Conclusions

In this paper, we have discussed the IANSEP, analyzed its peculiarities studying the 2 √ó 2 case, and proposed two solution methods. One of them has been
parallelized, giving good results. The algorithms have been implemented using
C language and standard libraries such as LAPACK, ScaLAPACK, so that the
resulting codes are ecient and portable.
The study in section 2 shows that the Non-Symmetric problem is far more
complex than the symmetric one, and that even if the matrix A(d) has only real
eigenvalues, the problem may not have any solution.
The 'Brute Force' approach is an attempt to state the problem directly, that
for some problems (and thanks to the power of today's processors) can be successful, but which compares poorly with the other method, the restricted Newton
method.
The method in section 3 is a good option for the solution of the IANSEP,
working quite well both in its sequential and parallel versions.

Acknowledgement
This work has been supported by Spanish MYCT and FEDER under Grant TIC
2003-08238-C02-02.

236

P.V. Alberti, V.M. Garc√≠a, and A.M. Vidal

References
1. Pedro V. Alberti and Antonio M. Vidal. Soluci√≥n Paralela de M√≠nimos Cuadrados
para el Problema Inverso Aditivo de Valores Propios. Technical Report DSICII/03/02, Departamento de Sistemas Inform√°ticos y Computaci√≥n, Universidad
Polit√©cnica de Valencia, Camino de Vera s/n, 46022, Valencia Espa√±a, 2002.
2. E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. LAPACK
User's Guide. SIAM, Second edition, 1995.
3. L. S. Blackford, J. Choi, A. Cleary, E. D. Acevedo, J. Demmel, I. Dhillon, J. Dongarra, S. Hammarling, G. Henry, A. Petitet, K. Stanley, D. Walker, and R. C.
Whaley. ScaLAPACK User's Guide. SIAM, 1997.
4. D. L. Boyle and G. H. Golub. A survey of inverse eigenvalue problems. Inv. Prob.,
595-622, 1987.
5. Xuzho Chen and Moody T. Chu. On the least squares solution of inverse eigenvalue
problems. SIAM J.Numer. Anal., 33(6):24172430, 1996.
6. Moody T. Chu. Inverse eigenvalue problem. SIAM Rev., 40(1):139, March 1998.
7. Hua Dai. A Numerical Method for Solving Inverse Eigenvalue Problem. Technical
Report TR/PA/98/33, Nanjing 210016, People's Republic of China, 1998.
8. S. Friedland, J. Nocedal, and M. L. Overton. The formulation and analysis of
numerical methods for inverse eigenvalue problems. SIAM Anal. Vol 24, june, N3,
24(5):634667, June 1987.
9. C. T. Kelley. Iterative methods for linear and nonlinear equations. SIAM Pub.,
1995.
10. J. Peinado and A.M. Vidal. A new parrallel approach to the toeplitz inverse
eigenproblem using the newton's method. Lecture Notes in Computer Science.
Springer-Verlag, 1999.

