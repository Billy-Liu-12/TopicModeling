Procedia Computer Science
Volume 29, 2014, Pages 754–758
ICCS 2014. 14th International Conference on Computational Science

Computational Optimization, Modelling and
Simulation: Past, Present and Future
Xin-She Yang1, Slawomir Koziel2, and Leifur Leifsson2
1
2

School of Science and Technology, Middlesex University, London NW4 4BT, United Kingdom.
Engineering Optimization and Modeling Center, School of Science and Engineering, Reykjavik
University, 101 Reykjavik, Iceland.
xy227@cam.ac.uk

Abstract
An integrated part of modern design practice in both engineering and industry is simulation and
optimization. Significant challenges still exist, though huge progress has been made in the last few
decades. This 5th workshop on Computational Optimization, Modelling and Simulation (COMS 2014)
at ICCS 2014 will summarize the latest developments of optimization and modelling and their
applications in science, engineering and industry. This paper reviews the past developments, the stateof-the-art present and the future trends, while highlighting some challenging issues in these areas. It
can be expected that future research should focus on the data intensive applications, approximations
for computationally expensive methods, combinatorial optimization, and large-scale applications.
Keywords: algorithm; computational optimization; data-intensive method; large-scale optimization; metaheuristic;
nonlinear optimization; surrogate-based optimization; simulation.

1 Introduction
Optimization, together with modelling and simulation, has been an integrated part of modern
design practice. The main purpose for any design problem is to find a set of good, feasible, ideally the
global best, solutions to a given problem, measuring against a set of design criteria such as the
minimum costs, high performance, sustainability, recyclability and energy efficiency (Yang, 2010;
Talbi, 2009; Koziel et al., 2008; Bandler et al., 2004; Leifsson and Koziel, 2010). Nowadays, design
requirements and constraints are more stringent, which may require a paradigm shift in scientific
thinking and design practice. Real-world applications often involve highly complex constraints and
uncertainties with often multiple, conflicting objectives. Such noisy environments necessitate robust
designs that allow the design to be sufficiently robust under the acceptable variations of materials
properties and parameters in practice (Yang and Gandomi, 2012; Koziel and Yang, 2011).
The 5th workshop on Computational Optimization, Modelling and Simulations (COMS 2014) at
the ICCS 2014 strives to provide a platform to foster discussions and exchanges of ideas about the

754

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.067

Computational Optimization, Modelling and Simulation ...

X. Yang, S. Koziel and L. Leifsson

latest developments in optimization and computational modelling with a focus on applications in
science, engineering and industry. In the remaining sections of this summary paper, we will discuss
the past, present and future of computational optimization, modelling and simulation.

2 Past Success
The past two decades have seen a series of success in optimization and simulation techniques. Due
to the extensive progress, it is not possible to summarize all relevant developments in this paper.
Therefore, we will focus on only two areas: algorithms and computational techniques. On the one
hand, swarm intelligence based algorithms for optimization have been very active since the early
1990s. For example, the development of ant colony optimization (ACO) in 1992 and particle swarm
optimization (PSO) in 1995 had essentially opened up the modern era of swarm intelligence based
computing, or bio-inspired computing in general (Yang, 2010; Talbi 2009). At the same time, genetic
programming also formed a substantial part of the activities in soft computing and computer science.
In addition, differential evolution also appeared in 1997, followed by the development of harmony
search in 2001. The bee-based algorithms appeared in around 2005, and the firefly algorithm appeared
in 2008. Then, cuckoo search was published in 2009, followed by the appearance of the bat algorithm
in 2010. In fact, the number of algorithms expands significantly with more than four dozen algorithms
and more than 100 variants. In fact, these algorithms have been applied in almost all areas of science
and engineering (Koziel and Yang, 2011).
On the other hand, modelling and computational techniques in the context of optimization have
also been developed and improved in the last two decades. Traditional modelling techniques tended to
focus on the mathematical models based on partial differential equations and accurate models, while a
vast majority of mathematical models are not solvable analytically, and thus approximate methods and
numerical methods are the alternatives. Thus, the modern trends tend to use approximate models to
speed up the evaluations computationally. Surrogate-based models and space mapping methods have
shown promising results in reducing the computational costs in evaluating design options (Forrester
and Keane, 2009; Forrester et al., 2006; Leifsson and Koziel, 2010; Koziel at al., 2013). These
approximation methods try to save computational costs by using a cheaper but faster surrogate model
to replace the high-fidelity models, based on the assumptions that the cheaper models will contain the
same local modality of the objective landscape, and the optimality can be reached in a finite number of
steps. Combined information can usually be used to approximate the local landscape by methods such
as kriging, polynomials, neural networks and other techniques. These modelling techniques in
combination with optimization algorithms form surrogate-based optimization methods (Koziel et al.,
2013). All these techniques have demonstrated good reduction of computational costs and
effectiveness.

3 The Present State of the Art
Since most real-world problems are not analytically tractable, most models in practice use some
sort of approximations. There has been tremendous progress in the past five decades concerning
numerical methods such as the finite element methods, finite volume methods, computational fluid
dynamics and other methods; however, for highly nonlinear and transient problems, especially those
involving Navier-Stokes equations, no truly efficient and accurate methods can be suitable for the
increasing needs for faster, realistic simulations. For the optimization purpose, three areas are quite
exciting: metaheuristic optimization algorithms, approximate models, and data-intensive methods.
Firstly, nature-inspired metaheursitic algorithms have been developed to solve nonlinear,
multimodal optimization problems in recent years. For example, cuckoo search, firefly algorithm and

755

Computational Optimization, Modelling and Simulation ...

X. Yang, S. Koziel and L. Leifsson

bat algorithm have all shown promising efficiency for optimization (Yang, 2010; Yang, 2013). These
algorithms have simplicity, flexibility and parallelism. Such algorithms are easy to implement and
their core algorithmic computation should take no more 100 lines in any programming language, and
they are yet very flexible to deal with very tough, complex optimization problems, either continuous
or discrete. In addition, these algorithms are also gradient-free optimization methods, which do not use
any derivative information and thus have the advantages of gradient-free methods. Furthermore, as
these algorithms use multiple agents, and thus it is natural to use parallel implementations for largescale optimization problems. In fact, swarm intelligence based optimization algorithms have become
the hotspot of the current research in optimization and computational intelligence.
Secondly, approximate models for simulating the main behavior of physical, chemical and
biological systems are becoming increasingly popular. For example, in microwave engineering, it is
very computational expensive to produce highly accurate models and simulation results, due to the
computational costs in solving the full Maxwell equations, and therefore, physics-based model and
surrogate-based model have to be used for improving the computational efficiency (Koziel et al, 2008;
Koziel and Yang, 2011). Similarly, in aerospace engineering, CFD-based models and design
optimization can be improved by using multi-fidelity models properly (Leifsson and Koziel, 2010).
For some complex tasks, the actual system behavior may not have any explicit, closed expressions,
even in terms of equations. In this case, some approximate learning-based models such as neural
networks can be very useful and effective in practice.
Finally, more and more applications and models are data-intensive models. Applications in data
mining such as feature selection, classification and image processing are both data intensive and
computationally expensive. These data-intensive problems are often optimization problems with extra
challenging issues. Apart from the difficulty in dealing with large volume datasets, evaluation of an
option can be very computationally expensive. For example, the classification of a large dataset of
several gigabytes into multiple classes can be very time consuming, and it is essentially a challenging
optimization problem. Methods such as CURE (clustering using representatives) can be very effective,
though there is often no guarantee for global optimality (Rajaraman et al., 2010).
Overall, the truly effective solution methods for a challenging optimization problem require the
smooth running and high efficiency of three key components: an efficient optimization algorithm, a
highly accurate model for a given design option, and a computationally effective numerical method to
evaluate the design models. The overall optimization process can be slowed down by any possible
bottleneck in any one of the three parts. Therefore, future challenges need to address all these three
components/areas. However, we will only focus on some of these areas in the rest of this paper when
outlining out recommendations for future research.

4 Future Trends
The developments concerning computational optimization, modelling and simulation continue to
be rapid and significant. Due to the vast expansion of these areas, it is not possible to discuss all
relevant issues and this workshop can only provide a snapshot in a timely manner. The accepted
papers of this workshop COMS2014 at ICCS 2014 have spanned a wide range of applications and
reflect the state-of-the-art developments in computational optimization, modelling and simulation.
From the past five workshop of this COMS series, we can highlight six areas as future trends for
further research. These six areas are: algorithm development, computationally expensive techniques,
large-scale optimization, multi-objective optimization, data-intensive applications, and combinatorial
optimization.
Algorithm developments will still be one of the main activities in optimization. After all, for tough
optimization problems such as NP-hard combinatorial problems, more efficient methods need to be

756

Computational Optimization, Modelling and Simulation ...

X. Yang, S. Koziel and L. Leifsson

developed. In addition, mathematical analysis of existing algorithms is highly needed. At the moment,
there are some significant gaps between theory and practice.
Computationally expensive techniques will continue to be another main area and it may still
remain challenging for quite a while. After all, as sizes of optimization problems become larger, and
the need for high accuracy becomes more important, evaluations of computational models will become
more expensive. The simple use of the parallel and cloud computing facilities may not solve the
problem. It may require a paradigm shift in thinking of ways to approximations and building of more
accurate but cheaper models.
As optimization moves into real-world applications, large-scale optimization is becoming the main
norm. A problem can typically have thousands or even millions of design variables, and such largescale problems become very challenging. For the moment, it is not clear if the algorithms and methods
that work well for small-scale problems can be scaled up to solve large-scale problems. Again, grid
and cloud computing may not be able to solve all the problems. A more fundamental rethinking of the
methods may be needed.
Most engineering applications and other real-world applications are multi-objective, and thus
multi-objective optimization should be the main focus. Inevitably, multi-objective optimization
problems are even more computationally expensive, compared with their single-objective counterparts
since the Pareto front construction can typically require many times more computational efforts.
Currently, most existing studies have focused on two or three objectives. In reality, dozens of design
objectives need to be considered for realistic design optimization problems (Ouaarab et al., 2013;
Yang and Deb, 2013). Therefore, there is a strong need to develop more research in this area. In
addition, parameter-tuning for algorithms can be very important to ensure the best performance of an
algorithm (Yang et al., 2013) and more research is highly needed.
Obviously, as data volumes are rapidly expanding, driven by information technology and the social
networks, data-intensive applications will become ever more important. In fact, the so-called digital
economy and data mining form the hotspot of the current research in many applications.
The above optimization techniques may be continuous, discrete or even mixed types. A class of
discrete optimization may deserve special attention. That is combinatorial optimization. Combinatorial
problems such as the traveling salesman problem (TSP) can be NP-hard, and there is no known
efficient algorithm at the moment, though metaheuristic algorithms have demonstrated some
promising effectiveness in solving TSP (Ouaarab et al., 2013). However, these problems do have
diverse applications. Therefore, substantial efforts for future research should be dedicated to
combinatorial optimization, especially those large-scale, real-world, combinatorial optimization
applications.
Obviously other areas such as parameter tuning of algorithms are also important (Yang et al.,
2013). The review and discussion presented in this paper can only cover a fraction of the large areas. It
can be expected more research efforts in the above areas can be very useful with potential far-ranging
impacts and implications.

References
Yang, X. S., (2010). Engineering Optimization: An Introduction with Metaheuristic Applications,
John Wiley & Sons.
Talbi, E. G., (2009). Metaheuristics: From Design to Implementation, John Wiley & Sons.
Koziel, S., Bandler J. W., and Madsen, K., (2008). Quality assessment of coarse models and
surrogates for space mapping optimization, Optimization and Engineering, 9(4): 375-391.
Leifsson L. and Koziel, S., (2010). Multi-fidelity design optimization of transonic airfoils using
physics-based surrogate modelling and shape-preserving response prediction, J. Comp. Science, 1(2):
98-106.

757

Computational Optimization, Modelling and Simulation ...

X. Yang, S. Koziel and L. Leifsson

Yang, X. S. and Gandomi, A. H., (2012). Bat algorithm: a novel approach for global engineering
optimization, Engineering Computations, 29(5):464-483.
Bandler, J. W., Cheng, Q. S., Dakroury, S. A., Mohamed, A. S., Bakr, M. H., Madsen, K., and
Sondergaard, J., (2004). Space mapping: the state of the art, IEEE Trans. Microwave Theory Tech.,
52(1): 337 361.
Koziel, S. and Yang, X. S., (2011). Computational Optimization, Methods and Algorithms,
Springer, Heidelberg.
Forrester, A.I. J., Keane, A.J., (2009). Recent advances in surrogate-based optimization, Prog. in
Aerospace Sciences, 45 (1-3): 50-79.
Forrester, A.I.J., Bressloff, N.W., and Keane, A.J., (2006). Optimization Using Surrogate Models
and Partially Converged Computationally Fluid Dynamics Simulations, Proceedings of the Royal
Society A: Mathematical, Physical and Engineering Sciences, 462(2071): 2177-2204.
Koziel, S., Yang, X. S., and Zhang, Q. -J., (2013). Simulation-Driven Design Optimization and
Modelling for Microwave Engineering, Imperial College Press, London.
Yang, X. S., (2013). Multiobjective firefly algorithm for continuous optimization, Engineering
with Computers, 29(2): 175-184.
Rajaraman, A., Leskovec, J., Ullman, J. D., (2010). Mining of Massive Datasets, Cambridge
University Press, Cambridge, UK.
Ouaarab, A., Ahiod, B., Yang, X. S., (2013). Discrete cuckoo search algorithm for the travelling
salesman problem, Neural Computing and Applications, 2013.
http://link.springer.com/article/10.1007%2Fs00521-013-1402-2
Yang, X. S., and Deb, S., (2013). Multiobjective cuckoo search for design optimization,
Computers & Operations Research, 40 (6): 1616-1624.
Yang, X. S., Deb, S., Loomes, M., Karamanoglu, M., (2013). A framework for self-tuning
optimization algorithms, Neural Computing and Applications, 23(7-8): 2051-2057.

758

