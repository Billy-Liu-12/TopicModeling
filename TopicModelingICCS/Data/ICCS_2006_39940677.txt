Path Following by SVD
Luca Dieci1 , Maria Grazia Gasparo2 , and Alessandra Papini3
1

2

3

School of Mathematics, Georgia Institute of Technology,
Atlanta GA 30332, USA
dieci@math.gatech.edu
Universit`
a di Firenze, Dip. Energetica “S. Stecco”, via C. Lombroso 6/17,
I-50134 Firenze, Italia
mariagrazia.gasparo@unifi.it
Universit`
a di Firenze, Dip. Energetica “S. Stecco”, via C. Lombroso 6/17,
I-50134 Firenze, Italia
alessandra.papini@unifi.it

Abstract. In this paper, we propose a path-following method for computing a curve of equilibria of a dynamical system, based upon the
smooth Singular Value Decomposition (SVD) of the Jacobian matrix.
Our method is capable of detecting fold points, and continuing past
folds. It is also able to detect branch points and to switch branches at
such points. Algorithmic details and examples are given.
Subject Classiﬁcations: 65F15, 65F99.

1

Introduction

One of the most important and recurring problems in applications is that of
ﬁnding solutions of overdetermined nonlinear systems, f (u) = 0, where f is
a C k map, k ≥ 1, from (part of) Rn+1 → Rn . Standard occurrences of this
situation are homotopy techniques for solving nonlinear systems, see [15], and
also techniques to ﬁnd equilibria or periodic solutions of parameter dependent
dynamical systems, see [11]. In such case, the system is usually written as
f (x, α) = 0, f : Rn × R → Rn .

(1)

As it is well understood, assuming that 0 is a regular value for f , the solution
set of f (u) = 0, is a C k curve (e.g., see [10]); we stress that, for (1), this does
not mean that the curve can be globally parametrized in α. Computation of this
regular curve of equilibria is the task of path-following algorithms, or continuation methods. The successful continuation methods are of predictor-corrector
type: From knowledge of a point on the curve, they seek a new point on the
curve at a certain (arc-length) distance from the present one, by iteratively correcting an initial prediction of this new point. The standard prediction stage is
carried out by a tangent (or Euler) approximation, and the standard correction
is performed by Newton’s method or one of its variants. We refer to [1] for an
excellent overview of continuation techniques. Now, while continuing the curve of
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 677–684, 2006.
c Springer-Verlag Berlin Heidelberg 2006

678

L. Dieci, M.G. Gasparo, and A. Papini

equilibria, a robust algorithm must also be able to adaptively choose the steps
to be taken, and to detect bifurcation values (e.g., points where two solution
curves intersect, or points where –for (1)– the curve fails to be parametrizable in
α). Predictor-corrector algorithms are well understood and reliable implementations exist; see [9, 15]. In practical terms, the largest cost of prediction-correction
methods is given by the need for frequent factorizations of the Jacobian matrices
involved.
One aspect which has not been satisfactorily resolved in previous works on
predictor-corrector algorithms is that the dynamical point of view, inherent in
the continuation context, gets lost at the linear algebra level: the linear algebra
is done in a static way, namely canned linear algebra software is used to factor
the Jacobians. Our approach, which we present in this paper, is to view the
Jacobians as smooth functions and to use the underlying smoothness of the
factors in their decompositions to device better continuation strategies; at the
same time, we will monitor variation of the factors to determine how to choose
the continuation steps. Motivated by their relevance in detecting bifurcation
phenomena, and by the provable smoothness in situations of practical interest
(see [6] for the C k case, and [4] for the analytic case), our particular emphasis here
is on SVD decompositions. We must point out right away that a smooth SVD
will ordinarily require a singular value to cross zero when the Jacobian becomes
singular (one obtains a signed SVD), and two singular values will exchange
ordering when they coalesce (one obtains an unordered SVD).

2

Path Following Methods Via SVD

In this work, we focus on computing curves of equilibria of (1): f (x, α) = 0. By
using arc-length parametrization, the problem is rewritten as
f (x(s), α(s)) = 0, x(s)
˙ T x(s)
˙
+ α(s)
˙ 2 = 1,
T
is the tangent vector and satisﬁes
where (x(s),
˙
α(s))
˙

fx x˙ + fα α˙ = 0.

(2)

A point (x, α) on the curve is a regular point if fx (x, α) is invertible, is a fold
(turning) point if fx (x, α) is singular and fα (x, α) ∈ range(fx (x, α)), is a branch
fx fα
point if fx (x, α) is singular and the enlarged matrix M =
has rank
x˙ T α˙
equal to n. At a regular point there is a unique tangent; this also occurs at a
fold point with α˙ = 0; at a branch point instead, there are two tangents and
two branches of equilibria crossing at the point. A branch point may occur with
fα ∈ range(fx ) and rank(fx ) = n − 1, and also with rank(fx ) = n − 2.
The pseudo arc-length path following approach (see e.g. [10], [13]) can be
sketched as follows. Given a point (x0 , α0 ) = (x(s0 ), α(s0 )) on the path (i.e.
f (x0 , α0 ) = 0), a tangent (x˙ 0 , α˙ 0 ) and s1 = s0 + h for some steplength h, we
seek (x1 , α1 ) = (x(s1 ), α(s1 )) by solving

Path Following by SVD

F (x, α) ≡

f (x, α)
= 0.
x˙ T0 (x − x0 ) + α˙ 0 (α − α0 ) − h

679

(3)

To solve (3), we can use an iterative method starting from the tangent predictor
(0)

(0)

(x1 , α1 ) = (x0 , α0 ) + h(x˙ 0 , α˙ 0 ).
Typically, the stationary Newton method is used as corrector: for k = 0, 1, . . .
(0)

(0)

(0)

(0)

fx (x1 , α1 ) fα (x1 , α1 )
x˙ T0
α˙ 0
(k+1)

(x1

(k+1)

, α1

Δx
(k)
(k)
= −F (x1 , α1 )
Δα

(k)

(4)

(k)

) = (x1 + Δx, α1 + Δα) .

The idea to use SVD for computing bifurcations of vector ﬁelds appeared
in [5] several years ago. Afterwards, as far as we could determine, it has not
been considered any more. Why? Surely, one reason is that existing techniques
typically work just ﬁne. But, we believe that a more cogent reason is that by
using the standard linear algebra SVD, whereby singular values are kept always
positive and ordered, it is nearly impossible to locate exactly a fold or a branch
point: One would need to step exactly at such points! Simply monitoring small
singular values, as done in [5], is at best ineﬃcient and potentially misleading.
The answer to this impasse is beautifully provided by smoothness: If the Jacobian
fx becomes singular, a singular value will go through 0, and monitoring the signs
of the singular values will suﬃce. As we will make clear below, our smooth SVD
method provides not only a theoretically sound, but also a computationally
interesting, way to compute curves of equilibria. As a matter of fact, we know
of no other technique which allows at once to compute the points on the curve,
provide tangents to form the predictor, detects folds and branch points, and also
allows easily to switch branches at branch points.
Motivated by the work [7], where we studied several methods to compute
smooth curves of SVD, we have written a Matlab code implementing a SVDbased path following method for tracking smooth path of equilibria. Our code
computes a smooth SVD of fx at points on the curve and uses this SVD to
locate folds and generic branch points (switching branches and continuing new
branches). Moreover the code avoids to compute fx and fα at the predictor and
solves (3) by a Newton-type method, where fx (x0 , α0 ) and fα (x0 , α0 ) are used
(0)
(0)
(0)
(0)
instead of fx (x1 , α1 ) and fα (x1 , α1 ) (cfr. (4)). From now on, the symbols
fx and fα will be used to denote fx (x0 , α0 ) and fα (x0 , α0 ) respectively.
Notice that if fx = U ΣV T , then the Newton-type system
fx fα
x˙ T0 α˙ 0

Δx
c
=
Δα
d

becomes simply
Σ
U T fα
T
x˙ 0 V α˙ 0

UT c
V T Δx
=
Δα
d

680

L. Dieci, M.G. Gasparo, and A. Papini

which has a very simple structure and can be solved with a computational cost
of O(n) ﬂops, by ad hoc substitution techniques tailored for the two cases Σ
invertible and Σ singular. So, taking into account the matrix-vector products,
each iteration costs O(n2 ) ﬂops.
Analogously, the SVD of fx is easily exploited in the computation of the
tangents. Indeed, problem (2) becomes
ΣV T x˙ + U T fα α˙ = 0.
If Σ is invertible, we set α˙ = ±1 (the sign is chosen so that we do not trace back
the same piece of the curve), x˙ = −αV
˙ Σ −1 U T fα and then we normalize. If we are
at a fold point (Σ singular and fα ∈ range(fx )), the solution is (x,
˙ α)
˙ = (V en , 0).
Finally, at a branch point (rank[fx , fα ] = n − 1, but rank(M ) = n) we have two
tangents in the kernel of [fx , fα ], and we proceed as follows: (1) We approximate
the tangent, call it u, to the branch that we are following, by normalizing the
secant approximation obtained using the last two points on the curve; (2) we
seek a point on the other branch by looking for solutions lying on a hyperplane
parallel to the tangent line we have, and at a distance h from it (this we can do
using a vector v in the null space of [fx , fα ] orthogonal to u).

3

Continuation of the SVD

In [7], we proposed several techniques to compute a smooth block-SVD for a
smooth matrix-valued function A(s) : [a, b] → Rn×n . In the context of path
following for equilibria, we have A(s) = fx (x(s), α(s)) and want to smoothly
compute its complete signed SVD. The theory developed in [7] guarantees that
one of the algorithms there studied, namely Algorithm BSVD, can be successfully used to this scope as long as the singular values remain distinct. We refer
to [7] for details. Here we only recall that this method is essentially based on
the solution of suitable algebraic Riccati equations at each continuation step.
These equations are solved by Newton’s method, for which we can construct a
second order approximation as initial guess. Convergence is ensured as long as
the continuation steplength h is suﬃciently small.
If two singular values coalesce within a continuation step, the Newton iteration for the Riccati equations may either converge to a wrong solution or fail
to converge. Now, having two singular values coalescing is a non-generic occurrence for one-parameter problems (see [6]), and thus one should not witness it in
practice; naturally, even less likely (and thus not very interesting) is the case of
three or more singular values coalescing at once, a case which we can thus safely
disregard. However, special symmetries in the problem make the occurrence of
two singular values coalescing (and crossing) possible, and we want methods
robust enough to handle this case. Futhermore, singular values nearing each
other can cause numerical diﬃculties. To overcome this critical situation, in the
present paper, we implemented a novel technique, which we call the accordion
strategy. The idea is to adaptively switch from a complete SVD to a block SVD in

Path Following by SVD

681

order to bypass coalescing (or just close) singular values. In practice, at each step
we monitor the singular values to detect if we are nearing a possible crossing.
If this is the case, we group into a 2 × 2 block the two singular values which
seem to coalesce and apply Algorithm BSVD to smoothly continue a block-SVD
with one block of dimension 2 and the others of dimension 1. This structure is
possibly maintained over several continuation steps, until the crossing has been
safely passed, and we can split the 2 × 2 block and proceed with a complete
SVD. Of course, as the continuation proceeds, the 2 × 2 block must be further
decomposed to get always a smooth complete SVD. To do this, we solve a simple
Procrustes problems (see [12] for analogous reﬁning methods in the context of
computing analytic path of SVD). In the context of continuation methods for
large bifurcation problems, strategies where one dynamically chooses the block
sizes have also been considered in [2, 3].
The accordion strategy works very well in practice so long as coupled with
a reliable criterion to select the steplength at each continuation step. In the
continuation context, the stepsize control is generally convergence-dependent
through the number of performed iterations ([8], [9],[10]). In our code, instead,
we implemented a technique based on the distance between the predictors and
the converged values. This is similar in spirit to the stepsize control in codes for
solving initial value problems of diﬀerential equations.
Finally, the code allows to locate fold and branch points accurately. Given
an interval [s0 , s1 ] such that σn (s0 ) · σn (s1 ) < 0, we use the secant method to
ﬁnd s∗ s.t. σn (s∗ ) = 0 and compute the point (x(s∗ ), α(s∗ )) on the equilibria
curve. Obviously, each secant iteration involves a continuation step from s0 to
the current iterate.

4

Algorithmic Details

We now discuss in more details the three key algorithmic choices we have adopted
in our code.
1. When and how to group/split singular values. Given s0 , assume we have
the decomposition A(s0 ) = U (s0 )Σ(s0 )V (s0 )T with σ1 (s0 ) > σ2 (s0 ) > . . . >
σn (s0 ) ≥ 0. We predict the singular values at s1 = s0 + h by [6]
(pred)

σi

= σi (s0 ) + (U T (s0 )(A(s1 ) − A(s0 ))V (s0 ))ii = σi (s0 ) + hσ˙ i (s0 ) + O(h2 )

and declare a possible crossing if
(pred)

either

(pred)

(pred)

(pred)

σ
σi+1 − σi
−σ
< 0 or i+1(pred) i
σi+1 (s0 ) − σi (s0 )
σi
+1

≤η

for some small η > 0 (η = 10−4 is the default value). In this case, we group
σi , σi+1 into a 2 × 2 block.
Once the singular values σi+1 (s1 ) and σi (s1 ) have been computed, the 2 × 2
block is unrolled if
σi+1 (s1 ) − σi (s1 )
> η.
σi (s1 ) + 1

682

L. Dieci, M.G. Gasparo, and A. Papini

2. Reﬁnement of a 2 × 2 block to get a complete SVD. Given a block C, we get
(pred)
a standard decomposition UCT CVC = diag(σ1 , σ2 ) with sign(σi ) = sign(σi
)
and then possibly modify it to recover smoothness in the complete SVD. To
do this, we solve a Procrustes problem to minimize the distance (in Frobenius
norm) between UC , VC and suitable reference orthogonal factors. If σ1 = σ2 , UC
and VC are correct up to permutation and/or changes of signs of their columns.
If σ1 = σ2 , then UC and VC may have to be changed into UC Q and VC Q for a
suitable orthogonal matrix Q.
3. Stepsize control. Denote by x(pred) , α(pred) , Σ (pred) the predictors used for
x(s1 ), α(s1 ) and Σ(s1 ), respectively. Our steplength choice tries to perform a
mixed absolute/relative error control, monitoring the errors x(pred) − x(s1 ) ,
α(pred) − α(s1 ) , Σ (pred) − Σ(s1 ) , in such a way that the iterative procedure
involved in a continuation step will converge in a few iterations. Moreover, starting from the second continuation step, we try to control also U (pred) − U (s1 )
and V (pred) −V (s1 ) , where U (pred) = U (s0 )+hU˙ (s0 ), V (pred) = V (s0 )+hV˙ (s0 ),
and the derivatives are approximated by diﬀerences using the orthogonal factors
obtained at the last two steps. At the end of a continuation step of size h, we
compute the weighted norm ρσ =

1
n

(pred)

σi
−σi 2
n
i=1 ( r |σi |+ a ) ,

where

r

and

a

are

relative and absolute error tolerances, and analogously we compute ρx , ρα , ρU ,
ρV . Then, we set ρ = max(ρσ , ρx , ρα , ρU , ρV ) and hnew = √hρ . If ρ ≤ 1.5, hnew is
used to proceed the continuation; otherwise the step just completed is rejected
and retried with the new steplength.
A continuation step may also fail because of lack of convergence either when
solving a Riccati equation or when computing a new point on the curve. In both
cases, the steplength is halved and the step retried.

5

Some Numerical Results

We refer on some experiments on two standard test problems. The results have
been obtained with the following data:
- Initial steplength: 10−3 ; minimum steplength: 10−8 ;
- Tolerances for solving algebraic Riccati equations: 10−8 ;
- Tolerances for computing fold and branch points: 10−12 ;
- Tolerances for computing points on the curve: 10−14 .
In the tables we give:
Nsteps: required number of continuation steps to complete the path;
hmax: maximum used steplength;
Nits1 : average number of iterations required to solve a Riccati equation (this is
needed to update the SVDs);
Nits2 : average number of iterations per continuation step required to compute
the point on the curve. The numbers Nits1 and Nits2 take into account all
performed iterations, on both successful and unsuccessful steps.

Path Following by SVD

683

Example 1. This is known as the aircraft problem [14]. The dimension is n = 5.
The curve has to be followed from (x0 , α0 ) = (0, 0) until α is out of [−1, 1].
Starting with α˙ 0 = 1, two folds are
found at α = 0.18608332702306 and
α = −0.50703056119994. The ﬁgure
on the right shows the ﬁrst component of the solution vs. α. Table 1
shows the results obtained with several choices of the parameters r and
a for the steplength control. Starting with α˙ 0 = −1, two folds are detected at α = −0.18690833269959
and α = 0.51015853464868; the performance is identical to that in
Table 1.
0

−2

x(1)

−4

−6

−8

−10

−12
−0.6

−0.4

−0.2

0

0.2

α

0.4

0.6

0.8

1

1.2

Table 1. Example 1
a (= r )
−4

10
10−3
10−2

Nsteps
694
226
82

Nits1
2
3
4

Nits2
4
6
11

hmax
0.24
0.70
1.72

Example 2. This is a test problem from the AUTO manual [9]:
⎡
⎤
x1 (1 − x1 ) − 3x1 x2
f (x, α) = ⎣ − 41 x2 + 3x1 x2 − 3x2 x3 − α(1 − e−5x2 ) ⎦ .
− 21 x3 + 3x2 x3
The continuation process starts
from (x0 , α0 ) = (1, 0, 0, 0) and stops
when α is out of [0, 0.6]. The code
detects two branch points, at α =
0.55 and α = 0.36846953170021,
and a fold at α = 0.56459590997250.
In the ﬁgure on the right, we show
the ﬁrst solution component vs. α.
At each branch point we started new
runs to follow the branches. In
Table 2 we give a summary of performance of the code relatively to
completion of the three paths in the
ﬁgure.
In both examples, 3 ÷ 5 secant iterations were needed to locate either a fold
or a branch point.
10

9

8

7

x(1)

6

5

4

3

2

1

0
−0.1

0

0.1

0.2

0.3
α

0.4

0.5

0.6

0.7

684

L. Dieci, M.G. Gasparo, and A. Papini
Table 2. Example 2
a (= r )
−4

10
10−3
10−2

Nsteps
792
281
121

Nits1
2
2
3

Nits2
2
3
3

hmax
0.76
2.25
5.27

Acknowledgement. This work was supported in part under NSF-DMS Grant
0139895, INDAM-GNCS Rome-Italy, and MIUR Rome-Italy.

References
1. Allgower, E., Georg, K.: Numerical Continuation Methods, Springer-Verlag, New
York (1990)
2. Beyn, W.J., Kleß, W., Th¨
ummler, V.: Continuation of low-dimensional invariant
subspaces in dynamical systems of large dimension. In: Fiedler, B. (ed.): Ergodic
Theory, Analysis and Eﬃcient Simulation of Dynamical Systems. Springer (2001)
47–72
3. Bindel, D., Demmel, J., Friedman, M.: Continuation of Invariant Subspaces for
Large Bifurcation Problems. In: Proceedings of the SIAM Conference on Applied Linear Algebra. The College of William and Mary, Williamsburg, VA (2003)
http://www.siam.org/meetings/la03/proceedings.
4. Bunse-Gerstner, A., Byers, R., Mehrmann, V., Nichols, N. K.: Numerical Computation of an Analytic Singular Value Decomposition by a Matrix Valued Function,
Numer. Math. 60 (1991) 1–40
5. Chow, S., Shen, Y.: Bifurcations via Singular Value Decompositions. Appl. Math.
Comput. 28 (1988) 231–245
6. Dieci, L., Eirola, T.,: On Smooth Decomposition of Matrices. SIAM J. Matrix.
Anal. Appl. 20 (1999) 800–819
7. Dieci, L., Gasparo, M.G., Papini, A.: Continuation of Singular Value Decompositions. Mediterr. j. math. 2 (2005) 179–203
8. Dhooge, A., Govaerts, W., Kuznetsov, Y.A.: A MATLAB Package for Numerical
Bifurcation Analysis of ODE. ACM Trans. on Math. Software 29 (2003) 141–164
9. Doedel, E.J., et al.: AUTO97: Continuation and Bifurcation Software for Ordinary Diﬀerential Equations (with HomCont), User’s Guide. Concordia University,
Montreal, P.Q, Canada (1997) http://indy.cs.concordia.ca
10. Keller, H.B.: Numerical Methods in Bifurcation Problems. Springer Verlag, Tata
Institute of Fundamental Research, Bombay (1987)
11. Kuznetsov, Y.A.: Elements of Applied Bifurcation Theory. Springer-Verlag, New
York (1995)
12. Mehrmann, V., Rath., W.: Numerical Methods for the Computation of Analytic
Singular Value Decompositions. Electron. Trans. Numer. Anal. 1 (1993) 72–88
13. Rheinboldt, W.C.: Numerical Analysis of Parametrized Nonlinear Equations. Wiley, New York (1986)
14. Rheinboldt, W.C., Burkardt, J.V.: A locally parametrizied continuation process.
ACM Trans. on Math. Software 9 (1983) 215–235
15. Watson, L.T., Sosonkina, M., Melville, R.C., Morgan, A.P., Walker, H.F.: Algorithm 777: HOMPACK 90: a suite of Fortran 90 codes for globally convergent
homotopy algorithms. ACM Trans. Math. Software 23 (1997) 514–549

