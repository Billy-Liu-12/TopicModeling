Parallelism of Association Rules Mining and Its
Application in Insurance Operations
Jinlan Tian, Lin Zhu, Suqin Zhang, and Gang Huang
Department of Computer Science and Technology
Tsinghua University., Beijing, 100084, PR China
tjlan@mail.tsinghua.edu.cn

Abstract. Association rules mining is a basic method in data mining.This paper ﬁrst introduces the basic concepts of association rules
mining and Apriori algorithm. It also provides a parallel association
rules model scheme for improving the mining eﬃciency when treating
large numbers of data sets as well as the analyse of the scheme eﬀect. In
conclusion we discuss how to apply association rules mining to insurance
data sets, ﬁnd out the knowledge hidden behind the data sets, and
provide powerful decision-making support for people.
Keywords: data mining; association rules mining; parallel algorithm;
insurance

1

Introduction

Data Mining is an advanced process to ﬁnd and extract conﬁdent, novel, eﬀective
and comprehensible patterns which are hidden behind a mass of data sets [1][2].
Along with the prevalence of database, many large-scale companies collect the
data as many as billions of or ever more. The huge data sets should be well understood for providing information for company directors. The ability of dealing
with large data sets is crucial for data mining tools.
Association rules mining is an important pattern of knowledge patterns of
data mining. The concept of association rules mining,which is simple and practical, is provided by Agrawal£Imielinski and Swami[1]. The patterns of association rules mining belong to descriptive patterns, and the algorithms to discover
rules belong to unsupervised learning. In this paper, we ﬁrst introduce the deﬁnition and attributes of association rules mining, and Apriori, the algorithm
which has close relationship to it. Then we present a design of parallel scheme
of association rules mining. At last, we discuss how to utilize MineSet, a data
mining tool of SGI, into insurance data sets to dig out association rules.

This research is supported by a joint research grant from National Science Foundation of China (project No.60131160743) and Hong Kong Research Grant Council.
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3039, pp. 907–914, 2004.
c Springer-Verlag Berlin Heidelberg 2004

908

2

J. Tian et al.

The Deﬁnition and Attributes of Association Rules
Mining

Just pay attention to some transactions that relate to many items: item X appears at transaction 1, item Y appears at transaction 2, and item X and Y
appear at transaction 3 simultaneously. Therefore, are there any rules of item X
and Y appear at transactions? In the area of data mining, association rules act as
such knowledge patterns which describe the rules of items appearing at the same
transaction simultaneously. More exactly, association rules describe how the appearance of item X aﬀects the appearance of item Y through quantiﬁcation.
Some basic concepts of association rules are rendered below[4].
Let R = {I1 , I2 , · · · , Im } be a set of items. Let W , the task-relevant data,
be a set of database transaction where each transaction T is a set of items such
that T ⊆ R. Let A be a set of items. A transaction T is said to contain A if and
only if A ⊆ T . An association rule is an implication of the form A ⇒ B, where
A ⊂ I, B ⊂ I, and A ∩ B = ∅.Here are the four basic attributes of associate
rules[3][8].
Conﬁdence. The rule A ⇒ B has conﬁdence c in the transaction set W if
c is the percentage of transactions in W containing A that also contain B.
Conﬁdence is the scale of veracity of association rules.
Support. The rule A ⇒ B holds in the transaction set W with support s, where
s is the percentage of transactions in W that contain A B (i.e., both A
and B). Support is the scale of weightiness of association rules. The bigger
the support, the more important the rule is.[5]
Expected conﬁdence. The rule A ⇒ B has expected conﬁdence e in the transaction set W if e is the percentage of transactions in W that contain B.
Lift. Lift is the ratio of conﬁdence and expected conﬁdence. Lift describes how
the appearance of A aﬀects the appearance of B. Generally speaking, available association rules should have the lift that is bigger than 1.

3
3.1

Parallelism of Association Rules Mining Algorithm
Algorithm of Association Rules Mining

Rules that satisfy both a minimum support threshold (min sup) and a minimum
conﬁdence threshold (min conf) are called “strong”[6]. “How are association rules mined from large databases?” Association rule mining is a two-stop process:
– Find all frequent itemsets: By deﬁnition, each of these itemsets will occur
at least as frequently as a pre-determined minimum support count.
– Generate strong association rules from the frequent itemsets: By
deﬁnition, these rules must satisfy minimum support and minimum conﬁdence.
Additional interestingness measures can be applied, if desired. The second
step is the easier of the two. The overall performance of mining association rules
is determined by the ﬁrst step.

Parallelism of Association Rules Mining

909

Aprior [7][8] is a basic algorithm for mining frequent itemsets for Boolean
association rules. Aprior employs an iterative approach known as a level-wise
search, where k-itemsets are used to explore (k + 1)-itemsets. First, the set of
frequent 1-itemsets is found. This set is denoted L1 . L1 is used to ﬁnd L2 ,the
set of frequent 2-itemsets, which is used to ﬁnd L3 , and so on, until no more
frequent k-itemsets can be found. The ﬁnding of each Lk requires one full scan
of the database.The pseudocode for the Apriori algorithm is shown below.
procedure AprioriAlg()
begin
L1 := { frequent 1-itemsets};
// find the frequent 1-itemsets
for ( k:=2;Lk = ∅ ; k++) do {
Ck :=apriori-gen(Lk−1 ; // generate candidates Ck based on
// Lk−1 in order to find Lk
For all transactions t in the dataset do {
//scan the dataset for counts
for all candidates c ∈ Ck contained in t do
c.count ++;
}
Lk :={c ∈ Ck |c.count ≥ minsupport}
}
Answer:= k L[K];
end;
The database is scanned repetitious times in Apriori algorithm. The ﬁrst scan
of Apriori ﬁnds the frequent 1-itemsets. The every following scan, for example,
the kth scan, ﬁrstly use Lk−1 to generate candidates Ck ,and then scan the whole
database to ﬁnd grequent itemsets in Ck and put them into Lk .
3.2

Parallel Scheme Design

Data mining always treats very large members of data, often millions of records
in some data sets. It will cost insuﬀerably long time for data mining tools to
deal with these records. So the ability of dealing with huge numbers of data sets
is crucial to data mining tools. They need parallel technologies.
Most job of the Apriori algorithm is about the scanning and statistics of data.
However, the statistics is independent transversely (among association rules)
and longitudinally (among records). Therefore, the data should be distributed
to multi-processors. Two schemes here.
1) Longitudinal partition
Every processor runs an integrated algorithm under such partition. But each
processor treats with diﬀerent columns of data records. For more detail, count
combinative modes among columns of records, and then every processor treats
with one kind of combinative mode to build association rules of the data treated
with. For example, there are three columns (F1 , F2 , F3 ) in records. There are
three kinds of combinative modes according to every two combination. Assign

910

J. Tian et al.

them into three separate processors, and then we will get the related association
rules.
However, the eﬃciency of this partition method is far from satisfying. Because:
– There are many repetitious statistics because some diﬀerent records involve
the same columns.
– The bottleneck of the algorithm we discussed is the scan of database. But
the longitudinal partition does not solve this problem eﬀectively.
2) Transverse partition
Divide the data into n parts in such partition methods, and assign the n
parts into n processors. Then collect the statistical results at last[9].
It will spend most of time in Apriori algorithm to scan databases and count
the frequency that the items appear. So it is the key issue to make this module
into parallel.
There are two characters in this kind of parallel:
– Regard the record as unit, so the data are independent of each other. Diﬀerent records will not aﬀect each other.
– Diﬀerent records share the same handle process.
Therefore we could use SIMD model[10] to construct out parallel algorithm.
First, divide the data into n parts, assign them into n processor to parallel, and
synthesize the results at last. The processors are not required to be synchronous.
Figure 1 shows the ﬂow chart of transverse partition method:

Fig. 1. Flow chart of transverse partition method

In conclusion, we do not need to consider the data-correlation problem and
the synchronization of processors. This scheme is so eﬀective that it can reduce
the execution time to the ratio of almost 1/n towards the primary algorithm.

Parallelism of Association Rules Mining

4

911

Application in Insurance Operations

Association rules can be used in many ﬁelds, such as merchandise retail, ﬁnance, insurance and so on. There are many data mining tools implementing the
association rules mining method at present. Now we will discuss how to utilize
MineSet[11], a data mining tool provided by SGI Company, to operate insurance
data with association rules.
1) Data Preparation
Here are the records in the data data resource.
Company ID Company
Com- Com- ComIndividual Age Total
Salary
Name
pany pany penInsurance
per Year
Type Area sation
ID
Code Times
35020438 60 7,051
0000000664 Oil company 3
3
0
08264031
of city A
35020421 77 7,382
0000000664 Oil company 3
3
1
04054011
of city A
third 2
1
0
13242745 53 17,617 0000000663 The
Middle
12206811
school of city
A
1
0
31011072 26 15,485 0000000662 Government 2
of city A
03033631
......
Each record includes the basic information of a policy holder and the times
he has claimed for compensation. We want to ﬁnd out the characters of people
who have claimed form compensation and those whose have not. The data should
be prepared before mining. As we just concern the Compensation Times and its
related information, the redundant information in the dataset, such as individual
insurance ID, company ID and company name, should be removed.
Take notice of age and total salary per year, they are continuous. But when
using association rules, the association rules generated algorithms cannot deal
with continuous data and should be discretized. Divide the attribute age into
ﬁve groups (...40], (40...50], (50...60], (60...70] and (70...]; total salary per year
into three groups £...6,000], (6,000...10,000] and (10,000...].
As for the attribute of compensation times, we only concern whether a policy
holder claimed or not, and ignore the concrete number of compensation times.
Thus attribute compensation times are converted to If Compensating, 1 represents compensated and 0 represents not. Here are the data after convertion.
Total Salary per Type of Company Area If
CompensaYear
Company Code
ting
3
3
0
(50...60) (6,000...10,000]
(70...)
(6,000...10,000]
3
3
1
(50...60) (10,000...]
2
1
0
(...40)
(10,000...]
2
1
0
......
Age

912

J. Tian et al.

2) Mine Association Rules
We need to specify the minimum support and minimum conﬁdence. Take
the minimum support as 1%. As minimum support rises, the rules we can ﬁnd
reduce, so the time used in mining will reduce. But if minimum support is too
high, we may miss some rules which should be found. We take the minimum
credibility as 50%, before using MineSet.
3) Visualized Display and Comprehend the Rules
When MineSet ﬁnd out Association rules, it will use Scatter Visualize [11] to
display the mining result. Figure 2 illustrates the result.

Fig. 2. Association rules mining result

It is a three-dimensional picture. The ﬁrst is LHS (left-hand side) to represents the items set A. The second is RHS (right-hand side) to represent the items
set B. Every oblong in the ﬁgure represents an association rule A ⇒ B,as A is
the value projected on LHS, B is the value projected on RHS.
The third dimension is the height of an oblong which represents the conﬁdence of the rule. The color of every oblong shows the lift of the rule. (each color
stands for an area of lift, you can ﬁnd the corresponding relations at the bottom
left corner of the ﬁgure). When the mouse is on an oblong, the information of
corresponding association rule will be displayed at top left of the screen. For
example, the information included in the oblong in the ﬁgure above is:
LHS
Company Type=3 RHS
If Compensating=0
conﬁdence: 85.18 expected: 84.00
support: 60.77 lift: 1.03
So the association rule which the oblong in the picture stands for is: Company
Type=3 ⇒ If Compensating=0. The value of the four parameters of this rule is:
Support= 60.77%, Conﬁdence= 85.18%, Expected Conﬁdence= 84.00%, Lift=
1.03.
We can see, 84.00% of all policy holders have not claimed for compensation,
60.77% have done and their company type is 3. Among the policy holders whose
company type is 3, 85.13% have not claimed for compensation. “Lift = 1.03”

Parallelism of Association Rules Mining

913

tells us that “Company Type= 3” does not have a considerable aﬀection on
whether the policy holders has claimed or not. It is because that without this
term the compensation rate of policy holders does not has an obvious change.
Some of the association rules gained are not useful to insurance business,
such as the association rules between total salary per year and company type,
and ignored.
In the association rules we have just mentioned, LHS and RHS include only
one item. They are one-to-one single rules. If more items for LHS and RHS are
permitted, multi-corresponding association rules[12] can be obtained. They are
shown with Record Visualize:
Support Conﬁdence Expected Lift LHS
RHS
84.77
84
1.0091 Company
If
Compensa1.9997
Type=2
and ting =0
Age=(40 ... 50]
1.1047 Company Area If
Compensa3.4213
92.8
84
Code =5
ting =0
1.6091
86.55
84
1.0304 Company Area If
CompensaCode=6
and ting =0
Age =(30 ... 40]
93.1
84
1.1083 Company
If
Compensa15.1695
Type=3
and ting =0
Age =(40 ... 50]
Compensa2.2653
87.88
84
1.0461 Company area If
Code =4 and ting =0
Total Salary per
Year=(6000 ...
10000]
......
A row represents an association rule. The columns show LHS, RHS and other
four parameters. We can see that among the people whose company type is 3
and age is between 40 and 50 years old, 93.1% have not claimed for compensation, much higher than expected conﬁdence. However, among the people whose
company type is 2 and age is between 40 and 50 years old, 84.77% have not
claimed for compensation. If these results are based on some external reason,
(For example, the companies with the company type 3 do not bring too much
pressure to their employees, so the employees are not so tired to catch ill easily.)
insurance company then may pay more attention on those customers who meet
such conditions above for reducing the investment venture and increase operation earnings. When those rules are applied in practice, they should be adjusted
with the time goes by. Then we can gain the most appropriate and best results
that they are the closest to the original requirements.

5

Conclusion

In this paper we present the parallel scheme design of association rules mining
and its application on insurance data. Parallel data mining algorithms are eﬀec-

914

J. Tian et al.

tive methods to solve the performance problem when treating large numbers of
data sets. Association rules mining can be utilized into many areas other than
insurance, such as credit card company, stock exchange and bank. Markets could
use association rules to decide what to buy and how to put goods. In addition,
association rules mining also has great aﬀects in the application on communication industry, it can be used to analyze the factors of customer loss, adjust
preferential action in time and reduce the loss of important customers. In conclusion, association rules mining can be applied at various areas widely, discover
the knowledge hidden behind the data, and provide powerful decision-making
support for people.

References
1. Peatetsky-Shapiro, G., Fayyad, U., and Smyth, P., From Data Mining to Knowledge Discovery: An Overview, Fayyad, U.M., Piatetsky-Shapiro, G., Smyth, P.,
and Uthurusamy, R., (eds), Advances in Knowledge Discovery and Data Mining,
AAAI/MIT Press, pp.1-35,1996
2. Introduction to data mining and knowledge discovery, Third Edition, by Two
Crows Corporation
3. K.Decker and S.Focardi, Technology Overview: A Report on Data Mining, Technical Report CSCR TR-95-02, Swiss Scientiﬁc Computing Center, 1995
4. Heikki Mannnila, Hannu Toivonen and A. Inkeri. Verkamo, Eﬃcient algorithms
for discovering association rules, AAAI Workshop on Knowledge Discovery in Databases, pages 181-192, July 1994
5. Tony Xiaohua Hu, Knowledge Discovery in Databases: An Attribute-Oriented
Rough Set Approach, Ph.D. thesis, Regina university, 1995
6. Gao Wen, KDD Knowledge Discovery in Databases, Computer World, vol. 37, 1998
7. Rakesh Agrawal , Manish Mehta , John Shafer and Ramakrishnan Srikant, The
Quest Data Mining System, AAAI/MIT Press, pp.244-249,1996
8. R.Feldman, A.Amir, Y.Auman, A.Zilberstien and H.Hirsh, Incremental Algorithms
for Association Generation, AAAI/MIT Press,pp.227-241,1995
9. Z.Zhang Y.Lu and B.Zhang, An Eﬀective Partitioning-Combining Algorithm for
Mining Quantitative Association Rules, AAAI/MIT Press,pp.241-252,1995
10. Chen Guoliang, Design and Analysis of parallel algorithms, Higher Education publishing company, China, 2002
11. SGI Company, MineSet2.0 Tutorial
12. David W.Cheung, Vincent T.Ng and Benjamin W.Tam, Maintenance of Discovered
Knowledge: A Case in Multi-level Association Rules, AAAI/MIT Press, pp.307309,1996

