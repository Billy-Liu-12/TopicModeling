Eﬃcient Generation of Parallel Quasirandom
Faure Sequences Via Scrambling
Hongmei Chi1,2 and Michael Mascagni1,3
1

2

School of Computational Science, Florida State University,
Tallahassee, FL 32306-4120, USA
chi@scs.fsu.edu
Department of Computer and Information Sciences, Florida A& M University,
Tallahassee, FL 32307-5100, USA
3
Department of Computer Science, Florida State University,
Tallahassee, FL 32306-4530, USA

Abstract. Much of the recent work on parallelizing quasi-Monte Carlo
methods has been aimed at splitting a quasirandom sequence into many
subsequences which are then used independently on the various parallel
processes. This method works well for the parallelization of pseudorandom numbers, but due to the nature of quality in quasirandom numbers,
this technique has many drawbacks. In contrast, this paper proposes an
alternative approach for generating parallel quasirandom sequences via
scrambling. The exact meaning of the digit scrambling we use depends on
the mathematical details of the quasirandom number sequence’s method
of generation. The Faure sequence is scramble by modifying the generator matrices in the deﬁnition. Thus, we not only obtain the expected
near-perfect speedup of the naturally parallel Monte Carlo methods, but
the errors in the parallel computation is even smaller than if the computation were done with the same quantity of quasirandom numbers using
the original Faure sequence.
Keywords: Parallel computing, Faure sequence, quasi-Monte Carlo,
scrambling, optimal sequences.

1

Introduction

One major advantage of Monte Carlo methods is that they are usually very
easy to parallelize; this leads us to all Monte Carlo methods “naturally parallel” algorithms. This is, in principal, also true of quasi-Monte Carlo (QMC)
methods. As with ordinary Monte Carlo, QMC applications have high degrees of
parallelism, can tolerate large latencies, and usually require considerable computational eﬀort, making them extremely well suited for parallel, distributed, and
even Grid-based computational environments. Parallel computations using QMC
require a source of quasirandom sequences, which are distributed among the individual parallel processes. In these environments, a large QMC problem can be
broken up into many small subproblems. These subproblems are then scheduled
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 723–730, 2007.
c Springer-Verlag Berlin Heidelberg 2007

724

H. Chi and M. Mascagni

on the parallel, distributed, or Grid-based environment. In a more traditional
instantiation, these environments are usually a workstation cluster connected by
a local-area network, where the computational workload is carefully distributed.
Recently, peer-to-peer and Grid-based computing, the cooperative use of geographically distributed resources uniﬁed to act as a single powerful computer,
has been investigated as an appropriate computational environment for Monte
Carlo applications [9,10]. QMC methods can signiﬁcantly increase the accuracy
of the likelihood-estimated over regular MC [7]. In addition, QMC can improve
the convergence rate of traditional Markov chain Monte Carlo [16]. This paper
explores an approach to generating parallel quasirandom sequences for parallel,
distributed, and Grid-based computing.
Like pseudorandom numbers, quasirandom sequences are deterministically
generated, but, in contrast, are constructed to be highly uniformly distributed.
The high level of uniformity is a global property of these sequences, and something as innocent sounding as the deletion of a single quasirandom point from
a sequence can harm its uniformity quite drastically. The measure of uniformity
used traditionally in quasirandom number is the star-discrepancy. The reason
for this is the Koksma-Hlawka inequality. This is the fundamental result in QMC
theory, and motivates the search and study of low-discrepancy sequences. This
result states that for any sequence X = {x0 , . . . , xN −1 } and any function, f , with
bounded variation deﬁned on the s-dimensional unit cube, I s , the integration
error over I d is bounded as,
1
f (x) dx −
N
s
I

N
∗
f (xi ) ≤ V [f ]DN
,

(1)

i=1

∗ 1
where V [f ] is the total variation of f , in the sense of Hardy-Krause, DN
is the
star discrepancy of sequence X [20]. As we are normally given a problem to solve,
∗
that we can control. This is done by constructing low-discrepancy
it is only DN
sequences for use in QMC.
However, the successful parallel implementation of a quasi-Monte Carlo application depends crucially on various quality aspects of the parallel quasirandom
sequences used. Randomness can be brought to bear on otherwise deterministic
quasirandom sequence by using various scrambling techniques. These methods
randomize quasirandom sequences by using pseudorandom numbers to scramble
the order the of quasirandom numbers generated or to permute their digits. Thus
by the term “scrambling” we are referring more generally to the randomization
of quasirandom numbers. Scrambling provides a natural way to parallelize quasirandom sequences, because scrambled quasirandom sequences form a stochastic
family which can be assigned to diﬀerent processes in a parallel computation. In
1

For a sequence of N points X = {x0 , . . ., xN−1 } in the d-dimensional unit cube
I s , and for any box, J, with one corner at the origin in I s , the star discrepancy,
in J
∗
∗
, is deﬁned as DN
= supJ ∈I s |μx (J) − μ(J)|, where μX (J) = #of points
is
DN
N
the discrete measure of J, i. e., the fraction of points of X in J, and μ(J) is the
Lebesgue measure of J, i. e., the volume of J.

Eﬃcient Generation of Parallel Quasirandom Faure Sequences

725

addition, there are many scrambling schemes that produce scrambled sequences
∗
with the same DN
as the parent, which means that we expect no degradation
of results with these sorts of scrambling. These scrambling schemes are different from other proposed QMC parallelization schemes such as the leap-frog
scheme [2] and the blocking scheme [18], which split up a single quasirandom
sequence into subsequences.
The Faure sequence is one of the most widely used quasirandom sequences.
The original construction of quasirandom sequences was related to the van der
Corput sequence, which itself is a one-dimension quasirandom sequence based
on digital inversion. This digital inversion method is a central idea behind the
construction of many current quasirandom sequences in arbitrary bases and dimensions. Following the construction of the van der Corput sequence, a signiﬁcant generalization of this method was proposed by Faure [4] to the sequences that now bear his name. In addition, an eﬃcient implementation of
the Faure sequence was published shortly afterwards [6]. Later, Tezuka [20] proposed a generalized Faure sequence, GFaure, which forms a family of randomized Faure sequences. We will discuss the scrambling of Faure sequences in this
paper.
The organization of this paper is as follows. In §2, an overview of scrambling
methods and a brief introduction to the theory of constructing quasirandom
sequences is given. Parallelizations and implementations of quasirandom Faure
sequences are presented in §3. The consequences of choosing a generator matrix,
the resulting computational issues, and a some numerical results are illustrated
in §4, and conclusions are presented in §5.

2

Scrambling

Before we begin our discussion of the scrambled Faure sequence, it behooves
us to describe, in detail, the standard and widely accepted methods of Faure
sequence generation. The reason for this is that construction of Faure sequence
follows from the generation of the Van der Corput and Sobo´l sequences. Often
QMC scrambling methods are combined with the original quasirandom number
generation algorithms.
The construction of quasirandom sequences is based on ﬁnite-ﬁeld arithmetic.
For example, the Sobo´l sequences [19] are constructed using linear recurring relations over F2 . Faure used the Pascal matrix in his construction, and Niederreiter
used the formal Laurent series over ﬁnite ﬁelds to construct low-discrepancy sequences that now bear his name.
We now brieﬂy describe the construction of the above “classical” quasirandom
sequences.
– Van der Corput sequences: Let b ≥ 2 be an integer, and n a non-negative
integer with n = n0 + n1 b + ... + nm bm it b-adic representation. Then the
m
. Here
nth term of the Van der Corput sequence is φb (n) = nb0 + nb21 + ... + nbm
φb (n) is the radical inverse function in base b and and n = (n0 , n1 , ..., nm )T

726

H. Chi and M. Mascagni

is the digit vector of the b-adic representation of n. φb (·) simply reverses the
digit expansion of n, and places it to the right of the “decimal” point. The
Van der Corput sequence in s-dimensions, more commonly called the Halton
sequence, is one of the most basic one-dimension quasirandom sequences, and
can be rewritten in the following form:
(φb1 (Cn), φb2 (Cn)..., φbs (Cn))
Here the “generator matrix” C is the identity matrix and the nth Halton
sequence is deﬁned as (φb1 (n), φb2 (n)..., φbs (n)) where the bases, b1 , b2 , ..., bs ,
are pairwise coprime. The other commonly uses quasirandom sequences can
be similarly deﬁned by specifying diﬀerent generator matrices.
– Faure and GFaure sequences: The nth element of the Faure sequence is
expressed as
(φb (P 0 n), φb (P 1 n), ..., φb (P s−1 n)),
where b is prime and b ≥ s and P is Pascal matrix whose (i, j) element
i−1
is equal to
Tezuka [22] proposed the generalized Faure sequence,
j−1
GFaure, with the jth dimension generator matrix C (j) = A(j) P j−1 , where
A(j) are a random nonsingular lower triangular matrices. Faure [5] extended
this idea to bigger set. Also a subset of GFaure is called GFaure with the
i-binomial property [21], where A(j) is deﬁned as:
⎛
⎞
h1 0 0 0 ...
⎜ g2 h1 0 0 ...⎟
⎜
⎟
⎜ g3 g2 h1 0 ...⎟
⎜
⎟
⎟
A(j) = ⎜
⎜ g4 g3 g2 h1 ...⎟ ,
⎜ · · · · ...⎟
⎜
⎟
⎝ · · · · ...⎠
· · · · ...
where h1 is uniformly distributed on Fb − {0} and gi is uniformly distributed
on Fb . For each A(j) , there will be a diﬀerent random matrix in the above
form.
We will generate parallel Faure sequences by randomizing the matrix A(j) . However, arbitrary choice of matrix could lead to high correlation between diﬀerent quasirandom streams. We will address this concern in next section and
show how to choose the matrix A(j) so that correlation between streams is
minimized.

3

Parallelization and Implementations

Much of the recent work on parallelizing quasi-Monte Carlo methods has been
aimed at splitting a quasirandom sequence into many subsequences which are
then used independently on the various parallel processes. This method works

Eﬃcient Generation of Parallel Quasirandom Faure Sequences

727

well for the parallelization of pseudorandom numbers, but due to the nature
of quality in quasirandom numbers, this technique has many drawbacks. In
contrast, this paper proposes an alternative approach for generating parallel
quasirandom sequences. Here we take a single quasirandom sequence and provide diﬀerent random digit scramblings of the given sequence. If the scrambling
preserves certain equidistribution properties of the parent sequence, then the
result will be high-quality quasirandom numbers for each parallel process, and
an overall successful parallel quasi-Monte Carlo computation as expected from
the Koksma-Hlawka inequality [11].
Parallelization via splitting [18] uses a single quasirandom sequence and assigns subsequences of this quasirandom sequence to diﬀerent processes. The idea
behind splitting is to assume that any subsequence of a given quasirandom sequence has the same uniformity as the parent quasirandom sequence. This is
an assumption that is often false [8]. In comparison to splitting, each scrambled
sequence can be thought of as an independent sequence and thus assigned to
a diﬀerent process, and under certain circumstances it can be proven that the
scrambled sequences are as uniform as the parent [15]. Since the quality (small
discrepancy) of quasirandom sequences is a collective property of the entire sequence, forming new sequences from parts is potentially troublesome. Therefore,
scrambled quasirandom sequences provide a very appealing alternative for parallel quasirandom sequences, especially where a single quasirandom sequence is
scrambled to provide all the parallel streams. Such a scheme would also be very
useful for providing QMC support to the computational Grid [9,10].
We will consider a variety of generator matrices for parallelizing and implementing parallel Faure sequences. The generation of the original Faure sequences
is fast and easy to implement. Here, we applied the same methods as was used
in Halton sequences because the original Halton sequence suﬀers from correlations [3] between radical inverse functions with diﬀerent bases used for diﬀerent dimensions. These correlations result in poorly distributed two-dimensional
projections. A standard solution to this phenomenon is to use a randomized
(scrambled) version of the Halton sequence. We proposed a similar algorithm
to improve quality of the Faure sequences. We will use the the same approach
here to randomize the generator matrix and thus generate parallel Faure sequences. The strategy used in [3] is to ﬁnd an optimal hi and gi in base b to
improve the quality of the Faure sequence. Most importantly, the two-most signiﬁcant digits of each Faure point are only scrambled by h1 and g2 . Thus the
choice of these two elements is crucial for producing good scrambled Faure sequences. After these choices, the rest of elements in matrix A(j) could be chosen
randomly.
Whenever scrambled methods are applied, pseudorandom numbers are the
“scramblers”. Therefore, it is important to ﬁnd a good pseudorandom number
generator (PRNG) to act as a scrambler so that we can obtain well scrambled
quasirandom sequences. A good parallel pseudorandom number generator such
as SPRNG [13,12] is chosen as our scrambler.2
2

The SPRNG library can be downloaded at http://sprng.fsu.edu.

728

4

H. Chi and M. Mascagni

Applications

FINDER [17], a commercial software system which uses quasirandom sequences
to solve problems in ﬁnance, is an example of the successful use of GFaure,
as a modiﬁed GFaure sequence is included in FINDER, where matrices A(j) are
empirically chosen to provide high-quality sequences.
Assume that an integrand, f , is deﬁned over the s-dimensional unit cube,
[0, 1)s , and that I(f ) is deﬁned as: I(f ) = I s f (x) dx. Then the s-dimensional
integral, I(f ), in Equation (2) may be approximated by QN (f ) [14]: QN (f ) =
N
s
i=1 ωi f (xi ), where xi is in [0, 1) , and the ωi s are weights. If {x1 , . . . , xN } is
1
chosen randomly, and ωi = N , then QN (f ) becomes the standard Monte Carlo
integral estimate, whose statistical error can be estimated using the Central
Limit Theorem. If {x1 , . . . , xN } are a set of quasirandom numbers, then QN (f )
is a quasi-Monte Carlo estimate and the above mentioned Koksma-Hlawka inequality can be appealed to for error bounds.
To empirically test the quality of our proposed parallel Faure sequence, we
evaluate the test integral discussed in [6] with ai = 1
1

1
s
Πi=1

...
0

0

|4xi − 2| + ai
dx1 . . . dxs = 1.
1 + ai

Table 1. Estimation of The Integral
r
10
10
10
10
10
10
10

N
1000
3000
5000
7000
30000
40000
50000

s = 13
0.125
0.908
0.912
0.943
0.988
1.014
1.006

Ê1
0

...

s = 20
0.399
0.869
0.985
1.014
1.097
1.118
1.016

Ê1
0

(2)

|4xi −2|+1
s
Πi=1
dx1 . . . dxs = 1
2

s = 25
0.388
0.769
1.979
1.342
1.171
1.181
1.089

s = 40
0.699
0.515
0.419
0.489
1.206
1.118
1.034

In Table 1, we presented the average of ten (r = 10) Faure parallel streams for
computing the numerical values of integral. The accuracy of quasi-Monte Carlo
integration depends not simply on the dimension of the integrands, but on their
eﬀective dimension [23]. It is instructive to publish the results of these numerical integrations when we instead use the original Faure sequence to provide the
same number of points as were used in the above computations. Table 2 shows
these results. The astonishing fact is that the quality numerical integration using the original is lower than the parallel scrambled Faure sequence. We do not
report speedup results, as this is a naturally parallel algorithm, but we feel it
important to stress that using scrambling in QMC for parallelization has a very
interesting consequence: the quality of the parallel sequences is actually better than the original sequences. The authors are not aware of similar situations,

Eﬃcient Generation of Parallel Quasirandom Faure Sequences
Table 2. Estimation of The Integral
r
10
10
10
10
10
10
10

N
1000
3000
5000
7000
30000
40000
50000

s = 13
0.412
1.208
0.919
1.043
0.987
1.010
0.996

Ê1
0

...

s = 20
0.456
0.679
0.976
1.214
1.097
1.103
1.006

Ê1
0

729

|4xi −2|+1
s
Πi=1
dx1 . . . dxs = 1
2

s = 25
1.300
0.955
1.066
0.958
0.989
1.201
1.178

s = 40
0.677
0.775
0.871
0.916
1.026
0.886
0.791

where parallelization actually increases the quality of a computation, but are
interested to learn about more examples in the literature.

5

Conclusions

A new scheme for parallel QMC streams using diﬀerent GFaure sequences is proposed. The advantage of this scheme is that we can provide unlimited independent streams for QMC in heterogeneous computing environment. This scheme
is an alternative for generating parallel quasirandom number streams. The obtained are very interesting as the scrambled versions used in individual processes
are of higher quality than the original Faure sequence. We need to carry out a
big, yet feasible, computations that will provide the data required for a parallel
generator based on these ideas. More Numerical experiments, such as application
in bioinformatics [1], need to done to further validate this parallel methods. However, this parallelization has a very interesting property. The parallel version of
the quasirandom numbers are of better quality than the original sequence. This
is due to the fact that the scrambling done for parallelization also increases the
quality of the sequences. Thus, not only do we have a faster parallel computation, but the parallel computation is simultaneous more accurate without any
extra computational eﬀort.

References
1. P. Beerli and H. Chi. Quasi-markov chain Monte Carlo to improve inference of
population genetic parameters. Mathematics and Computers in Simulation, page
In press, 2007.
2. B.C. Bromley. Quasirandom number generators for parallel Monte Carlo algorithms. Journal of Parallel and Distributed Computing, 38(1):101–104, 1996.
3. H. Chi, M. Mascagni, and T. Warnock. On the optimal Halton sequences. Mathematics and Computers in Simulation, 70/1:9–21, 2005.
4. H. Faure. Discrepancy of sequences associated with a number system(in dimension
s). Acta. Arith, 41(4):337–351, 1982[French].
5. H. Faure. Variations on(0,s)-sequences. Journal of Complexity, 17(4):741–753,
2001.

730

H. Chi and M. Mascagni

6. B. Fox. Implementation and relative eﬃciency of quasirandom sequence generators.
ACM Trans. on Mathematical Software, 12:362–376, 1986.
7. W. Jank. Eﬃcient simulated maximum likelihood with an application to online
retailing. Statistics and Computing, 16:111–124, 2006.
8. L. Kocis and W. Whiten. Computational investigations of low discrepancy sequences. ACM Trans. Mathematical software, 23:266–294, 1997.
9. Y. Li and M. Mascagni. Analysis of large-scale grid-based Monte Carlo applications. International Journal of High Performance Computing Applications,
17(4):369–382, 2003.
10. K. Liu and F. J. Hickernell. A scalable low discrepancy point generator for parallel
computing. In Lecture Notes in Computer Science 3358, volume 3358, pages 257–
262, 2004.
11. W. L. Loh. On the asymptotic distribution of scrambled net quadrature. Annals
of Statistics, 31:1282–1324, 2003.
12. M. Mascagni and H. Chi. Parallel linear congruential generators with SophieGermain moduli. Parallel Computing, 30:1217–1231, 2004.
13. M. Mascagni and A. Srinivasan. Algorithm 806: SPRNG: A scalable library for
pseudorandom number generation. ACM Transactions on Mathematical Software,
26:436–461, 2000.
14. H. Niederreiter. Random number generation and quasi-Monte Carlo methods.
SIAM, Philadephia, 1992.
15. A. B. Owen. Randomly permuted (t, m, s)-nets and (t, s)-sequences. Monte Carlo
and Quasi-Monte Carlo Methods in Scientiﬁc Computing, 106 in Lecture Notes in
Statistics:299–317, 1995.
16. A. B. Owen and S. Tribble. A quasi-Monte Carlo metroplis algorithm. Proceedings
of the National Academy of Sciences of the United States of America, 102:8844–
8849, 2005.
17. A. Papageorgiou and J. Traub. Beating Monte Carlo. RISK, 9:63–65, 1997.
18. W. Schmid and A. Uhl. Techniques for parallel quasi-Monte Carlo integration with
digital sequences and associated problems. Math. Comput. Simulat, 55(1-3):249–
257, 2001.
19. I. M. Sobo´l. Uniformly distributed sequences with additional uniformity properties.
USSR Comput. Math. and Math. Phy., 16:236–242, 1976.
20. S. Tezuka. Uniform Random Numbers, Theory and Practice. Kluwer Academic
Publishers, IBM Japan, 1995.
21. S. Tezuka and H. Faure. I-binomial scrambling of digital nets and sequences.
Journal of Complexity, 19(6):744–757, 2003.
22. S. Tezuka and T. Tokuyama. A note on polynomial arithmetic analogue of Halton
sequences. ACM Trans. on Modelling and Computer Simulation, 4:279–284, 1994.
23. X. Wang and K.T. Fang. The eﬀective dimension and quasi-monte carlo. Journal
of Complexity, 19(2):101–124, 2003.

