Quality of Feature Selection Based on
Microarray Gene Expression Data
Henryk Maciejewski
Institute of Computer Engineering, Control and Robotics,
Wroclaw University of Technology,
ul. Wybrzeze Wyspianskiego 27, 50-370 Wroclaw, Poland
Henryk.Maciejewski@pwr.wroc.pl

Abstract. This paper is devoted to the problem of feature selection
for class prediction based on results of DNA microarray experiments. A
method is presented to objectively compare quality of feature sets obtained using diﬀerent gene-ranking methods. The quality of feature sets is
expressed in terms of predictive performance of classiﬁcation models built
using these features. A comparative study is performed involving means
comparison, fold diﬀerence and rank-test (Wilcoxon statistic) methods.
The study shows that best performance can be obtained using the ranktest approach. It is also shown that the means comparison method can be
signiﬁcantly improved by also taking into account fold-change information. Performance of such mixed methods of feature selection can surpass
performance of rank-test methods.

1

Introduction

Genome-wide expression proﬁling using DNA microarray or similar technologies
has become an important tool for research communities in academia and industry. Microarray gene expression studies are designed to obtain insights into
yet unknown gene functions/interactions, investigate gene-related disease mechanisms or observe relationships between gene proﬁles and some factors (such
as some risk factor or response to some therapy). Microarray studies motivated
development of speciﬁc data analysis methods, broadly categorized into class
discovery, class comparison and class prediction [12]. Class discovery aims to discover groups of co-regulated genes across the samples tested, or, alternatively, to
discover groups of samples similar in terms of their gene expression proﬁle, thus
discovering new disease taxonomies [2]. The purpose of class comparison studies
is to identify genes with most diﬀerent expression proﬁles across the classes compared. This identiﬁes groups of genes whose expression is signiﬁcantly related
to the classes and which possibly account for the diﬀerence between the classes
compared. The purpose of class prediction is to build a predictive model for determination of the class membership of samples based on their gene expression
proﬁles. Application areas of this seem very promising not only in research, but
in medical diagnosis or prediction of response to treatment. Although US Food
and Drug Administration recently approved the ﬁrst microarray chip to help
M. Bubak et al. (Eds.): ICCS 2008, Part III, LNCS 5103, pp. 140–147, 2008.
c Springer-Verlag Berlin Heidelberg 2008

Quality of Feature Selection Based on Microarray Gene Expression Data

141

doctors administer patient dosages of drugs that are metabolized diﬀerently by
cytochrome P450 enzyme variant, more wide-spread application of microarrays
in clinical or regulatory applications requires that several issues related to accuracy and reproducibility of microarray results as well as analysis of microarray
data are resolved.
One step on the way to bringing microarrays to clinical applications was recently made by the Microarray Quality Control (MAQC) Consortium [6], [11],
who through a comprehensive experimental study showed that microarrays have
grown robust enough to produce data that is reproducible and comparable across
diﬀerent microarray platforms and laboratories. As another conclusion from their
research, MAQC recommends using fold-change ratio as a measure of gene ranking for the purpose of identiﬁcation of diﬀerently expressed genes in microarray
studies. This recommendation is drawn from the observation that this method
of gene selection yields best reproducibility of results across diﬀerent microarray
platforms. MAQC also advices against using means-comparison methods, such
as the t-test, for gene ranking. This has opened recent discussion related to validity of gene selection methods. E.g., Klebanov et al. [8] argues that fold-change
cannot be regarded superior to the t-test, as it realizes smaller power, and in
general, reproducibility of results should not be used as an indication about the
adequacy of the gene selection method.
This discussion has motivated the study reported in this paper. Our work
addresses another perspective (or criterion) for choosing the right method of
gene selection. It is proposed to judge the quality of a gene selection method by
looking at the information value of genes returned by the method and regarded
as features for class prediction. In other words, a gene selection method will be
deemed superior if it tends to produce features yielding best predictive performance of sample classiﬁers. In the following section, an approach is explained to
arrive at the quality of features obtained using a given gene selection method.
Next, this approach is used to compare three widely used gene selection methods (means-comparison, fold-change and a method based on the statistical rank
test). The comparative study is based on the data originally published by Golub
et al. [5] and Alon et al. [1]. Finally, it is shown that combining diﬀerent feature
selection methods (e.g., enhancing means-comparison method by also including
the fold-change criterion) can result in increased performance of class prediction.

2

Quality of Features from Diﬀerent Gene Selection
Methods

Here we present an approach to express quality of a gene selection method in
terms of predictive performance of a classiﬁer using the genes regarded as features. In Sect. 2.1 we discuss the challenges that need to be overcome to build and
properly validate performance of a sample classiﬁer based on gene expressions.
This should be seen as the motivation for the procedure detailed in Sect. 2.2
for judging the quality of gene selection.

142

2.1

H. Maciejewski

Classiﬁcation in High Dimensionality Data

Building a class prediction model based on microarray study data is a challenging task due to very high dimensionality of data obtained and relatively small
number of samples available. Microarray studies typically produce data vectors
with dimensionality d ∼ 103 to 104 (the number of genes observed in one DNA
chip), while the number of samples tested is at most n ∼ 102 . In other words, microarray studies deﬁne an ill-formulated problem of classiﬁcation, where d
n,
while standard approaches to predictive modeling require that d
n. This
implies that signiﬁcant dimensionality reduction is required. Another challenge
related to the analysis of such data concerns proper estimation of expected predictive performance of the classiﬁer for new data. Considering the small number
of samples available for model building and testing requires that a properly tailored data-reuse approach is used. How these issues will be approached in the
procedure in Sect. 2.2 is now developed.
The following notation will be used to represent results of a microarray experiment. Let (xi , yi ), i = 1, 2, ..., n denote data vectors related to the n samples
tested in a microarray study, where xi ∈ Rd represents gene expressions from
the sample i and yi ∈ C = {c1 , c2 } denotes the class membership associated
with the sample i. For the problem of class prediction it is assumed the class
membership yi for each xi is known prior to analysis. Only the binary classiﬁcation case is considered here, where yi ∈ {c1 , c2 }; this can be extended to the
multi class problem by using ANOVA based metrics for gene ranking (such as
the F-statistic).
The problem of class prediction is formally stated in the statistical decision
theory [7] as looking for a prediction model f : Rd → C, minimizing the expected
prediction error:
EP E = E [L (Y, f (X))]
(1)
where the loss function L, used to penalize misclassiﬁcation events can be deﬁned
as e.g.,
1 for Y = f (X)
L (Y, f (X)) =
.
(2)
0 for Y = f (X)
Since in class prediction studies only samples (xi , yi ), i = 1, 2, ..., n of the random
n
variables X and Y are known, empirical risk deﬁned as n1 i=1 L (yi , f (xi )) is
used to estimate the EP E (1). It should be noted that this must be computed
based only on the data points not used for the purpose of building the model
f , and not used in the stage on feature (gene) selection. Considering the small
number of data points from a microarray study, EP E can be estimated by
repeatedly training and testing the model for diﬀerent data splits, where a subset
of available data is used for feature selection and model building, leaving the
remaining (smaller) part for estimation of EP E. This leads to a cross-validation
estimate of EP E deﬁned as [7]:
CV =

1
n

n

L yi , f −i (xi )
i=1

(3)

Quality of Feature Selection Based on Microarray Gene Expression Data

143

where f −i is the classiﬁer ﬁtted to data with the sample xi removed. This version of cross-validation realizes smaller bias (at the price of higher variance) as
compared with the procedures leaving more samples for testing [7].
It should be noted that estimating EP E based on samples used for feature
selection leads to overoptimistic estimates of predictive performance of classiﬁers,
as pointed out in [14], and is not an uncommon error in literature.
Another issue concerning class prediction based on microarray data is related
to setting the right dimensionality of the feature set. Here the well known fact
should be considered [7] pertaining to binary classiﬁcation that in d dimensions
d + 1 points can be always perfectly separated by a simplest linear classiﬁer.
n), one
This implies that for microarray data ((xi , yi ), i = 1, 2, . . . , n where d
can always obtain perfect ﬁt of the model to data, providing enough (i.e. n − 1)
genes are selected. However, such models will not guarantee good predictive performance for new data, as they are prone to overﬁtting meaning small prediction
error for training data with high prediction error for test (new) data [12]. This
limits the number of genes that should be selected as features for class prediction
to no more then the number of data points available in microarray data.
2.2

Quality of a Feature Selection Method

Considering the above mentioned challenges, the following procedure is proposed
to arrive at the quality measures attributed to a given feature selection method.
In the next chapter three speciﬁc feature selection methods are compared using
this procedure.
1. Select the value d∗ of dimensionality of the feature vector from the range
1..n − 2.
2. Remove the sample (xi , yi ) from the original data set (the remaining n − 1
samples will be referred to as the training data).
3. Using the training data select d∗ genes ranked top by the gene selection
procedure considered.
4. Reduce dimensionality of the vectors x by leaving only values of expression
of the d∗ genes selected (the vectors obtained will be denoted x ).
5. Build a classiﬁcation model denoted f −i by ﬁtting it to the n − 1 points x ,
obtained in the previous step.
6. Compute ei = L yi , f −i (xi ) .
7. Repeat Steps 2 through 6 for i = 1, 2, . . . , n.
8. Compute CVd∗ = n1 ni=1 ei (this estimates the EP E - see (3)).
9. Repeat Steps 1 through 8 for a grid of values d∗ spaced evenly in the range
1..n − 2, using approx. 10 values of d∗ .
10. Plot the obtained relationship CVd∗ versus d∗ .
It is proposed that the quality of a feature selection method be judged by observing the minimum values of CVd∗ obtained. Also, comparing the plots obtained
in Step 10 for diﬀerent feature selection methods gives an indication about the
quality of features produced by competing methods over a range of diﬀerent
dimensionality models. This approach is used in the sample study shown in the
following section.

144

3

H. Maciejewski

Comparing Quality of Commonly Used Feature
Selection Methods

Using the approach proposed in Sect. 2.2, the quality of three diﬀerent methods
commonly used for ranking genes is compared:
1. Gene ranking based on the Wilcoxon statistical rank-test,
2. Gene ranking based on the fold diﬀerence (used and recommended by Shi et
al. [11]),
3. Gene ranking based on the signal to noise measure (which is an example of
direct means comparison methods, such as the t-test).
Feature selection based on the ﬁrst method requires that the Wilcoxon nonparametric group comparison test is performed independently for every gene.
This gives a p-value indicating whether expression of this gene for the groups of
samples of class c1 and c2 can be considered diﬀerent. Gene selection using this
method returns the set of top d∗ (Step 4 in Sect. 2.2) genes ranked by increasing
p-value of the test.
Feature selection using the fold diﬀerence measure requires that for every gene
the ratio of mean expressions from samples of class c1 and c2 is computed. More
speciﬁcally, if for a given gene, the mean value of gene expression from samples
of class c1 and c2 is denoted μ1 and μ2 , respectively, then the (log) fold diﬀerence
measure is deﬁned as:
f c = |log(μ1 ) − log(μ2 )|

(4)

which produces high values if either of the means exceeds the other. Gene selection using this method returns the set of top genes ranked by decreasing value
of f c.
Feature selection based on the signal to noise uses the measure deﬁned as:
sn =

|μ1 − μ2 |
σ1 + σ2

(5)

where σ1 and σ2 are standard deviations of expressions of a ﬁxed gene for the
samples of class c1 and c2 , respectively. Gene selection returns the set of top
genes ranked by decreasing value of sn.
Fig. 1 compares the EP E vs. model dimensionality for these three gene selection methods (marked in the plot by ’w’, ’sn’ and ’fc’). As a classiﬁer we used
in this study the multilayer perceptron (MLP) model with one hidden layer. We
observe that the minimum value of EP E (i.e., the best predictive performance
expected for new, independent samples) is realized for the Wilcoxon method,
with 15 genes selected. It can be also observed that for the wide range of diﬀerent dimensionality models (up to 50 features), Wilcoxon feature selection yields
signiﬁcantly fewer prediction errors then signal to noise or fold diﬀerence.
Fig. 1 also includes EP E for a model built using a combined method of feature
selection (marked in the plot as ’snfc’). This approach includes the following steps:

Quality of Feature Selection Based on Microarray Gene Expression Data

145

Fig. 1. Expected prediction error of neural network model for diﬀerent methods of
gene selection. (Notation: w=Wilcoxon test, fc=fold diﬀerence, sn=signal to noise,
snfc=signal to noise with additional fold diﬀerence criterion).

1. For each gene, the f c and sn measures are computed according to (4) and
(5).
2. Genes are ranked by decreasing values of sn.
3. The required number of top genes is returned, providing a gene realizes at
least two-fold diﬀerence in expression (i.e., f c ≥ 1, where in (4) we used the
logarithm to the base 2).
The threshold of at least two-fold diﬀerence in expression was also used as the
feature selection criterion in [11]. Interestingly, features returned from this combined model yield signiﬁcantly better EP E then features from individual models
ns and f c, with minimum values of EP E realized for 10-20 genes. This approach
shows similar performance in terms of feature quality to the Wilcoxon method.
The same analysis repeated for a diﬀerent classiﬁcation model – logistic regression gives results depicted in Fig. 2.
Basically, the conclusions drawn from Fig. 1 regarding the quality of competing feature selection methods are conﬁrmed: the Wilcoxon method realizes
the best predictive performance (for 10-20 features), and the combined method
(’snfc’) leads to remarkable improvement in feature quality, making this method
comparable with the Wilcoxon rank test.

146

H. Maciejewski

Fig. 2. Expected prediction error of logistic regression model for diﬀerent methods
of gene selection. (Notation: w=Wilcoxon test, fc=fold diﬀerence, sn=signal to noise,
snfc=signal to noise with additional fold diﬀerence criterion).

Figs. 1 and 2 also illustrate model dimensionality related issues: too small a
model dimensionality leads to poor prediction performance (due to the model
being too simple), while too big a dimensionality leads to overﬁtting of the
model. This compromise should be taken into consideration when setting the
right dimensionality of a class prediction model.
Similar analysis repeated for the colon data set [1] basically conﬁrms the
conclusions drawn from the leukemia study. Again, the Wilcoxon method tends
to produce the best predictive performance (the EP E ≈ 0.16 for 20 genes, using
the MLP classiﬁer). Similar results were observed for 10 or 30 features obtained
with the combined method.

4

Conclusions

We demonstrated that the quality of gene selection methods can be empirically
compared by observing the performance of class prediction models built using
features returned by these methods. To obtain a fair picture of the quality, such
analysis should not be limited to one pre-ﬁxed number of genes selected, it should
rather be made for a representative collection of diﬀerent dimensionality models,
which allows to observe the size of feature vectors yielding good class prediction.

Quality of Feature Selection Based on Microarray Gene Expression Data

147

Using this approach, we showed that the Wilcoxon rank test is a superior
gene selection method then fold-change or direct means comparison. However,
signiﬁcant improvement can be achieved if diﬀerent gene selection criteria are
used simultaneously. This suggests that feature selection for microarray class
prediction probably should comprise information from several diﬀerent criteria,
thus increasing information contents of the feature set. This however requires
further research.
Being able to quantitatively rank gene selection methods, as shown in this
work, raises another interesting question to what extend the genes selected as
best features for sample classiﬁcation really account for the diﬀerences between
classes. This open question requires further research in an interdisciplinary team.

References
1. Alon, U., et al.: Broad patterns of gene expression revealed by clustering analysis
of tumor and normal colon tissues probed by oligonucleotide arrays. Proc. Natl.
Acad. Sci. USA 96, 6745–6750 (1999)
2. Bittner, M., Meltzer, P., Chen, Y.: Molecular classiﬁcation of cutaneous malignant
melanoma by gene expression proﬁling. Nature 406, 536–540 (2000)
3. Dudoit, S., Shaﬀer, J., Boldrick, J.: Multiple Hypothesis Testing in Microarray
Experiments. UC Berkeley Division of Biostatistics Working Paper Series, Paper
110 (2002)
4. Ewens, W., Grant, G.: Statistical Methods in Bioinformatics. Springer, New York
(2001)
5. Golub, T., et al.: Molecular classiﬁcation of cancer: Class discovery and class prediction by gene expression monitoring. Science 286, 531–537 (1999)
6. Guo, L., et al.: Rat toxicogenomic study reveals analytical consistency across microarray platforms. Nature Biotechnology 24, 1162–1169 (2006)
7. Hastie, T., Tibshirani, R., Friedman, J.: The Elements of Statistical Learning. Data
Mining, Inference and Prediction. Springer, New York (2002)
8. Klebanov, L., et al.: Statistical methods and microarray data. Nature Biotechnology 25, 25–26 (2007)
9. Maciejewski, H.: Adaptive selection of feature set dimensionality for classiﬁcation
of DNA microarray samples. In: Computer recognition systems CORES, Springer
Advances in Soft Computing, Springer, Heidelberg (2007)
10. Maciejewski, H., Konarski, L.: Building a predictive model from data in high dimensions with application to analysis of microarray experiments. In: DepCoS RELCOMEX. IEEE Computer Society Press, Los Alamitos (2007)
11. MAQC Consortium [Shi L. et al.]: The MicroArray Quality Control (MAQC)
project shows inter- and intraplatform reproducibility of gene expression measurements. Nature Biotechnology 24, 1151–1161 (2006)
12. Markowetz, F., Spang, R.: Molecular diagnosis. Classiﬁcation, Model Selection and
Performance Evaluation, Methods Inf. Med. 44, 438–443 (2005)
13. Polanski, A., Kimmel, M.: Bioinformatics. Springer, Heidelberg (2007)
14. Simon, R., et al.: Pitfalls in the Use of DNA Microarray Data for Diagnostic and
Prognostic Classiﬁcation. Journal of the National Cancer Institute 95, 14–18 (2003)

