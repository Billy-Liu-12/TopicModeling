Procedia Computer Science
Volume 80, 2016, Pages 1125–1134
ICCS 2016. The International Conference on Computational
Science

Solving PhaseLift by Low-rank Riemannian Optimization
Methods∗
Wen Huang1 , Kyle A. Gallivan2 , and Xiangxiong Zhang3
1

ICTEAM Institute, Universit´e catholique de Louvain, Louvain-la-Neuve, Belgium.
2
Department of Mathematics, Florida State University, Tallahassee FL, USA.
3
Department of Mathematics, Purdue University, West Lafayette, IN, USA.

Abstract
A framework, PhaseLift, was recently proposed to solve the phase retrieval problem. In this
framework, the problem is solved by optimizing a cost function over the set of complex Hermitian
positive semideﬁnite matrices. This paper considers an approach based on an alternative cost
function deﬁned on a union of appropriate manifolds. It is related to the original cost function
in a manner that preserves the ability to ﬁnd a global minimizer and is signiﬁcantly more
eﬃcient computationally. A rank-based optimality condition for stationary points is given and
optimization algorithms based on state-of-the-art Riemannian optimization and dynamically
reducing rank are proposed. Empirical evaluations are performed using the PhaseLift problem.
The new approach is shown to be an eﬀective method of phase retrieval with computational
eﬃciency increased substantially compared to the algorithm used in original PhaseLift paper.
Keywords: Riemannian optimization, Hermitian positive semideﬁnite, Riemannian quasi-Newton, Rank
adaptive method

1

Introduction

Recovering a signal given the modulus of its transform, e.g., Fourier or wavelet transform, is
an important task in the phase retrieval problem. It is a key problem for many important
applications, e.g., X-ray crystallography imaging [14], diﬀraction imaging [7], optics [26] and
microscopy [20].
This paper considers the discrete form of the phase retrieval problem where an indexed
set of complex numbers x ∈ Cn1 ×n2 ×...×ns is to be recovered from the modulus of its discrete
Fourier transform |˜
x(g1 , g2 , . . . , gs )|, where (g1 , g2 , . . . , gs ) ∈ Ω := G1 × G2 × . . . Gs and Ω is a

∗ This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and
Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science
Policy Oﬃce. This work was supported by grant FNRS PDR T.0173.13.

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.422

1125

Riemannian Optimization Methods For PhaseLift

W. Huang and K. A. Gallivan and X. Zhang

˜ , is given by
grid in an s-dimensional space. The discrete Fourier transform of x, denoted x
˜ (g1 , g2 , . . . , gs ) =
x
1
√
ni

xi1 i2 ...is exp −2π
1 ,i2 ,...,is

(i1 − 1)g1
(is − 1)gs
+ ... +
n1
ns

√

−1 ,

(1.1)

where n = n1 n2 . . . ns , ij is an integer satisfying 1 ≤ ij ≤ nj for j = 1, . . . s, xi1 i2 ...is denotes
˜ (g1 , g2 , . . . , gs ) denotes the corresponding entry of x
˜.
the corresponding entry of x and x
It is well-known that the solution of the phase retrieval problem is not unique. Many
approaches e.g., [23, 13, 9, 25, 11] have been proposed to recover the phase. Some frameworks use
multiple structured illuminations or the mathematically equivalent construct of masks combined
with convex programming, e.g., PhaseLift [9]. For the PhaseLift framework, four major results
are of interest here. First, using a small number (related to s) of noiseless measurements of the
modulus deﬁned by certain carefully designed illuminations, the phase can be recovered exactly
[9]. Second, when these carefully designed measurements are not used, exact recovery is still
possible using O(n2 ) noiseless measurements [10]. Third, the phase can be recovered exactly
with high probability using O(n log n) noiseless measurements of the modulus [12]. Finally, the
stability of recovering the phase using noisy measurements is shown in [12].
The problems in PhaseLift concern optimizing convex cost functions deﬁned on a convex
set of complex matrices, i.e.,
min H(X),

X∈Dn

(1.2)

where H : Dn → R : X → H(X), and Dn denotes the set of all n-by-n complex Hermitian
positive semideﬁnite matrices. However, the dimension of (1.2) is usually too large to be solved
by standard convex programming techniques. Since the desired optimum, X∗ , is known to be
a rank-one matrix, a low-rank matrix approximation of the argument matrix is used in [9] to
save computations for PhaseLift. While this approximation has good empirical performance,
no convergence proof is given in [9].
This paper focuses on the framework of PhaseLift and an alternate cost function F : Cn×p →
R : Y → F (Y ) = H(Y Y ∗ ) deﬁned by matrix factorization is considered. Even though F is
not convex, it is shown to be a suitable replacement of the cost function H. Riemannian
optimization methods on an appropriate quotient space are used for optimizing F . Using the
cost function F with a small dimension p reduces storage and the computational complexity
of each iteration. This new approach is shown to perform empirically much better than the
low-rank approximate version of the algorithm used for PhaseLift in [9] from the points of view
of eﬃciency and eﬀectiveness. Finally, note that the analysis and algorithm presented is not
speciﬁc to the cost function used for phase retrieval in PhaseLift but for a general cost function
deﬁned on Dn and therefore the approach has potential for optimization in other applications
where the global optimum is known to have low rank. The idea of using low-rank factorization
to solve positive semideﬁnite constrained problems is, of course, not new but all the research
results of which the authors are aware, are for real positive semideﬁnite matrix constraints, see
[8, 19].
The paper is organized as follows. Section 2 presents the notation used. The derivation
of the optimization problem framework in PhaseLift is given in Section 3. The alternate cost
function and optimality conditions are given in Section 4. Riemannian optimization methods
and the required geometric objects are presented in Section 5. In Section 6, the eﬀectiveness of
the methods are demonstrated and, ﬁnally, conclusions are given in Section 7.
1126

Riemannian Optimization Methods For PhaseLift

2

W. Huang and K. A. Gallivan and X. Zhang

Notation

For any z ∈ Cn1 ×n2 ×...ns , vec(z) ∈ Cn , where n = n1 n2 . . . ns , denotes the vector form of z, i.e.,
s−1
(vec(z))k = zi1 i2 ...is , where k = i1 + j=1 n1 n2 . . . nj (ij+1 − 1). Given z1 , z2 ∈ Cn1 ×n2 ×...ns ,
T
z1 , z2 denotes vec(z1 ) vec(z2 ). Re(·) denotes the real part of the argument and superscript
∗ denotes the conjugate transpose operator. Given a vector v with length h, all upper case
DIAG(v) denotes an h-by-h diagonal matrix the diagonal entries of which are v. All lower
case diag(M ) denotes a vector of the diagonal entries of M ∈ Cs×k and trace(M ) denotes the
∗
M⊥ = I(s−k)×(s−k) and
trace of M . If s ≥ k, M⊥ denotes an s × (s − k) matrix such that M⊥
∗
M⊥ M = 0(s−k)×k .
Given an embedded submanifold M ⊆ Cs×k , Tx M and Nx M denote the tangent space
and normal space of M at x ∈ M respectively. Dk denotes set {X ∈ Cn×n |X = X ∗ , X ≥
0, rank(X) ≤ k}, 1 ≤ k ≤ n. Note that the statement X ≥ 0 means that matrix X
is positive semideﬁnite or deﬁnite. St(k, s) denotes the complex compact Stiefel manifold
{A ∈ Cs×k |A∗ A = Ik×k } with s ≥ k. SC
+ (k, s) denotes the set of all Hermitian positive
semideﬁnite s × s matrices of ﬁxed rank k. Cs×k
denotes the complex noncompact Stiefel man∗
ifold, i.e., the set of all s × k full column rank complex matrices. Os denotes the group of s-by-s
unitary matrices.

3

The PhaseLift Approach to Phase Retrieval

The phase retrieval problem recovers x from quadratic measurements of the form A(x) =
{| ak , x |2 : k = 1, 2, . . . , m}, where ak ∈ Cn1 ×n2 ×...ns , k = 1, 2, . . . , m are given. It is wellknown that the quadratic measurements can be lifted up to be linear measurements of the rankone matrix X = xx∗ , where x = vec(x) ∈ Cn . Speciﬁcally, the measurements are | ak , x |2 =
trace(ak a∗k xx∗ ) := trace(Ak X), where ak = vec(ak ) ∈ Cn . Deﬁne A to be the linear operator
mapping X into b := {trace(Ak X) : k = 1, 2, . . . m}. The goal of the phase retrieval problem is
to
ﬁnd X,

such that A(X) = b, X ≥ 0 and rank(X) = 1.

(3.1)

The alternative problem suggested in [9] considers an optimization problem that does not force
the rank of matrix to be one but adds a nuclear norm penalty term to favor low-rank solutions
min

X∈Dn

b − A(X)

2
2

+ κ trace(X),

(3.2)

where κ is a positive constant.
Measurements with noise, b ∈ Rm , are assumed to have the form b = A(X) + , where
∈ Rm is noise sampled from a distribution p(:; μ). The task suggested in [9] is
min − log(p(b; μ)) + κ trace(X)
X

(3.3)

such that μ = diag(ZXZ ∗ ) and X ∈ Dn ,
or equivalently
min − log(p(b; diag(ZXZ ∗ ))) + κ trace(X)

X∈Dn

(3.4)

where κ is a positive constant. Problems (3.3) and (3.4) are preferred over Problem (3.1), since
they are convex programming problems when the log-likelihood function is concave.
1127

Riemannian Optimization Methods For PhaseLift

4

W. Huang and K. A. Gallivan and X. Zhang

Theoretical Results

This section presents theoretical results that motivate the design of algorithms for optimizing
a class of cost functions deﬁned on Dn without giving the proofs due to space limits. They can
be found in [18]. The analysis does not rely on the convexity of the particular cost function H
from the class.

4.1

Equivalent Cost Function

The cost functions generically denoted H all satisfy
H : Dn → R : X → H(X).

(4.1)

It is well-known that for any X ∈ Dn , there exists Yn ∈ Cn×n such that Yn Yn∗ = X. Furthermore, if X has rank p, then there exists Yp ∈ Cn×p such that Yp Yp∗ = X. Throughout this
paper, the subscript of Y is used to denote the column size of Y . A surjective mapping between
Cn×p and Dp is given by αp : Cn×p → Dp : Yp → Yp Yp∗ . Thus, if the desired solution of H is
known to be at most rank p, then an alternate cost function to H can be used:
Fp : Cn×p → R : Yp → H(αp (Yp )) = H(Yp Yp∗ ).
The subscripts of F and α indicate the column size of the argument. The domain of Fp has
lower dimension than that of H which may yield computational eﬃciency. Therefore, instead
of Problem (1.2), the problem minYp ∈Cn×p Fp (Yp ) is considered.

4.2

Optimality Conditions

In this section, characterizations of stationary points of F and H over Dn are used to derive
the relationship between optimizing F and optimizing H over Dn . Since H is deﬁned on a
constrained set, a stationary point of H does not simply satisfy grad H(X) = 0. The stationary
points of H are deﬁned as follows by [18, Lemma 5]:
Deﬁnition 4.1. A stationary point of (4.1) is a matrix X ∈ Dn such that grad H(X)X = 0
and grad H(X) ≥ 0.
The gradient and the action of Hessian of Fp are easily computed and are given in Lemma
4.1 in terms of H.
Lemma 4.1. The gradient of Fp at Yp is given by grad Fp (Yp ) = 2 grad H(Yp Yp∗ )Yp and the
action of the Hessian of Fp at Yp on ηp ∈ Cn×p is given by Hess Fp (Yp )[ηp ] = 2 grad H(Yp Yp∗ )ηp +
2(Hess H(Yp Yp∗ )[ηp Yp∗ + Yp ηp∗ ])Yp .
Theorem 4.1 and [19, Theorem 7] show similar results under diﬀerent frameworks. Both
results suggest considering the cost function Fp if the desired minimizer of H is known to have
rank smaller than p, as is the case with PhaseLift for phase retrieval. This is formalized in
Theorem 4.1 and has critical algorithmic, eﬃciency and optimality implications when H has
suitable structure such as convexity as in the case of PhaseLift.
Theorem 4.1. Suppose Yp = Ks Q∗ is a rank deﬁcient minimizer of Fp , where Ks ∈ C∗n×s and
Q ∈ St(s, p). Then (Ks )∗⊥ grad H(Yp Yp∗ )(Ks )⊥ is a positive semideﬁnite matrix and, therefore,
X = Yp Yp∗ is a stationary point of H. If furthermore H is convex, then X is a global minimizer
of (4.1).
1128

Riemannian Optimization Methods For PhaseLift

5

W. Huang and K. A. Gallivan and X. Zhang

A Riemannian Approach

Riemannian optimization is an active research area and recently many Riemannian optimization
methods have been systemically analyzed and eﬃcient libraries designed, e.g., Riemannian trustregion Newton method [1, 4], Riemannian Broyden family of methods including RBFGS and
its limited-memory version (LRBFGS) [22, 15, 17], Riemannian trust-region symmetric rankone update method and its limited-memory version [15, 16], Riemannian Newton method and
Riemannian non-linear conjugate gradient method [24].

5.1

Riemannian Optimization on Fixed Rank Manifold

Derivations for Riemannian objects of SR
+ (p, n) have been given in [2]. This section includes
results of Riemannian objects for the complex case, i.e., SC
+ (p, n). Since the mapping αp is not an
injection, all the minimizers of Fp are degenerate, which causes diﬃculties in some algorithms,
e.g., Riemannian and Euclidean Newton method. In order to overcome this diﬃculty, a function
deﬁned on a quotient manifold with ﬁxed rank is considered. To this end, deﬁne the mapping βp
∗
to be the mapping αp restricted to Cn×p
, i.e., βp : Cn×p
→ SC
∗
∗
+ (p, n) : Y → αp (Y ) = Y Y . and
n×p
n×p
the function Gp to be Fp restricted to C∗ , i.e., Gp : C∗
→ R : Y → Fp (Y ) = H(βp (Y )).
Like αp , the mapping βp is a surjection but not a injection and there are multiple matrices
C
−1
in Cn×p
mapping to a single point in SC
∗
+ (p, n). Nevertheless, given a X ∈ S+ (p, n), βp (X)
−1
is a manifold while αp (X) is not a manifold. Therefore, using the mapping βp , a quotient
manifold can be used to remove the degeneracy by deﬁning the equivalence class βp−1 (Y Y ∗ ) =
[Y ] = {Y O|O ∈ Op } and the set
}.
/Op = {[Y ]|Y ∈ Cn×p
Cn×p
∗
∗
This set can be shown to be a quotient manifold over R. To clarify the notation, π(Y ) is used
/Op and π −1 (π(Y )) is used to denote [Y ] viewed as
to denote [Y ] viewed as an element in Cn×p
∗
.
The
function
m
:
π(Y
)
→
Y Y ∗ is a diﬀeomorphism between Cn×p
/Op and
a subset of Cn×p
∗
∗
p
(p,
n).
SC
+
Choosing a representative for an equivalence class and deﬁnitions of related mathematical
objects have been developed in many papers in the literature of computation on manifolds, e.g.,
[3]. The vertical space at Y ∈ π −1 (π(Y )), which is the tangent space of π −1 (π(Y )) at Y , is
VY = {Y Ω|Ω∗ = −Ω, Ω ∈ Cp×p }.
= Cn×p that is orthogThe horizontal space at Y , HY , is deﬁned to be a subspace of TY Cn×p
∗
onal to VY , i.e., satisfying HA ⊕ VA = TA GL(n, C). Therefore, a Riemannian metric of Cn×p
∗
is required to deﬁne the meaning of orthogonal. The standard Euclidean metric,
gY (ηY , ξY ) = Re(trace(ηY∗ ξY ))

(5.1)

and Y ∈ Cn×p
, is used in this paper. The horizontal space is therefore
for all ηY , ξY ∈ TY Cn×p
∗
∗
HY ={V ∈ Cn×p |Y ∗ V = V ∗ Y }
={Y (Y ∗ Y )−1 S + Y⊥ K|S ∗ = S, S ∈ Cp×p , K ∈ C(n−p)×p }.
/Op .
The horizontal space HY is a representation of the tangent space Tπ(Y ) Cn×p
∗
It is known that for any ηπ(Y ) ∈ Tπ(Y ) Cn×p
/Op , there exists a unique vector in HY ,
∗
called the horizontal lift of ηπ(Y ) and denoted by η↑Y , satisfying D π(Y )[η↑Y ] = ηπ(Y ) , see e.g.,
[3]. The orthogonal projections onto the horizontal space or the vertical space are also easily
characterized.
1129

Riemannian Optimization Methods For PhaseLift

W. Huang and K. A. Gallivan and X. Zhang

Lemma 5.1. The orthogonal projection onto the vertical space VY of η ∈ Cn×p
is PYv (η) = Y Ω,
∗
where Ω is the skew symmetric matrix that solves the Sylvester equation, ΩY ∗ Y + Y ∗ Y Ω =
Y ∗ η − η ∗ Y . The orthogonal projection onto the horizontal space HY is PYh (η) = η − Y Ω.
Finally, the desired cost function that removes the equivalence is deﬁned as
/Op → R : π(Y ) → fp (π(Y )) = Gp (Y ) = Fp (Y ).
fp : Cn×p
∗

(5.2)

The function fp in (5.2) has the important property that π(Y ) is a nondegenerate minimizer
/Op if and only if Y Y ∗ is a nondegenerate minimizer of H over SC
of f over Cn×p
∗
+ (p, n).
The gradient and the action of the Hessian of (5.2) are given in Lemma 5.2.
Lemma 5.2. The gradient of f satisﬁes (grad f (π(Y )))↑Y = PYh (grad F (Y )), and the action
of Hessian of (5.2) at π(Y ) along ηπ(Y ) ∈ Tπ(Y ) Cn×p
/Op satisﬁes (Hess f (π(Y ))[ηπ(Y ) ])↑Y =
∗
h ˙
˙
PY (M − η↑Y Ω), where M = grad F (Y ), M = Hess F (Y )[η↑Y ], and Ω is the skew-symmetric
matrix that solves ΩY ∗ Y + Y ∗ Y Ω = Y ∗ M − M ∗ Y .

5.2

Dynamic Rank Reduction

The domain of fp , Cn×p
/Op , is not closed, i.e., a sequence {W (i) } representing {π(W (i) )}
∗
ˆ with rank less than p. It is impossible, in
generated by an algorithm may have a limit point W
practice to check whether a limit point of iterates {W (i) } is a lower rank matrix or just close to
one of lower rank. However, when the desired rank of the minimizer is known and the current
iterate W (i) has a higher rank than the desired rank, as is the case with PhaseLift for phase
retrieval, a straightforward technique can be used to address the lack of closure by dynamically
reducing the rank. This technique is discussed below.
The thin singular value decomposition of the i-th iterate is W (i) = U ΣV ∗ and Σ =
√
˜ be DIAG(σ1 , . . . , σp ) F / p.
DIAG(σ1 , σ2 , . . . , σp ), where σ1 ≥ σ2 ≥ . . . ≥ σp ≥ 0. Let σ
σ > δ and σq+1 /˜
σ ≤ δ for a given threshold δ, then
If there exists q < p such that σq /˜
ˆ = U (:, 1 : q) DIAG(σ1 , . . . σq )V (:, 1 : q)∗ is chosen to be the initial point for optimizing cost
W
/Oq . The details of reducing rank are given in Algorithm 1. Note that
function fq over Cn×q
∗
the step of decreasing the rank may produce an iterate that increases the cost function value.
This facilitates global optimization by allowing nondescent steps.
Algorithm 1 Reduce Rank
Input: Y ∈ Cn×p ; threshold δ;
Output: W ∈ Cn×q ;
1: Take thin singular value decomposition for Y , i.e., Y = U DIAG(σ1 , . . . , σp )V ∗ , where
U ∈ Cn×p , V ∈ Cp×p and σ1 ≥ . . . ≥ σp ≥ 0;
√
2: Set σ
˜ = DIAG(σ1 , . . . , σp ) F / p;
3: if σp /˜
σ > δ then
4:
q ← p, W ← Y and return;
5: else
6:
Find q such that σq /˜
σ > δ and σq+1 /˜
σ ≤ δ;
7:
Let W = U (:, 1 : q) DIAG(σ1 , . . . σq )V (:, 1 : q)∗ and return;
8: end if
Combining a Riemannian optimization method with the procedure of reducing rank gives
Algorithm 2.
1130

Riemannian Optimization Methods For PhaseLift

W. Huang and K. A. Gallivan and X. Zhang

Algorithm 2 Rank Reduce Algorithm
(0)

(0)

Input: p > 0; Yp ∈ Cn×p a representation of initial point π(Yp ) for f ; Stopping criterion
threshold ; rank reducing threshold δ; a Riemannian optimization method;
Output: W
1: for k = 0, 1, 2, . . . do
(k)
2:
Apply Riemannian method for cost function f over Cn×p
/Op with initial point π(Yp )
∗
until i-th iterate W (i) satisfying g(grad f, grad f ) < 2 or the requirement of reducing
rank with threshold δ;
3:
if g(grad f, grad f ) < 21 then
4:
Find a minimizer W = W (i) over Cn×p
/Op and return;
∗
5:
else {iterate in the Riemannian optimization method meets the requirements of reducing
rank}
ˆ ∈ Cn×q ;
6:
Apply Algorithm 1 with threshold δ and obtain an output W
(k+1)
ˆ
7:
p ← q and set Yp
= W;
8:
end if
9: end for

6

Experiments

In this section, numerical simulations for noiseless problems and those with Gaussian noise are
used to illustrate the performance of the proposed method and to compare it to the performance
of the current convex optimization approach.

6.1

Cost Function, Gradient, and Action of Hessian and Complexity
for PhaseLift

The known random masks or illumination ﬁelds deﬁned on the discrete signal domain are
denoted wr ∈ Cn1 ×n2 ×...ns , r = 1, . . . l. It follows that { ak , x , k = 1, . . . m} is
⎛
⎞
(Fns ⊗ Fns−1 ⊗ . . . Fn1 ) DIAG(w1 )x
⎜
⎟
..
⎝
⎠,
.
(Fns ⊗ Fns−1 ⊗ . . . Fn1 ) DIAG(wl )x
where ⊗ denotes the Kronecker product and Fni ∈ Cti ×ni , i = 1, . . . , s denotes the onedimensional Discrete Fourier Transform (DFT). Let Zi denote (Fns ⊗Fns−1 ⊗. . . Fn1 ) DIAG(wi ),
Z denote (Z1T Z2T . . . ZlT )T . We have A(x) = diag(Zxx∗ Z ∗ ), which implies that A(X) =
diag(ZXZ ∗ ).
When the entries in the noise are drawn from the normal distribution with mean 0 and
variance τ , the cost functions of (3.4) and (3.2) are essentially identical, i.e., for (3.2), H1 (X) =
b − diag(ZXZ ∗ ) 22 + κ trace(X), and for (3.4), H2 (X) = τ12 b − diag(ZXZ ∗ ) 22 + κ trace(X),
(see details in [18, Section 3]). Without loss of generality, only the cost function H(X) = b −
diag(ZXZ ∗ )) 22 / b 22 + κ trace(X) is considered. The Euclidean gradient of H is grad H(X) =
2
Z ∗ DIAG(diag(ZXZ ∗ ) − b)Z + κIn×n , and the action of the Euclidean Hessian at X along
b 2
2

V is Hess H(X)[V ] = b2 2 Z ∗ DIAG(diag(ZV Z ∗ ))Z, where V = V ∗ . The gradients and actions
2
of Hessians of functions Fp and fp can be constructed using Lemmas 4.1 and 5.2.
The complexities of evaluations of the function value, gradient and action of Hessian of Fp
are all of the same order, O(pms maxi (log(ni )). The complexities of evaluations of the function
1131

Riemannian Optimization Methods For PhaseLift

noiseless

Algorithm 2

iter
nf
ng
ff
RMSE
t

124
129
124
4.62−12
6.34−6
2.12

1
1022
2212
1106
8.18−12
1.01−5
1.272

W. Huang and K. A. Gallivan and X. Zhang

2
377
804
402
4.50−11
1.74−5
5.251

LR-FISTA
4
8
601
1554
1278
3360
639
1680
4.64−12 1.54−11
1.46−5
1.10−4
9.351
3.482

16
2000
4322
2161
1.27−9
2.56−3
6.862

Table 1: Comparisons of Algorithm 2 and LR-FISTA for the noiseless PhaseLift problem (3.2)
with n1 = n2 = 64 and several values of k. represents the number of iterations reach the
maximum. iter, nf , ng, ff , and t denote the number of iteration, the number of function
evaluation, the number of gradient evaluation, ﬁnal cost function value and computational time
in second respectively.

value, gradient and action of Hessian of fp are O(pms maxi (log(ni )), O(pms maxi (log(ni )) +
O(np2 ) + O(p3 ) and O(pms maxi (log(ni )) + O(np2 ) + O(p3 ) respectively. If p << n then all of
these complexities are dominated by O(pms maxi (log(ni )).

6.2

Comparisons with a Standard Low-rank Method

Cand`es et al., [9, 12] use a Matlab library TFOCS [6] that contains a variety of accelerated
ﬁrst-order methods given in [21] and, in particular, the method based on FISTA [5] is used to
optimize the cost functions in PhaseLift. For large-scale problems, a low rank version of FISTA
called LR-FISTA is used. The main diﬀerence is that the iterates of LR-FISTA are low-rank
matrices computed via projection rather than the full-rank iterates of FISTA.
As in [9], the diﬀerence between the true solution and the minimizer is measured by the
relative mean-square error (RMSE) mina:|a|=1 ax − x∗ 2 / x∗ 2 and by 10 log10 (RMSE) when
expressed in dB. The scale of the noise is measured by the signal-to-noise ratio (SNR) in dB given
by SNR = 10 log10 ( b 22 / b − ˆb 22 ), where b = diag(Zx∗ x∗∗ Z ∗ ) and ˆb is the noise measurements.
Tables 1 and 2 report experimental results for Algorithm 2 and LR-FISTA for the noiseless
and Gaussian noise problems (3.2) and (3.4) respectively. For the Gaussian noise problem, τ
is 10−4 and the corresponding SNR is 31.05 dB in this experiment. Multiple examples with
diﬀerent random seeds and diﬀerent SNR show similar results. First, increasing k for LRFISTA usually does not improve the performance in the sense of eﬃciency and eﬀectiveness
for both noiseless and Gaussian noise problems. Second, increasing κ usually does not reduce
the RMSE. When it does, the RMSE values are not reduced signiﬁcantly. Therefore, κ = 0 is
used in the later comparisons for Gaussian noise problems. Third, Algorithm 2 outperforms
LR-FISTA signiﬁcantly in the sense that Algorithm 2 provides similar accuracy usually while
requiring fewer operations of all types (cost function evaluation, gradients etc.) and yielding a
signiﬁcantly smaller computational time.

7

Conclusion

In this paper, the recently proposed PhaseLift framework for solving the phase retrieval problem
has motivated the consideration of a class of cost functions on the set of complex Hermitian
positive semideﬁnite matrices Dn . An alternate cost function F related to factorization is used
1132

Riemannian Optimization Methods For PhaseLift

noise
iter
nf
ng
ff
RMSE
t

κ

Algorithm 2

10−6
0
10−6
0
10−6
0
10−6
0
10−6
0
10−6
0

128
138
132
143
128
138
1.84−5
4.08−7
6.72−4
6.70−4
2.13
2.20

1
1027
1070
2210
2306
1105
1153
1.84−5
4.08−7
6.72−4
6.70−4
1.272
1.342

W. Huang and K. A. Gallivan and X. Zhang

2
2000
2000
4266
4308
2712
2154
1.91−5
1.16−6
1.09−3
1.09−3
2.752
2.632

LR-FISTA
4
8
2000
2000
2000
2000
4312
4336
4322
4314
2156
2168
2161
2157
2.35−5 3.55−5
6.27−6 2.51−5
2.10−3 3.53−3
2.18−3 4.01−3
3.012
4.642
2.982
4.322

16
2000
2000
4316
4320
2158
2160
7.62−5
8.89−5
6.27−3
7.29−3
7.042
6.912

Table 2: Comparisons of Algorithm 2 and LR-FISTA for the noise PhaseLift problem (3.4)
with SNR be 31.05 dB, n1 = n2 = 64 and several values of k and κ. represents the number of
iterations reach the maximum.

to replace any cost function H in this class. The important optimality condition, Theorem
4.1, shows that if Yp is a rank deﬁcient minimizer of Fp , then Yp Yp∗ is a stationary point of
H. Additionally, Algorithm 2 based on optimization on a ﬁxed rank manifold and dynamically
reducing rank is developed for optimizing the cost function F . For optimization on a ﬁxed rank
manifold, recently developed state-of-the-art Riemannian optimization methods on a quotient
space are used. In the experiments, it is shown that Algorithm 2 with LRBFGS yields more
eﬃcient than LR-FISTA for both noiseless and noise artiﬁcial data. The code used for these
experiments is available at http://www.math.fsu.edu/~whuang2/papers/SPLRROMCSCshort.
htm.

References
[1] P.-A. Absil, C. G. Baker, and K. A. Gallivan. Trust-region methods on Riemannian manifolds.
Foundations of Computational Mathematics, 7(3):303–330, 2007.
[2] P.-A. Absil, M. Ishteva, L. De Lathauwer, and S. Van Huﬀel. A geometric Newton method for Oja’s
vector ﬁeld. Neural Computationomputation, 21(5):1415–33, May 2009. doi:10.1162/neco.2008.0408-749.
[3] P.-A. Absil, R. Mahony, and R. Sepulchre. Optimization algorithms on matrix manifolds. Princeton
University Press, Princeton, NJ, 2008.
[4] C. G. Baker. Riemannian manifold trust-region methods with applications to eigenproblems. PhD
thesis, Florida State University, Department of Computational Science, 2008.
[5] A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183–202, January 2009. doi:10.1137/080716542.
[6] S. Becker, E. J. Cand, and M. Grant. Templates for convex cone problems with applications to
sparse signal recovery. Mathematical Programming Computation, 3:165–218, 2011.
[7] O. Bunk, A. Diaz, F. Pfeiﬀer, C. David, B. Schmitt, D. K. Satapathy, and J. F. van der Veen.
Diﬀractive imaging for periodic samples: retrieving one-dimensional concentration proﬁles across

1133

Riemannian Optimization Methods For PhaseLift

[8]

[9]
[10]

[11]
[12]

[13]

[14]
[15]
[16]
[17]
[18]

[19]
[20]

[21]
[22]

[23]
[24]
[25]
[26]

W. Huang and K. A. Gallivan and X. Zhang

microﬂuidic channels. Acta crystallographica. Section A, Foundations of crystallography, 63(Pt
4):306–314, July 2007. doi:10.1107/S0108767307021903.
S. Burer and R. D. C. Monteiro. A nonlinear programming algorithm for solving semideﬁnite
programs via low-rank factorization. Mathematical Programming, 95(2):329–357, February 2003.
doi:10.1007/s10107-002-0352-8.
E. J. Cand`es, Y. C. Eldar, T. Strohmer, and V. Voroninski. Phase retrieval via matrix completion.
SIAM Journal on Imaging Sciences, 6(1):199–225, 2013. arXiv:1109.0573v2.
E. J. Cand`es and X. Li. Solving quadratic equations via phaselift when there are about
as many equations as unknowns. Foundations of Computational Mathematics, June 2013.
doi:10.1007/s10208-013-9162-z.
E. J. Cand´es, X. Li, and M. Soltanolkotabi. Phase retrieval via Wirtinger ﬂow: theory and
algorithms. IEEE Transactions on Information Theory, 64(4):1985–2007, 2016.
E. J. Cand`es, T. Strohmer, and V. Voroninski. PhaseLift : Exact and stable signal recovery
from magnitude measurements via convex programming. Communications on Pure and Applied
Mathematics, 66(8):1241–1274, 2013.
C. Chen, J. Miao, C. w. Wang, and T. K. Lee. Application of optimization technique to noncrystalline x-ray diﬀraction microscopy: Guided hybrid input-output method. Physical Review B,
76(6):064113, August 2007. doi:10.1103/PhysRevB.76.064113.
R. W. Harrison. Phase problem in crystallography. Journal of the Optical Society of America A,
10(5):1046–1055, May 1993. doi:10.1364/JOSAA.10.001046.
W. Huang. Optimization algorithms on Riemannian manifolds with applications. PhD thesis,
Florida State University, Department of Mathematics, 2013.
W. Huang, P.-A. Absil, and K. A. Gallivan. A Riemannian symmetric rank-one trust-region
method. Mathematical Programming, 150(2):179–216, February 2015.
Wen Huang, K. A. Gallivan, and P.-A. Absil. A Broyden Class of Quasi-Newton Methods for
Riemannian Optimization. SIAM Journal on Optimization, 25(3):1660–1685, 2015.
Wen Huang, K. A. Gallivan, and Xiangxiong Zhang. Solving phaselift by low rank riemannian
optimization methods for complex semideﬁnite constraints. Technical Report UCL-INMA-2015.01,
U.C.Louvain, January 2015.
M. Journ´ee, F. Bach, P.-A. Absil, and R. Sepulchre. Low-rank optimization on the cone of positive
semideﬁnite matrices. SIAM Journal on Optimization, 20(5):2327–2351, 2010.
J. Miao, T. Ishikawa, Q. Shen, and T. Earnest. Extending X-ray crystallography to allow the
imaging of noncrystalline materials, cells, and single protein complexes. Annual review of physical
chemistry, 59:387–410, January 2008. doi:10.1146/annurev.physchem.59.032607.093642.
Y. Nesterov. Introductory lectures on convex programming: a basic course, volume I. Springer,
2004.
W. Ring and B. Wirth. Optimization methods on Riemannian manifolds and their application to shape space.
SIAM Journal on Optimization, 22(2):596–627, January 2012.
doi:10.1137/11082885X.
J. L. C. Sanz. Mathematical considerations for the problem of Fourier transform phase retrieval
from magnitude. SIAM Journal on Applied Mathematics, 45(4):651–664, 1985.
H. Sato. A Dai-Yuan-type Riemannian conjugate gradient method with the weak Wolfe conditions.
Computational Optimization and Applications, 2015. to appear.
I. Waldspurger, A. DAspremont, and S. Mallat. Phase recovery, maxcut and complex semideﬁnite
programming. Mathematical Programming, December 2013. doi:10.1007/s10107-013-0738-9.
A. Walther. The question of phase retrieval in optics. Optica Acta: International Journal of
Optics, 10(1):41–49, January 1963. doi:10.1080/713817747.

1134

