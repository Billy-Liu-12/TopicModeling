Quantum-Behaved Particle Swarm Optimization
Algorithm with Controlled Diversity
Jun Sun, Wenbo Xu, and Wei Fang
Center of Intelligent and High Performance Computing,
School of Information Technology, Southern Yangtze University,
No. 1800, Lihudadao Road, Wuxi Jiangsu 214122, China
{sunjun_wx, xwb_sytu, wxfangwei}@hotmail.com

Abstract. Premature convergence, the major problem that confronts
evolutionary algorithms, is also encountered with the Particle Swarm
Optimization (PSO) algorithm. In the previous work [11], [12], [13], the
Quantum-behaved Particle Swarm (QPSO) is proposed. This novel algorithm is
a global-convergence-guaranteed and has a better search ability than the
original PSO. But like other evolutionary optimization technique, premature in
the QPSO is also inevitable. In this paper, we propose a method of controlling
the diversity to enable particles to escape the sub-optima more easily. Before
describing the new method, we first introduce the origin and development of the
PSO and QPSO. The Diversity-Controlled QPSO, along with the PSO and
QPSO is tested on several benchmark functions for performance comparison.
The experiment results testify that the DCQPSO outperforms the PSO and
QPSO.

1 Introduction
The Particle Swarm Optimization (PSO), first introduced by Kennedy and Eberhart
[5], is a stochastic optimization that can be likened to the behavior of a flock of birds.
It has been used to solve a range of optimization problems, including neural network
training [6] and function minimization. Since its origin in 1995, several attempts have
been made to improve the performance of the original PSO ([1], [2], [4], [8], [9], [10],
[17]). The original PSO, however, is not a global optimization algorithm, as has been
demonstrated by F. van den Bergh in [3]. In our previous work [11], [12], [13], we
proposed a novel global-convergence-guaranteed PSO, Quantum-behaved Particle
Swarm Optimization (QPSO).
Like other evolutionary algorithm, the PSO as well as QPSO, confront the problem
of premature convergence, which results in great performance loss and sub-optimal
solutions. In the PSO or QPSO, the fast information flow between particles seems to
be the reason for clustering of particles. Diversity declines rapidly, leaving the PSO or
QPSO algorithm leads to low diversity with fitness stagnation as an overall result. In
this paper, we propose a Diversity-Controlled Quantum-behaved Particle Swarm
Optimization (DCQPSO). In the DCQPSO, a threshold value was set for population’s
diversity measure to prevent premature convergence and therefore enhance the overall
performance of the QPSO. The rest part of the paper is organized as follows. In the
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part III, LNCS 3993, pp. 847 – 854, 2006.
© Springer-Verlag Berlin Heidelberg 2006

848

J. Sun, W. Xu, and W. Fang

next section, the PSO is introduced. The origin and development of QPSO is
described in Section 3 and the DCQPSOs are proposed in Section 4. Section 5 is the
experiment results and discussion. Some conclusion remarks are given in Section 6.

2 PSO Algorithms
The PSO is a population-based optimization technique, where a population is called a
swarm. Each particle represents a possible solution to the optimization task at hand.
During each iteration each particle accelerates in the direction of its own personal best
solution found so far, as well as in the direction of the global best position discovered
so far by any of the particles in the swarm. Let M denote the swarm size. Each
individual i ( 1 ≤ i ≤ M ) has the following attributes: A current position in the search
space X i = ( xi,1 , xi, 2 , L, xi,n ) , a current velocity Vi = (v i ,1 , v i , 2 , L , v i , n ) , and a personal

best position in the search space Pi = ( p i ,1 , p i , 2 , L , p i , n ) . During each iteration, each
particle is swarm is updated using (1) and (2). Assuming that the function f is to be
minimized, that the swarm consists of n particles, and that r1 ~ U ( 0 ,1) , r2 ~ U ( 0 ,1)
are elements from two uniform random sequences in the range (0,1), then
v i , j (t + 1) = w ⋅ v i , j (t ) + c1 ⋅ r1,i (t ) ⋅ [ p i , j (t ) − x i , j (t )] + c 2 ⋅ r2,i (t ) ⋅ [ p g , j (t ) − x i , j (t )]

for all j ∈ 1,2 L , n , thus,

(1)

vi , j is the velocity of the jth component of the velocity of

the ith particle, and c1 and c 2 denote the acceleration coefficients. Pg is the global
best position found by any particle during all previous steps. The new position of a
particle is calculated using
X i (t + 1) = X i (t ) + Vi (t + 1)

(2)

The value of each component in every Vi vector can be clamped to the range
[− v max , v max ] to reduce the likelihood of particles leaving the search space. The
variable w in (1) is called the inertia weight, whose value is typically setup to vary
linearly from 1 to near 0 during the course of training run. Acceleration coefficients
c1 and c 2 also control how far a particle will move in a single iteration.

3 Quantum-Behaved Particle Swarm Optimization
Trajectory analyses in [5] demonstrated that, to guarantee convergence of the PSO
algorithm, each particle must converge to its local attractor q = (q1, q2 ,LqD ) , of which
the coordinates are:

q d = ( c1 r1 p id + c 2 r2 p gd ) ( c1 r1 + c 2 r2 ) , (d=1,2,…n)

(3)

q d = ϕ ⋅ pid + (1 − ϕ ) ⋅ p gd , ϕ ~ U (0,1) , (d=1,2,…n)

(4)

or

QPSO Algorithm with Controlled Diversity

849

Assume that there is one-dimensional Delta potential well on each dimension at point
q and each particle has quantum behavior. For simplicity, we consider a particle in
one-dimensional space, with point q the center of potential well. Solving the
Schrödinger equation, we can get the normalized the following probability
distribution function F
F (y) =

∫ Q ( y ) dy
y

= e

−∞

−2 q− X

L

(5)

where L determines search scope of each particle. Employing Monte Carlo method,
we can obtain the position of the particle

x = q ±

L
ln( 1 u )
2

u = rand ( 0 ,1 )

(6)

where u is a random number uniformly distributed in (0, 1).
A global point called Mainstream Thought or Mean Best Position of the population
is introduced into PSO. The global point, denoted as mbest, is defined as the mean of
the pbest positions of all particles. That is
mbest =

1
M

⎛ 1

M

M

∑ P = ⎜⎜⎝ M ∑ p
i

i =1

i1

,

i =1

1
M

M

∑p
i =1

i2

, L,

1
M

M

∑p
i =1

id

⎞
⎟
⎟
⎠

(7)

where M is the population size and Pi is the pbest position of particle i. Then the
value of L and the position are evaluated by
L = 2 β ⋅ mbest

− x

x := q ± β ⋅ mbest − x ⋅ ln( 1 / u )

(8)
(9)

where parameter β is called Contraction-Expansion Coefficient, which could be tuned
to control the convergence speed of the algorithms. The PSO with equation (19) is
called Quantum-behaved Particle Swarm Optimization (QPSO).

4 Diversity-Controlled QPSO
As we know, a major problem with PSO and other evolutionary algorithms in multimodal optimization is premature convergence, which results in great performance loss
and sub-optimal solutions. In a PSO system, with the fast information flow between
particles due to its collectiveness, diversity of the particle swarm declines rapidly,
leaving the PSO algorithm with great difficulties of escaping local optima. Therefore,
the collectiveness of particles leads to low diversity with fitness stagnation as an
overall result. In QPSO, although the search space of an individual particle at each
iteration is the whole feasible solution space of the problem, diversity loss of the
whole population is also inevitable due to the collectiveness.
In 2002, Ursem has proposed a model called Diversity-Guided Evolutionary
Algorithm (DGEA) [14], which applies diversity-decreasing operators (selection,

850

J. Sun, W. Xu, and W. Fang

recombination) and diversity-increasing operators (mutation) to alternate between two
modes based on a distance-to-average-point measure. The performance of the DGEA
clearly shows its potential in multi-modal optimization.
Also in 2002, Riget et al [15] adopted the idea from Usrem into the basic PSO
model with the decreasing and increasing diversity operators used to control the
population. This modified model of PSO uses a diversity measure to have the
algorithm alternate between exploring and exploiting behavior. They introduced two
phases: attraction and repulsion and the swarm alternate between these phases
according to its diversity. The improved PSO algorithm is called Attraction and
Repulsion PSO (ARPSO) algorithm.
Inspired by works undertaken by Ursem and Riget et al, we introduce the
Diversity-Controlled model in Quantum-behaved PSO. The diversity is measure by
the following formula.
S

diversity ( S ) =

1
⋅∑
S ⋅ A i =1

D

∑ (x
j =1

ij

− x j )2

(10)

where S is the swarm, S = M is the population size, A is the length of longest the
diagonal in the search space, D is the dimensionality of the problem, xij is the jth
value of the ith particle and x j is the jth value of the average point.
But unlike to their works, we only set a low bound to the diversity of the
population. The procedure of the algorithm is as follows. After initialization, the
algorithm is running in attraction mode that guaranteed by setting the value of
β smaller than 1.0. In [13], using stochastic simulation, we found out that the particle
will converge when β < 1.778 and otherwise will diverge. In this paper, the attraction
mode is realized by varying β from 1.0 to 0.5 over the running. That is,

β = (1.0 − 0.5) × ( MAXITER − t ) / MAXITER − 0.5

(11)

where MAXITER is the maximum number of iterations and t is the number of
current iteration. In the course of the running of the algorithm, if the diversity
measure of the population declines to below the threshold value dlow, the particles
will explode to increase the diversity until it is larger than dlow. There are two
method of making the particle to explode. One method is to control the ContractionExpansion Coefficient β. That is, we can set β=β0 (β0>1.778) once the diversity is
lower than the threshold value dlow. In this paper the DCQPSO using this method is
called DCQPSO1. The other method of increasing the diversity is initializing the
Mean Best Position (mbest) of the population across the search space once the
diversity is smaller than dlow. The reason for the initialization of mbest is that when
the diversity is low, the distance between the particle and the mbest position is too
small for the particle to escape the local optima as can be seen from equation (9).
Therefore initializing the mbest could enlarge the gaps between particles and the
mbest position, consequently making particles explode temporarily. The DCQPSO
with this operation is called DCQPSO2. The DCQPSO algorithms are formulated as
follows.

QPSO Algorithm with Controlled Diversity

851

Initialize the population
for t=1 to MAXITER
Compute the mbest of the population;
measure the diversity of the population by (10)
β=(1.0-0.5)*(MAXITER-t)/MAXITER+0.5;(in attraction
mode)
if (diversity<dlow)(in explosion mode)
β=β0; (for DCQPSO1)
(or initializing the mbest; (for DCQPSO2);
endif
for i=1 to population size M;
if f(Pi)<f(Xi) then Xi=Xi
pg=argmin(Pi);
for d=1 to dimension n
fi=rand(0,1);
q=fi*pid+(1-fi)*pgd;
u=rand(0,1);
if rand(0,1)>0.5;
Xid=q-β∗abs(mbestd-xid)*log(1/u);
else
Xid=q+β∗abs(mbestd-xid)*log(1/u);
endif
endfor
endfor
endfor

It can be seen that the DCQPSO runs in attraction mode during the most of the
iterations. Only when the diversity falls below the dlow do the particles fly in
explosion mode. The explosion process is transitory, and once diversity is over the
threshold, the population will return to attraction mode again.

5 Experiment Results and Discussion
We have tested the QPSO and DCQPSO on four widely known benchmark functions
for testing the performance of different evolutionary optimization strategies. These
functions are all minimization problems with minimum value zero. The four test
functions are listed in Table 1. In all performance tests, the initial range of the
population in all cases listed in Table 1 is asymmetry. Table 1 also lists Vmax for
original PSO.
The fitness value is set as function value and the neighborhood of a particle is the
whole population. The population size is set to be 20 for all cases. We test original
PSO with inertia weight (called Standard PSO or SPSO), QPSO and DCQPSOs for
performance Comparison. We had 50 trial runs for every instance and recorded mean
best fitness. The maximum number of iterations is set as 1000, 1500 and 2000
generations corresponding to the dimensions 10, 20 and 30 for first three functions,
respectively, The dimension of the last functions is 2 and the maximum number of
iterations is 2000 for this function. In performance test of the SPSO, the inertia weight

852

J. Sun, W. Xu, and W. Fang

Table 1. The table lists expression of benchmark function, the initial range of the population in
the performance tests. The third column is the upbound of the velocity of the particle in the case
of the SPSO.
Functions
Rosenbrock
function f2
Rastrigrin
function f3
Griewank
function f4
Shaffer’s
function f5

Formulations
n

f ( x) 2 = ∑ (100( xi +1 − xi ) + ( xi − 1) )
2 2

2

i =1

n

f ( x ) 3 = ∑ ( x i − 10 cos( 2πx i ) + 10)
2

i =1

f ( x) 4 =

(x −100)
1
cos( i
) +1
∑(xi −100)2 − ∏
4000 i =1
i
i =1

Xmax

Vmax

(15, 30)

100

100

(2.56, 5.12)

10

10

(300, 600)

600

600

(30, 100)

100

100

n

n

f (x) 7 = 0.5 +

Initial Range

(sin x + y ) − 0.5
(1.0 + 0.001(x 2 + y 2 ) 2
2

2

2

Table 2. Average best fitness and standard deviation of all algorithms on Rosenbrock function
Dimension MAXITER

Mean Value

St. Dev.

94.1276
204.337
313.734
59.4764
110.664
147.609
19.0109
82.0134
111.9926
34.6391
102.1606
128.0084

194.3648
293.4544
547.2635
153.0842
149.5483
210.3262
29.5079
84.4259
164.3119
63.4889
178.6908
160.3456

SPSO

QPSO

DCQPSO1

DCQPSO2

10
20
30
10
20
30
10
20
30
10
20
30

1000
1500
2000
1000
1500
2000
1000
1500
2000
1000
1500
2000

Table 3. Average best fitness and standard deviation of all algorithms on Rastrigrin function
Dimension

MAXITER

Mean Value

St. Dev.

1000
1500
2000
1000
1500
2000
1000
1500
2000
1000
1500
2000

5.5382
23.1544
47.4168
5.2543
16.2673
31.4576
4.8308
13.0424
22.7104
4.6831
15.3056
24.2655

3.0477
10.4739
17.1595
2.8952
5.9771
7.6882
2.4628
4.8795
5.5532
3.6387
11.8478
6.4856

10
SPSO

QPSO

DCQPSO1

DCQPSO2

20
30
10
20
30
10
20
30
10
20
30

QPSO Algorithm with Controlled Diversity

853

w is decreases linearly from 0.9 to 0.4 as in [17]. In performance tests for QPSO and
DCQPSOs, the Contraction-Expansion Coefficient β varies from 1.0 to 0.5 linearly
when the algorithms are running. For DCQPSOs, this parameter control means that
the population is in attraction mode. The threshold value of the diversity measure dlow
is to be 0.005. Moreover, in DCQPSO1, the value of β0 is set as 2.0.
The mean values and standard deviations of best fitness for 50 runs of each
function are recorded in Table 2 to Table 5. The numerical results show that the
DCQPSOs works better on the first three functions than QSPO and SPSO. DCQPSO1
has slightly better performance than DCQPSO2. On Shaffer’s function, the
performances of DCQPSOs are not improved.
Table 4. Average best fitness and standard deviation of all algorithms on Greiwank function

Dimension

Mean Value

St. Dev.

0.09217
0.03002
0.01811
0.08331
0.02033
0.01119
0.0781
0.0189
0.0090
0.0655
0.0202
0.0087

0.0833
0.03255
0.02477
0.06805
0.02257
0.01462
0.0745
0.0229
0.0132
0.0464
0.0204
0.0122

MAIXTER

1000
SPSO

QPSO

DCQPSO1

DCQPSO2

10
20
30
10
20
30
10
20
30
10
20
30

1500
2000
1000
1500
2000
1000
1500
2000
1000
1500
2000

Table 5. Average best fitness and standard deviation of all algorithms on Shaffer’s function

Mean Value
Dimension

MAXITER

SPSO

2

2000

2.78E-04

0.001284

St. Dev.

QPSO
DCQPSO1

2
2

2000
2000

0.001361
0.0012

0.003405
0.0032

DCQPSO2

2

2000

0.0019

0.0039

6 Conclusion
In this paper, we proposed a method of controlling the diversity measure of the
QPSO. The methodology of DCQPSO is setting a threshold value for the diversity to
prevent the particles from clustering. Controlling of the diversity has been testified to
be a good technique for enhancing the performance of the QPSO. However, for other
benchmark functions, such as Sphere function and Ackley function, the results of this
method is poor, since the optima of these functions is easy to find and the local search

854

J. Sun, W. Xu, and W. Fang

ability is key to the performance of the algorithm. Annealing the diversity threshold
dlow could lead to improvements, because it may be an advantage to decrease dlow
near the end of the optimization.

References
1. P. J. Angeline, “Evolutionary Optimization Versus Particle Swarm Optimization:
Philosophy and performance Differences,” Evolutionary Programming VII (1998), Lecture
Notes in Computer Science 1447, pp. 601-610, Springer.
2. F. Van den Bergh, A. P. Engelbrecht, “A New Locally Convergent Particle Swarm
Optimizer,” 2002 IEEE International Conference on systems, Man and Cybernetics, 2002.
3. F. Van den Bergh, “An Analysis of Particle Swarm Optimizers,” PhD Thesis. University
of Pretoria, Nov 2001.
4. M. Clerc, “The Swarm and Queen: Towards a Deterministic and Adaptive Particle Swarm
Optimization,” Proc. Congress on Evolutionary Computation 1999, pp. 1951-1957.
5. M. Clerc and J. Kennedy, “The Particle Swarm: Explosion, Stability, and Convergence in a
Multi-dimensional Complex Space”, IEEE Transaction on Evolutionary Computation, no.
6, pp. 58-73, 2002.
6. A. P. Engelbrecht and A. Ismail, “Training product unit neural networks, “ Stability
Control: Theory APPL., vol. 2, no. 1-2, pp.59-74
7. J. Kennedy, R. C. Eberhart, “Particle Swarm Optimization,” Proc. IEEE Int’l Conference
on Neural Networks, IV. Piscataway, NJ: IEEE Service Center, 1995, pp. 1942-1948.
8. J. Kennedy, “Sereotyping: Improving Particle Swarm Performance with cluster analysis,”
in Proc. 2000 Congress on Evolutionary Computation, pp. 1507-1512.
9. J. Kennedy, “Small worlds and Mega-minds: Effects of Neighborhood Topology on
Particle Swarm Performance,” Proc. Congress on Evolutionary Computation 1999, pp.
1931-1938.
10. P. N. Suganthan, “Particle Swarm Optimizer with Neighborhood Operator,” Proc. 1999
Congress on Evolutionary Computation, pp. 1958-1962.
11. J. Sun et al, “Particle Swarm Optimization with Particles Having Quantum Behavior,”
Proc. 2004 Congress on Evolutionary Computation, pp. 325-331.
12. J. Sun et al, “A Global Search Strategy of Quantum-behaved Particle Swarm
Optimization,” Proc. 2004 IEEE Conference on Cybernetics and Intelligent Systems.
13. J. Sun et al, “Adaptive Parameter Control for Quantum-behaved Particle Swarm
Optimization on Individual Level”, Proceedings of 2005 IEEE International Conference on
Systems, Man and Cybernetics, pp. 3049-3054.
14. R. K. Ursem: Diversity-Guided Evolutionary Algorithms, Proceedings of The Parallel
Problem Solving from Nature Conference 2001.
15. J. Vesterstrom, J. Riget and T. Krink: Division of Labor in Particle Swarm Optimization.
IEEE 2002 Proceedings of the Congress on Evolutionary Computation.
16. Y. Shi and R. Eberhart, “Empirical Study of Particle Swarm optimization,” Proc. of
Congress on Evolutionary Computation, 1999, 1945-1950.
17. Y. Shi, R. C. Eberhart, “A Modified Particle Swarm,” Proc. 1998 IEEE International
Conference on Evolutionary Computation, pp. 1945-1950.

