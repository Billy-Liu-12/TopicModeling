Contour Extraction Algorithm Using a Robust Neural
Network
Zhou Zhiheng, Li Zhengfang, and Zeng Delu
College of Electronic & Information Engineering, South China University of Technology,
510641 Guangzhou, China
crenna@163.com

Abstract. For the contour extraction from the images, the traditional active contour models may trap in local minimum and strongly depend on initial contour.
A contour extraction algorithm based on a robust neural network is proposed in
this paper. A searching series of circles are used in obtained feature pixels with
adaptive threshold for the final curve function approaching by neural network.
Robust back propagation algorithm has been used to control the final curve
shape. The simulations also show that the proposed algorithm has a great performance for different kinds of images.
Keywords: contour extraction, neural network.

1 Introduction
Object extraction has a wide variety of applications in computer vision and image processing. Snake [1,2] and geodesic active contours models [3] have been developing rapidly during past years. These models usually take an initial contour defined for an object
contour and make it evolve until the contour satisfactorily approximates the actual
object contour. The initial contour is a rough approximation and the final contour is an
accurate representation of the object boundary. The models can be achieved by introducing an energy function and then minimizing it. In order to deal with topological
changing of the evolving contour, Chop[4], Caselles et al.[5] and Malladi et al.[6] introduced level set theory.
But the minimization of all these methods may trap in local minimum, especially in
the case of the contour with long concavities. On the other hand, the initial contour
must fully be inside or outside the object contour, and the direction of contour evolution must be given to the algorithm in advance.
Addressing all mentioned problems, a contour extraction algorithm based on neural network is proposed in this paper. Assume the object contour can be viewed as a close curve in
the two-dimensional surface. We intend to approach the curve function from some training
feature pixels obtained by a series of searching circles with adaptive threshold.

2 Feature Pixels Searching
The algorithm chooses a circle in the image, and then searches the feature pixels on
the circle according to some rules. After creating a new circle through changing of
Y. Shi et al. (Eds.): ICCS 2007, Part IV, LNCS 4490, pp. 283–290, 2007.
© Springer-Verlag Berlin Heidelberg 2007

284

Z. Zhou, Z. Li, and D. Zeng

radiuses, it searches the feature pixels on the new circle as before. The above procedure
repeats till the radiuses tend to zero. These series of circles are called as “Searching
Circles”.
Firstly, we choose a pixel in the middle (as possible) of the image as the initial center O0 = ( x0 , y0 ) , and initial radiuses r0 large enough to cause the initial circle C0
to encircle the objects in the image.
2.1 Radius Changing
Generally, in order to stop the searching process the radiuses of the circles are supposed to become less and less. So, the key problem is how to reduce the radius. If the
reduction of radiuses is too much, some parts of the contour would possibly be
missed. If it is too less, the computational costs will be enhanced. Evidently, we can
choose a big reduction when the curve is far away from the real contour, and viceversa. If we denote I ( x, y ) as the value at pixel ( x, y ) , rn as the radius of the current searching circle

Cn , then reduction of the radius

Δrn = rn − rn +1 f Δrn ( max{| ∇I ( x, y ) || ( x, y ) ∈ Cn })
(1)
where ∇I ( x, y ) is the gradient of the image at ( x, y ) and
ln(255 2)
f Δr (u ) =
.
(2)
ln(2 + u )
So, f Δr (u ) is a decreasing function with respect to x , which means Δr becomes
smaller as the searching circle is closed to the objects boundaries meanwhile the absolute gradients become bigger. In equation (2), avoiding the denominator being 0, we
use “2+u”. On the other hand, if the gradient is bigger than 255/2, there is a strong
enough edge passing this pixel. So, u is comparable to 255/2.
2.2 Adaptive Threshold
The simplest method for judging contour feature pixels is to use gradient threshold,
nevertheless a single threshold is not fit for the whole image. In order to save more
computations, the threshold T is adaptively determined by the method, which is given
as following:
(a) Select an initial estimate for T.
(b) Divide all pixels of the former n searching circles

C0 ,

, Cn −1 into two

groups, such as

G1 = {( x, y ) | ∇I ( x, y ) > T } , G2 = {( x, y ) | ∇I ( x, y ) ≤ T } .

(c) Compute the average gradient values
respectively.
(d) For the n+1th searching circle

μ1

and

μ2

for the pixels in

Cn , use new threshold value

(3)

G1 and G2 ,

Contour Extraction Algorithm Using a Robust Neural Network

T=

1
( μ1 + μ2 )
2

285

(4)

(e) Repeat steps (b) through (d) until searching stops or the difference in T in successive iteration is smaller enough.
It can be f ound that when the pixels on the contour and pixels in other smooth
region occupy comparable numbers in the image, a good initial value for T is the
average gradient value of the image. But, when the former is smaller than the later,
the average gradient value is no longer a good initial choice and median value between the maximum and minimum gradient values will be better.

3 Contour Approaching
The object contour can be viewed as a close curve in the two dimensional surface. The
feature pixels, obtained in the second section, can be viewed as some training samples
of the curve. So, the contour can be obtained by approximated the curve function by
these samples. Hornik [7] used the Stone-Weirstrass theorem to prove that a two-layer
feedforward network can approximate a continuous real function on a compact subset
∞

of ℜ arbitrarily closely in terms of the L norm. We try to use neural network to
approach the curve function, and then obtain the whole object contour.
n

3.1 Function Approximation by Feed-Forward Network
Denote the contour feature pixels set by

{( x , y ) ; p = 1,
p

p

}

, n , where

y p = f ( x p ) . The task of the neural network is to learn an estimation y = f ( x) of
function f ( x ) , so that the error will approach the minimum in a certain kind of
measurement. Multi-layer networks are highly nonlinear models for function approximations.
In general, an L-layer feedforward network with fixed nonlinear activation functions can be parameterized by a set of L-1 weights

wl , l = 0,1,

, L − 2 . The

w relates the lth layer output x to the l+1th layer activation Al +1 by means
l +1
l l
of an affine transformation, i.e., A = w x , 0 ≤ l ≤ L − 1 . Notice that the 0th
layer output is the network input x. For an input x, the network estimated output y is
l

weight

l

determined by the following forward propagating recursive equations which characterize the network dynamics.

x 0 = x , xl = G l ( Al ) ,
l −1 l −1

where A = w
l

0

Here x and x

x , l = 1,

L −1

(5)

, L − 1 , y = f ( x; w) = x L −1 .
l

are the input and network output, respectively, and G is a func-

tion, which applies a nonlinear activation function
argument.

g l ( ) to each component of its

286

Z. Zhou, Z. Li, and D. Zeng

In particular, the parametric model represented by a three-layer network with one
input node, a single output node, and N nodes in the hidden layer has the form
N

f ( x; w ) = ∑ β i g i (α i x )
where

βi , 1 ≤ i ≤ N

(6)

i =1

are weights connecting N hidden nodes to the output node,

αi ,

1 ≤ i ≤ N are weights connecting input layer node to the ith hidden layer node and
the g i ( ) s are the hidden layer activation functions.
3.2 Robust Back Propagation Algorithm
Back propagation (BP) algorithm allows multi-layer feed-forward neural networks to
learn input-output mappings from training samples. The BP algorithm iteratively
adjusts the network weights to minimize the least squares energy function

E ( w) = ∑ ( y p − y p )
n

2

(7)

p =1

where

y p is the desired output for the pth training sample, and y p is the correspond-

E ( w) reaches zero when the estimator f
given by the network interpolates all training pixels, i.e., y p = y p .

ing estimated output. It can be found that

The final contour is determined by feature pixels obtained in the second section.
But directly approximation from feature pixels will make the object’s shape complicated, in another words, the function of the curve be undesired fluctuating, because of
noise pixels or misjudged pixels in the second section. All these feature pixels can be
viewed as outliers. We intend to make the final curve detours these outliers, so we
must reduce the big error deviation causing by them. Robust Statistics is an important
research field for solving this kind of problem.
Based on the theory of robust statistics, the energy function can be rewritten as

E ( w, a) = ∑ ρ p ( y p − y p , a p )
n

(8)

p =1

where

ρ p (u )

is a Huber function [8] as shown in Fig.1,

2
⎪⎧ u
ρ p (u, a p ) = ⎨ 2
⎪⎩a p + 2a p (| u | −a p )

| u |≤ a p
| u |> a p

,

a >0.

(9)

a p is a parameter for the outliers adjusting influence on the energy function. It can be
found that if

a p goes bigger, the less influence of outliers will be added on the energy

function, and vice versa. On the other hand, if a feature pixel with smaller absolute
gradient value, it tends to be outliers and the final curve will detours it. And

Contour Extraction Algorithm Using a Robust Neural Network

287

ρp

outlier ( xp , y p )

i
i

u

ap

( xp , y p )

Fig. 1. Huber function

Fig. 2. The curve detours the outlier

on the contrary, the feature pixel with bigger absolute gradient value is on the final
curve. So, we construct the relative expression between a p and absolute gradient
value

(

)

a p = lg ∇I ( x p , y p ) + 1 .

Fig.2 shows how the curve detours the outlier. In this case,

(10)

∇I ( x p , y p ) is rela-

tively small. The dashed lines are the curve whose function is directly approximated
from training data. And the real lines are the curve whose function is approximated by
robust energy function. The robust processing will make the final curve closer to all
feature pixels with bigger absolute gradient values.

4 Simulation Results
This section we are going to present the performance of our robust approaching algorithm after simulation. The design of initial searching circle C0 : Assume the resolu-

M × N , we choose initial center O0 = ([ M 2] , [ N 2]) and initial radius r0 = [ min( M , N ) 2] to cover the
tion

of

the

observed

image

is

whole part of the image.
In order to verify the performance of the proposed algorithm, simulations will be
implemented in different kinds of images, such as complicated background, and noisy
boundary.
4.1 Complicated Background
If the image contains complicated background, the contour of an object may be composed of different parts of boundaries, or objects’ contours are very different from
each other. Traditional contour extraction algorithm mainly depends on the variation
of gradients to do the judgments. Simple judging mode cannot discriminate different
parts of contour.

288

Z. Zhou, Z. Li, and D. Zeng

(a) Image “Hawk”

(b) Feature points

(c) Extracted contour

Fig. 3. Robust NN for image “Hawk”

The proposed contour extraction algorithm is based on adaptive threshold. We use
image “Hawk” with complicated background and 128 128 in size to do the simulation.
In Fig.3, the final contour can approximate the actual object contour of image “Hawk”.

×

4.2 Noisy Boundary
In traditional active contour model, if the evolving curve reaches the object contour,
the gradient-directed function will tend to zero. In fact, this function has some limitations. On one hand, as pointed in the famous C-V model [9], image gradients are
bounded. On the other hand, if the object boundary is blurring, the gradients does not
change obviously. In these cases, the function does not tend to zero even if the evolving curve reaches the object contour. It will cause the evolving curve pass through the
actual contour. For image noise, active contour model cannot give solutions. But the
proposed robust method can solve the problem efficiently.

(a) Image “Cells”

(b) Feature points

(c) Robust NN extracted contour

(d) C-V model extracted contour

Fig. 4. Robust NN and C-V model for image “Cells” with time cost 3.1s and 42.8s, respectively

Contour Extraction Algorithm Using a Robust Neural Network

289

×

We use image “Cells” with size 83 65 to do the simulation. In Fig.4, it can be
found that the final contour obtained by the proposed algorithm is quite accurate. It
can be found that C-V model does not superior to robust NN, but it costs much more
time than robust NN. We also do other comparisons for Gaussian white noise contaminated image between robust NN and C-V model as shown in Table 1.
Table 1. Computational cost time (s) comparisons with Gaussian white noise contaminated
image with size 256×256

Variance
0
0.01
0.02
0.03

C-V model
100.8
140.6
187.6
221.3

Robust NN
29.9
41.7
43.8
59.8

5 Conclusions
Object detection in the image has a wide variety of applications in computer vision.
An approaching algorithm for object contours based on a robust neural network is
proposed in this paper. A series of searching circles are used in obtained feature pixels
with adaptive threshold for the final curve function approaching by neural network.
Robust back propagation algorithm has been used to control the final curve shape.
The simulations also show that the proposed algorithm has a great performance in
contour extraction. Whatsoever, the contributions in this paper only serve as a prelude
to our future work, in hopes of better results, to integrate this method with snakes,
geodesic active contour, etc.
Acknowledgments. Supported by National Natural Science Foundation of China
(Grant No. 60325310, No. U0635001), the Science Foundation of Guangdong Province for Program Research Team (Grant No. 04205783), the Specialized Prophasic
Basic Research Projects of Ministry of Science and Technology, China (Grant No.
2005CCA04100), China Postdoctoral Science Foundation (Grant No.20060390728).

References
1. Kass, M., Witkin, A., Terzopoulos, D.: Snakes: Active Contour Models. Int. J. Computer
Vision, Vol. 1, (1988) 321-332
2. Jacob, M., Blu, T., Unser, M.: Efficient Energies and Algorithms for Parametric Snakes.
IEEE Trans. on Image Processing, Vol.13, No.9, (2004) 1231-1243
3. Paragios, N., Deriche, R.: Geodesic Active Contours and Level Sets for the Detection and
Tracking of Moving Objects. IEEE Trans. on Pattern Analysis and Machine Intelligence,
Vol.22, No.3, (2000) 266-280
4. Chop, D.: Computing Minimal Surfaces via Level Set Curvature-Flow. J. Computational
Physics, Vol. 106, (1993) 77-91
5. Caselles, V., Kimmel, R., Sapiro, G.: Geodesic Active Contours. Proc. IEEE Int. Conf.
Computer Vision, (1995)

290

Z. Zhou, Z. Li, and D. Zeng

6. Malladi R, Sethian JA, Vemuri BC: Shape Modeling with Front Propagation: A Level Set
Approach. IEEE Trans. on Pattern Analysis and Machine Intelligence, Vol.17, No.2, (1995)
158-175
7. Hornik, K., Stinchcombe, M., White, H.: Multilayer Feed-forward Networks Are Universal
Approximators. Neural Network, Vol. 2, (1989) 359-366
8. Huber, P. J.: Robust Statistics. New York: Wiley, (1981) 73-106
9. Chan, T.F., Vese L.A.: Active Contours without Edges. IEEE Trans. on Image Processing,
Vol.10, No.2, (2001) 266-277

