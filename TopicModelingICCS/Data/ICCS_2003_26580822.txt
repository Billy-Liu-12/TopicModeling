A Dynamically Grouped Multi-multicast Stream
Scheduling Strategy for Video-on-Demand Systems*
Dafu Deng, Hai Jin, and Zongfen Han
Huazhong University of Science and Technology, Wuhan, 430074, China
hjin@hust.edu.cn
Abstract. Network bandwidth is the key performance bottleneck for a videoon-demand (VoD) server. It controls the number of clients the server can support simultaneously. Previous works have shown some strategies, such as the
batching strategy and the stream merging strategy, that use one multicast stream
to serve different clients requesting the same video object at the same time.
They improve the performance of server bandwidth effectively. But the batching strategy results in long start-up latency and the traditional stream merging
strategy also wastes lots of server bandwidth. In this paper, we propose a dynamically grouped multi-multicast stream scheduling strategy, called DGMM,
and analyze its performance in two factors: the start-up latency and the average
bandwidth consumption.

1 Introduction
Video-on-Demand (VoD) is a service that allows clients to communicate with a video
server selecting and viewing a video of their choice simultaneously. A few companies, such as IBM, Microsoft and Apple, successfully ran VoD systems serving a lot
of clients with high cost. With broadband network technology, the client-end bandwidth can achieve almost 100Mbits/s. It can support up to 60 MPEG-I streams (approximately 1.5Mbits/s per MPEG-1 stream). Therefore, server I/O bandwidth and
network bandwidth are the major limiting factors in the widespread usage of VoD
systems. They control the number of streams concurrently sent by a video server.
A conventional video server simply schedules one requested stream for each client,
while most clients often request the same hot video at the same time [5][6]. This phenomenon results in that conventional VoD servers send some streams of same video
data at the same time. It wastes a mass of server bandwidth. Still conventional systems do not scale well, and better solutions are necessary.
The batching strategy [1][5][6][9] presents one such solution. It uses a single multicast stream of data to serve clients that request the same hot video during the same
short time interval. In the batching strategy, a time threshold must be set firstly. Video
servers just schedule the multicast stream at the end of each time threshold. In order
to obtaining a good efficiency in usage of bandwidth, value of this time threshold
must be at least 7 minutes [5]. Therefore, the expected start-up latency is approximate
3.5 minutes. This long delay increases clients reneging rate and decreases the popularization of VoD systems.

*

This paper is supported by Wuhan Key Hi-Tech Project under grant 20011001001.

P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2658, pp. 822–831, 2003.
© Springer-Verlag Berlin Heidelberg 2003

A Dynamically Grouped Multi-multicast Stream Scheduling Strategy

823

Stream merging strategies [2][3][4][7][8][10][11][12] present a good idea to solve
long start-up latency problem. In stream merging strategy, video server immediately
schedules one or two kinds of streams to serve each client request: the complete multicast stream and the patching unicast stream. For the first arrived request, the video
server schedules a complete multicast stream to transmit the integrated video object
immediately. For later requests with the same object, the video server firstly notifies
them to join the multicast group for receiving the remainder of scheduled complete
multicast stream, and then, schedules a patching multicast stream to transmit the lost
video data. Thus, later starters must concurrently receive two streams and merging
them into an integrated video stream. This strategy guarantees the zero start-up latency and high server bandwidth efficiency when client request rates are low and
moderate. However, the server bandwidth efficiency is decreased dramatically at high
request rates due to mass retransmission of same video data.
This paper contributes in developing a novel stream scheduling strategy, called
Dynamically Grouped Multi-Multicast, which can significantly improving server
bandwidth efficiency over a wide range of client request rates. The subsequent sections are organized as follows. In section 2, we describe the basic idea of dynamically
grouped multi-multicast stream strategy, and in section 3, introduce an example algorithm. Section 4 presents performance evaluation based on experimental research.
Finally, section 5 contains our concluding remarks and future works.

2 Dynamically Grouped Multi-multicast Scheduling Strategy
2.1 Preliminaries
Consider that clients requesting different hot video objects are served independently.
Clients request the same hot video object will be discussed in the following sections.
Time is divided into fixed size intervals T. The time slot in which the first client request arrived is labeled t0. The following time slots are labeled t1, …, tn (0•n<+). The
hot video with L minutes is divided into L/T fixed size segments, denoted as V0, V1,
…, V L/T-1. Other conceptions are defined as follows.
Clients requests: For requests arriving at the same time slot, video servers can
batch them together and serve them all by a multicast stream. Therefore, those requests are considered as one request. We use Ci to represent the request arriving at the
time slot ti.
Requests group: Given a clients’ requests sequence C0, …, Ci, …, Cj, …, Cn
(0<i<j<n<+), the sequence is not continuous because requests may not arrive in
some time slots. We sequentially divide those requests into several flexible sized
requests groups G0, G1,…, Gk (0<k<+), while Gk is called the k-th requests group.
Complete multicast stream (CS): For requests group Gi, in order that all clients
can receive all the video segments, video servers must schedule a multicast stream,
which transmits all the segments. This multicast stream is defined to be the complete
multicast stream. We use CSi to represent the complete multicast stream in requests
group Gi, Ncs(i) represents the serial number of the time slot at the end of which CSi is
scheduled, and l(CSi) represents the number of video segments transmitted on CSi.

824

D. Deng, H. Jin, and Z. Han

Patching multicast stream (PS): In a requests group Gi, once CSi has been initialized, clients with requests arrival time later than time tNcs(i) may miss some video
segments that have been transmitted. Therefore, video server must initialize several
streams to patch the lost video segments to clients. We use patching multicast streams
to define those streams and use PSk (0<k) to present the patching multicast stream
initialized at the end of time slot tk. l(PSk) is used to represent the number of video
segments transmitted on PSk.
Segment transmission time (STT): Assuming that video server use CBR (constant bit rate) transmission mode, any segment must be transmitted completely in a
time slot. Therefore, if a video segment is transmitted on a stream, the transmission
must begin at a fixed time point, called segment transmission time (STT). We use
Γ(m,n) to represent the segment transmission time of segment Vm transmitted on
stream PSn. The following formula can be deduced: Γ(m,n)=tn+m*T.
2.2 Basic Idea of DGMM
DGMM scheduling strategy determines how to divide the requests sequence into
different requests groups and how to schedule streams for intra-group requests and
inter-group requests so that the bandwidth efficiency can be improved significantly.
Rules of DGMM strategy are described as follows.
Grouping rule: A video server dynamically maintains several request groups G0,
G1,…,Gn. When the first client request arrived, the video server creates requests group
G0 and puts the request C0 into G0. For other request Ci, if ti<tcs+(L/T -1)*T, where tcs
is the first request arrival time slot of the latest created requests group Gn, the video
server puts the request into Gn. Otherwise, it creates a new requests group Gn+1 and
puts the request into it. When all requests of the requests group Gi have been served,
Gi is deleted. For example, as shown in Figure 1, requests C0, C1, C2, C3, C4, C5, C6, C7
are put into requests group G0 because their requests arrival time slots are less than
t0+(L/T -1)*T. Request C14 is grouped into G1 because time slot t14 is later than
t0+(L/T -1)*T.
Inter-group rule: According to the above grouping rule, there is no video segments can be shared among inter-group requests. Therefore, the video server handles
each grouped requests independently.
Intra-group rule: The objective of each client request in a requests group Gi is to
receive all the L/T parts of transmission and view them without any interruption.
For the first client request of requests group Gi, the video server schedules a complete
multicast stream CSi at the end of the first request arrival time slot. The corresponding
clients join the multicast group of CSi to receive and then playback all segments of
requested videos. For any other request Ck (Ncs(i)<k< Ncs(i)+L/T-1), as video segments V0, …, Vk-Ncs(i)-1 have been transmitted, the video server firstly notifies the corresponding clients to join the multicast group of CSi to receive and buffer video segments Vk-Ncs(i), …,VL/T -1. Then, for each segment of V0, …, Vk-Ncs(i)-1, the video server
searches all the existed patching multicast streams PSNcs(i)+1, …, PSk-1.
If there are no patching multicast streams existed, it schedules a patching multicast
stream PSk to transmit video segments V0, …, Vk-Ncs(i)-1 and notifies the corresponding
clients to receive and playback those video segments. If video segment Vj (0MN

A Dynamically Grouped Multi-multicast Stream Scheduling Strategy

825

Ncs(i)-1) is transmitted on a existed patching multicast stream PSm (Ncs(i)<m<k-Ncs(i))
and the transmit time Γ(j, m) tk, the video server notifies those clients to join the
multicast group of PSm to receive segment Vj. At last, for video segments not transmitted on existed streams or the segment transmission time of them is less than tk, the
video server schedules a patching multicast stream PSk at the end of time slot tk and
transmits them at the corresponding segment transmission time. The corresponding
clients Ck must also join the multicast group of PSk to receive those segments.
CS0

CS1

V 11

V 11

V 10

V 10

V9

V9

V8

V8

C0

C1 C2 C3 C4 C5 C6 C7

t7

t 10

t 11

t 12

t 13

t 14

t 15

t 16

V

t 18 t 19

3

V
2

V

t 20 t 21

C14 C17 C20 C21

0

V

0

V

1

V

V

t 17

4

V

G0

t9

1

V
0

V

0

V0

t8

2

2

V

V1

0

t6

V

V

t1

PS17

V2

1

V

2

V

1

t5

0

V

t0

V

6

5

4

V3

V

1

t4

0

V

0

t3

0

V

V

V

0

t2

V

V 1 PS1

PS20

V4

PS3
PS2

V2

V0

V
V5

3

V

V3

V

PS4

V4

PS21

6

5

PS6
PS5

V

V
V5

V

6

V7

6

PS7

V7

t
t 22

G1

Fig. 1. A scheduling example of DGMM

Figure 1 shows a scheduling example of DGMM. The solid lines describe multicast streams, while the dotted lines indicate the skipped video segments. Because it is
similar between requests group G0 and requests group G1, we just discuss the scheduling for group G1. CS1 is the complete scheduled multicast stream and the client
request C14 joins the multicast group of CS1 to receive and playback all segments.
Because segments V0, V1, V2 have been transmitted completely when request C17 arrives, the video server schedules PS17 to transmit those missed segments. The client
C17 join the multicast group of CS1 to receive and buffer segments V3, …, V11 and join
the multicast group of PS17 to receive and playback segments V0, V1, V2.
The similar case is happened for request C20. For serving the request C21, the video
server firstly notifies the corresponding clients to join the multicast group of CS1 to
receive and buffer segments V7, V8, V9, V10, V11. Then, it searches the existed patching
multicast streams P17, P18 and finds that segments V1, V2, V3, V4, V5 can be received on
PS18 by client C21 (i.e. Γ(1, 18), …, Γ(5, 18)t21). Therefore, the server notifies C21 to
join the multicast group of PS18 to receive those segments. At last, the server schedules a patching multicast stream P21 to transmit segments V0, V6 at the corresponding
segment transmission time. The client C21 also needs to join the multicast group of
PS21 to receive segments V0, V6.

826

D. Deng, H. Jin, and Z. Han

3 An Example Algorithm of DGMM
A video server is usually comprised of three parts--scheduler, data server, and video
storage. A scheduler is a controller of the video server. It is responsibility for exchanging control messages with clients on a control channel and for scheduling a data
server to transmit video segments. Functions of a data server are reading video segments from a video storage and allocating data channels to transmit video segments.
When a client request arrives, the scheduler determines data channels a client should
join and sends a message list Ml to notify the information of those channels. The information of each data channel is embedded in one element of Ml. We use a triple
Mi(a, A, SId) to describe the i-th element of Ml, where a is the multicast IP address of
that channel, A is a bit array indicating which video segment is transmitted on that
channel, and SId is the exclusive identity of that channel. Here we discuss an example
algorithm for the client, the scheduler, and the data server.
3.1 Client Algorithm
Each client contains a set-top box, a disk, and a display monitor. Clients communicate
with a video server by the set-top box. There is a controlling thread, a network listening thread, a task thread, a display thread, and a buffer management thread running in
the set-top box. The controlling thread requests its desired video, waits to receive
message list Ml comprised of M0(a, A, SId), …, Mi(a, A, SId). For each message, the
controlling thread notifies the network listening thread to listen in the corresponding
data channel. When a video segment arrives on a multicast stream, the network listening thread notifies the task thread to run the corresponding task to receive them.
Each task is responsible for receiving video segments on one data channel, and sending them to the display thread or save them to disk. Figure 2(a) shows the client data
receiving algorithm in detail.
3.2 Server Scheduler Algorithm
The key function of a scheduler is to determine in which data channel a client can
receive valid video segments and how many video segments should be transmitted on
that channel. In order to implementing this function, a stream information list is built
for all data channels allocated to serve a group requests. Each unit of the stream information list describes the information of one data channel in a triple Si(t, a, A),
where t is the initiating time of a data channel, a is the multicast IP address of the data
channel, and A is an array with each element the serial number of a video segment
transmitted on data channel. Furthermore, a message list Ml comprised of M0(a, A,
SId), …, Mi(a, A, SId) is built to record the information of data channels allocated for
one request. The video server uses this message list to notify that client to receive
video segments on the corresponding channels.
Figure 2(b) illustrates the server scheduler algorithm. The scheduling thread is
driven by two kinds of events: the request arrival event and the time out event. The
request arrival event is started when a request arrives, while the time out event is
started at the end of each time slot. Each event includes a parameter to indicate the

A Dynamically Grouped Multi-multicast Stream Scheduling Strategy

827

requested video object so that the scheduler can find out appropriate scheduling parameters.
Client Main Control Thread:
1. Send a request to video server;
2. Wait for messages M0(a,A,SId),…,Mi(a,A,SId);
3. For each message Mi(a,A,SId),inform network listening thread to listen
in a data channel Sid and then initiate a task to receive data from it;
Client Task Thread:
1.Wait for listened data channels to be notified that some media data has
arrived;
2.According S id of notified data channel, select the corresponding task
to run on it;
3.If the value returned by current task is -1
4. delete the current task;
5.go to 1;
Client Task:
1.while(1)
2. Receive arrived media data on the corresponding data channel;
3. If the received media data is not NULL
4. If the received media data must be displayed now,
5.
put it to the display buffer which is shared by the display thread;
6.
else
write media data to disk;
7. If the received media data is the last media data on the data channel.
8. return -1;
9. else
inform network listening thread to listen to the data channel again;
10. return 0;

(a)Client receiving algorithm

Notations:
the current time;
tcur:
Si(t,a,A): the ith stream information unit;
Data Server Thread:
1 m = the length of array A in Si(t,a,A);
2 n = 0;
3 for(j=n;j<m;j++)
4
if(t of Si(t,a,A)+Aj*T<=tcur)
read the media unit MAj from video storage and send it to client.
5
n++;
else
6
sleep(t of Si (t,a,A)+Aj*T-tcur );

Notations:
L: Length of the requested video;
T: Time interval;
Tc: The last complete multicast stream initial time.
Tp: The last patching multicast stream initial time.
tr : The request arrival time.
Q: The queue for batching clients that are not served immediately.
Scheduler Thread Algorithm:


If a request arrival event start
{

2
Finds out corresponding parameters Q,Tc, and L based on
requested video object.
3
if ((tr>=(Tc+L-T))||(tr==t0))
{
4
Schedules a complete multicast stream to transmit the
requested video.
5
Updates Tc (Tc=tr).
6
Initializes a new timer and set time out interval to T;
}
else
7
Put the arrived request into Q;
}
8 Else if a time out event start
{
9
Finds out Q and Tp based on the request video object parameter
included in the
event.
10
if (Q is not null)
{
11
Searches the existed stream information list to find out
which video
segments will be sent on other existed patching streams.
12
Builds the message information listMl and sends it to all
clients batched
in Q.

Schedules a patching multicast stream to transmit the lost
video segments.

Update Tp (Tp = tc).

Delete all requests batched in Q;
}

Update timer to the end time of next time slot.
}
 wait for next event start.

(b) Server scheduler algorithm

(c)Data server algorithm

Fig. 2. An example algorithm of DGMM.

3.3 Data Server Algorithm
Each data server thread is responsible for serving a multicast stream. The function of
a data server thread is reading media data from a video storage, and then sending
them to clients on a data channel according to the corresponding stream information
unit Si(t, a, A). On a special data channel, a video segment must be transmitted at a
fixed time point, and the multicast stream may be not continual. Therefore, we must
interrupt the data server thread and wake up it at the appropriate time point. Figure
2(c) shows the data server algorithm.

828

D. Deng, H. Jin, and Z. Han

4 Performance Evaluations
In this section we will give out experimental results with comparison with the FCFS
batching strategy and the stream merging strategy.
4.1 Experimental Parameters
We consider two factors for each video: its length and popularity. The data from
Internet Movie Database (http://www.imdb.com) has shown a normal distribution
with a mean of 102 minutes and a standard deviation of 16 minutes. In order to reserve some client bandwidth used to obtain other services (i.e FTP, WWW, Email),
we assume that the maximum bandwidth for a client is 30 concurrent MPEG-1
streams (near 45 Mb/s), and a video is split into several parts (usually 2 parts). The
length of each part is less than 60 minutes, and each part is considered as an integrated video. Clients who request a video longer than 60 minutes must send request
more than once. The time interval T for each request is 1 minute. Therefore, a video is
divided into 45~60 fixed size segments.
The popularity of each video was modeled using a Zipf-like distribution with parameter 0.271. This is the mostly used distribution for VoD studies. In our experiment, the number of videos stored on a video storage is 100. Client requests are generated using a Poisson arrival process with an interval time of 1/λ, for varying λ values, between 100 to 1400 arrivals per hour. Clients simply selected a video, waited for
their request to be served, and then watched the video until it was completed.
Video server and network are main components in VoD systems. For a video
server, we utilize Darwin-streaming server (http://www.apple.com), which can support 600-800 MPEG-1 unicast streams simultaneously. We also use 1000M Ethernet
to simulate the broadband network. Because the bandwidth for each NIC is 100Mb/s.
Figure 3 shows the main experimental environment parameters.
V i d e o le n g t h ( m in u t e s )
N u m b e r o f v id e o s

L

Nv

45~60
100

V id e o F o r m a t

M P E G -I

C l i e n t s ’ m a x i m u m b a n d w i d t h ( M b it s / s )

100

S e r v e r ’s m a x i m u m b a n d w i d t h ( M b i t s / s )
C l i e n t s a r r iv a l r a t e

(/h o u r )

1000
100~1400

Fig. 3. Experiment Parameters

4.2 Results
For a video server, there are two most important performance factors: start-up latency,
which is the amount of time clients must wait to watch the chosen videos; and average
bandwidth consumption, which indicates the bandwidth efficiency of a video server.

A Dynamically Grouped Multi-multicast Stream Scheduling Strategy

829

4.2.1 Start-up Latency

30
25
20

λ=100
λ=500
λ=800
λ=1400

15
10
5
0
0

200

400

600

800

Clients Number

Average start-up latency (seconds)

Average start-up latency (seconds)

Figure 4 displays the system average start-up latency at client request rates 100, 500,
800, 1400 per hour, and shows how these latencies are affected by the number of
served clients. We choose 100 to be the low request arrival rate, 500 and 800 to be the
middle request arrival rate, and 1400 to be the high request arrival rate. As one can
see, the system average start-up latency is changed very small under different request
arrival rate. It always remains on 25±5 seconds when there are enough clients’ requests arrived. This latency can be accepted by almost all clients.

200
180
160

DGMM
FCFS batch
with time interval
7 minutes
time-threshold stream
merging

140
120
100
80
60
40
20
0
0

200

400

600

800

1000

1200

1400

1600

Clients arrival rate (/hour)

Fig. 4. Request arrival rate vs. average the Fig. 5. A start-up latency comparison among
FCFS batching strategy with the time interval
start-up latency.
7 minutes, the time-threshold stream merging
strategy with parameter W=20 minutes and
unconstrained clients buffer, and the DGMM
strategy with time slot =1 minute

Figure 5 displays the start-up latency comparison among FCFS batching with time
interval T=7 minutes, the stream merging strategy with parameter W=20 minutes and
unconstrained client disk space and our DGMM. We choose 7 minutes because paper
[5] have presented that FCFS batching could obtain a good tradeoff between start-up
latency and bandwidth efficiency at this time interval. The same as to the stream
merging strategy, paper [8] have proposed a time-threshold stream merging strategy
and showed that the total performance was better than other traditional stream merging strategies when the time-threshold W was 20 minutes and the client storage disk
was unconstrained. As one can see, DGMM strategy outperforms the FCFS strategy
and just is little poorer than the time-threshold stream merging strategy in the aspect
of the system average start-up latency. The reason of little poor performance compared with the time-threshold stream merging strategy is that DGMM batches clients’
requests arrived at the same time slot. This will increase the bandwidth efficiency.
4.2.2 Bandwidth Consumption
Figure 6 shows how request arrival rate affects the average server bandwidth consumption. We can find out that the average server bandwidth consumption is increased in some degree with the increasing of request arrival rate. The reason is that

830

D. Deng, H. Jin, and Z. Han

240
220
200
180
160
140
120
100
80
60
40
20
0

λ=100
λ=500
λ=800
λ=1400

0

200

400

600

800

Server average bandwidth (Mbits/s)

Average bandwidth (Mbits/s)

server will support more clients at a period of time. As showed on Figure 7, when
request arrival rate is less than 150 requests per hour, the bandwidth consumption of
three kinds of scheduling strategies are held in same level. But by the increasing of
request arrival rate, the increasing degree of DGMM is distinctly less than FCFS
batching and the time-threshold stream merging strategy. When request arrival rate is
500, the average bandwidth consumption of DGMM is approximate 170Mb/s.

Clients Number

Fig. 6. Request arrival rate vs. average
Bandwidth.

450
400
350
300
250
200
150

GMM
FCFS batch
Time-threshold stream
merging.

100
50
0
0

200

400

600

800

1000 1200 1400 160

Client arrival rate (/hour)

Fig. 7. An average bandwidth comparison
among the FCFS batching strategy with time
interval 7 minutes, the time-threshold stream
merging strategy with parameter W=20 minutes and unconstrained clients buffer, and the
DGMM strategy with time slot =1 minute

At the same request arrival rate, the average bandwidth consumption of the FCFS
batching is approximate 320Mb/s and that of the time-threshold stream merging strategy is approximate 220Mb/s. At middle request arrival rate, DGMM can save approximate 45% and 23% bandwidth consumption compared with FCFS batching and
time-threshold stream merging strategy, respectively. When request arrival rate is
higher than 1000 requests per hour, the bandwidth performance of the time-threshold
stream merging strategy is decreased dramatically. It is worse than FCFS batching. In
any case, they are all worse than DGMM. (FCFS: approximate 380Mb/s; Timethreshold stream merging: approximate 400Mb/s; DGMM: 240Mb/s; at request rate:
1100 request per hour). Therefore, DGMM outperforms the FCFS batching strategy
and the stream merging strategy at the aspect of bandwidth performance.

5 Conclusions and Future Works
This paper presents a novel stream scheduling strategy that significantly reduces the
demand on the server network-I/O bandwidth. Unlike existing batching strategy and
stream merging strategy, DGMM dynamically groups the clients’ requests according
to the request arrival time and schedules two kinds of multicast stream: continuous
completely multicast stream and no-continuous patching multicast stream. This guarantees that no redundant video data are transmitted at the same time and the transmitting video data are shared among grouped clients. Furthermore, we give out an exam-

A Dynamically Grouped Multi-multicast Stream Scheduling Strategy

831

ple algorithm and study the performance of DGMM from start-up latency and bandwidth consumption.
Time interval T is an important issue in DGMM. It determines the number of
streams that can be concurrently received by a client. If T is too small, the number of
concurrently received streams may be increased dramatically. Therefore, the bandwidth of clients may be exhausted. But if T is too large, the start-up latency of clients
may be too long to be endured. In this paper, we simply choose 1 minute to be the
value of T because most clients can accept the start-up latency less than 1 minute and
current broadband network technology improves the bandwidth of client to 100Mb/s.
In the near future, we will study the effects of time interval T and propose an optimal
time interval T.

References
[1]

C. C. Aggarwal, J. L. Wolf, and P. S. Yu, “The Maximum Factor Queue Length Batching
Scheme for Video-on-Demand Systems”, IEEE Transactions on Computers, Vol.50,
No.2, pp.97–110, Feb. 2001.
[2] S. W. Cater and D. D. E. Long, “Improving video-on-demand server efficiency through
stream tapping”, Proc. of ICCCN, Las Vegas, NV, Sept. 1997, pp.200–207.
[3] S. W. Cater and D. D. E. Long, “Improving bandwidth efficiency on video-on-demand
servers”, Computer Networks, Vol.30, No.1-2, pp.99–111, Jan. 1999.
[4] S.-H. G. Chan and E. Chang, “Providing scalable on-demand interactive video services
by means of client buffering”, Proc. IEEE ICC, Helsinki, Finland, June 2001.
[5] J.-K. Chen and J.-L. C. Wu, “Heuristic batching policies for video-on-demand services”,
Computer Communications, Vol.22, pp.1198–1205, 1999.
[6] A. Dan, D. Sitaram, and P. Shahabuddin, “Dynamic batching policies for an on-demand
video server”, Multimedia Systems, Vol.4, pp.112–121, June 1996.
[7] D. Eager and J. Z. M. Vernon, “Bandwidth Skimming: A Technique for Cost-Effective
Video-on-Demand”, Proc. Multimedia Computing and Networking 2000, San Jose, CA,
January 2000.
[8] L. Gao and D. Towsely, “Threshold-based multicast for continuous media delivery”,
IEEE Transactions on Multimedia, Vol.3, No.4, pp.405–414, December 2001.
[9] S.-H. G. Chan and F. Tobagi, “Tradeoff between System Profit and User Delay/Loss in
Providing Near Video-on-Demand Service”, IEEE Transactions on Circuits and Systems
for Video Technology, Vol.11, No.8, Aug. 2001.
[10] K. A. Hua, Y. Cai, and S. Sheu, “Patching: A multicast technique for true video-ondemand services”, Proc. of ACM Multimedia, Sept. 1998.
[11] H. Shachnai and P. Yu, “Exploring Wait Tolerance in Effective Batching for Video-onDemand Scheduling”, Multimedia Systems, Vol.6, No.6, pp.382–394, 1998.
[12] S. Viswanathan and T. I. Metropolitan, “Video-on-demand service using pyramid broadcasting”, Multimedia Systems, Vol.4, No.4, pp.197–208, Aug. 1996.

