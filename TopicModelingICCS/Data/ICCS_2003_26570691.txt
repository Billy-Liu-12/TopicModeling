Romberg Integration: A Symbolic Approach
with Mathematica
Ali Yazıcı1 , Tanıl Ergen¸c2 , and Irfan Altas3
1

2

Computer Engineering Department, Atilim University, Ankara – Turkey
aliyazici@atilim.edu.tr
Mathematics Department, Middle East Technical University, Ankara – Turkey
tanil@metu.edu.tr
3
School of Information Studies, Wagga Wagga - Australia
ialtas@csu.edu.au

Abstract. Higher order approximations of an integral can be obtained
from lower order ones in a systematic way. For 1-D integrals Romberg
Integration is an example which is based upon the composite trapezoidal
rule and the well-known Euler-Maclaurin expansion of the error. In this
work, Mathematica is utilized to illustrate the method and the underlying theory in a symbolic fashion. This approach seems plausible for
discussing integration in a numerical computing laboratory environment.

1

Introduction

In the last decade, there has been a great interest in using technology in education. The authors of this paper have been involved in teaching with some
symbolic algebra packages such as Mathematica and Maple. Use of a symbolic
package in teaching mathematics has had a positive impact on student learning.
A student survey in a calculus course revealed that majority of students made
use of a symbolic package to verify their symbolic and numerical work, simplify
certain mathematical derivations, and, to some extent, set assistance in proving
simple theorems.
Here, an elegant numerical method, the so-called Romberg integration is considered to demonstrate the use and power of symbolic packages to convey various
ideas and concepts. Authors’ teaching experience has revealed that students feel
more comfortable with the underlying theory if the discussion is supported with
a symbolic code. This approach helps students in great extent to follow and verify
the mathematical derivations and theoretical justiﬁcations easily in a laboratory
environment.
In this work, Romberg integration is taken as a case study. This approach
may be applicable to similar numerical and mathematical techniques. Any symbolic package would serve the purposes of this study. However, because of its
popularity in symbolic computations, and availability in the authors’ environment, Mathematica was chosen.
In Section 2, the Romberg integration is summarized. Then, in Section 3
a Mathematica implementation is provided. Sections 4 and 5 demonstrate the
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2657, pp. 691–700, 2003.
c Springer-Verlag Berlin Heidelberg 2003

692

A. Yazıcı, T. Ergen¸c, and I. Altas

details of the method symbolically through a set of appropriate Mathematica
commands. A discussion about error is given in Section 6. In Section 7, a dynamic
implementation is provided followed by Section 8 where cautious extrapolation
for treating singularities is discussed. The ﬁnal section is devoted to a general
discussion and conclusions.

2

Romberg Integration

The Romberg method approximates the integral, I, below using the linear combinations of well-known trapezoidal sums Ti1 ’s in order to achieve higher orders.
b

I=

f (x)dx,
a

a, b ∈ R,

f ∈ C k [a, b]

(1)

The method is based on the Euler-Maclaurin asymptotic error expansion
formula and the Richardson extrapolation to the limit [1]. Romberg [2] has been
the ﬁrst to formulate the Richardson’s method for automatic calculations.
Each trapezoidal sum (of polynomial order 1) is deﬁned as


2i−1 −1
b−a
Ti1 =
f [a] + f [b] + 2
f [xj ]
(2)
2i
j=1
for i = 1, 2, ..., n (n maximum level of subdivision), xj = xo + jh, j = 1, 2, . . . , i
and h = (b − a)/2i−1 . Note that for the ith subdivision of the interval xo = a,
and xi = b. The computation starts with T11 on the interval [a, b], and T21 , T31 ,
and so on are computed by successively halving the interval and applying the
basic rule to each subinterval formed. In this subdivision process the Romberg
sequence {1, 2, 4, 8, . . . 2k , . . .} is utilized to bisect the interval. Other subdivision sequences are also possible [3]. However, Romberg sequence provides full
overlapping of the nodes of integration from one extrapolation level to another.
Obviously, as the number of subintervals increases, the accuracy of approximations to I improves.
The triangular Romberg table can be constructed using Tij values as
T11
T21
..
.

T22
.. ..
. .
Tn1 Tn2 Tn3

.. . .
.
.
Tn4 · · · Tnn

(3)

where Tij ’s are obtained from
j−1
4j−1 Tij−1 − Ti−1
=
, i = 2, 3, · · · , n and j = 2, 3, · · · , i
(4)
4j−1 − 1
It is well known that the entries in the second column of (3) are composite
Simpson approximations [4]. The third column entries are composite approximations based on the Newton interpolatory formulae. Since the ﬁrst column

Tij

Romberg Integration: A Symbolic Approach with Mathematica

693

entries are ﬁrst order approximations to I, trapezoidal sums are exact whenever
the integrand f (x) is linear in x. All diagonal sequences converge to I, provided
that the 1st column also converges as well [5]. Moreover, if column k is of order
p then the column k + 1 entries are of order p + 2. This could easily be justiﬁed
using the asymptotic error expansion formula (even in powers of h):
I − Ti1 = c1 h2 + c2 h4 + · · · + ck h2k + O(h2k+2 ),

h = (b − a)/2i−1

(5)

The ci ’s are constants (i.e. independent of h). Obviously, as h approaches to
zero, Tj1 converges to I. For singular integrals this expansion is not valid and it
takes diﬀerent forms depending on the nature of singularity [6].
The identities in (4) and (5) can be utilized to show that
I − T22 = I −

4T21 − T11
1
= − c2 h41 + O(h61 )
3
4

(6)

which demonstrates that error is of O[h4 ] and, hence, a speed-up in the
convergence to I.
In the next section, a Mathematica function is provided to verify the computations above in a symbolic computation environment.

3

Symbolic Romberg Integration

Symbolic packages are heavily used in engineering research and as an instructional tool in education (see for example [7], and [8])with an emphasis on computational aspects.
In a teaching environment, a symbolic code could be quite beneﬁcial to illustrate the diﬃcult concepts of a problem. For example, some of the theoretical aspects of the Romberg integration method, such as the justiﬁcation of the
asymptotic error expansion, and the discussion on the convergence may become
easy once the symbolic power is facilitated.
Many sophisticated library functions are available for numerical integration
(see for example Mathematica’s Integrate function). The main objective of this
study though, is to illustrate the details of a numerical technique by utilizing
the symbolic power provided by a symbolic software package.
For this purpose, a Mathematica 4.1 [9] function is given below to illustrate
the theoretical as well as computational properties of the method.
To study the non-numerical properties of the method, a static implementation (with a preset value of n) is given.
Romberg[f[ x ],{x , a , b } ,n ] :=
(h = b - a;
t[1] = 12 h(f [a] + f [b]);
romb[1,1]= t[1];
For m = 2, m ≤ n, m + +, k = m − 1; Do x[j] = a +

(j−i)h
, {j, 1, 2k
2k

+ 1} ;

694

A. Yazıcı, T. Ergen¸c, and I. Altas

t[m] = 12 t[m − 1] +

h

2(k−1)
j=1

f [x[2j]]

2k

;

For[m=2, m≤n, m++, romb [m,1]=t[ m]];
For [i = 2, i ≤ n, i + +,
j−1
For j = 2, j ≤ i, j + +romb[i, j] = 4 romb[i,j−1]−romb[i−1,j−1]
4j−1 −1

;)

The symbolic power of Mathematica now can be facilitated to study the
method for a symbolic function g over [a, b] by calling Romberg for, say, n = 10
levels of subdivision using Romberg[g[x], {x, a, b}, 10].

4

Experiments

A sample Mathematica 4.1 session is arranged to demonstrate the properties of
the Romberg integration for a general function g. The following input commands
are to be executed following the call to Romberg function.
– Set up the ﬁrst trapezoidal approximation t[1] to I over [a,b].
In[1]:=t[1]
1
2 (−a + b) (g[a] + g[b])
– Display the second approximation t[2] over 2 sub-intervals
In[2]:=Simplify [t[2]]
− 14 (a − b) g[a] + g[b] + 2g a+b
2
– Set up the composite trapezoidal rule t[3] over 4 sub-intervals.
In[3]:=t[3]
1 1
1
1
2 4 (−a + b)(g[a] + g[b]) + 2 (−a + b)g a + 2 (−a + b) +
1
1
3
4 (−a + b) g a + 4 (−a + b) + g a + 4 (−a + b)
– Simplify the expression
In[4]:=Simplify [%]
− 18 (a − b) g[a] + g[b] + 2 g

a+b
2

+g

1
4 (3a

+ b) + g

1
4 (a

+ 3b)

– Display a ﬁrst level extrapolation (Simpson’s rule over [a,b]).
In[5]:=Simplify[4t[2]-t[1])/3]
− 16 (a − b) g[a] + g[b] + 4g a+b
2
– Compare Out[5] with the value of romb[2,2].
In[6]:=Simplify[romb[2,2]]
− 16 (a − b) g[a] + g[b] + 4g a+b
2
– Display the value of romb[3,2] (Simpson’s rule applied to 2 sub-intervals)
In[7]:=Simplify [romb [3,2]]
1
− 12
4g 14 (3a + b) + 4g 14 (a + 3b)
(a − b) g[a] + g[b] + 2g a+b
2

Romberg Integration: A Symbolic Approach with Mathematica

695

– Display the value of romb[3,3] (ﬁrst entry in the third column of the
Romberg table). Observe that this is Newton’s interpolatory formula.
In[8]:=Simplify[romb [3,3]]
1
− 90
+ 8g 14 (3a + b) + 8g 14 (a + 3b)
(a − b) 7g[a] + 7g[b] + 4 3g a+b
2
– Compute the integral below by displaying romb[6,6]. Estimate the err(or)
by comparing the result with that of Mathematica’s Integrate (actual).
π
2

cos x dx = 2
0

In[9]:=f [x− ]:= Cos[x]
In[10]:=Romberg[f[x], {x, a, b}, 10]
In[11]:=romb [2,2]
1.00228
In[12]:=romb [4,4]
1.
In[13]:=actual=Integrate[Cos[x],{x,0, Pi/2}]
1
In[14]:=err=Abs[actual-romb[6,6]]
2.22045 × 10−16
– Trapezoidal rule is linear and, therefore, integrates linear polynomials exactly, and each Romberg column doubles the order. To investigate this let
f be xˆ7, over [0, 1/2], and observe that romb[4, j] is exact (1/2048 =
0.000488281).
In[15]:=f [x− ] := x7
In[16]:=a=0
In[17]:=b=0.5
In[18]:=Romberg[f[x],{x, a, b},4]
In[19]:=romb [4,3]
0.000488281 (exact!)

5

Justiﬁcation of the Method

Romberg extrapolation method is based upon the existence of the asymptotic
error expansion discussed in Section 2. Assuming the existence of such an
error expansion, Mathematica’s Sum, and Expansion functions can be used to
illustrate how the method works by symbolically deriving expressions for the
entries of the Romberg table. The commands written for this purpose are given
below:
In[20]:=Array [c,4]
{c[1], c[2], c[3], c[4]}
In[21]:=e[h− ] := Sum[c[i]hˆ(2i), {i, 1, 4}]
In[22]:=p = (4e[h/2] − e[h])/3

696

A. Yazıcı, T. Ergen¸c, and I. Altas
h2 c[1]
4

−h2 c[1] − h4 c[2] − h6 c[3] − h8 c[4] + 4
In[23]:=q=(4e[h/4]-e[h/2])/3
1
3

2

4

6

8

c[2]
c[3]
c[4]
− h 4c[1] − h 16
− h 64
− h256
+4
In[24]:=Expand [Simplify[p]]
5 6
8
− 14 h4 c[2] − 16
h c[3] − 21
64 h c[4]
In[25]:=Expand [Simplify [16q-p)/15]]
21h8 c[4]
1 6
64 h c[3] + 1024
1
3

h2 c[1]
16

+

+

h4 c[2]
16

h4 c[2]
256

+

+

h6 c[3]
64

h6 c[3]
4096

+

+

h8 c[4]
256

h8 c[4]
65536

The last two results show that the accuracy of the values in the second
and third columns of the Romberg table are of O(h4 ), and O(h6 ), respectively.

6

About the Error Term

Mathematica function Series can be used to verify the error term of the basic
Trapezoidal rule given by
E=−

h2
(b − a)h4 (4)
[f (b) − f (a)] +
f (µ),
12
720

µ [a, b]
a+h

In order to verify the error, consider S =
Sin[x]dx
a
−Cos[a + h] + Cos[a] and perform the following input commands:

(7)
=

In[26]:=f [x− ] := Sin[x]
In[27]:=Romberg[f[x],{x, a, a+h},6]
In[28]:=t[1]
1
2 h(Sin[a] + Sin[a + h])
In[29]:=s=Integrate[Sin[x], {x,a,a+h}]
Cos[a]-Cos[a+h]
In[30]:=e=Series[s-t[1], {h, 0, 3}]
1
3
4
12 Sin[a]h + O[h]
In[31]:=terror=-hˆ2/12(Cos[a+h]-Cos[a])
1 2
− 12
h (−Cos[a] + Cos[a + h])
In[32]:=Series [terror, {h,0,3}]
1
3
4
12 Sin[a]h + O[h]
Observe that error expression above is identical with the dominant term of
the error formula (7).

7

Computational Complexity of Romberg Integration

The complexity of any numerical integration algorithm is mainly depicted by
the number of function evaluations at the nodes of integration. In Romberg
integration, from level i-1 to i, 2i additional integrand evaluations are required.
In higher dimensions, this causes too many function evaluations, and the method

Romberg Integration: A Symbolic Approach with Mathematica

697

becomes computationally ineﬃcient. A dynamic implementation minimizes the
cost of the algorithm. That is, at each level, rows of the table are completed by
the Romberg formula and an error test is performed to check the accuracy of
the diagonal value romb[i, i]. Once the error criteria is satisﬁed, the algorithm
terminates avoiding further subdivisions and function evaluations. The dynamic
implementation is given below:
DRomberg[f [x− ], {x− , a− , b− }, n− , tol− ] :=



h = b − a; array[t, n]; Array[r, {n, n}];
t[1] = N 12 h(f [a] + f [b]) ;
feval=2;romb[1,1]=t[1];
relerr=1.;i=2;
While[relerr ≥ tol && i < n ,
k = i − 1;
, {j, 1, 2k + 1} ;
Do x[j] = a + (j−1)h
2k
t[i] = N

1
2 t[i

− 1] +

h

2k−1
j=1

2k

f [x[2j]]

;

romb[i, 1] = t[i];
f eval = f eval + 2k−1 ;
F or [j = 2, j ≤ i, j + +,
j−1
romb[i, j] = N 4 romb[i,j−1]−romb[i−1,j−1]
;;
4j−1 −1
relerr = N Abs

romb[i,i]−romb[i−1,i−1]
romb[i,i]

P rint[”i = ”, i, ”, Romberg diagonal element = ”,
romb[i, i], ”rel.err.est = ”, relerr];
i + +]


P rint[”N umberof f unct.evalf = ”, f eval]; 


Here, n is the maximum level possible, and tol is the user-deﬁned error
tolerance. A sample run and its output are given for the integration of ecosx ,
over [0, 2] with the error tolerance value= 0.00001 (exact value= 3.454359).
In[1]:=f [x− ] := Exp[Cos[x]]
In[2]:=DRomberg[f[x],{x, 0, 2}, 10, 0.00001]
i=2, Romberg diagonal element=3.41466, rel. err. est.=0.0107744
i=3, Romberg diagonal element=3.4567, rel. err. est.=0.0121627
i=4, Romberg diagonal element=3.45432, rel. err. est.=0.000688374
i=5, Romberg diagonal element=3.45436, rel. err. est.=9.83452x10−6
Number of funct. eval f = 17

8

Cautious Extrapolation

The basic assumption in the preceding discussion is the existence of the error
expansion given by (5). If such an expansion is not valid (for end point singu-

698

A. Yazıcı, T. Ergen¸c, and I. Altas

larities, and singularities in the derivatives of f) then Romberg fails to provide
the required accuracy or diverges. Singularities can be detected dynamically by
providing a control over the values of the Romberg table. This process is known
as cautious extrapolation [10] and described brieﬂy in the sequel. Deﬁne,
d [i, j] = romb [i, j] − romb [i − 1, j] ,

i = 2, 3, . . .

and

j = 1, 2, . . . , i

(8)

Assuming that the error expansion given by (5) holds, one obtains romb[i, j]
values satisfying the equations below:
 2(j+1)

h

I − romb [i, j] = Cj+1 
+O(h2(j+2) )
 i


2 

(9)

where Cj ’s are constants (i.e. independent of h). Using (8) and (9) and after
some algebraic manipulations one obtains
 2j

2j




h
h





d [i, j − 1] = Cj 
 i
 −Cj 

 +O(h2(j+1) )



i−1
2
2 
= Cj h2j (1 − 4j ) · 4−ij + O(h2(j+1) )

(10)

and
d [i − 1, j − 1] = Cj h2j (1 − 4j ) · 4−(i−1)j + O(h2(j+1) )

(11)

Therefore, as j (depth of extrapolation) increases, one gets
4−(i−1)j
d [i − 1, j − 1]
→
= 4j
d [i, j − 1]
4−ji

(12)

Consequently, before computing a new Romberg column, one should ﬁrst
check whether the ratio above approximates 4j or not. A typical test condition
can be speciﬁed as
d [i − 1, j − 1]
− 4j ≤ tol · 4j
d [i, j − 1]

(13)

where tol is the user speciﬁed tolerance value, say 0.1 for one digit accuracy, in
the ratio.
Again, the symbolic power of Mathematica is used to verify the cautious
extrapolation. Consider the following Mathematica call to display one of the
ﬁrst column diﬀerences (i = 1) for a symbolic function f [x− ] := g[x].
In[3]:=Print[Simplify[(romb[2,1]-romb[1,1])/(romb[3,1]-romb[2,1])]]
2(g[a]+g[b]−2g [ a+b
2 ])
1 (3a+b) −2g 1 (a+3b)
g[a]+g[b]+2g [ a+b
−2g
]
[
] [4
]
2
4

Romberg Integration: A Symbolic Approach with Mathematica

699

Using a series expansion around (a-b) and taking into account the ﬁrst 2
terms, one obtains
2(g[a]+g[b]−2g [ a+b
2 ])

In[4]:=Simplif y[Series[ g[a]+g[b]+2g
4−

g

(4)

[b](a−b)
16g [b]

2

1
1
[ a+b
2 ]−2g [ 4 (3a+b)]−2g [ 4 (a+3b)]

, {a, b, 2}]]

+ O[a − b]3

Observe that the ﬁrst term of the expansion is 4ˆ1 as expected. For the
second column diﬀerences (i = 2) the expected value of the ratio is 4ˆ2 = 16
ignoring the other terms of expansion. This is illustrated below:
In[5]:=Simplif y[Series[ romb[3,2]−romb[2,2]
romb[4,2]−romb[3,2] , {a, b, 2}]]
16 −

3g (6) [b](a−b)2
8g (4) [b]

+ O[a − b]3

To show the same numerically, the integrand f [x− ] := xˆ4 over [0, 1] is considered, and a call to Romberg is made. The ﬁrst 2 column diﬀerences are computed
to be 3.90551 and 16 respectively. The ﬁrst diﬀerence is close to 4, whereas the
second diﬀerence is 16 as expected (since for this function ﬁfth (and higher order)
derivatives are zero).
The second test involves integration of a function with derivatives that
vary greatly in magnitude, f [x− ] := 1/ |x| over [−9, 10000]. The diﬀerences
(2.10058, 2.13913, and 2.14663) are computed for the ﬁrst three columns of the
table respectively (i = 1, 2, and 3). Obviously, these values are considerably far
from the expected ones because of the singularity. In this case, Romberg method
should work cautiously to produce an accurate result since the ﬁrst term in the
error expansion formula is no longer h2 . Exact value of the integral is 206, and
romb[10, 10] = 200.566 displaying slow convergence.
Now, consider an integral where f has an end-point singularity.
1

I=
0

cos x
√ dx
x

(14)

Since f(x) is not deﬁned at x=0, the Romberg algorithm terminates with
the following error message.
Power::infy : Infinite expression 1/0 encountered.
In order to estimate this integral accurately, one alternative would be to pick
a small positive number, a, and compute the following integral to obtain an
approximate value
1

I=
a

cos x
√ dx
x

(15)

Using the Romberg function with a=0.000001 one gets romb[4,4]=39.6507 as the
integral value whereas the real value of the integral is 1.809048476. Although

700

A. Yazıcı, T. Ergen¸c, and I. Altas

the integral is continuous and bounded in the interval [0.000001,1], the diﬃculty
arises from large variations in values of the integrand near the lower end of the
integral. This erratic behavior is due to large variations in derivatives. One way
to remedy this deﬁciency is to introduce more subdivisions of the interval. For
example, for the same integral, values of romb[11,11] and romb[16,16] are 2.06852
and 1.81138, respectively providing better approximations to the integral.
Each singularity requires a special attention. In this particular case, one may
use the substitution, t = x0.5 to transform the integral to a nicely behaving one.
1

2 cos t2 dt

I=

(16)

0

9

Conclusions

In this article, Romberg integration method is considered as a case study in
order to present a highly technical method in a simpliﬁed manner by facilitating
Mathematica. The concepts and the methodology adopted here can be easily
applied to numerical diﬀerentiation, interpolation, and approximation among
the many others.
Although the presentation does not involve any rigorous proofs at all, some
hints are automatically provided by the symbolic derivations and justiﬁcations.
For the treatment of singularities, cautious extrapolation is also discussed
and illustrated symbolically and numerically. As an ongoing research project the
authors are investigating singular integrals using Mathematica. The results from
this project will be reported elsewhere.

References
1. Joyce, D.C.: Survey of Extrapolation Processes in Numerical Analysis, SIAM Review, 13, 4 (1971) 435–490.
2. Romberg. W.: Vereinfachte Numerische Integration, Kgl. Nordske Vid. Selsk. Forh,
bf 28 (1955) 30–36.
3. Yazıcı, A.: On the Subdivision Sequences of Extrapolation Method of Quadrature,
METU Journal of Pure and Applied Sciences, 23, 1 (1990) 35–51.
4. Burden, R.L. and Faires, J.D.: Numerical Analysis, 3rd. Ed., PWS Publishers
(1985).
5. Kelch, R.: Numerical Quadrature by Extrapolation with Automatic Result Veriﬁcation, in Scientiﬁc Computing with Automatic result Veriﬁcation, Academic
Press, Inc. (1993) 143–185.
6. Lyness, J.N. and Mc Hugh, B.J.J.: On the Remainder Term in the N-Dimensional
Euler-Maclaurin Expansion, Num.Math., 15 (1970) 333–344.
7. Skeel, R.D. and Keiper, J.B.: Elementary Numerical Computing with Mathematica, McGraw-Hill (1993).
8. Mathews, J.H. and Fink, K.D.: Numerical Methods Using Matlab, 3rd Edition,
Prentice Hall (1999).
9. Wolfram, S.: The Mathematica Book, Cambridge University Press (1999).
10. Johnston, R.L.: Numerical Methods: A Software Approach, John Wiley and Sons
(1982).

