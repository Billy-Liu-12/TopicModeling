Some Architectural Features
of Ada Systems Affecting Defects
William M. Evanco and June Verner
Drexel University, 3141 Chestnut Street
Philadelphia, PA 19104
{William.Evanco,June.Verner@cis.drexel.edu}

Abstract. In this study, we discuss some software architecture tradeoffs for
Ada83 systems. External and internal complexities are specified for Ada packages and these complexities are related to the numbers of defects uncovered
during testing using a non-linear model based on the negative binomial probability distribution. The non-linear associations among the software measures
that we investigate are exploited to identify optimal relationships between context coupling and the number of visible declarations. The data we used to develop our model consists of Ada package characteristics from four software
systems. Some of the packages are reused from previous projects and nondefect changes may have been made to these packages during the software development process. Therefore, in our defect model, we controlled for these two
factors. For the 262 packages that we considered, our research shows that with
respect to software defects there is too much context coupling, indicating that
the architecture is far from optimum. If less of the workload were delegated to
other packages and instead implemented within the package through hidden
declarations, then context coupling might be reduced.

1

Introduction

Interest in improving the quality of software systems has led to numerous studies
analyzing the relationships between software quality outcomes and the complexity
characteristics of software [1,2,3]. One indicator of software system quality is its reliability as measured by the number of defects in its constituent components. By relating the number of defects to software complexity characteristics such as module
cohesion and coupling, we can get an early indication of the software’s quality.
A software designer must make decisions regarding system partitioning and this
partitioning impacts both component composition and coupling. Software quality attributes such as reliability and maintainability are influenced by the precise arrangement of components and their coupling [4]. Designers may choose to build systems
with large components having relatively little coupling, small components that are
extensively coupled to each other or something between these two extremes.
Although we have been told that modules should be constructed to exhibit high
cohesion and low coupling [5], such qualitative statements provide no real guidance
as to how low the coupling should be, nor what level of cohesion we should try to
achieve. There is substantial evidence that highly coupled systems exhibit more defects [6]. On the other hand, the concept of cohesion is problematic. While high cohesion appears, at face value, to be a desirable trait for modules, there are both theoJ.-P. Rosen and A. Strohmeier (Eds.): Ada-Europe 2003, LNCS 2655, pp. 232−245, 2003.
 Springer-Verlag Berlin Heidelberg 2003

Some Architectural Features of Ada Systems Affecting Defects

233

retical and empirical problems with the concept of cohesion. Cohesion tends to be
strongly related to the semantics of the problem domain and, for the most part, seems
to defy easy definition and measurement [7]. Moreover, cohesion measures that have
been developed appear thus far not to have a consistently significant relationship to
defects in software [6]. Consequently, the idea of cohesion may be a less useful concept in terms of providing guidance for making software architecture decisions.
Much effort has been devoted to identifying and quantifying the characteristics
of software components that may contribute to low system reliability as measured by
defect counts. These characteristics are then related to software defects through models that are estimated by various means. Because the mechanisms underlying the
generation of software defects are not well understood, exact models cannot be
specified on the basis of theory. We rely on empirically estimated defect models that
incorporate these characteristics as explanatory variables and provide an approximation to the exact models over a range of the explanatory variables. The resulting
models generally focus on the quality attributes of reliability, as measured by faults
or defect counts [1–3], and maintainability, as measured by the efforts to repair or
change software [8,9].
Deciding upon the “best” partitioning of a software system requires models relating software quality outcomes to measurable characteristics of a software system
that can be obtained during the design stage of software development. With appropriate models, one can examine tradeoffs among the measurable characteristics and
select those characteristics to optimize one or more quality outcomes. Many models
have been proposed relating software characteristics to quality outcomes [2,3,10].
Some of these models are based on statistical techniques such as multivariate regression analysis. Multivariate regression techniques are then used to determine the values of the parameters associated with each of the linear terms. Once we have such a
model, it can be used to predict a quality factor associated with a new project based
on its software characteristics. The advantage of such models is that the software
characteristics are generally known long before the software quality factors.
However, as a general rule, these linear models do not lend themselves to an examination of optimal software components. Linear models are monotonic in their
behaviors with respect to the explanatory variables and these variables are not linked
in any way that would allow for an examination of tradeoffs. A greater value of some
software characteristic, such as cyclomatic complexity for example, leads to a greater
expected number of defects. In linear models, cyclomatic complexity is not coupled
to nesting depth or to the call structure, for example, so that tradeoffs cannot be examined among these independent variables with regard to their impacts on defects.
Other modeling approaches use pattern recognition [2], neural networks [11],
genetic algorithms [12], and Bayesian Belief Networks [13]. These approaches,
though oriented toward the identification of defect-prone modules, are nonparametric and obscure explicit functional relationships between characteristics and
outcomes. For example, a major drawback of neural network approaches is that
analysis results, expressed in terms of neuron weights, cannot be interpreted in simple terms that are related to the initial software measures. Analyses using genetic algorithms focus on the use of software characteristic variables to predict defects, but
there has been little concern about the statistical significance of these variables. In
addition, the emphasis of these approaches on “defect-proneness” (a binary variable)
as an outcome variable, rather than a more disaggregated measure such as the actual

234

W.M. Evanco and J. Verner

number of defects, leads to a relative insensitivity of the outcome variable to changes
in the software characteristics.
In this study, we attempt to extend our previous work [14] to object-based programming languages such as Ada83, which support the specification of objects but
do not support inheritance relationships. In the next section, we discuss the problem
statement. In Sect. 3, the methodology used to attack the problem, based on nonlinear regression modeling, is presented. In Sect. 4, the model variables and empirical data are discussed. In Sect. 5 we present the empirical results, while Section 6 includes the discussion and conclusions.

2

Problem Statement

Ada packages encapsulate logically related entities and computational resources. Entities may be objects or types while computational resources are subprograms or
tasks. The package consists of a specification, identifying the visible declarations of
entities and computational resources, and a body, implementing the details of the
package1. The implementation details are hidden from the package user. Context
clausing (i.e., a “with” statement) allows the visible declarations to be exported to
(imported by) other program units such as subprograms, packages, tasks, or generic
units.
Some of the details of the visible declarations in the package specification may
be implemented within the corresponding package body, while other implementation
details are deferred by the use of context clausing. Thus, for example, using algorithmic and control statements, parts of a visible procedure may be elaborated in the
procedure body, which is encapsulated in the package body. The implementation of
other parts of the procedure may be deferred by calling subprograms that are imported from other packages. In this study, we define and measure two top-level features of system architecture, namely, the external complexity of packages as indicated by their coupling to other packages and their internal complexity as indicated
by their “workload.” We then consider the tradeoffs that may exist between internal
complexity and external complexity. As noted earlier we may reduce the internal
complexity of a package by increasing its external complexity and, conversely, we
might reduce external complexity, but at the expense of increasing internal complexity.
This situation is similar to that expressed in Card and Agresti [15] and Evanco
and Verner [14] for procedural languages in which one can defer the implementation
details of a subroutine or function through call statements. By establishing the impact
of both internal and external complexity on software defects, one can identify the optimal call structure given that a subroutine has a certain level of input/output data
[15] or unique operands [14]. Similarly, for the case of Ada packages, we can pose
the question: Given the visible declarations of a package, is there an optimal relationship between internal and external complexity such that the number of defects
will be minimized?

1

Subunits may also be specified to implement details outside the package body.

Some Architectural Features of Ada Systems Affecting Defects

235

A long-standing belief in the software metrics literature – one supported by empirical evidence – is that software defects uncovered during the testing process occur
more frequently for software components that are more complex [10]. Software
complexity begins to reveal itself during the design phase and the subsequent coding
phase [1]. Thus, if models for defect counts are developed during the design or implementation phases prior to testing, one may be able to analyze tradeoffs among design parameters so as to optimize some quality factor.
Software complexity has been defined differently by different authors. What has
come to be commonly believed is that software complexity cannot be specified by a
single software characteristic measure [1,16]. Rather, software complexity is a multidimensional concept and different facets of complexity are measured by different
complexity metrics. We focus, in this study, on two complexity factors, related to internal and external complexity, which can easily be collected during top-level design.
In addition to software complexity, other features of software or its development
environment may affect software defects [1]. We can view these features as contributing to a more general complexity that is related to defects. For example, a software
component that is reused verbatim from a reuse library or from another project may
be viewed as less complex than one that is newly created. The component has been
tested and used previously and should have far fewer defects than a newly constructed component. In addition, the reuse of a component may only require the staff
to understand its required inputs and the delivered outputs, rather than its internals.
Another factor that may contribute to complexity is the number of non-defect
changes made to a component either to adapt a reused component for a new system
or to add new features or requirements during the testing phase. Such changes generally are unanticipated and may result in greater software complexity. An initial design may not easily accommodate these changes, leading to a convoluted design or
code. In addition, the number of non-defect changes may be viewed as indicative of
a more complex development environment in which requirements not well-specified
initially force adjustments later in the project.

3

Methodology

In this study, we restrict ourselves to the analysis of Ada packages consisting of a
specification, body, and possible subunits. Thus, the Ada packages will all involve
subprograms and those Ada packages consisting only of named collections of declarations will not be considered.
A small software component such as a package may consist of a relatively small
number of source lines of code. Some packages have zero defects while others have
only small numbers of defects. Thus, in any sort of analysis that we might perform,
the defect count should be treated as a discrete countable variable and appropriate
analytical methods must be identified for our model building exercise. Previous efforts in this area have utilized Poisson regression models [17]. However, a drawback
of Poisson models is that the standard deviation is required to be equal to the mean.
Consequently, Poisson models may be inappropriate for data exhibiting overdispersion—when the variance of the defect counts is greater than its mean [18]. In
such a case, the standard errors associated with the parameter estimates may be
overly optimistic (too small) and the chance of including insignificant variables will
increase. In the case of under-dispersion, we would expect the standard errors asso-

236

W.M. Evanco and J. Verner

ciated with the parameter estimates to be larger than their true values yielding pessimistic estimates.
In order to deal with this problem, we propose a count model based on a negative binomial statistical distribution, which treats the variance as a quadratic function
of the mean, with a dispersion parameter that is estimated on the basis of the empirical data. Negative binomial count models have been discussed extensively in the statistical literature [18] and applied to the analysis of software defects [19]. The methodology allows us to determine the expected number of defects in a package. A major difference between this study and another by Evanco [19] is that in this study we
focus on non-linear models that can be used for prescriptive purposes.
The negative binomial regression model specifies that the number of defects, ni, for
subprogram i is drawn from a negative binomial distribution with parameters λi and θ.

f (ni | X i ) =

Γ(θ + ni )
sini (1 − si )θ
Γ(ni + 1))Γ(θ )

(1)

where Γ(.) is the gamma function and

si =

λi

(2)

λi + θ

The mean of the negative binomial distribution is given by λi and its variance by
λi(1+λi/θ) where θ is a parameter measuring the extent of dispersion2. The parameter, λi, is interpreted as the expected number of defects in subprogram i and is related
to the vector of characteristics, Xi, that influence the number of defects by
ln(λi) = β’Xi

(3)

where “ln” represents the natural logarithm, β is a column vector of parameters to be
estimated (the prime represents its transpose), and Xi is a column vector of explanatory variables. The column vector Xi may include basic characteristics of subprograms or higher order terms in these characteristics (e.g., quadratic terms). In this
study, we keep up to quadratic terms, specifying the natural logarithm of the expected number of defects by
n

ln( λ i ) = a 0 +

∑
i =1

aixi +

1
2

n

n

∑∑ γ x x

ij i j

( 4)

i =1 j =1

where the ai (i=0, 1, …, n) and the γij (i,j=0, 1, …,n) with γij =γji are the parameters to
be estimated. This functional form is better able to model more of the non-linearity
in the explanatory variables and may provide a better fit to the data. As is usual with
any regression analysis, the validity of the model is constrained to within the range
of values of the explanatory variables used to estimate its parameters. For example, if
our collection of packages used to calibrate the model ranged between 20 and 200
2

For very large θ, the mean λ is approximately equal to the variance and a Poisson model
would apply.

Some Architectural Features of Ada Systems Affecting Defects

237

source lines of code, we would not expect the model to be applicable for predicting
the defects of a package with 500 source lines of code.
The parameters, ai, i=1,…,n, and the γij, i,j=1, 2,…,n are estimated based on
maximum likelihood estimates using the GENMOD procedure of the Statistical
Analysis System (SAS). The GENMOD procedure allows the use of both Poisson
and negative binomial probability distributions when one has a dependent variable,
such as the number of defects, which is based on count data.

4

Model Variables and Empirical Data

As noted earlier, in this study, we focus on the analysis of defects in Ada packages
having a specification, a body, and possible subunits; we will regard this component
group as a “package.”
4.1

Model Variables

Software architectural decisions occurring during top-level architectural design affect the complexity of the resulting software. We can represent the various facets of
this complexity by measures. Moreover, these measures can be collected by automated means using a software analyzer if the top-level design representation is available in compilable form. Then, if we have a model that relates these measures to
software development outcomes such as the number of defects in packages, we can
predict these numbers based on early architectural characteristics. Similarly, if we
know the relationships between the different facets of software complexity and the
numbers of expected defects, then we may be able to identify architectural characteristics of the software that may minimize the numbers of defects.
The number and types of visible declarations contained in a package are determined by design considerations. For example, a problem domain may be partitioned
into objects that represent the conceptual view of that domain. Those objects are defined in terms of their internal content and their relationships to the rest of the problem domain. There is some flexibility, however, in the level of disaggregation that a
designer chooses when objects are specified. For example, a house may be defined as
an object and implemented at that level, or the individual rooms within a house may
be defined as objects. Thus, a designer may be able to influence the quality of software as measured by the numbers of defects by paying attention to the granularity of
the objects that are defined during the partitioning process.
During top level design, the visible declarations in a package specification are
identified. These declarations can be exported to and used by other packages. The
declarations can be either data or program unit related. The details of the visible declarations may be implemented, in part, within the body of the package and are not
visible to other packages. These details may include hidden subprograms, tasks, and
data declarations. Thus, the number of visible declarations, denoted by X, implies a
workload for the package that is reflected in the package body.
While some of the details associated with the visible declarations may be implemented in the corresponding body, other implementation details may be delegated
or deferred to other packages by the use of context clauses (“with” statements). A
context clause allows a package to import the visible declarations of another package

238

W.M. Evanco and J. Verner

and to use these declarations in the implementation of its body. Thus, part of the
workload implied by the visible declarations of a library package can be implemented within its body while another part can be delegated to the resources of other
packages. The number of unique “with” statements for a package3, denoted by W, is
a measure of the external complexity of the package.
This external complexity measure was first proposed by Agresti and Evanco [1]
and is comparable to the coupling between object (CBO) metric proposed by
Chidamber and Kemerer [20] and the coupling factor (COF) proposed by Abreu et
al. [21]. The CBO metric makes no distinction between import and export coupling
in the sense that two classes are coupled if one uses the other or vice versa. The COF
metric does distinguish between the two cases. The context coupling measure used in
this study is concerned only with import coupling where a package uses the resources of another package. Like the COF and CBO measures, the context coupling
measure does not distinguish among actual method invocations and attribute references in a package.
We expect the internal complexity of a package to increase as the number of
visible declarations increases if the workload associated with the visible declarations
is implemented within the package body. However, insofar as the workload associated with the visible declarations is deferred to other packages through object coupling, the internal complexity of a package is reduced. This reduction of internal
complexity is made at the cost of increasing the external complexity through object
coupling. We take as a measure of internal complexity the ratio X/W–reflecting the
fact that external complexity is increased as the number of visible declarations is increased and is decreased as the object coupling increases, deferring the workload to
other objects. To avoid a singularity, when W=0, we set X/W=0 in our data.
This approach to external and internal complexity is similar to that of Card and
Agresti [15]. They defined these complexities for procedural languages such as
FORTRAN. The fan-out of a module measures the number of calls that the module
makes to other modules and is regarded as a measure of external complexity. The
number of I/O variables divided by the fan-out is a measure of the internal complexity. Similar to our situation, the I/O variables represent a workload for a module.
This workload can either be implemented within the module or deferred to other
modules by means of call statements.
Our data for the Ada packages is heterogeneous. The constituents of packages
may have been reused from previous projects. For example, an Ada package may
contain both subprograms that are newly developed and ones which are reused. In
addition, packages experience different levels of non-defect changes throughout the
development process, reflecting requirements changes. These two factors may be expected to influence the numbers of defects and may interact in non-linear ways with
the architectural characteristic variables discussed above. Therefore, we include them
in our analysis as discussed below.
Each component of a package (i.e., specification, body, subunits) is characterized by its origin. A component may be: newly developed, reused with extensive
3

A package may be “withed” into another package at the specification or body level. We
make no distinction between the two cases in the count of “with” statements. However, if a
package is “withed into both the specification and body of another package, then this increases the number of unique “with” statements by unity.

Some Architectural Features of Ada Systems Affecting Defects

239

modifications (>25% of source lines of code changed), reused with slight modification (<25% of source lines of code changed), or reused verbatim (i.e., no changes)4.
We compute the fraction of source lines of code in a package that are newly developed or reused with extensive modifications, denoted by FNEM. Components that
are newly developed or reused with extensive modifications have been shown to exhibit substantially more defects than components that are reused with slight modifications or reused verbatim [10]. Thus, FNEM can be viewed as a measure of complexity contributing to the presence of defects.
The number of non-defect changes made to a package, denoted by CHG, also
contributes to the composite complexity and to the number of defects. The changes
made to adapt reused components for use in a new project are not included in the
CHG number. The expected value of the number of defects, l, is thus regarded as a
function of W, X/W, FNEM, and CHG given by f(W, X/W, FNEM, CHG).
The functional form of the expected defect number is not known on a priori
theoretical grounds. Typically, linear regression models are proposed which effectively are Taylor expansions of some unknown functional form where only the lowest order (linear) terms are kept. The unknown parameters associated with the linear
terms are then estimated by, for example, a least squares approach. However, in order to explore potential non-linear behaviors (and potential tradeoffs among the architectural variables), we Taylor expand the composite complexity, keeping up to
quadratic terms, as follows:
f(W, X/W, FNEM, CHG) = a0 + a1*W + a2*(X/W) + a3*FNEM + a4*CHG
+ b11*W2 + b22*(X/W)2 + b33*FNEM2 + b44*CHG2
+ b12*W*(X/W) + b13*W*FNEM + b14*W*CHG
+ b23*(X/W)*FNEM + b24*(X/W)*CHG
+ b34*FNEM*CHG
4.2

(5)

Empirical Data

Data from four Ada projects developed at the Software Engineering Laboratory of
the NASA Goddard Space Flight Center are used in this study. The application domains were flight telemetry and dynamic simulations. The four projects yielded a total of 262 packages, which are the units of observation in the statistical analysis. The
software data were obtained using the Ada Source Analyzer Program (ASAP) [22] to
extract raw data from the code from which the measures were then derived. The
means and standard deviations (in parentheses) of relevant variables characterizing
the Ada packages are shown in Table 1 for each of the four projects.
Across all projects, the mean number of source lines of code (SLOC) per Ada
package was 575 ranging from about 400 to 761 across the four projects. These
SLOC supported an average of about 34 visible declarations for all projects, ranging
from about 24 to 43 visible declarations per package across the projects. To support
the implementation of a package, there was an average of almost 8 context clauses
(unique “with” statements) across all projects, ranging from 6.4 to 9.1 context
clauses within individual projects. The exports per “with” statement averaged 9.2
4

This particular classification was used because the component origin data was provided to
us in this form only.

240

W.M. Evanco and J. Verner

across all of the projects and ranged from 7.5 to 10 within the projects. The fraction
of new and extensively modified code had a mean of .46 for all of the projects and
ranged between .04 and .66 across the projects. There was an average of 3.9 changes
per package ranging from .19 changes to 7.2 changes per package across the projects. The low of .19 changes per package for Project D was due to the heavy reuse
of components in this project. The mean number of defects per package found during
unit, system, and acceptance testing was 2.4 ranging from .08 to 4.2 among the projects. The defects are highly correlated with the value of FNEM.

Table 1. Statistical characteristics of packages

5

Analysis Results

In the statistical analysis of this section, we estimate the various coefficients of the
model presented in (5). Not all of the coefficients may be statistically significant, so
in such cases the associated terms are dropped from the analysis. The next subsection
discusses the statistical results and in Sect. 5.2, we use the resulting equations for
prescriptive analyses.
5.1

Statistical Analysis

The maximum likelihood estimates of the parameters, obtained from the GENMOD
procedure of the SAS statistical analysis system, are shown in Table 2. The model
keeps only the linear and quadratic terms as shown in the expansion (5) that are statistically significant. The numbers in parentheses are the standard errors associated

Some Architectural Features of Ada Systems Affecting Defects

241

with the coefficient estimates. The coefficient estimates are all statistically significant at the 1% level with the exception of XPW, which is significant at the 5% level.
The coefficients of the expected number of defects are all positive implying that as
internal complexity (X/W) and external complexity (W) increase so does the expected number of defects. Similarly, the larger the fraction of new and extensively
modified reused code in a package and the more changes made to the package, the
greater the expected number of defects.
The coefficient of determination, R2, indicates that 71% of the variation is explained by the four variables introduced into the analysis. For the kind of micro-data
being considered (i.e., Ada packages), this is a relatively large value. Finally, a significant value of the dispersion parameter of .34 indicates that our data exhibits substantial over-dispersion and that we were justified in using a count model based on
the negative binomial probability distribution rather than the Poisson distribution.

Table 2. Negative binomial model results

5.2

Coefficient

Parameter Estimates

Constant
X/W
W
(X/W)2
W2
FNEM
FNEM2
CHG
CHG2
FNEM*W
__________________
Dispersion
R2

-1.82 (.28)
.03 (.009)
.07 (.02)
-.0001 (.00004)
-.0014 (.0004)
5.99 (1.05)
-4.71 (.96)
.08 (.01)
-.0008 (.0002)
.04 (.02)
__________
.34 (.11)
.71

Prescriptive Analyses

Using the results of these analyses, we can now pose prescriptive questions regarding
tradeoffs between internal and external complexity and the impact of these tradeoffs
on package defects. Given that the number of visible declarations in a package is
governed by object-based principles for decomposing a problem space into objects,
for analysis purposes we regard this number


dλ
X
X2
= λ * .077 − .034 * 2 − .0028 * W + .0002 * 3 + .039 * FNEM
dW
W
W



as a parameter.
The first derivative of the expected number of defects, λ, is given b.

(6)

242

W.M. Evanco and J. Verner

Setting this derivative equal to zero and solving numerically for W given a specific X value provides us with a critical point of the function for λ. The second derivative of function, λ, at the critical point is given by:

The second derivative is positive for values of X and W, so that the function, λ, is a
minimum for these values. Note that the value of FNEM affects our results, but the
number of non-defect changes represented by C does not because C enters into equation (5) only linearly.
The plot of W vs. X giving minimum values of expected defects is shown in
Fig. 1 for FNEM=1. Since W is an integer value, when dealing with specific packages, we must round to the nearest integer when using this plot to estimate the value
of W, yielding the minimum expected defects for a package with X visible declarations. The integer-rounded W values are shown in Figure 1 for different ranges of X.
For example, for a package with 15 visible declarations, the optimum W=2. The optimum number of “with” statements rises with the number of visible declarations.
For an average package having about 34 visible declarations, the optimum number of
“with” statements is three, while for ninety visible declarations, the optimal value is
five “with” statements.

Fig. 1. Optimal context clausing vs. visibile declarations, FNEM=1

Some Architectural Features of Ada Systems Affecting Defects

243

Fig. 2. Optimal context clausing vs. visible declarations, FNEM=0

Figure 2 shows the results of equivalent calculations for FNEM=0 (i.e., the
package contains new and extensively modified reused code. Context clausing in this
case rises a bit more steeply than that indicated in Fig. 1. However for the average
package containing 34 visible declarations, the optimum context clausing still remains three. Reused verbatim and slightly modified code is more tolerant of context
clausing, rising faster as the number of visible declarations increases. For the average
package of 34 visible declarations, the optimum context clausing is four.
We use the model to calculate the relationship between the variables characterizing a package – namely X and W – that minimizes the numbers of defects in that
package. Given that the number of visible declarations in packages are determined
by object-based principles for decomposing a problem space into objects [22], in the
analysis that follows, we will regard this number as a parameter.
From Table 1, we note that for the four projects in our data, the mean number of
visible package declarations ranges from about 29 to 44, while the mean context
clausing ranges from 6.4 to 9.1. Thus, it appears that, on the average, the packages of
these projects make too much use of context clausing, consequently delegating too
much of the workload implied by the mean number of declarations to other packages. A typical example of this delegation may be a call statement in a subprogram
within a package to another subprogram of a package that is context coupled to the
package. Consequently, if less of the workload were delegated and, instead implemented within the package through hidden declarations contained in the body, the
context coupling might be reduced.

244

W.M. Evanco and J. Verner

From a different perspective, if the elements in a package lack cohesiveness,
then according to Stevens et al. [5] coupling may be increased. Assuring that the
constituent parts of a package are tightly related might reduce coupling and lower the
number of defects. The delegation of workload of package A to some package B may
reduce package A’s cohesiveness in the sense that the constituents of package B may
be closely associated with those of package B at a semantical level [24]. However,
examining issues revolving around cohesion and identifying specific means to increase cohesion/reduce coupling is beyond the scope of this study.
A relatively easy way to reduce external complexity is to identify packages (e.g.,
package A) that are used as resources for only one other package (e.g., package B).
The resources of package A may then be incorporated into the body of package B,
reducing the context coupling of package B while not increasing the number of visible declarations. Presumably, the resources of package A are highly related to those
of package B, since they are used only by package B, and, hence, may be highly cohesive with the package B resources.

6

Conclusions

We demonstrated that internal and external complexity measures can be defined for
an object-based language such as Ada. These measures are related to the number of
package defects uncovered during testing. Based on this relationship, we demonstrated that tradeoffs exist between context clausing and the visible declaration numbers in a package.
The results of this study can be used in a prescriptive fashion as one input in deciding among different designs, in guiding the evolution of an initial design, or in
modifying an existing system. A software designer may not be able to strictly adhere
to these prescriptive guidelines for all packages in the system. However, these guidelines can be used to identifypotential problem areas that may be either modified or
subjected to additional testing. While the analysis was conducted for Ada software
systems, the results may be applicable to other object-oriented/based languages. The
extent of this applicability is currently being explored.
The model presented in this paper is relatively simple, focusing only on some of
the architectural features that manifest themselves during top-level design. In future
work, we plan to introduce software features into our models that reflect some of the
lower level architectural decisions. For example, the cyclomatic complexity and the
numbers of parameters involved in the subprograms of the packages may affect defect numbers. Such models will be useful at later design and implementation phases.
We might expect these models to be substantially more complex than the ones discussed here and to exhibit additional tradeoffs among the software characteristics
that emerge throughout design and implementation.

References
1.
2.

Agresti, W. and Evanco, W. (1992), Projecting Software Defects from Analyzing Ada
Designs, IEEE Transactions on Software Engineering, 18 (11), pp. 988–997.
Briand, L.; Basili, V.; Thomas, W. (1992), A Pattern Recognition Approach for Software
Engineering Data Analysis, IEEE Transactions on Software Engineering, 18 (11), pp.
931–942.

Some Architectural Features of Ada Systems Affecting Defects
3.
4.

5.
6.
7.

8.
9.
10.
11.
12.

13.
14.
15.
16.
17.
18.

19.

20.
21.

22.
23.
24.

245

Munson, J. and T. Khoshgoftaar (1992), The Detection of Fault-Prone Programs, IEEE
Transactions on Software Engineering, 18 (5), pp. 423–433.
Kazman, R.; Klein, M.; Barbacci, M.; Longstaff, T.; Lipson, H. Carriere, J. (1998), The
Architecture Tradeoff Analysis Method, 4th International Conference on Engineering of
Complex Computer Systems.
Stevens, W.; Myers, G.; Constantine, L. (1974), Structured Design, IBM Systems Journal,
13 (2), pp. 115–139.
Briand, L. and Wust, J. (2002), Empirical Studies of Quality Models in Object Oriented
Systems, Advances in Computers, 56, pp. 97–166.
Mišic, V. (2001), Cohesion is Structural, Coherence is Functional: Different Views, Different Measures, 7th International Software Metrics Symposium, pp. 135–144, London,
England.
Evanco, W. (1995), Modeling the Effort to Correct Faults, Journal of Systems and Software, Volume 29, pp. 75–84.
Rombach, D. (1987), A Controlled Experiment on the Impact of Software Structure on
Maintainability, IEEE Transaction on Software Engineering, 13, pp. 344–354.
Evanco, W. and W. Agresti (1994), A Composite Complexity Approach for Software Defect Modelling, Software Quality Journal, Volume 3, Number 1, pp. 27–44.
Khoshgoftaar, T. and Szabo, R. (1996), Using Neural Networks to Predict Software
Faults During Testing, IEEE Transactions on Reliability, 45 (3), pp. 456–462.
Baisch, E. and Liedtke, T. (1997), Comparison of Conventional Approaches and Softcomputing Approaches for Software Quality Prediction, IEEE International Conference
on Systems, Man, and Cybernetics: Computational Cybernetics and Simulation, Volume
2, pp. 1045 –1049.
Fenton, N. and Neil, M. (1999), A Critique of Software Defect Prediction Models, IEEE
Transactions on Software Engineering, 25 (5), pp. 675–689.
Evanco, W. and Verner, J. (2001), Revisiting Optimal Software Components, Proceedings of the 12th European Software Control and Metrics Conference, pp. 117–124.
Card, D. N. and W. W. Agresti (1988), Measuring Software Design Complexity, Journal
of Systems and Software, Volume 8, Number 3, pp. 185–197.
Munson, J. and T. Khoshgoftaar (1988), The Dimensionality of Program Complexity,
Proceedings of the 11th International Conference on Software Engineering, pp. 245–253.
Evanco, W. (1997), Poisson Analyses of Defects for Small Software Components, Journal of Systems and Software, 38 (1), pp. 27–35
Cameron, A. and Trivedi, P. (1986), Econometric Models Based on Count Data: Comparison and Application of Some Estimators and Tests, Journal of Applied Econometrics,
1, pp. 29–54.
Evanco, W.M. (2000), Subprogram Defect Predictions Based on Negative Binomial
Models, Proceeding of the 13th International Conference on Software and Systems Engineering and Applications, Volume 2, Paris, France.
Chidamber, D. and C. Kemerer (1994), A Metrics Suite for Object Oriented Design,
IEEE Transactions on Software Engineering, 20 (6), pp. 476–493.
Abreu, F.; M. Goulao; R. Esteves (1995), Toward the Design Quality Evaluation of Object-Oriented Software Systems, Proceedings of the 5th International Conference on
Software Quality, Austin, TX.
Doubleday, D. L. (1987), ASAP: An Ada Static Source Code Analyzer Program, TR1895, Department of Computer Science, University of Maryland
Booch, G. (1983), Software Engineering with Ada, Benjamin Cummings, Menlo Park,
CA.
Henderson-Sellers, B. (1996), Object-Oriented Metrics: Measures of Complexity, Prentice Hall, Upper Saddle River, NJ.

