Available online at www.sciencedirect.com

Procedia Computer Science 9 (2012) 383 – 392

International Conference on Computational Science, ICCS 2012

Reusing Random Walks in Monte Carlo Methods for Linear Systems
Hao Jia, Yaohang Lia*
a

Department of Computer Science, Old Dominion University, Norfolk, VA 23529, USA

Abstract
In this paper, we present an approach of reusing random walks in Monte Carlo methods for linear systems. The fundamental idea
is, during the Monte Carlo sampling process, the random walks generated to estimate one unknown element can also be
effectively reused to estimate the other unknowns in the solution vector. As a result, when the random walks are reused, a single
random walk can contribute samples for estimations of multiple unknowns in the solution simultaneously while ensuring that the
samples for the same unknown element are statistically independent. Consequently, the total number of random walk transition
steps needed for estimating the overall solution vector is reduced, which improves the performance of the Monte Carlo algorithm.
We apply this approach to the Monte Carlo algorithm in two linear algebra applications, including solving a system of linear
equations and approximating the inversion of a matrix. Our computational results show that compared to the conventional
implementations of Monte Carlo algorithms for linear systems without random walk reusing, our approach can significantly
improve the performance of Monte Carlo sampling process by reducing the overall number of transition steps in random walks to
obtain the entire solution within desired precision.
Keywords: Monte Carlo Method; Random Walk; Linear System; Inverse Matrix

1. Introduction
The Monte Carlo method is base on experimental mathematics using statistical sampling. Applying Monte Carlo
methods to applications in linear systems is originally proposed by von Neumann and Ulam [1]. Considering a linear
system of
x = Hx + b
where H is an M x M matrix, b is a given constant vector, and x is the unknown vector, the fundamental idea of the
Monte Carlo solver is to construct Markov chains by generating random walks to statistically sample the underlying
Neumann series
I + H + H 2 + H3
of the linear system. If ||H|| < 1, the Neumann series converge to (I - H)-1 and hence the mathematical expectation of
the random walks starting from the ith row of matrix H equals to the solution xi.
Other techniques have also been developed to improve the Monte Carlo algorithm for estimating the solutions of

* Corresponding author. Tel.: +1-757-683-6001; fax: +1-757-683-4900.
E-mail address: yaohang@cs.odu.edu.

1877-0509 © 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
doi:10.1016/j.procs.2012.04.041

384

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

a linear system. Wasow [2] modified the scheme by von Neumann and Ulam by designing another unbiased
estimator, which has been shown to have smaller variance under some special conditions. Halton [3] proposed a
sequential Monte Carlo method to accelerate the Monte Carlo process by taking advantage of the rough estimate of
the solution to transform the original linear system x = Hx + b to a new system y = Hy + d, where ||d|| < ||b||. Dimov
et al. [4] developed an accelerating Monte Carlo scheme to control the convergence of the Monte Carlo algorithm
for different unknown elements with different relaxation parameters, which can increase the efficiency of the
random walk estimators. This iterative scheme is also used to approximate evaluation of the inverse matrix. Tan [5]
studied the antithetic variates techniques for variance reduction in Monte Carlo linear solvers. Srinivasan and
Aggarwal [6] used non-diagonal splitting to improve the Monte Carlo linear solvers. Moreover, for applications with
large linear systems, Sabelfeld and Mozartova [7] designed a sparsified randomization algorithm by using a sparse,
random matrix G, which is an unbiased estimator of H, to replace the original matrix H during the sampling process.
Furthermore, Mascagni and Karaivanova [8] investigated the usage of quasirandom numbers in the Monte Carlo
solver. Nevertheless, the fundamental mechanism of these Monte Carlo solvers, i.e., constructing Markov chains
based on random walks to estimate solutions of the linear systems, remains the same.
The main drawback of the Monte Carlo methods is that they can only provide statistical estimates for a given
linear system with a slow convergence rate of O(N -1/2) [9], where N is the number of samples. Consequently, the
Monte Carlo solvers are usually not as efficient as the modern deterministic direct or iterative solvers to obtain very
precise solutions. However, in many important applications such as preconditioning [10], machine learning [11], and
information retrieval [12], where the matrices are large while not very accurate solutions can be satisfactory, the
Monte Carlo algorithms become attractive due to the fact that the Monte Carlo convergence rate is independent of
the size of the matrix [9]. Moreover, similar to many Monte Carlo algorithms, most Monte Carlo methods for linear
system are embarrassingly parallel [17], which are efficient and scalable on traditional parallel systems as well as a
variety of emerging high performance computing platforms such as multi-core systems [13], the computational
Grids [14], the Cloud computing architectures [15], and the General Purpose Graphics Processing Unit (GPGPU)
clusters [16].
In the original Monte Carlo algorithm proposed by von Neumann and Ulam [1], a random walk can be used to
estimate only one element in the unknown vector x. Therefore, for applications interested in the general shape of x,
the original Monte Carlo algorithm is rather inefficient since separate random walks need to be generated for
estimating different elements in x. Reusing the random walks can improve the efficiency of Monte Carlo algorithms.
Sbert et al. has shown that reusing the paths of random walks can reduce the cost of Monte Carlo algorithms in
radiosity applications [19]. Moreover, Hammersley and Hamscomb [9] described an adjoint method for von
Monte Carlo scheme, where a random walk can be used for estimate the overall solution x.
However, a potential problem is that the samples generated by the adjoint method are correlated, which may lead to
biases in estimation of the solutions.
In this paper, we present a new approach of reusing random walks in the Monte Carlo algorithms for linear
systems. In this reusing random walk scheme, during the Monte Carlo sampling process, a random walk can
contribute samples for estimation of multiple unknown elements in x simultaneously and ensure that the samples for
the same unknown element are independent in statistical sense. As a result, reusing random walks can significantly
improve efficiency of Monte Carlo linear solver in estimating the entire solution x in a linear system. We use the
iterative Monte Carlo scheme developed by Dimov et al. [4] as an example to demonstrate the effectiveness of our
approach of reusing random walks. In addition to solving systems of linear equations, our approach of reusing
random walks can be applied to Monte Carlo approximate evaluation of an inverse matrix, which is also shown in
this paper.
The rest of the paper is organized as follows. We review the random walk method in the Monte Carlo linear
system solver proposed by von Neumann and Ulam as well as the iterative scheme developed by Dimov et al. in
Section 2. Sections 3 and 4 describe our reusing random walks approach and its applications in solving linear system
and inverse matrix approximation, respectively. Section 5 presents our computational results. Finally, Section 6
concludes our summary and future research directions.
2. Random Walks and Monte Carlo Linear Solvers
Although different estimators are proposed in different Monte Carlo linear solvers, the fundamental mechanism

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

385

of the Monte Carlo algorithm is to construct Markov chains based on random walks to estimate the solutions of the
linear systems.
The original Monte Carlo linear solver proposed by von Neumann and Ulam [1] employs a terminating random
walk (terminating Markov chain). Considering a linear system of
x = Hx + b,
where H is an M x M matrix and b is a given constant vector, an M x M transition probability matrix P is
constructed by satisfying the following conditions:
Pij 0;
Pij

1; and

j

H ij

0

Pij

0.

The terminating probability vector T is defined as
Ti

1

Pij .
j

Then, a random walk starting at i0 and terminating after k steps is defined as
i0, i1
ik),
ik are the row numbers visited during the random walk. The transition probability of random
where the integers i1
P(in+1 = j | in = i, n < k) = Pij
and terminating probability is
P(k = n | in = i, n - 1 < k) = Ti.
Also, define X( ) such that
H i0 i1 ...H ik 1ik bik

X( )

Pi0 i1 ...Pik 1ik Tik

.

As a result, if the underlying Neumann series converges, X( ) is an unbiased estimator of component xi in the
unknown vector x where i = i0.
Dimov et al. proposed an accelerating Monte Carlo scheme to improve the efficiency of the random walk
estimator. The M x M transition probability matrix Q is defined as
Qij

| H ij |
| H ij |

.

j

Instead of defining an explicit terminating probability, for a random walk
i0, i1
a weight quantity Wn is calculated at each transition step by
W0

1, W1

W0

H i0i1
Qi0i1

, ... , Wn

Wn

H in 1in
1

Qin 1in

,....

The random walk will be terminated at the kth step when |Wk|
Similarly, if the underlying Neumann series converges,

for the first time, where

k

Y( )
n 0

Wn bin

is an unbiased estimator for xi where i = i0.
3. Reusing Random Walks in Monte Carlo Solver for Linear Systems
3.1. Analysis of Random Walk Reusing

i0,

is a given tolerance.

386

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

In the original Monte Carlo linear solver by von Neumann and Ulam or the alternative scheme by Dimov et al., a
random walk is used to generate a sample for a single component xi in the unknown vector x by initiating the
random walk at the ith row in the transition matrix. Generally, Monte Carlo algorithms require sufficient number of
independent samples to obtain a reasonably accurate estimation of a solution. Assuming that averagely each element
in the unknown vector x requires N independent samples to achieve certain accuracy, finding the overall solution of
x with M unknown components demands M * N random walks. Figure 1 illustrates 50 independent random walks
generated for producing 50 samples to compute every unknown element in a 6 x 6 system of linear equations
without being reused. This is rather costly particularly when the linear system is large.
Random Walks
1st:
2nd:

x1

3rd:
50th:

1 4 4 5 5 4 4 5 5 4
1 3 3 5 5 2 2 5 5 4 4 1
1 3 3 6 6 3 3 6 6 3

Random Walks
1st:
2nd:

x4

1 4 4 1 1 3 3 6 6 3

3rd:
50th:

Random Walks
st

1 :
2nd:

x2

3rd:
50th:

2 5 5 4 4 5 5 4 4 5
2 5 5 2 2 5 5 4 4 5
2 5 5 3 3 5 5 2 2 5 5 4

1 :
2nd:

x5

2 5 5 2 2 5 5 4 4 5

2nd:

x3

3rd:
50th:

3 1 1 3 3 5 5 4 4 5 5 2 2 5
3 5 5 2 2 5 5 2 2 5 5 2
3 6 6 3 3 6 6 3
3 1 1 3 3 6 6 3 3 6 6 3

4 5 5 2 2 5 5 2 2 5
Random Walks

st

3rd:
50th:

Random Walks
1st:

4 5 5 3 3 1 1 3 3 6 6 3
4 1 1 4 4 5 5 4 4 5
4 5 5 4 4 5 5 2

5 3 3 1 1 3 3 6 6 3
5 4 4 1 1 3 3 5 5 4 4 1
5 2 2 5 5 2 2 5 5 4
5 4 4 5 5 4 4 1
Random Walks

1st:
2nd:

x6

3rd:
50th:

6 3 3 5 5 2 2 5
6 3 3 6 6 3
6 3 3 1 1 3 3 5 5 2
6 3 3 5 5 4 4 5

Figure 1: 50 Independent Random Walks Generated for Estimating Each Unknown Element in a 6 x 6 System of
Linear Equations without Being Reused
Our further analysis finds that Monte Carlo algorithms require statistical independence of samples when
estimating the same element in the unknown vector x; however, such independence is not necessary among samples
for different elements. In other words, the samples for one element can be correlated with those for a different
element. As a result, a random walk, or at least part of it, for generating samples for one element can be reused for
estimating another different one.
Consider the 1st random walk for estimating x5 shown in Figure 1
.
5
can be regarded as part of a
After transition from 5 to 3, the partial random walk
random walk starting at 3 and thus it can be reused to estimate element x3. Similarly, after the random walk reach 1,
can also be reused to estimate element x1 and so on. Reusing the
the partial random walk
random walks can reduce the total number random walk steps needed for estimating the overall solution vector x
and therefore improve the performance of the Monte Carlo solver.
3.2. Monte Carlo Linear Solver with Random Walk Reusing
We use the iterative Monte Carlo scheme developed by Dimov et al. [4] as an example to illustrate our
implementation of reusing random walks in Monte Carlo linear solvers. Figure 2 shows the pseudocode of the
Monte Carlo linear solver with random walk reusing. The main difference between the conventional scheme and the
reusing random walk scheme is that a reusing random walk will not terminate until the current random walk no
longer contributes to any unknown elements demanding more samples. During the sampling process, a contribution
set S is used to keep track of the indices of the unknown elements in the solution vector being contributed by the
current random walk and an array flag is used to indicate if there is sufficient number of samples for each unknown
element. For each unknown element xi, a data structure is used to store the current weight quantity (W) and the
current sample value (X). A random walk starts from the index of a randomly selected unknown element requiring

387

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

more samples. When convergence of the random walk on an unknown element xi is observed, a sample for xi is
generated and index i is removed from contribution set S, i.e., the current random walk no longer contribute to xi.
Afterward, the statistical variance of xi is estimated. If the statistical error is less than the statistical error bound ,
the corresponding value in the flag array is set, indicating that xi does not need more samples. If contribution set S is
empty indicating that the current random walk no longer contributes to any unknown elements in need of more
samples, the random walk will stop. Then, a new random walk is spawn starting from the index of one of the
unknown elements still requiring more samples. This process repeats until all unknown elements in solution vector x
obtain sufficient number of random samples to achieve desired statistical accuracy.
Input:
Coefficient matrix , constant vector , tolerance , and statistical error bound
Preprocessing:
Calculate the probability matrix and the row sum vector
where rsum(i)=
Monte Carlo algorithm with random walks reusing:
While
is not empty
Begin // starting a new random walk
Select a starting state
Set
Set
and
While the set is not empty
Begin
Generate an uniformly distributed random number
Locate index satisfying
For each element
whose index
// contribute to multiple elements
Begin
Calculate
Calculate
If
, then // convergence
Begin
as a sample for
Generate
Delete from the set
Calculate variance of
If statistical error of < then
Begin // random walk no longer contribute to
Set
End
End
End
// update the random walk state
Set
and
, then
If
Begin
// contribute to a new element
Add into the set
and
Set
End
End
End

;

Figure 2: Pseudocode of Monte Carlo Linear Solver with Reusing Random Walks

388

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

Random Walk
1 4 5 5 2 2 5 2 5 3 3 5 4 5 5 2 2 5 2 5 4 5 2 5 2 5 4 5 5 4 4 1 3 6 6 6 6

(Elements)
x1

1 4 5 5 2 st2 5 2 5 3

1 3 6 nd 6 6 6

1

2

2 2 5 2 5 st 3 3 5 4 5

x2

2 2 5 2 5nd 4 5 2 5 2 5 4 5 5rd 4 4 1 3

1

x3

2

3

3 3 5 4 5 st5 2 2 5 2

3 6 nd
6 6 6

1

x4

4 5 5 2 2 st5 2 5 3 3
1

x5

5 5 2 2 5 st 2 5 3 3 5
1

4 5 5 2 2nd 5 2 5 4
2

5 5 2 2 nd
5 2 5 4 5
2

x6

2

4 5 5 4 rd4 1 3 6
3

5 2 5 4 rd5 5 4 4
3

6 6 st 6 6
1

Figure 3: Example of a Random Walk being Reused for Estimating 6 Unknown Elements in a 6x6 Linear System
Figure 3 illustrates an example of a hypothetical random walk starting from 1 being reused for estimating 6
unknown elements in a 6 x 6 linear system. The reusing random walk implementation shown in Figure 2 ensures
that the random samples generated for the same element are statistically independent without overlapping
trajectories.
4. Reusing Random Walks for Approximating an Inverse Matrix
One can rewrite the linear system x = Hx + b into a more common form
Ax = b,
where A = I H is another M x M matrix. Setting

bi

(0, 0, ..., 1, ..., 0) T ,
i

solution vector xi = (x1i, x2i, , xMi )T of Axi = bi is the ith column of the inverse matrix A-1. Therefore, repeatedly
using Monte Carlo linear solver to evaluate the each column of the inverse matrix of A-1, one can have an
approximate estimation of the inverse matrix A-1.
Reusing random walks can be also extended to the application of approximating an inverse matrix. Figure 4
depicts a scheme of reusing a random walk in approximating the inverse matrix of a 6 x 6 matrix. A single random
walk step can contribute to the evaluations of the elements in an entire row while statistical estimations of multiple
rows in A-1 can share the same random walk.

389

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

Random Walk
(Elements)

1 4 5 5 2 2 5 2 5 3 3 5 4 5 5 2 2 5 2 5 4 5 2 5 2 5 4 5 5 4 4 1 3 6 6 6 6

x11

1 4 5 5 2 st2 5 2 5 3

1 3 6 nd 6 6 6

x12

1 4 5 5 2 st2 5 2 5 3

1 3 6 nd 6 6 6

x13

1 4 5 5 2 st2 5 2 5 3

1 3 6 nd 6 6 6

x14

1 4 5 5 2 st2 5 2 5 3

1 3 6 nd 6 6 6

x15

1 4 5 5 2 st2 5 2 5 3

1 3 6 nd 6 6 6

x16

1 4 5 5 2 st2 5 2 5 3

1 3 6 nd 6 6 6

1

2

1

2

1

2

1

2

1

2

1

2

x21

2 2 5 2 5 st 3 3 5 4 5

2 2 5 2 5
4 5 2 5 2 5 4 5 5
4 4 1 3
nd
rd

x22

2 2 5 2 5 st 3 3 5 4 5

2 2 5 2 5
4 5 2 5 2 5 4 5 5
4 4 1 3
nd
rd

x23

2 2 5 2 5 st 3 3 5 4 5

2 2 5 2 5
4 5 2 5 2 5 4 5 5
4 4 1 3
nd
rd

x24

2 2 5 2 5 st 3 3 5 4 5

2 2 5 2 5
4 5 2 5 2 5 4 5 5
4 4 1 3
nd
rd

x25

2 2 5 2 5 st 3 3 5 4 5

2 2 5 2 5
4 5 2 5 2 5 4 5 5
4 4 1 3
nd
rd

x26

2 2 5 2 5 st 3 3 5 4 5

2 2 5 2 5
4 5 2 5 2 5 4 5 5
4 4 1 3
nd
rd

1
1
1
1
1
1

2

3

2

3

2

3

2

3

2

3

2

3

x31

3 3 5 4 5 st5 2 2 5 2

3 6 6
6 6
nd

x32

3 3 5 4 5 st5 2 2 5 2

3 6 6nd 6 6

x33

3 3 5 4 5 st5 2 2 5 2

3 6 6
6 6
nd

x34

3 3 5 4 5 st5 2 2 5 2

3 6 6
6 6
nd

x35

3 3 5 4 5 st5 2 2 5 2

3 6 6
6 6
nd

x36

3 3 5 4 5 st5 2 2 5 2

3 6 6
6 6
nd

1

2

1

2

1

2

1

2

1

2

1

2

x41

4 5 5 2 2 st5 2 5 3 3

4 5 5 2 nd
2 5 2 5 4

4 5 5 4 rd 4 1 3 6

x42

4 5 5 2 2 st5 2 5 3 3

4 5 5 2 nd
2 5 2 5 4

4 5 5 4 rd 4 1 3 6

x43

4 5 5 2 2 st5 2 5 3 3

4 5 5 2 nd
2 5 2 5 4

4 5 5 4 rd 4 1 3 6

x44

4 5 5 2 2 st5 2 5 3 3

4 5 5 2 nd
2 5 2 5 4

4 5 5 4 rd 4 1 3 6

x45

4 5 5 2 2 st5 2 5 3 3

4 5 5 2 nd
2 5 2 5 4

4 5 5 4 rd 4 1 3 6

x46

4 5 5 2 2 st5 2 5 3 3

4 5 5 2 nd
2 5 2 5 4

4 5 5 4 rd 4 1 3 6

1

1
1
1
1
1

2

2
2
2
2
2

3

3
3
3
3
3

x51

5 5 2 2 5 st 2 5 3 3 5

5 5 2 2 5
2 5 4 5
nd

5 2 5 4 rd 5 5 4 4

x52

5 5 2 2 5 st 2 5 3 3 5

5 5 2 2 5
2 5 4 5
nd

5 2 5 4 rd 5 5 4 4

x53

5 5 2 2 5 st 2 5 3 3 5

5 5 2 2 5
2 5 4 5
nd

5 2 5 4 rd 5 5 4 4

x54

5 5 2 2 5 st 2 5 3 3 5

5 5 2 2 5
2 5 4 5
nd

5 2 5 4 rd 5 5 4 4

x55

5 5 2 2 5 st 2 5 3 3 5

5 5 2 2 5
2 5 4 5
nd

5 2 5 4 rd 5 5 4 4

x56

5 5 2 2 5 st 2 5 3 3 5

5 5 2 2 5
2 5 4 5
nd

5 2 5 4 rd 5 5 4 4

1
1
1
1
1
1

2
2
2
2
2
2

3
3
3
3
3
3

x61

6 6 st 6 6

x62

6 6 st 6 6

x63

6 6 st 6 6

x64

6 6 st 6 6

x65

6 6 st 6 6

x66

6 6 st 6 6

1
1
1
1
1
1

Figure 4: Reusing a Random Walk in Approximating the Inverse Matrix of a 6 x 6 Matrix

5. Computational Results

390

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

# of Random Walk Transitions

1.0E+12
1.0E+11

Monte Carlo with
Random Walks Reusing

1.0E+10

Monte Carlo without
Random Walks Reusing

1.0E+09
1.0E+08
1.0E+07
1.0E+06
1.0E+05
1.0E+04
5.0E-02

5.0E-03

5.0E-04

5.0E-05

Variance

Figure 5: Performance comparison of Monte Carlo linear solver with random walks reusing and without random
as coefficient matrix. The
walks reusing under different precisions. The linear system uses
computational results are based on the averages of 20 runs.
UFL sparse matrix collection [18] as
We use a strictly
306 x 306 matrix with
the coefficient matrix for a linear system in this computational experiment
2,018 nonzero elements. Figure 5 compares the numbers of random walk transitions in Monte Carlo linear solver to
obtain the entire solution vector in different precisions with random walks reusing and the one without random
walks reusing. One can find that our random walk reusing approach can reduce the number of random walk
transitions by approximately 5.8 times. A random walk transition is a relatively costly operation in the Monte Carlo
comparison
linear solvers. Considering a row in the coefficient matrix with K nonzero elements,
operations are needed to find the next state by comparing the transition probabilities if binary search is used.
Figure 6 compares the numbers of random walk transitions in the Monte Carlo algorithm of approximating the
isions with random walks reusing and the one without random walks
reusing. Reusing random walks in inverse matrix estimation is even more effective than its implementation in Monte
Carlo linear solver. The total number of transition is reduced by about 56.9 times when the random walks are reused
in calculating the inverse matrix of
Monte Carlo algorithms, a random walk can contribute to more elements a random walk can be potentially reused
for estimating different rows and a transition in the random walk can also be used to evaluate the elements in the
entire rows that it is contributing to.

391

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

# of Random Walk Transitions

1.0E+13

1.0E+12

Monte Carlo with
Random Walks Reusing

1.0E+11

Monte Carlo without
Random Walks Reusing

1.0E+10
1.0E+09
1.0E+08
1.0E+07
1.0E+06
1.0E+05
1.0E+04
5.0E-02

5.0E-03

Variance

5.0E-04

5.0E-05

Figure 6: Performance Comparison of Monte Carlo Algorithms of Approximating the Inverse Matrix
with Reusing Random Walks and without Reusing Random Walks in different precisions. The computational results
are based on the averages of 20 runs.

6. Conclusions and Future Research Directions
In this paper, we present an approach of reusing random walks in Monte Carlo algorithms for linear systems to
improve their efficiency in obtaining the entire solution. When the random walks are shared, a single random walk
can contribute to estimations of multiple unknowns in the solution vector simultaneously. We apply the reusing
random walk techniques to the Monte Carlo algorithms of solving a linear system as well as approximating a
ion. Our computational results show that compared to the conventional implementations of the Monte
Carlo algorithms, our reusing random walks approach can significantly reduce the overall number of random walk
transition steps during the Monte Carlo sampling process to obtain solutions within desired precision.
We use the iterative scheme by Dimov et al. [4] as an example to illustrate our implementation of reusing random
walk in this paper. In general, the random walk reusing approach is applicable to other Monte Carlo estimators as
well.
One of the main advantages of the Monte Carlo methods is their high parallel efficiency. Our future work will
focus on developing efficient parallel Monte Carlo algorithms for linear algebra applications with reusing random
walks on traditional and emerging parallel computing platforms.
Acknowledgements
We would like to thank Dr. Michael Mascagni for his valuable discussions on reusing random walk paths.
Yaohang Li acknowledges support from NSF grant 1066471 and ODU 2011 SEECR grant.
References
[1] G. E. Fo

392

Hao Ji and Yaohang Li / Procedia Computer Science 9 (2012) 383 – 392

Aids to Computation, 4: 127-129, 1950.
[2]
Computation, 6: 78-81, 1952.
[3] J. H. Halton, Sequential Monte Carlo techniques for the solution of linear systems, Journal of Scientific
Computing, 9: 213-257, 1994.
[4] I. T. Dimov, T. T. Dimov, T. V. Gurov, A new iterative Monte Carlo Approach for Inverse Matrix Problem,
Journal of Computational and Applied Mathematics, 92: 15-35, 1998.
[5]
Computational Science (ICCS02), 2002.
[6]
Proceedings of the International Conference on Computational Science and its Applications (ICCSA03), 2003.
[7] K. Sabelfeld,
15(3): 257284, 2009.
[8] M. Mascagni, A. Karaivanova, A Parallel Quasi-Monte Carlo Method for Solving Systems of Linear
Proceedings of International Conference on Computational Science (ICCS02), 2002.
[9] J. M. Hammersley, D. C. Handscomb, Monte Carlo Methods, Chapman and Hall, 1964.
, symmetric
[10] H. Ji, D. Nguyen, Y. Liang, Y.
and non-symmetric
Large[11]
Vision and Pattern Recognition (CVPR08), 2008.
[12]
48(3): 569-581, 2006.
[13]
Proceedings of IEEE International Symposium on Parallel and Distributed Processing (IPDPS10), 2010.
[14]
International Journal of High Performance Computing Applications, 15(3): 200-222, 2001.
[15]
Proceedings of 10th International Symposium on Pervasive Systems, Algorithms, and Networks, (ISPAN09),
2009.
GPU Gems 2, Chapter
[16] J. Krüger
44, 2009.
-scale Grid[17] Y.
High Performance Computing Applications (IJHPCA), 17(4): 369-382, 2003.
[18] UFL sparse matrix collection. http://www.cise.ufl.edu/research/sparse/matrices/index.html, 2012.
[19] M. Sbert, P. Bekaert, J. Halton, Reusing paths in radiosity and global illumination, Monte Carlo Methods and
Applications, 10: 575-585, 2004.

