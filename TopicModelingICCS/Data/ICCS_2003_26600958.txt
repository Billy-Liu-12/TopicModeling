An Efficient Dispersal and Encryption Scheme for
Secure Distributed Information Storage*
Sung Jin Choi 1, Hee Yong Youn1**, and Bo Kyoung Lee2
1

School of Information and Communications Engineering
Sungkyunkwan University
440-746, Suwon, Korea +82-31-290-7949
{choisj, youn}@ece.skku.ac.kr
2 Information Security Technology Division
Korea Information Security Agency
138-803, Seoul, Korea +82-2-405-5263
bklee@kisa.or.kr

Abstract. Digital information is a critical resource, creating a need for distributed storage systems that provide sufficient data availability and security in the
face of failures and malicious attacks. However, the requirements for achieving
high availability and security with distributed storage systems usually conflict
with each other. This paper proposes a novel data dispersal/encryption scheme
improving both the availability and security of distributed storage system by
using some important properties of matrices. It also allows complete recovery of
original data even though they are partially damaged. Analysis shows it improves the availability about 15% compared with an efficient existing scheme
for both read and write operation, while it allows secure storage simultaneously.

1 Introduction
Digital information has become a critical resource, creating a need for distributed
storage systems that provide sufficient data availability and data security in the face of
failures and malicious attacks. Many research groups have been exploring the design
and implementation of such survivable storage systems. These systems are built on
various decentralized storage system technologies sharing a same high level architecture. The challenge in the development of survivable storage is to achieve acceptable
levels of performance and manageability. Moreover, a means for evaluating survivable
storage systems is required to facilitate the design of the systems [1].
A data distribution scheme needs data encoding and partitioning algorithm. There exist
many such algorithms applicable to survivable storage, including encryption, replication, striping, erasure-resilient coding, secret sharing, and various combinations of
them. They offer different levels of performance (throughput), availability (prob__________________________________
* This work was supported by Korea Research Foundation Grant (KRF-2002-041-D00421)
** Corresponding author

P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 958–967, 2003.
© Springer-Verlag Berlin Heidelberg 2003

An Efficient Dispersal and Encryption Scheme

959

ability that data can be accessed), and security (effort required to compromise the
confidentiality or integrity of stored data).
For example, replication provides high availability at the sacrifice of network
bandwidth and storage space, whereas short secret sharing provides high availability
and security with low storage and network bandwidth overhead but at high computation overhead. Likewise, selecting the number of shares required to reconstruct a secret-shared value involves a trade-off between availability and confidentiality: if more
machines must be compromised to steal the secret, then more machines must be operational to provide it legitimately. Availability of storage system needs to be improved through data distribution, and development of new efficient data distribution
and protection scheme is inevitable.
In distributed storage system availability and security of data are greatly influenced
by the policy how the data are dispersed. For example, complete recovery is possible
even though most data are lost in one scheme while one node failure causes loss of
entire data in another scheme, vice versa. Usually, the requirements for achieving high
availability and security with distributed storage system conflict with each other, and
there exist some tradeoff between them. This paper proposes a novel data dispersal/encryption scheme to improve both the availability and security of distributed
storage system by using some important properties of matrices. It also allows complete recovery of original data even though they are partially damaged. Analysis
shows that the availability is improved about 15% compared with an efficient existing
scheme, while it allows secure storage.
The rest of the paper is organized as follows. The next section explains representative data distribution schemes. Section 3 presents the proposed dispersal/encryption
scheme using eigenvalues and eigenvectors of matrices. In Section 4 we evaluate and
compare the performance of the proposed scheme. Finally, Section 5 concludes the
paper with future work.

2 Related Work
Secure distributed information storage system uses general threshold schemes to encode data before it is stored. Specifically, a p-m-n threshold scheme breaks data into n
shares such that any m of the shares can reconstruct the original data and fewer than p
shares reveal absolutely no information about the original data. Although encryption
makes it difficult to ascertain the original data, it does not change the value of p since
information is still available for theft. Different parameter selections of p-m-n expose
a large space of encoding mechanisms for storage [2].
An example of a specific threshold scheme is N-way replication. It is a 1-1-N
threshold scheme. That is, each replica reveals some information on the encoded data
(hence p = 1). A single replica is required to reconstruct the original data (m = 1), and
there are N replicas to select from when attempting to reconstruct the original data (n
= N). Table 1 lists some specific examples of general threshold schemes.
The threshold schemes can be implemented in different manners. Blakley’s secret
sharing scheme works in an m-dimensional space. Secrets (data) are points in the

960

S.J. Choi, H.Y. Youn, and B.K. Lee
Table 1. Specific threshold schemes.

Parameters
1-1-n
1-n-n
n-n-n
1-m-n
m-m-n
p-m-n

Description
Replication
Decimation (Striping)
Splitting (XORing)
Information Dispersal
Secret Sharing
Ramp Scheme

space, and the shares are multidimensional planes. Fewer than m shares represent a
multidimensional plane that contains the secret. However, since all points in the field
being considered are part of the plane, no information is revealed. With m shares, a
single point of intersection - the secret - is determined. Figure 1 illustrates the Blakley’s secret sharing scheme. Shamir’s secret-sharing scheme is based on interpolating
the coefficients of a polynomial by evaluating the polynomial at certain points [3].
y
a 1 x + b1

S

x
a 3 x + b3

a 2 x + b2

Fig. 1. Blakley’s secret sharing scheme with m=2, n=3, and original data S.

All implementations of secret sharing use random numbers to guarantee that collecting fewer than p shares reveals no information on the original data. Rabin’s information dispersal algorithm, a 1-m-n threshold scheme, does not use random numbers.
Indeed, the parameter p indicates the number of random numbers required per encoding (i.e. p-1random numbers are required to encode a secret for any threshold
scheme). Ramp schemes implement the full range of general p-m-n threshold schemes,
while they are like secret-sharing schemes up to p shares and information dispersal
schemes with p or more shares [4-5].
Figure 2 shows some examples of threshold schemes. (a) Replication (1-1-n) increases availability by increasing the storage required by a factor of n. It provides no
confidentiality because each share contains an entire copy of the original information
object. (b) Splitting (n-n-n) increases confidentiality by increasing the storage required
by a factor of n but decreases availability because all n shares must be available. (c)
Decimation (1-n-n) divides information objects into n pieces and stores each piece
separately. It decreases availability because all shares must be available while it offers
no confidentiality because each share exposes 1/n of the original information. (d)
Rabin’s information dispersal algorithm (1-m-n) offers a range of storage solutions
that show trade-off between availability and required storage space. Like decimation,
it does not offer confidentiality [6].

An Efficient Dispersal and Encryption Scheme

(a)

(b)

(c)

(d)

961

Fig. 2. Examples of simple threshold schemes.

The threshold schemes can be used instead of cryptographic techniques to guarantee
the confidentiality, and multiple schemes can be combined. For example, short secret
sharing encrypts the original information with a random key, stores the encryption key
using secret sharing, and stores the encrypted information using secret sharing or information dispersal. Short secret sharing offers a different set of trade-offs between
confidentiality and storage requirements than general threshold schemes. The confidentiality of the data stored by short secret sharing hinges on the difficulty of analyzing the information gained by collecting the shares because the information gained
pertains to the encrypted data.
An extension to threshold schemes is cheater detection. Here the shares are constructed in such a fashion that a client reconstructing the original information object
can tell, with high probability, whether some shares have been modified or not. This
technique allows strong information-integrity guarantees. Cheater detection can also
be implemented using cryptographic techniques such as adding digests to data before
encoding or to the shares themselves after the data have been encoded [7].
Secret-sharing scheme is m-m-n threshold scheme that shows trade-off between
confidentiality and availability; the higher the confidentiality guarantee, the more
shares required to reconstruct the original information object. It can be thought of as a
combination of splitting and replication techniques.

3 The Proposed Scheme
We first present some definitions and theorems required to explain the proposed dispersal/encryption scheme.
3.1 Eigenvalues and Eigenvector’s Definition
• Definition 1.
Let A be an n × n matrix. A nonzero vector v is an eigenvector of A if Eq. (1) holds
for some scalar λ. λ is called an eigenvalue of A corresponding to the eigenvector v.
Eigenvalues are also known as characteristic, or proper, values or even as latent roots.

Av = λv .

(1)

Let us now discuss how to compute eigenvalues and eigenvector in general. Because

962

S.J. Choi, H.Y. Youn, and B.K. Lee

Av=λv ⇒ Av=λIv
⇒ Av − λIv = 0 .
⇒ (A − λI)v = 0

(2)

We see that v is an eigenvector if and only if it is a nontrivial solution of the homogeneous system (A − λI)v = 0 . In this case v is a nonzero vector of the null space
of A − λI . The system has a nontrivial solution if and only if the determinant of the
coefficient matrix is zero. Thus, λ is an eigenvalues of A if and only
if det(A − λI) = 0 . The following is a well known theorem [8].
• Theorem 1.
Let A be a square matrix.
1. A scalar λ is an eigenvalue of A if and only if det(A- λ I) = 0.
2. A vector v is an eigenvector of A corresponding to an eigenvalue λ if and only if v
is a nontrivial solution of the system (A- λ I)v = 0.
3.2 Dispersal/Encryption Scheme
We need a general method for finding eigenvalue and eigenvector by using Definition
1 and Theorem 1, and it is the Power Method. It computes the dominant eigenvalue
and an eigenvector corresponding to the dominant eigenvalue. Without loss of generality, it is necessary to assume that A has the following two properties:
i. There is a single eigenvalue of maximum modulus.
ii. There is a linearly independent set of n eigenvectors.
According to the first assumption, the eigenvalues can be labeled such that

λ1 > λ 2 ≥ λ 3 ≥ L ≥

n

.

(3)

According to the second assumption, there is a basis {u (1) , u (2) ,..., u (n ) } for C n such that

Au ( j) = λ j u ( j) (1 ≤ j ≤ n) .

(4)

Let x (0) be an element of C n such that when x (0) is expressed as a linear combination
of the basis elements u (1) , u (2) ,..., u (n ) , the coefficient of u (1) is not 0. Thus,

x (0) = a1u (1) + a 2 u (2) + L + a n u (n ) (a1 ≠ 0) .

(5)

We form then x (1) = Ax (0) x (2) = Ax (1) L x (k) = Ax (k −1) to have

x (k ) = A k x (0) .

(6)

In the following analysis there is no loss of generality in absorbing all the coefficients
a j in the vectors u ( j) that they multiply. Hence, we may rewrite Eq. (5) as

An Efficient Dispersal and Encryption Scheme

x (0) = u (1) + u (2) + L + u (n ) .

963

(7)

By this equation and (6), we have
x (k ) = A k u (1) + A k u (2) + L + A k u (n ) .

(8)

Using Eq. (4), we arrive at

x (k ) = λ1k u (1) + λ k2 u (2) + L λ kn u (n ) .

(9)

k
k


λ 
λ 
x (k ) = λ1k  u (1) +  2  u (2) + L +  n  u (n )  .


 λ1 
 λ1 

(10)

 λj 
Since λ1 > j IRU  ≤ M ≤ Q , we see that the coefficients   tend to 0 and the
 λ1 
(1)
vector within the brackets converges to u as k → ∞.
To simplify the notation, we write x (k ) in the form
k

x (k ) = λ1k  u (1) + ε(k )  .

(11)

where ε (k ) → 0 as k → ∞. In order to be able to take ratios, let ϕ be any linear functional on C n for which ϕ(u (1) ) ≠ 0 . Recall that a linear functional ϕ satisfies

ϕ(αx + β y) = αϕ(x) + βϕ(y), for scalars α and β and vectors x and y. (For example,
ϕ could simply evaluate the jth component of any given vector.) Then
ϕ(x (k ) ) = λ1k  ϕ(u (1) ) + ϕ(ε(k ) )  .

(12)

Consequently, the following ratios converges to λ1 as k → ∞:

rk ≡

 ϕ(u (1) ) + ϕ(ε(k +1) ) 
ϕ(x (k +1) )
=
λ
1
 → λ1 .
(1)
(k)
ϕ(x ( k ) )
 ϕ(u ) + ϕ(ε ) 

(13)

This constitutes the Power Method for computing λ1 . Since the direction of the
vector x (k ) aligns more and more with u (1) as k → ∞ , the method can also give us the
eigenvector u (1) [9]. If eigenvectors found are

u (1)

 s1 
 t1 
 z1 
M
M
M
=   s n ∈ R, u (2) =   t n ∈ R,KK , u (n) =   z n ∈ R .
M
M
M
 
 
 
s n 
 t n 
 z n 

(14)

964

S.J. Choi, H.Y. Youn, and B.K. Lee

Here P (P =  u (1) u ( 2) L u (n )  ) is actually stored data and matrix D consisting of eigen-

0
0
3

values becomes Decryption Key. For example, if original data is A=  −4 6
2  ,
16 −15 −5
λ1 = 0, λ 2 = 1, λ 3 = 3 . Eigenvectors that correspond to each
λ
be 0   0  u
come  s  ,  2t  ,  0  s,t,u ∈ R . Therefore, if s = t = u = 1 , the actually stored data
 −3s   −5t   2u 
P and decryption key D are as follows.
 0 0 1
0 0 0


P =  1 2 0  , D=  0 1 0 
 −3 −5 2 
 0 0 3 
An important property of the proposed scheme is that it allows both secret dispersal
as a general threshold scheme and encryption of data at the same time. That is, one
cannot extract original data even though the stored data P is available since deciding
the original matrix using the eigenvector is NP-hard problem. Refer to the example
above. There exist infinite ways to form P matrix by arbitrarily deciding the s, t, and u
values. As a result, the proposed scheme offers high availability and security as well
as complete recovery of original data even though some partial damage to the data
occurs.
3.3 Data Recovery Scheme
We next show how the original data is recovered using the matrix diagonalization
method.
• Definition 2.
Assume an n × n matrix A can be converted to a diagonal matrix D, which is called
diagonalizable. Then there exists an invertible n × n matrix P such that

P −1AP = D .

(15)

The process of finding matrices P and D is called diagonalization. First, it is worth to
notice that if D is a diagonal matrix with diagonal entries λ1 ,K , λ n , then for i=1,…,n

Dei = λei .

(16)

Hence, the standard basis vectors e1 ,K , e n are eigenvectors of D. In particular, the
eigenvectors of D are linearly independent. More generally, we have following Theorem 2.
• Theorem 2.
(Criterion for Diagonalization)
Let A be an n × n matrix.

An Efficient Dispersal and Encryption Scheme

965

1. A is diagonalizable if and only if it has n linearly independent eigenvectors.
2. If A is diagonalizable with P −1AP = D , then the columns of P are eigenvectors of A
and the diagonal entries of D are the corresponding eigenvalues.
3. If {v1 ,K , v n } are linearly independent eigenvectors of A with corresponding eigenvalues λ1 ,K , λ n , then A can be diagonalized by

λ1 L 0 
P = [v1 v 2 L v n ] and D=  M O M  .
 0 L λ n 

(17)

• PROOF.
Let P be a matrix with columns of n-vectors v1 ,K , v n and D be a diagonal matrix
with diagonal entries λ1 ,K , λ n , respectively. Then

AP = A[v1 v 2 L v n ] = [Av1Av 2 L Av n ] .

(18)

λ1 L 0 
[λ1 v1λ 2 v 2 L λ n v n ] = [v1 v 2 L v n ]  M O M  = PD .
 0 L λ n 

(19)

If A is diagonalizable, with P −1AP = D , then AP = PD . Hence, Avi = λ i vi , i=1,…,n.
So, the λ i s are eigenvalues and the vi s are corresponding eigenvectors.
Suppose that A has n linearly independent eigenvectors, say, v1 v 2 L v n (the columns
of P). If λ1 ,K , λ n are the corresponding eigenvalues, then Avi = λ i vi , i=1,…,n. If D
is a diagonal matrix with diagonal entries λ1 ,K , λ n , then AP = PD by (18) and (19).
Because P is a square matrix with linearly independent columns, it is invertible.
Hence, P −1AP = D and A is diagonalizable [10].

P −1AP = D .

(20)

If we multiply P matrix to both sides in upside form, Eq. (20) becomes PP −1APP −1 = PDP −1 . Since PP −1 = I, P -1P = I (I: identity matrix),
A = PDP −1
λ1 L L 0 
0 λ L 0 
2
  u (1) L u (n )  −1 .
=  u (1) L u (n )  

(21)
M
O M 


 0 L L λ n 
P: Set of Eigenvectors, D: Decryption Key consisting of eigenvalues.
Therefore, the original data can be recovered from P that was stored in the storage
nodes by A = PDP −1 . For the same example of Section 3.2, we get original data by

966

S.J. Choi, H.Y. Youn, and B.K. Lee

0
0
 0 0 1  0 0 0   4 −5 −2   3
 1 2 0  0 1 0   −2 3 1  =  −4 6
2 



 
 −3 −5 2  0 0 3  1 0 0  16 −15 −5

4 Performance Evaluation
The substantial body of prior work in building highly-available systems provides a
clear metric for evaluating information availability: the probability that a desired piece
of information can be accessed at any given point in time. Assuming uncorrelated
failures, this probability can be computed from the probabilities that required system
components are available. For example, a p-m-n threshold scheme requires at least m
of the n storage nodes containing the shares to be operational to perform a read. If
f node is the probability that a storage node has failed or is otherwise unavailable, then
the availability of the stored information is

Availability read =

n −m

n

i=0

 

∑  i  (f

node

)i (1 − f node ) n − i .

(22)

For writes, the computation of availability depends upon the system’s design. A
system could require that all of n specific nodes be operational for a write to succeed.
This approach clearly has poor availability. To improve write availability in a system
with N > n storage nodes, the write operation can attempt to write the shares at different storage nodes until it has completed n writes. Alternatively, a system could allow a
write to complete when fewer than n shares have been written. This requires more
work during failure recovery or reduces read availability of the stored data (because n
is effectively lower for that data). We calculate write availability using the last approach. Thus, m storage nodes of the N storage nodes in the system must be available
for a write to be performed, and write availability is [11]

Availability write =

Striping

Ramp

N−m

 N

∑  i (f
i =0

 

node

)i (1 − f node ) N − i .

(23)

Striping

Proposed Scheme

Ramp

Proposed Scheme

SPRR

1 .0 0





O











c

 RPZR


O RPXR

 RPVR



c RPTR

0 .8 0
0 .6 0
0 .4 0
0 .2 0
0 .0 0

RPRR

SR

TR

UR

VR

WR

XR

YR

ZR

[R

[[

p   B Bp   

Fig. 3. Comparison of read availability

SR

TR

UR

VR

WR

XR

YR

ZR

[R

[[

p   B Bp   

Fig. 4. Comparison of write availability

Figure 3 and 4 show the comparison of the read and write availability of the proposed
scheme along with striping and ramp scheme (p-2-n). Here up to 100 nodes were

An Efficient Dispersal and Encryption Scheme

967

tested. The figures reveal that the proposed scheme display incomparably better availability than striping while it is consistently better than the ramp scheme for about 15%
for both read and write operation.

5 Conclusion and Future Work
In this paper we have presented a new data dispersal/encryption scheme to improve
the availability and security of distributed storage system at the same time by using
some important properties of matrix. As a result, the proposed scheme offers high
availability and security as well as complete recovery of original data even though
partial damage occurs to the data. Analysis shows that the availability is improved
about 15% compared with an existing representative scheme for both read and write
operation, while it allows secure storage.
Necessity of storage system providing safe data storage is inevitable as dependency
on storage device is embossed at this point. Therefore more efforts are required to
develop effective data distribution and encryption techniques customized to various
applications and operation environment. A formal design methodology which identifies the tradeoff between the performance measures such as availability, security, and
operation speed also needs to be developed.

References
1.

Yvo Desmedt: Some Recent Research Aspects of Threshold Cryptography: Information
Security, First International Workshop ISW ’97, Lecture Notes in Computer Science
#1196, M. Mambo E. Okamoto, E. Davida, Ed., (1997) 158–173
2. A. Shamir: How to Share a Secret: Comm. ACM. (1979) 612–613
3. E. Karnin, J. Greene, M. Hellman.: On Secret Sharing Systems: IEEE Trans. Information
Theory (1983) 35–41
4. G. R. Blakley, Catherine Meadows: Security of ramp schemes: Advances in Cryptology,
Springer-Verlag, (1985) 242–268
5. A. De Santis and B. Masucci: Multiple Ramp Schemes: IEEE Trans. Information Theory
(1999) 1720–1728
6. Jay J. Wylie, Michael W. Bigrigg, John D. Strunk, Gregory R. Ganger, Han Kiliccote,
Pradeep K. Khosla: Survivable Information Storage systems: IEEE Computer (2000)
7. Y. Deswarte, L. Blain, J. Fabre: Intrusion Tolerance In Distributed Computing Systems:
Proc. IEEE Symp. Security and P privacy, IEEE CS Press, Los Alamitos, Calif (1991)
110–120
8. George Nakos, David Joyner: Linear Algebra with Applications, Brooks/Cole USA (1998)
442–455
9. David Kincaid, Ward Chenney: Numerical Analysis Mathematics of Scientific Computing.
2nd edn, Brooks/Cole USA (1996) 274–276
10. Birkhauser: Linear Algebra, Birkhauser Boston (1997) 216–219
11. Mehmet Bakkaloglu, Jay J. Wylie, Chenxi Wang, Gregory R. Ganger: On Correlated Failures in Survivable Storage Systems: School of Computer Science Carnegie Mellon University, Pittsburgh, PA15213 (2002)

