A Comparison of Neural Networks and Classical
Discriminant Analysis in Predicting Students’
Mathematics Placement Examination Scores
Stephen J. Sheel1, Deborah Vrooman2, R.S. Renner 3, Shanda K. Dawsey4
1

Department of Computer Science
Coastal Carolina University
Steves@coastal.edu
2

Department of Mathematics
Coastal Carolina University
Vroomand@coastal.edu

3

Department of Computer Science
California State University, Chico
Renner@ecst.csuchico.edu
4

Coastal Carolina University
AVX Corporation
Dawsey@sccoast.net

Abstract. Implementing a technique that is efficient yet accurate for college
student placement into the appropriat e mathematics course is important.
Coastal Carolina University currently groups students into entry-level
mathematics courses based upon their scores on a mathematics placement
examination given to incoming freshmen. This paper examines alternative
placement strategies. Using multiple regression analysis, the accumulative high
school grade point average, mathematics SAT, and the final grade in Algebra II
were found to be the best predictors of success on a mathematics placement
examination. Entry-level mathematics placement based on neural networks and
discriminant analysis is contrasted with placement results from the mathematics
placement test. It is found that a neural network can outperform classical
discriminant analysis in correctly predicting the recommended mathematics
placement. Consequently, a trained neural network can be an effective
alternative to a written mathematics placement test.

1

Introduction

As technology advances, methodologies evolve to enhance our abilities to perform
arduous tasks more expediently. Using modern computer technologies not only
makes completing tasks more efficient, but also may achieve a higher degree of
accuracy. For instance, classifying students into an appropriate entry -level course is
often a time-consuming task. The traditional classification method is to administer a
placement exam to each student for the purpose of measuring his or her ability in a
particular subject and/or area. Testing students requires time and energy. The exam
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2074, pp. 952−957, 2001.
� Springer-Verlag Berlin Heidelberg 2001
�

A Comparison of Neural Networks and Classical Discriminant Analysis

953

questions must be developed and analyzed, and a process for administrating and
scoring the exams must be implemented. In administering the exam, there is the
arrangement of a time and place for taking the exam, production of a physical copy of
the exam, and the delegation of a proctor. Once the exams are given, the exams must
be scored and students, based upon their scores, placed into the appropriate entry-level
course.
Similarly, a computer-based test requires design, programming,
implementation, and scoring. Several tools can be used for predictive purposes in
applied research. In studies where the criterion variable is nominal rather than
continuous, neural networks and classical discriminant analysis can be used to predict
group membership.
Currently at Coastal Carolina University, most incoming freshmen and transfer
students take a mathematics placement test prior to course enrollment. Students are
then placed into a mathematics course according to their performance. The entry -level
mathematics courses are as follows: Math 130I -- Intensive College Algebra, Math
130 -- College Algebra, Math 131 -- Trigonometry and Analytic Geometry, and Math
160 -- Calculus I. The placement test created by the Department of Mathematics and
Statistics is being utilized by all colleges at Coastal Carolina University, except the E.
Craig Wall College of Business. Students entering the College of Business are
assigned to a mathematics class according to their academic achievement in secondary
education. Prior to summer 2000, the mat hematics placement test was given in the
form of a written instrument usually during a student orientation session in the
summer before fall enrollment. In summer 2000, students applying to Coastal
Carolina University had the option of taking a computer based mathematics placement
test online over the Internet before arriving or taking it at the University.
Neural networks and discriminant analysis are two techniques that can be
employed for membership classification. This study compares the effectiveness of
placement based on neural networks and discriminant analysis with that of traditional
testing. The results for both the neural network and discriminant analysis are
compared to the results obtained by the mathematics placement test. For this study,
results are contrasted for the mathematics placement test given before and after the
advent of the computer based online testing. If a trained neural network or prediction
equation based on discriminant analysis yields statistically similar results to the
mathematics placement test, then one or the other could be used for entry-level
placement in mathematics courses.

2

Related Applications in Education

Within the last decade, neural networks and discriminant analysis have been compared
as predictors of success or failure in various disciplines. Gorr, Nagin, and Szczypula
[5] conducted a comparative study of neural networks and statistical models for
predicting college students’grade point averages. Discriminant analysis is included as
one of the statistical models compared to a neural network. Their study concluded
that the neural network serves as a better predictor than discriminant analysis. On the
other hand, Wilson and Hardgrave [8] found that the discriminant analysis approach
predicts graduate student success in a master’s level business administration (MBA)
program better than the neural network approach.

954

S.J. Sheel et al.

The use of neural networks as a predictor has increased over the past few years.
Cripps [3] uses a neural network to predict grade point averages of Middle Tennessee
State University students. According to Carbone and Piras [2], neural networks are
instrumental in predicting high school dropouts. In Nelson and Henriksen’s study [6],
a neural network uses input from student responses on a mathemat ics placement
examination given to incoming students at Ball State University and outputs the
mathematics course in which each student should be placed. The implementation of
neural networks as a prediction tool continues to increase.

3

Setting-up the Experiments

When assigning college students to an entry-level mathematics course on the basis of
their high school performance, certain factors may contribute to student performance
in mathematics. High school grade point average (GPA), class rank, Scholastic
Aptitude Tests (SAT), grades earned in high school algebra I and II, geometry, and
advanced mathematics courses are academic performance indicators that have the
potential of affecting mathematics course placement in college. Multiple correlation
coefficients adjusted to beta weights were used to analyze the variance of these
predictors of scores on the mathematics placement test. The three factors chosen to
have the most influence on mathematics placement test scores are high school GPA,
SAT mathematics score, and final grade in high school algebra II.
The scale used for high school GPA and the final grade in high school algebra II
is 0.0 to 4.0, with 0.0 representing the lowest possible score or an “F”, 1.0
representing a "D", 2.0 representing a "C", 3.0 representing a "B", and 4.0
representing a perfect score or an “A”. The SAT mathematics score serves as a
measurement of a student’s overall mathematical ability. The scale for the SAT
mathematics score ranges from a low of 200 to a high of 800.

4

Neural Network Approach

An artificial neural network represents a connectionist structure whereby information
is implicitly stored within the network connections and the solution is uncovered over
a long series of computations. The neural network used in thi s study is a recurrent
backpropagation network generated using a commercial simulation tool called
BrainMaker Professional [1]. A three-layer feed-forward architecture was chosen: a
three-unit input layer, ten -unit hidden layer, and a four -unit output layer. The first
layer represents the inputs to the network (GPA, SAT, AlgII), and the output layer
represents the classification (appropriate entry-level course). The hidden layers are
purely computational units for the network.
Backpropagation is a supervised learning algorithm, which requires “training”
the neural network. Training is performed using labeled data (data in which the target
outputs are known). Values associated with network connections oscillate until the
network stabilizes (reaches minimum error criteria), at which point the connection
values (weights) are frozen (fixed). This fixed topology is then used to test the

A Comparison of Neural Networks and Classical Discriminant Analysis

955

network against new unseen data representing student records that were not part of the
training set.
In this experiment, the network is trained using data for entry -level college
students grouped according to their performance on the mathematics placement test.
The student’s high school grade point average, SAT mathematics score, and high
school algebra II score are used in the input layer. The output layer consists of four
nodes representing courses in which the student may be placed into by the
mathematics placement exam. A subset of the available data is held out for testing.

5

Classical Approach (Statistical Modeling)

Discriminant analysis is a statistical technique used to classify objects into distinct
groups, based on a set of criteria or characteristics of the objects. Fisher’s Linear
Discriminant Analysis (FLDA) is a favorable classification rule that works well in
situations where the groups to be discriminated are linearly separable. Objects are
grouped according to their discriminant score, which is computed based on the
object’s observed values of the discriminating criteria or characteristics [4].

6

Data Collection

Academic information for students entering Coastal Carolina University from the fall
semester of 1995 to the spring semester of 1997 was obtained through the Office of
Institutional Advancement and used for the first data set. The second data set co nsists
of students entering Coastal Carolina University in the fall of 2000 who took the
computer based placement test. The data was divided into the following categories for
each student: high school grade point average, high school rank, SAT verbal, SA T
mathematics, algebra I, algebra II, geometry, advanced mathematics and mathematics
placement examination scores. All student records with blank fields were deleted
from the study. The first data set is composed of students who were correctly placed
in an entry-level mathematics class using the traditional written instrument. Only
records of students receiving a final grade of "C" or higher were selected. In the
second data set, students with a final grade of "D" or higher were included in the
analysis. The total number of records in the first data set is 458 and the second data set
is 198.

7

Results and Conclusions

Using the first data representing the written placement test, the 458 student records are
randomly ordered and assigned to two equal data partitions. The first partition is used
to train the neural network and to create the discriminant analysis predictive equation.
The second partition is used to test the trained neural network and the predictive
discriminant analysis equation. Both methodol ogies use the overall high school GPA,
the SAT mathematics score, and the final grade in Algebra II as input, and the
mathematics placement result as the dependent variable.

956

S.J. Sheel et al.

The trained neural network correctly places 206 out of the 229 (90.0%) records
in the testing data set when compared to the mathematics placement test. The
predictive equations derived using discriminant analysis correctly places 155 out of
229 (67.7%) records in the testing data set. These experiments reflect a 22.2%
positive difference in classification performance rate of the neural network and
discriminant analysis. This difference represents an improvement of 68.9%, where
improvement is measured by the reduction in classification error (e.g. (74-23)/74), see
Table 1, row 1).
Using a chi-square contingency test, the null hypothesis of independence
between the placement results and the methodology used is rejected. The placement
results reflect a 0.01 level dependency on methodology. Hence, there is not a
significant difference between the mathematics placement test and the trained neural
network. This insignificance implicates the neural network as a valid replacement
candidate for the mathematics placement test, at 90% accuracy.
Table 1. Classification results for comparison methods
# Of
Records

Nnet
Misclass.
Records

Nnet
Class.
Rate

D.A.
Misclass.
Records

D.A.
Class.
Rate

Improvement of
nnet over D.A.
(Misclassification
Reduction)

Experiment
1

229

23

90.0%

74

67.7 %

68.9 %

Experiment
2

99

27

72.7 %

25

74.7 %

- 8.0 %

-

50

81.4 %

99

71.2 %

49.5 %

Average

In a similar manner, a second neural network was created to analyze the student
placement data for the students taking the online computer based mathematics
placement test. The trained neural network correctly places 72 of the 99 (72.7%)
records in the testing data set. The predictive equations derived using discriminant
analysis correctly places 74 of the 99 (74.7%) records. These experiments reflect a
2.0% negative difference in classification performance rate of the neural network and
discriminant analysis, or an 8.0% increase in classification error (see Table 1, row 2).
In this experiment, the results from neither method appear to be significant, and the
dependency on the mathematics placement test is more significant.
The network generated for the first experiment outperformed the discriminant
analysis technique by a significant amount. The network generated for the second
experiment slightly under-performed the discriminant analysis technique, but not by a
significant amount. When averaging the two experiments the results fall clearly in
favor of the neural network, with an average misclassification rate of 81.4%, as
compared to discriminant analysis with an average misclassification rate of 71.2%.
The average improvement in terms of record classification error reduction is 49.5%
(see Table 1, row 3). Due to the degree of difference between training data set sizes,

A Comparison of Neural Networks and Classical Discriminant Analysis

957

one may speculate that the network in the first experiment was able to benefit from a
larger train ing set size. The training size and the train -test split within this problem
domain will be issues left for future research.
The results from these two experiments show that trained neural networks can be
used with a minimal list of input parameters as a tool to effectively place students into
entry-level mathematics courses. Such networks demonstrate an ability to improve
upon discriminant analysis techniques, as shown here by as much as 68.9%. The
neural network in the second data set performed as well as discriminant analysis, but
was not statistically significant to the results of the actual mathematics placement test.
When contrasted to the logistical difficulties of testing, scoring, and reporting the
scores on a paper mathematics placement test, neural network methods also provide
greater temporal efficiency and an opportunity for administrative cost reduction.
Future work will explore the use of NNES ensemble networks [7], and alternative
training methods to increase the performance of neural ne tworks.

References
1. BrainMaker Professional User’s Guide and Reference Manual, 4th Ed., California Scientific
Software, Nevada City, CA (1993)
2. Carbone, V., Piras, G.: “Palomar project: Predicting school renouncing dropouts, using the
artificial neural networks as a support for educational policy decisions”, Substance Use &
Misuse, Vol.33, No.3 (1998) 717-750
3. Cripps, A.: “Predicting grade point average using clustering and ANNs”, Proceedings of
World Congress on Neural Networks [CD-ROM], 486-490. Available: INSPEC Abstract
Number C9807-7110-003 (1996)
4. Guertin, W.H., Bailey, J.P.: Introduction to Modern FACTER ANALYSIS, Ann Arbor, MI:
Edward Brothers, Inc. (1970)
5. Gorr, W. L., Nagin, D., Szczypula, J.: “Comparative study of artificial neural network and
statistical models for predicting student grade point averages” International Journal of
Forecasting, Vol.10, No.2 (1994) 17-34
6. Nelson, C.V., Henriksen, L.W.: “Using neural net technology to enhance the efficiency of a
computer adaptive testing application”, Mid-Western Educational Research Association
Annual Meeting [Microfiche], 1-40. Available: ERIC Number ED387122 (1994)
7. Renner, R.S., Lacher, R.C.: “Combining Constructive Neural Networks for Ensemble
Classification,” Proceedings of the Fifth Joint Conference on Information Sciences (2000)
887-891

8. Wilson, R.L., Hardgrave, B.C.: “Predicting graduate student success in an MBA program:

Regression versus classification”, Educational and Psychological Measurement, vol.55,
No.2 (1995) 186-195

