Active and Logistical Networking for Grid
Computing: The E-toile Architecture
Alessandro Bassi1 , Micah Beck3 , Fabien Chanussot1 , Jean-Patrick Gelas1 ,
Robert Harakaly2 , Laurent Lef`evre1 , Terry Moore3 , James Plank3 , and
Pascale Primet1
1
INRIA / LIP (UMR CRNS, INRIA, ENS, UCB Lyon1)
Ecole Normale Sup´erieure de Lyon - 46, all´ee d’Italie - 69364 LYON Cedex 07 - France
laurent.lefevre@inria.fr, {fabien.chanussot,pascale.primet}@ens-lyon.fr
2
UREC CNRS
Ecole Normale Sup´erieure de Lyon - 46, all´ee d’Italie - 69364 LYON Cedex 07 - France
robert.harakaly@urec.cnrs.fr
3
LoCI Laboratory - University of Tennessee
203 Claxton Building - 37996-3450 Knoxville, TN, USA
{abassi,mbeck,tmoore, plank}@cs.utk.edu

Abstract. While active networks provide new solutions for the deployment of dynamic services in the network by exposing network processing
resources, logistical networks focus on exposing storage resources inside
networks by optimizing the global scheduling of data transport, and data
storage. In this paper, we show how active and logistical environments
working together can improve Grid middleware and provide new and
innovative high-level services for Grid applications1 . We validate and experiment this approach combining the Internet Backplane Protocol2 suite
with the Tamanoir Active Node environment. Our target architecture is
the French e-Toile Grid infrastructure [1] based on high performance
backbone (VTHD) [2].

1

Introduction

The emergence of Grid computing as the ultimate solution for the scientiﬁc
computing community has driven attention and research in the recent past, and
especially since the proliferation of high performance network capabilities. The
common purpose is to aggregate geographically distant machines and to allow
them to work together to solve large problems of any nature.
1

2

This work is supported and carried out within the framework of the RNTL e-Toile
project and the RNRT VTHD++ project. More information on e-Toile project are
available on http://www.urec.cnrs.fr/etoile/
This work is supported by the National Science Foundation Next Generation Software Program under grant # EIA-9975015, the Department of Energy Scientiﬁc Discovery through Advanced Computing Program under grant # DE-FC02-01ER25465,
and the NSF Internet Technologies Program under grant # ANI-9980203.

M. Bubak et al. (Eds.): ICCS 2004, LNCS 3038, pp. 202–209, 2004.
c Springer-Verlag Berlin Heidelberg 2004

Active and Logistical Networking for Grid Computing

203

The optimization of the data transfers within a Grid, which we deﬁne as
High Performance Grid Networking, is the focus of our interest in this area. As
the load, the capacity and the availability of network links used during data
transfers may heavily aﬀect Grid application performances, a fully functional
Grid is dependent on the nature and quality of the underlying network. Appropriate performance, together with a high degree of ﬂexibility, are therefore key
factors of a successful Grid project. One of the important characteristic of the
data transfers within a Grid environment is that the spectrum of exchanged data
volume can spread over 9 orders of magnitude, ranging from few bytes in interactive traﬃc up to terabytes scale bulk data transfer. Requirements in terms of
reliability and delay can also be very heterogeneous.
To introduce our work in this area, and present our research eﬀorts within the
e-Toile [1] grid environment, we would like to step back and reason about some
fundamental characteristic that current network services show. In particular, we
would like to focus the attention on the encapsulation of current network services,
while our approach allows low-level functionalities to be exposed to higher levels.
The architectural design of the e-Toile grid platform, based on a very high
speed network and on active and logistical network technologies, allows the study
of the existing communications limits regarding services and protocols and the
validation of more eﬃcient approaches aiming to carry gigabit performance to
the grid user level and taking into consideration the speciﬁc needs of grid ﬂows;
these goals are achievable through services which are made possible by the exposure of certain equipments’ functionalities. While in the context of the e-Toile
project diﬀerent innovative approaches are explored, such as network performance measurement, diﬀerentiated services evaluation, high performance and
enhanced transport protocols, active networking technology and services and
logistical networking, this paper will focus on the last two aspects.
The paper is organized as follows: in section 2 we will describe our driving
philosophy about network services, while section 3 will focus on the concept of
an active grid. in section 4 we will describe the e-Toile grid platform and active
and logistical deployment on the e-Toile platform (section 5).

2

Exposing Network Services

To the extent that the scientiﬁc computing community is already using the network as a computer, the Internet provides a ubiquitous communication substrate
connecting its components (with routers acting as special-purpose elements invisible in the architecture), while network servers provide all access to storage and
computation. Illustrations of such servers and services are plentiful: FTP, NFS,
and AFS provide access to storage; Condor, NetSolve, Ninf provide lightweight
access to processing; HTTP provides access to both; GRAM provides access to
heavyweight computing resources; LDAP provides access to directory services;
and so on. What is notable about these instances, and is equally true of almost
all the other cases we could add to the list, is that they represent relatively encapsulated network services, where with encapsulated network service we mean

204

A. Bassi et al.

architectures implementing functionalities that do not closely model the underlying network resource, but have to be implemented by aggregating the resource
and/or applying signiﬁcant additional logic in its utilization.
The best eﬀort delivery of datagrams at the IP level, on the other hand, can
be taken as example of a relatively exposed network service. An exposed network
service adds enough additional abstraction to the underlying network resource
to allow it to be utilized at the next higher level, but does not aggregate it
or add logic beyond what is necessary for the most common and indispensable
functionality that uses it.
An important diﬀerence between the two approaches emerges when we need
to extend the functionality of a given service. Encapsulated services tend to be
implemented by heavyweight servers and have APIs designed at a high semantic
level, interposing themselves between the client and low overhead, transparent
access to the underlying resources As a result, it can be diﬃcult, ineﬃcient,
or in some cases impossible to build new functionality on top of such APIs.
Instead, encapsulated services tend to implement new functionality through plug
in modules that extend the functionality of the server, introducing new code that
has access to low level interfaces within the server. These plug-in modules are
the server equivalent of microcode in CISC processors, raising a familiar set of
questions about access control and security for the management of such code.
Extending the functionality of an exposed service makes diﬀerent demands
because exposed services have lighter weight servers and APIs designed at a
simpler semantic level. Since these factors are conducive to low overhead and
more transparent access to the underlying resources, it tends to be much easier
and more eﬃcient to build new functionality on top of exposed services. Exposed
services promote the layering of higher-level functionality on top of their APIs,
either in higher-level servers or in client code. This layering of services, which
is analogous to the user-level scheduling of a RISC processor by a compiler, is
perhaps most familiar in construction of a network services stack.
2.1

Exposing Network Storage Resources: The Internet Backplane
Protocol

Despite the familiarity of the exposed approach for the network services stack,
it may still not be obvious how to apply it to a resource such as storage. After all, almost every technology for the access and/or management of network
storage one can think of (FTP, HTTP, NFS, AFS, HPSS, GASS, SRB, NAS,
etc.) encapsulates the storage behind abstractions with relatively strong semantic properties. For that reason, our research in this area had to start by creating
a protocol, the Internet Backplane Protocol (IBP) [3], that supports the management of remote storage resources while leaving them as exposed as possible.
IBP is a network service that provides an abstraction of shared network storage.
Each IBP server (called also depot) provides access to an underlying storage
resource to any client that connects to the server. In order to enable sharing,
the depot hides details such as disk addresses, and provides a very primitive

Active and Logistical Networking for Grid Computing

205

capability-based mechanism to safeguard the integrity of data stored at the depot. IBP’s low level, low overhead model of storage is designed to allow more
complex structures, such as asynchronous networking primitives and ﬁle and
database systems, to be built on top of the IBP API. This key aspect of the IBP
storage model, the capacity of allocating space on a shared network resource, can
be seen as doing a C-like malloc on an Internet resource, with some outstanding
diﬀerences, such, for instance, time-limitation, to prevent Denial-of-Use attacks.
With IBP in place the question becomes how easy or diﬃcult it is to layer
storage services with strong semantic properties on top of the weak underlying
storage resources provided by IBP depots. Our experience shows that the answer
varies between diﬀerent cases. In some cases (e.g. building a ﬁle abstraction)
earlier models can be followed and the design is relatively straightforward; in
other cases (e.g. point-to-multipoint communication) the inclination to take a
more encapsulated approach remains strong, and the consequently the design
choice is more diﬃcult.
2.2

Exposing Network Processing Resources: Tamanoir

The growing interest in the Active Networking ﬁeld might be seen as a natural consequence of the diﬃculties experienced when integrating into a shared
network infrastructure the existing technologies with new ones. In “active” networking vision, network equipments can perform computations on user data in
transit, therefore exposing their computation capabilities accessible by the end
users by supplying programs called services, that modify the behavior of the
network. These equipments are called active nodes (AN) and show a greater
ﬂexibility towards the deployment of new functionalities, more adapted to the
architecture, the users and the service providers’ requirements. The price to pay
to have this greater ﬂexibility is, generally, an increased attention needed towards
security and performance.
The Tamanoir [4] framework is an high performance active environment
based on active edge routers, able to handle diﬀerent applications and various data stream at the same time. The two main transport protocol, TCP and
UDP, are supported by the Tamanoir Active Node (TAN) for carrying data. One
of the characteristics of Tamanoir is the capacity of making use and exposing
logistical storage for optimizing end-user services requests, especially in terms
of performance. As explained in section 5, each Tamanoir node can take advantage not only of IBP depot located on the same node, but also with any depot
participating in backbones such as the Logistical Backbone.

3

Concepts of an Active Grid

Our attention towards an active grid paradigm was driven by the complains of
Grid application designers about standard network characteristics, such as reliable packet transport between nodes using the TCP/IP protocol suite, not being
suited for typical Grid applications. The active grid architecture we envision is

206

A. Bassi et al.

based on a virtual topology of active network nodes spread on programmable
routers of the network. Active routers are deployed on network periphery, and
allow data stream processing and storage, either in an explicit way (following a
request by the application) or encapsulated one. Considering that the future of
WAN backbones lies on all-optical equipment, we concentrate active operations
on routers and nodes mapped at network periphery.
Active nodes are connected between each other and each AN manages communications for a small subset of Grid nodes. Grid data streams cross the active
layer twice, before and after passing through the passive backbone.
3.1

Active Network Beneﬁts for Grid Applications

The communications needs of Grid applications can be improved by the use of an
Active Grid architecture, in the following areas: application deployment (needs
of active reliable multicast), Grid management and support, wide-area parallel
processing (needs of QoS and data conversion services. . . ).
Most of services needed by Grid environments, such as high performance
transport, dynamic topology adapting, QoS, on-the-ﬂy data compression, data
encryption, data multicast, data conversion, and errors management can be easily and eﬃciently deployed on demand with an Active Grid architecture.
3.2

Active Grid Architecture

To support most Grid applications, an Active Grid architecture have to deal with
the two main Grid conﬁgurations, Meta Cluster Computing and Global Computing. In the ﬁrst case, where the conﬁguration shows an high level of coupling,
an active node is mapped on network head of each cluster or parallel machine.
This node manage all data streams coming or leaving a cluster. All active nodes
are linked with other AN mapped at backbone periphery. An Active node delivers data streams to each node of a cluster and can aggregate output streams to
others clusters of the Grid. In the second one, characterized by a loosely coupled
conﬁguration, an AN can be associated with each Grid node or can manage a set
of aggregated Grid nodes. Hierarchies of active nodes can be deployed at each
network heterogeneity point. Each AN manages all operations and data streams
coming to Grid Nodes, such as subscribing operations of voluntary machines,
results gathering, nodes synchronization or checkpointing. For both conﬁgurations, active nodes could manage the Grid environment by deploying dedicated
services adapted to Grid requirements : management of nodes mobility, dynamic
topology re-conﬁguration, fault tolerance.

4

The E-toile Grid Platform

The e-Toile project, funded by the French Ministry of Research in the realm of
the RNTL (R´eseau National des Technologies Logicielles) [5] initiative, focuses
on three complementary objectives:

Active and Logistical Networking for Grid Computing

207

– to build an experimental high performance grid platform that scales to
nation-wide needs and geographical distribution, providing an high performance network and software support for the ACI-GRID [6] initiative
– to develop original Grid services in order to go beyond the various limits of
existing middleware and to exploit completely the services and capacities offered by a very high performance network. The e-Toile middleware integrates
the most recent and relevant works of the French computer science laboratories (INRIA, CNRS) on the area of advanced communication services.
– to evaluate the deployment cost of chosen computing intensive and dataintensive applications and to measure the gain obtained thanks to the grid.
The partners of the project, providing various resources (clusters, storage
space. . . ) and federating the available tools in an integrated plate-form, are
INRIA (Reso, Remap, Apache, Paris), CNRS (PRISM, IBCP), Communication
& Systems, SUN Labs Europe, EDF (Electricite De France, French Electricity
Board) and CEA (Atomic Energy Center).
The e-Toile middleware relies upon existing middleware, in particular Globus
and the Sun Grid Engine, and integrates independent building blocks developed
in the context of ACI-GRID. The most innovative grid components are in the
areas of grid services (in terms of resource allocation), performance measurement,
security, communication paradigms, distributed storage and active networking.
The ﬁgure 1 represents the architecture of the testbed with the resources
currently interconnected. The platform is composed by two distinct testbed:

Fig. 1. Physical Architecture of the e-Toile grid

208

A. Bassi et al.

a development testbed in order to allow testing of new middleware component
and a production one for grid applications. The VTHD (Vraiment Tr´es Haut
D´ebit) [2] network infrastructure interconnects the grid nodes with 1 or 2 Gbps
links. This existing french high performance research backbone has been extended to all participant sites.
Network monitoring and performance measurement tools, developed by INRIA and CNRS within the European DataGRID project are deployed in e-Toile.
The MapCenter [7] Grid status visualization tool permit users and managers to
visualize the available resources in real time and services.
One of the original aim of the e-Toile project is to focus on the High Performance Grid Networking dimension and to evaluate the beneﬁts grid middleware
and grid application can extract from enhanced networking technology. The performance problem of the grid network can be studied from diﬀerent point of view:
– Measuring and monitoring the end-to-end performances helps to characterize
the links and the network behaviour. Network cost functions and forecasts,
based on such measurement information, allow the upper abstraction level
to build optimization and adaptation algorithms.
– Evaluating the advantages of diﬀerentiated services (Premium or Less than
Assured Services) oﬀered by the network infrastructure for speciﬁc streams.
– Creating enhanced and programmable transport protocols to optimize heterogeneous data transfers within the grid.

5

Active and Logistical Resource Deployment in E-toile

Logistical and active networking equipments are currently deployed in the e-Toile
architecture. Each service willing to use logistical storage has to instantiate its
own IBP client classes in order to communicate with an IBP depot. These classes
provide constructors and methods to create capabilities on any IBP depot, with
whom the Tamanoir service can write, read and manage data remotely on the
IBP depot.
A ﬁrst and very basic TAN service, called IBP Service uses a IBP store
operation to redirect the beginning of a data stream towards the IBP depot.
The IBP service checks as well the presence of the required service each time
that a new packet arrive, and if so, a IBP load operation is done to redirect
all the data cached in the IBP depot towards the service able to process, route
and forward eﬃciently these data. The only diﬀerence between the IBP Service
and any other service lies in the load-time, which is done at boot time for the
IBP Service, in order to be able to cache data immediately.
The use of IBP depot on each TAN should allow the storage of data to
provide reliability through redundancy. If data are replicated on diﬀerent server
and one of them become either out of order or unreachable, data should still be
downloadable from another server transparently.
Explicit routing and optimized scheduling are also possible through logistical
active nodes. Several experiments made by the IBP team show that, in order to
transmit as fast as possible huge amount of data, the path chosen by ”classic”

Active and Logistical Networking for Grid Computing

209

routers might show well below performance than the optimal one. Adding a
staging point in the middle of two fast connections, knowing the topology of
the underlying network, often improves performance dramatically. Unfortunately
current transport protocols encapsulate the path, oﬀering an end-to-end service
that is not well adapted to the performance needs a grid application often has.
A Tamanoir service, upon reception of a data stream, could store the stream on
a number of diﬀerent depots, participating in directories such as the Logistical
Backbone (L-Bone), optimizing the total transfer time explicitly routing the data
packets towards faster connections, and staging data in middle points at the
boundaries of high-speed connections. We run several experiments mixing active
and logistical equipment, and the latency measured [8] for packet caching of an
active stream shows a very small overhead.In case of a change in the application
scheduling, data stored at those intermediate nodes could be re-routed towards
the new processing node in a much more eﬃcient way.

6

Conclusions and Future Works

A grid, empowered with active and logistical networking, can not only improve
signiﬁcantly its global performances, but also and foremost provide new and
innovative services to grid applications and middleware, giving an easy and direct
control over high level services, such as reliable multicast and active QoS.
In addition to the technical challenges outlined in this article, the direction
of our research is towards the integration of our active and logistical technologies
with existing middleware, such as Globus and the Sun Grid Engine, giving them
the ability to encapsulate active and logistical technologies for their internal
needs, and to expose active and logistical services to upper layer’s applications.
Our plan is also to integrate these technologies further, especially adding
active and intelligent services to the logistical layer in ﬁelds such as eﬃcient
and reliable data deployment for the grid. IBP depots, through the Data Mover
(DM) plug-in module, by sending a request to a Tamanoir Active Node could
take advantage of any active services and could improve data transport.

References
1. RNTL e-Toile French Grid Project - http://www.urec.cnrs.fr/etoile.
2. Very high broadband RNRT VTHD project: (http://www.vthd.org)
3. Beck, M., Moore, T., Plank, J.: An end-to-end approach to globally scalable network
storage. In: ACM SIGCOMM 20002 Conference, Pittsburgh, PA, USA. (2002)
4. Gelas, J.P., El Hadri, S., Lef`evre, L.: Towards the design of an high performance
active node. Parallel Processing Letters 13 (2003)
5. RNTL: (http://www.industrie.gouv.fr/rntl)
6. ACI Grid initiative: (Initiative of french ministry of research for globalisation of
computer resources and data - http://www-sop.inria.fr/aci/grid/public/)
7. MapCenter Grid visualization tool: (http://ccwp7.in2p3.fr/mapcenter/)
8. Bassi, A., Gelas, J.P., Lef`evre, L.: Tamanoir-IBP: Adding Storage to Active Networks. In: Active Middleware Services, Edinburgh, Scotland, IEEE computer society
(2002) 27–34 ISBN: 0-7695-1721-8.

