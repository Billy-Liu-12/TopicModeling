Localized Ensemble Kalman Dynamic
Data Assimilation for Atmospheric Chemistry
Adrian Sandu1 , Emil M. Constantinescu1 , Gregory R. Carmichael2 ,
aescu4
Tianfeng Chai2 , John H. Seinfeld3 , and Dacian D˘
1

Department of Computer Science, Virginia Polytechnic Institute and State
University, Blacksburg, VA 24061.
{asandu, emconsta}@cs.vt.edu
2
Center for Global and Regional Environmental Research, The University of Iowa,
Iowa City, 52242-1297.
{gcarmich,tchai}@cgrer.uiowa.edu
3
Department of Chemical Engineering, California Institute of Technology, Pasadena,
CA 91125.
seinfeld@caltech.edu
4
Department of Mathematics and Statistics, Portland State University.
daescu@pdx.edu
Abstract. The task of providing an optimal analysis of the state of
the atmosphere requires the development of dynamic data-driven systems (DDDAS) that eﬃciently integrate the observational data and the
models. Data assimilation, the dynamic incorporation of additional data
into an executing application, is an essential DDDAS concept with wide
applicability. In this paper we discuss practical aspects of nonlinear ensemble Kalman data assimilation applied to atmospheric chemical transport models. We highlight the challenges encountered in this approach
such as ﬁlter divergence and spurious corrections, and propose solutions
to overcome them, such as background covariance inﬂation and ﬁlter
localization. The predictability is further improved by including model
parameters in the assimilation process. Results for a large scale simulation of air pollution in North-East United States illustrate the potential
of nonlinear ensemble techniques to assimilate chemical observations.

1

Introduction

Our ability to anticipate and manage changes in atmospheric pollutant concentrations relies on an accurate representation of the chemical state of the
atmosphere. As our fundamental understanding of atmospheric chemistry advances, novel data assimilation tools are needed to integrate observational data
and models together to provide the best estimate of the evolving chemical state
of the atmosphere. The ability to dynamically incorporate additional data into
an executing application is a fundamental DDDAS concept (http://www.cise.
nsf.gov/dddas.) We refer to this process as data assimilation. Data assimilation
has proved vital for meteorological forecasting.
This work was supported by the National Science Foundation through the award
NSF ITR AP&IM 0205198 managed by Dr. Frederica Darema.
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 1018–1025, 2007.
c Springer-Verlag Berlin Heidelberg 2007

Localized Ensemble Kalman Dynamic Data Assimilation

1019

In this paper we focus on the particular challenges that arise in the application
of nonlinear ensemble ﬁlter data assimilation to atmospheric chemical transport
models (CTMs). Atmospheric CTMs solve the mass-balance equations for concentrations of trace species to determine the fate of pollutants in the atmosphere
[16]. The CTM operator, M, will be denoted compactly as
ci = Mti−1 →ti ci−1 , ui−1 , cin
i−1 , Qi−1 ,

(1)

where c represents the modeled species concentration, cin the inﬂow numerical
boundary conditions, u the wind ﬁelds, Q the surface emission rates, and the
subscript denotes the time index. In our numerical experiments, we use the Sulfur
Transport Eulerian Model (STEM) [16], a state-of-the-art atmospheric CTM.
Kalman ﬁlters [12] provide a stochastic approach to the data assimilation
problem. The ﬁltering theory is described in Jazwinski [10] and the applications
to atmospheric modeling in [13]. The computational burden associated with
the ﬁltering process has prevented the implementation of the full Kalman ﬁlter
for large-scale models. Ensemble Kalman ﬁlters (EnKF) [2,5] may be used to
facilitate the practical implementation as shown by van Loon et al. [18]. There
are two major diﬃculties that arise in EnKF data assimilation applied to CTMs:
(1) CTMs have stiﬀ components [15] that cause the ﬁlter to diverge [7] due to the
lack of ensemble spread and (2) the ensemble size is typically small in order to
be computationally tractable and this leads to ﬁlter spurious corrections due to
sampling errors. Kalman ﬁlter data assimilation has been discussed for DDDAS
in another context by Jun and Bernstein [11].
This paper addresses the following issues: (1) Background covariance inﬂation
is investigated in order to avoid ﬁlter divergence, (2) localization is used to prevent spurious ﬁlter corrections caused by small ensembles, and (3) parameters
are assimilated together with the model states in order to reduce the model errors
and improve the forecast. The paper is organized as follows. Section 2 presents
the ensemble Kalman data assimilation technique, Section 3 illustrates the use
of the tools in a data assimilation test, and Section 4 summarizes our results.

2

Ensemble Kalman Filter Data Assimilation

Consider a nonlinear model ci = Mt0 →ti (c0 ) that advances the state from the
initial time t0 to future times ti (i ≥ 1). The model state ci at ti (i ≥ 0) is
an approximation of “true” state of the system cti at ti (more exactly cti is the
system state projected onto the model space space). Observations yi are available
at times ti and are corrupted by measurement and representativeness errors εi
(assumed Gaussian with mean zero and covariance Ri ), yi = Hi cti + εi . Here
Hi is an operator that maps the model state to observations.
The data assimilation problem is to ﬁnd an optimal estimate of the state using
both the information from the model (ci ) and from the observations (yi ).
The (ensemble) Kalman ﬁlter estimates the true state ct using the information
from the current best estimate cf (the “forecast” or the background state) and
the observations y. The optimal estimate ca (the “analysis” state) is obtained as

1020

A. Sandu et al.

a linear combination of the forecast and observations that minimize the variance
of the analysis (P a )
ca = cf + P f H T HP f H T + R

−1

y − H(cf ) = cf + K y − H(cf ) . (2)

The forecast covariance P f is estimated from an ensemble of runs (which produces an ensemble of E model states cf (e), e = 1, · · · , E). The analysis formula
(2) is applied to each member to obtain an analyzed ensemble. The model advances the solution from ti−1 to ti , then the ﬁlter formula is used to incorporate
the observations at ti . The ﬁlter can be described as
cfi (e) = M cai−1 (e) , cai (e) = cfi (e) + Ki yi − Hi cfi (e)

.

(3)

The results presented in this paper are obtained with the practical EnKF implementation discussed by Evensen [5].
2.1

The Localization of EnKF (LEnKF)

The practical Kalman ﬁlter implementation employs a small ensemble of Monte
Carlo simulations in order to approximate the background covariance (P f ). In
its initial formulation, EnKF may suﬀer from spurious correlations caused by
sub-sampling errors in the background covariance estimates. This allows for
observations to incorrectly impact remote model states. The ﬁlter localization
introduces a restriction on the correction magnitude based on its remoteness.
One way to impose localization in EnKF is to apply a decorrelation function
ρ, that decreases with distance, to the background covariance. Following [8], the
EnKF relation (2) with some simplifying assumptions becomes
cai = cfi + ρ(Dc ) ◦ Pif HiT ρ(Dy ) ◦ Hi Pif HiT + Ri

−1

yi − Hi (cfi ) , (4)

where D{c,y} are distance matrices with positive elements (di,j ≥ 0), and 0 ≤
ρ(di,j ) ≤ 1, ρ(0) = 1, ∀i, j. The decorrelation function ρ is applied to the distance
matrix and produces a decorrelation matrix (decreasing with the distance). The
operation ‘◦’ denotes the Schur product that applies elementwise ρ(D) to the
projected covariance matrices P f H T and H P f H T , respectively. Here, Dy is
calculated as the distance among the observation sites, and Dc contains the
distance from each state variable to each observation site.
We considered a Gaussian distribution for the decorrelation function, ρ. Since
our model generally has an anisotropic horizontal–vertical ﬂow, we consider the
two correlation components (and factors, δ) separately:
ρ Dh , Dv = exp − Dh /δ h

2

2

− (Dv /δ v )

,

(5)

where Dh , Dv , δ h , δ v are the horizontal and vertical components. The horizontal
correlation-distance relationship is determined through the NMC method [14].
The horizontal NMC determined correlations were ﬁtted with a Gaussian distribution, δ h = 270 km. The vertical correlation was chosen as δ v = 5 grid points.

Localized Ensemble Kalman Dynamic Data Assimilation

2.2

1021

Preventing Filter Divergence

The “textbook application” of EnKF [5] may lead to ﬁlter divergence [7]: EnKF
shows a decreasing ability to correct ensemble states toward the observations.
This is due to an underestimation of the model error covariance magnitude
during the integration. The ﬁlter becomes “too conﬁdent” in the model and
“ignores” the observations in the analysis process. The solution is to increase
the covariance of the ensemble and therefore decrease the ﬁlter’s conﬁdence in
the model. The following are several ways to “inﬂate” the ensemble covariance.
The ﬁrst method is the additive inﬂation [4], where the model errors are simulated by adding uncorrelated noise (denoted by η) to the model (η− ) or analysis
(η+ ) results. This increases the diagonal entries of the ensemble covariance. Since
the correlation of the model errors is to a large extent unknown, white noise is
typically chosen. With the notation (3), cfi (e) = M cai−1 (e) + η− (e) + η+ (e).
The second method is the multiplicative inﬂation [1], where each member’s deviation from the ensemble mean is multiplied by a constant (γ > 1). This increases each entry of the ensemble covariance by that constant squared (γ 2 ).
{f /a}
The ensemble can be inﬂated before (γ{−} ) or after (γ{+} ) ﬁltering: ci
(e) ←
{f /a}
+ γ{−/+} , where · denotes the ensemble average.
ci
A third possibility for covariance inﬂation is through perturbations applied
to key model parameters, and we refer to it as model-speciﬁc inﬂation. This
approach focuses on sources of uncertainty that are speciﬁc to each model (for
instance in CTMs: boundary conditions, emissions, and meteorological ﬁelds).
With the notation (3) and considering p as a set of model parameters, the modelspeciﬁc inﬂation can be written as cfi (e) = M cai−1 (e), αi−1 (e) pi−1 , where α(e)
are random perturbation factors of the model parameters.
2.3

Inﬂation Localization

The traditional approach to covariance inﬂation increases the spread of the ensemble equally throughout the computational domain. In the LEnKF framework,
the corrections are restricted to a region that is rich in observations. These states
are corrected and their variance is reduced, while the remote states (i.e., the
states that are relatively far from the observations’ locations) maintain their
initial variation which is potentially reduced only by the model evolution. The
spread of the ensemble at the remote states may be increased to unreasonably
large values through successive inﬂation steps. And thus, the covariance inﬂation
needs to be restricted in order to avoid the over-inﬂation of the remote states.
A sensible inﬂation restriction can be based on the localization operator, ρ(D),
which is applied in the same way as for the covariance localization. The localized
multiplicative inﬂation factor, γ , is given by
γ (i, j, k) = max {ρ (Dc (i, j, k))} (γ − 1) + 1 ,

(6)

where γ is the (non-localized) multiplicative inﬂation factor and i, j, k refer to
the spatial coordinates. In this way, the localized inﬂation increases the ensemble
spread only in the information-rich regions where ﬁlter divergence can occur.

1022

3

A. Sandu et al.

Numerical Results

° Latitude N

The test case is a real-life simulation of air pollution in North–Eastern U.S. in
July 2004 as shown in Figure 1.a (the dash-dotted line delimits the domain).
The observations used for data assimilation are the ground-level ozone (O3 )
measurements taken during the ICARTT [9,17] campaign in 2004 (which also
includes the initial concentrations, meteorological ﬁelds, boundary values, and
emission rates). Figure 1.a shows the location of the ground stations (340 in
total) that measured ozone concentrations and an ozonesonde (not used in the
assimilation process). The computational domain covers 1500 × 1320 × 20 Km
with a horizontal resolution of 60 × 60 Km and a variable vertical resolution.
The simulations are started at 0 GMT
July 20th with a four hour initialization
48
step ([-4,0] hours). The “best guess” of the
46
state of the atmosphere at 0 GMT July 20th
44
S
is used to initialize the deterministic so42
lution. The ensemble members are formed
40
by adding a set of unbiased perturbations
38
to the best guess, and then evolving each
36
member to 4 GMT July 20th . The pertur34
−85
−80
−75
−70
−65
bation is formed according to an AR model
° Longitude W
[3] making it ﬂow dependent. The 24 hours
assimilation window starts at 4 GMT July Fig. 1. Ground measuring stations in
20th (denoted by [1,24] hours). Observa- support of the ICARTT campaign
tions are available at each integer hour in (340 in total) and the ozonesonde (S)
this window, i.e., at 1, 2, . . ., 24 hours (Fig- launch location
ure 1.a). EnKF adjusts the concentration
ﬁelds of 66 “control” chemical species in each grid point of the domain every
hour using (2). The ensemble size was chosen to be 50 members (a typical size
in NWP). A 24 hour forecast window is also considered to start at 4 GMT July
21st (denoted by [24,48] hours).
The performance of each data assimilation experiment is measured by the R2
correlation factor (correlation2 ) between the observation and the model solution.
The R2 correlation results between the observations and model values for all the
numerical experiments are shown in Table 1. The deterministic (best guess)
solution yields an R2 of 0.24 in the analysis and 0.28 in the forecast windows.
In Table 1 we also show the results for a 4D-Var experiment.
Figure 2.a shows the O3 concentration measured at a Washington DC station
and predicted by the EnKF and LEnKF with model-speciﬁc inﬂation. Figure 2.b
shows the ozone concentration proﬁle measured by the ozonesonde for the EnKF
and LEnKF with additive inﬂation. Two eﬀects are clear for the “textbook”
EnKF. The ﬁlter diverges after about 12 hours (2.a), and spurious corrections
are made at higher altitudes (2.b), as the distance from the observation (ground)
sites increases. The vertical proﬁle in Figure 2.b shows great improvement in the
analyzed solution of LEnKF. The results in Table 1 conﬁrm the beneﬁts of
localization by dramatically improving the analysis and forecast ﬁt.

Localized Ensemble Kalman Dynamic Data Assimilation

1023

Table 1. The R2 measure of model-observations match in the assimilation and forecast
windows for EnKF, 4D-Var, and LEnKF. (Multiplicative inﬂation: γ− ≤ 4, γ+ ≤ 4;
Model-speciﬁc inﬂation: 10% emissions, 10% boundaries, 3% wind).
R2
R2
analysis forecast
Deterministic solution, no assimilation
0.24
0.28
EnKF, “textbook application”
0.38
0.30
4D-Var - 50 iterations
0.52
0.29
LEnKF, model-speciﬁc inﬂation
0.88
0.32
LEnKF, multiplicative inﬂation
0.82
0.32
LEnKF, additive inﬂation
0.92
0.31
LEnKF with parameter assimilation, and 0.89
0.41
multiplicative localized inﬂation
Method & Details

Observations
Deterministic
EnKF
LEnKF

O3 [ppbv]

80

20
Height [grid points]

100

60
40
20
0
−4 1

24
Time [Hours]
60

80

46

46

44

44

42
40

150

38
36

(c) EnKF “Textbook application”

60

80

100 [ppbv]

40

36
−65

40

42

38

−75
−70
° Longitude W

100
O3 [ppbv]

20
48

−80

50

(b) Ozonesonde concentration proﬁle
100 [ppbv]

48

34
−85

5
0

° Latitude N

° Latitude N

40

Observations
Deterministic
EnKF
LEnKF

10

48

(a) Ozone concentration
20

15

34
−85

−80

−75
−70
° Longitude W

−65

(d) LEnKF Multiplicative inﬂation

Fig. 2. Ozone concentration (a) measured at a Washington DC station (ICARTT ID:
510590030) and predicted by EnKF (“textbook”) and LEnKF with model-speciﬁc inﬂation, and (b) measured by the ozonesonde for EnKF and LEnKF. Ground level ozone
concentration ﬁeld (c,d) at 14 EDT in the forecast window measured by the ICARTT
stations (shown in color coded ﬁlled circles) and predicted EnKF and LEnKF.

1024

3.1

A. Sandu et al.

Joint State and Parameter Assimilation

In regional CTMs the inﬂuence of the initial conditions is rapidly diminishing
with time, and the concentration ﬁelds are “driven” by emissions and by lateral
boundary conditions. Since both of them are generally poorly known, it is of considerable interest to improve their values using information from observations.
In this setting we have to solve a joint state-parameter assimilation problem [6].
The emission rates and lateral boundary conditions are multiplied by speciﬁc
correction coeﬃcients, α. These correction coeﬃcients are appended to the model
state. The LEnKF data assimilation is then carried out with the augmented
model state. With the notation (1), LEnKF is applied to
{1,2}

cfi αi

T

{2}
in
= Mti−1 →ti cai−1 , ui−1 , α{1}
i−1 ci−1 , αi−1 Qi−1

T

αi−1

.

For α, we consider a diﬀerent correction for each species and each gridpoint. The
initial ensemble of correction factors is an independent set of normal variables
and the localization is done in the same way as in the state-only case.
The R2 after LEnKF data assimilation for combined state and emission correction coeﬃcients (presented in Table 1) show improvements in both the forecast
and the analysis windows. Figures 2.(c,d) show the ground level ozone ﬁeld concentration at 14 EDT in the forecast window measured by the ICARTT stations,
EnKF with state corrections and LEnKF with joint state-parameter corrections.
In the LEnKF case under consideration the addition of the correction parameters to the assimilation process improves the assimilated solution (especially on
the inﬂow boundary (West)).

4

Conclusions

This paper discusses some of the challenges associated with the application of
nonlinear ensemble ﬁltering data assimilation to atmospheric CTMs. Three aspects are analyzed in this study: ﬁlter divergence - CTMs tend to dampen perturbations; spurious corrections - small ensemble size cause wrong increments, and
model parametrization errors - without correcting model errors in the analysis,
correcting the state only does not help in improving the forecast accuracy.
Experiments showed that the ﬁlter diverges quickly. The inﬂuence of the initial conditions fades in time as the ﬁelds are largely determined by emissions and
by lateral boundary conditions. Consequently, the initial spread of the ensemble
is diminished in time. Moreover, stiﬀ systems (like chemistry) are stable - small
perturbations are damped out quickly in time. In order to prevent ﬁlter divergence, the spread of the ensemble needs to be explicitly increased. We
investigated three approaches to ensemble covariance inﬂation among which
model-speciﬁc inﬂation is the most intuitive. The “localization” of EnKF is
needed in order to avoid the spurious corrections noticed in the “textbook” application. The correlation distances are approximated using the NMC method.
Furthermore, covariance localization prevents over-inﬂation of the states that are

Localized Ensemble Kalman Dynamic Data Assimilation

1025

remote from observation. LEnKF increased both the accuracy of the analysis and
forecast at the observation sites and at distant locations (from the observations).
Since the solution of a regional CTM is largely inﬂuenced by uncertain lateral
boundary conditions and by uncertain emissions it is of great importance to
adjust these parameters through data assimilation. The assimilation of emissions
and boundary conditions visibly improves the quality of the analysis.

References
1. J.L. Anderson. An ensemble adjustment Kalman ﬁlter for data assimilation. Mon.
Wea. Rev, 129:2884–2903, 2001.
2. G. Burgers, P.J. van Leeuwen, and G. Evensen. Analysis scheme in the ensemble
Kalman Filter . Mon. Wea. Rev, 126:1719–1724, 1998.
3. E.M. Constantinescu, T. Chai, A. Sandu, and G.R. Carmichael. Autoregressive
models of background errors for chemical data assimilation. To appear in J. Geophys. Res., 2006.
4. M. Corazza, E. Kalnay, and D. Patil. Use of the breeding technique to estimate the
shape of the analysis “errors of the day”. Nonl. Pr. Geophys., 10:233–243, 2002.
5. G. Evensen. The ensemble Kalman ﬁlter: theoretical formulation and practical
implementation. Ocean Dynamics, 53, 2003.
6. G. Evensen. The combined parameter and state estimation problem. Submitted to
Ocean Dynamics, 2005.
7. P.L. Houtekamer and H.L. Mitchell. Data assimilation using an ensemble Kalman
ﬁlter technique . Mon. Wea. Rev, 126:796–811, 1998.
8. P.L. Houtekamer and H.L. Mitchell. A sequential ensemble Kalman ﬁlter for atmospheric data assimilation . Mon. Wea. Rev, 129:123–137, 2001.
9. ICARTT. ICARTT home page:http://www.al.noaa.gov/ICARTT .
10. A.H. Jazwinski. Stochastic Processes and Filtering Theory. Academic Press, 1970.
11. B.-E. Jun and D.S. Bernstein Least-correlation estimates for errors-in-variables
models . Int’l J. Adaptive Control and Signal Processing, 20(7):337–351, 2006.
12. R.E. Kalman. A new approach to linear ﬁltering and prediction problems. Trans.
ASME, Ser. D: J. Basic Eng., 83:95–108, 1960.
13. R. Menard, S.E. Cohn, L.-P. Chang, and P.M. Lyster. Stratospheric assimilation
of chemical tracer observations using a Kalman ﬁlter. Part I: Formulation. Mon.
Wea. Rev, 128:2654–2671, 2000.
14. D.F. Parrish and J.C. Derber. The national meteorological center’s spectral
statistical-interpolation analysis system. Mon. Wea. Rev, (120):1747–1763, 1992.
15. A. Sandu, J.G. Blom, E. Spee, J.G. Verwer, F.A. Potra, and G.R. Carmichael.
Benchmarking stiﬀ ODE solvers for atmospheric chemistry equations II - Rosenbrock solvers. Atm. Env., 31:3,459–3,472, 1997.
16. A. Sandu, D. Daescu, G.R. Carmichael, and T. Chai. Adjoint sensitivity analysis
of regional air quality models. J. of Comp. Phy., 204:222–252, 2005.
17. Y. Tang et al. The inﬂuence of lateral and top boundary conditions on regional
air quality prediction: a multi-scale study coupling regional and global chemical
transport models. Submitted to J. Geophys. Res., 2006.
18. M. van Loon, P.J.H. Builtjes, and A.J. Segers. Data assimilation of ozone in the
atmospheric transport chemistry model LOTOS. Env. Model. and Soft., 15:603–
609, 2000.

