A Novel Navigation Algorithm for Locomotion Interfaces
with Programmable Platforms
Jungwon Yoon1 and Jeha Ryu2
1

School of Mechanical and Aerospace Engineering and ReCAPT,
Gyeongsang National University, Jinju, Gyeongnam 660-701, Korea
jwyoon@gsnu.ac.kr
2
Human-Machine-Computer Interface Laboratory, Department of Mechatronics,
Gwangju Institute of Science and Technology, Bukgu, Gwangju 500-712, Korea
ryu@gist.ac.kr

Abstract. This paper describes a novel navigation algorithm using a locomotion
interface with two 6-DOF parallel robotic manipulators. The suggested novel
navigation system can induce user's real walking and generate realistic visual
feedback during navigation, using robotic manipulators. For realistic visual
feedback, the virtual environment is designed with three components; 3D object
modeler for buildings and terrains, scene manager and communication manager
component. The walking velocity of the user is directly translated to VR actions
for navigation. Finally, the functions of the RPC interface are utilized for each
interaction mode. The suggested navigation system can allow a user to explore
into various virtual terrains with real walking and realistic visual feedback.

1 Introduction
The sense of distance or orientation while walking is much better than that while
riding in a vehicle for locomotion for virtual environments. Therefore, the proprioceptive feedback of walking will enhance user’s immersion in most applications of virtual environments. A locomotion interface (LI) is an input-output device to simulate
walking interactions with virtual environments without restricting human mobility in
a confined space such as a room [1]. Fig. 1 shows the overall diagram for navigation
with the LI in virtual environments, which are generated by a computer. When a
human walks on the LI, the walking motions of the human are recognized by several
sensors. Then, the LI utilizes the sensed information to generate infinite surfaces for
continuous walking. Also, the sensed information will be transferred to virtual environments for scene update according to motions of the human walking. Finally, a
human can immerse into virtual environments by feedback of visual and locomotion
information.
Recently, programmable foot platforms [2-3] with robotic devices are suggested to
simulate even and uneven omni-directional surfaces that are required for locomotive
interactions in diverse virtual environments. Even though programmable foot platform devices can ideally simulate various terrains for natural walking, there are very
few experimental reports for the programmable foot prototypes with real waking
except Gait Master [2]. For allowing user’s continuous walking with the limited
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part II, LNCS 3992, pp. 610 – 617, 2006.
© Springer-Verlag Berlin Heidelberg 2006

A Novel Navigation Algorithm for Locomotion Interfaces

611

workspace of the interface, Iwata [2] suggested the principal of cancellation: while
one platform will follow one foot during the swing phase, the other platform will
move back the other foot. However, there are no general algorithms for navigation of
locomotion interface using robotic manipulators. Therefore, it is necessary to develop
a generalized navigation control algorithm that allows a user to interact with virtual
environments while walking over various terrains using 6-dof programmable devices.
In this paper, control and navigation algorithms that can allow continuous walking
over various terrains using the proposed interface are developed.
Visual feedback

Human

Ground
generation

Walk
or Run

Virtual
Walking
Machine
Human foot motions

Virtual
Environments
Human foot & body
motions

Motion
Sensing
Fig. 1. Navigation using a virtual walking machine

2 Locomotion Interface
2.1 Overview
The suggested locomotion interface is composed of two planar devices on which two
footpad devices are mounted. The planar device [4] is planar parallel manipulator
that is composed of a platform and three limbs, each of which has three serial revolute
joints (RRR) with the actuated first joint. The 3-dof footpad device [5] is composed of
platform, and two limbs. The footpad device can generate pitch, roll, and heave motions at the platform.

Fig. 2. The locomotion Interface with programmable foot platforms

Fig. 2 shows the structure of the proposed locomotion interface which is based on
thorough understanding of the human gait. The user standing on the interface can

612

J. Yoon and J. Ryu

walk and interact with the virtual environment while wearing a Head Mount Display
(HMD), or watching big display screen. The position and orientation of a human foot
can be measured using a Polhemus 3D magnetic tracker, which is tightly connected to
the shoe so that it should precisely trace the foot motion without delay.

3 Walking Control Algorithm
The locomotion interface control system should enable a user to walk smoothly and
continuously in a confined area. Thus, the control algorithm should be designed to
keep the position of the human at a neutral position during walking.
3.1 New Cancellation Method
For a single normal gait cycle, the stance phase accounts for approximately 60 percent, while the swing phase accounts for approximately 40 percent. It should be noted
however that a double support phase exists during which both limbs are in contact
with the ground. During this phase, the body's center of gravity is at its lowest position. These double supports happen during initial 10% and final 10% of stance phase.
Therefore, we suggest new cancellations method, in which the walking motions consider double stance phase. Thus, each platform will follow the magnetic tracker attached to a foot during swing phase when human foot is moving forward without
contacting any object, while the other platform will move back during single stance
phase when only one foot is in contact with ground. If two feet are in contact with the
platforms, the two platforms will keep their current positions. The transitions between
swing and stance phase are detected by using switch sensor system exerted by the
human foot.
Walking Simulation
Walking

θ C = θ slope

Sensing GRF at two
platforms

GRF (Left)
≥ threshod

No

φc = φ slope
No

Yes
Left Stance &
Right Swing

Following Right Platform
&
Moving Back Left Platform

Calculate zC
with cancellation method

GRF (Right)
≥ threshod

Yes

Double Stance

Sustain Two platforms

Right Stance &
Left Swing

zC ≤ H threshold

Following Left Platform
&
Moving back Right Platform

No

zC = H threshold

Yes

zC

Control Action for Footpad Devices
Control Actions

End

Fig. 3. New cancellation method

end

Fig. 4. Walking algorithm for spatial motions

Fig. 3 shows the block diagram of the proposed cancellation method. The proposed cancellation algorithm can allow a user to stop and start naturally according to
user’s intentions because of the added double support phases. Therefore, this

A Novel Navigation Algorithm for Locomotion Interfaces

613

algorithm will allow more natural walking on any programmable locomotion interfaces, satisfying normal gait conditions.
The proposed cancellation method is basically designed for natural walking with
constant speed. However, if there is a velocity change, a human foot may be in the
swing phase before or after the backward movement to the same positions with average velocities of previous swing phase during single stance phase. Due to this reason,
home positioning errors generated by velocity change are inevitable. Therefore, by
moving center positions of the two platforms to home positions without changing the
relative positions between the two platforms, the neutral positions can be maintained
although a user changes walking velocities.
3.2 Spatial Motions
For spatial motions of the locomotion interface, the footpad device will be used to
generate various terrains such as stairs and slopes. In order to simulate stairs, the
platform of the footpad device should have zero angles since the stairs have no slope.
Therefore, cancellation method about planar motions can also be applied to lift motion control. If the zC is higher than the ground height H threshold , the command lift
motion zC of the footpad device will be H threshold to keep stairs surface. This algorithm for spatial motions is shown in Fig. 4. For slope surface generation, if the pitch
angles of the footpad device have constant values and the roll angle is zero, the surface will be uphill or downhill slopes. If ground has up-slope, the pitch angle should
be positive and the ground height should be increased as human foot proceeds in
forward direction as shown in Fig. 5. Therefore, to sustain the contact of the human
foot with the ground at slope surfaces, the ground height threshold H thereshold should
be computed in equation (1), while the same walking scheme for planar motions and
lift motions will be applied to retreat the human foot back for continuous walking.
θ C = θ slope , φC = φslope , H threshold = H ground + yC tan(θ )

(1)

where θ C and φC are the desired pitch and roll angles of the footpad device, and

yC is the back-and-forth desired control command of a human foot. This walking
control algorithm, therefore, will sustain continuous walking over various terrains
with the 6-dof locomotion interface in a limited area.

St e

p le

h
ng t

Heave
motion

H threshold = H ground

θ
H ground

+ ytrack tan θ

Back-and-force motion ( ytrack )

Fig. 5. The walking surface generation on slopes

614

J. Yoon and J. Ryu

4 Navigation Using the Locomotion Interface
4.1 Virtual Environments
Virtual terrains (see Fig. 6) have been developed by using OpenGL API (Application
Program Interface) based on Microsoft Visual C++ programs for window environment. The viewpoint is selected as the first person viewpoint so that operator may see
virtual environment and feel more realistic. Virtual environments are displayed with
large screen to guarantee safety of the subject during the locomotion interactions.
Even though HMD (Head Mounted Display) can provide full sight of virtual environment, the wearing of the HMD may prevent the user from coping with dangerous
situations during walking interactions on the locomotion interface.
The virtual environment consists of three components:3D object modeler for buildings and terrains, scene manager and communication manager component. The 3D
object modeler component provides geometric modeling functionality for virtual environment through polygon extrusion of 2D profile in the 2D map and 3D CAD model.
The 3D model can be created for 2D map by extruding 2D profile geometry with b and
m. In simple features specification of the Open GIS Consortium (OGC)[6] , the WellKnown Binary (WKB) representation for geometry provides a portable representation of
a geometry value as a contiguous stream of bytes. Also, WKB representation is used to
store geometry information as in OGC simple features specification.
The scene manager component manages the scene graph for real-time rendering
according to the VWM requests. The communication manager component manages
the communication between virtual walking machine and virtual environment via
remote procedure call (RPC) to interact the VWM user. The interface using the interface definition language (IDL) for RPC is defined to communicate between the VWM
and virtual environment. The proposed RPC interface provides virtual environment
switching and interaction functions.

(a) Upright navigation

(b) Slope navigation

Fig. 6. Virtual terrains

4.2 Interaction Between the LI and Virtual Environments
There are two types of RPC methods for interaction: position-based interaction and
action-based interaction. The position-based interaction performs the navigation in
virtual environments according to the position changes in local coordinate system of
the VWM, while the action-based interaction performs relative motion at current
virtual environments according to the velocity changes of the VWM. Since there are

A Novel Navigation Algorithm for Locomotion Interfaces

615

many virtual environments with various terrains, the action-based interaction is easy
to control the virtual environments in that it performs the navigation according to the
VWM user actions rather than the position changes. Therefore, the walking velocity
of the user will be directly translated to VR actions for navigation. The update rate for
the VWM velocity is selected to be 20Hz, which is enough to show smooth walking
actions. Then, the user walking velocity is estimated as;
Single Right Stance Phase:
sw
Vwalking = Vavg
,L

(2)

sw
Vwalking = Vavg
,R

(3)

Vwalking = 0

(4)

Single Left Stance Phase:
Double Stance Phase:
sw is the average velocity during the swing phase and the V
where Vavg
,i
walking is the
estimated walking velocity of a user on the locomotion interface. Since human foot
moves forward only during swing phase, the average velocity of the human walking
can be estimated as average velocity during only swing phase motion. Therefore, after
the each foot moves forward and when the foot contacts on the platform, the walking
velocity will be updated. During double limb stance, since the foot will not move
forward, the velocity should be set to zero. Finally, the functions of the RPC interface
shown in Fig.7 are utilized for each interaction mode.
The functions Forward (speed) and Backward (speed) for back-and forth motions
will move the current camera position to the next camera position towards the direction
vector of the current camera. The speed will determine differential displacement during
sampling time. Similarly, the functions UpStair(speed) and DownStair(speed) will
change the camera position of virtual environments for z direction. The functions LookLeft (angle), LookRight (angle), LookUp (angle),and LookDown (angle) are defined to
change directions of the camera, which will be connected to HMD(Head Mounted
Display) to reflect the change in user’s view in virtual environments.

// switch various virtual environments such as floor, sloop, turning and stairway.
void SetEnvMode (int mode);
// control position-based interaction.
void SetVWMParam (VWMPosition point, VWMOrientation orientation);
void SetVWMCameraParams (VWMPosition focal, VWMPosition point, VWMOrientation
orientation);
// control action-based interaction.
void Forward (float speed);
void Backward (float speed);
void LookLeft (float angle);
void LookRight (float angle);
void LookUp (float angle);
void LookDown (float angle);
void UpStair (float speed, float ratio);
void DownStair (float speed, float ratio);

Fig. 7. RPC interface for interaction between the VWM and virtual environments

616

J. Yoon and J. Ryu

4.3 Evaluations
For the preliminary interface evaluation, five subjects among our laboratory students
participated in walking over the designed locomotion interface device. The subjects
who have no experience of the walking on the interface were instructed how to walk
over the walking interface. Since there is velocity limitation (maximum 1.2m/s) for
the locomotion interface, they were requested to walk with normal speeds that they
generally walk. Even though the number of subjects is small, it is useful for discussing the overall performance of the walking interface. Initially, most of them were
afraid of the waking on the interface but after trial walking, they were able to walk
without anxiety. Fig. 8 (a) shows the scores of the each item (safety, reality, and overall) for upright walking with respect to subjects A…E. After interactions with the
walking device, they scored each item. Most of them are satisfied with the walking
control algorithm since the algorithm has been developed based on the real human
gait motions. But, they indicated that for moving back motions during stance phase,
they felt the body inertia of moving back motions due to the neutral home positioning
during double stance phase. For overall evaluations, subjects generally were satisfied
with the reality of the walking with the interface device. For slope walking on the
interface shown in Fig. 8 (b), the subjects were more positive for real walking in that
there was not much of the body inertia for backward motions, especially for the backand-forth motions. Since real bodies were moving up and moving down for walking
interaction on slope grounds, they felt that their walking motions were more similar to
real walking. For turning motions [7-8], since the two platforms may have possibility
to collide each other when the platform follows the human foot, the only passive motions are allowed.
‫ڋڋڌ‬

‫ڋڋڌ‬

‫ڋړ‬

‫ڋړ‬
‫ڴگ ڠڡ ڜ ڮ‬

‫ڋڑ‬

‫ڴگڤڧ ڜڠ ڭ‬

‫ڋڏ‬

‫ڧڧ ڜ ڭڠڱ ڪ‬

‫ڋڍ‬
‫ڋ‬

‫ڜ‬

‫ڝ‬

‫ڞ‬

‫ڟ‬

‫ڴگڤڧ ڜڠ ڭ‬

‫ڋڏ‬

‫ڧڧ ڜ ڭڠڱ ڪ‬

‫ڋڍ‬
‫ڋ‬

‫ڠ‬

‫ڴگ ڠڡ ڜ ڮ‬

‫ڋڑ‬

‫ڜ‬

‫ڝ‬

(a) upright walking

‫ڞ‬

‫ڟ‬

‫ڠ‬

(b) slope walking

Fig. 8. Evaluation results

With preliminary evaluations, some important understandings of the developed locomotion interface are addressed. The walking control and navigation algorithm was
operating well with the proposed novel programmable locomotion interface. The
walking interactions with the upright and slope grounds were successful on the locomotion interface.

A Novel Navigation Algorithm for Locomotion Interfaces

617

5 Conclusions1 and Future Work
This paper proposes novel navigation system that can induce user's real walking and
generate realistic visual feedback during navigation, using robotic manipulators. For
realistic visual feedback, the virtual environment is designed with three components;
3D object modeler for buildings and terrains, scene manager and communication
manager component. The suggested navigation system can allow a user to explore
into various virtual terrains with real walking and realistic visual feedback. As future
works, the various haptic effects such as soft and hard grounds, or slippage will be
simulated by changing the impedance parameters. Also, comparison between VWM
and joystick navigation will be performed. After enhancing the control performances
and the safety of the VWM, the final goal is to let user wear the HMD for full immersion in the virtual navigation with natural walking.

References
1. Hollerbach, M.,“Locomotion interfaces,'' in: Handbook of Virtual Environments Technology, K.M. Stanney, ed., Lawrence Erlbaum Associates, Inc. (2002) 239-254.
2. Iwata, H., Yano, H., and Nakaizumi, F., Gait Master: a versatile locomotion interface for
uneven virtual terrain, Prof. of IEEE Virtual Reality (2001) 131 - 137.
3. Schmidt, H., Sorowka, D., Hesse, R., and Bernhardt, R., Design of a Robotic Walking
Simulator for Neurological Rehabilitation, IEEE/RSJ Int. Conf. On Intelligent Robots and
Systems (2002) 1487-1492.
4. Yoon, J. and Ryu, J., The Development of the 3-DOF Planar Parallel Robot (RRR Type)
for Omni-directional Locomotion Interface, 3rd IFAC Symposium on Mechatronic Systems,
Sept.6-8, Sydney, Australia, 2004.
5. Yoon, J. and Ryu, J., A New Family of 4- Dof Hybrid Parallel Mechanisms with Two Platforms and Its Application to a Footpad Device, Journal of Robotic Systems, 22:(5) (2005)
287-298.
6. Open GIS Consortium, OpenGIS Simple Feature Specification for OLE/COM, OpenGIS
Implementation Specifications, Revision 1.1, 1999.
7. Bouguila, L., Ishii, M., and Sato, M., Realizing a New Step-in-place Locomotion Interface
for Virtual Environment with Large Display System. Proceedings of the Workshop on Virtual Environments (2002) 197-207.
8. http://www.virtusphere.com.

1

Research reported here was supported by grant (No. R01-2002-000-00254-0) from the Basic Research
Program of the Korea Science & Engineering Foundation and by the Korea Research Foundation Grant
funded by the Korean Government(MOEHRD)” (KRF-2005-005-J09902).

