A Flexible Multiagent Parallel File System for Clusters
Marıa
´ S. Perez
´ ½ , Jesus
Robles½
´ Carretero¾ , Felix
´ Garcıa
´ ¾ , Jose´ M. Pena
˜ ½, and Vıctor
´
½

¾

DATSI. FI. Universidad Polit´ecnica de Madrid. Spain
Departamento de Inform´atica. Universidad Carlos III de Madrid. Spain

Abstract. The emergence of applications with greater processing and speedup
requirements, such as Grand Challenge Applications (GCA), involves new computing and I/O needs. Many of these applications require access to huge data
repositories and other I/O sources, being the I/O phase a bottleneck in the computing systems, due to its poor performance. In this sense, parallel I/O is becoming one of the major topics in the area of high-performance systems. Existing data-intensive GCA have been used in several domains, such as high energy physics, climate modeling, biology or visualization. The I/O problem is not
solved in this kind of applications. New approaches are required in this scene.
This paper presents MAPFS, a multiagent architecture, whose goal is to allow
applications to access data in a cluster of workstations in an efficient and flexible
fashion, providing formalisms for modifying the topology of the storage system,
specifying different data access patterns and selecting additional functionalities.

1 Introduction
Nowadays, there is a growing interest in the development of high-performance I/O systems, because the I/O phase has become a bottleneck in the computing systems due to
its poor performance. In this sense, one of the major goals of high-performance computing is to provide an efficient access to data, being parallel I/O one of the most relevant
issues in this field.
Currently, there are different parallel file systems, such as Galley [11], Parallel
File System (PFS) [4] and Portable Parallel File System (PPFS) [8], which offer highperformance services to access resources. Many of these systems have been widely
developed for parallel machines and are not suitable for clusters of workstations. Nevertheless, in parallel computing there is an increasing trend towards the usage of clusters,
mainly because of their prices and their ease of integration. In this sense, the Parallel
Virtual File System (PVFS) [3] is used in dedicated clusters of workstations.
On the other hand, parallel file system optimizations provide improved I/O operations. The usage of hints related to different aspects of data distribution and access
patterns allows parallel file systems to increase the performance of these operations.
Processes such as caching or prefetching are useful approaches used in addition with
these last ones [12], [2]. The agent technology [5], [7] is a suitable framework for integrating these functions in the storage system, because of its adaptability to different
domains and its capability to achieve process autonomy.
This paper presents MAPFS, a multiagent architecture, whose goal is to allow applications to access data in a cluster of workstations in an efficient and flexible fashion,
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 248−256, 2003.
 Springer-Verlag Berlin Heidelberg 2003

A Flexible Multiagent Parallel File System for Clusters

249

providing formalisms for modifying the topology of the storage system, specifying different data access patterns and selecting additional functionalities.
The outline of this paper is as follows. Section 2 presents MAPFS as a flexible infrastructure for data-intensive applications in a cluster environment. Section 3 shows the
results obtained for the evaluation of applications using MAPFS. Section 4 describes a
comparison between MAPFS and PVFS. Finally, section 5 summarizes our conclusions
and suggests further future work.

2 MAPFS Overview
The emergence of applications with greater I/O access requirements, named data-intensive applications or I/O-intensive applications, demands new I/O solutions. Examples of
data-intensive and Grand Challenge applications [6] include data mining systems, data
warehousing [9], high energy physics applications [15], and satellite data processing
[1]. These applications may require access to data sources distributed among different nodes. Moreover, typical data-intensive applications require access to terabyte size
datasets, which must be processed in an efficient way, in order to increase the performance of the applications executed on the cluster. Furthermore, data-intensive applications are very different depending on the kind of functional requirements and access
patterns. It is critical for I/O system to be flexible enough to match these demands. The
usage of hints, caching and prefetching policies or different data distribution configurations are optional features, which can reduce latency and increase I/O operations
performance.
MAPFS [13] is a multiagent architecture, which provides flexibility in different
aspects:
– System topology configuration: Ability to change system topology, setting the I/O
nodes and their relationships. This feature is achieved through the usage of storage
groups, which are described in section 2.2.
– Access pattern specification: Although MAPFS is a general purpose I/O system, it
can be configured in order to adapt to different I/O access patterns [14].
– There are different reasons to allow some functionalities (such as caching or prefetching) to run in parallel on different nodes and even on the data servers. Moving
executions to data servers may reduce network latency and traffic. The agent technology is useful in this scene, because of the agents properties, such as autonomy,
proactivity and reactivity. MAPFS is composed of a multiagent subsystem, which
is responsible of making several independent tasks.
2.1 MAPFS Architecture
MAPFS is based on a client-server architecture using general purpose servers. In the
first prototype, NFS servers are used. NFS [10] has been ported to different operating
systems and machine platforms and it is widely used by many servers worldwide. Data
is distributed through the servers belonging to a storage group, using a stripe unit.
In the client-side, it is necessary to install a MAPFS client, which provides a parallel
I/O interface to the servers.

250

M.S. Pérez et al.

Distributor agents

Hints agents

Extractor agents

Cache agents

Fig. 1. Taxonomy of agents used in MAPFS

Additional multiagent subsystems provide several functionalities and they are executed on different nodes. Every storage group is associated to a multiagent subsystem.
These multiagent subsystems use an agent hierarchy, which solves the information retrieval problem in a transparent and efficient way. The taxonomy of agents used in
MAPFS is composed of:
– Extractor agents: They are responsible for information retrieval, invoking parallel
I/O operations.
– Distributor agents: They distribute the work load to the extractor agents. These
agents are placed at the higher level of the agents hierarchy.
– Caching and prefetching agents: They are associated with one or more extractor
agents, caching or prefetching their data.
– Hints agents: They must study applications access patterns to build hints improving
data access.
Figure 1 represents the relation among these agents. The taxonomy of agents can be
extended to provide additional functionalities.
The most usual configuration is to run these subsystems on the data servers, helping
to reduce network traffic. In this case, a major requirement is to install a technology that
supports distributed execution of agents. MAPFS provides this optional functionality.
2.2 Storage Groups
The concept of grouping is fundamental in every aspect of the life. Edwin P. Hubble,
which is considered the founder of the observational cosmology, said in the thirties
that the best place for searching a galaxy is next to another one, describing the concept
of galaxy grouping. Like in real life, computer science has a significant number of
groupings, e.g. process group or user group.
A storage group is defined in MAPFS as a set of servers clustered as groups. These
groups take the role of data repositories and can be built applying several policies, trying
to optimize the accesses to all the storage groups. Some significant policies are:
– Grouping by server proximity: Storage groups are built based on the physical distribution of the data servers. Storage groups are composed of servers in close proximity to each other. This policy optimizes the queries addressed to a storage group
because of the similar latency of messages sent to servers.

A Flexible Multiagent Parallel File System for Clusters

251

Fig. 2. MAPFS interface showing the system topology

– Grouping by server similarity: Storage groups are composed of servers with similar
processing capacity. This policy classifies storage groups in different categories,
depending on their computational and I/O power.
The main advantages of storage groups are:
1. Logic abstraction of the concept of storage server: As a partition is a logic abstraction of the physical disk, the storage group is also a logic abstraction of the storage
server concept.
2. Dynamic management of servers: As we mentioned previously, the usage of storage
groups provide dynamic management of servers through the MAPFS interface (see
figure 2).
3. Efficiency of the storage operations: The policies used in the system provide a way
of increasing the global efficiency of the system.
4. Load balancing: It is possible to use a concrete storage group in order to optimize
system load balancing, depending on the load of the remaining storage groups.
5. Transparent migration: In addition to the MAPFS interface, the system can change
the distribution of storage groups in a transparent way in order to optimize different
aspects related to the system performance.
The system topology can be changed dynamically. In this case, data must be reconstructed, because the system must map the files stored in the servers of the previous
topology to the new configuration. Data reconstruction degrades the performance of the
I/O system. In order to avoid data reconstruction, MAPFS defines two types of storage
groups, main storage groups and secondary groups, which form a lattice structure between them. Secondary groups are used for storing new data, avoiding the migration
of the files data. In fact, this approach postpones data reconstruction until the system
runs a de-fragmentation operation, which is used for deleting secondary groups and
simplifying the storage system description.

252

M.S. Pérez et al.

2.3 Access Pattern Specification
There are a huge number of applications using parallel file systems. These applications
have very different requirements and data access patterns. Therefore, it is desirable that
the underlying file system allows these applications to provide information about the
layout of the data used by them. This information is given as hints, which are used for
improving read and write operations performance. MAPFS uses these hints to access
data. For example, storage systems using hints may provide greater performance because they use this information to decrease cache faults and to prefetch the data most
probably used in next executions. In other words, the more information it has been used,
the less uncertainty in the future access guesses and, therefore, the better prefetching
and caching results.
In MAPFS, hints can be obtained in two ways:
1. Given by the user, that is, the user application provides to I/O system the necessary
specifications.
2. Built by the multiagent subsystem. If this option is selected, the multiagent system
must analyze the access pattern of the applications in order to build hints improving
data access.
If hints are provided by the user application, it is necessary for the system to provide
syntactic rules for setting the system parameters, which configure the I/O system. On
the other hand, if the multiagent subsystem creates the hints, it is also necessary to store
them in a predefined way. In any case, lexical and syntactic rules must be introduced in
the system.
The system is configured through several operations, which are independent of the
I/O operations, although these last ones use the former operations. The configuration
operations are divided in:
– Hints Setting Operations: Operations for establishing the hints of the system. Therefore, they can set and get the values of the different fields of the hints.
– Control User Operations: Higher level operations that can be used directly by the
user applications to manage system performance.
Figure 3 shows the three subsets of the Storage System API. As can be seen in the
figure, there are three ways of accessing the Hints Setting Module:
1. The I/O operations may ask for hints values and even modify them.
2. The control user operations may modify the hints. This is the normal way for the
user applications to interact with hints.
3. To make the system flexible, the Hints Setting Module may be accessed directly
through the Hints Setting API. The multiagent system may build and modify hints
through this interface.
The MAPFS I/O API was described in [13]. The hint setting operations are the
following ones:
– Mapfs Hints * mapHintsNew(int block ident): This operation creates a new hint
structure for the block with identifier block ident.

A Flexible Multiagent Parallel File System for Clusters

I/O API

Hints Setting API

253

Control User API

Storage System
Fig. 3. Storage System API

– void mapHintsFree(Mapfs Hints *hint): This operation releases a hint structure.
– int mapHintsSet(Mapfs Hints *hint, int code field, void * value): This operation
modifies a field of the hint structure with a value. The operation returns 0 if successful and -1 otherwise.
– void * mapHintsGet(Mapfs Hints *hint, int code field): This operation returns the
value of a concrete field of the hint structure. If the field is not defined, mapHintsGet() returns NULL.
Hints in MAPFS are built based on the concept of attribute. An attribute can take
different values, which provides useful information for the I/O operations. The control
user operations have a similar structure:
– Mapfs CtrlUser * mapCtrlUserNew(Mapfs Tuples *tupl): This operation creates a
new Control User structure for a set of tuples represented by tupl.
– void mapCtrlUserFree(Mapfs CtrlUser *ctrlUser): This operation releases a Control User structure.
– int mapCtrlUserSet(Mapfs CtrlUser *ctrlUser, int code field, void *expr): This operation modifies a field of the Control User structure with an expression. The operation returns 0 if successful and -1 otherwise.
– void *mapCtrlUserGet(Mapfs CtrlUser *ctrlUser, int code field): This operation
returns the value of a concrete field of the Control User structure. If the field is not
defined, mapCtrlUserGet() returns NULL.
Control User operations are higher level operation using expressions instead of simple attributes, which are translated to hints by the MAPFS system. These expressions
are formed by boolean operations applied to attributes. An example is shown in the
section 3.

3 MAPFS Evaluation
In order to validate our implementation, it is necessary to evaluate its performance.
Experiments were run on a cluster of four nodes Athlon 650MHz, with 256 MB of
RAM memory, attached to a Gigabit network. This cluster constitutes our trial storage
group.

254

M.S. Pérez et al.
4.5

Speedup MAPFS vs Local

Speedup

4

3.5

3
1K

2K
4K
Access size(bytes)

8K

Fig. 4. Speedup of the MAPFS solution on a cluster of 4 nodes versus Local solution

Our experiment consists of four processes running a multiplication of two matrices,
where the matrices are stored in the cluster, using MAPFS as underlying platform. The
resultant matrix is also stored in a distributed fashion. A prefetching multiagent subsystem is used, which is responsible for prefetching rows and columns of the matrices. In
this case, the hints provided by the applications are the indexes of the matrix row and
the matrix column of the element calculated in every iteration. It is possible to prefetch
data used in later executions, using this information. The control user structure provided
by the application follows this expression:
row=i AND column=j
Therefore, the sequence of configuration operations made by the application are:

1. Mapfs CtrlUser *mapCtrlUser = mapCtrlUserNew(data);
2. mapCtrlUserSet(mapCtrlUser, position, "row=i AND column=j");
This control user structure is translated to hints by the multiagent subsystem. Hints
are used as data tags for processing the elements in an efficient manner, skipping nonrelated elements in the cache.
This experiment was compared to another one, which consists in multiplying the
same matrices stored on the local disk through the usage of a traditional I/O system.
The size of the matrices was 100 MB.
Figure 4 shows the speedup of the MAPFS solution versus local solution, varying
the access size used in the I/O operations. As can be seen, the speedup is very close to
, the number of nodes, which is the maximum speedup, limited by the “Amdahl law”.

A Flexible Multiagent Parallel File System for Clusters
3600

255

MAPFS Time
PVFS Time

3500

Time (mins)

3400
3300
3200
3100
3000
2900
1K

2K
4K
Access size (bytes)

8K

Fig. 5. Execution time of multiplication of two matrices with MAPFS and PVFS

4 Comparison with PVFS
The best way of evaluate MAPFS is to compare the performance of an application using
this parallel file system and another parallel file system. PVFS [3] has been chosen due
to the following reasons:
1. It is a parallel file system developed for Linux clusters.
2. It provides high bandwidth for concurrent read/write operations from multiple processes or threads to a parallel file.
3. It is robust and scalable.
4. It gives support for multiple APIs, including a native PVFS API, the UNIX/POSIX
API and MPI-IO API. We have used the first one for implementing the application.
Again, we have compared a multiplication of two matrices distributed among different nodes both in MAPFS and PVFS. Figure 5 shows the execution time of the application using both parallel file systems. As can be seen in the figure, the difference
is significant, although it decreases as the access size is increased. It is important to
emphasize the fact that PVFS is a high-performance parallel file system.

5 Conclusions and Future Work
In this work we have presented MAPFS, a new multiagent architecture for high performance I/O in clusters. MAPFS provides the following properties: (i) system topology
configuration; (ii) access pattern specifications by applications, and (iii) usage of a multiagent subsystem in order to run specific functionalities, such as caching or prefetching
processes.
MAPFS has been compared to both a local solution and PVFS, a high performance
parallel file system developed for Linux clusters, concluding that MAPFS provides a
resultant speedup very close to the maximum one, improving the results of PVFS.
As future work, it would be interesting to evaluate the performance of the system
with other applications, using more complex hints.

256

M.S. Pérez et al.

References
1. Anurag Acharya, Mustafa Uysal, Robert Bennett, Assaf Mendelson, Michael D. Beynon,
Jeff Hollingsworth, Joel Saltz, and Alan Sussman. Tuning the performance of I/O-intensive
parallel applications. In Proceedings of the Fourth ACM Workshop on I/O in Parallel and
Distributed Systems, May 1996.
2. Pei Cao, Edward W. Felten, and Kai Li. Implementation and performance of applicationcontrolled file caching. In Operating Systems Design and Implementation, pages 165–177,
1994.
3. P. H. Carns, W. B. Ligon III, R. B. Ross, and R. Thakur. PVFS: A parallel file system for
linux clusters. In Proceedings of the 4th Annual Linux Showcase and Conference, pages
317–327, October 2000.
4. R. Esser and R. Knecht. Intel Paragon XP/S— architecture and software environment. In
Proceedings of Supercomputer ’93, Lecture Notes in Computer Science, Mannheim, Germany, 1993.
5. Stan Franklin and Art Graesser. Is it an agent, or just a program?: A taxonomy for autonomous agents. In Proceedings of the Third International Workshop on Agent Theories,
Architectures and Languages, Springer-Verlag, 1996.
6. Grand Challenging Applications. http://www.mcs.anl.gov/projects/grand-challenges.
7. N. R. Jennings, K. Sycara, and M. Wooldridge. A roadmap of agent research and development. Autonomous Agents and Multi-Agent Systems Journal, 1(1):7–38, 1998.
8. James V. Huber Jr., Christopher L. Elford, Daniel A. Reed, Andrew A. Chien, and David S.
Blumenthal. PPFS: A high performance portable parallel file system. In Proceedings of the
9th ACM International Conference on Supercomputing, pages 385–394, Jul 1995.
9. R. Kimball. The Data Warehouse Toolkit. John Wiley and Sons, Inc., 1996.
10. Network Working Group. NFS: Network File System Protocol Specification, March 1989.
RFC 1094.
11. Nils Nieuwejaar and David Kotz. The Galley parallel file system. In Proceedings of the 10th
ACM International Conference on Supercomputing, pages 374–381. ACM Press, May 1996.
12. R. Hugo Patterson, Garth A. Gibson, and M. Satyanarayanan. A status report on research in
transparent informed prefetching. ACM Operating Systems Review, 27(2):21–34, 1993.
13. Mar´ıa S. P´erez, F´elix Garc´ıa, and Jes´us Carretero. A new multiagent based architecture
for high performance I/O in clusters. In Proceedings of the 2nd International Workshop on
Metacomputing Systems and Applications MSA’2001, September 2001.
14. Mar´ıa S. P´erez, Ram´on A. Pons, F´elix Garc´ıa, Jes´us Carretero, and V´ıctor Robles. A proposal
for I/O access profiles in parallel data mining algorithms. In 3rd ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed
Computing, June 2002.
15. A. Shoshani, L. Bernardo, H. Nordberg, D. Rotem, and A. Sim. Storage management for
high energy physics applications. Computing in High Energy Physics, 1998.

