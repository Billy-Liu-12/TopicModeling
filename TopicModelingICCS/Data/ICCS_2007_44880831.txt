An Interactive Graphical Environment for Code
Optimization
Jie Tao1 , Thomas Dressler2 , and Wolfgang Karl2
1

Institut f¨
ur Wissenschaftliches Rechnen
Forschungszentrum Karlsruhe
76021 Karlsruhe, Germany
jie.tao@iwr.fzk.de
2
Institut f¨
ur Technische Informatik
Institut f¨
ur Technische InformatiK
76128 Karlsruhe, Germany
karl@ira.uka.de

Abstract. Applications usually do not show a satisﬁed initial performance and require optimization. This kind of optimization often covers a complete process, starting with gathering performance data, followed by performance visualization and analysis, up to bottleneck ﬁnding and code modiﬁcation. In this paper we introduce DECO (Development Environment for Code Optimization), an interactive graphical interface that enables the user to conduct this whole process within a single
environment.
Keywords: Performance tools, visualization, cache optimization.

1

Introduction

General-purpose architectures are not tailored to applications. As a consequence,
most applications usually do not show high performance as initially running on
certain machines. Therefore, applications often have to be optimized for achieving expected performance metrics.
This kind of optimization, however, is a quite tedious task for users and as a
consequence various tools have been developed for providing support. First, users
need a performance analyzer [1] or a visualization tool [7] capable of presenting
the execution behavior and performance bottlenecks. These tools have to rely on
proﬁlers [4], counter interfaces [3], or simulators [6] to collect performance data.
Hence, tools for data acquisition are required. In addition, users need platforms
to perform transformations on the code. These platforms can be integrated in
the analysis tool but usually exist as an individual toolkit.
In summary, users need the support of a set of diﬀerent tools. Actually, most
tool vendors provide a complete toolset to help the user step-by-step conduct
the optimization process, from understanding the runtime behavior to analyzing
performance hotspots and detecting optimization objects. Intel, for example, has
developed VTune Performance Analyzer for displaying critical code regions and
Y. Shi et al. (Eds.): ICCS 2007, Part II, LNCS 4488, pp. 831–838, 2007.
c Springer-Verlag Berlin Heidelberg 2007

832

J. Tao, T. Dressler, and W. Karl

Thread Proﬁler for presenting thread interaction and contention [5]. The Center
for Information Services and High Performance Computing at the University of
Drednen developed Vampir [2] for performance visualization and Gooﬁ [8] for
supporting loop transformation in Fortran programs.
Similarly, we implemented a series of tools for cache locality optimization. This
includes a cache visualizer [9] which demonstrates cache problems and the reason
for them, a data proﬁler which collects information about global cache events, a
cache simulator [10] for delivering runtime cache activities, and a pattern analysis
tool [11] for discovering the aﬃnity among memory operations.
By applying these tools to optimize applications, we found that it is inconvenient to use them separately. In this case, we developed the program development
environment DECO in order to give the user a single interface for conducting the
whole process of code tuning. A more challenging motivation for us to develop
DECO is the user requirement of a platform to work with their programs. This
platform must provide all necessary functionality for building and running an
application. The third reason for a program development environment is that
users need to compare the execution time or other performance metrics of diﬀerent runs with both unoptimized and optimized code versions. It is more ﬂexible
if users could acquire this information within a single view than having to switch
across several windows.
These features are general and can be applied directly or with slight extension
by other tool developers to build a development environment for their own need.
For our purpose with cache locality optimization DECO has an additional property: it visualizes the output of the pattern analysis tool and maps the access
pattern to the source code.
The rest of the paper is organized as follows. We ﬁrst describe the design and
implementation of DECO in Section 2. In Section 3 we present its speciﬁc feature
for cache locality optimization, together with some initial optimization results
with small codes. In Section 4 the paper is concluded with a short summary and
some future directions.

2

DECO Design and Implementation

The goal of DECO is to provide program developers an easy-to-use environment
for step-by-step running the program, analyzing the performance, conducting
optimization, executing the program again, and then studying the impact of
optimizations. This is actually a feedback loop for continuous optimization. Users
repeat this loop till a satisﬁed performance is achieved. For giving the user a
simple view DECO provides all needed functionality for the whole loop in a
single window.
As depicted in Figure 1, this window consists of a menu bar and three visualization areas. The menu bar is located on the top of the window, with items
for ﬁle operation, view conﬁguration, project creation, executable building, and
performance analyzing. The left ﬁeld under the menu bar is a code editor, where
the program source is displayed in diﬀerent color for a better overview and an

An Interactive Graphical Environment for Code Optimization

833

Fig. 1. Main window of the program development environment

easy logic analysis. Next to the editor is a subwindow for demonstrating runtime
results, such as execution time, cache miss statistics, communication overhead
(e.g. for MPI programs), and analysis of speciﬁc constructs (e.g. parallel and
critical regions in OpenMP programs). In addition, the visualization of access
pattern, for our special need of cache locality optimization, is combined with
this subwindow. The output and error reports delivered during the run of applications or tools are displayed at the bottom.
Building Projects. DECO targets on realistic applications which are usually
comprised of several ﬁles including head and Makeﬁle. Hence, applications are
regarded as project within DECO. Projects must be created for the ﬁrst time
and then can be loaded to the DECO environment using corresponding options
in the menu bar.
Figure 2 shows two sample subwindows for creating a project. First users have
to give the project a name and the path where the associated ﬁles are stored.
Then users can add the ﬁles that need analysis and potentially optimization
into the project by simply select the object from the ﬁles at the given path, as
illustrated on the top picture of ﬁgure 2. It is allowed to concurrently open a set
of ﬁles, but only one ﬁle is active for editing.
After modiﬁcation of the source program users can generate an executable of
the application using Menu Compile that contains several options like make and
make clean, etc. Commands for running the application are also included.
Tool Integration. DECO allows the user to add supporting tools into the
environment. To insert a tool, information about the name, the path, and conﬁguration parameters has to be provided. For this, DECO lists the potential parameters that could be speciﬁed as command line options for a speciﬁc toolkit. In
case of the cache simulator, for example, it allows the user to specify parameters
for the frontend, the simulator, and the application.
Using this information, DECO builds an execution command for each individual tool and combines this command with the corresponding item in the
menu Analysis of the main window. This means, tools can be started with menu

834

J. Tao, T. Dressler, and W. Karl

Fig. 2. Creating a new project

choice. During one tool is running, users can conﬁgure another tool or edit the
applications.
Execution Results. To enable a comparative study of diﬀerent program versions, DECO visualizes the output of applications. Depending on the application,
this output can be execution time, overhead for parallel programs, statistics on
memory accesses, or time for synchronization of shared memory applications.
The concrete example in Figure 1 visualizes the statistics on cache hits and
misses.

3

Visualizing the Access Pattern

As mentioned, a speciﬁc feature of DECO for our cache locality optimization is
the ability of depicting access patterns in the source code. This leads the user
directly to the optimization object and more importantly shows the user how
to optimize. In the following, we ﬁrst give a brief introduction of the pattern
analysis tool, and then describe the visualization in detail.
Pattern Analyzer. The base of the analyzer [11] is a memory reference trace
which records all runtime memory accesses. By applying algorithms, often used
in Bioinformatics for pattern recognition, it ﬁnds the aﬃnity and regularity between the references, like access chain and access stride. The former is a group
of accesses that repeatedly occur together but target on diﬀerent memory locations. This information can be used to perform data regrouping, a strategy for
cache optimization, which packs successively requested data into the same cache
block by continually deﬁning the corresponding variables in the source code.
The latter is the stride between accesses to neighboring elements of an array.
This information can be used to guide prefetching, another cache optimization
strategy, because it tells which data is next needed.
Additionally, the pattern analyzer delivers the information whether an access
is a cache hit or a cache miss. For a cache miss, it further calculates the push
back distance which shows the number of steps a miss access must be put back

An Interactive Graphical Environment for Code Optimization

835

in order to achieve a cache hit. It is clear that users can use this information to
change the order of memory accesses for a better cache hit ratio. However, it is
diﬃcult to apply this information in its original form based on virtual addresses
and numbers. Therefore, DECO provides this speciﬁc property of mapping the
pattern to the program.
Visualization. Using DECO, patterns are displayed within the source code but
also in a separate window for a deeper insight. Figure 3 is an example of the
access chain. The window on the right side lists all detected chains with detailed
description, including the ID, number of elements, frequency of occurrence, and
the initial address. It is also possible to observe more detailed information of a
single chain, for example, all accesses contained and the miss/hit feature of each
access. This detailed information helps the user decide whether the grouping
optimization is necessary.
On the left side access chains are demonstrated in the source code. By clicking
an individual chain in the right window, the corresponding variables and the
location of references are immediately marked in the program. Users can utilize

Fig. 3. Presentation of access chains in two windows

Fig. 4. Visualization of access stride

836

J. Tao, T. Dressler, and W. Karl

this information to move the declarations of the associated variables into a single
code line.
Similarly, the push back distance is also combined with the program. For a
selected variable DECO marks the ﬁrst access to it in the code. Then the rest
accesses are one-by-one marked with diﬀerent colors presenting their hit/miss
feature. In case of a cache miss, the position, where the reference has to be issued
for avoiding the miss, is also marked with color. Based on this information users
can decide if it is possible to shift an access. This optimization improves the
temporal locality of single variables and is especially eﬀective for variables in
loops.
The access stride for arrays can be observed in three diﬀerent forms. First,
an initial overview lists all detected strides with the information about start
address, stride length, and the number of occurrence. A further view displays
individual strides in detail, with descriptions of all references holding this stride.
The third form is a diagram. The lower side of Figure 4 is an example. Within
this diagram, all array elements holding the stride are depicted with small blocks.
Each small block represents a byte; hence, an element usually consists of several
blocks, depending on the type of the array. For example, the concrete diagram
in Figure 4 actually demonstrates an array of 4-bytes elements and a stride of
length one. The ﬁrst block of each element is colored in order to exhibit the
hit/miss feature. This helps the user reorganize the array structure or change
the sequence of accesses to it, if large number of misses had been introduced
by this array. The size of blocks can be adjusted using the spin-box at the right
corner above the diagram. This allows the user to either observe the global access
characteristics of the complete array or focus on a speciﬁc region of elements.
Sample Optimization. We show two examples to demonstrate how to use this
special feature of DECO for cache optimization. The ﬁrst code implements a
simple scheduler for user-level threads. With this scheduler the threads release
the CPU resources by themselves, rather than being evicted after the timeslice.
For saving registers by thread swap, a stack is managed for each thread. The
current position at the stack has to be recorded in order to restore the registers
when the thread acquires the timeslice again. We use a struct to store this stack
pointer together with its ID and the stack. By thread switching the stack pointer
has to be updated, where the pointer of the old thread has to be written back
and the pointer of the new thread is fetched. The declaration of struct and the
code for stack pointer update is depicted in Figure 5.
We perform 1000 switchings between four threads with only the operation of
processor release. The trace analysis detects ﬁve access chains that repeat more
than 1000 times. Observing the chains in more detail, we ﬁnd that among all
accesses to the associated addresses in four of the ﬁve only three hits exist with
each. Switching to the marked code lines in the source, we further detect that
the corresponding accesses are performed for stack pointer update. This leads
us to move the deﬁnition of stackPointer out of struct and deﬁne all the four
pointers together. In this case, the number of L1 misses reduces from 4011 to 9.
This signiﬁcant improvement is the result of grouping.

An Interactive Graphical Environment for Code Optimization

837

Fig. 5. Source code of the thread scheduler

The second example performs matrix addition. The working set contains three
matrices which is declared one after another. Initial run of this code reported
12288 L1 miss without any hits. The trace analysis detected three strides of
length one, each corresponding to a single matrix. In principle, for such a stride
many accesses shall be cache hit because with a size of 64 bytes one cache line
can hold several elements. The only explanation lies in that there exists mapping
conﬂict between all three matrices and this conﬂict results in the eviction of a
matrix block out of cache before the other elements can be used.
To eliminate this conﬂict, an eﬃcient way is to insert a butter between two
matrices so that the mapping behavior of the second matrix is changed. As the
applied L1 is a 2-way cache, meaning that a cache line can hold two data blocks,
we need only to alter the mapping behavior of one matrix. Here, we put a buﬀer
of one cache line between the second and the third matrix. In this case, only 769
misses has been observed.

4

Conclusions

This paper introduces a program development environment that helps the user
perform code optimization. This environment is implemented because we note
that code optimization requires support of several tools and it is inconvenient
to use them separately. Hence, our environment integrates diﬀerent tools into a
single realm. In addition, it provides a ﬂexible interface for users to work with
their programs and to study the impact of optimizations. A more speciﬁc feature
of this environment is that it directly show access patterns in the source code.
This allows the user to locate the optimization object and the strategy.

References
1. D. I. Brown, S. T. Hackstadt, A. D. Malony, and B. Mohr. Program Analysis
Environments for Parallel Language Systems: The TAU Environment. In Proc. of
the Workshop on Environments and Tools For Parallel Scientiﬁc Computing, pages
162–171, May 1994.

838

J. Tao, T. Dressler, and W. Karl

2. H. Brunst, H.-Ch. Hoppe, W. E. Nagel, and M. Winkler. Performance Optimization
for Large Scale Computing: The Scalable VAMPIR Approach. In Computational
Science - ICCS 2001, International Conference, volume 2074 of LNCS, pages 751–
760, 2001.
3. J. Dongarra, K. London, S. Moore, P. Mucci, and D. Terpstra. Using PAPI For
Hardware Performance Monitoring On Linux Systems. In Linux Clusters: The
HPC Revolution, June 2001.
4. J. Fenlason and R. Stallman. GNU gprof: The GNU Proﬁler.
available
at http://www.gnu.org/software/binutils/manual/gprof-2.9.1/html mono/gprof.
html.
5. Intel Corporation.
Intel Software Development Products.
available at
http://www.intel. com/cd/software/products/asmo-na/eng/index.htm.
6. P. S. Magnusson and B. Werner. Eﬃcient Memory Simulation in SimICS. In
Proceedings of the 8th Annual Simulation Symposium, Phoenix, Arizona, USA,
April 1995.
7. B. P. Miller, M. D. Callaghan, J. M. Cargille, J. K. Hollingsworth, R. B. Irvin,
K. L. Karavanic, K. Kunchithapadam, and T. Newhall. The Paradyn parallel
performance measurement tool. IEEE Computer, 28(11):37–46, November 1995.
8. R. Mueller-Pfeﬀerkorn, W. E. Nagel, and B. Trenkler. Optimizing Cache Access:
A Tool for Source-To-Source Transformations and Real-Life Compiler Tests. In
Euro-Par 2004, Parallel Processing, volume 3149 of LNCS, pages 72–81, 2004.
9. B. Quaing, J. Tao, and W. Karl. YACO: A User Conducted Visualization Tool
for Supporting Cache Optimization. In High Performance Computing and Communcations: First International Conference, HPCC 2005. Proceedings, volume 3726
of Lecture Notes in Computer Science, pages 694–703, Sorrento, Italy, September
2005.
10. J. Tao and W. Karl. CacheIn: A Toolset for Comprehensive Cache Inspection.
In Proceedings of ICCS 2005, volume 3515 of Lecture Notes in Computer Science,
pages 182–190, May 2005.
11. J. Tao, S. Schloissnig, and W. Karl. Analysis of the Spatial and Temporal Locality
in Data Accesses. In Proceedings of ICCS 2006, number 3992 in Lecture Notes in
Computer Science, pages 502–509, May 2006.

