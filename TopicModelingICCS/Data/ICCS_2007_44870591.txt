Mapping Pipeline Skeletons
onto Heterogeneous Platforms
Anne Benoit and Yves Robert
LIP, UMR CNRS-INRIA-UCBL 5668, ENS Lyon, France
{Anne.Benoit|Yves.Robert}@ens-lyon.fr

Abstract. Mapping applications onto parallel platforms is a challenging problem, that becomes even more diﬃcult when platforms are heterogeneous –nowadays a standard assumption. A high-level approach to
parallel programming not only eases the application developer’s task,
but it also provides additional information which can help realize an eﬃcient mapping of the application. In this paper, we discuss the mapping
of pipeline skeletons onto diﬀerent types of platforms (from fully homogeneous to heterogeneous). We assume that a pipeline stage must be
mapped on a single processor, and we establish new theoretical complexity results for two diﬀerent mapping policies: a mapping can be either
one-to-one (at most one stage per processor), or interval-based (interval
of consecutive stages per processor). We provide several eﬃcient polynomial heuristics for the most important policy/platform combination,
namely interval-based mappings on platforms with identical communication links but diﬀerent speed processors.
Keywords: Pipeline skeleton, scheduling algorithms, throughput optimization, heterogeneous platforms, complexity results.

1

Introduction

Mapping applications onto parallel platforms is a diﬃcult challenge. Several
scheduling and load-balancing techniques have been developed for homogeneous
architectures (see [8] for a survey) but the advent of heterogeneous clusters has
rendered the mapping problem even more diﬃcult. Typically, such clusters are
composed of diﬀerent-speed processors interconnected either by plain Ethernet
(the low-end version) or by a high-speed switch (the high-end counterpart), and
they constitute the experimental platform of choice in most academic or industry
research departments. In this context, a structured programming approach rules
out many of the problems which the low-level parallel application developer is
usually confronted to, such as deadlocks or process starvation. Moreover, many
real applications draw from a range of well-known solution paradigms, such as
pipelined or farmed computations. High-level approaches based on algorithmic
skeletons [4,6] identify such patterns and seeks to make it easy for an application
developer to tailor such a paradigm to a speciﬁc problem.
In this paper, we focus on the pipeline skeleton, which is one of the most
widely used. Consecutive tasks are input to the ﬁrst stage and progress from
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 591–598, 2007.
c Springer-Verlag Berlin Heidelberg 2007

592

A. Benoit and Y. Robert

stage to stage until the ﬁnal result is computed. Each stage has its own communication and computation requirements: it reads an input ﬁle from the previous
stage, processes the data and outputs a result to the next stage. The pipeline
operates in synchronous mode: after some latency due to the initialization delay,
a new task is completed every period. The period is deﬁned as the longest cycletime to operate a stage. The problem of mapping pipeline skeletons onto parallel
platforms has received some attention. In particular, Subhlok and Vondran [9,10]
have dealt with this problem on homogeneous platforms. In this paper, we extend their work and target heterogeneous clusters. Our main goal is to assess
the additional complexity induced by the heterogeneity of processors, and/or of
communication links. As in [9], we aim at deriving optimal mappings, i.e. mappings which minimize the period of the system. Each pipeline stage can be seen
as a sequential procedure which may perform disc accesses or write data in the
memory for each task. This data may be reused from one task to another, hence
tasks must be processed in sequential order within a stage. Moreover, due to
the possible local memory accesses, a given stage must be mapped onto a single
processor: we cannot process half of the tasks on a processor and the remaining
tasks on another without exchanging intra-stage information, which might be
costly and diﬃcult to implement. Therefore a processor that is assigned a stage
will execute the operations required by this stage for all the tasks fed into the
pipeline. The optimization problem can be stated informally as follows: which
stage to assign to which processor? We consider two main variants, in which we
require the mapping to be one-to-one (a processor is assigned at most one stage),
or interval-based (a processor is assigned an interval of consecutive stages).
In addition to these two mapping strategies, we target three diﬀerent platform
types: (i) Fully Homogeneous platforms have identical processors and interconnection links. (ii) Communication Homogeneous platforms, with identical links
but diﬀerent speed processors; and (iii) Fully Heterogeneous platforms, with different speed processors and diﬀerent capacity links. The main objective of the
paper is to assess the complexity of each mapping variant onto each platform
type. We establish several new complexity results for this important optimization
problem, and we derive eﬃcient polynomial heuristics for the most important
policy/platform combination, namely interval-based mappings on Communication Homogeneous platforms.
The rest of the paper is organized as follows. Section 2 presents target optimization problems. Next in Section 3 we proceed to the complexity results. In
Section 4 we introduce several heuristics to solve the mapping problem. These
heuristics are compared through simulations, whose results are analyzed in Section 5. Due to lack of space, related work is not discussed in this paper: please
refer to the extended version [1] for a full overview of relevant literature.

2

Framework

Applicative Framework. We consider a pipeline of n stages Sk , 1 ≤ k ≤ n,
as illustrated on Figure 1. The k-th stage Sk receives an input from the previous

Mapping Pipeline Skeletons onto Heterogeneous Platforms

δ0

S1
w1

δ1

S2
w2

...

δ k−1

Sk

δk

...

wk

sin Pin

Sn
wn

δn

Pout sout
bv,out

bin,u
Pu
su

Fig. 1. The application pipeline

593

bu,v

Pv
sv

Fig. 2. The target platform

stage, of size δ k−1 , performs a number of wk computations, and outputs data of
size δ k to the next stage.
Target Platform. We target a heterogeneous platform (see Figure 2), with
p processors Pu , 1 ≤ u ≤ p, fully interconnected as a (virtual) clique. There
is a bidirectional link linku,v : Pu → Pv between any processor pair Pu and
Pv , of bandwidth bu,v . Communications contention is taken care of by enforcing the one-port model [2]. In this model, a given processor can be involved in
a single communication at any time-step, either a send or a receive. However,
independent communications between distinct processor pairs can take place simultaneously. The one-port model seems to ﬁt the performance of some current
MPI implementations, which serialize asynchronous MPI sends as soon as message sizes exceed a few megabytes [7]. The speed of processor Pu is denoted as
su , and it takes X/su time-units for Pu to execute X ﬂoating point operations.
We also enforce a linear cost model for communications, hence it takes X/bu,v
time-units to send (resp. receive) a message of size X to (resp. from) Pv . We
assume that additional processors Pin and Pout are devoted to input/output data.
We classify particular platform categories: (i) Fully Homogeneous– Platforms
with identical processors (su = s) and links (bu,v = b). They represent typical
parallel machines. (ii)Communication Homogeneous– Platforms with diﬀerentspeed processors (su = sv ) interconnected by links of same capacities (bu,v = b).
They correspond to networks of workstations with plain TCP/IP interconnects
or other LANs. (iii) Fully Heterogeneous– Platforms with su = sv and bu,v =
bu ,v . Hierarchical platforms made up with several clusters interconnected by
slower backbone links can be modeled this way.
Mapping Problem. The general mapping problem consists in assigning application stages to platform processors. Two diﬀerent mapping strategies are
discussed below.
One-to-one Mapping. Assume that each stage Sk of the application pipeline is
mapped onto a distinct processor Palloc(k) (which is possible only if n ≤ p). What
is the period of Palloc(k) , i.e. the minimum delay between the processing of two
consecutive tasks? To answer this question, we need to know which processors
the previous and next stages are assigned to. Let t = alloc(k − 1), u = alloc(k)
and v = alloc(k + 1). Pu needs δ k−1 /bt,u to receive the input data from Pt ,
wk /su to process it, and δ k /bu,v to send the result to Pv , hence a cycle-time of

594

A. Benoit and Y. Robert

δ k−1 /bt,u + wk /su + δk /bu,v for Pu . The period achieved with the mapping is the
maximum of the cycle-times of the processors.
The optimization problem can be stated as follows: determine a one-to-one
allocation function alloc : [1, n] → [1, p] (augmented with alloc(0) = in and
alloc(n + 1) = out) such that the period Tperiod is minimized, where:
Tperiod = max

1≤k≤n

δ k−1
balloc(k−1),alloc(k)

+

wk
salloc(k)

+

δk
balloc(k),alloc(k+1)

(1)

Interval Mapping. One-to-one mappings may be unduly restrictive. A natural extension is to search for interval mappings, i.e. allocation functions where
each participating processor is assigned an interval of consecutive stages. Intuitively, assigning several consecutive tasks to the same processors will increase
their computational load, but may well dramatically decrease communication
requirements. In fact, the best interval mapping may turn out to be a one-toone mapping, or instead may enroll only a very small number of fast computing
processors interconnected by high-speed links. Interval mappings constitute a
natural and useful generalization of one-to-one mappings. To express this optimization problem, we need to enforce that the intervals achieve a partition of
the original set of stages S1 to Sn . We search for a partition of [1..n] into m
intervals Ij = [dj , ej ] such that dj ≤ ej for 1 ≤ j ≤ m, d1 = 1, dj+1 = ej + 1 for
1 ≤ j ≤ m − 1 and em = n. Interval Ij is mapped onto processor Palloc(j) , and
the period is expressed as
Tperiod = max

1≤j≤m

δ dj −1
balloc(j−1),alloc(j)

+

ej
i=dj

wi

salloc(j)

+

δ ej
balloc(j),alloc(j+1)

(2)

Here, we assume that alloc(0) = in and alloc(m + 1) = out. The search is over
all possible partitions into intervals, and over all processor assignments.

3

Complexity Results

To the best of our knowledge, this work is the ﬁrst to study the complexity of
the One-to-one Mapping and Interval Mapping strategies, for each of the
diﬀerent platform categories (Fully Homogeneous, Communication Homogeneous
and Fully Heterogeneous). Table 1 summarizes all our new results.
For Fully Homogeneous or Communication Homogeneous platforms, determining the optimal One-to-one Mapping can be achieved through a binary
search over possible periods, invoking a greedy algorithm at each step. The problem surprisingly turns out to be NP-hard for Fully Heterogeneous platforms. The
Interval Mapping problem is more complex to deal with. For Fully Homogeneous platforms we simply recall the optimal dynamic programming algorithm
of Subhlok and Vondran [9]. For Communication Homogeneous platforms the
problem turns out to be NP-hard. Quite interestingly, this result is a consequence of the fact that the natural extension of the chains-to-chains problem [5]

Mapping Pipeline Skeletons onto Heterogeneous Platforms

595

to diﬀerent-speed processors is NP-hard1 . Finally, both optimization problems
are NP-hard for Fully Heterogeneous platforms.
The proof of all these results, as well as the description of the binary search
and dynamic programming algorithms, are provided in the extended version [1].
Table 1. Complexity results for the diﬀerent instances of the mapping problem
Fully Homogeneous Comm. Homogeneous Fully Heterogeneous
One-to-one polyn. (bin. search)
polyn. (bin. search)
NP-complete
Interval polyn. (dyn. prog. [9])
NP-complete1
NP-complete

4

Heuristics

In this section several heuristics for Communication Homogeneous platforms are
presented. We restrict to such platforms because, as already pointed out in Section 1, clusters made of diﬀerent-speed processors interconnected by either plain
Ethernet or a high-speed switch constitute the typical experimental platforms
in most academic or industry research departments.
BS121: Binary Search for One-to-One Mapping– This heuristic implements the optimal polynomial algorithm for the One-to-one Mapping case [1].
When p < n, we cut the application in ﬁxed intervals of size L = n/p .
SPL: Splitting Intervals – This heuristic sorts the processors by decreasing
speed, and starts by assigning all the stages to the ﬁrst processor in the list.
This processor becomes used. Then, at each step, we select the used processor j
with the largest period and we try to split its interval of stages, giving some
stages to the next fastest processor j in the list (not yet used). This can be
done by splitting the interval at any place, and either placing the ﬁrst part of
the interval on j and the remainder on j , or the other way round. The solution
which minimizes max(period(j), period(j )) is chosen if it is better than the
original solution. Splitting is performed as long as we improve the period of the
solution.
BSL and BSC: Binary Search (Longest/Closest) – The last two heuristics
perform a binary search on the period of the solution. For a given period P , we
study if there is a feasible solution, starting with the ﬁrst stage (s = 1) and
constructing intervals (s, s ) to ﬁt on processors. For each processor u, and each
s ≥ s we compute the period (s, s , u) of stages s..s running on processor u
and check whether it is smaller than P (then it is a possible assignment). The
ﬁrst variant BSL choose the longest possible interval (maximizing s ) ﬁtting on
a processor for a given period, and in case of equality, the interval and processor
1

For the sake of completeness, this result is mentioned here, but it was not available
at the date of the original submission. Please refer to the extended version [1] for
further information on the chains-to-chains problem [3,5], and the NP-completeness
of its generalization to heterogeneous platforms.

596

A. Benoit and Y. Robert

with the closest period to the solution period. The second variant BSC does not
take into account the length of the interval, but only ﬁnds out the closest period.
The code for these heuristics and more heuristics described in [1] can be found
on the Web at: http://graal.ens-lyon.fr/∼abenoit/code/sh.c

5

Experiments

Several experiments have been conducted in order to assess the performance of
the previous heuristics. We have generated a set of random applications with
n = 1 to 50 stages, and two sets of random platforms, one set with p = 10
processors and the other with p = 100 processors. The ﬁrst case corresponds
to a situation in which several stages are likely to be mapped on the same
processor because there are much fewer processors than stages. However, in the
second case, we expect the mapping to be a One-to-one Mapping, except
when communications are really costly. The heuristics have been designed for
Communication Homogeneous platforms, so we restrict to such platforms in
these experiments. Although there are four categories of parameters to play
with, i.e. the values of δ, w, s and b, we can see from equation (2) that only the
relative ratios δb and ws have an impact on the performance.
Each experimental value reported in the following has been calculated as
an average over 100 randomly chosen application/platforms pairs. We report
four main sets of experiments. For each of them, we vary some key application/platform parameter to assess the impact of this parameter on the performance of the heuristics. The ﬁrst two experiments deal with applications where
communications and computations have the same order of magnitude, and we
study the impact of the degree of heterogeneity of the communications: in the
ﬁrst experiment the communication are homogeneous, while in the second one
they are heterogeneous. The last two experiments deal with imbalanced applications: the third experiment assumes large computations (large value of the w
to δ ratio), while the fourth one reports results for small computations.
Please refer to the extended version [1] for a detailed description of each set of
experiments and the full results description. We ﬁrst point out that our heuristics are always much more eﬃcient than random or greedy mappings described
in [1], and which do not appear in these curves for readability reasons. Each
of our heuristics may turn out to be the most eﬃcient, depending upon the
application and platform characteristics. When there are more processors than
pipeline stages, we can expect that a One-to-one Mapping is a good choice.
If communications are homogeneous or less important than the computational
part, the optimal binary search BS121 should be used (Experiments 1 and 3,
with p = 100, see for instance Figure 3). With similar communications but
fewer processors (Experiments 1 and 3, p = 10, see for instance Figure 4), it is
necessary to share the computation load between processors, and the decision
where to split intervals can be really relevant. Since BS121 is using intervals of
ﬁxed length, it cannot make any clever choices. In such cases, BSC is the most
eﬃcient heuristic. The third case is when communications are costly or with a

Mapping Pipeline Skeletons onto Heterogeneous Platforms
3.2

300

BinarySearch1to1
SPLitting
BinarySearchLongest
BinarySearchClosest

3.1

597

BinarySearch1to1
SPLitting
BinarySearchLongest
BinarySearchClosest

250

3

Maximum period

Maximum period

200
2.9

2.8

150

100
2.7

50

2.6

2.5

0
0

10

20
30
Number of stages (p=100)

40

50

0

Fig. 3. Experiment 1, p = 100
20

10

20
30
Number of stages (p=10)

40

50

Fig. 4. Experiment 3, p = 10

BinarySearch1to1
SPLitting
BinarySearchLongest
BinarySearchClosest

18

Maximum period

16

14

12

10

8
0

10

20

30

40

50

Number of stages (p=100)

Fig. 5. Experiment 2, p = 100

high degree of heterogeneity, as in Experiments 2 and 4 (see for instance Figure 5). Then BS121 do not return satisfying results, because it may cut intervals
on costly links between stages (independently of the number of processors). In
such cases, the splitting heuristic SPL is the best choice.

6

Conclusion

In this paper, we have thoroughly studied the diﬃcult problem of mapping applications which have a pipeline structure onto heterogeneous platforms. To the
best of our knowledge, it is the ﬁrst time that pipeline mapping is studied from
a theoretical perspective, while it is quite a standard and widely used pattern
in many real-life applications. The optimal algorithms and complexity results
provided in this paper for the diﬀerent mapping strategies and platform types
represent a signiﬁcant contribution to the theoretical analysis of this important
optimization problem. In addition to the optimal algorithms for Fully Homogeneous platforms, we designed a set of eﬃcient polynomial heuristics for the
One-to-one Mapping and Interval Mapping strategies on Communication
Homogeneous platforms. Finally, we point out that the absolute performance
of the heuristics is quite good, since their result is close to the optimal solution

598

A. Benoit and Y. Robert

returned by an integer linear program. Due to a lack of space, this last important
result is discussed in [1].
There remains much work to extend the results of this paper. On the practical
side, we still need to design eﬃcient heuristics for Fully Heterogeneous platforms,
which is a challenging problem. Also, we would like to further assess the interest of fully general mappings, where a processor may be assigned several nonconsecutive stages (hence which do not form an interval). Such mappings, which
are discussed in the extended version [1], require a multi-port communication
model instead of the one-port model used in this paper. In the longer term, we
plan to perform real experiments on heterogeneous platforms, using an alreadyimplemented skeleton library, in order to compare the eﬀective performance of
the application for a given mapping (obtained with our heuristics) against the
theoretical performance of this mapping. A natural extension of this work would
be to consider other widely used skeletons: when there is a bottleneck in the
pipeline operation due to a stage which is both computationally-demanding and
not constrained by internal dependencies, we can split the workload of this stage
among several processors. Extending our mapping strategies to automatically
identify opportunities for such deal skeletons [4], and implement these, is a difﬁcult but very interesting perspective.

References
1. Benoit, A., Robert, Y.: Mapping pipeline skeletons onto heterogeneous platforms. Research Report 2007-05, LIP, ENS Lyon, France, available at
graal.ens-lyon.fr/∼ yrobert/ (2007)
2. Bhat, P., Raghavendra, C., Prasanna, V.: Eﬃcient collective communication in
distributed heterogeneous systems. Journal of Parallel and Distributed Computing
63 (2003) 251–263
3. Bokhari, S.H.: Partitioning problems in parallel, pipeline, and distributed computing. IEEE Trans. Computers 37(1) (1988) 48–57
4. Cole, M.: Bringing Skeletons out of the Closet: A Pragmatic Manifesto for Skeletal
Parallel Programming. Parallel Computing 30(3) (2004) 389–406
5. Pinar, A., Aykanat, C.: Fast optimal load balancing algorithms for 1D partitioning.
J. Parallel Distributed Computing, 64(8) (2004) 974–996
6. Rabhi, F., Gorlatch, S.: Patterns and Skeletons for Parallel and Distributed Computing. Springer Verlag (2002)
7. Saif, T., Parashar, M.: Understanding the behavior and performance of nonblocking communications in MPI. In: Proceedings of Euro-Par 2004: Parallel Processing, LNCS 3149, Springer (2004) 173–182
8. Shirazi, B.A, Hurson, A.R, Kavi, K.M.: Scheduling and load balancing in parallel
and distributed systems. IEEE Computer Science Press (1995)
9. Subhlok, J., Vondran, G.: Optimal mapping of sequences of data parallel tasks.
In: Proc. 5th ACM SIGPLAN Symposium on Principles and Practice of Parallel
Programming, PPoPP’95, ACM Press (1995) 134–143
10. Subhlok, J., Vondran, G.: Optimal latency-throughput tradeoﬀs for data parallel
pipelines. In: ACM Symposium on Parallel Algorithms and Architectures SPAA’96,
ACM Press (1996) 62–71

