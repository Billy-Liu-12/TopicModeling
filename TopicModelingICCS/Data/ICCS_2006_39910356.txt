Speech Event Detection Using Support Vector
Machines
P. Y´elamos1, J. Ram´ırez1 , J.M. G´
orriz1 ,
2
C.G. Puntonet , and J.C. Segura1
1

Dept. of Signal Theory, Networking and Communications,
University of Granada, Spain
javierrp@ugr.es
2
Dept. of Architecture and Computer Technology,
University of Granada, Spain

Abstract. An eﬀective speech event detector is presented in this work
for improving the performance of speech processing systems working in
noisy environment. The proposed method is based on a trained support
vector machine (SVM) that deﬁnes an optimized non-linear decision rule
involving the subband SNRs of the input speech. It is analyzed the classiﬁcation rule in the input space and the ability of the SVM model to
learn how the signal is masked by the background noise. The algorithm
also incorporates a noise reduction block working in tandem with the
voice activity detector (VAD) that has shown to be very eﬀective in high
noise environments. The experimental analysis carried out on the Spanish SpeechDat-Car database shows clear improvements over standard
VADs including ITU G.729, ETSI AMR and ETSI AFE for distributed
speech recognition (DSR), and other recently reported VADs.

1

Introduction

With the advent of wireless communications, new speech services are being deployed with the development of modern robust speech processing technology.
An important obstacle aﬀecting these systems is the environmental noise and
its harmful eﬀect on the system performance. Most of the noise reduction algorithms often require a precise voice activity detector (VAD). The detection
task is not as trivial as it appears since the increasing level of background noise
degrades the classiﬁer eﬀectiveness.
Since their introduction in the late seventies [1], Support Vector Machines
(SVMs) marked the beginning of a new era in the learning from examples paradigm. SVMs have attracted recent attention from the pattern recognition community due to a number of theoretical and computational merits derived from
the Statistical Learning Theory [2, 3] developed by Vladimir Vapnik at AT&T.
Enqing [4] applied SVMs to the VAD problem showing promising results when
the standardized ITU-T G.729 VAD [5] speech features were used as the inputs
to the classiﬁcation module. Later, this VAD was incorporated to a variable low
bit-rate speech codec [6] using the local cosine transform. Recently, Qi et al.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 356–363, 2006.
c Springer-Verlag Berlin Heidelberg 2006

Speech Event Detection Using Support Vector Machines

357

[7] has extended these ideas to the problem of classifying speech into voiced,
unvoiced and silence frames. Again the SVM-based classiﬁer operated on the
G.729 speech features including the full-band energy diﬀerence, the low-band
energy diﬀerence, the spectral distortion and the zero-crossing rate. This paper shows an eﬀective SVM-based speech event detector for low-delay speech
processing. The proposed method combines a noise robust speech processing
feature extraction process together with a trained SVM model for classiﬁcation. The results show improvements in speech/pause discrimination when compared to standardized VADs [5, 8, 9] and other recently published VAD methods
[10, 11, 12, 13].

2

Support Vector Machines

SVMs have recently been proposed for pattern recognition in a wide range of
applications by its ability for learning from experimental data. The reason is
that SVMs are much more eﬀective than other conventional parametric classiﬁers. In SVM-based pattern recognition, the objective is to build a function
f : RN −→ {±1} using training data that is, N -dimensional patterns xi and
class labels yi :
(x1 , y1 ), (x2 , y2 ), ..., (x , y ) ∈ RN × {±1}

(1)

so that f will correctly classify new examples (x, y).
Hyperplane classiﬁers are based on the class of decision functions:
f (x) = sign{(w · x) + b}

(2)

It can be shown that the optimal hyperplane is deﬁned as the one with the
maximal margin of separation between the two classes. The solution w of a
constrained quadratic optimization process can be expanded in terms of a subset
of the training patterns called support vectors that lie on the margin:
w=

νi xi

(3)

i=1

Thus, the decision rule depends only on dot products between patterns:
νi (xi · x) + b}

f (x) = sign{

(4)

i=1

The use of kernels in SVM enables to map the data into some other dot
product space (called feature space) F via a nonlinear transformation Φ : RN −→
F and perform the above linear algorithm in F. Figure 1 illustrates this process
where the 2-D input space is mapped to a 3-D feature space where the data is
linearly separable. The kernel is related to the Φ function by k(x, y) = (Φ(x) ·
Φ(y)) In the input space, the hyperplane corresponds to a nonlinear decision

358

P. Y´elamos et al.

function whose form is determined by the kernel. There are three common kernels
that are used by SVM practitioners for the nonlinear feature mapping:
– Polynomial
k(x, y) = [γ(x · y) + c]d

(5)

– Radial basis function (RBF)
k(x, y) = exp(−γ||x − y||2 )

(6)

k(x, y) = tanh(γ(x · y) + c)

(7)

– Sigmoid

Thus, the decision function is nonlinear in the input space
νi k(xi , x) + b}

f (x) = sign{

(8)

i=1

and the parameters νi are the solution of a quadratic programming problem
that are usually determined by the well known Sequential Minimal Optimization
(SMO) algorithm [14]. Many classiﬁcation problems are always separable in the
feature space and are able to obtain better results by using RBF kernels instead
of linear and polynomial kernel functions [15, 16].
F(3)
x(2)

Ö(·)

F(2)
x(1)

F(1)
Input space

Feature space

Fig. 1. Eﬀect of the map from input to feature space where the separation boundary
becomes linear

3

Speech Event Detection

The ﬁrst step in deﬁning the classiﬁcation rule is the training process on the
training data set and the associated class labels. The signal is preprocessed
and a feature vector is extracted for training. Once the SMV model has been
trained, the proposed speech event detector is described as follows: i) the input
signal is decomposed into speech frames and feature extraction is conducted for
classiﬁcation, and ii) the speech features x are processed by the SVM decision
function f deﬁned in equation 8.

Speech Event Detection Using Support Vector Machines
x(n)

X(w)
DFT

Xf(w)

Denoising
(Wiener filter)

Filterbank

Subband
SNRs

359

x

N(w)
Residual noise
spectrum
estimation

Noise
spectrum
estimation

Nr(w)

Fig. 2. Block diagram of the proposed SVM-based VAD

3.1

Feature Extraction

The algorithm for feature extraction is stated as follows. The input signal x(n)
sampled at 8 kHz is decomposed into 25-ms overlapped frames with a 10-ms
window shift. The current frame consisting of 200 samples is zero padded to 256
samples and power spectral magnitude X(ω) is computed through the discrete
Fourier transform (DFT). A denoising process based on a two-stage Wiener ﬁlter
is applied to improve the performance of the VAD in high noise environments.
It is described as follows:
1. Spectral subtraction.
S1 (ω) = Ls Xf (ω) + (1 − Ls ) max(X(ω) − αN (ω), βX(ω))

(9)

2. First WF design and ﬁltering.
μ1 (ω) = S1 (ω)/N (ω)
W1 (ω) = μ1 (ω)/(1 + μ1 (ω))
S2 (ω) = W1 (ω)X(ω)

(10)

3. Second WF design and ﬁltering.
μ2 (ω) = S2 (ω)/N (ω)
W2 (ω) = max(μ2 (ω)/(1 + μ2 (ω)), β)
Xf (ω) = W2 (ω)X(ω)

(11)

where Ls = 0.99, α = 1 and β = 10(−22/10) is selected to ensure a -22dB maximum attenuation for the ﬁlter in order to reduce the high variance musical noise
that normally appears due to rapid changes across adjacent frequency bins. Once
the input signal has been denoised, a ﬁlterbank reduces the dimensionality of
the feature vector to a representation including broadband spectral information
suitable for detection. Thus, the signal and the residual noise is passed through
a K-band ﬁlterbank which is deﬁned by
ωk+1

EB (k) =

ωk+1

Xf (ω);

ω=ωk
π
k
ωk = K

NB (k) =

N (ω)
ω=ωk

(12)

k = 0, 1, ..., K − 1

and the subband SNRs are computed as
SNR(k) = 20 log10

EB (k)
NB (k)

k = 1, 2, ..., K − 1

(13)

360

P. Y´elamos et al.
Training data

Upper band SNR

60

40

20

0

−20
60
40
60

20

40
0

20
−20

Medium band SNR

0
−20

Lower band SNR

(a)
SVM decision rule

20

Upper band SNR

15
10
5
0
−5
−10
20
20

10
10
0
Medium band SNR

0
−10

−10

Lower band SNR

(b)
Fig. 3. Classiﬁcation rule in the input space after training a 3-band SVM model. a)
Training data set, b) SVM classiﬁcation rule.

Speech Event Detection Using Support Vector Machines

3.2

361

Training

The SVM model has been trained using LIBSVM software tool [17]. A training
set consisting of 12 utterances of the AURORA 3 Spanish SpeechDat-Car (SDC)
was used. This database contains 4914 recordings using close-talking and distant
microphones from more than 160 speakers. The ﬁles are categorized into three
noisy conditions: quiet, low noisy and highly noisy conditions, which represent
diﬀerent driving conditions with average SNR values between 25dB, and 5dB.
The recordings used for training the SVM are selected to deal with diﬀerent
noisy conditions. Fig. 3.1.a shows the training data set in the 3-band input
space. After the training process, the SVM decision rule deﬁned by equation 8
is graphically shown in Fig 3.1.b where the non-speech and speech classes are
clearly distinguished in the 3-D space. Note that, the SVM model learns how
the signal is masked by the noise and automatically deﬁnes the decision rules in
the input space.
The SVM formulation is based on C -Support Vector Classiﬁcation [18, 3] while
the decision rule is deﬁned by equation 8. An RBF kernel is used and the training
process consists in ﬁnding the solution of a primal problem
minα 12 αT Qα − eT α
0 ≤ αi ≤ C, i = 1, 2, ...,
subject to
yα = 0

(14)

by using LIBSVM [17], where e= [1 1 ... 1], C > 0 is the upper bound and
Qij = yi yj k(xi , xj ). After this process, the support vectors xi and coeﬃcients
αi required to evaluate the decision rule deﬁned in equation 8 are selected where
νi = yi αi . Note that, b can be used as a decision threshold for the VAD in the
sense that the working point of the VAD can be shifted in order to meet the
application requirements.

4

Experimental Framework

This section analyzes the proposed VAD and compares its performance to other
algorithms used as a reference. The analysis is based on the ROC curves, a
frequently used methodology to describe the VAD error rate. The AURORA
subset of the original Spanish SDC database [19] was used again in this analysis.
The non-speech hit rate (HR0) and the false alarm rate (FAR0= 100-HR1)
were determined for each noisy condition being the actual speech frames and
actual speech pauses determined by hand-labelling the database on the closetalking microphone. Thus, the objetive is to work as close as possible to the
ideal [0%,100%] point where both speech and non-speech are determined with
no error. Preliminary experiments determined that increasing the number of
subbands up to four subbands improved the performance of the proposed VAD
by shifting the ROC curves in the ROC space.
Fig. 4 compares the ROC curve of the proposed VAD to frequently referred
algorithms [11, 12, 13, 10] for recordings from the distant microphone high noisy

362

P. Y´elamos et al.

conditions. The working points of the ITU-T G.729, ETSI AMR and AFE VADs
are also included. The results show improvements in detection accuracy. Thus,
among all the VAD examined, our VAD yields the lowest false alarm rate for a
ﬁxed non-speech hit rate and also, the highest non-speech hit rate for a given false
alarm rate. The beneﬁts are especially important over ITU-T G.729 [5], which
is used along with a speech codec for discontinuous transmission, and over the
Li’s algorithm [12], that is based on an optimum linear ﬁlter for edge detection.
The proposed VAD also improves Marzinzik’s VAD [13] that tracks the power
spectral envelopes, and the Sohn’s VAD [10], that formulates the decision rule
by means of a model-based statistical likelihood ratio test.

PAUSE HIT RATE (HR0)

100

80

SVM VAD
G.729
AMR1
AMR2
AFE (Noise Est.)
AFE (frame-dropping)
Li
Marzinzik
Sohn
Woo

60

40

20

0
0

10

20

30

40

FALSE ALARM RATE (FAR0)

50

60

Fig. 4. Comparative results to other VAD methods

5

Conclusions

This paper has shown an eﬀective speech event detector combining spectral noise
reduction and support vector machine learning tools. The use of kernels enables
deﬁning a non-linear decision rule in the input space which is deﬁned in terms of
subbands SNRs. It is also shown the ability of SVM tools to learn how the speech
is masked by the acoustic noise. With these and other innovations the proposed
method has shown to be more eﬀective than VADs that deﬁne the decision rule
in terms of an average SNR values. The proposed algorithm also outperformed
ITU G.729, ETSI AMR1 and AMR2 and ETSI AFE standards and recently
reported VAD methods in speech/non-speech detection performance.

Acknowledgements
This work has been funded by the European Commission (HIWIRE, IST No.
507943) and the Spanish MEC project TEC2004-03829/FEDER.

Speech Event Detection Using Support Vector Machines

363

References
1. Vapnik, V.: Estimation of Dependences Based on Empirical Data. Springer-Verlag,
New York (1982)
2. Vapnik, V.: The Nature of Statistical Learning Theory. Springer-Verlag, Berlin
(1995)
3. Vapnik, V.: Statistical Learning Theory. John Wiley and Sons, Inc., New York
(1998)
4. Enqing, D., Guizhong, L., Yatong, Z., Xiaodi, Z.: Applying support vector machines
to voice activity detection. In: 6th International Conference on Signal Processing.
Volume 2. (2002) 1124–1127
5. ITU: A silence compression scheme for G.729 optimized for terminals conforming
to recommendation V.70. ITU-T Recommendation G.729-Annex B (1996)
6. Enqing, D., Heming, Z., Yongli, L.: Low bit and variable rate speech coding using local cosine transform. In: Proc. of the 2002 IEEE Region 10 Conference
on Computers, Communications, Control and Power Engineering (TENCON ’02).
Volume 1. (2002) 423–426
7. Qi, F., Bao, C., Liu, Y.: A novel two-step SVM classiﬁer for voiced/unvoiced/silence
classiﬁcation of speech. In: International Symposium on Chinese Spoken Language
Processing. (2004) 77–80
8. ETSI: Voice activity detector (VAD) for Adaptive Multi-Rate (AMR) speech traﬃc
channels. ETSI EN 301 708 Recommendation (1999)
9. ETSI: Speech processing, transmission and quality aspects (STQ); distributed
speech recognition; advanced front-end feature extraction algorithm; compression
algorithms. ETSI ES 201 108 Recommendation (2002)
10. Sohn, J., Kim, N.S., Sung, W.: A statistical model-based voice activity detection.
IEEE Signal Processing Letters 16 (1999) 1–3
11. Woo, K., Yang, T., Park, K., Lee, C.: Robust voice activity detection algorithm
for estimating noise spectrum. Electronics Letters 36 (2000) 180–181
12. Li, Q., Zheng, J., Tsai, A., Zhou, Q.: Robust endpoint detection and energy normalization for real-time speech and speaker recognition. IEEE Transactions on
Speech and Audio Processing 10 (2002) 146–157
13. Marzinzik, M., Kollmeier, B.: Speech pause detection for noise spectrum estimation
by tracking power envelope dynamics. IEEE Transactions on Speech and Audio
Processing 10 (2002) 341–351
14. Platt, J.: Fast Training of Support Vector Machines using Sequential Minimal
Optimization. In: Advances in Kernel Methods - Support Vector Learning. MIT
Press (1999) 185–208
15. Clarkson, P., Moreno, P.: On the use of support vector machines for phonetic
classiﬁcation. In: Proc. of the IEEE Int. Conference on Acoustics, Speech and
Signal Processing. Volume 2. (1999) 585–588
16. Ganapathiraju, A., Hamaker, J., Picone, J.: Applications of support vector machines to speech recognition. IEEE Transactions on Signal Processing 52 (2004)
2348–2355
17. Chang, C., Lin, C.J.: LIBSVM: a library for support vector machines. Technical
report, Dept. of Computer Science and Information Engineering, National Taiwan
University (2001)
18. Cortes, C., Vapnik, V.: Support-vector network. Machine Learning (1995)
19. Moreno, A., Borge, L., Christoph, D., Gael, R., Khalid, C., Stephan, E., Jeﬀrey,
A.: SpeechDat-Car: A Large Speech Database for Automotive Environments. In:
Proceedings of the II LREC Conference. (2000)

