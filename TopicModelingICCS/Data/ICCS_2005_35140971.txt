Statistical Inference Method of User Preference on
Broadcasting Content
Sanggil Kang1, Jeongyeon Lim2, and Munchurl Kim2
1 Department

of Computer Science, College of Information Engineering,
The University of Suwon, Hwaseong, Gyeonggi-do, Korea
sgkang@suwon.ac.kr
2
Laboratory for Multimedia Computing, Communications and Broadcasting,
Information and Communications University, Daejeon, Korea
{jylim,mkim}@icu.ac.kr

Abstract. This paper proposes a novel approach for estimating the statistical
multimedia user preference by providing weights to multimedia contents with
respective to their consumed time. The optimal weights can be obtained by
training the statistical system in the sense that the mutual information between
old preference and current preference is maximized. The weighting scheme can
be done by partitioning a user’s consumption history data into smaller sets in a
time axis. With developing a mathematical derivation of our learning method,
experiments were implemented for predicting the TV genre preference using
2,000 TV viewers’ watching history and showed that the performance of our
method is better than that of the typical method.

1 Introduction
With the flood of multimedia content over the digital TV channels, the internet, and
etc., users sometimes have a difficulty in finding their preferred content, spend heavy
surfing time to find them, and are even very likely to miss them while searching. By
predicting or recommending the user’s preferred content, based on her/his usage
history in content consumptions, the problems can be solved to some extent.
Various preference recommendation techniques can be classified into three
possible categories such as the rule-based, collaborative filtering, and inference
method. The rule-based recommendation is usually implemented by a predetermined
rule, for instance, if -then rule. Kim et al. [1] proposed a marketing rule extraction
technique for personalized recommendation on internet storefronts using tree
induction method [2]. As one of representative rule-based techniques, Aggrawall et al.
[3, 4] proposed a method to identify frequent item sets from the estimated frequency
distribution using association-rule mining algorithm [5]. Collaborative filtering (CF)
technique recommends a target user the preferred content of the group whose content
consumption mind is similar to that of the user. Because of the nature of the
technique, CF has been attractive for predicting various preference problems such as
net-news [6, 7], e-commerce [8, 9], digital libraries [10, 11], digital TV [12, 13]. In
general, rule-based and CF techniques need expensive effort, time, and cost to collect
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3514, pp. 971 – 978, 2005.
© Springer-Verlag Berlin Heidelberg 2005

972

S. Kang, J. Lim, and M. Kim

a large number of users’ consumption behavior due to the nature of their
methodologies. However, inference is the technique that a user’s content consumption
behavior is predicted based on the history of personal content consumption behaviors.
Ciaramita et al. [14] presented a Bayesian network [15], the graphical representation
of probabilistic relationship among variables which are encoded as nodes in the
network, for verb selectional preference by combining the statistical and knowledgebased approaches. The architecture of the Bayesian network was determined by the
lexical hierarch of Wordnet [16]. Lee [17] designed an interface agent to predict a
user’s resource usage in the UNIX domain by the probabilistic estimation of
behavioral patterns from the user behavior history.
From the literatures mentioned above, there is one thing not to be overlooked,
which is that all data are equally weighted in computing the statistical preference. In
this case, recently collected data may not be appreciated because the size of the user’s
usage history data usually dominates over that of the new data. In general, the recent
usage history will give more impact on predicting the future preference than old one.
In order to take into the consideration, we provide weights to data with respect to their
collected or consumed time.
The objective of our work is to find the optimal weights bringing better
performance than the typical methods. In this paper, a new adaptive learning method
is proposed for obtaining the optimal weights. Our method executes by partitioning
the usage history data into smaller sets in a time axis, on which the weights are
provided. Thus, the weighted data can differently reflect their significance on
predicting the preference. We utilize a supervised learning technique commonly used
in neural network for estimating the weights using the mutual information , which is
an optimality index to be maximized during the learning process. Also, the weights
are updated whenever a predetermined amount of data is collected.
The remainder of this paper is organized as follows. Section 2 describes a window
weighing scheme. Section 3 describes our learning method. In Section 4, we show the
experimental results performed on a realistic set of data. We then conclude our paper
in Section 5.

2 Window Weights
For predicting users’ preference, the time that content is consumed can be a critical
factor. In order to consider this, we partition the usage history data stored in a
chronicle into smaller sets in a time axis and give weights to the frequencies of
content in the partitioned datasets. The smaller dataset, named as window in our
paper, resides within a predetermined non-overlapped time interval L . Usually, the
content in the recent windows will give a potent influence on predicting the future
preference. In case the data size in those windows is not big, it can not be enough to
represent the statistical future preference, which makes us reluctant to use only the
latest window. To compensate this problem, we group the windows into two regions:
old preference region (OPR) and current preference region (CPR). CPR includes the
latest window and is used as a reference for predicting future preference. The OPR
has enough windows in order for the estimated conditional probabilities in the region
to be able to represent the future preference (FP), compared to CPR. The frequencies

Statistical Inference Method of User Preference on Broadcasting Content

973

of content can be modified by assigning weights to the windows in OPR. A set of the
window weights can be denoted as w = [ w1 w2 … wM ] , here M is the total number

of windows in the OPR. The statistical preference of the i th content xi in OPR can be
expressed as

θˆxi = p( X = xi | E ) =

M

∑

m =1

wm ni , m /

M

∑

m =1

wm N m

(1)

where X is a set of consumed content, and N m and ni , m is the sample number of
whole content and content xi within the m th window in OPR, respectively. Also, θˆxi

is the estimated statistical preference of xi for FP with given evidence E . From
Equation (1), we can see that the conditional probability is a function of the window
weights, which means the accuracy of the preference prediction depends upon the
values of the weights. As addressed, the latest window can give a big impact on
predicting the future preference (FP) so the weights are adjusted in the sense that a set
~
of the content in the OPR, denoted as X O , is getting correlated with a set of weighted
~
content in the CPR, denoted as X C . Here, X O is the weighted version of X O which
is a set of content in the OPR.
In some typical methods, the statistical preference is computed using the entire
history dataset, which causes the new coming content not be appreciated in estimating
the preference because the size of the user’s usage history data usually dominates over
that of the new content.. In order to complement this weak point, we rule out the most
outdated window when new data is filed up during the next time interval L from the
last window in the usage history data. It can be operated by shifting (or sliding) a
window at a time and continuing the same processing to find the optimal weights and
so on. This scheme can allow an on-line prediction. From the following section, s

with the parenthesis indicate the s th window shifting process.

3 Determination of Optimal Window Weights
Our learning method is to determine an optimal set of the window weights in the
~
sense that the mutual information, denoted as I X O (s ); X C (s ) , between X C (s ) and
~
X O (s ) is maximized at the s th shift. At each window shifting, the weight updates are
done based on a gradient ascent algorithm. The weight update continues until the
mutual information (MI) reaches the maximum value. The mathematical derivation of
our learning method starts with the definition of the MI such as
~
~
I X O (s ); X C (s ) = log p X C (s ) | X O (s ) / p( X C (s ))
(2)
~
= log p X C (s ) | X O (s ) − log( p( X C (s ))).

(

(

)

((
((

)
))

)

)

From Equation (2), the larger the value of the MI, the more X C (s ) is correlated
~
with X O (s ) . We assume that X C (s ) includes at least a content to exclude the extreme

974

S. Kang, J. Lim, and M. Kim

Usage
history

~
XO (s)

XO (s)

θ xi (s)

XC (s)

(

Weights
w(s)

)

accuracy

~
I XO (s); XC (s)

Comparison:

θˆxi (s)
Fig. 1. The schematic of learning method

case in which the equation can not be appropriately applied. For instance, if
~
X C (s ) = Θ then the log p Θ | X O (s ) can not be calculated, where Θ means the
empty set. As searching the optimal weights in the weight space, the partial derivative
of the mutual information with respective to the weight wm (s ) is calculated as
following:
~
∂I X O (s ); X C (s ) / ∂wm (s )
(3)
~
= ∂ log p X C (s ) | X O (s ) / ∂wm (s ) − ∂ log( p( X C (s ))) / ∂wm (s )

((

(

((

))

)

))

where, the MI is composed of the logarithmic functions so it is differentiable at a
concerning point in the weight space. Thus, it is feasible to use the gradients. Since
the prior probability p( X C (s )) on the right hand side is not a function of w(s ) ,
Equation (3) can be simplified as
~
~
(4)
∂I X O (s ); X C (s ) / ∂wm (s ) = ∂ log p X C (s ) | X O (s ) / ∂wm (s )

(

)

((

))

(

)

~
In order to compute the partial derivative, we need to formulize p X C (s ) | X O (s )
in terms of the weights. Let’s consider X C (s ) = [x1 (s ) x2 (s ) " xi (s ) " x J (s )] , here
J is the number of attributes in X C (s ) and assume that all elements in X C (s ) are
~
~
contained in X O (s ) . In order to obtain p X C (s ) | X O (s ) , we first need to determine
~
the conditional probability p xi (s ) | X O (s ) which means the probability of occurring
~
~
attribute xi given X O (s ) . The conditional probability p xi (s ) | X O (s ) is given by

(
)

(

(

)

)

(

~
p xi (s ) | X O (s ) = ∑ wm (s )ni , m (s ) / ∑ wm (s )N m (s )
m

(

m

)

)

(5)

~
The conditional probability p X C (s ) | X O (s ) can be obtained by multiplications of

the conditional probabilities of all content in X C (s ) under the assumption that the
consumption of the contents is independent among them.

Statistical Inference Method of User Preference on Broadcasting Content

(

)

(

975

)

nx ( s )
~
~
p X C (s ) | X O (s ) = ∏ p xi (s ) | X O (s ) i
i

= ∏ ⎛⎜ ∑ wm (s )ni, m (s ) / ∑ wm (s )Nm (s )⎞⎟
i ⎝m
m
⎠

nx

i

(6)

(s)

((

))

~
where n xi (s ) is the number of xi in X C (s ) . Thus, log p X C (s ) | X O (s ) in (2) is
nx (s) ⎞
⎛
i
~
⎟
log p X C (s ) | X O (s ) = log ⎜ ∏ ⎛⎜ ∑ wm (s )ni ,m (s ) / ∑ wm (s )Nm (s )⎞⎟
⎜ i ⎝m
⎟
m
⎠
⎝
⎠
⎛
⎞
= ∑ nxi (s )⎜ log⎛⎜ ∑ wm (s )ni ,m (s )⎞⎟ − log⎛⎜ ∑ wm (s )Nm (s )⎞⎟ ⎟
i
⎠
⎝m
⎠⎠
⎝ ⎝m

((

))

(7)

Therefore,
~
∂I X O (s ); X C (s ) / ∂wm (s )

(

)

= ∑ n xi (s )⎛⎜ n i ,m (s ) / ∑ wm (s ) ni , m (s ) − N m (s ) / ∑ wm (s )N m (s )⎞⎟
i
m
m
⎝
⎠

(8)

The weights are updated every epoch defined as one sweep for all data included in
the current windows. The amount of update ∆wm (s ) can be obtained using the delta
rule such as
~
(9)
∆wm (e, s ) = η ⋅ ∂I X O (s ); X C (s ) / ∂wm (s )

(

)

where notation e is the number of epochs and η is the learning rate which
determines the degree of searching step in the weight space during the learning
process. We can express the weight update in every epoch e as
wm (e, s ) ← wm (e − 1, s ) + ∆wm (e, s ).

(10)

However, the point we should not overlook is that the weights may trace to the
negative weight space during the learning process according to the initial location of
the weights. The negative weights cause a problematic situation in calculating the
conditional probabilities which should always be positive. Thus, the weight searching
can be caught in a vicious circle as the epoch runs. To avoid this situation, we put
restrictions on weight update in order to force weights in only positive space during
training. If a weight move to the negative space, we do not update the weight, as seen
in Equation (11).
⎧wm (e, s ) ← wm (e − 1, s ) + ∆wm (e, s ), if wm (e, s ) > 0 ⎫
⎨
⎬
otherwise ⎭
⎩wm (e, s ) ← wm (e − 1, s ),

(11)

Now, we have a question about stopping criteria like “When do we have to stop
learning?” In our method, the learning process continues until the predetermined
number of epochs is reached, or until the maximum MI is reached. In the case that MI

976

S. Kang, J. Lim, and M. Kim

reaches the saturation much faster than the predetermined epoch, we pay the overtraining time and effort for the large epoch. To avoid this situation, we stop the
training when the MI does not increase any more for some predetermined epoch.

4 Experimental Results and Analysis
In this section, we show the numerical accuracy of our learning method by comparing
with that of the typical method, that is, no-training method in which no weights are
assigned. We applied our method to the Digital TV genre recommendation problem.
For the training and test data set, we used a large set of TV watching history data
collected from December 1, 2002 to May 31, 2003, which is provided by AC Nielsen
Korea, one of the authorized market research company in Korea. For 2,000 TV
viewers, the TV watching history was collected by a set-top box installed in their
houses, which can record login and logout time, broadcasting time and day, watched
program genre, etc. From the data, we can extract only two evidences such as TV
watching time and day for computing the statistical preference of each genre. The
genre includes eight attributes such as Education, Drama & Movie, News, Sports,
Children, Entertainment, Information, Others. The considered watching time is only
from 6 p.m. to 12 p.m. in our experiment because the user barely watched TV during
other time periods. The watching time period was slotted by every two hours for each
day. Thus, the set of evidence can be expressed as E = {(6 p.m. ~ 8 p.m., Monday), (6
p.m. ~ 8 p.m., Monday), . . . , (10 p.m. ~ 12 p.m., Sunday)} with 21 elements. For
each case in E , we first extracted and arranged the genres of the watched TV
programs from each viewer’s watching history and then partitioned them by every
one week. If there is any missing week, the window of the week was replaced with
the next week in order to render training to be possible.
The accuracy is evaluated in terms of the error between the estimated statistical
preference and the true preference for the future preference with η = 0.1 and the initial
weight vector whose elements are all ones.
Error (s ) =

J

∑ θˆx

i =1

i

(s ) − θ x (s )
i

(13)

where θˆxi (s ) and θ xi (s ) is the estimated statistical preference and true preference of

xi for the future preference at shift s , respectively. As sliding one window at a time
until approaching to the last window, we repeated the processes of training and
calculating the errors by varying M, the number of windows in the OPR, for 2,000 TV
viewers. By gender and age group of the viewers, we tabulated the mean error over
the viewers, for the typical and our method as shown in the table.
From the table, it is shown that the performances of our method were better than
those of the typical method for 10s, 20s, 30s, and 40s. For 10s, around 50% at
maximum improvement was made, for 20s and 30s, around 37%, for 40s, around
12%. However, for 50s, it can be stated that there was no improvement. It can be
induced that the trend of the preference of 40s and 50s viewers usually is steadier than

Statistical Inference Method of User Preference on Broadcasting Content

977

10s, 20s, and 30s. It is hard to provide a unique number of windows in OPR for
obtaining optimal performance for all age and gender identity, for instance, the
number of window 3 or 4 for 10s, 4 or 5 for 20s, etc.
Table 1. The mean errors of the typical method and our method by varying the value of M
Age (Gender)

Method

The number of windows in the OPR, M

10s (male)

Typical
Our
Typical
Our
Typical
Our
Typical
Our
Typical
Our
Typical
Our
Typical
Our
Typical
Our
Typical
Our
Typical
Our

3
0.24
0.12
0.22
0.13
0.22
0.14
0.2
0.14
0.22
0.13
0.21
0.14
0.23
0.16
0.19
0.17
0.14
0.15
0.13
0.15

10s (female)
20s & (male)
20s & female
30s & (male)
30s &(female)
40s & (male)
40s& (female)
50s & (male)
50s& (female)

4
0.21
0.1
0.2
0.15
0.21
0.15
0.19
0.11
0.23
0.14
0.19
0.15
0.22
0.17
0.18
0.16
0.15
0.14
0.14
0.13

5
0.22
0.13
0.21
0.16
0.19
0.12
0.22
0.13
0.2
0.12
0.2
0.11
0.23
0.17
0.19
0.17
0.14
0.13
0.15
0.15

6
0.2
0.14
0.24
0.15
0.21
0.14
0.19
0.15
0.22
0.13
0.19
0.11
0.21
0.17
0.18
0.16
0.15
0.13
0.14
0.13

7
0.24
0.16
0.23
0.14
0.2
0.16
0.21
0.13
0.22
0.14
0.22
0.15
0.19
0.16
0.2
0.17
0.14
0.13
0.14
0.12

8
0.23
0.15
0.25
0.15
0.22
0.17
0.22
0.12
0.23
0.13
0.22
0.13
0.22
0.18
0.19
0.18
0.14
0.12
0.15
0.12

5 Conclusion
In this paper, we presented a new system for estimating the statistical user preference
with introducing the window weights and developing the optimal index, the mutual
information, used as a teacher when training the system. By forcing to have old
preference be correlated with current preference, the prediction can be good for the
near future preference which is correlated with the current preference. From the
experimental results, the training speed, which is less than 100 epochs when the initial
weighs are all ones, can be acceptable in the practical situation. Also, it was shown
that our method was outperformed to the typical method for the 10s, 20s, 30s, and
40s age.
However, we determined the optimal values of the parameters from the exhaustive
empirical experience using 2,000 TV viewers’ watching information. The 2,000
viewers might not be enough for the exhaustive experiment. It is needed to collect
more viewers’ information. Also, we need to do further study for developing an
automatic algorithm to estimate the optimal values of parameters for each TV viewer
when training our system.

978

S. Kang, J. Lim, and M. Kim

Acknowledgements
This research work was carried out at Information and Communications University
under the Project titled by “Development of Intelligent Agent and Metadata
Management Technology in SmarTV” in 2004 funded by Ministry of Information and
Communication in Korean government.

References
1. J.W. Kim, B.H. Lee, M.J. Shaw, H.L. Chang, M. Nelson, “Application of decision-tree
induction techniques to personalized advertisements on internet storefronts,” International
Journal of Electronic Commerce, vol. 5, no. 3, pp. 45-62, 2001
2. J.R. Quinlan, Induction of decision trees, “Machine Learning,” vol. 1, pp. 81-106, 1986
3. R. Aggrawall, T. Imielinski, A. Swami, “Mining association rules between sets of items in
large databases,” Proc. ACM SIGMOD Int’l Conference on Management of Data, pp. 207216 , 1994
th
4. R. Aggrawall, R. Srikant, “Fast algorithms for mining association rules,” Proc. 20 Int’l
Conference on Very Large Databases, 478-499, 1994
5. M.Z. Ashrafi, D. Tanizr, K. Smith, “ODAM: An optimized distributed association rule
mining algorithm,” IEEE Distributed Systems Online, vol. 3, no. 3, pp. 1-18, 2004
6. P. Resnick, N. Lacovou, M. Suchak, P. Bergstrom, J. Riedl, “GroupLens: an open
architecture for collaborative filtering of netnews,” Internet Research Report, MIT Center
for Coordination Science, 1994, http://www-sloan.mit.edu/ccs/1994wp.html
7. D.A. Maltz, “Distributing information for collaborative filtering on Usenet net news,” SM
Thesis, Massachusetts Institute of Technology, Cambridge, MA, 1994
8. J.B. Schafer, J. Konstan, J. Riedl, “Recommender systems in e-commerce,” ACM
Conference on Electronic Commerce, pp. 158-166, 1999
9. G. Linden, B. Smith, J. York, “Amazon.com recommendations: item-to-item collaborative
filtering,” IEEE Internet Computing, pp. 76-80, 2003
10. K.D. Bollacker, S. Lawrence, C.L. Giles, “A system for automatic personalized tracking of
scientific literature on the web,” Proc. ACM Conference on Digital Libraries, pp. 105-113,
1999
11. R. Torres, S.M. McNee, M. Abel, J.A. Konstan, J. Riedl, “Enhancing digital libraries with
TechLens+”, ACM/IEEE-CS Joint Conference on Digital Libraries, pp. 228-236, 2004
12. P. Cotter, B. Smyth, “Personalization techniques for the digital TV world,” Proc.
European Conference on Artificial Intelligence, pp. 701-705, 2000
13. W.P. Lee, T.H. Yang, “Personalizing information appliances: a multi-agent framework for
TV programme recommendations,” Expert Systems with Applications, vol. 25, no. 3, pp.
331-341, 2003
14. M. Ciaramita, M. Johnson, “Explaining away ambiguity: Learning verb selectional
preference with Bayesian networks,” Proc. Intl. Conference on Computational Linguistics,
pp. 187-193, 2000
15. F. V. Jensen, Bayesian Networks and Decision Graphs, Springer, 2001.
16. G. Miller, R. Beckwith, C. Fellbaum, D. Gross, K.J. Miller, “Wordnet: An on-line lexical
database,” International Journal of Lexicography, vol. 3, no. 4, pp. 235-312, 1990
17. J.J. Lee, “Case-based plan recognition in computing domains,” Proc. The Fifth
International Conference on User Modeling, pp. 234-236, 1996

