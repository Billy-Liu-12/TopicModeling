The Autonomous Concurrent Strategy for Large
Scale CAE Computation
P. Uhruski, W. Toporkiewicz, R. Schaefer, and M. Grochowski
Computer Science Department, AGH University of Science and Technology,
Krak´
ow, Poland
uhruski@ii.uj.edu.pl, Wojciech.Toporkiewicz@sheraton.com,
schaefer@agh.edu.pl, grochows@ii.uj.edu.pl

Abstract. The paper presents the Agent-Oriented technology for running the parallel CAE computation. Fast and eﬀective distributed diffusion scheduling is available that minimizes computation and communication time necessary for task governing and provides transparency in
resource availability. Detailed evaluation of the diﬀusion rule parameters
was obtained in the course of analysis of computational, memory and
communicational complexity of CAE tasks.

1

Introduction

Computer Aided Engineering (CAE) tasks belong to the most tiring and resource
consuming. The eﬃcient way to solve such problems is the parallel processing in a
distributed environment (see e.g. [14]). We suggest the Agent-Oriented approach
for implementing and governing the CAE computation in the computer network.
Such system delivers much more transparency and portability in comparison to
the one designed by using the traditional tools (e.g. PVM, MPI). High eﬃciency
of such a system is caused also by the special kind of diﬀusion scheduling [5] that
allows to adopt dynamically the computing architecture to the current resource
distribution and to minimize the communication overhead. Agents being parts
of such a system called Smart Solids Agents (SSA) are specially designed to
follow the Subdomain-By-Subdomain (SBS) method used as the parallelization
strategy (see e.g. [15]).

2

CAE Concurrent Strategy Based on Non-overlapping
Domain Decomposition

Let us consider a computational mechanics problem over a solid domain described by a diﬀerential equation (e.g. linear elasticity stationary problem).
Application of Finite Element Method (FEM) makes possible to ﬁnd its approximate solution by solving of a set of linear equations Bx = f . For FEM
problems there is a parallel-processing oriented approach called Subdomain by
Subdomain (SBS) [15] based on decomposition of Ω into a set of disjoined parts
{Ωj }. SBS is usually combined with an iterative algorithm used for solution of
resulting linear equation - Conjugate Gradient (CG) [16] in our case.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part III, LNCS 3993, pp. 783–790, 2006.
c Springer-Verlag Berlin Heidelberg 2006

784

P. Uhruski et al.

Domain decomposition (DD) on purpose of SBS is governed by two criteria: (i)
meeting memory allocation constrains for a resulting subtask; (ii) minimization
of interface between subdomains (see [12, 3]). Both of these criteria are evaluated in quantity of degrees of freedom (Dof) (see the next paragraph for Dof
explanation) since on their number depend operating memory requirements and
computation time of a resulting SBS task.
Generation of Computational Mesh (CM). CM in FEM consists of nodes grouped
in elements [2]. Elements provide local support for base functions used to approximate problem’s solution on the area of each of them. Dof are functionals
connected with mesh nodes that deﬁne the local approximation of a solution
over an element. Moreover each Dof corresponds with the single coordinate of
the approximate solution x. Dof that are connected with CM nodes belonging to
only one Ωj are called internal Dof, while common to more than one - boundary
Dof.
Generation of FEM matrices. As for matrix coeﬃcients we utilize Galerkin’s [15]
formulation of FEM. Matrix of j th subdomain is of the form:
(j)

(j)

(j)

Bii Bib
(j)
(j)
Bbi Bbb

xi
(j)
xb

(j)

=

fi
(j)
fb

(j)

(j)

Bii is a block of coeﬃcients coming exclusively from internal Dof and Bbb from
(j)
(j)
boundary ones while Bib , Bbi are ’mixed’ blocks.
Formulation of Schur Complement System (SCS). It is possible [15, 16] to transform a global problem to one comprising only boundary components of solution
(j)
(j)
(j)
(j)
(j)
(j)
s
xb : Cxb = fb where C = j=1 (Pb )T C (j) Pb , C (j) = Bbb − Bbi (Bii )−1 Bib ,
xb = j=1 (Pb )T xb , fb = j=1 (Pb )T (fbb −Bbi (Bii )−1 fi ) Pb are mappings between the global Dof numbering scheme used in Ω and local schemes
used in {Ωj }.
s

(j)

(j)

s

(j)

(j)

(j)

(j)

(j)

(j)

Solution of SCS. Provided that SCS is symmetric and positive deﬁned CG
method may be applied to obtain its solution. CG is based on minimization
of the quadratic form q(x) = 12 xT Cx − xT fb which has the unique minimizer x
being also the solution of SCS. CG is an iterative method where starting from
the initial point x0 at each step approximate solution is improved in the direction
dk : xk+1 = xk − αk dk , k = 0, 1, .... Value for αk can be determined by the explicit minimization of q along xk − αk dk so that q(xk − αk dk ) = minα (xk − αdk ).
Iteration is terminated when the distance between xk and xk+1 falls below required threshold (see e.g. [16]).
Finding ”internal” variables. Having computed boundary variables xb these re(j)
(j)
(j)
ferring to internal Dof can be evaluated using the formula xi = (Bij )−1 (fi −
(j) (j)

Bib xb ) .

The Autonomous Concurrent Strategy for Large Scale CAE Computation

785

Domain decomposition is implemented as a recursive bisection algorithm
which consists in dividing problem’s domain with planes into two parts in each
step and greedy optimization of interface (see [3] for details). Domain decomposition is performed sequentially on one machine. Partitioning respects both
criteria (i), (ii) and the density of Dof function ρDof that provides the rough
number of Dof falling into particular area Ωj . This part delivers minimum computational complexity O(log s) with respect to the number of subdomains s.
This task is performed sequentially and has negligible memory complexity.
We utilize tetrahedral Delaunay [2] CM generated in parallel over {Ωj }. Computational complexity of a task in this step is between O(N 2 ) and O(N 3 ) where
N is the number of Dof in particular Ωj . There is little communication between
tasks - it is only necessary to interchange information on interfacing CM in order
to assure its identity.
Computational complexity of FEM matrices generation may vary considerably depending on physical properties of a problem. There is no communication
between tasks.
The key advantage of SBS consist in retaining the matrix C in a distributed
form of its local components C (j) . Finding each of C (j) may be accomplished by
(j)
inverting local matrices Bii thus computational complexity of a task in this step
is not greater then O(Nij3 ) where Nij is the number of internal Dof in particular
Ωj . There is no communication between tasks.
The main activity of a task during CG iteration consist in multiplication of
a local component of SCS by subsequent approximation of the solution√vector.
2
)
Total computational complexity associated with the j th subdomain is O( nNbj
√
in this step where Nbj is the number of boundary Dof in Ωj . n represents a
rough evaluation of PCG iteration number while n stands
for the C dimension
√
2
). This part of SBS
(see [1]). Total communication complexity is also O( nNbj
process is strongly synchronized since after each multiplication step it is necessary to assembly entire vector xk on the master node in order to verify coherence
condition and compute direction vector dk .
Finding internal variables can be completed in the time O(Nij ) and commu(j)
nication is O(Nbj ) since only xb needs to be sent to the task associated with
2
Ωj . The maximum memory complexity of above steps is O(Nij2 + Nbj
).
Our implementation of SBS-CG process diﬀers from the most standard approach in decomposing model of Ω on the base of ρDof rather than partitioning
ready CM. This provides for straightforward parallelization of later CM generation and since computational and memory complexity of this process is square
with respect to the number of nodes this strategies provide considerable savings
in terms of operating memory and CPU time.

3

The Course of the Agent-Oriented Approach

The agent paradigm may be applied to the CAE computation to unleash any
possible relaxations in the course of computation. Each task associated with Ωj
part of a solid is being wrapped by an autonomous agent that tries to compute

786

P. Uhruski et al.

as much independently as possible synchronizing with other tasks only when
required. Agents are responsible for allocation of appropriate computational resources and running internal task work as long as no synchronization is required.
Let us outline possible relaxation of consecutive steps of CAE technology:
– Mesh computation may be done autonomously with respect to the neighboring agents that need to exchange the sibling interface. That means this
step requires only partial synchronization between neighboring solid parts
and no global synchronization is imposed.
– Interior meshes are generated asynchronously.
– Linear equation matrix creation may be done autonomously while its assembling requires communication.
The proposed Agent-Oriented solution is based on the Octopus platform [4],
which is composed of software servers statically allocated on computer nodes
(hence named Virtual Computation Node - VCN) that perform information,
migration and hibernation policies for mobile computing units - agents (see [7]).
Every VCN maintains a basic set of operations supporting agents communication
needs. It builds up the topology of neighboring VCNs that let agents examine
load of sibling nodes and migrate if required using the diﬀusion based scheduling
principle.
Such layered architecture makes the underlying network environment transparent to the agent based application. Octopus supports agent activities and
provides required, uniﬁed information while hiding possibly heterogeneous environment including amount of machines, their load and network segments bandwidth. That allows agents to be executed in a heterogeneous environment. On
the other hand, the computing application is composed of mobile agents that
wrap computational tasks.
Octopus platform was implemented in JAVA [9] and on purpose of inter-agent
communication utilizes CORBA [11] architecture.

4

Agent-Oriented CAE Computation in the Octopus
Environment

The Smart Solid Agent (SSA) architecture [4, 8] was chosen to perform CAE
type computational tasks. Its overall intention is to facilitate the design and implementation of computing application for heterogeneous and dynamic computer
network.
Computing application composed of mobile SSA agents is responsible for execution of carrying task and for ﬁnishing its computation in the shortest possible
time. Each Smart Solid Agent is represented by a pair A = (T, S) where T is
the carried task including all data required for computation and S is a shell
responsible for the agent speciﬁc logic. The shell S maintains the computational
task including communication capabilities and scheduling mechanism realized
by partitioning of the agent and by migration among available computers in the
network.

The Autonomous Concurrent Strategy for Large Scale CAE Computation

787

At the beginning the problems’ domain Ω is decomposed into subdomains
Ωj to achieve optimal grain respecting the current computational environment.
Then for every subdomain a computational task is created. In order to allow SSA
to carry more then one task a special task called ”task container” is utilized to
wrap execution of many tasks. The agent partitioning is implemented by division
of contained set of tasks and creation of two child agents with cloned shells and
with new ”task containers” including divided subsets of tasks.

5

Governing of the CAE Agents

The CAE multi-agent application starts from one agent containing all tasks
coming from decomposition of the whole domain Ω of a CAE problem. The
ﬁrst agent as well as all its child agents search for needed resources by using
the diﬀusion scheduling (see e.g. [5]). Roughly saying diﬀusion scheduling allows
SSA to migrate to the least loaded VCN in its neighborhood or to be partitioned
in case of insuﬃcient resources found on the current VCN.
If an agent contains only one task it executes the task in it’s own thread. For
a ”task container” with more then one task their execution can be performed in
parallel on UMA machines.
Diﬀusion rules implemented in agent logic S are based on the parameters
E, M, C collected for all tasks working in the neighborhood of each particular
VCN. Meaning of such parameters is as follows: E is the remaining computation time measured in units common for all computational tasks; M is required
RAM and C characterizes communication needed for a task. Communication
description C is a set of pairs (T, data) where T is an identiﬁer of a destination
task and data is amount of data exchanged betwen T and the task. The momentary values of E, M, C may be evaluated trough analysis of memory, time, and
communication complexity of utilized algorithms.
Each CAE task (see section 2) is responsible for generation of computational
mesh over associated subdomains Ωj , creation of FEM matrices and solving linear equations as a slave of a SBS-CG solver. Assuming featured complexities a
task provides the following values required for performing diﬀusion scheduling,
during each step of computation:
Mesh generation: M ∼ M1 = β(Nij + Nbj ) where β coeﬃcient is dependent on
the shape of a subdomain; E ∼ (Nij + Nbj − Ntj )3 where Ntj is the number
of vertices already included in the ﬁnal mesh. Mesh generator ﬁrst creates all
vertices and then takes one by one and generates ﬁnal mesh (when the mesh
is generated Ntj = Nij + Nbj ); C is insigniﬁcant and can be omitted. Communication is only required at the beginning of mesh generation to synchronize
two-dimensional meshes on interfaces. The exact number of Dof is available when
all mesh vertices have been generated. Before and during vertices generation step
ρ
.
the number of Dof is evaluated as (Nij + Nbj )
Ωj Dof

788

P. Uhruski et al.

2
2
Matrix generation: M ∼ M2 = M1 + (Njj
+ Nbj
); E ∼ α(Nij + Nbj )2 where α
may be very large and may vary considerably depending on physical properties
of a problem; There is no communication between tasks (C = φ).

SCS formulation: M ∼ M2 ; E ∼ (Nij )3 ; C = φ.
√
2
(1 − (1 − q)2 tq t−2 ), 0 < q < 1 where t is the
CG iterations: M ∼ M2 ; E ∼ nNbj
√
2
CG iteration number; C ∼ {(Tm , nNbj
)} and Tm stands for the master node
of a SBS-CG solver.
Finding internal variables: M ∼ M2 ; E ∼ Nij ; C ∼ {(Tm , Nbj )}, j = 1, . . . , s.

6

Numerical Test

Initially performed tests intend to show if the diﬀusion based strategy for the
ﬁrst two phases of CAE properly utilized available computational resources and
provided satisfactory speedup. Our computing environment was composed of
up to 10 PC machines with Intel Celeron processors and 512MB RAM. Every
machine hosted one VCN application (an Octopus computation node). As the
underlying operating system we selected the SLAX Linux operating system [10].
This Linux distribution was selected basing on the SLAX ability to boot up from
a bootable CD. That way we were able to link an available IBM PC compliant
machine into the computational platform without additional installation. Each
booted machine completed a star-like Octopus virtual topology by connecting
to one selected root machine. Hence we obtained a cluster-like environment of
10 machines all connected by a fast LAN network.
An example solid was selected (see ﬁgure 1) and pre-partitioned. That resulted
in 14 tasks (12 similar in size and 2 slightly larger ones), each related to a

Fig. 1. Decomposed domain of the problem with visible interface meshes

The Autonomous Concurrent Strategy for Large Scale CAE Computation

789

Table 1. Speed up of mesh generation for diﬀerent values of Dof function ρDof representing mesh density
Mesh

Number of Number of Execution time [sec]

Speed up

density

vertices

elements

Serial

Parallel

0,50

93420

535380

815

134

6,08

0,75

313523

1823385

5492

806

6,81

0,85

377562

2721561

10986

1595

6,89

1,10

975482

5823631

40613

5856

6,94

single piece of the solid. In the course of computations all machines were used
by the agents thus 100% resources were allocated. The table 1 presents the
speedup gained by the mesh generation agents versus serial computation time.
Explanation of the achieved speedup comes from the number of tasks and the
number of utilized machines. During the computation 6 machines were executing
one task each (the larger tasks were executed by these), while other 4 machines
were running two, similar in size, tasks each. We had 8, similar in size tasks
executed in pairs by four machines. That means the maximum achieved speedup
could be half of the tasks amount. Finally please note that the overall parallel
time results from the the slowest tasks and since all tasks were similar in size,
the overall speedup could be half of the tasks amount and that is 7.

7

Conclusions

The paper presents Agent-Oriented technology for running parallel CAE computations in a computer network. The approach provides fast and eﬀective distributed diﬀusion scheduling that minimizes computation and communication
time necessary for task governing. Moreover resources in a dynamic network
environment are transparently available. (see [8, 5, 7] for more test results). Detailed evaluation of the diﬀusion rule parameters were obtained on the basis
of computational, memory and communicational complexity analysis of CAE
tasks.The numerical test presented in the section 7 shows behavior of agents
performing two initial phases of CAE process - domain decomposition and mesh
generation.

References
1. Barragy E., Carey G.F., Van de Geijn R.: Performance and Scalability of Finite
Element Analysis for Distributed Parallel Computation. Journal of Parallel and
Distributed Computing 21, (1994) pp. 202-212.
2. Georg P.L.: Automatic Mesh Generation. John Wiley & Sons, 1991.

790

P. Uhruski et al.

3. Schaefer R., Toporkiewicz W., Grochowski M.: Rough partitioning of lumped structures, in Formal Methods and Intelligent Techniques in Control, Decision Making, Multimedia and Robotics. Polish-Japanese Institute of Information Technology
Press, Warsaw, October 2000, pp. 151-166.
4. Grochowski M., Schaefer R., Uhruski P.: An Agent-based Approach To a Hard
Computing System - Smart Solid. Proc. of the International Conference on Parallel
Computing in Electrical Engineering (PARELEC 2002), 22-25 September 2002,
Warsaw, Poland. IEEE Computer Society Press 2002, pp. 253-258.
5. Grochowski M., Schaefer R., Uhruski P.: Diﬀusion Based Scheduling in the AgentOriented Computing Systems. Lecture Notes in Computer Science, Vol. 3019,
Springer 2004, pp. 97-104.
6. Momot J., Kosacki K., Grochowski M., Uhruski P., Schaefer R.; Multi-Agent System for Irregular Parallel Genetic Computations. Lecture Notes in Computer Science, Vol. 3038, Springer 2004, pp. 623-630.
7. Smoka M., Uhruski P., Schaefer R., Grochowski M.; The Dynamics of Computing
Agent Systems. Lecture Notes in Computer Science Vol. 3516, Springer 2005, pp.
727-734.
8. Uhruski P., Grochowski M., Schaefer R.: Multi-agent Computing System in a Heterogeneous Network. Proc. of the International Conference on Parallel Computing in Electrical Engineering (PARELEC 2002), 22-25 September 2002, Warsaw,
Poland. IEEE Computer Society Press 2002, pp. 233-238.
9. Sun Microsystems, Java Technology, http://java.sun.com/
10. SLAX, SLAX Linux operating system, http://slax.linux-live.org/
11. CORBA, Object Management Group, http://www.omg.org/
12. Schaefer R., Flasi´
nski M., Toporkiewicz W.: Optimal Stochastic Scaling of CAE
Parallel Computations. Lecture Notes in Computer Intelligence, Vol. 1424, Springer
1998, pp.557-564.
13. Norton C. D., Cwik T. A.: Parallel Unstructured AMR and Gigabit Networking for
Beowulf-Class Clusters. Lecture Notes in Computer Science, Vol. 2328, SpringerVerlag Heidelberg 2002, pp. 552-563.
14. Mann V., Parashar M.: Engineering an interoperable computational collaboratory
on the Grid. Concurrency and Computation. Practice and Experience., 14, pp.
1569-1593, 2002.
15. Papadrakakis M.: Domain decomposition techniques in Computational Structural
Mechanics in M. Papadrakakis (Ed.), Parallel Solution Methods in Computational
Mechanics, John Wiley and Sons (1996), pp. 87-140.
16. Golub G., Ortega J.M.: Scientiﬁc Computing. An Introduction with Parallel Computing, Academic Press Ltd., 1993.

