Computational Models of Natural Language
Argument
Chris Reed1 and Floriana Grasso2
1
2

Department of Applied Computing, University of Dundee, Scotland
chris@computing.dundee.ac.uk
Department of Computer Science, University of Liverpool, England
floriana@csc.liv.ac.uk

Abstract. This paper oﬀers an introduction to the 2001 Workshop on
Computational Models of Natural Language Argument (CMNLA 2001),
a special event of the International Conference on Computational Science. The contributors to the workshop represent, in their backgrounds,
the diversity of ﬁelds upon which the focus of the event draws. As a
result, this paper aims not only to introduce the accepted papers, but
also to provide a background that will be accessible to researchers in the
various ﬁelds, and to sit each work into a coherent context.

1

Introduction

There is rapidly growing interest in the applications of argumentation for computer reasoning. One of the most mature and substantial research projects in
the area is Pollock’s OSCAR system [36], but the use of argumentation and dialectics in computational contexts has become increasingly popular, and with a
variety of aims. Emphasis has been put on many aspects of the argumentation
process: from the study on the structure of “valid” arguments [13,26], to the
way complex arguments can be unreeled [9,48]. Argumentation is starting to
play a key role in communication in multi-agent systems with signiﬁcant results
reported, inter alia, in [32]. Perhaps not by coincidence, argumentation theory
itself has been enjoying a renaissance in recent years, demonstrated by the wide
and extensive bibliography oﬀered by [43].
Surprisingly, the ways in which arguments are rendered in natural language,
the most obvious vehicle for the purpose, have not been investigated at depth,
apart from few exceptions [10,28,31,37]. The endeavour is particularly challenging, both for computational linguists and for computer scientists, as argumentation is typically rich with rhetorical devices interacting at many diﬀerent layers
of abstraction, and is heavily dependent upon extra-linguistic context if it is
to be successful. Moreover, a vast literature on both argumentation theory and
rhetoric can oﬀer great potential for exploitation, and, as in many other computational modelling problems, cross-disciplinary fertilisation is crucial for achieving
signiﬁcant results.
The 2001 Workshop on Computational Models of Natural Language Argument (CMNLA 2001) aims exactly at bringing this issue into the limelight.
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2073, pp. 999–1008, 2001.
c Springer-Verlag Berlin Heidelberg 2001
�

1000

C. Reed and F. Grasso

The emphasis of the workshop is therefore squarely on computational models of natural language argumentation. As a result, the introduction and discussion presented here avoids the rich literature and fertile areas of research in
which formal models of argumentation are employed for artiﬁcial reasoning, and
computer-computer communication. Similarly, topics within the venerable ﬁeld
of argumentation theory in its own right do not here form a key focus of study,
although it is inevitable that discussion at the workshop itself should draw on
these ﬁelds. The discussion will instead focus on framing the problem, by providing a background that will be accessible to researchers in the various ﬁelds.
The paper also aims to introduce the accepted papers, and, by emphasising the
diversity of ﬁelds upon which the focus of the event draws, to sit each work into
a coherent context.
1.1

Computational Models of Discourse

Computational Linguistics scientists concentrate on the “study of computer systems for understanding and generating natural language” [20], in order to develop “a computational theory of language, using the notions of algorithms and
data structures from Computer Science” [1]. Typical problems for these research
ﬁelds are [1]: How is the structure of sentences identiﬁed? How can knowledge
and reasoning be modelled? How can language be used to accomplish speciﬁc
tasks? Research spans, naturally enough, across the two ends of the human communication problem: understanding natural language, and producing it.
Understanding a piece of text is not merely a problem of “parsing” the sentences it comprises to identify the grammatical structure that can describe it.
It is not even, or not only, to extract the “meaning” of such sentences, taking
care of inherent natural language ambiguities. It is recognised that discourse has
a much more complex structure than the simple collection of its sentences, and
higher level factors must come into play in deciding whether a text is coherent.
In other words, understanding text means primarily establishing whether such
text had a purpose, in the mind of the writer, and how the purpose has been
achieved by the writer, with the choice of one particular articulation of the sentences. Enlightening examples of such “rhetorical” parsing are in [29]. To achieve
this level of comprehension, works on discourse annotation become of paramount
importance, as they allow to gain a deeper understanding of how this presumed
“structure” of a text is build up by human writers (a remarkable example for
argumentative texts is [41]).
The same assumption that text has a structure, that can be determined, at
least partially, by the writer’s goal, has driven research in automatic natural
language generation, for the complementary task of producing a piece of text
in a human language from computer accessible, or, in general, non-linguistic
representation of information [40]. If the text has to be produced for a purpose,
and not by just gluing together sentences, knowledge is required of, at least, the
domain of discourse, the purpose of the piece of text, the strategy to achieve
such purpose, the rules for discourse organization, and, in order for the text to
be tailored to a particular audience, the characteristics of the addressee.

Computational Models of Natural Language Argument

1001

Models of the structure of discourse are based on diverse hypotheses. For
example, many of the early natural language processing systems have associated
discourse with the concept of “recipe”, or schema: if most of the texts containing
an explanation (e.g. in an encyclopedia) have the same structure (start with the
identiﬁcation, “X is a Y”, then pass to listing peculiar attributes of X etc.) then
we can ascribe the same structure to all texts having the same purpose (to explain) [33]. Other systems are based on a diﬀerent, less rigid approach: following
Austin’s intuition that utterances are performatives just as physical actions are
[3], the metaphor of a “plan” has been used to describe discourse [2,22]. Just as
a robot may have the goal of building a brick tower, and can decompose this
problem into smaller and smaller tasks, until easily executable basic actions can
be performed (lift arm, pick up block etc.), similarly a natural language tool may
decompose a communicative goal into its steps, and use a plan based mechanism
to achieve them. The original problem is then transformed into the problem of
deciding how such communicative goals can be deﬁned in the ﬁrst place, and
how they can be achieved, that is decomposed into smaller, more manageable
problems. Guidance on these issues comes typically from discourse organisation
theories, the most popular of which is perhaps the Rhetorical Structure Theory
(RST) [27], a theory which, despite some criticisms [34], has been very widely
used (see for example [24]).
1.2

Computational Models of Argumentative Discourse

The emerging area across computational linguistic and argumentation theory
sets itself the task of investigating the forms and varieties in which arguments
are put forward in natural language. Important issues are, therefore, those concerning the linguistic characteristics of argumentative texts: discourse markers,
sentence format, referring expressions, style, and in general how natural language arguments can be produced on one hand, and recognised on the other.
But equally fundamental are considerations on models of the argumentative process itself, in terms of characteristics of the audience [35], ultimate judge of the
quality of an argument: their beliefs and propensities, but also emotions, personalities, values, norms. Preliminary reﬂections on this subject are included in
[17]. The CMNLA 2001 workshop aimed at establishing common grounds for research, by gathering together researchers from very diverse and complementary
ﬁelds, from computer science, to linguistic, to philosophy. Together, the contributors worked at deﬁning the gaps that need to be bridged, while at the same
time proposing avenues to bridge them.

2

The Gap at the Human Computer Interface

Work at the human-computer interface is confounded by two related challenges.
The ﬁrst arises as a result of human limitations, and the need to restrict, abridge,
and limit, whilst at once explaining, repeating, and emphasising information in
such a way that it can be successfully assimilated by the human. Computational

1002

C. Reed and F. Grasso

models of interaction, and particularly linguistic models of interaction, must necessarily take account of the limitations of the human interlocutor if they are to
succeed. This consideration becomes all the more important in more demanding communicative situations, where, for example, the aim is to eﬀect attitude
change through persuasion, or to oﬀer explanation through the expression of
complex reasoning.
The second challenge is posed by the limitations of the communicating computer system, or, more accurately perhaps, by the traditional design of such
systems. A sound and productive engineering approach has led to the development of natural language processing systems which build incrementally, one on
the next. This much is to be valued most highly, and is taken as an indicator of a
growing maturity in the ﬁeld. It has also inevitably led to the widespread adoption of simplifying assumptions and a speciﬁc circumscription of the problem
which are only now starting to be questioned. The underlying representation of
linguistic and extra-linguistic knowledge, and the tasks which should properly
be considered as part of the domain of Natural Language Processing are thus
becoming important items on the research agenda in their own right.
Together, these two challenges represent a gap at the human-computer interface, comprising both the oversight of human limitations, and the underestimation of factors that need to be accounted for. Computational implementations
of argumentation are one means of closing this gap. Theories of argument have
squarely addressed complex communicative encounters involving persuasion and
explanation, and oﬀer insight into ways of circumventing, handling, and even
exploiting, human limitations apposite in such situations. Furthermore, argumentation theory has, necessarily, embraced a much wider range of issues that
impinge on communication. Similarly, computational systems focused speciﬁcally upon argumentation are necessitating a broader view of what constitutes
Natural Language Processing, and are demanding reconsideration of some of the
basic assumptions of the ﬁeld.
2.1

Human Limitations

Following complex argumentation is an extremely demanding task for most people. If the single, simple deductive step embodied in the Wason selection task
[45] can unerringly produce such dismal performance - and its manifold variations produce such wide discrepancies - then it should come as no surprise that
comprehending substantial chains of argumentative steps represents a superbly
intensive cognitive task. Even in cases in which the structure of argumentation is
quite straightforward, the job of assimilating the data presented is not a simple
one. Fox et al.’s [12] work on computer systems which reason and then present
explanations in the oncology domain has clearly demonstrated that whilst formal models of argumentation provide a powerful mechanism for reasoning under
conditions of uncertainty, the subsequent presentation of that reasoning to a
human is highly troublesome.
In the ﬁrst place, there are two conﬂicting forces which introduce a tension into the process of generating text involving arguments. On the one hand,

Computational Models of Natural Language Argument

1003

humans tire easily, becoming bored if information is repeated, or even if inferences are laboriously drawn out explicitly. This is reason for the ubiquity of
enthymemes, in which components of an argument step are left implicit. Instead
of carefully enumerating conclusion and minor and major premises of a Modus
Ponens (as in The litmus paper turned red, and if litmus paper turns red then
the solution is acid, so the solution is acid), one might more naturally oﬀer an
enthymematic version (The litmus paper turned red, so the solution is acid).
On the other hand, humans also have a tendency to get lost in an argument,
and typically require a battery of linguistic devices to mark the way. A prime
example is oﬀered in the use of repetition and conﬁrmation in informationally
redundant utterances or IRUs, described by Walker [44]. IRUs have a range of
functions including aid memory, support saliency, etc. but what concerns us here
is the very idea that it is necessary at all to introduce components which convey
no new information. Reed’s [37] analysis of similar phenomena takes a related,
if symmetrically opposite, approach whereby such utterances are not added to a
text, but are instead always present at a deep level, and pruned as appropriate
at the surface level - this analysis then supports explanation of diﬀerences in
occurrences of enthymemes. For although enthymematic contraction is almost
canonical in arguments structured around Modus Ponens, it is extremely rare in
Modus Tollens constructions.
This tension between the need for brevity on the one hand and the requirements of waymarking on the other is one of the key issues addressed in Fiedler
and Horacek [11]. The domain for their P. Rex system is the presentation of
logical proofs. It is quite clear from their analysis that even in the relatively
stylised linguistic usage of mathematical proof, it is crucial to be able to determine when an enthymeme (or other generic form of argument contraction) is
appropriate, and when it is not. To render a proof comprehensible, information
must be omitted where obvious or easily inferred (or where it occurs in particular
conﬁgurations of particular syllogisms), but explained in detail where necessary.
The waymarking which is so vital to argument comprehension is perhaps
best exempliﬁed in the use of discourse markers (also, cues or clues). The use of
speciﬁc lexical items marking argument structure was ﬁrst discussed in the computational linguistics literature by Cohen [7], and has since played an important
role in several models of natural language argument generation including [10,18,
38]. Carenini’s GEA system [5], however, is one of very few which follows the task
of generating the text of an argument from high level intentional goal through
to textual output. Here, after selecting argument content, various components
contribute to the ultimate lexical realisation, including processing to introduce
appropriate discourse markers, aimed at making the reader’s task that much
easier - and the aims of the argument consequently that much more likely to be
fulﬁlled.
In addition to these opposing forces working on the level of detail in an argument, and the introduction of discourse markers, there are also further considerations of human limitations and susceptibilities available to computer systems
engaging argument. One is the technique of ’loading’ or ’aﬀect’ - using biased or

1004

C. Reed and F. Grasso

evaluative terms to more or less subtly inﬂuence the reception of the argument.
Hovy [23] included a study of aﬀect in his PAULINE system; by altering values
for a small range of stylistic variables (formality, force, etc.) the structure and
lexical choice eﬀected by the system could be radically altered. Gavenko’s discussion [15] oﬀers a broad analysis of particular forms of such aﬀect including
the use of visual and haptic metaphor. A computational model armed with the
ability to ﬂexibly employ such metaphors would signiﬁcantly enhance the argumentation that could be generated by aiding the interlocutor in their task of
comprehension.
2.2

Computer Limitations

To many in computational linguistics, and particularly in projects concentrating on argumentation, sentences like “The CN Tower is the world’s tallest free
standing structure”, or, “The CN Tower is an engineering marvel”, are typically
represented in some knowledge base as p, or, q. Both are simply examples of
’propositions’. Gilbert [16] performs two tasks. The ﬁrst is to remind us of the
fact that such an abstraction is woefully inappropriate. Where the ﬁrst sentence
is (in the right context) a fact, the other (in the right context) is a value; the
former does not admit of argumentation, whilst the latter does. Gilbert then discusses how the distinction between, and arrangement of, such facts and values
is dependent upon the ’ﬁeld’ of context. Each user then represents not just one
ﬁeld, but a prioritized hierarchical arrangement of many diﬀerent ﬁelds. This
characterisation is similar to the trees of preferences used in systems such as [18]
and [5], but Gilbert’s suggestion goes further by associating with a given user
not just a network of preferences (and values, and beliefs), but rather, a whole
host of such networks, one for each role that the user might adopt. These networks are then themselves arranged in a hierarchy depending upon the context.
Issues of inheritance and conﬂict between ﬁelds are going to play an important
role in any system adopting this view of users, and these interactions are as yet
ill-understood. There are, however, promising directions such as the application
of context logic for capturing the closely related notion, due to Perelman and
Ohlbrechts-Tyteca [35], of ’audience’. Preliminary work on this idea is to be
reported in [8].
Perhaps the strongest tradition in widening the remit of natural language
processing systems is in the incorporation of various non-textual information.
One of the key pieces of work in the area is Maybury’s system of ’communicative acts’ which he applied both to the generation of argument [31] and to the
inclusion of multimedia sources [30]. Green’s analysis [19], examines how multimedia resources are employed in real argumentation, in an attempt to enrich
automated generation of multimedia-rich argument. The structure of argumentation in non-textual source is notoriously diﬃcult to identify in anything but
the most trivial of examples, but recent work has made advances in this direction. Groarke’s study [21], in particular, shows how art and editorial cartooning
can be analysed to reveal deductive structure, and how that structure can then
be assessed.

Computational Models of Natural Language Argument

1005

A third traditional restriction in the design of natural language processing
systems is founded on intuitions about ethics and the role of the computer. Machines have not traditionally been equipped with the ability to deceive. And yet,
it is becoming clear that in particular scenarios, such a capability is crucial. In
negotiating (with one user, on behalf of another), or dealing with emotive issues
(the oncological domain of Fox et al. [12] mentioned above is a rich source) there
is a demand in the former case, for deception, and in the latter, for at least
some equivocation. Recognition of the importance of the role of insincerity is
what has motivated the work of Caroﬁglio and de Rosis [6], who build a probabilistic account based on Toulmin [42] structures of argument. Of course, as
Caroﬁglio and de Rosis point out, deception carries with it a risk of discovery,
which could be damaging in any communicative encounter. An analysis of cases
of human deception in [4] demonstrates that equivocation plays a key role in
salving the conscience and oﬀering means of recovery in the event of discovery.
The subtleties of linguistic prevarication employed in deception are beyond most
current computational systems which typically exploit knowledge of a user’s misconceptions (such as the ’licentious’ ﬂag in Zukerman et al.’s [47] NAG system).
The analysis oﬀered by Caroﬁglio and de Rosis provides a means to start reﬁning the mechanisms which can be employed in the various forms of insincere
communication.
Finally, a crucial challenge to be overcome if computers are to engage in
dialogic argument is the problem of comprehension. Natural language understanding itself is an immense challenge of course, but understanding argument
poses further problems above and beyond understanding the individual discourse
elements. In order to understand and, ultimately, be in a position to be able to
respond to human argument, it is essential that the large scale structure which
provides the scaﬀolding is recognised accurately. This, after all, is one of the
primary aims of the (primarily North American) undergraduate courses on argument analysis supported by texts such as [46]. The prospect of being able to
automatically produce the sorts of diagrams available in, for example, Freeman’s
[14] analyses is extremely attractive. But to achieve that sort of competence,
there are substantial problems upon which work has barely begun: automatic
argument reconstruction, fallacy detection, the recognition of argument forms,
and so on.

3

Prospects

The overlap between argumentation theory and Artiﬁcial Intelligence (AI) is particularly lucky as it can draw upon talented researchers in an extremely wide array of ﬁelds: linguistics, psychology, mathematics, cognitive science, philosophy,
rhetoric, speech communication, politics, computer science, law, social science,
economics, and more. The substantial work that can be achieved when members of these ﬁelds converge on argumentation was demonstrated dramatically
at the Symposium on Argument and Computation, held in Scottish Highlands
in June 2000. During the course of a week, two dozen scholars, most of whom

1006

C. Reed and F. Grasso

had not met previously, worked together to write a book examining the areas of
interdisciplinary overlap. The remarkable results, which are to be published as
[39], testify not only to the dedication of the contributors, but also to the level
of interest that is being sustained in the area.
With a foundation like this, the prospects for argumentation and AI are
extremely good - but there is a great deal of work to be done. Events like the
Symposium on Argument and Computation and CMNLA are not only indicators
of the interest within both ﬁelds in the crossdisciplinary overlap, but are also
catalysts in stimulating new collaborations. The fruits of these collaborations
hold very great promise.

Acknowledgements
We are most grateful to our colleagues who acted as reviewing committee, thus
providing immense help in achieving a stimulating ﬁnal programme:
– Cristiano Castelfranchi, Department of Communication Science, University
of Siena, Italy.
– Fiorella de Rosis, Department of Informatics, University of Bari, Italy.
– Leo Groarke, Department of Philosophy, Wilfrid Laurier University, Waterloo, Ontario, Canada.
– Ehud Reiter, Department of Computer Science, University of Aberdeen,
Scotland.
– Antoinette Renouf, Department of English Language and Literature, University of Liverpool, England.
We are also grateful to SIGGEN, the Association for Computational Linguistics Special Interest Group in Natural Language Generation, for kindly oﬀering
support-in-name to the workshop.

References
[1] J.F. Allen. Natural Language Understanding. The Benjamin/Cummings Publishing Company, Inc., 2nd edition, 1995.
[2] D.E. Appelt. Planning English Sentences. Studies in Natural Language Processing. Cambridge University Press, 1985.
[3] J. Austin. How To Do Things With Words. Oxford University Press, 1975.
[4] J.B. Bavelas, A. Black, N. Chovil, and J. Mullet. Truth, lies and equivocation.
Journal of Language and Social Psychology, 9(1-2):135–161, 1990.
[5] G. Carenini. GEA: a Complete, Modular System for Generating Evaluative Arguments. In (current volume).
[6] V. Caroﬁglio and F. de Rosis. Exploiting Uncertainty and Incomplete Knowledge
in Deceptive Argumentation. In (current volume).
[7] R. Cohen. Analyzing the Structure of Argumentative Discourse. Computational
Linguistics, 13(1-2):11–24, 1987.
[8] J. Crosswhite, J. Fox, C.A. Reed, T. Scaltsas, and S. Stumpf. Computational
Models of Rhetoric. In Reed et al. [39], (to appear).

Computational Models of Natural Language Argument

1007

[9] H. Dalianis and P. Johannesson. Explaining Conceptual Models - Using Toulmin’s
argumentation model and RST. In Proceedings of The Third International workshop on the Language Action Perspective on Communication Modelling (LAP98),
pages 131–140, 1998.
[10] M. Elhadad. Using Argumentation in Text Generation. Journal of Pragmatics,
24:189–220, 1995.
[11] A. Fiedler and H. Horacek. Argumentation in Explanations to Logical Problems.
In (current volume).
[12] J. Fox and S. Das. A uniﬁed framework for hypothetical and practical reasoning
(2): lessons from medical applications. In D. Gabbay and H.J. Olbach, editors,
Practical Reasoning: Proceedings of FAPR’96. Springer-Verlag, 1996.
[13] J. Fox, P. Krause, and M. Elvang-Goransson. Argumentation as a General Framework for Uncertain Reasoning. In D. Heckerman and A. Mamdani, editors, Proceedings of the 9th Conference on Uncertainty in Artiﬁcial Intelligence, pages
428–434. Morgan Kaufmann Publishers, 1993.
[14] J.B. Freeman, editor. Dialectics and the MacroStructure of Argument. Foris, 1991.
[15] S. Gavenko. Analysis of the Argumentative Eﬀect of Evaluative Semantics in
Natural Language. In (current volume).
[16] M.A. Gilbert. Getting Good Value: Facts, Values and Goals in Computational
Linguistics. In (current volume).
[17] M.A. Gilbert, F. Grasso, L. Groarke, C. Gurr, and J.M. Gerlofs. The Persuasion
Machine: An Exercise in Argumentation and Computational Linguistics. In Reed
et al. [39], (to appear).
[18] F. Grasso, A. Cawsey, and R. Jones. Dialectical Argumentation to Solve Conﬂicts
in Advice Giving: a case study in the promotion of healthy nutrition. International
Journal of Human-Computer Studies, 53(6):1077–1115, 2000.
[19] N. Green. An Empirical Study of Multimedia Argumentation. In (current volume).
[20] R. Grishman. Computational Linguistics : an Introduction. Studies in Natural
Language Processing. Cambridge University Press, 1986.
[21] L. Groarke. Logic, art and argument. Informal Logic, 18(2-3):105–129, 1996.
[22] B.J. Grosz and C.L Sidner. Plans for Discourse. In P. Cohen, J. Morgan, and
M. Pollack, editors, Intentions in Communication, chapter 20, pages 417–444.
MIT Press, Cambridge (Mass.), 1990.
[23] E. Hovy. Pragmatics and Natural Language Generation. Artiﬁcial Intelligence,
43:153–197, 1990.
[24] E. Hovy. Automated Discourse Generation using Discourse Structure Relations.
Artiﬁcial Intelligence, 63(1-2):341–385, 1993.
[25] K. Jokinen, M. Maybury, M. Zock, and I. Zukerman, editors. Proceedings of the
ECAI-96 Workshop on: Gaps and Bridges: New directions in Planning and NLG,
1996.
[26] N. Karacapilidis. An Argumentation Based Framework for Defeasible and Qualitative Reasoning. In Jokinen et al. [25], pages 37–42.
[27] W. Mann and S. Thompson. Rhetorical Structure Theory: Toward a Functional
Theory of Text Organization. Text, 8(3):243–281, 1988.
[28] D. Marcu. The Conceptual and Linguistic Facets of Persuasive Arguments. In
Jokinen et al. [25], pages 43–46.
[29] D. Marcu. The Theory and Practice of Discourse Parsing and Summarization.
MIT Press, 2000.
[30] M. Maybury. Planning multimedia explanations using communicative acts. In
Proceedings of the 9th National Conference on Artiﬁcial Intelligence (AAAI91),
pages 61–66. AAAI, MIT press, July 1991.

1008

C. Reed and F. Grasso

[31] M. Maybury. Communicative Acts for Generating Natural Language Arguments. In Proceedings of the 11th National Conference on Artiﬁcial Intelligence
(AAAI93), pages 357–364. AAAI, AAAI Press / The MIT Press, 1993.
[32] P. McBurney and S. Parsons. Agent ludens: Games for agent dialogues. In
P. Gmytrasiewicz and S. Parsons, editors, Proceedings of the Third Workshop
on Game-Theoretic and Decision-Theoretic Agents (GTDT2001), AAAI Spring
Symposium. AAAI Press, Menlo Park, CA, 2001.
[33] K. McKeown. Text Generation: Using Discourse Strategy and Focus Constraints
to Generate Natural Language Texts. Studies in Natural Language Processing.
Cambridge University Press, 1985.
[34] J. Moore and C. Paris. Planning Text for Advisory Dialogues: Capturing Intentional and Rhetorical Information. Computational Linguistics, 19(4):651–695,
1993.
[35] C. Perelman and L. Olbrechts-Tyteca. The New Rhetoric: a treatise on argumentation. University of Notre Dame Press, Notre Dame, Indiana, 1969.
[36] J. Pollock. OSCAR: a General Theory of Rationality. In R. Cummins and J. Pollock, editors, Philosophy and AI: Essays at the Interface, chapter 9, pages 189–213.
MIT Press, Cambridge (Mass.), 1991.
[37] C.A. Reed. The Role of Saliency in Generating Natural Language Arguments. In
T. Dean, editor, Proceedings of the Sixteenth International Joint Conference on
Artiﬁcial Intelligence (IJCAI’99), pages 876–881. Morgan Kaufmann Publishers,
1999.
[38] C.A. Reed and D.P. Long. Generating the structure of argument. In Proceedings of
the 17th International Conference on Computational Linguistics and 36th Annual
Meeting of the Association for Computational Linguistics (COLING-ACL’98),
pages 1091–1097, 1998.
[39] C.A. Reed, T.J. Norman, and D. Gabbay, editors. Argument and Computation.
(to appear).
[40] E. Reiter and R. Dale. Building Applied Natural Language Generation Systems.
Natural Language Engineering, 3(1):57–87, 1997.
[41] S. Teufel, J. Carletta, and M. Moens. An Annotation Scheme for Discourse-Level
Argumentation in Research Articles. In Proceedings of EACL, 1999.
[42] S. Toulmin. The Uses of Argument. Cambridge University Press, 1958.
[43] F. van Eemeren, R. Grootensdorst, F. Henkemans, J.A. Blair, R. Johnson,
E. Krabbe, C. Plantin, D. Walton, C. Willard, J. Woods, and D. Zarefsky. Fundamentals of Argumentation Theory: A Handbook of Historical Backgrounds and
Contemporary Developments. Lawrence Erlbaum Associates, Hillsdale, NJ, 1996.
[44] M.A. Walker. The Eﬀect of Resource Limits and Task Complexity on Collaborative Planning in Dialogue. Artiﬁcial Intelligence, 85(1-2):181–243, 1996.
[45] P. Wason. Reasoning. In B.M. Foss, editor, New Horizons in Psychology. Harmondsworth: Penguin., 1966.
[46] B.A. Wilson. The Anatomy of Argument. University Press of America, 1980.
[47] I. Zukerman, K. Korb, and R. McConachy. Perambulations on the Way to an
Architecture for a Nice Argument Generator. In Jokinen et al. [25], pages 32–36.
[48] I. Zukerman, R. McConachy, and K. Korb. Using Argumentation Strategies in
Automated Argument Generation. In M. Elhadad, editor, Proceedings of the 1st
International Conference on Natural Language Generation (INLG-2000), pages
55–62, 2000.

