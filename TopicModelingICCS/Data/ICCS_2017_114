Available online at www.sciencedirect.com

ScienceDirect
This space
isComputer
reservedScience
for the
header, do not use it
Procedia
108CProcedia
(2017) 435–444
This space is reserved for the Procedia header, do not use it
This space is reserved for the Procedia header, do not use it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Extending Perfect Spatial Hashing to Index Tuple-based
Extending
Perfect
Spatial Super
Hashing
to Index
Tuple-based
Graphs
Representing
Carbon
Nanotubes
Extending Perfect Spatial Hashing to Index Tuple-based
Graphs Representing
Super Carbon
Nanotubes2
1,2
2
Michael
, Giang NamSuper
NguyenCarbon
, and Christian
Bischof
GraphsBurger
Representing
Nanotubes
1
1
1

Michael Burger1,2 , Giang Nam Nguyen2 , and Christian Bischof2

Graduate School of Computational
Engineering, Dolivostr. 15, Darmstadt, Germany
Michael Burger1,2 , Giang
Nam Nguyen2 , and Christian Bischof2
burger@gsc.tu-darmstadt.de
Graduate
School of Computational Engineering, Dolivostr. 15, Darmstadt, Germany
2
Institute for Scientificburger@gsc.tu-darmstadt.de
Computing, Mornewegstr. 30, Darmstadt, Germany
Graduate School of Computational
Engineering, Dolivostr. 15, Darmstadt, Germany
2 {giang nam.nguyen@stud., christian.bischof@sc.}tu-darmstadt.de
Institute for Scientificburger@gsc.tu-darmstadt.de
Computing, Mornewegstr. 30, Darmstadt, Germany
2 {giang nam.nguyen@stud., christian.bischof@sc.}tu-darmstadt.de
Institute for Scientific Computing, Mornewegstr. 30, Darmstadt, Germany
{giang nam.nguyen@stud., christian.bischof@sc.}tu-darmstadt.de

Abstract
In
this paper, we demonstrate how to extend perfect spatial hashing (PSH) in order to hash
Abstract
multidimensional
data.
use case
we employ
problem
domain
of indexing
In this paper, we scientific
demonstrate
howAstoaextend
perfect
spatialthe
hashing
(PSH)
in order
to hash
Abstract
nodes
in
a
graph
that
represents
Super
Carbon
Nanotubes
(SCNTs).
The
goal
of
is to
multidimensional
data.
use case
we employ
problem
domain
ofPSH
indexing
In
this paper, we scientific
demonstrate
howAstoaextend
perfect
spatialthe
hashing
(PSH)
in order
to hash
hash
multidimensional
data
without
collisions.
Since
PSH
results
from
the
research
on
computer
nodes in a graph that
represents
Carbon
Thedomain
goal ofofPSH
is to
multidimensional
scientific
data. Super
As a use
case Nanotubes
we employ (SCNTs).
the problem
indexing
graphics,
principles
and without
methods
haveCarbon
onlySince
been
tested
on
2-from
and the
3-dimensional
problems.
hash multidimensional
collisions.
PSH
results
research
onPSH
computer
nodes
in aitsgraph
that data
represents
Super
Nanotubes
(SCNTs).
The
goal of
is to
In
our
case,
need todata
hash
up to collisions.
28
dimensions.
In
contrast
thethe
original
applications
of
graphics,
its we
principles
and
methods
have
onlySince
been PSH
tested
on 2-to
and
3-dimensional
hash
multidimensional
without
results
from
research
on problems.
computer
PSH,
we
do
not
focus
on
GPUs
as
target
hardware
but
on
an
efficient
CPU
implementation.
In our case,
need toand
hash
up to 28
dimensions.
contrast
the3-dimensional
original applications
of
graphics,
its we
principles
methods
have
only been In
tested
on 2-toand
problems.
Thus,
this
highlights
the
extensions
to the original
makeimplementation.
it suitable for
PSH,
dopaper
not need
focus
GPUs
hardware
butcontrast
on algorithm
an efficient
CPU
In
ourwe
case,
we
toonhash
up as
to target
28 dimensions.
In
to the to
original
applications
of
higher
dimensions.
Comparing
compression
and original
performance
resultstoCPU
ofmake
theimplementation.
new
PSH based
Thus, we
this
highlights
thethe
extensions
to the
it suitable
for
PSH,
dopaper
not focus
on GPUs
as
target hardware
but on algorithm
an efficient
graphs
and paper
a structure-tailored
custom
data
in our
parallelized
SCNT
simulation
higher this
dimensions.
Comparing
compression
and original
performance
resultstoofmake
the
new
PSH
based
Thus,
highlights
thethe
extensions
to structure
the
algorithm
it suitable
for
software,
we
find
that
PSH
in
some
cases
achieves
better
compression
by
a
factor
of
1.7 based
while
graphs dimensions.
and a structure-tailored
custom
data structure
in our parallelized
SCNT
simulation
higher
Comparing the
compression
and performance
results of the
new PSH
only
increasing
thethat
total
runtime
by
several
percent.
In particular,
after by
ouraextension,
PSH
can
software,
we afind
PSH
in some
casesdata
achieves
better
factor
1.7
while
graphs
and
structure-tailored
custom
structure
incompression
our parallelized
SCNTofsimulation
also
be
employed
to
index
sparse
multidimensional
scientific
data
from
other
domains
where
only increasing
thethat
total
runtime
by several
percent.better
In particular,
after by
ouraextension,
PSH
can
software,
we find
PSH
in some
cases achieves
compression
factor of 1.7
while
PSH
canemployed
avoid the
additional
index-structures
KD- In
or
R-trees.dataafter
also be
to
index
sparsebymultidimensional
scientific
fromour
other
domains
where
only
increasing
total
runtime
several like
percent.
particular,
extension,
PSH
can
PSH
can
avoid
additional
index-structures
likesuper
KD- carbon
or
R-trees.
also
be
employed
to index
multidimensional
scientific
data from
other domains where
Keywords:
perfect
spatial
hashing,
data
indexing,
nanotubes,
simulation
©
2017
The
Authors.
Published
bysparse
Elsevier
B.V.
Peer-review
under responsibility
of
the scientific committee
of theor
International
Conference on Computational Science
PSH
can
avoid
additional
index-structures
like
KDR-trees.
Keywords: perfect spatial hashing, data indexing, super carbon nanotubes, simulation
Keywords: perfect spatial hashing, data indexing, super carbon nanotubes, simulation

1 Introduction
1
Introduction
Carbon nanotubes (CNTs) and super carbon nanotubes (SCNT) have drawn much attention
1
Introduction
because of their outstanding mechanical and electrical properties ([10], [4]). A CNT, which

Carbon nanotubes (CNTs) and super carbon nanotubes (SCNT) have drawn much attention
corresponds
to anoutstanding
SCNT
order
0, can
be imagined
a rolledhave
up sheet
atoms,
because nanotubes
of their
mechanical
and
electrical as
properties
([10],
[4]).ofmuch
Acarbon
CNT,
which
Carbon
(CNTs)ofand
super
carbon
nanotubes
(SCNT)
drawn
attention
arranged
in
a
honeycomb
grid.
Following
[4],
to
construct
a
super
carbon
nanotube
of
order
corresponds
to anoutstanding
SCNT of order
0, can and
be imagined
a rolled ([10],
up sheet
because
of their
mechanical
electrical as
properties
[4]).of Acarbon
CNT, atoms,
which1
one
replaces
the
single
carbon
atoms
in
the
honeycomb
sheet
by
Y-shaped
junction-elements
arranged in atohoneycomb
Following
construct
nanotube
of order
corresponds
an SCNT grid.
of order
0, can [4],
be to
imagined
as a super
rolled carbon
up sheet
of carbon
atoms,1
and
each in
carbon-carbon-bond
by
a CNT.
an
SCNT
of order
L oneofneeds
one replaces
single carbon
in the
honeycomb
by Y-shaped
junction-elements
arranged
athe
honeycomb
grid. atoms
Following
[4],To
toconstruct
constructsheet
a super
carbon
nanotube
orderto1
replace
thecarbon-carbon-bond
single
atomscarbon
by appropriate
and the
by of
order
Ljunction-elements
−L1 one
tubes.
In our
and replaces
each
by a CNT.
construct
anbonds
SCNT
order
needs
to
one
the single
atoms
inY-junctions
theTo
honeycomb
sheet
by Y-shaped
modeling
approach,
presented
in
[3],
we
employ
sheets
of
level
L
−
1
to
construct
Y-junctions
replace
thecarbon-carbon-bond
single atoms by appropriate
Y-junctions
and the
by of
order
L −L1 one
tubes.
In our
and each
by a CNT.
To construct
anbonds
SCNT
order
needs
to
modeling
presented
in [3], weY-junctions
employ sheets
level
L −by
1 order
to construct
Y-junctions
replace theapproach,
single atoms
by appropriate
andofthe
bonds
L − 1 tubes.
In our
1
modeling approach, presented in [3], we employ sheets of level L − 1 to construct Y-junctions

1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.136

1
1

Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof
Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444

with elongated arms of level L − 1 used to replace the atoms and bonds to form a sheet of order
L. This can either be used to form a tube of order L or to construct a junction of level L that
can be employed to form higher order sheets.
We are working with directed graphs that represent our SCNT models. Each node corresponds to a carbon atom and each edge to a covalent C-C-bond. In contrast to many other
graph applications, the distinct nodes are not labeled with numbers or letters but are identified
by m-tuples. We call this type of graphs tuple-based graphs. Such a graph is shown in Figure
1, which represents the flat honeycomb grid of C-atoms that will result in a CNT when rolled
up. Each node is identified by a tuple with four entries.
0,2,1,0 0,2,1,1

0,2,0,1

1,2,1,0

1,2,0,0 1,2,0,1

0,1,1,0 0,1,1,1

0,1,0,1

Highest index

1010

2,1,0,0

1,0,1,0

No. of nodes

1011

1,1,1,1

1,1,0,0 1,1,0,1

1,0,0,0 1,0,0,1

1013
1012

2,2,0,0

1,1,1,0

0,0,1,0 0,0,1,1

0,0,0,1

1,2,1,1

size

436	

109
108
107
106
105
104

1,0,1,1

2,0,0,0

103
102
101
(1, 4, 8, 4)1 (2, 6, 12, 18)1 (1, 2, 8, 8)2 (1, 2, 4, 4)3

Figure 1: Graph with nodes labeled by tuples representing a honeycomb grid that can
be rolled up to a tube.

Figure 2: Comparison of the actual existing
nodes in an SCNT model and the highest index calculated by tree-based flattening.

For efficient and compact storage as well as fast access to the node and edge data it is necessary to assign each tuple a unique index that we call the serial index. There exist some straightforward ways to serialize multidimensional data ([8], [3]) which allow a fast index-computation.

m
m
There, an integer vector v of length m is mapped by φ(v) = i=1 vi j=i+1 (Vj + 1) where
V is an m-vector of the highest occurring values in each dimension of all v’s and 0 is a possible
value. This procedure is the reference for the comparison of the achieved index compression and
is referenced as tree-based flattening in the following [3]. However, those schemes fail on large
sparse data sets as they result from the tuple system. To give a first impression of this problem,
Figure 2 compares, on a logarithmic scale, the actual number of nodes for several graphs with
the highest index calculated by tree-based flattening. Four different tubes are shown with their
configuration (dx , lx , d0 , l0 )L with dx /lx setting the diameter and the length of the Y-junction
arms, d0 /l0 determining the diameter and length of the tube and L setting the order of the
tube. Details concerning the parameters can be found in [3].
The difference between the number of nodes and the occurring indices grows with the size and
the order of the tube. For order 3 tubes the difference is already six orders of magnitude. Thus,
there is the need for an alternative method to map each tuple to a serial index without occupying
too large an index space for sparse tuple-data, while being able to calculate the transformation
efficiently. One existing approach to cope with sparse, spatial data is the so called perfect
spatial hashing (PSH) developed by Lefebvre and Hoppe [7] that has been employed for spacesaving storage of 2D and 3D graphics data on graphic cards. In this paper, we demonstrate
that this algorithm can be extended to the storage of high-dimensional sparse data and employ
our tuple-based graphs as a use case. Other possible fields of application may arise from fields
in which multidimensional measurement data needs to be managed as it is, for example, the
case in genomics or cancer surveillance.
2

	

Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof
Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444

2

The Tuple System

Our SCNTs are modeled by directed graphs as shown in Figure 1. To uniquely identify the
nodes within the graphs, they are labeled by m-tuples t = (xm , xm−1 , . . . , x1 ) where xm is
called the leading tuple entry and x1 the lowest tuple entry, respectively. The tuples code the
hierarchy- and symmetry-relations between nodes as well as their spatial positions as described
in detail in [3]. The distinct entries in a tuple can be accessed via subscript operator tj with
j ∈ [1, . . . , m − 1, m]. Assume we have a set S of n tuples ti with i ∈ [1, 2, . . . , n], then the so
called tuple extent is defined as the tuple text = (max ti,m , max ti,m−1 , . . . , max ti,1 ). The tuple
extent determines an upper bound on all possible tuples that can be created.
In general, SCNTs of order L are formed by Y-junctions of level L − 1, themselves formed
by Y-junctions of level L−2, and so on, down to the level (−1) of single atoms with three bonds
to their neighbors each. This hierarchy is also visible within the tuple system and a general
tuple identifying a node in an order L SCNT is of the form:
t = xm xm−1 xm−2 xm−3 xm−4 xm−5 . . . xm−10 xm−11





tube order L

Y−junction level L−1

...

x x ... x x
 8 7  2 1

(1)

Y−junction level 0

Equation 1 shows that always eight subsequent tuple entries code the information for a Yjunction of a certain level. The four highest tuple entries additionally contain the information
of the diameter and the length of tube. They are called tube part and the remainder of the
tuple junction part.

2.1

Theory of Perfect Spatial Hashing

PSH, as described in [7], works on a d-dimensional domain U where d ∈ [2, 3] because 2D
and 3D graphics are considered. The domain U contains all positions p in the original PSH.
In each dimension the entries can assume u discrete entries from {0, 1, . . . , u − 1}. Thus, the
domain U can have in total u = ud entries/data points when fully occupied. For SCNTs we
have m dimensions with m ∈ [4, 12, 20, 28] because of the respective tuple lengths
mfor orders 0
- 3. There, the cardinality of U is determined by the tuple extent text with u = i=1 text
i .
A subset S ⊂ U denotes all those positions pi that are occupied in U e.g. in [7], all pixels with
colors. Its cardinality is given by n. This subset S corresponds to all actually existing
   tuples
ti within a given graph. The density ρ of the data is given by the fraction ρ = S /U  = n/u.
Each position pi is associated with a data record D(pi ). For the picture example this could
be the color information of the pixel. Accordingly, in the tuple-based graphs each tuple ti is
associated with the information of a node D(ti ) like its position or adjacent edges.
PSH tries to map the sparsely defined data
 D(p
 i ) with pi ∈ S to a record in a dense hash
map H by a hash function h : D(pi ) → H h(pi ) . Perfect hashing means that there are no
collisions in the hash map, i.e. for all i, j ∈ [1, 2, . . . , n] and i = j it holds that h(pi ) = h(pj ).
This is achieved through the combination of two imperfect hash functions h0 and h1 , combined
and
with an offset table Φ with rd = r entries. The resulting hash table H has md =
 m entries

the perfect hash function h is described for each dimension by: h(p) = h0 (p)+Φ h1 (p) mod m.
The procedure of fetching two tuples t1 and t2 with the help of h is visualized in Figure 3.
It is assumed that both tuples collide in h0 . Therefore, Φ requires an entry for h1 (t1 ) and one
for h1 (t2 ) to resolve the collision and avoid further collision with other tuples in H.
The two involved imperfect hash functions are defined as h0 = M0 p mod m and h1 =
M1 p mod r. Since Lefebvre and Hoppe [7] found that M0 and M1 can be simply set to m × m
3

437

438	

Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444
Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof

Figure 3: Fetching the data for two tuples t1 and t2 in the case of a collision in h0 . Figure
based on Figure 2 of [7].

identity matrices, the hash function evaluation of h0 and h1 reduces to an application of the
mod m and mod r calculation to each entry of the tuples with the additional recommendation
that r and m do no have a common divisor.

2.2

Evaluation of Perfect Spatial Hashing for Indexing Tuples

Following [7], PSH has several properties that directly fit to the problem domain of tuple-based
graphs: (1) It compresses spatial multidimensional data into small, dense tables, decreasing
the tuple extent of the hashed tuples. (2) It increases the density of the hashed domain and
allows to derive a serial index on the hashed domain quickly by tree-based flattening. (3) PSH
avoids collisions and thus makes the calculated serial indices unique, which is a prerequisite for
the SCNT simulation. (4) In contrast to most other perfect hash functions, PSH seeks also
to create a minimal function with a fully occupied hash table H, resulting in minimal serial
indices. (5) Another positive property of PSH is the uniform access time. A query always
requires two search operations in two tables Φ and H. For other hashing schemes resolution of
collisions leads to different times.
PSH also has some drawbacks compared to other hashing schemes but they are no severe
problem for the tuple-based graphs. PSH only works on static data sets, but the structure of
SCNTs is constant during simulation. The construction of the offset table Φ is complex and
the process may fail, requiring several restarts. But this pre-computing step needs to be done
once before the SCNT simulation and so its runtime is not crucial, particularly as the hashing
scheme can be stored and reused.
In addition, compared to [7], some simplifications are possible. In contrast to spatial positions, tuples are discrete data with no need for discretization or rounding. Furthermore, no
normalization of data is required since CPUs have direct integer support. There is also no problem with false positives since the solving algorithm never requests non-occupied tuples avoiding
to store an additional integer per hash entry to identify false positives as done in [7].
But there are two main differences to the original work we have to cope with. First, PSH
has only been applied to 2D and 3D problems, but we have up to 28 dimensions. Section
4 highlights the effect of this difference on the algorithm and the underlying data structures.
Second, for all their tests in [7], the authors only employed spaces with quadratic or cubic shape
which simplifies the problem and particularly leads to minimal hash functions more easily.
4

	

Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444
Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof

3

Related Work

Before deciding to extend PSH, we also considered several other spatial hashing schemes. Garcia
et al. developed another coherent spatial hashing scheme [5] capable of a fast parallel hash table
construction that succeeds in most cases with the first or at least very few trials. The authors
state that they reach a higher memory coherence than [7]. The imbalance in the amount of
memory accesses per entry is compensated by the usage of some additional memory. However,
they gave up the concept that every resulting hashing scheme needs to be perfect.
Another non-perfect spatial hashing scheme has been proposed by Pozzer et al. [9] targeting
CPUs in the application domain of collision detection. They employ fixed-size vectors and
pivots, i.e. static data structures and compare the construction and access performance with
two spatial hashing algorithms employing dynamic structures by Buckland [2] and Hastings [6].
In both cases they are at least three times faster. PSH is mentioned as related work but not
taken into account for comparison which also employs static data structures.
Alcantara et al. [1] propose a parallel, spatial hashing scheme based on a two step procedure
of FKS perfect hashing and cuckoo hashing targeted on GPU architectures. Their goal is to
create a hash table in which each item can, even in the worst case, be accessed in constant
time. Compared to PSH the access time of items is at the same level, while the construction
of the hash structure is faster by some orders of magnitude. The memory overhead during
construction is 1.42 ∗ n compared to 1.12 ∗ n of PSH. Normally, about 70% of the possible
entries in the hash structure are used. However, their hash function requires integers as input.
Their approach of encoding the 3D coordinates of a voxel by 10 bit of a 32 bit integer each, is
not feasible for higher dimensions.
Ng and Ravishankar [8] present a scheme for indexing large data bases that can also be
employed to calculate a unique serial index for multidimensional data as we have demonstrated
in [3]. With a modified method of [8], a fast and straightforward index computation is possible
with the drawback that the maximum index grows very fast for the sparse tuples spaces.

4

Implementation

This section describes the details of our C++ implementation and highlights our extensions to
PSH for higher dimensional domains.

4.1

Creating the Offset Table

The construction of the offset table Φ is an NP-hard problem. For each h1 (t) an appropriate
offset must be found avoiding collisions in H. Thus, in principle, the choice of an entry is
dependent on all other entries whose number can be several millions. Hence, the construction
is realized with a trial and error approach like in [7] and based on several heuristics.
We change several things to optimize the speed of construction and the quality of the result.
→
r = (r1 , r2 , . . . , rd ) and
First of all, we do not stick to a constant r and m but allow vectors −
→
−
m = (m1 , m2 , . . . , md ) with different entries rk and mk for each dimension to reduce the values
d
d
of r and m which are defined by r = k=1 rk and m = k=1 mk , respectively. High values of
r lead to a large Φ since h1 (t) will map each t to a distinct slot, while a large m results in high
serial indices.
For the instantiation of the iterative construction, we apply√two heuristics. Initially, all mk
are set to the smallest possible and uniform m satisfying m ≥ d n. All entries rk are set to the
smallest possible r satisfying: rd ≥ σn with σ = 1/2d as proposed by [7]. Now, the value of m
5

439

440	

Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof
Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444

is compared to n. If m is at least higher by a factor of 3, the entries within the respective tuple
extent text are searched that have
d the greatest distance to m. At these positions the entry mk
is decremented by 1 as long as k=1 mk ≥ n.
In the second step, a first feasibility check is performed ensuring that there are no two
tuples t1 , t2 with h0 (t1 ) = h0 (t2 ) ∧ h1 (t1 ) = h1 (t2 ) which makes the construction of a perfect
hash function impossible. This check can be performed very efficiently with an additional table
T col−h1 that is required for the next step anyways. It stores those sets of tuples that are mapped
to the same hash value by h1 . For each tuple ti the hash-value h1 (ti ) is calculated. Now, a
lookup on the table T col−h1 is performed that has h1 (ti ) as its key value. If the key h1 (ti ) does
not exist, a new vector is inserted that has a reference to ti as first entry. In the case that there
already is an entry for h1 (ti ), the reference to ti is appended to the existing vector. In this way,
just a small percentage of tuples will be left, divided in sets with a typical size  100. Since
only nodes within the same set can violate h0 (t1 ) = h0 (t2 ) ∧ h1 (t1 ) = h1 (t2 ) it is sufficient to
test every tuple ti against the other tuples in this set for a collision in h0 . If there is only one
collision, rk and mk need to be updated. Since the main goal is to assign minimal serial indices
to the tuples, the algorithm primarily tries to adapt the rk values by searching those entries
with the highest distance to their respective entries in text and incrementing them by one. Out
of the tuples resulting in collisions, k are picked at random and the colliding positions in the
rk ’s are also incremented as long as all k collisions are resolved. The hope is that many more,
ideally all, collisions are avoided due to these changes. The values presented here were obtained
with k = 1 resulting in the most optimization steps but the lowest possible values for r and
m. We also tested k = 10, resulting in a faster construction but slightly higher values for r.
Afterward, the second step is repeated until it succeeds.
→
The third step tries to construct an offset table Φ for the given −
r resolving all collisions in
h0 . To that end, we apply the heuristic of [7] and start to find offsets for the biggest colliding
sets of U in T col−h1 . From this auxiliary table it is easy to deduce the order in which the sets
should be processed. For each set an offset is randomly generated and tested for feasibility. If
an appropriate offset is found, i.e. it resolves existing collisions without creating new ones, it is
inserted into Φ. Then, the algorithm proceeds with the next largest set until all collisions are
covered. In the case that it is not possible to find an appropriate offset for a set cl , i.e. the l’s
set that is processed, the algorithm applies backtracking. The chosen offset for the last set cl−1
is changed and afterward cl is processed again. If this attempt does not succeed, the offset for
cl−2 is changed. After several unsuccessful attempts the algorithm goes back to step two.
This three step procedure is repeated until a PSH is found or canceled when m and r become
too high to achieve a sufficient reduction.

4.2

Dynamic Data Structures and 1-dimensional Keys

Since PSH was designed to work on GPUs, static multidimensional arrays are used for the tables
Φ and H. The size of these tables is md and rd and the hashed 2D and 3D coordinates are
used to access the entries. This is feasible under the simplifying assumption that the problem
domains are always quadratic or cubic. For the case of longer tuples with unequal dimensions
this procedure wastes much memory. Table 1 visualizes this fact for several tubes. For example,
for (1, 6, 12, 18)1 nearly 1.6 ∗ 107 entries will be statically allocated for Φ while only 1.7 ∗ 104
entries are required. To cope with this problem, we employ the dynamic std :: unordered map
which only stores existing values and the search for an entry is possible in constant time.
Another problem is the usage of the tuples and their hashes as keys for Φ and H, respectively,
since a lot of memory is required when storing the vectors representing the tuples. Thus, we
6

	

Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof
Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444

employ serial indices as keys that are calculated on the basis of the knowledge of the tuples
and h0 , h1 , m and r. The keys for Φ are calculated by applying h1 to the current tuple t and
→
then this hashed tuple is serialized by tree-based flattening with −
r as extent. For order 3 tubes
this means that instead of 28 16 bit-values only one 64 bit-value is required, which reduces the
storage for 1 ∗ 107 entries in H for the keys by a factor of 7 from 530 MB to 75 MB. Additionally,
long tuples cause high construction- and access-time. Generating a map with 1∗107 randomized
28-vectors as keys and values requires about 30 s on our test system, while the same test is done
in about 10 s if the vectors are serialized and inserted in an integer based map. In this way, we
can avoid the drawbacks of vectors as keys by exploiting our knowledge about the tuples.

4.3

Density Threshold and Different Compression Modes

The construction of a perfect hash function always succeeds if r or m are chosen large enough,
since either Φ contains an entry for every ti or H allocates so many slots that for each
  tuple a
slot can be directly assigned. Then, it is possible that H reserves more slots than U  and the
calculated serial indices are partly much higher than those calculated on the original domain.
An analysis of those cases reveals
  that they normally appear if the domain U is occupied
 
relatively dense. This means that S  is not much smaller than
  U . To exclude those cases,


we have empirically determined a density threshold ρthres = S /U  < 0.15. For all domains
with higher ρthres it is not tried to construct a full perfect hashing function because of the low
probability of finding a sufficiently compact one. Instead, only a perfect hashing on the whole
junction part i.e. the part of the tuple after the four highest entries [xm , . . . , xm−3 ] is generated,
since [xm , . . . , xm−3 ] are usually relatively dense and thus can prevent a compact hash function.
The resulting sub-tuple is appended to the original tube part and this new tuple is serialized by
tree-based flattening. The compression of the whole domain is called mode 1, the compression
of the junction part mode 2.
   
The reduction factor as a measurement of the efficiency of PSH is defined by ψ = U /H .
For mode 2, ψ is equal to the reduction factor ψ juncs achieved on the junction part of the tuple.

5

Results

Tests for the compression quality and the speed of calculation were performed on a dual socket
machine (2 * Intel Sandy Bridge Xeon E5-2670 processor with 8 cores each) running CentOS 7
with 128 GB of shared DDR3 ECC RAM. The g++ compiler (version 4.8.5) with optimization
level O3 and the GNU OpenMP implementation are employed.

5.1

Compression Results

We compare the reduction factor for the serial indices between general PSH to a structuretailored index calculation scheme described in [3] that we call IndexGraph. Summarized briefly,
the IndexGraphs are based on a hierarchy of maps that compress each junction level separately.
For each junction level an internal serial index is calculated, consecutively numbered and the
correlation stored in a table. This allows the assignment of the smallest possible indices to
the junction part. The dense part of the tuples corresponding to the tube gets its index via
tree-based flattening. Combining both leads to the serial index for the whole tuple.
Figure 4 summarizes the reduction factors for the different tested tubes, whose properties
are listed in Table 1, on a logarithmic scale. Configurations that are marked by an asterisk over
their bar use compression mode 2 because it reaches the better result while all others are hashed
7

441

Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof
Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444

Table 1: Summary of the tested tubes. For each configuration, the second column shows the
number of tuples to hash. Columns r = rd and m = md give the values achieved by the original
PSH algorithm while r∗ and m∗ give the new values resulting from our extended procedure.
%Φ shows the fraction: (used slots in Φ) / (No. tuples), while the last column gives the time
to construct PSH in seconds.
Configuration No. tuples
r
r∗
m
m∗
%Φ Constr.(s)
1
4
3
2
2
(1, 4, 8, 4) *
1.7 ∗ 10
6.6 ∗ 10
9.6 ∗ 10
2.6 ∗ 10
2.6 ∗ 102 99%
<1
4.5 ∗ 104
6.6 ∗ 103 9.6 ∗ 102 2.6 ∗ 102 2.6 ∗ 102 99%
<1
(1, 4, 8, 14)1 *
(1, 6, 12, 18)1
1.3 ∗ 105
1.6 ∗ 107 9.4 ∗ 105 5.3 ∗ 105 1.6 ∗ 105 13%
<1
1.7 ∗ 105
1.6 ∗ 107 9.4 ∗ 105 5.3 ∗ 105 2.4 ∗ 105 13%
<1
(2, 6, 12, 18)1
(2, 6, 12, 116)1
1.0 ∗ 106
1.3 ∗ 1014 2.7 ∗ 106 1.7 ∗ 107 1.0 ∗ 106
6%
4.7
5.6 ∗ 106
4.3 ∗ 107 3.3 ∗ 105 6.6 ∗ 104 6.6 ∗ 104 97%
<1
(2, 3, 6, 12)2 *
(1, 2, 8, 8)2
1.0 ∗ 106
9.5 ∗ 1013 2.0 ∗ 107 1.0 ∗ 106 1.0 ∗ 106 38%
11.8
3
7
2.5 ∗ 10
2.3 ∗ 1013 6.9 ∗ 109 2.7 ∗ 107 2.7 ∗ 107 75%
370
(1, 2, 4, 4)
by mode 1. In all cases, our extended PSH algorithm achieves a reduction of the maximum
index of the same order of magnitude as the IndexGraph, although the IndexGraphs exploit
properties of SCNT models like repetitions in the tuple extent while PSH can be applied to
generic data.

Comparison of reduction factors of both approaches with ideal case
reduction factor ψ

442	

−375%

Reduction PSH ψPSH
Reduction IG ψIG
Ideal reduction ψideal

107
106
105

−4%

103
102

−45%

*

−45%

*

−21%

+167%

*

104

−36%

−3%

101
100

(1, 4, 8, 4)1

(1, 4, 8, 14)1 (1, 6, 12, 18)1 (2, 6, 12, 18)1 (2, 6, 12, 116)1 (2, 3, 6, 12)2

(1, 2, 8, 8)2

(1, 2, 4, 4)3

Tube configuration

Figure 4: The reduction factors achieved by PSH (ψPSH ) and by our structure-tailored
IndexGraph (ψIG ) for different tube configurations compared to the ideal reduction (ψideal )
calculated by the fraction of the number of tuples of the configuration and the highest index
resulting from tree-based flattening. The numbers over the bars show the relative difference
of both indexing procedures by: ψPSH /ψideal − ψIG /ψideal .
The order 1 tube (2, 6, 12, 116)1 demonstrates the efficiency of our algorithmic extensions
compared to the standard PSH approach. The tube is characterized by highly varying entries
within its tuple extent text = (59 12 2 2 | 6 3 3 8 4 4 2 2), which is a problem for the original PSH.
The constraint of choosing a uniform m forces the algorithm to m = 4 and r = 15, as demonstrated in Table 1, in order not to violate the prerequisite  ∃t1 , t2 ∈ S | h0 (t1 ) = h0 (t2 )∧h1 (t1 ) =
h1 (t2 ). These values are actually higher than those for the order 2 and 3 tubes with longer
tuples and more nodes. The resulting reduction factor would only be 5 in that case while the
IndexGraph reaches the ideal value of 75. In our algorithm, the original r12 = 1512 = 1.3 ∗ 1014
8

	

Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof
Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444

→
is replaced by the new vector −
r = (15 3 3 3 | 3 3 3 3 3 3 3 3). But most important is that also m
can be reduced by one order of magnitude by replacing the uniform m = 4 with the vector
→
−
m = (4 4 2 2 | 4 4 4 4 4 4 2 2).
For the remaining order 1 tubes the IndexGraph and the PSH achieve reduction factors in
the range of the ideal value regardless of the chosen compression mode where for (2, 6, 12, 18)1
m can be reduced by the factor 2.2 compared to the original PSH and even a factor of 3.3 for
tube (1, 6, 12, 18)1 . r can be decreased by over one order of magnitude for these tubes.
For the tube (1, 2, 8, 8)2 the reduction through PSH is even higher than that of the IndexGraphs and nearly reaches the optimum (18662 versus 19109). This tube is a kind of best-case
scenario for PSH. It consists of 1, 024, 000 nodes which is very close to 220 = 1, 048, 576 with
20 being the tuple length for an order 2 tube. In this case m = 2 is chosen, resulting in a hash
table H with 1, 048, 576 available slots. In combination with an appropriate Φ all nodes can be
assigned a slot, resulting in an occupation of 98% and hence nearly a minimal hash function.
As a last point, the size of the table Φ is investigated which is not crucial for performance
but for the memory consumption of the PSH structure and is the main difference concerning the
required storage compared to IndexGraphs whose small tables can be neglected. The second
to last column of Table 1 shows how many slots are used in Φ in relation to the overall number
of tuples in the respective tube. For the three mode 2 tubes nearly every tuple is hashed to a
different slot. That is not an issue, since in these cases the number of tuples to hash is equal to
the number of nodes within a junction, which is much smaller than the total number of nodes
in the tube, e.g. 176 compared to 1.6 ∗ 105 for (2, 6, 12, 18)1 . As already mentioned, the size of
r influences the size of Φ with a higher r leading to more entries. Hence, the optimization of r
can also reduce the size of Φ. This can be demonstrated for (2, 6, 12, 116) where the number of
entries is reduced from 2.5 ∗ 105 to 6.5 ∗ 104 and thus from 25% to 6%. But also for (1, 2, 8, 8)2
there is a reduction from 6.4 ∗ 105 to 3.8 ∗ 105 entries. The only instance where PSH does not
perform that good is the order 3 tube which requires a relatively dense offset table, caused by
the complexity of the 28-dimensional problem, requiring further optimizations.

5.2

Performance Results

In a first test, we performed a search of about 5 ∗ 107 random tuples on different tube configurations with PSH and with IndexGraphs. The tests show, that on these synthetic benchmarks,
the search time for PSH is higher by a factor about 1.5 with values ranging from 1.26 to 1.67.
The influence of PSH on our overall solving routine is not that significant. For singlethreaded execution, the performance difference lies below 10%. However, PSH has a negative
influence on the scaling behavior of the solver, so the difference grows to about 20% when
running with four threads and this difference remains when running with 8 and 16 threads.
The runtime for the construction of PSH plays, as explained, an subordinate role. But we
also measured the time to construct the perfect hash function for all tubes, which is shown
in the last column of Table 1. For nearly all tubes, the PSH can be generated within a few
seconds. Only for the order 3 tube about 6 minutes are required. We are confident that there
is potential to further optimize the runtime of the construction process.

6

Summary and Outlook

We presented a generalization of the perfect spatial hashing algorithm that is able to cope with
high dimensional data as well as varying size per dimension. It was successfully applied to the
problem of indexing nodes in tuple-based graph models of SCNTs. The resulting algorithm is
9

443

444	

Extending Perfect Spatial Hashing
Burger,
Nguyen and Bischof
Michael Burger et al. / Procedia Computer Science 108C (2017)
435–444

competitive with a structure-tailored scheme exploiting special SCNT properties although PSH
is a general scheme that has no assumptions about the data to hash. Required extensions to
the original algorithm were proposed and an efficient implementation was outlined.
In the future, we want to apply PSH to other application domains as well by adapting the
presented methodology to the respective problem domain and compare it to domain-specific
solutions.
→
Furthermore, we plan to further improve the performance and quality in determining −
r and
→
−
m because,
for
some
cases,
it
seems
to
be
reasonable
to
make
a
compromise
between
the
size
 
of r and Φ or to accept a slightly higher m to reduce collisions. We also plan to investigate
ways of reducing the influence of PSH on the scalability of our solving routine.

Acknowledgement
The work of M. Burger is supported by the ’Excellence Initiative’ of the German Federal
and State Governments and the Graduate School of Computational Engineering at Technische Universität Darmstadt (TUD). The calculation have been performed on the LichtenbergHochleistungsrechner at TUD. We thank M. Gösele for introducing PSH to us and the anonymous reviewers for their helpful comments.

References
[1] D. A. Alcantara, A. Sharf, F. Abbasinejad, S. Sengupta, M. Mitzenmacher, J. D. Owens, and
N. Amenta. Real-time parallel hashing on the gpu. In ACM SIGGRAPH Asia 2009 Papers,
SIGGRAPH Asia ’09, pages 154:1–154:9, New York, NY, USA, 2009. ACM.
[2] M. Buckland. Programming game AI by example. Wordware Pub Co, first edition, 2004.
[3] M. Burger, C. Bischof, C. Schröppel, and J. Wackerfuß. Methods to model and simulate super
carbon nanotubes of higher order. Concurrency and Computation: Practice and Experience, 2016.
[4] V. R. Coluci, D. S. Galvao, and A. Jorio. Geometric and electronic structure of carbon nanotube
networks:’super’-carbon nanotubes. Nanotechnology, 17(3):617, 2006.
[5] I. Garcı́a, S. Lefebvre, S. Hornus, and A. Lasram. Coherent parallel hashing. In Proceedings of the
2011 SIGGRAPH Asia Conference, SA ’11, pages 161:1–161:8, New York, NY, USA, 2011. ACM.
[6] E. J. Hastings, J. Mesit, and R. K. Guha. Optimization of large-scale, real-time simulations by
spatial hashing. In Proc. 2005 Summer Computer Simulation Conference, volume 37, pages 9–17,
2005.
[7] S. Lefebvre and H. Hoppe. Perfect spatial hashing. In John Finnegan and Julie Dorsey, editors,
ACM SIGGRAPH 2006 Papers, page 579, 2006.
[8] W. K. Ng and C. V. Ravishankar. Block-oriented compression techniques for large statistical
databases. IEEE Transactions on Knowledge and Data Engineering, 9(2):314–328, 1997.
[9] C. T. Pozzer, C. A. de Lara Pahins, and I. Heldal. A hash table construction algorithm for spatial
hashing based on linear memory. In Proceedings of the 11th Conference on Advances in Computer
Entertainment Technology, ACE ’14, pages 35:1–35:4, New York, NY, USA, 2014. ACM.
[10] Z. Qin, X. Feng, J. Zou, Y. Yin, and S. Yu. Superior flexibility of super carbon nanotubes:
Molecular dynamics simulations. Applied Physics Letters, 91(4):043108, 2007.

10

