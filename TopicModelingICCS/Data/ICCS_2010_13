Available online at www.sciencedirect.com

Procedia
Computer
Science001(2009)
(2012)
951–960
Procedia
Computer Science
000–000

Procedia
Computer
Science
www.elsevier.com/locate/procedia
www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Automated measurement of quality of mucosa inspection for
colonoscopy
Xuemin Liua, Wallapak Tavanaponga*, Johnny Wonga, JungHwan Ohb, Piet C. de Groenc
b

a
Department of Computer Science, Iowa State University, Ames, IA, 50011, USA
Department of Computer Science and Engineering, University of North Texas, Denton, TX 76203, USA
c
Mayo Clinic College of Medicine, Mayo Clinic, Rochester, MN 55905, USA

Abstract
Colonoscopy is currently the preferred screening modality for prevention of colorectal cancer. However, the effectiveness of
colonoscopy depends on the quality of the procedure, which depends on several factors. In this paper, we present new methods
that derive a new quality metric for automated scoring of quality of mucosa inspection performed by the endoscopist. We
conducted Pearson’s Correlation analysis of the computerized metric scores against the averages of the manual scores given by
four domain experts on twenty-one colonoscopy videos. Our metric shows a relatively strong positive correlation (Pearson’s
correlation coefficient of 0.72) between the computer-generated score and the ground truth. Hence, the proposed work is very
promising to be used for quality control/assurance in routine colonoscopy screening.
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝
Keywords: Quality of colonoscopy; image analysis; objective quality metrics

1. Introduction
Colorectal cancer is the third leading cause of cancer-related deaths in the Western world [1]. Colorectal cancers
are malignant tumors that develop in the colon and rectum. If the cancer is found and treated early before metastasis
to lymph nodes or other organs occurs, the survival rate is higher. Colonoscopy has made a significant contribution
to the decline in the number of colorectal cancer-related deaths. During colonoscopy, an endoscope, which is a
flexible tube with a tiny video camera with a wide-angle lens at the tip, is inserted into the rectum via the anus. The
camera generates a video signal of the interior of the human colon, which is displayed on a monitor for real-time
analysis by the physician. The endoscope is advanced gradually into the cecum (the most proximal part of the colon)
or the terminal ileum. This phase is called an insertion phase. The withdrawal phase follows, where the endoscope is
gradually withdrawn. Careful mucosa inspection and diagnostic or therapeutic interventions such as biopsy, polyp
removal, etc., are performed during the withdrawal phase.
Colonoscopy is, however, not perfect. Recent data suggest that there is a significant miss rate associated with
colonoscopy for the detection of even large polyps and cancers. The average miss rate is estimated around 4-12%,
estimated from data in [2-8]. For this reason, issues regarding quality of colonoscopy, such as cecum intubation rate
and colon preparation, have been extensively studied [9, 10]. A number of indirect markers of colonoscopy quality
have been proposed [11]. Given a large number of colonoscopic procedures performed each year (e.g., over 14

* Corresponding author. Tel.:+ 1-515-294-2987; fax: +1-515-294-0258.
E-mail address: tavanapo@cs.iastate.edu.

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.105

952

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

millions in the US alone [12]), detailed manual assessment of quality of every procedure is subjective (based on
experience of the reporting physician) and very time-consuming. This has motivated us to introduce a number of
automated methods that perform objective measurement of quality of colonoscopy. We implemented these methods
in a software system to compute post-procedure scores of quality for routine colonoscopy screening to
ensure/improve patient care. The quality scores are also suitable for pay-for-performance based reimbursement.
One of several important quality indicators of colonoscopy is the quality of the mucosa circumferential inspection.
Experienced endoscopists state that as much as possible of the mucosa (all sides or 360 degrees inspection) of the
colon wall should be examined throughout the withdrawal phase of colonoscopy. Fig. 1(A-B) shows a desirable
withdrawal inspection pattern in which the lumen is seen in the camera field of view. The colon center axis is at the
center of the lumen (green area). Fig. 1(C-D) shows a different inspection pattern where one side of the colon wall is
seen each time without the center of the lumen. Depending on the configuration of the anatomy and the location in
the colon a combination of these two types of inspection may be required to see all mucosa.

Fig. 1 Circumferential withdrawal inspection pattern: A and C show the spiral shape of the movement of the tip of the endoscope.
B and D show the visual field in red. Green bar represents the colon lumen; A and B reflect views in which the distant proximal
colon is visible (lumen view). C and D reflect views in which the distant proximal colon is absent and only colon wall is seen.

We previously proposed an automated method that measures quality of circumferential mucosa inspection [13-14].
We have improved upon our previous work, resulting in the following contribution in this paper. 1) We present a
new method that utilizes quasi-parallel curves/edges of nested colon folds to estimate the location of the colon
center axis for the types of images that our previous technique could not handle well. We call our new technique
“PCurve” to signify the utilization of these parallel curves. 2) We introduce a new quality metric and methods to
compute the new metric based on the detected location of the colon center axis. 3) We presented the result of
Pearson’s correlation analysis that evaluates the new metric and our previous metric against the ground truth given
by four domain experts. Our new metric shows a relatively strong positive correlation (Pearson’s correlation
coefficient of 0.72) with the ground truth. Therefore, the proposed method is very promising to be used for quality
control/assurance in routine colonoscopy screening.
The remainder of this paper is organized as follows. Section 2 presents our previous work. Section 3 presents
PCurve and effectiveness of PCurve. Section 4 describes our proposed metric and the result of the correlation study.
Finally, we conclude the paper and provide the description of our future work in Section 5.
2. Related Work
There is no prior work that attempts to objectively derive quality of circumferential mucosa inspection of
colonoscopic procedures except our previous work [13-14]. Work in the area of microrobotic endoscopy [15-18]
address the problem of segmenting the lumen boundary using region-growing [15, 17], an N-level quadtree-based
pyramid structure [16], or APT-Iris [18]. These techniques might be applicable to locate the colon center axis for
colonoscopic images with dark lumen. Grayscale Shape-based View Mode Classification (GSVM) [19] employs the
relative darkness of the lumen coupled with shape features of the colon folds surrounding the lumen to determine the
presence of the lumen in a colonoscopic image. Other research interests include automatic detection of polyp
regions in colonoscopic images [20-23].

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

Our previous method for objectively measuring quality of circumferential inspection patterns [13-14] states
several drawbacks of GSVM, and thus proposes a new approach working as follows. Pixels in each clear (nonblurred) image are first classified into either lumen pixels or non-lumen pixels using a decision tree classifier on
RGB values. Then, it uses a Support Vector Machine classifier to determine whether the image is a lumen view or a
wall view based on a set of features derived from classification of lumen pixels. A lumen view is defined as a clear
frame in which the distant colon lumen is seen. A wall view is a clear frame without the distant colon. The colon
center axis location in 2D is then estimated only on lumen view images. The weighted center of qualified lumen
pixels in a lumen view image is used as the estimated location of the colon center axis, which is used as the
reference to find the side of the colon wall on which the camera is focusing. Quadrant Coverage Histogram (QCH)
metric is then extracted. QCH, in essence, estimates the average number of quadrants of the colon wall inspected in
a given duration (time window). A short duration of inspection that can cover the four quadrants of the colon wall
may indicate good quality. The experimental results show that the endoscopist completed inspection of the four
quadrants every 20 seconds on average on three test videos; however, formal validation of correlation between QCH
metric values and the ground truth scores given by the domain experts was not provided. Readers interested in more
details are referred to [13-14].
3. Proposed Work
Our previous method misclassifies some true non-dark lumen images as wall images. The number of
misclassified non-dark lumen images varies depending on how the endoscopist positions the camera. Adding nondark lumen pixels for training of the decision tree classifier improves sensitivity but reducing specificity. We,
therefore, propose the PCurve technique that utilizes quasi-parallel edges/curves of nested colon folds to estimate
the location of the colon center axis. We use the term “quasi” to indicate that these curves are not strictly parallel
due to the complex nature of the colon and colon distortion. Based on our observation, we categorize non-dark
lumen images into two classes: 1) “M-Class” having at least two groups of quasi-parallel folds as in Fig. 2(a) and 2)
“S-Class” having a single group of quasi-parallel folds as in Fig. 2(c). For M-Class, we can use the intersection of
the perpendicular bisectors of any two groups of the quasi-parallel folds as the location of the colon center axis as
shown in Fig 2(b). For S-Class, a different method is needed. The detected location of the colon center axis is used
to derive quality metrics.

Fig. 2 Non-dark lumen image examples: (a) three groups of quasi-parallel folds forming the triangles; (b) intersection of
perpendicular bisectors of the red and blue groups of quasi-parallel folds is used to estimate the location of the colon center axis
(blue rectangle); (c) one group of quasi-parallel folds

PCurve consists of three major steps: 1) pre-processing, 2) determination whether an image is a wall image or an
S-class lumen image or an M-Class lumen image, and 3) estimation of the colon center axis location. We apply
PCurve only on images classified as wall images by our previous method to recall true non-dark lumen images
missed by our previous method.
1) Pre-processing discards an edge with the number of edge pixels outside a pre-determined range observed for
most colon fold edges. Next, we cut the remaining edges having corners (e.g., edges of a triangle in Fig. 2) at
each corner into smaller edge segments to facilitate detection of quasi-parallel folds. Last, we remove small
branches of these edges. Due to limited space, we omit the details of this step.

953

954

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

2) We calculate the number of groups of parallel edges in the image to be between zero and two inclusive. The
first step is to find an edge pair in which the edges in the pair are quasi-parallel. Checking all possible
combinations of any two edges whether they are quasi-parallel is time consuming. To reduce the number of
combinations, we first compute the coarse orientation of each edge by fitting a line on the edge using the builtin polyfit Matlab function. Next, we calculate the angle value of the fitted line using the vertical axis as the
reference. We use K-means clustering algorithm with K=2 to divide the edges into two groups based on the
angle values. In each group, we perform a detailed check of all possible pair combinations whether edges in
each pair are quasi-parallel to each other as follows.
Given a pair of edges, we project each edge on to each other by locating on the other edge the points closest (in
the sense of Euclidean distance) to the endpoints of the edge being considered. For instance, consider the edge
pair AB and CD (Fig. 3(c)). The closest points of A and B on edge CD are A’ and B’, respectively. The closest
points of C and D on edge AB are C’ and D’, respectively. Hereafter, we use the projected edges (e.g., A’B’ and
C’D’) instead of the original edges to decide whether the two original edges in the pair are quasi-parallel. We
discard short projected edges (the edge length smaller than a threshold L). We divide each remaining projected
edge pair (e.g., A’B’ and C’D’) into pairs of small edge segments as shown in Fig. 3(d). Next, we determine
whether the edge segments in each of these pairs are quasi-parallel, i.e., they have the angle difference within a
degree threshold A. If at least T percent of all pairs is quasi-parallel, we claim the entire edge pair quasi-parallel
(e.g., AB and CD are quasi-parallel). We selected L=40, A=20, T=70, and the number of edge segment pairs
based on experiments with our training dataset.

Fig. 3 Quasi-parallel edge detection: (a) non-dark lumen image; (b) corresponding qualified edges; (c) a pair of candidate quasiparallel curves marked by a blue semi-transparent rectangle in (b); (d) the pair of candidate edges cut into pairs of small edge
segments

3) Based on our observation, some wall images have only one group of two parallel edges (e.g., images in the
cecum around the appendiceal orifice or two parallel edges of the same very protruding fold). Lumen images
typically have more than two parallel edges in a group. Therefore, if we detect only one group of two parallel
edges in an image, we classify the image as a wall image. Otherwise, the image is considered a lumen image
and is further classified. Then we define the angle of a group of quasi-parallel curves as the average of the angle
values of all the curves in the group. There are two angle differences between two different groups of quasiparallel curves, and their summation is equal to 180 degrees. If the smaller angle difference is less than 35
degrees, we consider them in the same group. Finally, we assign lumen images with one group of parallel
curves into S-Class and images with at least two groups of parallel curves into M-Class.
3.1. PCurve for M-Class
The colon center axis location is estimated to be at the intersection point of two perpendicular bisectors of the
two groups of quasi-parallel curves. Fig. 2(a) shows a non-dark lumen image with three groups of quasi-parallel
folds, but one group of quasi-parallel folds is occluded by water used for cleansing the colon mucosa. Therefore,
only two groups of quasi-parallel curves are detected (see Fig. 2(b)). Group I is a set of red curves along quasiparallel folds on the left side. Group II is a set of blue curves on quasi-parallel folds on the right side. The red line

955

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

AA’ and the blue line BB’ are the perpendicular bisector for curves in Group I and Group II, respectively. The
intersection point C of these two lines lies correctly in the neighborhood of the colon center axis.
To find the perpendicular bisector line, we need to know at least the slope (S) of the line and the coordinate of
one point (P) on the line. Given slope values (s1, s2, …, sn) of n quasi-parallel curves in a group, we determine the
slope S of the perpendicular bisector line for a group of quasi-parallel curves using Equation (1).
n

1/ tan(¦ arctan( si ) / n)

S

(1)

i 1

The coordinate of the point P on the perpendicular bisector is chosen as follows. We first draw a line (line L) to
be quasi-parallel to all the curves in its group (with slope value equal to -1/S) and across the center of the image.
Then, we project the center point of each curve in the group onto L. At last, given the coordinates of all projected
center points (xi, yi) on L and the length of the corresponding curve li, where i=1, 2, …, n, we calculate the
coordinate (X,Y) of P as the weighted center of the projected points using Equation (2). The intersection point of the
two perpendicular bisectors is marked as the location of the colon center axis.
n

X

n

n

n

¦ x xl / ¦l ˈ Y ¦ y xl / ¦l
i

i 1

i

i

i 1

i

i 1

i

(2)

i

i 1

3.2. PCurve for S-Class
Images in S-Class have only one group of parallel curves. We use the following observations to design the
technique to find the coordinate of the colon center axis. 1) A significant intensity change occurs before entering and
leaving the neighborhood of the colon center axis. 2) The intensity around the colon center axis is lower than the
average intensity of the image. We first find the perpendicular bisector of the group of parallel curves using the
same technique as that of M-Class images. Fig. 4(a) shows the detected group of parallel curves in blue and the
corresponding perpendicular bisector of these curves (dark blue line in Fig. 4(a)). We find candidates for the colon
center axis location on the perpendicular bisector as follows. Let Vi be the intensity of pixel i and I be the average
intensity value of the pixels along the perpendicular bisector in the grayscale image. Pixels outside the area of the
endoscope signals (i.e., black corners in Fig. 4) are not considered. We compute Ci=VDi * (I-Vi) for each pixel i
along the perpendicular bisector where VDj = |Vi-Vi+d|. VDj is the absolute difference in intensity values of pixel i
and pixel i+d where d is a constant (d=10 based on experiments). Large VDi value indicates large intensity change.
Positive large I-Vi value indicates that pixel i has much lower intensity than the average intensity along the
perpendicular bisector. Fig. 4(c) shows the plot of Ci that combines the impact of both intensity change and actual
intensity. We find all candidate pixel k with positive Ck value and Vk is less than the intensity threshold (190).
Among all these candidates, we select the pixel with the lowest intensity as the colon center axis.

(a)

(b)

956

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

Fig. 4 (a) Labeled parallel curves in blue and the detected colon center axis marked by the blue rectangle for an S-class image; (b)
the plot of Ci

3.3. Experimental results
Videos in our experiments were selected from routine colonoscopy screening performed by several endoscopists
using Fujinon endoscopes. No patient identifiable information is included in these videos. One video file contains a
single colonoscopic procedure. The video format is MPEG-2 with the image resolution of 720x480 pixels. We
created a test bed of close to 3,000 images selected from eight videos listed in Table 1. For test sets I and III, images
were extracted at one frame per second. For test set II, images were extracted at five frames per second. Then, we
used our blurry frame detection software [24] to obtain only clear images and applied our previous method [14] on
them to obtain the test bed. We selected only S-Class lumen images to create test set I. Test set II includes only MClass lumen images. The reason for using a higher image extraction rate for test set II is because each of the videos
does not have many M-Class images. Test set III consists of only wall view images.
Table 1: Details of ground truth image datasets
Video ID

0293

0295

0297

0300

0304

0305

0307

0315

Test Set I

172

47

74

131

76

58

63

332

Total
953

Test Set II

143

-

143

569

-

-

-

143

998

Test Set III

-

196

-

-

489

315

-

-

1000

We implemented PCurve in Matlab. Threshold and parameter values for the software were chosen experimentally
from a separate training data set that does not overlap with the test data sets. For performance evaluation, we
superimpose a “view direction” arrow on the original image to create the corresponding arrow-annotated image with
the arrow head at the colon center axis and the arrow tail at the center of the image. The average time taken per
image for determining the colon center axis on the test machine (Windows 2003 SP2 on Intel Xeon dual Quad-Core
1.86GHz with 4 GB RAM) is 3.43 seconds. Each annotated image was manually evaluated by one trained staff and
verified by one experienced endoscopist. For the first two test image sets, we gave each image a score between A
(best quality) to D ratings (worst quality). Fig. 5 shows images and corresponding scores. Table 2 shows that
PCurve is effective for 92.45% (A and B ratings) of S-Class images and 90.18% (A and B ratings) for M-Class
images.

A

B (too long)

C

B (too short)

D

957

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

Fig. 5 Example of categories of ratings A to D; white dashed arrows are the ground truth. Solid arrows are annotated by our
program. For the B rating, the software-annotated and the ground truth arrows point to the same general direction, but the length
of the software-annotated arrow is either too long or too short. For C and D ratings, the software-annotated and the ground truth
arrows point to a different direction.
Table 2: Effectiveness of PCurve for S-Class and M-Class images
Evaluated Technique

PCurve for S-Class

PCurve for M-Class (%)

Category

% Correct

% Correct

A

74.92

73.95

B

17.52

16.23

C

4.30

6.61

D

3.25

3.21

For the third test set, only 8.4% (84/1000) of wall view images are incorrectly detected as non-dark lumen images.
The drawbacks of PCurve are as follows. When there is significant distortion (i.e, a bend or corner distal to the
position of the camera) inside the colon, the distal colon center axis is not close to the intersection of perpendicular
bisectors of the two groups of parallel folds. Furthermore, only partial edges of the folds are detected. One possible
solution is to give different weights to different segments along the parallel folds according to the intensity.
4. Proposed Quality Metric and Evaluation of Quality Metric
We define a ‘spiral’ as a completion of inspection of four different quadrants of the colon wall. We measure the
number of spirals considering only the lumen images. Using the center of the image as the reference, the quadrants
are fixed for all images: top-left quadrant (Q1), top-right quadrant (Q2), bottom right quadrant (Q3), and bottom left
quadrant (Q4). The more ‘spirals’, the more likely a high-quality inspection of the colon. The side of the colon that
is inspected is estimated to be 180 degrees opposite from the view direction of the colon lumen. Fig. 6(a-d) shows a
series of inspection of the quadrants: Q1, Q2, Q4, and Q3. Since endoscopists may have individual inspection
preference, e.g. clockwise or counter-clockwise order, we do not consider the order of these numbers as important.
As long as all four quadrants are inspected, one spiral is counted. Using this definition of ‘spiral’, we define ‘spiral
number’ as the number of spirals performed during a given duration of a procedure. We can automatically measure
‘spiral number’ of a withdrawal phase or ‘spiral number’ of an entire procedure. This spiral number metric provides
an indication of the quality of circumferential inspection.

(a)

(b)

(c)

(d)

Fig. 6 Four sequential images form a ‘spiral’ (a) quadrant Q1 is inspected; (b) quadrant Q2 is inspected; (c) quadrant Q4 is
inspected; (d) quadrant Q3 is inspected; the arrows are generated by our program

Pearson’s correlation is widely used as a measure of the strength of linear dependence between two variables. We
used Pearson’s correlation analysis to explore the correlation between the spiral metric and our previous QCH
metric against the circumferential inspection quality given by the domain experts. To use Pearson’s correlation
analysis, we need to ensure that the required assumptions for the analysis are satisfied. These assumptions are
linearity, normality, independence, and constant variance. Due to limited space, we omit the detailed procedure of
the assumption verification. We used Microsoft Excel Analysis Tools to verify that these assumptions are satisfied
before computing Pearson’s correlation. Pearson's correlation coefficient between two variables is defined as the
covariance of the two variables divided by the product of their standard deviations. Since all the assumptions were

958

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

satisfied, we used Equation (3) to calculate Pearson’s correlation coefficient r where r is between 0 (for no
correlation) and 1 (for the strongest correlation).

¦

r

¦

n
i 1

n
i 1

( X i  X )(Yi  Y )

( X i  X )2

¦

n
i 1

(3)

(Yi  Y ) 2

Given n videos used in the study, Yi is the ground truth score (0-100) of quality of the visualization technique for
video i given by the domain expert. Hence, the score reflects not only the circumferential inspection quality but also
the quality of examination of flexures, rectal valves, and the ileocecal valve. Xi is either the value of the spiral metric
or the value of QCH for video i depending on which metric is being correlated with the ground truth score. X and
Y are the means of Xi and Yi, respectively.
Experimental results
We selected 21 videos with good or excellent colon preparation (i.e. colon wall has been cleaned carefully and
there is little stool inside the colon) rated by four domain experts. The videos also have no biopsy or therapeutic
operations. This is to prevent inclusion of other patterns such as colon cleaning, polyp removal or biopsy from being
measured as circumferential inspection patterns. We first extracted one frame per second from each video. In order
to locate the colon center axis of each frame, we used our previous technique [14] supplemented with the proposed
PCurve technique handling non-dark lumen images. Then, we calculated the new quality metric - spiral number and
our previous metric – QCH score which is the time window (in seconds) where QCH value reaches four (i.e., the
average time the endoscopist inspects one round of four quadrants) [13] for the whole procedure and the withdrawal
phase only. We determined the start of the withdrawal phase for each video using the average maximum intubation
frame provided by the same domain experts.
Fig. 7 presents the plot of the ground truth scores, the spiral numbers and QCH scores for the withdrawal phase
and the whole procedure. The ground truth score is determined as the average of the manual scores given by four
domain experts. Pearson’s correlation coefficients are around 0.68 and 0.72 between the spiral numbers of
withdrawal phase/whole procedure and the ground truth scores, respectively; whereas the coefficients drop to 0.31
and -0.06, respectively when we used QCH scores of withdrawal phase/whole procedure as the X variables. We
consider the coefficients of 0.68 and 0.72 as high. Therefore, we conclude that the number of spirals is a marker of
circumferential inspection quality and that we indeed can use this metric to provide as an estimate of mucosa
inspection quality.

Fig. 7 (a) ground truth scores and spiral number metric; (b) ground truth scores and QCH metric

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000

5. Conclusion and future work
In this paper, we presented a novel technique for determining colon center axis location for non-dark lumen
images. We also proposed a spiral number metric and found that it has a strong correlation with visualization quality
given by four domain experts. Hence, this is a promising metric. Our future work is as follows. First, we will
improve detection accuracy of the colon center axis. Due to colon distortion, the colon center axis is not always
located close to the intersection of the perpendicular bisector lines of the two groups of parallel folds. Therefore, we
will consider assigning different weights to different segments along the parallel folds to improve accuracy. Second,
we are considering a different ground truth scoring system since the current ground truth scores given by
experienced endoscopists cover a few other aspects besides circumferential inspection quality, which may contribute
to a correlation coefficient of around 0.72 only when measuring circumferential inspection quality alone in the
correlation study. Third, we will optimize the technique for real-time feedback of inspection quality to assist the
endoscopist toward optimal quality inspection. The proposed method will be integrated into a computer-aided
quality control system for colonoscopy.

Acknowledgment and Disclosure
This work is partially supported by Agency for Healthcare Research and Quality (AHRQ HS17537), National Institute of Diabetes and Digestive
and Kidney Diseases (NIDDK DK083745), the Mayo Clinic, and Iowa State University Research Foundation. Any opinions, findings,
conclusions, or recommendations expressed in this paper are those of authors. They do not necessarily reflect the views of the funding agencies.
Johnny Wong, Wallapak Tavanapong and JungHwan Oh hold positions at EndoMetric, Corporation, Ames, IA 50014, U.S.A, a for profit
company that markets endoscopy-related software. Johnny Wong, Wallapak Tavanapong, JungHwan Oh, Piet de Groen, and Mayo Clinic own
stocks in EndoMetric. Piet de Groen, Johnny Wong, and Wallapak Tavanapong have received royalty payments from EndoMetric.

References
1. World Health Organization, "Cancer", February 2009, http://www.who.int/mediacentre/factsheets/fs297/en/
2. L.J. Hixson, M.B. Fennerty, R.E. Sampliner, D. McGee, H. Garewal, Prospective study of the frequency and size distribution of polyps
missed by colonoscopy, Journal of the National Cancer Institute, 82 (1990) 1769-72.
3. D.K. Rex, C.S. Cutler, G.T. Lemmel, E.Y. Rahmani, D.W. Clark, D.J. Helper, et al. Colonoscopic miss rates of adenomas determined by
back-to-back colonoscopies, Gastroenterology, 112 (1997) 24-8.
4. P. J. Pickhardt, P.A. Nugent, P.A. Mysliwiec, J.R. Choi, W.R. Schindler, Location of adenomas missed by optical colonoscopy, Annals of
Internal Medicine, 141 (2004) 352-9.
5. P.B. Cotton, V.L. Durkalski, B. C. Pineau, Y.Y. Palesch, P.D. Mauldin, B. Hoffman, et al. Computed tomographic colonoscopy (virtual
colonoscopy): a multicenter comparison with standard colonoscopy for detection of colorectal neoplasia, JAMA, 291 (2004) 1713-9.
6. A. Pabby, R. E. Schoen, J. L. Weissfeld, R. Burt, J. W. Kikendall, P. Lance, et al. Analysis of colorectal cancer occurrence during
surveillance colonoscopy in the dietary prevention trial, Gastrointestinal Endoscopy, 61 (2005) 385-91.
7. D. K. Rex, J. H. Bond, S. Winawer, T. R. Levin, R. W. Burt, D.A. Johnson, et al. Quality in the technical performance of colonoscopy and
the continuous quality improvement process for colonoscopy: recommendations of the U.S. multi-society task force on colorectal cancer,
American Journal Gastroenterol, 97 (2002) 1296-308.
8. D.H. Kim, P.J. Pickhardt, A.J. Taylor, W.K. Leung, T.C. Winter, J.L. Hinshaw, et al. CT colonography versus colonoscopy for the
detection of advanced neoplasia, N Engl J Med, 357 (2007) 1403–12.
9. D.K. Rex and B.W. Goodwine, Method of colonoscopy in 42 consecutive patients presenting after prior incomplete colonoscopy, Am J
Gastroenterol, 97 (2002) 1148–51.
10. D.K. Rex, T.F. Imperiale, D.R. Latinovich, and L.L. Bratcher, Impact of bowel preparation on efficiency and cost of colonoscopy, Am J
Gastroenterol, 97 (2002) 1696–1700.
11. D. K. Rex, J. L. Petrini, T. H. Baron, A. Chak, J. Cohen, S.E. Deal, et al. Quality indicators for colonoscopy, Gastrointestinal Endoscopy,
63 (2006) 16-26.
12. S. Vijan, J. Inadomi, R. A. Hayward, T. P. Hofer, and A. M. Fendrick, Projections of demand and capacity for colonoscopy related to
increasing rates of colorectal cancer screening in the United States, Aliment Pharmacol Ther, 20 (2004) 507-15.

959

960

X. Liu et al. / Procedia Computer Science 1 (2012) 951–960
X. Liu, W. Tavanapong, J. Wong, J. Oh, P. C. de Groen/ Procedia Computer Science 00 (2010) 000–000
13. D. Liu, Y. Cao, W. Tavanapong, J. Wong, J. Oh, and P. C. de Groen, Quadrant Coverage Histogram: A New Method for Measuring
Quality of Colonoscopy Procedures, Proc. of IEEE Engineering in Medicine and Biology Society (EMBC), Lyon, France (2007) 3470-3.
14. D. Liu, Y. Cao, W. Tavanapong, J. Wong, J. Oh, and P. C. de Groen, Mining Colonoscopy Videos to Measure Quality of Colonoscopic
Procedures, Proc. of IASTED Int’l Conf. on Biomedical Engineering, Innsbruck, Austria (2007) 409-14.
15. P.A. Brathwaite, K.B. Chandran, D.D. McPherson, and E.L. Dove, Lumen detection in human IVUS images using region-growing,
Computers in Cardiology (1996) 37-40.
16. G. N. Khan, A highly parallel shade image segmentation method, Proc. of International Conf. on Parallel Processing for Computer Vision
and Display, University of Leeds (1988).
17. S. Kumar, K. Vijayan Asari, and D. Radhakrishnan, A New Technique for the Segmentation of Lumen from Endoscopic Images by
Differential Region Growing, Proc. of 42nd Midwest Symposium on Circuits and Systems, New Mexico (1999).
18. H. Tian, T. Srikanthan, and K. Vijayan Asari, Automatic segmentation algorithm for the extraction of lumen region and boundary from
endoscopic images, Medical and Biological Engineering and Computing, 39 (2001) 8-14.
19. S. Hwang, J. Oh, J. Lee, Y. Cao, W. Tavanapong, D. Liu, et al. Automatic measurement of quality metrics for colonoscopy videos, Proc.
of the 13th annual ACM Int’l Conf. on Multimedia, Hilton, Singapore (2005) 912-21.
20. L. Alexandre, N.N. Nobre, and J. C. Casteleiro, Color and Position versus Texture Features for Endoscopic Polyp Detection, Proc. of Int’l
Conf. on BioMedical Engineering and Informatics, Sanya, China, 1 (2008) 38-42.
21. D.C. Cheng, W.C. Ting, Y.F. Chen, Q. Pu, and X.Y. Jiang, Colorectal Polyps Detection Using Texture Features and Support Vector
Machine, Proc. of Int’l Conf. on Advances in Mass Data Analysis of Images and Signals in Medicine, Biotechnology, Chemistry and Food
Industry (2008) 62-72.
22. D.K. Iakovidis, D.E. Maroulis, and S.A. Karkanis, An Intelligent System for Automatic Detection of Gastrointestinal Adenomas in Video
Endoscopy, Computers in Biology and Medicine, 36 (2006) 1084-103.
23. S. Hwang, J. Oh, W. Tavanapong, J. Wong, and P.C. de Groen, Polyp Detection in Colonoscopy Video Using Elliptical Shape Feature,
Proc. of IEEE Int'l Conf. on Image Processing, San Antonio, Texas (2007) 465-8.
24. J. Oh, S. Hwang, J. Lee, W. Tavanapong, P. C. de Groen, and J. Wong, Informative Frame Classification for Endoscopy Video, Journal of
Medical Image Analysis, 11 (2007) 110-27.

