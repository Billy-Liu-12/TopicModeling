Task Environments for the Dynamic
Development of Behavior
Derek Harter and Robert Kozma
Department of Mathematical Sciences; University of Memphis
Memphis, TN 38152 USA
{dharter, rkozma}@memphis.edu
http://www.psyc.memphis.edu/{∼harterd, ∼kozmar}

Abstract. The development of complex, adaptive behavior in biological
organisms represents vast improvement over current methods of learning for artiﬁcial autonomous systems. Dynamical and embodied models of cognition [1–13] are beginning to provide new insights into how
the chaotic, non-linear dynamics of heterogeneous neural structures may
self-organize in order to develop eﬀective patterns of behavior. We are
interested in creating models of ontogenetic development that capture
some of the ﬂexibility and power of biological systems. In this paper we
present a testbed for the creation and testing of models of development.
We present some results on standard neural networks in learning to perform this task and discuss future plans for developmental models in this
environment.

1
1.1

Introduction
Development and Non-linear Dynamics

The development of behavior in biological organisms is primarily a self-organizing phenomenon. Organisms are born with a basic repertoire of motor skills
and instinctive needs. These are often tied to simple action-loops [1], which provide a basic repertoire of simple pattern completion and instinctive behaviors
that can begin to satisfy the intrinsic drives of the organism. As the organism
develops both physically and behaviorally, however, these instinctive behavior
patterns begin to be associated with more general sensory stimuli. The organism
learns to recognize patterns in the environment that are important and useful
aﬀordances for beneﬁcial behaviors [14]. Increasingly complex patterns of behavior are organized around the solutions that are discovered at earlier stages
of development.
Thelen and Smith [13,15] view development as a shifting ontogenetic landscape of attractor basins. As physical and behavioral patterns develop the landscape is continually reformed and reshaped. Each developed behavior opens up
many possibilities for new more complex patterns of behavior, while closing oﬀ
possibilities for others. Even relatively simple tasks can provide opportunities
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2074, pp. 300–309, 2001.
c Springer-Verlag Berlin Heidelberg 2001
�

Task Environments for the Dynamic Development of Behavior

301

for the development of increasingly complex strategies in order to improve performance. For example in the simple task we present in the next section, humans
develop higher level strategies for improving their performance.
Many theories of the development of behavior in biological organisms are
beginning to view it in terms of a self-organizing dynamical system [13,9,8]. The
organization of patterns of behavior is viewed, in some sense, as the formation
and evolution of attractor landscapes. Some research [12,5,4,6,7,10] also indicates
that chaotic dynamics may play an essential part in the formation of perception
and behavior in biological organisms.
1.2

Category Formation through Aperiodic Chaotic Dynamics

Following experimental evidence and theoretical modeling [5,10], categories are
associated with localized wings of a complex, high-dimensional chaotic attractor.
The attractor landscape is formed in a ﬂexible way reﬂecting past experiences
and continuously modiﬁed based on the actual information the system receives
from the environment.
The system typically resides in a high-dimensional basal state. It can be
kicked-oﬀ from this state in response to external factors or internal developments. As the result, the state of the system is switched to a low-dimensional
wing, which might represent a previously learnt memory pattern or an elementary action. The system might reside in this wing or it may visit sequentially
various wings, thus representing a possible behavioral pattern. In either case,
the system moves back to the basal state upon completing the sensory inputinduced identiﬁcation task or performing the desired action. The advantage of
such a dynamical approach is the ﬂexibility and robustness of the selection of the
behavior and action as it is seen in biological systems. We attempt to implement
this dynamical strategy to solve action selection tasks as outlined in this work.
1.3

Task Environments for Testing Models of Development

Biological organisms are capable of marvelously complex patterns of behavior in
pursuit of the satisfaction of their endogenous drives. However, it is not always
apparent how much of the complexity of their behavior is internally generated,
and how much emerges from the interaction of simple response patterns within a
complex task environment. It seems doubtful that true progress in understanding the properties of intelligent behavior can be made by studying disembodied,
syntactic systems [16,17,1,8,18]. Intelligent behavior, at least in biological organisms, seems built upon a foundation of fast and robust pattern recognition
and completion, both of static and temporally extended, often vague and noisy
patterns. This observation is suggestive of several features that may be necessary
in the developmental processes of biological organisms.
Of course it is desirable to develop models of behavior in realistic and complex environments, but it is not always possible. The question then becomes:
what are the features of real world environments that are necessary for the development of complex behavior in biological organisms. Can we begin to study

302

D. Harter and R. Kozma

the phenomenon of the dynamic development of behavior in such a way that our
results are valid in more realistic, complex environments. The following are a few
features of environments that seem critical in creating models of the development
of behavior.
Real Time Constraints Invariably biological organisms face critical time pressures that constrain their behavior. It is not simply a matter of doing the right
thing, biological organisms must do the right thing and do it in a timely manner.
It is better to do something, even something not optimal, on time, than to be
too late and become someone else’s dinner.
Developmental processes occur within the real time interactions of the organism with the environment. A testbed for developmental processes should be able
to support tasks with real time constraints on the behavior of the developing
system. However, in order to begin creating models it is desirable to loosen the
restrictions of real time constraints. Therefore the testbed should have conﬁgurations with and without real time constraints on behavior. The task should
be similar enough in both conﬁgurations so that mechanisms developed without
constraints can eventually be tried in the more demanding situation of tasks
with real time constraints.
Multiple Sensory Modalities The task environment should support the simulation of multiple sensory modalities, so that associations can be formed between
purely reactive (intrinsic) behaviors, and more complex senses and behavior. This
type of learned association between events in disparate sensory modalities seems
to be crucial to many types of category formation and learned behavior. For example, in classical conditioned learning, the co-occurrence of an auditory stimuli
(bell) with onset of reward results in a conditioned response being developed
[19,20,21,22].
Exploitable Environmental Regularities Even though an environment is
complex, it still must posses statistically signiﬁcant, exploitable regularities in
order to be a viable, survivable niche. Such regularities may co-occur in spatial
location and time, or be more spatially or temporally extended. A major part of
developmental processes is discovering such regularities and learning to exploit
them.

2

Packing Task

Towards the end of studying and creating models of development, we have begun
work on creating appropriate tasks with the previous properties. We describe a
packing task here which is one such environment, and some work on standard
machine learning tools in this environment.

Task Environments for the Dynamic Development of Behavior

2.1

303

Description

In the packing task, the behaving system is presented with a series of shapes,
one shape at a time. In this packing task, which is a simpliﬁed form of the Tetris
game [23], the system can be presented with one of 3 shapes as shown in ﬁgure
1. The goal of the task is to move and rotate a shape before allowing it to drop
onto a playing ﬁeld in such a way as to end up with as compact of a packing as
possible. An example of a packing trial in progress can be found in ﬁgure 2.

0

1

2

Fig. 1. The shapes used in the packing task.

Fig. 2. An example packing task trial. Shapes enter from the top and must be positioned and rotated before they are dropped. Performance is evaluated by the height
and the density of the packing of the shapes.

The behaving system does not know in advance what sequence of shapes it
will be given. In our version of the packing task, the system is given random
sequences of 10 shapes. The performance of the system on the packing task is
evaluated by examining the density of their packing and by examining the total
height of the resulting packing.
The system can produce two types of behavior. It must specify where to
position (or move) the shape in the playing ﬁeld, and how to rotate the shape.
Once the system has speciﬁed the position and rotation of the shape, it is allowed
to fall down onto the playing ﬁeld. The shape settles into place and the next
shape is presented to the behaving system to be positioned and rotated.

304

2.2

D. Harter and R. Kozma

Encoding

We now present an example of a standard neural network that learns to perform
the simple packing task. The neural network needs to be given some sense of
the current state of the environment. For the experiments performed here, two
pieces of input were given to the network: the type of shape that has appeared,
and a perception of the contours of the current playing ﬁeld.
The encoding of the type of shape is relatively simple. In the packing task
environment there are 3 diﬀerent shape types. We used 2 bits to encode the type
of shape. The shapes in ﬁgure 1 were given numbers (from left to right) of 0, 1
and 2 and were encoded as 00, 01 and 10 respectively.
The perception of the state of the playing ﬁeld (the environment) is necessary
in order to produce good behavior on where and how to position the shape before
dropping it. In our reduced packing task, the playing ﬁeld consisted of 5 columns.
We sensed the height of each column currently in the environment, and encoded
this for training and testing the networks. The lowest point in the playing ﬁeld
is used as a baseline and is encoded as having a height of 0. All other heights
are calculated from the baseline depth. We used 2 bits to encode the height of
each column, and simply ignored perception of columns that were greater than
3 units above the baseline.
For example in ﬁgure 2, the leftmost column has the lowest depth in the
playing ﬁeld, and would be encoded with height 0. The next column to the right
has a height 2 units above the baseline. So from left to right, the height of the
columns in ﬁgure 2 would be encoded as 0, 2, 1, 2, 2. The type of shape shown
in ﬁgure 2 about to be dropped is shape number 1. As stated before we used 2
bits to encode the shape type, and 2 bits for each of the column heights, for a
total of 12 bits of input. The situation shown in ﬁgure 2 would be encoded as:
Type Col1 Col2 Col3 Col4 Col5
0 1 0 0 1 0 0 1 1 0 1 0
For the output of the system we developed the following encoding. We encoded the position to place the shape from the left edge in 3 bits. We need to be
able to specify up to 5 units of displacement, thus we needed 3 bits to encode
the 5 possibilities. The shapes can be rotated in increments of 90 degrees. Shape
2 (the L shape) can be rotated into 4 diﬀerent distinct orientations. Therefore
we also needed 2 bits to encode all possible speciﬁcations of rotation.
2.3

Training

We trained standard backpropogation networks using the encoding described
above. For training data we had a human perform 50 packing trials, and we
captured and encoded the input and the output of the behavior that the human
produced when performing the packing task. We also captured a similar set
of data for testing. We trained and tested the networks with many diﬀerent
conﬁgurations of number of hidden nodes and epochs trained. We then chose

Task Environments for the Dynamic Development of Behavior

305

the best conﬁgurations in order to evaluate the performance of the networks on
the packing task as discussed in the next section. The neural network performed
best with 50 hidden nodes.
2.4

Experiments

We then used our packing task testbed in order to evaluate the performance
of the networks on simulated packing trials. We gave the networks 100 random
trials and measured their performance by calculating the packing density and
height that they achieved. Packing height is simply a measure of the highest
column of blocks in the playing ﬁeld. Packing density is measured by looking
at the ratio of the number of ﬁlled spaces in the packing to the total area of
the packing. In ﬁgure 2 the packing has a height of 4 and a density of 17 / 20
or 0.85. The lower the height of the packing is the better the performance and
similarly the denser the packing is the better the performance.
2.5

Results

A human learned the packing task and was asked to perform the task for 100
trials. Similarly the resulting neural networks were run on 100 trials of the packing task. Table 1 shows a comparison of the average performance on the 100
trials of the neural network and the human. Figure 3 shows a histogram of the
performance of the human and the neural network rated by height and density.
Table 1. Comparison of average height and density performance measures on 100
simulated packing tasks
Height Density
Human
7.62
Neural Network 8.18

0.8748
0.8261

Basic neural networks perform adequately on the packing task, but obviously
are not quite as good at packing as humans, even for this simpliﬁed task domain.
Humans, when performing this task, alter their strategies as the task progresses.
Early on in a packing trial, a human is willing to leave open opportunities for
particular shapes. People know intuitively that, even though they see shape types
at random, they are likely to see the particular shape type needed if it is still
early in the trial. However, as the trial progresses, strategies shift to those that
will simply minimize the height of their packing.
This shift in strategies causes confusion for simple backpropogation networks.
They see this as conﬂicting output patterns for the same input. Strategies that
would possibly correct this deﬁciency for basic neural networks and other solutions will be discussed in the next section.

306

D. Harter and R. Kozma

2.6

Discussion of Development in the Packing Task

The development of diﬀering strategies given the context of the problem is a
prime example of the development of skills in biological organisms. People are
not given explicit examples of appropriate shifts in strategies. They develop such
strategies by interacting with the task environment, and guided by their previous experience with the constraints of the problem. They seem to quickly and
intuitively embody the opportunities that situations aﬀord for good behaviors,
and how such opportunities change with the changing situation. In other words,
they develop a set of skills and strategies for improving their performance on the
problem simply through interaction and experience in the task domain.

55

35

50
30
45
40

25

35
20

30
25

15

20
10

15
10

5
5

A

0

6

7

8

9

10

11

12

13

14

15

16

55

B

0
0.4

0.5

0.6

0.7

0.8

0.9

1

0.5

0.6

0.7

0.8

0.9

1

35

50
30
45
40

25

35
20

30
25

15

20
10

15
10

5
5

C

0

6

7

8

9

10

11

12

13

14

15

16

D

0
0.4

Fig. 3. Histograms of performance on 100 trials of the packing task. The top two ﬁgures
(A and B) show the performance of a human subject in the packing task, while the
bottom two (C and D) display the performance of a neural network. In the left column
we are measuring performance by the height of the packing. On the right we show
performance by the density of the packing.

Even in our simple environment we see that people develop diﬀering strategies for behavior based on the context of the progress of the trial. For example,

Task Environments for the Dynamic Development of Behavior

307

humans ﬁrst learn a basic set of good contours and correspondance with diﬀerent
shape types that provide for eﬃcient packings. From this basic set of behavior,
they begin to develop preferences for patterns that keep open future opportunities. For example, some contours will naturally accommodate more than one
shape type, and are preferred over other patterns that limit good packing to a
single shape type. Even further, people begin to develop higher level strategies
at this point. For example, if it is early in the trial they wait for more optimal
packings, but later on they simply try and minimize the height. The challenge
in creating models of development is in capturing this ability to, not only softly
assemble solutions through a repertoire of learned and innate skills, but to also
develop new skill and eﬀective higher level strategies for the problem domain.

3

Future Directions

The basic neural networks presented here are not quite capable of human level
performance in the packing task. The primary reason for this deﬁciency is an inability to perceive the changes in circumstances that cause a shift in the behavior
of the human trainers. We have no doubt that adding on more contextual input
(such as the current height of the packing, or a count of the number of shapes
packed so far) would improve the performance of the basic network, though it
remains to be seen if it could equal human performance. Also, other methods
such as recurrent, dynamical neural networks, or genetic algorithm optimizations, should be capable of bringing standard methods of machine learning up
to human level performance on this simple task.
The point is not to equal human performance in this simpliﬁed domain,
but to begin to create models that can develop behavior on their own in a
cognitively plausible manner, and that display some of the ﬂexibility of biological
development. Most standard methods of machine learning should be able to
competently handle the packing task environment in its simpliﬁed form but
inevitably will break down as we add complexity and real time constraints to
the task.
KIII is a dynamical memory device, which has been used successfully to
solve diﬃcult classiﬁcation problems in vague, and noisy environments [10]. The
KIII model incorporates several KII sets, which can be interpreted as units
generating limit cycle oscillations in an autonomous regime. High-dimensional
aperiodic and chaotic behavior does not emerge until the complete KIII system is
formed. KIII has a multi-layer architecture with excitatory and inhibitory lateral,
feed-forward, and feedback connections. KIII models can grasp the essence of
the observed dynamic behavior in certain biological neural networks. It seems
feasible to build a simpliﬁed version of KIII for the action selection task addressed
in this work. We call it 3*KII model, as it consists of 3 mutually interconnected
KII sets. Each KII set has a well-deﬁned oscillation frequency. The complete
3*KII model, however, may exhibit high-dimensional, aperiodic oscillations as
the result of competing, incommensurate frequencies of the KII components.

308

D. Harter and R. Kozma

The advantage of 3*KII is that it allows a self-organized encoding of behavioral patterns into localized wings of a high-dimensional attractor. Therefore, we
can obtain ﬂexible and noise-resistant transitions among the states of the system, self-organized into a sequence of elementary actions of phase transitions.
It is expected that deﬁning a more challenging packing task with larger number
and more complicated block patterns and also larger play ﬁeld the application
of dynamical encoding and action selection mechanism as 3*KII would prove
to be beneﬁcial. Also the emergence of self-organized action patterns would be
imminent and complex behavioral patterns could be studied.

4

Conclusion

The development of behavior, even in a simpliﬁed environment such as the packing task, can shed light on the mechanisms of biological development and learning. Biological organisms are able to eﬀectively develop increasingly complex
skills and strategies simply by interacting with and solving problems in their environment. The dynamic, self-organization of behavior in biological organisms is
a powerful model of learning that, if better understood, would provide great opportunities for improved artiﬁcial behaving and learning systems. Development
of behavior in biological organisms can be viewed as a self-organizing dynamical system. Some research also indicates the importance of chaotic modes of
organization in the development of behavior. We can begin to study models of
development even in simpliﬁed ways as long as we are aware of the essential
properties of the environments that are exploited by biological organisms during
developmental process. Some of these properties include critical real time constraints, a rich sensory modality and environmental regularities and exploitable
features.

References
1. Andy Clark. Being There: Putting Brain, Body, and World Together Again. The
MIT Press, Cambridge, MA, 1997.
2. Gerald M. Edelman and Giulio Tononi. A Universe of Consciousness: How Matter
Becomes Imagination. Basic Books, New York, NY, 2000.
3. Stanley P. Franklin. Artiﬁcial Minds. The MIT Press, Cambridge, MA, 1995.
4. Walter J. Freeman. Consciousness, intentionality and causality. In Núñez and
Freeman [24], pages 143–172.
5. Walter J. Freeman. How Brains Make Up Their Minds. Weidenfeld & Nicolson,
London, 1999.
6. Walter J. Freeman and Robert Kozma. Local-global interactions and the role of
mesoscopic (intermediate-range) elements in brain dynamics. Behavioral and Brain
Sciences, 23(3):401, 2000.
7. Walter J. Freeman, Robert Kozma, and Paul J. Werbos. Biocomplexity: Adaptive
behavior in complex stochastic dynamical systems. BioSystems, 2000.
8. Horst Hendriks-Jansen. Catching Ourselves in the Act: Situated Activity, Interactive Emergence, Evolution and Human Thought. The MIT Press, Cambridge, MA,
1996.

Task Environments for the Dynamic Development of Behavior

309

9. J. A. Scott Kelso. Dynamic Patterns: The Self-organization of Brain and Behavior.
The MIT Press, Cambridge, MA, 1995.
10. Robert Kozma and Walter J. Freeman. Chaotic resonance - methods and applications for robust classiﬁcation of noisy and variable patterns. International Journal
of Bifurcation and Chaos, 11(6), 2001.
11. Robert F. Port and Timothy van Gelder, editors. Mind as Motion: Explorations
in the Dynamics of Cognition. The MIT Press, Cambridge, MA, 1995.
12. Christine A. Skarda and Walter J. Freeman. How brains make chaos in order to
make sense of the world. Behavioral and Brain Sciences, 10:161–195, 1987.
13. Esther Thelen and Linda B. Smith. A Dynamic Systems Approach to the Development of Cognition and Action. The MIT Press, Cambridge, MA, 1994.
14. J. J. Gibson. The Ecological Approach to Visual Perception. Houghton Miﬄin,
1979.
15. Esther Thelen. Time-scale dynamics and the development of an embodied cognition. In Port and van Gelder [11], chapter 3, pages 69–100.
16. Rodney A. Brooks. Elephants don’t play chess. Robotics and Autonomous Systems,
6:3–15, 1990.
17. Rodney A. Brooks. A robot that walks: Emergent behaviors from a carefully
evolved network. In Randall Beer, R. Ritzmann, and T. McKenna, editors, Biological Neural Networks in Invertebrate Neuroethology and Robotics. Academic Press,
1993.
18. Rolf Pfeifer and C. Scheier. Understanding Intelligence. The MIT Press, Cambridge, MA, 1998.
19. Paul F. M. J. Verschure, B. Kröse, and Rolf Pfeifer. Distributed adaptive control:
The self-organization of behavior. Robotics and Autonomous Systems, 9:181–196,
1992.
20. Paul F. M. J. Verschure, J. Wray, Olaf Sporns, Giulio Tononi, and Gerald M.
Edelman. Multilevel analysis of classical conditioning in a behaving real world
artifact. Robotics and Autonomous Systems, 16:247–265, 1995.
21. Paul F. M. J. Verschure. Distributed adaptive control: Explorations in robotics
and the biology of learning. Informatik/Informatique, 1:25–29, 1998.
22. I. P. Pavlov. Conditioned Reﬂexes. Oxford University Press Press, Oxford, 1927.
23. David Kirsh and Paul Maglio. Reaction and reﬂection in tetris. In J. Hendler,
editor, Artiﬁcial Intelligence Planning Systems: Proceedings of the First Annual
International Conference (AIPS92), Morgan Kaufman, San Mateo, CA, 1992.
24. Rafael Núñez and Walter J. Freeman, editors. Reclaiming Cognition: The Primacy
of Action, Intention and Emotion. Imprint Academic, Bowling Green, OH, 1999.

