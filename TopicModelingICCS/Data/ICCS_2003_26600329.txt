Data Driven Design Optimization Methodology
A Dynamic Data Driven Application System
Doyle Knight
Dept of Mechanical and Aerospace Engineering
Rutgers - The State University of New Jersey
New Brunswick, NJ 08903
knight@soemail.rutgers.edu

Abstract. Engineering design optimization using concurrent integrated
experiment and simulation is a Dynamic Data Driven Application System (DDDAS) wherein remote experiment and simulation can be synergistically utilized in real-time to achieve better designs in less time
than conventional methods. The paper describes the Data Driven Design
Optimization Methodology (DDDOM) being developed for engineering
design optimization.

1

Introduction

A Dynamic Data Driven Application System (DDDAS) is an application software system capable of accepting and effectively utilizing remote data in real
time (i.e., during the execution of the application software). Many software systems currently utilize static input data, i.e., input data which is specified a
priori . The key concept of DDDAS is the generalization of application software
systems to dynamically utilize real-time data arising from remote experiment and
simulation, and to control such remote experiment and simulation to improve
the performance of the application software system. The concept is illustrated
schematically in Fig. 1.
Dynamic Data Driven Application Systems have become a major subject
of research interest due to the continuing rapid advances in technology. These
include, for example, improvements in computer processor performance (i.e.,
doubling every 18 to 24 months (Berkowitz 1996)), network bandwidth, Rapid
Prototyping (RP) and real-time data acquisition and control (e.g., using MicroElectro Mechanical Systems (MEMS)). These rapid technological advances provide the means to revolutionize the use of existing and future application software systems. For example, the NSF TeraGrid1 is a multi-year effort to deploy
20 TFlops of computing capacity at five sites connected through a 40 Gbps network. The TeraGrid will offer unprecedented remot computing capability which
can be utilized in real-time by application software systems executing at users’
sites. The incorporation of the NSF Teragrid into an application software system
is therefore an example of a Dynamic Data Driven Application System.
1

http://www.ncsa.uiuc.edu/About/TeraGrid/

P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 329−336, 2003.
 Springer-Verlag Berlin Heidelberg 2003

330

D. Knight
Remote

✲

❄

Simulation

(e.g., NSF TeraGrid)

Application
System

✻

✲ Experiment

✛ Remote real-time data to Application System
✲ Control by Application System
Fig. 1. Use of remote experiment and simulation in application software

The objective of this paper is to present a Dynamic Data Driven Application System for engineering design optimization. In the following sections, we
describe the general engineering design optimization problem, the conventional
approach to engineering design optimization, our Dynamic Data Driven Application System for engineering design optimization, and a demonstration example.

2

Design Optimization

The general engineering design optimization problem is defined as
minimize fj (x)

for j = 1, m

(1)

subject to
dk ≤ 0
where

for k = 1, l

f = (f1 , . . . , fm )t

(2)
(3)

is the vector of objective functions and
d = (d1 , . . . , dl )t

(4)

x = (x1 , . . . , xn )t

(5)

is the vector of constraints and

is the vector of design variables. The solution to the general engineering design
problem is the set of non-dominated designs known as the Pareto Set (Deb 2001).
Within this set of designs, improvement in one design criterion fj can only be
achieved at the expense of the degradation in the performance of one or more
other design criteria.

Data Driven Design Optimization Methodology

3

331

Conventional Engineering Design Optimization

Engineering design is a potential Dynamic Data Driven Application System
wherein remote real-time input from high performance computing resources
(e.g., NSF Teragrid) and experiment (e.g., using capability for rapid fabrication of new experimental configurations) can produce a better design in shorter
time with lower cost than the conventional approach. Fig. 2 illustrates the conventional approach to engineering design. An initial design is typically evaluated
using simulation software executing on local computer resources. An example is
Computational Fluid Dynamics (CFD) simulation using one of the several available commercial CFD software packages ( e.g., fluent, gasp, star-cd). The
results of the simulation are reviewed by the designer and additional simulations
performed as needed. An experiment is then planned and executed, and the results compared with the simulation. The process is iterated until a satisfactory
design has been achieved. A major limitation of the conventional approach is
the absence of synergistic real-time use of remot experimental data and high
performance computer resources (e.g., the NSF TeraGrid).

(Re)Design

✻
✻

✲ Simulation

 ❅
✲ OK?❅ Yes✲ Experiment
❅
 
❅ 
No

 ❅
✲ OK?❅ Done
✲
❅
 
❅ 
No

Fig. 2. Conventional approach to engineering design

4

Data Driven Design Optimization Methodology

We are developing an integrated software system, denoted Data Driven Design
Optimization Methodology (DDDOM), to synergistically incorporate remote experiment and simulation into an automated design optimization methodology.
The DDDOM is comprised of six elements as illustrated in Fig. 3 and are summarized below.
Controller The DDDOM Controller provides direction and control of the
design optimization process. It is written in Perl (Wall et al 2000), a powerful
systems programming language which enables robust program control on local
and remote systems. The Controller utilizes the Globus software system (Foster
and Kesselman 1997) to link to the NSF TeraGrid.
User Interface The User Interface provides for the initiation and monitoring of the design optimization. It also provides visualization of the intermediate
results of the design optimization process. The interface is written in Perl/Tk
(Lidie and Walsh 2002). Both Perl and Perl/Tk operate on virtually every platform and operating system.

332

D. Knight
External

Simulation

Experiment

(e.g., NSF TeraGrid)

x

✻

f, σ

❄
User Interface

✛

x

❄
DDDOM
Controller

✲

✻

control

x, f , σ

❄
Optimizer
(e.g., GA)

✻

f, σ

x

✛

control

✞
x, f , σ ✝
✲

archive

✞
✝

x, f , σ

☎
✆
☎
✆

❄
❄
✲ Surrogate Model

x, f , σ

(e.g., RBF ANN)

Fig. 3. Data Driven Design Optimization Methodology

Optimizer A Multi-Criteria Design Optimization (MDO) algorithm is used to
search the design space to define the Pareto Set. Both local (i.e., gradient-based)
and global (i.e., stochastic-based) algorithms are used. Examples are CFSQP
(Lawrence et al 1994) and GADO (Rasheed and Hirsh 1999), respectively.
Surrogate Model Surrogate Models of the objective functions f are developed during the design optimization using experiment and simulation. These
models are utilized by the optimizer to search the design space for the Pareto
Set. We utilize Response Surfaces (Myers and Montgomery 1995) and Radial
Basis Function Artificial Neural Networks (Hertz et al 1991). The Surrogate
Model incorporates the measure of uncertainty σ in the results generated by the
experiment and simulation.
Experiment Experiments are performed in real-time with the conditions of
the experiment defined by the Controller. The interface with experiments is
typically National Instruments LabView (Travis 2002). Rapid Prototyping is
used to build new models as needed with minimal delay (e.g., one day).
Simulation Simulations can be performed locally (i.e., at the same site as the
DDDOM is operated) or remotely (e.g., on the NSF TeraGrid). The simulations
are performed in real-time with the conditions of the simulation defined by the
Controller.

5

Example

A five minute demonstration has been developed to illustrate the principle of
operation of the DDDOM. The limited duration of the demonstration precludes

Data Driven Design Optimization Methodology

333

the actual use of RP which typically requires several hours for fabrication of the
prototype for experiment. Therefore, we have selected a single experimental configuration. Nonetheless, the experiment provides data to the DDDOM Controller
in real time, and the Controller directs the experiment, thereby illustrating the
DDDOM concept.
The specific problem is defined as follows. Consider the flow of air in a
converging-diverging nozzle attached to a stagnation chamber as illustrated in
Fig. 4. The nozzle is designed to achieve Mach 2 at the exit assuming isentropic
expansion throughout the nozzle. Depending upon the ratio of stagnation pressure pt∞ to ambient pressure pa , the flow in the diverging section of the nozzle
can be 1) subsonic everywhere, 2) supersonic and subsonic with a normal shock
at some location in the diverging section, and 3) supersonic everywhere (Anderson 2003). In the latter case, the theoretical exit Mach number is two. A
one-dimensional simulation based upon inviscid gas dynamics (Liepmann and
Roshko 1957) indicates that the exit pressure ratio pe vs stagnation pressure
p t∞ behaves as shown by the curve denoted Simulation in Fig. 5. This behavior
is idealized, however, due to the neglect of the viscous boundary layer on the
nozzle walls and the effect of the interaction of the normal shock wave (if it
exists) with the boundary layers. Consequently, the actual exit pressure pe vs
stagnation pressure pt∞ curve differs substantially from the idealized shape.

Air
Supply

Valve

❦

pt∞

✥
✥✥✥
✥✥✥
✚
✛
❵ ❵❵
❵❵❵
❵

Flow
✲
pe

pa

Fig. 4. Experimental configuration

The objective of the optimization is to determine the stagnation pressure
pt∞ which yields the minimum exit pressure pe for a fixed ambient pressure pa .
Although this is a single design objective problem, it illustrates the fundamental
concepts of DDDOM. Due to the physical assumptions inherent in the simulation
code, the pe vs pt∞ function obtained from the simulation can be significantly
in error. This is an intentional choice to force the DDDOM Controller to build
and refine the Surrogate Model utilizing both simulation and experimental data
to determine the optimum value of pt∞ (i.e., the value of pt∞ which yields the
minimum value of pe ). The dynamic updating of the Surrogate Model using real
time experimental data is an example of a Dynamic Data Driven Application
System.

334

D. Knight

✻
20
15

. ...........
.......
.....
.....
....
....
.
....
....
....
......
...
.......
.......
...
.
.
.
.
.
.
..
..
........
...
.......
...
.......
...
.......
...
.......
.
.
.
...
.
.
.
.
...
.......
....
........
....
..........
......
............
..................
.........
... ............................

✘
✘✘✘
✘
✘
✘✘
✘✘✘
✘
✘
■
❅
❅ Surrogate Model (final)
✘✘

pe (psia) 10

Simulation ✒

5

✲

0
0

10

20

30

40

50

60

70

80

pt∞ (psia)
Fig. 5. Exit pressure pe vs stagnation pressure pt∞

The experiment is located in a laboratory in the Department of Mechanical
and Aerospace Engineering at Rutgers University and controlled by a workstation running Windows 98. The DDDOM is executed on a separate workstation
in another building running Linux. The DDDOM and experiment workstation
communicate via high speed Ethernet. A National Instruments LabView Virtual
Instrument (VI) program (Travis 2002) executes on a workstation adjacent to
the experiment. The VI continually monitors an input file on the workstation
which contains a specified value of stagnation pressure pt∞ and adjusts the stagnation pressure by means of a servo-controlled valve to the specified value. The
VI thereafter writes the measured values of the stagnation pressure pt∞ (which
differs from the specified pt∞ due to ”play” in the valve) and exit pressure pe on
a file on the workstation.
The DDDOM Controller (Fig. 3) manages the optimization problem by the
following sequence:
1. The Surrogate Model is initialized using the one-dimensional inviscid simulation code.
2. The optimizer (a Genetic Algorithm) determines the minimum of the pt∞ vs
pe curve using the current Surrogate Model.
3. A value of pt∞ is chosen for the experiment. In the early stages of the optimization, the value determined in step no. 2 is chosen with a probability of
0.5; otherwise, a random value is chosen within the overall range of experimentally possible values of pt∞ (i.e., 15 psi to 60 psi). This procedure avoids
premature convergence to an exit pressure which is not the actual minimum.
4. A file is transferred to the workstation containing an identification number
and the prescribed value of pt∞ .
5. The VI on the workstation reads the file, changes the experimental total
pressure to the specified value within experimental tolerances, and writes

Data Driven Design Optimization Methodology

335

the identification number, the actual experimental total pressure pt∞ and
exit pressure pe to the file.
6. The DDDOM Controller accesses the file and reads the experimental values
of pt∞ and pe . The database for the Surrogate Model is updated using this
data and the nearest value to pt∞ in the database which was generated by
the one-dimensional simulation code is removed.
7. The convergence of the Surrogate Model is checked. If it is not converged,
the procedure is repeated beginning at step no. 2.

6

Conclusions

Engineering design is an example of a Dynamic Data Driven Application System
wherein real-time data from experiment and simulation can be effectively utilized
to yield better designs in shorter time. A Data Driven Design Optimization
Methodology (DDDOM) is being developed which incorporates experiment and
simulation in a real-time, synergistic manner. The theory and organization of
DDDOM is described. An example demonstration is described.

Acknowledgments.
The research is sponsored by the US National Science Foundation under grant
CTS-0121058. The program managers are Drs. Frederica Darema, C. F. Chen
and Michael Plesniak. The assistance of Profs. Greg Elliott and Madara Ogot in
development and implementation of the supersonic nozzle experiment is gratefully acknowledged.

References
Anderson, J. Modern Compressible Flow with Historical Perspective. McGraw Hill
(2003), New York.
Berkowitz, B. Information Age Intelligence. Foreign Policy 103 (1996) 35–50.
Deb, K. Multi-Objective Optimization using Evolutionary Algorithms. John Wiley &
Sons (2001), New York.
Foster, I. and Kesselman, C. Globus: A Metacomputing Infrastructure Toolkit. International Journal of Supercomputer Applications 11 (2) (1997) 115–128.
Hertz, J., Krogh, A., and Palmer, R. Introduction to the Theory of Neural Computation. Lecture Notes Vol I, Santa Fe Institute Studies in the Sciences of Complexity.
Perseus Publishing (1991), Cambridge, MA.
Knight, D., Elliott, G., Jaluria, Y., Langrana, N., and Rasheed, K. Automated Optimal Design Using Concurrent Integrated Experiment and Simulation. AIAA Paper
No. 2002-5636, AIAA/ISSMO Symposium on Multidisciplinary Analysis and Optimization, Atlanta, GA (2002).
Lawrence, C., Zhou, J., and Tits, J. User’s Guide for CFSQP Version 2.1. University
of Maryland, Electrical Engineering Dept & Institute for Systems Research (1994).
Lidie, S., and Walsh, N. Mastering Perl/Tk. O’Reilly and Associates (2002), Sebastopol,
CA.

336

D. Knight

Liepmann, H., and Roshko, A. Elements of Gas Dynamics. John Wiley & Sons (1957),
New York.
Myers, R., and Montgomery, D. Response Surface Methodology - Process and Product
Optimization Using Design Experiments. John Wiley & Sons (1995), New York.
Rasheed, K., and Hirsh, H. Learning to be Selective in Genetic-Algorithm-Based Design
Optimization. Artificial Intelligence in Engineering, Design, Analysis and Manufacturing 13 (1999) 157–169.
Travis, J. LabVIEW for Everyone. Prentice Hall (2002), Upper Saddle River, NJ.
Wall, L., Christiansen, T., and Orwant, J. Programming Perl. O’Reilly and Associates
(2000), Sebastopol, CA.

