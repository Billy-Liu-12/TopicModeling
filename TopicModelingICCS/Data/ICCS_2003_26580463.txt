Estimates Conformity Principle in the Problems of
Identification
Vladimir Fursov
Image Processing Systems Institute, the Russian Academy of Sciences,
443001, Molodogvardeiskay, 151, Samara, Russia,
fursov@smr.ru

Abstract. A non-traditional approach to solving the identification problems
using a small number of observations is developed. The approach is formulated
as an estimate conformity principle. The problem of identifying a linear
dynamic model is treated within this approach. A significant feature of the
above method is the use of a quality criterion not requiring the knowledge of a
priori probability noise distributions. The method is well suitable for real-time
object identification in adaptive control systems.

1 Introduction
In control systems, the improvement of the system quality is, as a rule, achieved via
the adaptation to the varying conditions of operation. The requirement that an
adaptive system should have fast response to the changing environment makes us, if
possible, use simple linear models and a small number of observations. Because of
this, a number of estimation problems solved with the aim of the aircraft adaptation
reduce to the following problem. One should find an estimate c$ of the vector of
parameter c, using the N¬ôM - matrix X and the N¬ô1 - vector y (N>M) accessible from
the direct observation or generated in one way or another, the matrix and the vector
being related via the equation of linear regression

Xc = y + ,

(1)

where is the N¬ô1 - vector of the ‚Äúoutput‚Äù errors caused by the measurement errors
and by the limitation imposed on the order of the model. In particular, a nonstationary
linear discrete system with one input u(k) and one output y(k) is described by the
equation [1]:

x k +1 =

k

xk + dk uk ,

yk = h T x k + ŒΩ k ,

(2)
(3)

x k is the n-dimensional vector of state, k is the n¬ôn - matrix of transient
state, d k and h are n¬ô1 - vectors, and ŒΩ k is the random noise of measurements.
where

P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2658, pp. 463‚Äì470, 2003.
¬© Springer-Verlag Berlin Heidelberg 2003

464

V. Fursov

We assume that the time of formation of the observation records for identification
is small, so that the parameters
k and d k can be considered as being constant. In
that case, for each row of the system (2) after N observations we can put down Eq. (1)
in which the M¬ô1 - vector of estimated parameters will include n elements of the
corresponding row of the F matrix and one element of the d vector, i.e. M=n+1.
Solving Eq. (1) n times we can construct estimates for all elements of the F matrix
and the d vector.
From the discrete equations of state, Eqs. (2) and (3), (assuming, as before, that F
and d are constant) by a conventional way [1] we can go over to a single finitedifference equation:
n

n

y (k + 1) = ‚àë ai y(k ‚àí i + 1) +‚àë b j u (k ‚àí j + 1) + Œæ( k + 1 ),k = n ‚àí 1, n ‚àí 2,... (4)
i =1

j =1

n

where

Œæ( k ) = ŒΩ(k ) + ‚àë a i ŒΩ(k ‚àí i )

is the equivalent noise of output

i =1

measurements. In this case, it is quite clear how to form the X - matrix and the y vector in Eq. (1) from the input, u(k), and output y(k), measurements. The M¬ô1 vector of the sought parameters takes the form

c T = [a1 , ...,a n , b1 , ..., bn ] ,

i.e. at b1 ‚â† 0 , M=2n.
It is common practice to use the statistical theory of estimation for the
development of identification algorithms [2]. With this approach, the quality criterion
is defined on the basis of a priori information about the distribution of errors. If such
an information is lacking a certain probable a priori hypothesis about error
distribution is put forth. Then, the procedure constructed on its basis is statistically
tested in order to concretize the probability model. Such an approach comes into
conflict with the idea of system adaptation. In that case even ‚Äúgood‚Äù asymptotic
properties of estimates in a particular situation may be misleading.
We develop an algebraic approach to the construction of estimation algorithms.
This involves a more realistic formulation of the task as compared with that adopted
in the theory of statistical estimation. We discuss the feasibility of solving such
problems on the basis of the estimates conformity principle

2 Conformity Principle
The requirement to derive an estimate vector cÀÜ possibly close to the parameter vector
c implies that there exists the exact model of the system under estimation
corresponding to Eq. (1)

y ‚àó = Xc ,

(5)

y‚àó = y ‚àí .

(6)

where

Estimates Conformity Principle in the Problems of Identification

465

Obviously, Eq. (5) also holds for all sub-systems of lesser dimensionality constructed
from the rows taken in an arbitrary combination. Of course, it appears impossible to
attain the exact fulfillment of the equality in (5) for all the rows of the over-defined
system because the error vector x in the initial set (1) is not known.
However, it is possible to specify a set

{( } of so-called correcting vectors (
k

k

with a view to selecting among them one sufficiently close to x. To the set of vectors

{( } there will correspond a set of variants of(the corrected systems given by
k

(
y k = Xc + ‚àí

(
(
where y k = y ‚àí k .

, k = 1, K ,

k

(7)

For each of the above variants, in its turn, one can specify L variants of the set of
equations of lesser dimensionality P: M < P < N, with the P¬ôN-matrix X l and P¬ô1 vectors

(
\

N O

and

O

‚àí

(

N O

:

(
y k ,l = X l c +

l

‚àí

(
k ,l

,

k = 1, K , l = 1, L .

(8)

For each (k,l)-variant one can also construct a set of sub-systems of lesser
dimensionality, for example, with M rows of the set of equations (8) taken in an
arbitrary combination:

(
y k ,l ,q = X l ,q c +

l ,q

‚àí

(

k ,l ,q

,

q = 1,Q .

(9)

Here, index q serves to denote the sub-system number and the correspondingsub-matrix and vectors of the k,l -th variant. If in constructing all sub-systems one
takes exactly M rows, then

Q = C PM .

Suppose also that

q = 1,Q

Rank X l ,q =M,
for any matrix

(10)

X l ,q . Otherwise, it is always possible to ensure the fulfillment of this

requirement by excluding the linearly dependent rows.
The essence of the estimate conformity principle is as follows. For each q-th subsystem of the

q = 1,Q k,l-th variant the estimate vector ÀÜc k ,l ,q is calculated. We

specify the function

[ ]

Wl ÀÜc l ,q characterizing the mutual closeness of the solutions

ÀÜc k ,l ,q derived on the k,l-th variant and the selection criterion of the most appropriate
variant using the calculated closeness functions

[

]

Wk ,l ÀÜc k ,l ,q , k = 1, K , l = 1, L .

The selection criterion of the point estimate of the sought-for parameter on a set of
estimates corresponding to the selected variants and eventually used for constructing
the sought-for point estimate ÀÜc is also specified.
Within the conformity principle, we can specify various functions of mutual
closeness, the criteria for selecting the "best" variants based on the mutual closeness
functions, and the criteria for constructing the estimate using the selected variants. We

466

V. Fursov

consider the situation when the function of mutual closeness of the set of estimates on
the variant is given by

[ ]

2
Wl ÀÜc l ,q = ‚àë ‚àë (cÀÜ q ,i ‚àí c ) ,

where

ci =

1 Q
‚àë cÀÜ q ,i
Q q =1

is the i-th component of the vector

M Q

(11)

i =1 q =1

c calculated by averaging the estimates {ÀÜc l ,q }

derived on the variants for which the values of the mutual closeness function
Wl ÀÜc l ,q have turned out to be less than a preset threshold.

[ ]

Since the function of mutual closeness of estimates,

[ ]

W ÀÜc q , is not directly

related to measuring and estimating errors a natural question arises: whether the
application of the estimates conformity principle may guarantee a required accuracy
when solving the set (1). To get the answer the qualitative analysis of possible
situations has been conducted.
If

(

= Xa , where a is an arbitrary Mx1-vector, which implies that the
(

correcting vector

is a linear combination of columns of the matrix X, then the

component of the estimating error belonging to the null-space

N ( XT ) of the matrix

; 7 [3] does not depend on the correcting vector and the estimating error will be
affected only by the initial data. This means that in this situation the criterion (8) will
not respond to variations in the corrections

(

.

In the general case, when the correcting vector

(

also contains the component

T

belonging to N ( X ) the estimates for different sub-systems will be different. This
will result in non-zero values of the criterion (11). For a sequence of the correcting
vectors,

{( }, from (
k

k

‚Üí

it follows that

Q

(( ) ‚Üí 0 . However, the fact that the
k

criterion (11) converges to zero does not guarantee that the sequence of the correcting
vectors will converge to the error vector x.
In view of the aforementioned properties we consider one possible strategy for
constructing the estimates using the criterion (11). In particular, we discuss a method
with which the estimates are being constructed for several variants of less-dimension

(

sub-systems at = 0 . For each of them, the criterion (11) is calculated with the use
of still less-dimension sub-systems. From the resulting set of sub-system variants and
the corresponding estimates we select that for which the criterion value turns out to be
the least one. In this paper, we give an example of implementation of the abovedescribed procedure that demonstrates that the Least Square Method‚Äôs (LSM)
estimates can be essentially improved.

Estimates Conformity Principle in the Problems of Identification

467

3 Analysis of Feasibility of Constructing the Estimates
Using Non-statistical Criteria
Since the function of mutual closeness of estimates,

[ ]

W ÀÜc q , is not directly related

with measurement and estimation errors, a natural question arises if the use of the
estimate conformity principle guarantees that the set (1) is solved to the required
accuracy. To get the answer we shall conduct a qualitative analysis of possible
situations.
Consider the set (8). If Rank(X)=M, the vector
‚àí
hand side of Eq. (8) can be represented as two components:

‚àÜc = F

‚àí1

2

TŒªT

(

‚àí

(

(

appearing in the right-

(
‚àí = X‚àÜc + T0 ‚àÜd ,

),

‚àÜd = T0T

(

‚àí

(

(12)
(13)

).

(14)

Here T is the N¬ôN matrix and F is the M¬ôM matrix such that

TT XF = S,

X = TSF T ,

Ô£Æ
XXT = TSS T TT = T Ô£Ø
Ô£∞0

0Ô£π T
T ,
0Ô£∫Ô£ª

(15)

where S is a diagonal N¬ôM-matrix composed of so-called singular numbers, si,
= diag (Œª1 ,Œª 1 ,...,Œª M ) is a diagonal matrix of eigen-values li, being
i=1,M, and
the corresponding singular numbers si squared.
In view of the decomposition in Eqs. (12)-(14), Eq. (8) can be rewritten as
follows
(
y = X(c + ‚àÜc ) + T0 ‚àÜd .
(16)
Premultiply both sides of Eq. (29) by XT. In view of the property
have

XT T0 = 0 , we

(
XT y = XT X(c + ‚àÜc )

(17)

Whence it follows that the root-mean-square estimate calculated on all data,

[

]

‚àí1
(
(
c = XT X XT y = c + ‚àÜc ,

(18)
contains an error (13) that depends only on the components of the difference vector

(
‚àí , belonging to R( X ) .

Let us now analyze the solutions to the sub-systems in (9) composed from (8)
using corrected data. In view of the decomposition in (12), each of the sub-systems
can be represented as

(
y q = X q (c + ‚àÜc ) + T0 ,q ‚àÜd , q = 1,Œ£

(19)

468

V. Fursov

T0 ,q is a sub-matrix of the T0 -matrix corresponding to the q-th sub-system,
and ‚àÜc , ‚àÜd are the same as in (13) and (14). By multiplying from the left both
where

sides of (19) by

XTq , it can easily be found that as distinct from (18), the LSM

estimate calculated on the portion of data (for the q-th sub-system) will contain not
only the error vector ‚àÜc but also an extra error

[

‚àÜ~cq = X Tq X q

]

‚àí1

[

X Tq T0 ,q ‚àÜd = X Tq X q

]

‚àí1

X Tq T0 ,q T0T

(

‚àí

(

).

(20)

This is because for sub-systems of dimensionality lesser than N the product

T
q

X T0 q

is not necessarily equal to zero. Based on the aforementioned relationships, we can
formulate the following important properties of the criterion in (11).

(

If
= , in accordance with (13) and (14), ‚àÜc and ‚àÜd become zero
simultaneously, and as one would expect, the sought-for vector parameter c will be
determined exactly both from the entire set of data and from data sets of all lessdimension sub-systems. The criterion in (11) that corresponds to the above-described
situation takes its minimum value of zero.
If

(

(

= Xa (where a is an arbitrary M¬ô1-vector, that is the correcting vector

is a linear combination of the columns of matrix X), then from the property

XT T0 = 0 and Eq. (14) we have ‚àÜd = T0T

, i.e. ‚àÜd does not depend on the

correcting vector and the error in (20) will only be determined by the initial data. In
this situation the criterion in (11) will not respond to variations in the corrections
In the general case, when the correcting vector

(

(

.

comprises both the

components belonging to the space of columns and the null-space, the error ‚àÜc
appearing in (18) will be determined by the contribution of the component X‚àÜc in
the right-hand side of (12). Whereas the sub-vectors
space component

T0 q ‚àÜd composed of the null-

T0 ‚àÜd , will determine the set of errors in (20), which cause the

estimation difference for different sub-systems. As a result, the value of the criterion
in (11) will be non-zero. It is clear that for a sequence of correcting vectors

(

k

‚Üí

it follows that

Q

(

{( } from
k

( ) ‚Üí 0 . However, the convergence of the criterion (11)
k

to zero does not guarantee that the correcting vector will converge to the error vector.
Based on the above-formulated properties a number of strategies for
constructing the estimates using the criterion in (11) have been proposed. In
particular, in one method the estimates were constructed for several variants of less-

(

dimension sub-systems at = 0 . For each such a sub-system, the criterion (11) is
calculated using still less-dimension sub-systems. From the resulting set of subsystem variants with the corresponding estimates the estimate characterized by the
least criterion value is chosen.

Estimates Conformity Principle in the Problems of Identification

469

4 Example
Below we discuss an example (N=10, M=4) of finding the solution using the criterion
(11). The initial set of data was generated using a random number generator. Best
conforming estimates were sought using C107=120 sub-system variants, with 7
observations made for every variant. Then, for every variant, for C74=35 (4¬ô4)-subsystems a set of LSM-estimates was calculated, for which the value of the criterion
(11) was derived. The resulting set of the conformity criterion values was arranged in
increasing order. For comparison, the criteria of estimation quality,

‚àÜc , were

arranged in the same order.
Figure 1 shows the values of the conformity criterion. Figure 2 shows the
corresponding values of the LMS-estimate quality criterion. The horizontal line shows
the quality criterion value for the LSM-estimate calculated on all parameters.
5

2.5

x 10

30

2

25

20

1.5

15
1

10
0.5

5
0

0

20

40

60

80

1XPEHU RI YDULDQWV
Fig. 1.

100

120

0
0

20

40

60

80

1XPEHU RI YDULDQWV

100

120

Fig. 2.

5 Conclusions
The aforesaid strategy for seeking the solution is conceptually similar to the ideas by
P. Kalman discussed in Ref. [4]. In this case, the criterion (8) ensures the possibility
of finding a sub-system with least-noised observations. The suitability of the strategy
depends on how well the assumptions of existence of a noise-free sub-system are
justified, as well as on the proper choice of dimension of the sub-systems that are
assumed to include the above observations.
In order to find a least-noised sub-system it may require to search through a great
number of variants. This fact is not astonishing, being the unavoidable fee for a priori
information deficiency [5]. It seems reasonable that the application of simple (and,
hence, relatively cheap) statistical schemes of data processing becomes feasible as a
result of considerable expenses incurred while making a great number of observations
at the stage of constructing the system (1).

470

V. Fursov

Acknowledgement. This work was financially supported by the RF Ministry of
Education, Samara Region Administration, the American Civilian Research and
Development Foundation (CRDF Project SA-014-02) as part of the joint RussianAmerican program "Basic Research and Higher Education" (BRHE) and by the
RFBR (grants N. 00-01-05001, N. 01-01-00097).

References
1. Graupe, D.: Identification of systems. Colorado State University Fort Collins, Robert E.
Kriger Publishing Company Huntington, New York, 1978.
2. Ljung, L.: System Identification, Theory for the User. University of Linkoping, Sweden
Prentice - Hall, Inc., 1987.
3. Bjorck Ake.: Least Squares Methods, Elsevier Science Publishers B.V. North Holland,
1990.
4. Kalman P.E.: Noised systems identification, Advances of Mathematical Sciences, v. 40,
issue 4(244), 1985.
5. Fursov V.: Conformity principle in the problems of evaluating using a small number of
observations, Proceedings of the IASTED International Conference Automation,
Control, and Information Technology, June 10-13, 2002, Novosibirsk, Russia, p. 279‚Äì
281.

