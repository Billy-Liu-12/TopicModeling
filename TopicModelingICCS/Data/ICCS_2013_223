Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 2611 – 2614

2013 International Conference on Computational Science

Simulated Naïve Creature Crossing a Highway
Anna T. Lawniczaka,*, Jason B. Ernsta, Bruno N. Di Stefanob
a
b

University of Guelph, Guelph, Ontario N1G 2W1, Canada
Nuptek Systems Ltd, Toronto, Ontario, M5R 3M6, Canada

Abstract
We present a simple cognitive agent, a “Simulated Naïve Creature”, capable of evaluating if a strategy has been applied
successfully. The agents are born as “tabula rasa”, i.e. a “blank slate”. They are provided with a mechanism to reason and
plan toward their goal, but they have no built-in knowledge-base of their environment. Our simulation shows that the
performance of the agents is affected by the conditions of the environment (e.g. the traffic density on the highway and by
the crossing point location on the highway) and by their fears and desires.

© 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and
peerpeer-review
review under
responsibility
of the
of the
International
Conference
on Computational
and/or
under
responsibility
of organizers
the organizers
of 2013
the 2013
International
Conference
on Computational
Science
Science
Keywords: Agents; Cognitive Agents; Learning; Cellular Automata; Rule 184; Nagel-Schreckenberg model.

1. Introduction
A cognitive agent is an abstraction of an autonomous entity capable of interacting with its environment and
other agents,[1], [2], [3], [4], [5]. The most common implementation of the cognitive agent abstract concept is a
software program in a virtual reality. Even when the agent is meant to be actually built in a concrete form,
almost always a software version is developed to model and simulate it, for verification of understanding, thus
avoiding costly mistakes in what is actually built, [6]. We have studied issues of minimal hardware
implementable agents at very low cost, [7]. The current paper is in the same spirit.
Alonso et al. write “When designing agent systems, it is impossible to foresee all the potential situations an
agent may encounter and specify an agent behaviour optimally in advance. Agents therefore have to learn from,
and adapt to, their environment, especially in a multi-agent setting.” [8].
In this paper we study a population of agents assuming that they are born as “tabula rasa”, i.e. a “blank
slate”. They are provided with a mechanism to reason and plan toward their goal, but they have no built-in
knowledge-base of their environment. Because the knowledge-base is implemented in software, a suitable data

*

Corresponding author. alawnicz@uoguelph.ca; Tel.: +1-519-824-4120 ext. 53287; fax: +1-519-837-0221

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.452

2612

Anna T. Lawniczak et al. / Procedia Computer Science 18 (2013) 2611 – 2614

structure for the knowledge-base is predefined and initialized to some value that coincides with no data, e.g. all
variables are set to zero. However, the agents have a built-in template to classify the environment and a
reasoning method to make good use of this classification. As the simulation of the model progresses, the full
knowledge-base is populated with values that actually represent the evolution of the system.
The paper is structured as follows: section 2 describes the universe of the problem domain that we are
studying (i.e., the environment, the population of agents, and the experiment); section 3 describes and discusses
the learning algorithms implemented for our agents; section 4 contains some experimental results; section 5
presents our conclusions and outlines future work.
2. Experimental Virtual Universe
Our experimental virtual universe was developed under several assumptions. A cognitive agent is “an
autonomous entity capable of interacting with its environment and other agents”, [1], [2], [3], [4], [5]. The
environment is a highway characterized by unidirectional vehicular traffic, without any intersection, [6]. The
cognitive agent under consideration is a creature with a strong instinct to forage for food and a strong instinct to
survive. All creatures are born on one side of the highway and the food is on the opposite side. Each creature
must cross the highway without being struck by the oncoming vehicles in order to reach food.
We equip each creature with a simple mechanism to evaluate the outcome of the crossing of creatures that
crossed previously. Each creature will try to imitate the successful crossings. If a crossing has not been
successful then under similar circumstances the creature will not cross and wait for better conditions. We
model the highway traffic by adopting the Nagel-Schreckenberg model, [9]. The model consists of four steps
that are applied simultaneously to all cars: acceleration, safety distance adjustment, randomization, and change
of position. As customary in the traffic modelling literature, we model the one lane highway as a large number
of adjacent cells, with each cell representing a segment of highway of 7.5m in length, [9]. Such representation
has been chosen because it corresponds on average to the space occupied by the typical car plus the distance to
the preceding car in a situation of dense traffic jam of cars of more or less homogeneous length (i.e., trucks and
busses are excluded). The simulation also supports multiple lanes. At each time step in the simulation, for each
lane, a new car may be generated with a probability specified in the configuration file as car creation
probability. If there is already a car in the first cell because it hasn’t sped up enough, or traffic is congested, the
generated car is added to a queue of cars waiting to enter the highway. The entrance point is always cell zero of
each lane. Cars accelerate by one until they reach their maximum speed which is specified in the configuration
file. For our investigation the implementation of the Nagel-Schreckenberg model requires to modify the
Cellular Automata (CA) paradigm and to make the evolution of the CA not only dependent on the state of the
neighbourhood but also on the current velocity of each vehicle.
The creatures are implemented in a fashion similar to the cars. They also use a queue so that if a creature has
not yet crossed, the new creatures line up behind it. The creatures are generated with a creation probability at
each time step at a cross point. The motion of the creature is modeled similarly to the motion of the vehicle,
with a CA-like approach. In a single time step, the creature looks at the environment (where cars are, and with
what speed they are travelling) then decides to move. If it decides to move, it moves onto the highway, then the
cars move. If a car moves into the cell occupied by the creature or to a cell with coordinate number higher than
the creature’s cell number, then the creature is hit. In order for a creature to decide whether to move, it must
consult the global “knowledge-base” derived from the creatures’ past experiences. This “knowledge-base” is a
table of states and results. The table has “fuzzy” categories for velocity (e.g., “fast”, “medium”, and “slow”)
and proximities (e.g., “close”, “med”, and “far”).
Our experiment is designed to evaluate how the decision to cross or not to cross is affected by traffic density
(measured as vehicle creation probability) and creature density (measured as creature creation probability).

Anna T. Lawniczak et al. / Procedia Computer Science 18 (2013) 2611 – 2614

3. Simple Learning Algorithms, The Naïve Algorithm Without And With Fear And Desire
We assume that all creatures, i.e. agents, witnessed what happen to the creatures that previously crossed the
road. There is only one knowledge base that is built during the experiment that is available to all agents. We
assume that the creature is capable of matching simple patterns, evaluating distances in an approximate way,
evaluating the velocity of moving vehicles in an approximate way, assigning a discrete number (i.e., class
identifiers) to an approximate class, understanding when another agent has been successful in crossing the road,
and repeating the action that has previously resulted in success. The creatures are not able to measure distances
accurately. They can only rank the position of a vehicle with respect to the crossing cell according to a discrete
number of categories (e.g., {far, mid-range, close} or, alternatively, {very far, far, mid-range, close, very
close}, etc.). The creature keeps track of what happens according to a mental table in which the columns store
information about verbal descriptions of velocity (e.g., such as “fast” “medium” and “slow”) and the rows store
information about verbal descriptions of the distance (e.g., such as “close distance”, “medium distance”, and
“far distance”).
The table is initialized as “tabula rasa”, i.e. a “blank slate”, represented with “0” at each location. If a
crossing results in a creature being struck, all other creatures will decrease by “-1” a current value of the table
entry for the specific (distance, velocity) combination. If the crossing is successful they will increase by “+1”
the current value of the table entry for the specific (distance, velocity) combination. The creatures will cross the
highway only for the (distance, velocity) combinations for which the corresponding entries of the table are nonnegative. After a certain number of simulation cycles, the table will represent what happened to the first few
generations of creatures and will be populated mostly by “-1” or positive integers. In this algorithm the
creatures avoid crossing the highway for a particular (distance, velocity) combination only from a time from
which the number of struck creatures is greater than those who crossed the highway successfully. This may be
modified by incorporating probabilistically creatures “fears” and “desires”. Thus, the generated population of
creatures would act in a stochastic way depending on “fear” and/or “desire” probabilities and one could study
how “Fear” and “Desire” may alter the decision and success of crossing the highway. The construction of the
knowledge base table in the “fear & desire” algorithm requires an appropriate modification including the
initialization of the table and details will be provided elsewhere.
In the case when a creature can experience fear or/and desire, in order to encourage creatures to cross the
highway at the start of the simulation, creatures pay no attention to their knowledge base table or their fear and
desire at the start of the simulation. For each (distance, velocity) combination this lasts until the first successful
crossing of a creature, or five consecutive unsuccessful crossing of the creatures, whichever comes first. After
this initialization, for each (distance, velocity) pair the creatures combine their “success ratio” of crossing the
highway with the fear and/or desire probabilities, depending what type of feelings creatures are experiencing. If
for a given (distance, velocity) combination the value in the knowledge base table is less than zero, then the
creature will not attempt to cross the highway under this condition and it will wait for a configuration for which
the entry of the table becomes non-negative.
4. Some Experimental Results
We present here results of selected experiments to evaluate the behaviour of the agent that we have
developed. Figure 1 contains histograms showing the number of creatures that at the end of the simulation have
successfully crossed (green colour), that had been killed (red colour), and that had been queued (blue colour),
all while attempting to cross at cross point 45, i.e. at cell number 45 from the beginning of the section of
highway under consideration. This histogram shows results for car creation probabilities p = 0.1, p = 0.3, p =
0.5, p = 0.7, and p = 0.9. As we already mentioned, we are interested in exploring how “Fear” and “Desire”
may alter the outcome of the plain naïve algorithm. Figure 1 (a) shows the results for the plain, naïve algorithm

2613

2614

Anna T. Lawniczak et al. / Procedia Computer Science 18 (2013) 2611 – 2614

without the influence of any “Fear” or “Desire” (i.e. when fear probability = 0.0 and desire probability = 0.0),
while Figure 1 (b) covers the case when fear probability = 0.0 and desire probability = 1.0. Figure 1 (c) depicts
the case for fear probability = 1.0 and desire probability = 0.0.

(a)

(b)

(c)

Figure 1 - Histogram of “Number of Creatures at End of Simulation”, for cross point = 45, who successfully crossed (green), who were
killed (red), and who were queued (blue). In subfigure (a) fear probability = 0.0, desire probability = 0.0. In subfigure (b) fear probability =
0.0, desire probability = 1.0. In subfigure (c) fear probability = 1.0, desire probability = 0.0.

5. Conclusions and Future Work
In this paper we described a simple cognitive agent able of examining its environment and deciding a
suitable course of action to achieve its goal. We propose few strategies that the agent may follow. The naïve
algorithm simulation results are consistent with the fact that crossing a highway becomes more difficult with
increase of cars density and it is affected by the creatures’ fears and desires. The results of various other
experiments will be reported elsewhere.
References
[1]
[2]

[3]

[4]
[5]
[6]
[7]
[8]
[9]

Ferber J., Multi-Agent Systems. An Introduction to Distributed Artificial Intelligence, Addison Wesley, London 1999.
Di Stefano, B. N., Lawniczak, A. T., "Cognitive agents: functionality & performance requirements and a proposed software
architecture", Proc. of Science and Technology for Humanity (TIC-STH), 2009 IEEE Toronto International Conference, 2009,
Page(s): 509 – 514.
Di Stefano, B. N., Lawniczak, A. T., "Cognitive agents: functionality & performance requirements and a proposed software
architecture", Proc. of Science and Technology for Humanity (TIC-STH), 2009 IEEE Toronto International Conference, 2009,
Page(s): 509 – 514.
Wooldridge, M., An Introduction to MultiAgent Systems, John Wiley & Sons, Ltd., Chichester, West Sussex, UK, 2009.
Uhrmacher, A. M., Weyns, D., Multi-Agent Systems Simulation and Applications, CRC Press, Taylor & Francis Group, Boca Raton,
Fl., 2009.
Di Stefano, B. N., Lawniczak, A. T., Modeling a Simple Adaptive Cognitive Agent, Acta Physica Polonica, B Proceedings
Supplement, Vol. 5 (1), 2012, 21-29.
Di Stefano, B., Lawniczak, A. T., Autonomous Roving Object’s Coverage of its Universe, Proc. 19th IEEE CCECE 2006-CCGEI
2006, Ottawa, Ontario, Canada (May/mai 2006), 1591-1594.
E. Alonso, M. d'Inverno, D. Kudenko, M. Luck and J. Noble, Learning in multi-agent systems, Knowledge Engineering Review,
16(3), 277-284, 2001.
Nagel K., Schreckenberg M. (1992). A cellular automaton model for freeway traffic, J. Physique I, 2, 2221 – 2229.

