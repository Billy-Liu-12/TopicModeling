A Dynamic Committee Scheme on Multiple-Criteria
Linear Programming Classification Method
Meihong Zhu1,2,Yong Shi1, Aihua Li1, and Jing He1
1

CAS Research Center on Data Technology and Knowledge Economy
Management School, Graduate University of CAS,
Beijing 100080, China
2
Statistics School, Capital University of Economics and Business
Beijing100070, China
{zhumh,yshi,lah04b,jinghe}@mails.gucas.ac.cn

Abstract. This paper aims to provide a scheme for effectively and efficiently
finding an approximately optimal example size with respect to a given dataset
when using Multiple-Criteria Linear Programming (MCLP) classification
method. By integrating techniques of both progressive sampling and
classification committee, it designs a dynamic classification committee scheme
for MCLP. The experimental results have shown that our idea is feasible and
the scheme is effective and efficient for exploring an approximately optimal
sample size. The empirical results also help us to further investigate some
general specialties of MCLP, such as the more general function expressions
reflecting the relationship between accuracy and sample size, and between
computing cost and sample size.
Keywords: Classification, Multiple-Criteria Linear Programming, Progressive
Sampling, and Committee.

1 Introduction
In data mining field, Multiple-Criteria Linear Programming (MCLP) classification
method is an outstanding classification tool [1-5]. But, just like many other
classification tools, its computation efficiency is sometimes low when faced with
large and high-dimension datasets. Among research efforts to improve classification
efficiency of MCLP, sampling is an important approach. In practice, MCLP is often
executed on a one-off (static) selected sample, while the sample size is often
determined by analysts subjectively. The subsequential problem is that we can’t judge
whether the one-off selected sample is good enough for analyses. If the sample is
small, it can’t reflect the original data sufficiently; contrarily, if it is too large,
computation cost will be unacceptable. So, how to identify an appropriate sample size
is the key to the success of applying sampling techniques to MCLP. Among various
sampling approaches, progressive sampling is a well-known one for finding an
approximately optimal example size [6, 7].
Y. Shi et al. (Eds.): ICCS 2007, Part II, LNCS 4488, pp. 401–408, 2007.
© Springer-Verlag Berlin Heidelberg 2007

402

M. Zhu et al.

This paper designs a scheme to effectively and efficiently find an approximately
optimal example size for MCLP classification method with respect to a given dataset.
This scheme integrates techniques of both progressive sampling and classification
committee. First, a new non-standard arithmetic progressive sampling procedure is
implemented to determine example size of each step. Secondly, at each step of
progressive sampling, a classification committee [8-13] is constituted by 9 samples
with the same size. Finally, by comparing the accuracies of adjacent committees
dynamically and interactively, an approximately optimal example size for MCLP is
found. Resumptively, this scheme can be called a Dynamic Committee Scheme on
MCLP classification method.
To illuminate our idea simply, this paper only focuses on two-group classification
problems. Two real-life databases with different sizes are applied to verify our idea.
Experiment results provide us following conclusions: Firstly, the Dynamic Committee
Scheme on MCLP can effectively find the approximately optimal example size for
MCLP classification method with respect to a given dataset, i.e., the approximately
optimal example size really exists. Secondly, it can efficiently find the approximately
optimal results, i.e., the computation is acceptable. Additionally, these experiment
results help us to execute an in-depth study of specialties of MCLP, such as the
relationship between classification accuracy and sample size, and that between
computing cost and sample size, and that between computing cost and number of
attributes.
The rest of the paper is organized as follows. Section 2 introduces some
background knowledge for latter analyses. Section 3 describes our dynamic
Classification Committee scheme on Multiple-Criteria Linear Programming
classification method in detail. Section 4 introduces experimental operations and
analyzes corresponding results. The last section concludes our work and presents
future research directions.

2 Background Knowledge
To understand our idea and method, three aspects of background knowledge are
needed.
2.1 Two-Class MCLP Classification Model
MCLP classification model is first presented by Shi et al.[1]. A two-class MCLP
model can be depicted as follows:
Given a training dataset which has p predictive variables (attributes) a = (a1, . . . ,
ap ) and n cases, let Ai = (Ai1, . . . , Aip) be the data for the variables in ith case, where i
= 1, . . . , n. We hope to explore the best coefficients of p variables denoted by X =
(x1, . . . , xp )T, and a boundary value b(a scalar ) to separate existing data into two
classes: G1 and G2; that is,
Ai X ≤ b, ∀Ai ∈ G1 and Ai X ≥ b, ∀Ai ∈ G2

(1)

A Dynamic Committee Scheme on MCLP Classification Method

403

In this expression, AiX is a linear function of attribute variables X used for classifying
each labeled or unlabeled case. To measure the separation degree of G1 and G2, we
define:
αi = the overlapping degree of two classes boundary for case Ai ;
βi = the distance of case Ai from its adjusted boundary.
The objective function is minimizing the sum of αi and maximizing the sum of βi
simultaneously. So there is following classification model (M1).
M in im iz e

∑

i

α i a n d M a x im iz e

∑

S u b je c t to :

i

βi

(2)

A i X = b +α i - β i , ∀ A i ∈ G 1 ,
A i X = b -α i + β i , ∀ A i ∈ G 2 .

Where Ai are given; X and b are unrestricted; and αi and βi ≥ 0.
This multi-objectives linear programming problem can be transformed into a
single-objective model by introducing the compromise solution approach [2,3].We
assume the “ideal value” of - Σi αi be α* > 0 and the “ideal value” of Σi βi be β* > 0. If
-Σi αi > α*, we define the regret measure as –dα+ = Σi αi + α*; otherwise, it is 0. If - Σi
αi < α*, the regret measure is defined as dα- = α* + Σi αi; otherwise, it is 0. Thus, we
have (i) α*+ Σi αi = d α- - dα+, (ii) | α* + Σi αi | = dα- + dα+, and (iii) dα- , dα+ ≥
0.Similarly, we have β* - Σi βi = d β- - d β+, | β* - Σi βi| = dβ- + dβ+, and dβ- , dβ+ ≥ 0. So
M1 can be changed into M2.
M inim ize d α- + d α+ + d β- + d βS u bject to :

α *+ ∑ i α i = d α- − d α+

(3)

β * - ∑ i β i = d β- − d β+

Ai X = b +α i - β i , ∀ A i ∈ G 1 ,
Ai X = b -α i + β i , ∀ A i ∈ G 2 .

Where Ai, α*, and β* are given, X and b are unrestricted, and αi , βi , dα-, dα+ , dβ- , dβ+
≥ 0. If b is given and X is found, we can classify a labeled or unlabeled by using linear
discriminant AX.
The standard two-class MCLP algorithm is based on the M2. It uses the idea of
linear programming to determine a boundary separating classes. Comparing with
other classification tools, it’s simple and direct, free of the statistical assumptions,
flexible in defining and modifying parameters, and high on classification accuracy
[5]. It has been widely used in business fields, such as credit card analysis, fraud
detecting, and so on. But faced with high dimension data or too much size of data,
sometimes its computing efficiency is low.
2.2 Progressive Sampling
Progressive sampling [7] is a famous dynamic sampling method that can be used in
large datasets. It attempts to maximize model accuracy as efficiently as possible. It is
based on the fact that when the sample size is large enough, with the further increase

404

M. Zhu et al.

of sample size, the model accuracy doesn’t increase significantly. It is in fact a tradeoff between classification accuracy and computing cost. Because of dynamic
interactions of sampling process, it overcomes the weakness of one-off (static)
sampling.
It starts with a small sample n0 and augment sample amount progressively at each
step. At each step, a model is built from the current sample and is evaluated. If the
resulting model has not reached user-specified accuracy threshold, the algorithm must
operate once again. Generally, the relation between accuracy and corresponding
sample size can be expressed in learning curve (Figure 1). The convergence nmin in the
curve is the approximately optimal sample size.
In progressive sampling, two key aspects affecting sampling effectivity and
efficiency are increasing mechanism of sample size and stopping or convergence
criterion of sampling .
As for the first aspect, [6] proposed an arithmetic increasing schedule as

S a = { n0 ,n1 ,n2 ,...,nk } = { n0 ,n0 + nδ ,n0 + 2nδ ,...,n0 + k ⋅ nδ } .
[7] presented a geometrical increasing schedule as

S g = { n0 ,n1 ,n2 ,...,nk } = { n0 ,a ⋅ n0 ,a 2 ⋅ n0 ,...,a k ⋅ n0 } .
[6] drew a conclusion that arithmetic sampling is more efficient that one-off sampling,
and [7] verified geometrical sampling is more efficient than arithmetic sampling.

Fig. 1. Accuracy vs. sample size

2.3 Classification Committee
To improve prediction performance of an individual classifier, classification
committee techniques are often used in many classification methods. There are many
researches on committee/multi classifier/ensemble. The most popular guidelines for
combining all individual classifiers are Bagging[8], Boosting[9],Random
Subspace[10], and Random Forest[11]. There have been many variations of the above
guidelines. The combination rules mainly include simple majority (mainly for
Bagging), weighted majority (mainly for Boosting), minimum, maximum, product,
average, Naive Bayes and so on[12].
Bagging is based on bootstrapping [13] and aggregating concepts, so it
incorporates the benefits of both approaches. In Bagging, m random independent
bootstrap samples with the same size n(≤N) are taken out from the original dataset N,
and then m individual classifiers are developed, and finally a classification committee

A Dynamic Committee Scheme on MCLP Classification Method

405

is made by aggregating these m member classifiers using a simple majority vote.
Bagging can be executed in parallel way, thus it is efficient.

3 A Dynamic Committee Scheme on MCLP Classification Method
In this paper, we want to explore the approximately optimal sample size nmin for
MCLP classification method with respect to a given dataset. For simplicity, our
research only focuses on two-class problems.
In our scheme, a committee is integrated by m individual classifiers. The
combination mechanism is a variation of Bagging technique, which takes out samples
in a non-repetition way from original dataset N with ni<<N.
To explain our method expediently, we define:
acc(ni)=classification accuracy on test set computed by the committee with sample
size ni;
c=user-defined accuracy threshold or criterion for stopping sampling.
To explore nmin, we design a progressive sampling scheme. In this scheme, sample
size is increased according to a non-standard arithmetic progressive manner. Initially,
sample sizes are arithmetically increased with a fixed increasing extent nδ (see
formula (4). When formula (5) is satisfied, the subsequent three sample sizes are
increased according to a less degree n'δ as shown in formula (6).

{ n0 ,n1 ,n2 ,...,nk } = { n0 ,n0 + nδ ,n0 + 2nδ ,...,n0 + k ⋅ nδ }

(4)

acc( nk-1 )-acc( nk-2 ) ≤ c, and acc( nk )-acc( nk-1 ) ≤ c

(5)

{nk+1 ,nk+2 ,nk+3 } ={nk +n'δ , nk +2n' δ , nk +3n'δ }, where n'δ < nδ

(6)

If formula (7) is satisfied, sampling process is cutoff; or else, later sample sizes are
still increased according to the increment nδ.
acc( nk+1 )-acc(nk ) ≤ c, acc( n k+2 )-acc(nk+1 ) ≤ c, and acc( nk+3 )-acc( nk+2 ) ≤ c (7)

When sampling process is stopped, the committee with the highest accuracy among
the six sequential committees generated from the above six sample
sizes { nk − 2 ,nk −1 ,nk ,nk +1 ,nk + 2 ,nk +3 } is the final committee for prediction.

4 Empirical Research
To indicate effectivity and efficiency of our design, two real databases with different
sizes are used in our experiment research. They are described as follows:
Table 1. Description of the Two Databases
Database

number of predictive attributes

Size of training set

Size of test set

Credit Card
Census Income

63
43

4000(small)
50000(large)

1000
20000

406

M. Zhu et al.

In our design, we stipulate parameter b =1, m=9, and c=0.3%~0.5%.
The operating results and intuitionistic expressions for two databases are shown in
following tables and figures. Detailedly, “time” in following tables indicates average
time for generating a single member classifier, and “acc1” means accuracy rate for
class 1 (majority class), and “acc2” means accuracy rate for class2 (minority class),
and “acc” denotes overall weighted-average accuracy.
4.1 Experiments and Results

As for the credit card dataset, considering its high dimension, we judge the computing
cost is high, so parameter c should be set comparatively high, and nδand n0
comparatively low. Here c is predefined as 0.3%, n0 as 200, and nδ as 200. The initial
scheme is S={200,400,600,800}. The results show that the absolute improvement of
acc on n2 vs. n1, n3 vs. n2 are all not more than 0.3%, i.e., the results on different
sample sizes are stabile, so latter sample sizes are changed at a less scope by n'δ =100
sequentially. Then S={200, 400, 600, 800, 900, 1000, 1100, …}.The acc
improvement on n4 vs. n3 ,n5 vs. n4, and n6 vs. n5 are all less than 0.3%,while the
computing costs significantly grow with the increase of n. So sampling process is
terminated. Among the latter six committees, the committee on n3 is adopted as the
final classifier for prediction due to its good performance. Additionally, to depict the
time vs. n curve, we add two excess sample points 700 and 1500 which are all marked
with symbol *.
Table 2. Time and Accuracy on Different Sample Sizes for the Credit Card Database

（）

N

Time

200
400
600
800
900
1000
1100
700*
1500*

s

1
10
60
210
390
660
1200
120
4800

（）

acc1

%

69.09
71.52
72.00
71.52
70.06
71.64
70.40
71.39
71.89

（）

acc2(%)

acc

82.57
81.14
80.00
84.00
84.57
81.71
85.65
84.00
83.51

69.7
73.2
73.4
73.7
73.6
73.4
73.1
73.6
73.8

%

time vs.n

acc vs. n
90

5000
4500

85

4000
3500

80

acc1

75

3000

acc2

2500

acc

2000
1500

70

1000
500

65
0

200

400

600

800 1000 1200 1400 1600

0
0

200

400

600

800

1000

1200

1400

1600

Fig. 2. Result of acc vs. n for Credit Card Fig. 3. Result of time vs. n for Credit Card
Database
Database

A Dynamic Committee Scheme on MCLP Classification Method

407

Similarly, we have following results with respect to the census database. The
approximately optimal sample size is n6=1700.
Table 3. Time and Accuracy on Different Sample Sizes for the Census Database
N

（）

time (s)

300
600
900
1200
1500
1600
1700
1800
1900*
2500*

（）

Acc1 %
78.52
78.07
77.89
78.44
78.42
78.57
78.77
78.13
78.79
78.56

8
9
25
55
143
200
230
290
340
940

（）

Acc %
85.20
86.00
87.42
87.25
86.38
86.72
86.69
87.75
86.77
86.86

Acc %
80.89
80.88
81.27
81.57
81.25
81.47
81.58
81.54
81.62
81.51

acc vs. n
time vs.n
90
88

1000
900

86

800
a cc 1

84

a cc 2

82

a cc

80

700
600
500
400
300
200

78

100
0

76
0

300

600

900

1200 1500

1800

2100 2400

2700

0

500

1000

1500

2000

2500

3000

Fig. 4. Result of acc vs. n for the census Fig. 5. Result of time vs. n for the census
database
database

4.2 Analysis of Results

From the results of two databases, we have three empirical results. Firstly, the
Dynamic Committee-Classifier Scheme on MCLP can effectively find the
approximately optimal example size for MCLP classification method with respect to a
given dataset, i.e., the approximately optimal example size really exists. Considering
the time cost, 800 is enough for the first dataset, which only accounts for 20% of
original training dataset; 1700 is sufficient for the second dataset, which only equals
to 3.5% of the whole training set. Secondly, it can efficiently find the approximately
optimal sample size. For example, in the credit card database, we can see
4800>1+10+60+210+390+660+1200. That is to say, if we sample a sample with 1500
cases, its computing cost outclasses the whole computing time of scheme
{200,400,600,800,900,1000,1100}, while its accuracy rate only has 0.1 percent of
improvement. From the time vs. n curve, we can also see that time cost is
unacceptable when n is too large. Lastly, we find some laws reflecting the relationship
between acc and n, between time and n, and between number of attributes and time.
The time vs. n curve is in the form of power function.

408

M. Zhu et al.

5 Conclusions and Future Efforts
To enhance computation efficiency, sampling is an important strategy in MCLP
classification. To ensure the credibility and efficiency of sampling, we integrate
progressive sampling and classification committee, and then design a dynamic
classification committee scheme for MCLP classification method. The experimental
results have shown that our idea is feasible and the scheme is effective and efficient in
exploring an approximately optimal sample size. The empirical results also help us to
further investigate some general specialities of MCLP. From the above two datasets,
we can see the time vs. n curve is in the form of power function. But we can’t
perfectly depict the form of acc vs. n curve due to deficiency of number of samples.
In our future researches, we will further explore more general forms of functions
acc=f(n) and time=f(n).

References
1. Shi, Y., Wise, M., Luo, M., Lin, Y.: Data mining in credit card portfolio management: a
multiple criteria decision making approach. In: Koksalan, M., Zionts, S. (eds.): Multiple
Criteria Decision Making in the New Millennium, Springer, Berlin(2001)427-436
2. Shi, Y., Yu, P. L.: Goal setting and compromise solutions. In: Karpak, B., Zionts, S. (eds.):
Multiple Criteria Decision Making and Risk Analysis Using Microcomputers, SpringerVerlag, Berlin (1989) 165-204
3. Shi,Y.: Multiple Criteria Multiple Constraint-levels Linear Programming: Concepts,
Techniques and Applications. World Scientific Publishing, River Edge, New Jersey (2001)
4. Shi, Y., Peng, Y., Xu, W. ,Tang, X.: Data Mining via Multiple Criteria Linear
Programming: Applications in Credit Card Portfolio Management. International Journal of
Information Technology and Decision Making. 1 (2002) 131-151.
5. Kou, G., Liu, X., Peng, Y., Shi, Y., Wise, M., Xu, W.: Multiple Criteria Linear
Programming to Data Mining: Models, Algorithm Designs and Software Developments.
Optimization Methods and Software. Vol. 18(2003) 453-473
6. John, G., Langley, P.: Static Versus Dynamic Sampling for Data Mining. In : Simoudis,
E., Han, J.W., Usama M. Fayya( eds): Proceedings of the Second International Conference
on Knowledge Discovery in Databases and Data Mining, AAAI/MIT Press( 1996)367–370
7. Provost, F., Jensen, D., Oates, T.: Efficient progressive sampling. In: Proceedings of the
Fifth KDDM, ACM Press, New York(1999) 23–32
8. Breiman, L.: Bagging predictors. Machine Learning. 24(2)(1996)123–140
9. Freund. Y., Schapire, RE. :Experiments with a new boosting algorithm. In: Proceedings
of 13th International Conference on Machine Learning (1996) 148–156
10. Ho, T.K.: The random subspace method for constructing decision forests. IEEE
transactions on Pattern Analysis and Machine Intelligence.20(8)(1998)832–844
11. Breiman, L.: Random forests. Machine Learning. 45(1)( 2001)5–32
12. Freund, Y., Schapire, RE.: Discussion of the paper Arcing Classifiers by Leo Breiman.
The Annals of Statistics 26 (3) (1998) 824–832
13. Efron, B., Tibshirani, R.: An Introduction to the Bootstrap. Chapman& Hall, New
York(1993)

