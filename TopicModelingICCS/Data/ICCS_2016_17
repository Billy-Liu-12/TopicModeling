Procedia Computer Science
Volume 80, 2016, Pages 650–661
ICCS 2016. The International Conference on Computational
Science

Biological Systems Through the Informational Lens
Albert Lawrence*, Tsvi Katchalski, Alex Perez, Varda Lev-Ram, Daniela
Boassa, Thomas Deerinck, Sebastien Phan, Steven Peltier and Mark Ellisman
National Center for Microscopy and Imaging Research, Center for Research in Biological
Structures, UCSD, La Jolla, CA 92093-0608, USA
aflawrence@ucsd.edu

Abstract
Computation is often seen as information processing. Many biological systems may be investigated in
terms of information storage, signaling, and data processing networks. Much of this data processing
activity is embodied in structural transformations in spatial scales ranging from the molecular to
cellular networks. The biomedical sciences make use of an increasingly powerful arsenal of tools and
technologies for obtaining structural data as well as details of mass transport and the chemical and
electrical signals that underlie these fundamental biological processes. For example, new staining
techniques combined with computer-based electron microscope tomography, permit the clear imaging
of chromatin filaments in the cell nucleus and filament networks in the cytoplasmic and extracellular
space via the electron microscope. The application of tomographic reconstruction software developed
at the National Center for Microscopy and Imaging Research (NCMIR) enables detailed 3D
reconstructions of the relevant biological structures and processes. In order to deal with fundamental
issues related to information processing in biological systems, new data processing methods as well as
advances in chemically sensitive probes and imaging technology must be applied across a wide range
of spatial and temporal scales. One class of increasingly useful tools for modeling biological systems,
evaluating imaging technologies and characterizing the fidelity of digital processing has its roots in
theoretical investigations in statistical mechanics, which arise from the concepts of information and
entropy. We review how concepts of information and entropy may give new perspectives on the flow
of information within biological systems, as well as our instrumentation and computer processing.
Keywords: chromatin, perineuronal net, tomography, information theory, Renyi, entropy, radon transform

1 Information in structural biology and systems biology
“When the American scientist Claude Shannon found that the mathematical formula of Boltzmann
defined a useful quantity in information theory, he hesitated to name this newly discovered quantity
*

650

Corresponding author
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.355

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

entropy because of its philosophical baggage. The mathematician John von Neumann encouraged
Shannon to go ahead with the name entropy, however, since ‘ no one knows what entropy is, so in a
debate you will always have the advantage’.” --The American Heritage Book of English Usage,
quoted in Borwein Maximum entropy and Feasibility methods for Convex and Nonconvex Inverse
Problems.
One answer to this apocryphal anecdote is that information is the change of entropy under
transformations of the system under investigation, and that entropy itself can be defined
mathematically, in a manner that is consistent with the physics of the system [1].
Recent years have witnessed a remarkable development of technology and tools that support the
detailed investigation of biological systems. On one hand, we have the development of fluorescence
microscopy [2,3,4,5], which gives highly localized information regarding the activity of protein
structures in biological processes. This, on the level of light microscopy, provides a unification of our
knowledge of genomics and the metabolic network with our observations of the dynamics of the living
cell. On the other hand, with improvements in sample preparation of biological specimens and
microscope technology we have been able to extend electron microscope investigations to the
resolution of protein assemblies within the cell. Electron tomography (ET) extends these tools to the
third dimension [6]. In combination with advanced staining techniques, ET, through imaging
contextual structure, can overcome the “pointilist” [1] nature of fluorescence microscopy in the range
between 10 to 500 nanometers, provide three dimensional (3D) reconstructions of protein assemblies,
correlate 3D structures with functional investigations at the light microscope level and provide
structural information which extends the findings of genomics and molecular biology.
One particular area of convergence is between investigations of two of the most information-rich
systems known to man--the cell nucleus and nerve cell networks. A central problem in the study of
these biological systems is determining how information embodied in the cell nucleus is accessed to
control processes in the cell cytoplasm and along the cell membrane. Figure 1, below illustrates
biological structures associated with these recently discovered connections. This figure shows sections
of 3D tomographic reconstructions made possible, in a large part, by computer software developed at
NCMIR.
Figure 1 also illustrates the connection between information in the cell nucleus and information
processing in the brain. Recent investigations aimed at long lived proteins, localized by fluorescence
microscopy, has pointed toward the hypothesis that networks of long-lived proteins encapsulating
neurons, the perineuronal net (PNN) play a determining role in the formation of long-term memory.
Findings of a genetic role in abnormalities of the PNN, which lead to development of schizophrenia,
have recently attained wide coverage in news media [7,8]. Thus, readout of information of specific
genetic information in the DNA, should control changes in brain connection networks and information
processing in the brain. The verification of such findings would point toward a detailed and systematic
approach to investigation of information transmission within biological systems. Elucidation of the
mechanisms of information transfer constitutes an ongoing research problem in biological systems.
Beyond this, a systems approach to the issue of information in biological processes may well be
extended to the laboratory process as an information transmission system. For example, what
information, in the form of entropy, is propagated throughout our experimental procedures? Beyond
the conventional techniques of computer based tomographic reconstruction employed by biological
researchers, we would propose, as a modest beginning the investigation of entropy measures within
the Radon transform and its inversion. Admittedly, the wider biological connections may be tenuous
(although tantalizingly promising) at the moment, an examination of our computer processing in terms
of entropy and information, has and should continue to contribute new theoretical insights into the
mathematics of tomographic reconstruction and lead to new techniques in image processing.

651

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

Figure 1: (a) Cross section of a 3D volume reconstructed using electron tomography showing chromatin
filaments at high magnification (b) Hippocampus serial block face showing neuron body at low
magnification. (c) Surface rendering of cortical neuron (cyan) and its perineuronal net (PNN) (magenta) (d)
Synaptic and post synaptic bundles serial block face. Note that (a) and (c) represent highly magnified views
of the particular structures which would occur in biological samples such as those pictured in (b) and (d).
This illustrates that the electron microscope gives detailed imagery at spatial scales not visible through light
microscopy. As detailed in sections 1.1 and 1.2 below information flows back and forth between the
structures, illustrated in (a) and (c).

Figure 1 also illustrates the connection between information in the cell nucleus and information
processing in the brain. Recent investigations aimed at long lived proteins, localized by fluorescence
microscopy, has pointed toward the hypothesis that networks of long-lived proteins encapsulating
neurons, the perineuronal net (PNN) play a determining role in the formation of long-term memory.
Findings of a genetic role in abnormalities of the PNN, which lead to development of schizophrenia,
have recently attained wide coverage in news media [7,8]. Thus, readout of information of specific
genetic information in the DNA, should control changes in brain connection networks and information
processing in the brain. The verification of such findings would point toward a detailed and systematic
approach to investigation of information transmission within biological systems. Elucidation of the
mechanisms of information transfer constitutes an ongoing research problem in biological systems.
Beyond this, a systems approach to the issue of information in biological processes may well be
extended to the laboratory process as an information transmission system. For example, what
information, in the form of entropy, is propagated throughout our experimental procedures? Beyond
the conventional techniques of computer based tomographic reconstruction employed by biological
researchers, we would propose, as a modest beginning the investigation of entropy measures within
the Radon transform and its inversion. Admittedly, the wider biological connections may be tenuous
(although tantalizingly promising) at the moment, an examination of our computer processing in terms
of entropy and information, has and should continue to contribute new theoretical insights into the
mathematics of tomographic reconstruction and lead to new techniques in image processing.

652

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

1.1 Information in the cell nucleus
Genetic information storage and retrieval is localized to the cell nucleus, particularly DNA within
the nucleus. In 1953 Watson and Crick discovered that DNA forms a double helix [8], revealing not
only DNA’s long sought atomic structure but providing a scheme for our understanding of how
genetic information is stored and copied. However, the double helix captures only the first-order
structure of DNA. It is now clear that the biological functions and activity of DNA in our genomes
cannot be predicted by linear sequence information alone [9]. Within the nucleus DNA is wrapped
around nucleosomes to form chromatin that coils into domains which are thought to correlate with
cytoplasmic structures controlled by the information stored in the DNA. One major problem is how
genetic information embedded in the tightly coiled chromatin is made accessible for read-out. It is
evident that structural transformations of the chromatin determine when and how DNA can be
accessed and read [10,11,12]. However, the detailed structure and organization of chromatin has not
been visualized in situ, in intact cell nuclei. Accomplishing this extended characterization, across
spatial scales, is of fundamental importance.
Researchers at Salk Institute for Biological Studies and NCMIR (both in La Jolla) have developed
processes that combine the functions of fluorescent dye for light microscopy and an electron dense
stain for EM imaging of chromatin in the cell nucleus [13,14,15]. The TxBR package developed by
workers at NCMIR, including one of the authors of this paper, makes possible the reconstruction and
visualization of chromatin ultrastructure at high resolutions in intact nuclei (down to the structural
scale of protein assemblies) and in 3 dimensions using multi-tilt EM tomography (EMT)
[16,17,18,19]. This reconstruction software compensates for the optical irregularities of the electron
microscope, as well as sample degradation These techniques will enable researchers to map changes in
the chromatin and their association with transformations in portions of the metabolic network. In turn
this information may be correlated with biological structure observed through 3D tomographic
reconstruction. Figure 1, above, illustrates the structures involved in the regulation of connections in
brain tissue. All of these images are obtained by computer based tomographic and image processing
techniques developed at NCMIR and reported elsewhere.

1.2 Information in the perineuronal networks
It is well recognized that the understanding patterns of connection in the brain, is essential to
understanding how the brain works. Both memories and the processing of incoming sensory data are
encoded in this enormous graph of interconnections. For large scale dynamical networks statistical
techniques based on information and entropy afford valuable insights. One major problem in the study
of the brain is how these patterns of interconnection are formed. Currently, experiments designed to
test the hypothesis that life-long memories are stored as the pattern of holes in the perineuronal net
(PNN) [20] are being carried out in Roger Tsien’s lab at UCSD. Figure 1, above, shows a
reconstruction of the PNN, generated by semi-automatic segmentation [21], around a neuron, with
holes which permit synaptic connections. This is described in a recent publication [22]:
“The PNN is a specialized form of extracellular matrix deposited around selected neurons during
critical periods of development in specific parts of the brain. These developmental processes are
controlled by genetic information embedded in the cell nucleus. The PNN is interrupted by holes
where synapses occur. A current hypothesis is that the PNN is a long-lived structure and that new
memories are created by cutting new holes in the PNN or enlarging existing holes to enable formation
of new synapses or to strengthen existing ones. There is much circumstantial evidence implicating the
PNN in synaptic plasticity. If correct, the PNN would be something like an enormously convoluted
punch card, with information continuously being stored in the location and size of the interruptions in
its coverage of the neuron – what we are calling holes. A basic premise of this hypothesis is that the
bulk of the PNN, should not undergo metabolic renewal from the first age at which memories are

653

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

retained until senescence, whereas the active constituents of synapses turn over much more frequently
and would therefore be poorer substrates for permanent information storage. “
Our present understanding of information processing in the brain is based on models of molecular
conformational changes, as well as transport and signaling at the molecular level. As such these
processes are fundamentally probabilistic, so a study of entropy and information transformation on the
molecular level is appropriate. Electron microscopy also provides a valuable tool to the investigation
of the molecular dynamics involved in the basic biological processes. For example, electron
cryotomography [23] can aid in the analysis of state transitions of biological molecules in the cell by
direct 3D visualization. Networks of state transitions are fundamental objects in biology and computer
science. Because of the strong analogies between computation in man made systems and computation
in the brain, elucidation of the mechanisms for information storage in brain networks could also lead
to deeper understanding of the mathematics of information and information processing, as we will
argue below. As man made computational systems evolve to the exascale and error rates become
more significant probabilistic considerations such as those found in the biological sciences may
become much more important in the development of computer technology.

2 Information in tomography
We may argue that the concepts of information and entropy apply, in a fundamental way to the
study of biological systems through the techniques of 3D reconstruction as exemplified by electron
tomography. Both the biological systems under investigation and the tools which are applied during
these investigations may be viewed from an information-theoretic standpoint.
At present, electron tomography is not a monolithic field of study, but is comprised of a variety of
techniques, roughly associated with the spatial scales of interest, and the nature of the objects under
investigation [24]. Researchers commonly use different techniques for elucidating the structure of
small particles and microfilaments (nm scale) as opposed to the structure of cells and long range
structure, such as exhibited by axons and dendrites in neural tissue (mm scale). Nevertheless, all of
these systems exhibit probabilistic aspects, and information theory provides a common thread.
Detailed investigation of molecular structure in the context of the larger structure of organelles, cells
and cell assemblies in tissues is crucial to the resolution of many research problems in biology and
statistical issues arise in the passage from shorter to longer scales in both time and space.
Many applications of tomography to the study of biological systems involve big data. EM images
span spatial scales ranging from a fraction of a nm to about 50mm, and 3D EM reconstructions may
cover 1᪀⁄᪀1015 of the volume of a typical optical microscope reconstruction. The limit of resolution of
light microscopy is on the order of a 250nm, and even though super-resolution techniques applied in
fluorescence microscopy [1,2,3,4] may give much better resolution, rare events and contextual
information are missed. One example where reconstruction at multiple spatial scales is particularly
important occurs in the study of the nervous system, where structure and function are correlated from
the molecular level to the whole brain. Thus, in order to pass from the spatial scales accessible to light
microscopy to the spatial scales accessible to electron microscopy we must assemble huge data sets.
Computer processing of these data sets may require compressive sensing, which is based on the
systematic reduction of the size of data sets through the application of information theoretic concepts.
This problem of scaling also extends to the time domain.
Passing from the systems under investigation to the instrumentation and computer processing
employed in these investigations, it may be argued that electron microscopy has a fundamentally
probabilistic aspect itself.

654

Biological Systems Through the Informational Lens

x
x

x
x

A. Lawrence, T. Katchalski,... and M. Ellisman

The fundamental theory of the electron microscope is based on the electron, and quantum
mechanical interactions between electrons and the sample under investigation. Scattering
events are probabilistic, and contribute to various forms of background noise.
Ignoring quantum effects, mechanical uncertainties in position and angle of the sample make
the position and direction of the electron in the sample uncertain. This certainly apparent
when we try to calculate the parameters of paths through voxels in a discrete computer
model.
Instrument calibration drift makes the optics of the instrument uncertain at the resolutions
required for detailed investigation of cellular ultrastructure.
Sample mass loss due to interaction with energetic electrons causes progressive warping of
the sample as repeated observations are made, thus making the shape of the sample during
any particular observation uncertain.

These statistical uncertainties may be dealt with as separate problems in the development of 3D
reconstruction codes. This is certainly the case with our EM tomography code, TxBR, but a more
unified point of view has some advantages in the development of image processing tools.

3 Entropy and the Radon transform
Electron microscope images can be reduced to physical examples of Radon transforms. If we
ignore background noise, the single scattering model gives a simple interpretation of the intensity of
the beam at each point in the image. In particular each pixel of an electron microscope image
represents the probability of an electron traversing a path through the object and ending at that point
without scattering in from other paths. These paths are given by classical model of an electron
traveling through a magnetic field. In order to transform the data to a physical model consistent with
the Radon transform the image data is log-transformed. The log transform is the Burg entropy
associated with the path of the electron. In the subsequent section, we generalize this entropy by
means of some simple substitution of variables, and show that we can obtain representation of Renyi
entropy from the Radon transform. These manipulations are related to the construction of the Maslov
dequantization, and yield a family of one-parameter generalizations of the basic Radon transform.
In the subsequent section we examine the concept of entropy of an image, and introduce a concept
of local entropy. This is a consequence of our model of image data, which interprets the pointwise
image intensity as a probability, and differs from the usual definition of entropy as being determined
by the distribution of image intensities.

3.1 Maslov dequantization
We review the mathematical definition of Maslov dequantization, the relationship of the Radon
transform to Renyi entropy, and the mathematical axioms associated with desirable properties of
entropy. In particular, the complete set gives Shannon entropy. The expandibility axion gives the
property we require for a definition of local entropy.
Maslov dequantization has been treated in terms of thermodynamic semirings [26,27]. We may
start with entropy functions on two variables, ܵሺ‫݌‬ǡ ͳ െ ‫݌‬ሻ. This yields an addition ْβ,᪀S on the positive
real numbers
ଵ

‫ْ ݑ‬ఉǡௌ ‫ ݒ‬ൌ  ቄ‫ ݑ݌‬൅ ሺͳ െ ‫݌‬ሻ‫ ݒ‬െ ܵሺ‫݌‬ሻቅ ǡ ݂‫ ߚݎ݋‬൐ Ͳ.
௣

ఉ

(1)

If S is the Shannon entropy: ܵሺ‫݌‬ǡ ͳ െ ‫݌‬ሻ ൌ ‫ ݌‬ሺ‫݌‬ሻ ൅ ሺͳ െ ‫݌‬ሻ ሺͳ െ ‫݌‬ሻ, this operation becomes

655

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

ଵ

‫ْ ݑ‬ఉǡௌ ‫ ݒ‬ൌ െ ൫ሺെߚ‫ݑ‬ሻ ൅ ሺെߚ‫ݒ‬ሻ൯.
ఉ

(2)

ଵ

We drop the subscript S in this case, and write ‫ْ ݑ‬ఉ ‫ ݒ‬ൌ െ ൫ሺെߚ‫ݑ‬ሻ ൅ ሺെߚ‫ݒ‬ሻ൯.
ఉ

The construction of the twisted addition above can be extended to a map from the positive reals to
a semiring with this twisted addition [28]. In particular, apply a change of variables ‫ ݔ‬հ ‫ ݑ‬ൌ ߙ  ‫ݔ‬. In
this ring ‫ْ ݑ‬ఈ ‫ ݒ‬ൌ ߙ ൫݁‫݌ݔ‬ሺ‫ݑ‬Ȁߙሻ ൅ ݁‫݌ݔ‬ሺ‫ݒ‬Ȁߙሻ൯and ‫ٖ ݑ‬ఈ ‫ ݒ‬ൌ ‫ ݑ‬൅ ‫ݒ‬. We denote this map of ring
structures ‫ܯ‬ఈ . For the purpose of later discussion, we can make the variable change ߙ հ ͳȀߚ and
denote the resulting map ‫ܯ‬ఉ . If we take the limit α᪀→᪀0, we obtain an idempotent semiring ܴ௠௔௫ with
‫ ݒ ْ ݑ‬ൌ ݉ܽ‫ݔ‬ሼ‫ݑ‬ǡ ‫ݒ‬ሽ and ‫ ݒ ٖ ݑ‬ൌ ‫ ݑ‬൅ ‫ݒ‬. This is also called the tropical algebra, and the limiting
process is called the Maslov dequantization [27]. The semiring ܴ௠௔௫ is isomorphic to a semiring
ܴ௠௜௡ , which may be obtained by letting α᪀→᪀∞. In this ring, ‫ ݒ ْ ݑ‬ൌ ݉݅݊ሼ‫ݑ‬ǡ ‫ݒ‬ሽ. These semirings
were proposed in a general scheme of image processing which was termed image algebra, and
proposed for its applications in electron microscopy by Peter Hawkes [29], before the current wave of
interest on the part of algebraic geometers.

3.2 Renyi entropy
In this section we relate possible definitions of local entropy to the Radon transform. The
expression for Renyi entropy originates in the work of Alfred Renyi [30], who proposed a measure of
information, ‫ܫ‬, which is compatible with the laws of probability, and which is additive for independent
events. In particular, if p and q are independent events ‫ܫ‬ሺ‫ݍ݌‬ሻ ൌ ‫ܫ‬ሺ‫݌‬ሻ‫ܫ‬ሺ‫ݍ‬ሻ. Using Hartley’s information
content ‫ܫ‬ሺ‫݌‬ሻ ൌ ሺ‫݌‬ሻ up to a multiplicative constant leads to the Shannon entropy of a set of events
ሺ‫ݔ‬ଵ ǡ ‫ݔ‬ଶ ǡ ‫ ڮ‬ǡ ‫ݔ‬௡ ሻ with probabilities ሺ‫݌‬ଵ ǡ ‫݌‬ଶ ǡ ‫ ڮ‬ǡ ‫݌‬௡ ሻ,
ܵሺܲሻ ൌ σ௜ୀ௡
(3)
௜ୀଵ ‫݌‬௜ ሺ‫݌‬௜ ሻ.
As Renyi observed other measures consistent with the requirements are possible. More generally,
ଵ
ఈ
൫σ௜ୀ௡
(4)
ܵఈ ሺܲሻ ൌ
௜ୀଵ ሺ‫݌‬௞ ሻ൯.
ଵିఈ
An example of an entropy measure in tomography may be found in the preprocessing of X-ray or
EM data. Recall that the underlying physical model for EMT or X-ray tomography is a classical single
scattering process in an object with physical scattering density ‫ݑ‬ሺܺǡ ܻǡ ܼሻ examined by a beam with
initial intensity ‫ܫ‬௜ . We assume a family of trajectories, each associated with an angle and a point on an
image. We assume also that the trajectories are continuous and those associated with a given angle are
topologically dense and non-intersecting in the object. In particular, each image is taken of the sample
rotated by θ, which can represent a single angle along an arc or a pair of angles on a sphere.
(5)
Ȟఏǡ௫ǡ௬ ሺ‫ݏ‬ሻ ൌ ቀߛଵǢఏǡ௫ǡ௬ ሺ‫ݏ‬ሻǡ ߛଶǢఏǡ௫ǡ௬ ሺ‫ݏ‬ሻǡ ߛଷǢఏǡ௫ǡ௬ ሺ‫ݏ‬ሻቁ
The beam intensity ‫ܫ‬௢௨௧ at image point ሺ‫ݔ‬ǡ ‫ݕ‬ሻ of the image at angle θ is given by the exponential of
integral along the trajectory Ȟሺఏǡ௫ǡ௬ሻ through the exit point:
‫ܫ‬௢௨௧ ሺߠǡ ‫ݔ‬ǡ ‫ݕ‬ሻ ൌ ‫ܫ‬௜௡ ൫െ ‫ݑ ׬‬൫Ȟሺఏǡ௫ǡ௬ሻ ሺ‫ݏ‬ሻ݀‫ݏ‬൯൯.
(6)
We can pass to the pixel discretization of the object and set of images and the object and write
‫ܫ‬௢௨௧ ሺߠǡ ‫ݔ‬௜ ǡ ‫ݕ‬௜ ሻ ൌ ‫ܫ‬௜௡ ς ൬െ‫ ݑ‬ቀȞሺఏǡ௫೔ ǡ௬೔ሻ ൫‫ݏ‬ఏǡ௜ǡ௝ǡ௞ ൯ቁ൰

(7)

In this discretization the pixel discretization is regular and the values ‫ݏ‬ఏǡ௜ǡ௝ǡ௞ are chosen so that the
points along the trajectory fall once into each voxel in the object through which the trajectory passes.
In order to apply the theory of the radon transform we take the log of ‫ܫ‬௢௨௧ . This gives
 ‫ܫ‬௢௨௧ ሺߠǡ ‫ݔ‬௜ ǡ ‫ݕ‬௜ ሻ ൌ  ‫ܫ‬௜௡ ൅ σ   ൬െ‫ ݑ‬ቀȞሺఏǡ௫೔ǡ௬೔ሻ ൫‫ݏ‬ఏǡ௜ǡ௝ǡ௞ ൯ቁ൰ ൌ  ‫ܫ‬௜௡ െ σ ‫ ݑ‬ቀȞሺఏǡ௫೔ǡ௬೔ሻ ൫‫ݏ‬ఏǡ௜ǡ௝ǡ௞ ൯ቁ. (8)
Assuming beam intensity is set to unity and scattering densities are normalized along each
trajectory the right hand quantity is Burg entropy. In order to simplify the discussion, we set
െ‫ ݑ‬ቀȞሺఏǡ௫೔ ǡ௬೔ሻ ൫‫ݏ‬ఏǡ௜ǡ௝ǡ௞ ൯ቁ ൌ ‫ݑ‬ఏǡ௜ǡ௝ǡ௞ . We can map each density ‫ݑ‬ఏǡ௜ǡ௝ǡ௞ into a particular voxel represented

656

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

by a scattering value ‫ݑ‬௜௝௞ and reinterpret ‫ݑ‬௜௝௞ probabilistically in terms of a distribution of atomic
scatterers. Along each trajectory, we can apply the Maslov map ‫ܯ‬ఉ where we make the variable
ଵ
change ‫ݑ‬ఏǡ௜ǡ௝ǡ௞ ฽ ߚ  ‫ݒ‬ఏǡ௜ǡ௝ǡ௞ and σ ‫ݑ‬ఏǡ௜ǡ௝ǡ௞ ฽  σ ݁‫݌ݔ‬൫ߚ‫ݒ‬ఏǡ௜ǡ௝ǡ௞ ൯.
ఉ

where the sum is along the trajectory. Noting that ݁‫݌ݔ‬ሺߚ‫ݔ‬ሻ ൌ ሺሺ‫ݔ‬ሻሻఉ , and writing
ଵ

ఉ

݁‫݌ݔ‬൫‫ݒ‬ఏǡ௜ǡ௝ǡ௞ ൯ ൌ ‫݌‬ఏǡ௜ǡ௝ǡ௞ we obtain the formal expression  σ൫‫݌‬ఏǡ௜ǡ௝ǡ௞ ൯ , which within a factor of
ఉ

ఉ
ଵିఉ

corresponds to Renyi entropy along the trajectory.

3.3 Renyi divergence
In order to extend the idea of entropy to the Radon transform, we must develop a more local
concept of entropy. Our definition of local information or information at a point is given as the change
of entropy when we remove the point in question from our probability distribution [31]. This notion
may be formalized in a manner similar to the treatment of Theiler [32]. Entropy at a point ‫ݔ‬ఏǡ௞ǡ௟ of the
θth image in an image series or a point ‫ݔ‬௜ǡ௝ǡ௞ in a volume, may regarded in either of two ways. The first
definition can be taken the difference between the total entropy of the image or some fixed subset of
pixels surrounding the point in question and the entropy of the set with the pixel in question removed.
This procedure is valid if we assume our definition of entropy satisfies the axiom of extensibility [26].
Another definition, consistent with the concept of Renyi divergence is to take the quotient. Both will
generate quantities, which can be regarded as information measures.
If we assume the expandability axiom above, we can define a new distribution,
௣ഇǡ೔ǡೕ
ሺ݅ǡ ݆ሻ ് ሺ݇ǡ ݈ሻ
ଵି௣
ഇǡೖǡ೗
(9)
‫ݍ‬ఏǡ௜ǡ௝Ǣ௞ǡ௟ ൌ ൝
Ͳሺ݅ǡ ݆ሻ ൌ ሺ݇ǡ ݈ሻ
then
ଵ
ఈ
ఈ
ఈିଵ
ൌ
൫σ௜ǡ௝ ‫ݍ‬ఏǡ௜ǡ௝Ǣ௞ǡ௟
Ȁ‫݌‬ఏǡ௜ǡ௝
൯,
(10)
‫ܦ‬ఏǡ௞ǡ௟
ଵିఈ
is the pointwise divergence image. We can treat this as a “probability” image by normalization. A
three dimensional volume can be treated similarly.
We may generalize this definition. A third alternative, which may be adopted for numerical
reasons, is to cover the image or a structure within the image by small boxes, each centered on a point
‫ݔ‬௞ǡ௟ . We may renormalize probabilities within each box to sum to 1 and perform the entropy
calculations with respect to each box separately. For purposes of illustration, we show the results of
this procedure in Figure 2, below. This is a variant of the fractal dimension calculation described in
[31]. Figure 2 shows a local entropy transform of an EM image and a section of the backprojection of
a tilt series modified by local entropy transforms.

657

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

Figure 2: (a) Tomogram generated from Renyi-difference images. (b) Original Tomogram. (c) Zoom x8
of subfigure a, approx. at the position of the red box. (d) Zoom x8 of subfigure b, approx. at the position of
the red box. All tomograms displayed in the same window 155-200. (e) A sample of image difference at zero
tilt between the Renyi difference image and the original image used to reconstruct the tomograms. (Thanks
to Guy Perkins, NCMIR for this data set.)

4 Conclusions
The information-theoretic viewpoint has been successful in reducing noise in images, improving
image sharpness, and detecting the dimensionality of image data. Maximum entropy methods
constitute a large class of iterative methods in image processing. Also, a statistical approach is
appropriate, for fundamental physical reasons. Beyond the random aspects of staining at the shortest
spatial scales, the large field images in the biological samples under study by electron microscopy are
actually images derived from electron scattering probabilities within the sample. Furthermore, the
imaging process is subject to noise generated by additional scattering in the sample, positioning,
random degradation and warping of the sample, and random errors in the detectors. For these reasons,
information theoretic techniques are appropriate. On a more fundamental level we have also shown
that the Radon transform can be interpreted in terms of Renyi entropy.

658

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

In order to gauge the information loss in our data processing, the entropy or information of an
image may be calculated. To make entropy considerations more consistent with the implicit
transforms in ET and the algorithms employed in the solution of the inverse problem, we have also
demonstrated the calculation the entropy at a point in the image and that these entropy calculations
work well with the inversion of the Radon transform. was accomplished by calculating the change of
entropy when the data for the point in question is omitted from the calculation. This idea can also be
employed through the use of realistic phantoms produce new images or density functions of phantom
volumes which may be compared to the original data. A practical objective of this work is the
improvement of the resolution of our tomographic reconstructions by improving the detection of sharp
gradients in our images. Improvement of resolution provides necessary information for the biological
research. For example, a factor of two improvement over present techniques is necessary obtaining
isotopic resolutions consistent with the spatial scale of chromatin filaments. This in turn will aid in
the task of following chromatin filaments throughout their convolutions within the cell nucleus and
correlating changes in structure with biological activity. The issue here is whether statistical
uncertainties limit resolution in a fundamental way. For example, it has been shown that for some
physical systems, entropy is subject to a fundamental uncertainty relation.

5 Further Work
At present there are possible several directions for further work. Although we would like a version
of the Radon transform and its inverse in the semiring described above, further mathematical
development is necessary. In particular, we need constructions analogous to the filtration and
backprojection. Convolution filtration, for example could be computed via a generalization of the
divergence formula above, where negative coefficients contribute to the numerator and negative
coefficients contribute to the denominator of the quotient inside the summation. We might guess that
Renyi divergence and the twisted addition under the Maslov isomorphism Mβ would give interesting
results, but the formulas are complicated, and numerical experiments might better serve our purpose.
We also have the standard Radon transform on a 3D object, which gives a series of 2D images. We
can define the local entropy transform of the object as well as the local entropies of the 2D images.
One issue is whether some reconstruction algorithm can produce the 3D entropy transformed object
from the 2D entropy transformed images.
We have, however, outlined the construction of several tools which could give us information
measures relevant to the performance of our algorithms. The easiest case would be the evaluation of
information loss under various experimental conditions. If we specialize Renyi entropy to the case
α᪀=᪀1 we recover Shannon entropy, which is defined above. The additivity axiom for Shannon entropy
gives us a relatively simple expression to work with. For example, it is easy to see how missing tilts
would lead to a reduction of information in the reconstruction. We need all possible tilts in order to
define a forward transform which gives enough data for a perfect reconstruction, i.e., to make the
forward transform nonsingular [1]. Applying the formula to the images in the tilt series, we see that we
are missing projection terms which would contribute to the entropy, and so the inverse transform
could not restore that information. It is also possible to distinguish between loss of information due to
discretization and loss of information due to missing directions in a particular discretization.
With the use of phantom data, and a good model of imaging in the electron microscope we can
make further comparisons. For example, Renyi divergence applied pointwise, as described above,
gives us a means to compare a reconstruction and the original phantom data, point by point. This
would tell us which features are best preserved in an information theoretic sense. Other applications of
Renyi entropy are the estimation of fractal dimension through adaptation of a box-counting form of
the entropy expression [32].

659

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

There are also a number of theoretical issues relating to the application of cryotomography to
conformational changes in protein structures. On the physical side EM tomography of single particles
(molecular structure) can be regarded as the theory of scattering of electrons from a many-body
system. There is a well-developed theory, which describes the target system in terms of density
matrices. The radon transform on the density matrix gives the Wigner distribution function, which is
analogous to classical probability. If we take the incoming electron plus the molecular system all into
account we are able to build up pictures of the molecular states from observation of each electron after
it exits. The electron microscope gives us statistical averages of many interactions.
At present we can reconstruct more or less stable conformational states from particle
tomography. The forward problem is the prediction of molecular states and the images they present in
the electron microscope. The inverse problem is inferring the Wigner distribution function from
tomographic reconstructions. In particular we want reconstruct from the coordinates of the exiting
electrons.

References
[1] Baez J, Fritz T and Leinster T. A Characterization of Entropy in Terms of Information Loss.
Entropy 2011, 13(11), 1945-1957. doi:10.3390/e13111945.
[2] Scherer N F. Imaging-pointillist microscopy. Nature Nanotechnology 1, 19 - 20 (2006)
doi:10.1038/nnano.2006.79.
[3] Betzig E. Single molecules, cells and super-resolution optics. Rev. Mod. Phys. 87:1153-68 (2016).
[4] Hell S F. Nanoscopy with freely propagating light. Rev. Mod. Phys. 87:1169-82 (2016).
[5] Morner W E. Single-molecule spectroscopy, imaging and photocontrol: Foundations for superresolution microscopy. Rev. Mod. Phys. 87:1169-1213 (2016).
[6] Lawrence A, Bouwer J C, Perkins G and Ellisman M H. Transform-based backprojection for
volume reconstruction of large format electron microscope tilt series. JSB, 154:144–167. (2006).
[7] Berretta S, Pantazopoulos H, Markota M, Brown C, Batzianouli E T. Losing the sugar coating:
potential impact of perineuronal net abnormalities on interneurons in schizophrenia. Schizophr.
Res. 2015. Sep;167(1-3):18-27. doi: 10.1016/j.schres.2014.12.040. Epub 2015 Jan 16.
[8] Sekar A, Bialas A R, de Rivera H, Davis A, Hammond T R, Kamitaki N, Tooley K, Presumey J,
Baum M, Van Doren V, Genovese G, Rose S A, Robert E. R E, Daly M J, Carroll M C, Stevens B
and McCarroll S A. Schizophrenia risk from complex variation of complement component 4.
Nature (2016) doi:10.1038/nature16549.
[9] Watson JD, Crick FH. Molecular structure of nucleic acids; a structure for deoxyribose nucleic
acid. Nature. 1953;171(4356):737-8. PubMed PMID: 13054692.
[10] Misteli T. The cell biology of genomes: bringing the double helix to life. Cell. 2013;152(6):120912. doi: 10.1016/j.cell.2013.02.048. PubMed PMID: 23498929.
[11] Woodcock CL, Ghosh RP. Chromatin higher-order structure and dynamics. Cold Spring Harb
Perspect Biol. 2010;2(5):a000596. Epub 2010/05/11. doi: cshperspect.a000596 [pii]
10.1101/cshperspect.a000596. PubMed PMID: 20452954; PMCID: 2857170.
[12] Bickmore WA, van Steensel B. Genome architecture: domain organization of interphase
chromosomes. Cell. 2013;152(6):1270-84. doi: 10.1016/j.cell.2013.02.001. PubMed PMID:
23498936.
[13] Shu X, Lev-Ram V, Deerinck TJ, Qi Y, Ramko EB, Davidson MW, Jin Y, Ellisman MH, Tsien
RY. A genetically encoded tag for correlated light and electron microscopy of intact cells, tissues,
and
organisms.
PLoS
Biol.
2011;9(4):e1001041.
Epub
2011/04/13.
doi:
10.1371/journal.pbio.1001041. PubMed PMID: 21483721; PMCID: PMC3071375

660

Biological Systems Through the Informational Lens

A. Lawrence, T. Katchalski,... and M. Ellisman

[14] Bentivoglio M, Su HS. Photoconversion of fluorescent retrograde tracers. Neuroscience letters.
1990;113(2):127-33. PubMed PMID: 1695999.
[15] Deerinck TJ, Martone ME, Lev-Ram V, Green DP, Tsien RY, Spector DL, Huang S, Ellisman
MH. Fluorescence photooxidation with eosin: a method for high resolution immunolocalization
and in situ hybridization detection for light and electron microscopy. J Cell Biol.
1994;126(4):901-10. PubMed PMID: 7519623; PMCID: 2120127.
[16] Mastronarde DN. Dual-axis tomography: an approach with alignment methods that preserve
resolution. J Struct Biol. 1997;120(3):343-52. doi: 10.1006/jsbi.1997.3919. PubMed PMID:
9441937.
[17] Ellisman MH, Boassa D, Nguyen P, Wan X, Lawrence A, Lanman J, Phan S. Automated
Procedures for the Alignment and Reconstruction of Multiple Tilt Electron Microscopic
Tomography Data. Microscopy and Microanalysis. 2014;20(SupplementS3):1258-9. doi:
doi:10.1017/S1431927614008022.
[18] Phan S, Lawrence A, Molina T, Lanman J, Berlanga M, Terada M, Kulungowski A, Obayashi J,
Ellisman M. TxBR montage reconstruction for large field electron tomography. J Struct Biol.
2012;180(1):154-64. doi: 10.1016/j.jsb.2012.06.006. PubMed PMID: 22749959.
[19] Wan X, Phan S, Lawrence A, Zhang F, Han R, Liu Z, Ellisman M H. Iterative Methods in Large
Field Electron Microscope Tomography. SIAM Journal on Scientific Computing. 2013;
35(5):S402-S19. doi: doi:10.1137/120881464.
[20] Tsien, Roger Y. Very long-term memories may be stored in the pattern of holes in the
perineuronal net. PNAS 2013 110 (30) 12456-12461. doi:10.1073/pnas.1310158110.
[21] Perez, A.J., Seyedhosseini, M., Deerinck, T.J. Bushong E.A., Panda, S., Tasdizen, T., and
Ellisman, M.H. (2013). A workflow for the automatic segmentation of organelles in electron
microscopy image stacks. Front. Neuroanat., 8(126).
[22] Lev-Ram, Varda, Bushong, E A, Deerinck, Thomas J, Palida, S F, Taliman, K M, Savas, J N,
Toyama, B H, Hakozaki, H, Yates, J R, Ellisman, M H, and Tsien R Y. Are very long-term
memories stored in the pattern of holes in the perineuronal net? SFN Chicago. October 17-21.
2015.
[23] Kühlbrandt, W., Cryo-EM Enters a New Age, eLife 2014;3:e03678
[24] Frank J, Electron Tomography Second Edition. Springer-Verlag New York, N Y. (2006).
[25] Borwein J M. Maximum entropy and feasibility methods for convex and nonconvex inverse
problems. Optimization: A Journal of Mathematical Programming and Operations Research, 61:133 (2012). DOI: 10.1080/02331934.2011.632502.
[26] Marcolli M and Tedeschi N. Entropy Algebras and Birkhoff Factorization. (2014)
arXiv:1412.0247 [math.QA]
[27] Marcolli M. Information Algebras and Their Applications, in Geometric Science of Information,
Second International Conference, GSI 2015 Palaiseau, France, October 28–30. pp 271-6. (2015).
[28] Litvinov G. The Maslov Dequantization, Idempotent and Tropical Mathematics: a Very Brief
Introduction. (2005). arXiv:math/0501038 [math.GM].
[29] Hawkes P. Image Algebra for Electron Images. Microscopy Microanalysis Microstructures
04/1995; 6(2):159-177. DOI: 10.1051/mmm:1995116.
[30] Rényi A. (1961). "On measures of information and entropy" (PDF). Proceedings of the fourth
Berkeley Symposium on Mathematics, Statistics and Probability 1960. pp. 547–561 (1961).
[31] Rychtarikova, R., Korbel, J., Machacek, P., Cısar, P., Urban J., Soloviov, D. and Stys, D., Point
information Gain, Point Information Gain Entropy and Point Information Gain Entropy Density
as Measures of Semantic and Syntactic information of Multidimensional Discrete Phenomena,
arXiv:1501.02891v4, 24 Mar 2015.
[32] Theiler J. Estimating Fractal Dimension. Journal of the Optical Society of America A Vol. 7,
Issue 6, pp. 1055-1073 (1990) doi: 10.1364/JOSAA.7.001055.

661

