What Makes the
Arc-Preserving Subsequence Problem Hard?
Guillaume Blin1 , Guillaume Fertin1 , Romeo Rizzi2 , and St´ephane Vialette3

2

1
LINA - FRE CNRS 2729 Universit´e de Nantes,
2 rue de la Houssini`ere BP 92208 44322 Nantes Cedex 3 - France
{blin, fertin}@univ-nantes.fr
Universit`
a degli Studi di Trento Facolt`
a di Scienze - Dipartimento di Informatica e
Telecomunicazioni
Via Sommarive, 14 - I38050 Povo - Trento (TN) - Italy
Romeo.Rizzi@unitn.it
3
LRI - UMR CNRS 8623 Facult´e des Sciences d’Orsay, Universit´e Paris-Sud
Bˆ
at 490, 91405 Orsay Cedex - France
vialette@lri.fr

Abstract. Given two arc-annotated sequences (S, P ) and (T, Q) representing RNA structures, the Arc-Preserving Subsequence (APS)
problem asks whether (T, Q) can be obtained from (S, P ) by deleting
some of its bases (together with their incident arcs, if any). In previous studies [3, 6], this problem has been naturally divided into subproblems reﬂecting intrinsic complexity of arc structures. We show that
APS(Crossing, Plain) is NP-complete, thereby answering an open
problem [6]. Furthermore, to get more insight into where actual border
of APS hardness is, we reﬁne APS classical subproblems in much the
same way as in [11] and give a complete categorization among various
restrictions of APS problem complexity.
Keywords: RNA structures, Arc-Preserving Subsequence, Computational complexity.

1

Introduction

At a molecular state, the understanding of biological mechanisms is subordinated to RNA functions discovery and study. Indeed, it is established that the
conformation of a single-stranded RNA molecule (a linear sequence composed of
ribonucleotides A, U , C and G, also called primary structure) partly determines
the molecule function. This conformation results from the folding process due
to local pairings between complementary bases (A − U and C − G). The RNA
secondary structure is a collection of folding patterns that occur in it.
RNA secondary structure comparison is important in many contexts, such as
(i) identiﬁcation of highly conserved structures during evolution which suggest
a signiﬁcant common function for the studied RNA molecules [9], (ii) RNA
This work was partially supported by the French-Italian PAI Galileo project number
08484VH and by the CNRS project ACI Masse de Donn´ees ”NavGraphe”.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 860–868, 2005.
c Springer-Verlag Berlin Heidelberg 2005

What Makes the Arc-Preserving Subsequence Problem Hard?

861

classiﬁcation of various species (phylogeny)[2], (iii) RNA folding prediction by
considering a set of already known secondary structures [13].
Structure comparison for RNA has thus become a central computational
problem bearing many challenging computer science questions. At a theoretical
level, RNA structure is often modelled as an arc-annotated sequence, that is a
pair (S, P ) where S is a sequence of ribonucleotides and P represents hydrogen bonds between pairs of elements of S. Diﬀerent pattern matching and motif
search problems have been investigated in the context of arc-annotated sequences
among which we can mention Arc-Preserving Subsequence (APS) problem,
Edit Distance problem, Arc-Substructure (AST) problem and Longest
Arc-Preserving Subsequence (LAPCS) problem (see for instance [3, 8, 7, 6,
1]). For other related studies concerning algorithmic aspects of (protein) structure comparison using contact maps, refer to [5, 10].
In this paper, we focus on APS problem: given two arc-annotated sequences
(S, P ) and (T, Q), this problem asks whether (T, Q) can be exactly obtained
from (S, P ) by deleting some of its bases together with their incident arcs, if
any. This problem is commonly encountered when one is searching for a given
RNA pattern in an RNA database [7]. Moreover, from a theoretical point of
view, APS problem can be seen as a restricted version of LAPCS problem, and
hence has applications in structural comparison of RNA and protein sequences
[3, 5, 12]. APS problem has been extensively studied in the past few years [6, 7,
3]. Of course, diﬀerent restrictions on arc-annotation alter APS computational
complexity, and hence this problem has been naturally divided into subproblems
reﬂecting the complexity of the arc structure of both (S, P ) and (T, Q): plain,
chain, nested, crossing or unlimited (see Section 2 for details). All of them
but one have been classiﬁed as to whether they are polynomial time solvable or
NP-complete. The problem of the existence of a polynomial time algorithm for
APS(Crossing,Plain) problem was mentioned in [6] as the last open problem
in the context of arc-preserving subsequences. Unfortunately, as we shall prove
in Section 4, APS(Crossing,Plain) is NP-complete even for restricted special
cases.
In analyzing the computational complexity of a problem, we are often trying to deﬁne a precise boundary between polynomial and NP-complete cases.
Therefore, as another step towards establishing the precise complexity landscape
of APS problem, we consider that it is of great interest to subdivide existing
cases into more precise ones, that is to reﬁne classical complexity levels of APS
problem, for determining more precisely what makes the problem hard. For that
purpose, we use the framework introduced by Vialette [11] in the context of 2intervals (a simple abstract structure for modelling RNA secondary structures).
As a consequence, the number of complexity levels rises from 4 to 8, and all the
entries of this new complexity table need to be ﬁlled. Previous known results
concerning APS problem, along with our NP-completeness proofs, allow us to
ﬁll all the entries of this new table, therefore determining what exactly makes
the APS problem hard.

862

G. Blin et al.

The paper is organized as follows. Provided with notations and deﬁnitions
(Section 2), in Section 3 we introduce and explain new reﬁnements of the complexity levels we are going to study. In Section 4, we show that APS({ , }, ∅)
is NP-complete thereby proving that classical APS(Crossing, Plain) is NPcomplete as well. As another reﬁnement to that result, we prove that APS({<,
}, ∅) is NP-complete. Finally, in Section 5, we give new polynomial time solvable
algorithms for restricted instances of APS(Crossing, Plain).

2

Preliminaries

An RNA structure is commonly represented as an arc-annotated sequence (S, P )
where S is a sequence of ribonucleotides (or bases) and P is a set of arcs connecting pairs of bases in S. Let (S, P ) and (T, Q) be two arc-annotated sequences
such that |S| ≥ |T | (in the following, n = |S| and m = |T |). APS problem asks
whether (T, Q) can be exactly obtained from (S, P ) by deleting some of its bases
together with their incident arcs, if any.
Since the general problem is easily seen to be intractable [3], the arc structure
must be restricted. Evans [3] proposed four possible restrictions on P (resp. Q)
which were largely reused in subsequent literature: (1) there is no base incident
to more than one arc, (2) there are no arcs crossing, (3) there is no arc contained
in another and (4) there is no arc.
These restrictions are used progressively and inclusively to produce ﬁve different levels of allowed arc structure: Unlimited - general problem with no restrictions, Crossing - restriction (1); Nested - restrictions (1) and (2); Chain
- restrictions (1), (2) and (3); Plain - restriction (4).
Guo proved in [7] that APS(Crossing, Chain) is NP-complete. Guo et
al. observed in [6] that NP-completeness of APS(Crossing, Crossing) and
APS(Unlimited, Plain) easily follows from results of Evans [3] concerning
LAPCS problem. Furthermore, they gave a O(nm) time algorithm for APS
(Nested, Nested). This algorithm can be applied to easier problems such as
APS(Nested, α) and APS(Chain, α) with α ∈ {Chain,Plain}. Finally, Guo
et al. mentioned in [6] that APS(Chain, Plain) can be solved in O(n+m) time.
Observe that Unlimited level has no restrictions, and hence is of limited interest
in our study. Consequently, from now on we will not be concerned anymore
with that level. Until now, the question of the existence of an exact polynomial
algorithm for APS(Crossing, Plain) remained open. We will show in the
present paper that APS(Crossing,Plain) is NP-complete.

3

Refinement of APS Problem

In this section, we propose a reﬁnement of APS problem. We ﬁrst state formally
our approach and explain why such a reﬁnement is relevant for both theoretical
and experimental studies.

What Makes the Arc-Preserving Subsequence Problem Hard?

3.1

863

Splitting the Levels.

As we will show soon, APS(Crossing, Plain) is NP-complete. That result
answers the last open problem concerning APS computational complexity with
respect to classical complexity levels. However, we are mainly interested in the
elaboration of a precise border between NP-complete and polynomially solvable
cases. Indeed, both theorists and practitioners might naturally ask for more information concerning APS hard cases in order to get valuable insight into what
makes the problem diﬃcult. As a next step towards better understanding what
makes APS problem hard, we propose to reﬁne classically models used for classifying arc-annotated sequences. Our reﬁnement consists in splitting those models
of arc-annotated sequences into more precise relations between arcs. For example, such a reﬁnement provides a general framework for investigating polynomial
time solvable and hard restricted instances of APS(Crossing, Plain), thereby
reﬁning in many ways Theorem 1 (see Section 5).
We use three relations ﬁrst introduced by Vialette [11] in the context of 2intervals. Actually, his deﬁnition of 2-intervals could almost apply in this paper
(the main diﬀerence lies in the fact that 2-intervals are used for representing sets
of contiguous arcs). Vialette deﬁned three possible relations between 2-intervals
that can be used for arc-annotated sequences as-well. They are the following:
for any two arcs A1 = (i, j) and A2 = (k, l) in P , we will write A1 < A2 if
i < j < k < l (precedence relation), A1 A2 if k < i < j < l (nested relation)
and A1 A2 if i < k < j < l (crossing relation). Two arcs A1 and A2 are
τ -comparable for some τ ∈ {<, , } if A1 τ A2 or A2 τ A1 . Let P be a set of arcs
and R be a non-empty subset of {<, , }. The set P is said to be R-comparable
if any two distinct arcs of P are τ -comparable for some τ ∈ R. An arc-annotated
sequence (P, A) is said to be an R-arc-annotated sequence for some non-empty
subset R of {<, , } if A is R-comparable. By abuse of notation, we write R = ∅
in case A = ∅. Observe that our model cannot deal with arc-annotated sequences
which contain only one arc. However, having only one arc or none can not really
aﬀect the problem computational complexity. Just one guess reduces from one
case to the other.
As a straightforward illustration of above deﬁnitions, classical complexity
levels for APS problem can be expressed in terms of combinations of our new
relations: Plain is fully described by R = ∅, Chain by R = {<}, Nested
by R = {<, } and Crossing by R = {<, , }. The key point is to observe
that our reﬁnement allows us to consider new structures for arc-annotated sequences, namely R ∈ {{ }, { }, {<, }, { , }}, which could not be considered
using classical complexity levels. Although other reﬁnements may be possible (in
particular well-suited for parameterized complexity analysis), we do believe that
such an approach allows a more precise analysis of APS complexity. Of course
one might object that some of these subdivisions are unlikely to appear in RNA
secondary structures. However, it is of great interest to answer, at least partly,
the following question: Where is the precise boundary between polynomial and
NP-complete cases ? Indeed, such a question is relevant for both theoretical and
experimental studies.

864

G. Blin et al.

3.2

Immediate Results

First, observe that we only have to consider cases of APS(R1 ,R2 ) where R1
and R2 are compatible, i.e. R2 ⊆ R1 . Indeed, if this is not the case, we can
immediately answer negatively since there exists two arcs in T which satisfy a
relation in R2 which is not in R1 , and hence T simply cannot be obtained from S
by deleting bases of S. Those useless cases are simply denoted by hatched areas
in Table 1.
Some known results allow us to ﬁll many entries of the new complexity table
derived from our reﬁnement. The remainder of this subsection is devoted to detailing these ﬁrst easy statements. We begin with an easy observation concerning
complexity propagation properties of APS problem.
Observation 1 Let R1 , R2 , R1 and R2 be four subsets of {<, , } such that
R2 ⊆ R2 ⊆ R1 and R2 ⊆ R1 ⊆ R1 . If APS(R1 , R2 ) is NP-complete (resp.
APS(R1 , R2 ) is polynomial time solvable) then so is APS(R1 , R2 ) (resp.
APS(R1 , R2 )).
On the positive side, Guo et al. have shown that APS(Nested, Nested) is
solvable in O(nm) time [6]. Another way of stating this is to say that APS({<
, }, {<, }) is solvable in O(mn) time. That result together with Observation 1
may be summarized by saying that APS(R1 , R2 ) for any compatible R1 and
R2 such that ∈
/ R1 and ∈
/ R2 is polynomial time solvable.
Conversely, Evans has proved that APS(Crossing,Crossing) is NP-complete
[3]. A simple reading shows that her proof is concerned with {<, , }-arcannotated sequences, and hence she actually proved that APS({<, , }, {<,
, }) is NP-complete. Similarly, in proving that APS(Crossing,Chain) is NPcomplete [7], Guo actually proved that APS({<, , }, {<}) is NP-complete.
Note that according to Observation 1, this latter result implies that APS({<
, , }, {<, }) and APS({<, , },{<, }) are NP-complete. Table 1 surveys
known and new results for various types of our reﬁned APS problem. Observe
that this paper answers all questions concerning APS problem with respect to
both classical and new complexity levels.
Table 1. Complexity results after complexity levels reﬁnement. ////: useless cases. :
results from this paper.
APS
R1 \ R2 {<,

, } { , }

{<, , } NP-C [3] NP-C
{ , }
NP-C
{<, }
{ }
{<, }
{ }
{<}
∅

{<, }

{ }

NP-C [7] NP-C
////
NP-C
NP-C
NP-C
O(nm2 )

{<,

}

NP-C [7]
////
////
////

{ }
NP-C
NP-C
////
////

{<}
NP-C [7]
////
NP-C
////

∅
NP-C
NP-C
NP-C
O(nm2 )

O(nm) [6] O(nm) [6] O(nm) [6] O(nm) [6]
O(nm) [6]
////
O(nm) [6]
O(nm) [6] O(n+m) [6]
O(n+m) [6]

What Makes the Arc-Preserving Subsequence Problem Hard?

4

865

Hardness Results

We show in this section that APS({ , }, ∅) and APS({<, }, ∅) are NP-complete
thereby proving that APS(Crossing, Plain) is NP-complete. That result answers an open problem posed by Gramm, Guo and Niedermeier in [6] which is the
last open problem concerning the APS computational complexity with respect
to classical complexity levels, i.e., Plain, Chain, Nested and Crossing.
Theorem 1. APS({ , }, ∅) is NP-complete.
We prove Theorem 1 by giving a polynomial time reduction from the well known
NP-complete 3-Sat problem [4]. Due to space considerations, the entire proof
is deferred to the full version of the paper.
It follows immediately from Theorem 1 that APS({<, , }, ∅), and hence
APS(Crossing, Plain), are NP-complete. One might naturally ask for more
information concerning hard cases of APS problem in order to get valuable
insight into what makes the problem diﬃcult. Another reﬁnement of the hardness
of APS(Crossing,Plain) is given by the following theorem.
Theorem 2. APS({<, }, ∅) is NP-complete.
The proof is also by reduction from 3-Sat. Due to space considerations, the
rather technical proof is also deferred to the full version of the paper.

5

Two Polynomial Time Solvable APS Problems

We prove in this section that APS({ }, ∅) and APS({ },{ }) are polynomial
time solvable. In other words, relation alone does not imply NP-completeness.
We need the following notations. Sequences are the concatenation of zero or
more elements from an alphabet. We use the period “.” as the concatenation
operator, but frequently the two operands are simply put side by side. Let T =
T [1] T [2] . . . T [m] be a sequence of length m. For all 1 ≤ i ≤ j ≤ m, we write
T [i : j] to denote T [i] T [i + 1] . . . T [j]. The reverse of T is the sequence T R =
T [m] . . . T [2] T [1]. A factorization of T is any decomposition T = x1 x2 . . . xq
where x1 , x2 , . . . xq are (possibly empty) sequences. Let (T, A) be a { }-arcannotated sequence and (i, j) ∈ A, i < j, be an arc. We call T [i] a forward base
and T [j] a backward base. We will denote by LFT the position of the last forward
base in (T, A) and by FBT the position of the ﬁrst backward base in (T, A), i.e.,
LFT = max{i : (i, j) ∈ A} and FBT = min{j : (i, j) ∈ A}. By convention, we let
LFT = 0 and FBT = |T | + 1 if A = ∅. Observe that LFT < FBT . We begin by
proving a factorization result on { }-arc-annotated sequences.
Lemma 1. Let S and T be two { }-arc-annotated sequences of length n and
m, respectively. If T occurs as an arc preserving subsequence in S, then there
exists a factorization (possibly trivial) T [LFT +1 : FBT −1] = xy such that T [1 :
LFT ] · x · (y · T [FBT : m])R occurs as an arc preserving subsequence in S[1 :
FBS −1] · S[FBS : n]R .

866

G. Blin et al.

Proof. Suppose that T occurs as an arc preserving subsequence in S. Since both
S and T are { }-arc-annotated sequences, then there exist two factorizations
S[1 : LFS ] = uw and S[FBS : n] = zv such that: (i) T [1 : LFT ] occurs in u,
(ii) T [LFT +1 : FBT −1] occurs in w · S[LFS +1 : FBS −1] · z and (iii) T [FBT :
m] occurs in v. Then it follows that there exists a factorization T [LFT +1 :
FBT −1] = xy such that x occurs in w · S[LFS +1 : FBS −1] and y occurs in z,
and hence T = T [1 : LFT ] · x · (y · T [FBT : m])R occurs as an arc preserving
subsequence in S = S[1 : FBS −1] · S[FBS : n]R
Theorem 3. APS({ },{ }) is solvable in O(nm2 ) time.

Algorithm 1:
: Two { }-arc-annotated sequences S and T of length n and m, respectively
Result : true iﬀ T occurs as an arc-preserving subsequence in S
begin
Data

1
2
3
4
5
6

S = S[1 : FBS −1] · S[FBS : n]R
foreach factorization T [LFT +1 : FBT −1]| = xy do
T = T [1 : LFT ] · x · (y · T [FBT : m])R
if T occurs as an arc preserving subsequence in S then
return true
return false
end

Proof. Consider Algorithm 1. Correctness of the algorithm follows from Lemma 1.
What is left is to prove the time complexity. Clearly, S = S[1 : FBS −1]·S[FBS :
n]R is a { }-arc-annotated sequence. The key point is to note that, for any factorization T [LFT +1 : FBT −1]| = xy, the obtained T = T [1 : LFT ]·x·(y·T [FBT :
m])R is a { }-arc-annotated sequence as-well. Now let k be the number of arcs
in T . So there are at most m − 2k iterations to go before eventually returning
false. According to the above, Line 4 constitutes an instance of APS({ },{ }).
But APS({ },{ }) is a special case of APS({<, },{<, }), and hence is solvable in O(nm) time [6]. Then it follows that the algorithm as a whole runs in
O(nm(m − 2k)) = O(nm2 ) time.
Clearly, the proof of Theorem 3 relies on an eﬃcient algorithm for solving
APS({ },{ }): the better the complexity for APS({ },{ }), the better the
complexity for APS({ },{ }). We have used only the fact that APS({ },{ })
is a special case of APS({<, },{<, }). It remains open, however, wether a
better complexity can be achieved for APS({ },{ }). Theorem 3, combined
with Observation 1, carries out easily to restricted versions.
Corollary 1. APS({ },∅) is solvable in O(nm2 ) time.

What Makes the Arc-Preserving Subsequence Problem Hard?

6

867

Conclusion

In this paper, we investigated the APS problem time complexity and gave a
precise characterization of what makes the APS problem hard. We proved that
APS(Crossing,Plain) is NP-complete thereby answering an open problem
posed in [6]. Note that this result answers the last open problem concerning APS
computational complexity with respect to classical complexity levels, i.e., Plain,
Chain, Nested and Crossing. Also, we reﬁned the four above mentioned levels
for exploring the border between polynomial time solvable and NP-complete
problems. We proved that both APS({ , }, ∅) and APS({<, }, ∅) are NPcomplete and gave positive results by showing that APS({ }, ∅) and APS({
},{ }) are polynomial time solvable. Hence, the reﬁnement we suggest shows that
APS problem becomes hard when one considers sequences containing { , α}comparable arcs with α = ∅. Therefore, crossing arcs alone do not imply APS
hardness. It is of course a challenging problem to further explore the complexity
of the APS problem, and especially the parameterized views, by considering
additional parameters such as the cutwidth or the depth of the arc structures.

References
1. J. Alber, J. Gramm, J. Guo, and R. Niedermeier. Computing the similarity of
two sequences with nested arc annotations. Theoretical Computer Science, 312(23):337–358, 2004.
2. G. Caetano-Anoll´es. Tracing the evolution of RNA structure in ribosomes. Nucl.
Acids. Res., 30:2575–2587, 2002.
3. P. Evans. Algorithms and Complexity for Annotated Sequence Analysis. PhD thesis,
U. Victoria, 1999.
4. M. Garey and D. Johnson. Computers and Intractability: A Guide to the Theory
of NP-Completeness. W. H. Freeman and Company, 1979.
5. D. Goldman, S. Istrail, and C.H. Papadimitriou. Algorithmic aspects of protein
structure similarity. In Proc. of the 40th Symposium of Foundations of Computer
Science (FOCS99), pages 512–522, 1999.
6. J. Gramm, J. Guo, and R. Niedermeier. Pattern matching for arc-annotated sequences. In Proc. of the 22nd Conference on Foundations of Software Technology
and Theoretical Computer Science (FSTTCS02), volume 2556 of LNCS, pages 182–
193, 2002.
7. J. Guo. Exact algorithms for the longest common subsequence problem for arcannotated sequences. Master’s Thesis, Universitat Tubingen, Fed. Rep. of Germany, 2002.
8. T. Jiang, G.-H. Lin, B. Ma, and K. Zhang. The longest common subsequence problem for arc-annotated sequences. In Proc. 11th Symposium on Combinatorial Pattern Matching (CPM00), volume 1848 of LNCS, pages 154–165. Springer-Verlag,
2000.
9. V. Juan, C. Crain, and S. Wilson. Evidence for evolutionarily conserved secondary
structure in the H19 tumor suppressor RNA. Nucl. Acids. Res., 28:1221–1227,
2000.

868

G. Blin et al.

10. G. Lancia, R. Carr, B. Walenz, and S. Istrail. 101 optimal PDB structure alignments: a branch-and-cut algorithm for the maximum contact map overlap problem.
In Proceedings of the 5th ACM International Conference on Computational Molecular Biology (RECOMB01), pages 193–202, 2001.
11. S. Vialette. On the computational complexity of 2-interval pattern matching.
Theoretical Computer Science, 312(2-3):223–249, 2004.
12. K. Zhang, L. Wang, and B. Ma. Computing the similarity between RNA structures.
In Proc. 10th Symposium on Combinatorial Pattern Matching (CPM99), volume
1645 of LNCS, pages 281–293. Springer-Verlag, 1999.
13. M. Zuker. RNA folding. Meth. Enzymology, 180:262–288, 1989.

