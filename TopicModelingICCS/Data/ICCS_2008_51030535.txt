Task Hibernation in a Formal Model of
Agent-Oriented Computing Systems
Maciej Smolka
Institute of Computer Science, Jagiellonian University, Krak´
ow, Poland
smolka@ii.uj.edu.pl

Abstract. The paper contains recent enhancements of a formal model of
agent-based computing systems. In such systems a computational task
together with its data is enveloped in a shell to form a mobile agent.
The shell carries the agent’s logic, ie. abilities to make decisions about
whether to migrate to a less loaded machine, split oneself or continue
the task. The model describes an agent-based computational application
as a controlled Markov chain. In this paper the operation of the agent
hibernation, which is the last resort in the case of a server overload, is
included in the model. This modiﬁcation has an inﬂuence on the form of
the state equations as well as the form of admissible control strategies.

1

Introduction

The multi-agent paradigm is already a classical design approach in a wide variety
of domains (cf. [1], [2]), which can take advantage of the idea of mobile intelligent autonomous application unit. Computing systems are seldom considered
as one of these domains. However, the concept of self-organising computational
application composed of mobile tasks, which can move between interconnected
computers according to a scheduling policy in order to ﬁnd a better environment for executing themselves is well-known for several years. The article [3]
describes such a system with a scheduling policy based on the heat conduction
phenomenon.
A step forwards has been to put a task together with its data into an agent
box, give the agent the ability to migrate, to communicate with other agents
and to split itself (ﬁrst of all its task) into two child agents (typically equal). In
such a case a scheduling strategy may be incorporated in all agents’ (distributed)
intelligence. The strategy tells an agent in what order it should perform its activities (computations, migration, partitioning) to achieve its goals, which include
typically the ﬁnishing of computations in the shortest possible time.
A multi-agent computational system of this type has been developed for the
last several years (cf. [4]). It exploits a scheduling policy based on the phenomenon of the molecular diﬀusion in crystals (cf. [5], [6]). In this policy an
agent makes decisions about actions to perform resting on its knowledge of the
load of its computational node as well as the load of the node’s direct neighbours.
When an agent wants and is able to migrate, it chooses the least loaded neighbour as the target. The application of the multi-agent paradigm together with
M. Bubak et al. (Eds.): ICCS 2008, Part III, LNCS 5103, pp. 535–544, 2008.
c Springer-Verlag Berlin Heidelberg 2008

536

M. Smolka

local, diﬀusion-based agent scheduling strategies provide us with a relatively
simple decentralised management of large-scale distributed computations.
Many theoretical questions has been raised during the development of the
above mentioned multi-agent system (MAS). The fundamental one is whether
the used heuristic scheduling strategy is in any sense optimal or quasi-optimal.
This in turn requires a precise deﬁnition of the optimality of a strategy. If the
answer to the ﬁrst question is negative, another problem is whether there exists
an optimal policy at all and, if so, what are its characteristics.
To address these (and other) questions a formal model of computing multiagent systems has been proposed (cf. [6,7,8]). The model is based on the stochastic optimal control theory. The model is still under development and its last
version is described in [9]. It already provides us with a precise deﬁnition of
the optimal task scheduling in our context as well as results on the existence of
optimal scheduling strategies and optimality conditions. The above mentioned
MAS has served as an example for the development of the model, but the latter
has proven more general (and complicated).
In this paper the model is extended by considering the operation of the agent
hibernation. Agents are hibernated eg. in an early stage of migration (cf. [4]),
but migrations has been already considered in our model (cf. [9]). The interesting
case of the hibernation occurs when a computational node is overloaded and an
agent cannot ﬁnd any neighbouring node to emigrate. The local MAS server will
then serialize the agent to the disk and deserialize it when the load is suﬃciently
low. We modify our state equations to allow such hibernations.
Finally we present results on the existence and the characterisation of optimal
scheduling strategies, which are adapted to the modiﬁed model.

2

System Architecture

First let us introduce to the reader the architectural principles of our exemplary
computing MAS. They constitute the foundations and the starting point for the
development of the mathematical model. Here we recall only the features most
important for the model, for a more complete description and some implementation details we refer the reader to [4] and [5].
The suggested architecture of the system is composed of a computational
environment (MAS platform) and a computing application being a collection of
mobile agents called Smart Solid Agents (SSA). The computational environment
is the triple (N, BH , perf ), where:
N = {P1 , . . . , PN } , where Pi is a MAS server called a Virtual Computational
Node (VCN). Each VCN can maintain a number of agents.
BH is the connection topology BH = {N1 , . . . , NN }, Ni ⊂ N is a direct neighbourhood of Pi (including Pi as well).
perf = {perf1 , . . . , perfN }, perfi : R+ → R+ is a family of functions where perfi
describes the relative performance of VCN Pi with respect to the total memi
ory request Mtotal
of all agents allocated at the node.

Task Hibernation in a Formal Model

537

The MAS platform is responsible for maintaining the basic functionalities of
the computing agents. Namely it delivers the information about the local load
concentration Lj and Qj (see (2) and (3) below), it performs agent destruction,
hibernation, partitioning and migration between neighbouring VCN’s and ﬁnally
it supports the transparent communication among agents.
We shall denote an SSA by Ai where index i stands for an unambiguous agent
identiﬁer (possibly a UUID). Each Ai contains its computational task and all
data necessary for its computations. Every agent is also equipped with a shell
which is responsible for the agent logic. At any time Ai is able to denominate the
pair (Ei , Mi ) where Ei is the estimated remaining computation time measured
in units common for all agents of an application and Mi is the agent’s RAM
requirement in bytes. An agent may undertake autonomously one of the following
actions:
– continue executing its internal task,
– migrate to a neighbouring VCN or
– decide to be partitioned, which results in creating two child agents {Aij =
(Tij , Sij )}, j = 1, 2.
We assume that in the case of the agent partitioning the following conditions
hold:
Ei > Eij , Mi > Mij , j = 1, 2.
The parent SSA disappears after the partition.
A computing application may be characterised by the triple (At , Gt , Scht ),
t ∈ [0, +∞) where At is the set of application agents active at the time t, Gt is
the tree representing the history of agents’ partitioning until t. All agents active
t
till t constitute the set of its nodes s=0 At , while the edges link parent agents to
their children. All information on how to rebuild Gt is spread among all agents
such that each of them knows only its neighbours in the tree. {Scht }t∈[0,+∞)
is the family of functions such that Scht : At → N is the current schedule of
application agents among the MAS platform servers. The function is deﬁned by
the sets ωj containing indices of agents allocated on each Pj ∈ N. Every ωj is
locally stored and managed by Pj .
Each server Pj ∈ N asks periodically all local agents (allocated on Pj ) for
their requirements and computes the local load concentration
Lj =

j
Etotal
j
perfj (Mtotal
)

j
=
where Etotal

j
Ei and Mtotal
=
i∈ωj

Mi .

(1)

i∈ωj

Then Pj communicates with neighbouring servers and establishes
k
k
, Mtotal
, perfk ) : Pk ∈ Nj
Lj = (Lk , Etotal

(2)

as well as the set of node indices
Qj = {k = j : Pk ∈ Nj , Lj − Lk > 0} .

(3)

538

3

M. Smolka

Global State of a Computing Application

In this section we introduce some key concepts appearing in our formal model
of computing multi-agent systems. The detailed description of the model may
be found in [9].
The key idea behind the model is to abandon the considering of single agents’
behaviour in favour of observing a global quantity characterising the state of a
computational application in an appropriate way. To this end we have introduced
the notion of the vector weight of an agent, which is the mapping
w : N × A −→ RM
+
with M ≥ 1. The weight has at least one positive component as long as the
agent is active (ie. its task is being executed) or hibernated. In other words the
equality
(4)
wt (Ai ) = 0
means that the agent Ai does not exist yet or already. Note that we observe the
application state in discrete time moments, so the set of times is N. We assume
that the dependency of the total weight of child agents after partition upon their
parent’s weight before partition is well-known and linear, i.e. there is a matrix
such that in the case of partition A → {A1 , A2 } we have
P ∈ RM×M
+
wt+1 (A1 ) + wt+1 (A2 ) = Pwt (A).

(5)

The single agent weight is only an auxiliary notion needed to deﬁne what shall
be one of the main observed global quantities, ie. the total weight of all agents
allocated on a virtual node P at any time t, which is
Wt (P ) =

wt (A).
Scht (A)=P

In previous papers Wt was the system state, but as we want to diﬀerentiate
between active and hibernated agents, we shall split the total weight into two
terms
Wt (P ) = Wta (P ) + Wth (P ),
where Wta (P ) is the total weight of active agents and Wth (P ) is the total weight
of hibernated agents. We shall observe the evolution of both quantities separately.
If the components of w include Ei and Mi deﬁned in Sec. 2 (as in [7], [8]),
then:
– Mi > 0 for active agents and Mi = 0 for hibernated ones,
– Ei is positive till the agent destruction and does not change as long as the
agent is hibernated.
i
i
In this case obviously Etotal
and Mtotal
will be among the components of W .
But in general it may be convenient to ﬁnd other state variables (see [9] for

Task Hibernation in a Formal Model

539

i
i
considerations on that topic). In any case both Etotal
and Mtotal
should remain
observables of our system.
In the sequel we shall assume that the number of virtual nodes

N=N
is ﬁxed. We could also assume that it is bounded, but this is not a big generalisation. For the sake of conciseness we introduce the notation
Wta,j = Wta (Pj ),

Wth,j = Wth (Pj )

for j = 1, . . . , N . Then Wta and Wth may be interpreted as vectors from RMN
+
or, if it is more convenient, as nonnegative M × N matrices.
According to the interpretation of (4) the equality Wt = 0, which is equivalent to Wta = Wth = 0, means that at the time t there are neither active nor
hibernated agents, ie. the computations are ﬁnished. In other words 0 is the ﬁnal
state of the application’s evolution.

4

Global State Evolution

In this section we shall formulate the equations of the evolution of our state
variables, ie. Wta and Wth . They are expected to be a generalisation of the state
equations presented in [9], so they should reduce to those equations in the absence
of hibernations. Consequently they shall be stochastic diﬀerence equations, which
means that the pair (Wta , Wth ) shall form a discrete stochastic process.
First of all let us recall what has been called the ’established’ evolution equation. It has been the equation showing the evolution of an application in the
absence of agent migrations and partitions and it has the following form.
Wt+1 = F (Wt , ξt )

(6)

where F is a given mapping and (ξt )t=0,1,... is a given sequence of random variables representing the background load inﬂuence. We assume that ξt are mutually
independent, identically distributed and have a common ﬁnite set of values Ξ,
which is justiﬁed in many natural situations (cf. [8], this paper also considers
more general assumptions on the background load).
In our case, we extend the meaning of the ’established’ evolution by excluding
hibernations as well. This results in the following conditions
Wth = 0,

Wta = Wt .

Thus we can rewrite (6) to obtain
a
Wt+1
= F (Wta , ξt )
h
Wt+1
= 0.

(7)

Since 0 has to be an absorbing state of W t = (Wta , Wth ), we need to assume that
for every t
F (0, ξt ) = 0
(8)

540

M. Smolka

with probability 1. To guarantee reaching the ﬁnal state we need also another
assumption stating that there exists t > 0 such that for every initial condition
W and Wt evolving according to (6) we have
Pr Wt = 0 | W0 = W

> 0.

(9)

It is easy to see that a similar condition holds for W t and the natural initial
state (W , 0). A desired consequence of (9) (cf. [10]) is that with any initial
condition our application will eventually ﬁnish the computations, which makes
the assumption quite useful.
The equations of migration and partition are almost the same as in [9], the
only diﬀerence is that they describe the behaviour of Wta (Wth does not change
during a migration or a partition).
In the case of sole hibernations and dehibernations at node Pj (and no migrations, partitions or ’established’ evolution) the system shall behave according to
the following equation.
⎧ a,j
h,j
a,j
a,j
h,j
a
⎪
⎪Wt+1 = I − diag(ut (Wt )) Wt + diag(ut (W t )Wt
⎪
⎪
⎨ h,j
h,j
a,j
a
Wt+1 = I − diag(ua,j
+ diag(uh,j
t (W t )) Wt
t (Wt ))Wt
(10)
a,i
a,i
⎪
⎪
W
=
W
⎪
t
t+1
⎪
⎩ h,i
Wt+1 = Wth,i
for i = j.
uh,j
: RMN
→ [0, 1]M and ua,j
: RMN
× RMN
→ [0, 1]M are the proportions of
t
t
+
+
+
components of the total weights of agents, respectively, hibernated and activated
(dehibernated) to the corresponding proportions of the total weights of all agents
allocated at node Pj at the moment t. We assume that the decision of hibernating
some agents is the result of a resource shortage. As hibernated agents do not
make use of any resources interesting from our point of view (we assume that
server disks are large enough) this decision is based on the weight of active
agents only. In other words uht does not depend on Wth . In contrast the decision
of reactivating some hibernated agents may depend on some of their features
(eg. even if some RAM is free, every single hibernated agent may be too big to
be activated), so uat depends on both weight components.
Now we are in position to present the complete state equations. They are an
extension of the state equations presented in [9] and they are constructed in a
similar way, ie. as a combination of the above mentioned simpliﬁed equations
reducing to these equations in their described particular context. We propose
the following combination.
⎧
a,i
a,i
ji
a,j
a
a
⎪
Wt+1
= g i F i (Wta , ξt ), P diag(uii
⎪
t (Wt )) Wt ,
j=i diag(ut (Wt )) Wt ,
⎪
⎪
⎪
⎪
h,i
⎪
diag(ua,i
⎨
t (W t )) Wt
h,i

Wt+1
⎪
⎪
⎪
a,i
⎪
W
⎪
0
⎪
⎪
⎩ h,i
W0

h,i
a,i
a
= (I − diag(ua,i
+ diag(uh,i
t (W t ))) Wt
t (Wt )) Wt
= Wi
=0

(11)

Task Hibernation in a Formal Model

541

for i = 1, . . . , N , where
Wta,i = I −

N
k=1

h,i
a,i
a
a
diag(uik
t (Wt )) − diag(ut (Wt )) Wt

and W is a given initial state. For (11) to reduce to simpliﬁed equations we
need an assumption on g, which may be eg. g(s, 0, 0, 0) = s, g(0, p, 0, 0) = p,
g(0, 0, m, 0) = m, g(0, 0, 0, h) = h. Note that in [8] and earlier papers we used a
stronger condition, ie. g(s, p, m, h) = s + p + m + h.
It follows that Wt is a controlled stochastic process with a control strategy
π = (ut )t∈N ,

ut = (ut , uat , uht ) : RMN
−→ U.
+

(12)

The control set U contains such elements a = (α, αa , αh ) from [0, 1]M(N ×N ) ×
[0, 1]MN ×[0, 1]MN that satisfy at least the following conditions for m = 1, . . . , M .
ji
αij
m · αm = 0 for i = j,

iN
h,i
αi1
m + · · · + αm + αm ≤ 1 for i = 1, . . . , N .

(13)

The ﬁrst equation in (13) can be interpreted in the following way: at a given
time migrations between two nodes may happen in only one direction. The second equality means that the number of agents leaving a node, partitioned or
hibernated at the node must not exceed the number of agents active at the node.
Remark 1. It is easy to see that the control set U deﬁned by the conditions (13)
is compact (and so are of course its closed subsets).
As in [9] we do not take the whole RMN
× RMN
as the state space. Instead we
+
+
a
h
MN
choose ﬁnite subsets S , S of N
both containing 0 and S = S a × S h = {s0 =
(0, 0), s1 , . . . , sK } shall be the state space. Consequently we assume that F and
g have values in S a . Additionally, we need also to assume that for every t ∈ N
and W = (W a , W h ) ∈ S
ut (W ) ∈ UW = a ∈ U : Ga (W , a, ξ) ∈ S a , Gh (W , a) ∈ S h for ξ ∈ Ξ
where Ga and Gh denote the right hand sides of, respectively, the ﬁrst and
the second equation in (11). The above equality implies that Ga (W , 0, ξ) =
F (W a , ξ) ∈ S a and Gh (W , 0) = W h ∈ S h for any W and ξ, which means that
(0, 0) ∈ UW , therefore UW is nonempty for every W ∈ S. On the other hand we
have Ga (0, a, ξ) = F (0, ξ) = 0 and Gh (0, a) = 0, i.e. 0 is an absorbing state of
W t independently of a chosen control strategy.
Remark 2. Similarly to [9] it remains true that W t is a controlled Markov chain
with transition probabilities pij (a) = Pr(G(si , a, ξ0 ) = sj ) for i, j = 0, . . . , K,
a ∈ Usi , G = (Ga , Gh ). The transition matrix for the control u is P (u) =
[pij (u(si ))]i,j=0,...,K .

542

5

M. Smolka

Optimal Scheduling Problem

Let us now recall (after [7]) the deﬁnition of the optimal scheduling for a computing MAS in terms of the stochastic optimal control theory. We have already
the state equations (11), so we need also a cost functional and a set of admissible
controls.
The general form of considered cost functionals is
V (π; s) = E[

∞
t=0

k(W t , ut (W t ))]

(14)

where π is a control strategy (12) and s = (sa , 0) is the initial state of W t , i.e.
W 0 = s. Since 0 is an absorbing state we shall always assume that remaining
at 0 has no cost, i.e. k(0, ·) = 0. This condition guarantees that the overall cost
can be ﬁnite.
The form of the set of admissible strategies is a modiﬁcation of the one used
in [9], namely
U = π : ut (W ) ∈ UW , t ∈ N .
Now we can formulate the optimal scheduling problem. Namely given an initial
conﬁguration (W , 0) we look for a control strategy π ∗ ∈ U such that
V (π ∗ ; (W , 0)) = min V (π; (W , 0)) : π ∈ U, W t is a solution of (11) . (15)
In other words an optimal scheduling for Wt is a control strategy π ∗ realising
the minimum in (15).
Our main general tool for proving the existence of optimal scheduling strategies is [9, Prop. 4]. Its key assumptions are (R1) and (R2). They are expressed
in terms of special properties of the transition matrix P (u), but they mean that
K-step (for (R2) n-step for some n) probability of reaching 0 from every initial
state is positive provided we use:
– for (R1) any stationary strategy π = (u, u, . . . );
– for (R2) one particular stationary strategy.
In (R2) we have to impose a stronger assumption on the one-step cost k, nevertheless it is much easier to check than (R1). In our case thanks to (9) the
assumption (R2) is satisﬁed eg. for the zero control strategy π = (0, 0, . . . ).
For this reason in the sequel we shall consider only costs which satisfy the
second part of (R2), ie.
k(s, a) ≥ ε > 0,

for s = 0, a ∈ Us .

(16)

Among cost functionals presented in [9] only the expected total time of computations VT satisﬁes automatically (16). Let us recall that it has the following
form.
VT (π; s) = E inf{t ≥ 0 : Wt = 0} − 1 .
(17)

Task Hibernation in a Formal Model

543

Remaining two functionals (VL and VM ) do not satisfy the assumption (16),
but we can reduce the problem by adding a term cVT with (maybe small) c > 0
to both of them.
First of the two (the one promoting good load balancing) after such a modiﬁcation has the following form.
VLT (π; s) = E

∞
t=0

N
i
i=1 (Lt

− Lt )2 + cVT (π; s),

Lt =

1
N

N
i=1

Lit

(18)

where Lit is the load concentration (1) at Pi at the moment t. These quantities
i
i
are well deﬁned because we have assumed that Etotal
and Mtotal
are observables
of our system.
The last cost functional from [9] (penalising migrations) after the modiﬁcation
has the following form.
VMT (π; s) = E

∞
t=0

M
m=1

i=j

ij
a
μij
m (um,t (Wt )) + cVT (π; s).

(19)

μij
m : [0, 1] → R+ allows us to take into account the distance between Pi and Pj .
Considerations accompanying (15) along with [9, Prop. 4] result in the following corollary.
Corollary 3. Problem (15) for VT , VLT or VMT has the unique solution.
Finally, let us recall the optimality conditions presented in [9, Prop. 6] and
rewrite it in our context in the following corollary.
Corollary 4. Let V denote any of the functionals VT , VLT , VMT . The optimal
solution of (15) is a stationary strategy π ∗ = u∞ = (u, u, . . . ) and it is the
unique solution of the equation
V (π ∗ ; s) = mina∈Us

K
j=1

pij (a)V (π ∗ ; sj ) + k(s, a) .

(20)

The solution of (20) exists and it is the optimal solution of (15).
(20) can be solved by means of an iterative procedure such as Gauss-Seidel.
The complexity of the computational problem depends ﬁrst of all on the size of
the state space S, which in general is expected to be quite big. To make things
better in a typical situation many states are inaccessible from one another so
the matrix pij is sparse. The complexity is increased on the other hand by the
minimisation and depends on the size (and the structure) of control sets Us .

6

Conclusions

The presented MAS architecture along with diﬀusion-based agent scheduling
strategies form a relatively easy to manage and quite eﬃcient framework for
large-scale distributed computations. The presented mathematical model provides us with a precise deﬁnition of optimal task scheduling in such an environment. It also gives us some useful results concerning the existence of optimal

544

M. Smolka

scheduling strategies (Cor. 3) as well as the optimality conditions (Cor. 4). The
latter show that the choice of scheduling strategies utilised during tests (cf. [5])
was proper, because it is a stationary strategy and according to Cor. 4 the optimal strategy belongs to that class. In this paper the formal model has been
extended to consider agent hibernations neglected so far. Also the existence results and the optimality conditions has been adapted appropriately. It appears
that it is an important extension and omitting hibernations in some cases might
result in a wrong observation of the state of a computing application. Further
plans concerning the model include detailed studies on the form of the optimal
strategies and, on the other hand, ﬁnishing some experiments (and starting some
new ones) expected to extend the model’s empirical basis.

References
1. Bradshaw, J.M. (ed.): Software Agents. AAAI Press, Menlo Park (1997)
2. Wooldridge, M.: An Introduction to Multi-agent Systems. Wiley, Chichester (2002)
3. Luque, E., Ripoll, A., Cort´es, A., Margalef, T.: A distributed diﬀusion method for
dynamic load balancing on parallel computers. In: Proceedings of EUROMICRO
Workshop on Parallel and Distributed Processing, San Remo, Italy, pp. 43–50.
IEEE Computer Society Press, Los Alamitos (1995)
4. Uhruski, P., Grochowski, M., Schaefer, R.: Multi-agent computing system in a
heterogeneous network. In: Proceedings of the International Conference on Parallel
Computing in Electrical Engineering (PARELEC 2002), Warsaw, Poland, pp. 233–
238. IEEE Computer Society Press, Los Alamitos (2002)
5. Grochowski, M., Schaefer, R., Uhruski, P.: Diﬀusion Based Scheduling in the AgentOriented Computing System. In: Wyrzykowski, R., Dongarra, J., Paprzycki, M.,
Wa´sniewski, J. (eds.) PPAM 2004. LNCS, vol. 3019, pp. 97–104. Springer, Heidelberg (2004)
6. Grochowski, M., Smolka, M., Schaefer, R.: Architectural principles and scheduling
strategies for computing agent systems. Fundamenta Informaticae 71(1), 15–26
(2006)
7. Smolka, M., Grochowski, M., Uhruski, P., Schaefer, R.: The dynamics of computing
agent systems. In: Sunderam, V.S., van Albada, G.D., Sloot, P.M.A., Dongarra, J.
(eds.) ICCS 2005. LNCS, vol. 3516, pp. 727–734. Springer, Heidelberg (2005)
8. Smolka, M., Schaefer, R.: Computing MAS dynamics considering the background
load. In: Alexandrov, V.N., van Albada, G.D., Sloot, P.M.A., Dongarra, J. (eds.)
ICCS 2006. LNCS, vol. 3993, pp. 799–806. Springer, Heidelberg (2006)
9. Smolka, M.: A formal model of multi-agent computations. LNCS. Springer, Heidelberg (to appear, 2008)
10. Kushner, H.: Introduction to Stochastic Control. Holt, Rinehart and Winston
(1971)

