Densification of Digital Terrain Elevations Using Shape
from Shading with Single Satellite Imagery
1

Mohammad A. Rajabi , J. A. Rod Blais

1

Dept. of Geomatics Eng., The University of Calgary, 2500, University Dr., NW,
Calgary, Alberta, Canada, T2N 1N4
{marajabi, blais}@ucalgary.ca

Abstract. Numerous geoscience and engineering applications need denser and
more accurate Digital Terrain Model (DTM) height data. Collecting additional
height data in the field, if not impossible, is either expensive or time consuming
or both. Stereo aerial or satellite imagery is often unavailable and very
expensive to acquire. Interpolation techniques are fast and cheap, but have their
own inherent difficulties and problems, especially in rough terrain. Advanced
space technology has provided much single (if not stereo) high-resolution
satellite imageries almost worldwide. This paper discusses the idea of using
Shape From Shading (SFS) methods with single high resolution imagery to
densify regular grids of heights. Preliminary results are very encouraging and
the methodology is going to be implemented with real satellite imagery and
parallel computations.

1 Introduction
In the present context, Digital Terrain Models (DTMs) are simply regular grids of
elevation measurements over the land surface. They are used for the analysis of
topographical features in GISs and numerous engineering computations. The National
Center for Geographic Information and Analysis (NCGIA) provides a list of global
DTMs with different resolutions (from 30 arc minutes to 30 arc seconds) which are
freely available on the Internet [1]. NCGIA also provides a list of freeware and
shareware programs to handle different formats of DTM files. DTMs can be used for
numerous applications such as, e.g.,
� Calculating cut-and-fill requirements for earth works engineering, such as
road construction or the area that would be flooded by a hydroelectric dam.
� Analyzing intervisibility to plan route location of radar antennas or
microwave towers, and to define viewsheds.
� Displaying 3D landforms for military purposes and for landscape design and
planning.
� Analyzing and comparing different kinds of terrain.
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2074, pp. 3−12, 2001.
�
� Springer-Verlag Berlin Heidelberg 2001

4

M.A. Rajabi and J.A.R. Blais

�

Computing slope maps, aspect maps and slope profiles that can be used to
prepare shaded relief maps, assist geomorphological studies, or estimate
erosion or run-off.
� Computing of geophysical terrain corrections for gravity and other field
observations.
� Displaying thematic information or for combining relief data such as soils,
land use or vegetation.
� Providing data for image simulation models of landscapes and geographical
processes.
� Investigating of erosion processes, land slides, contamination by dangerous
chemicals, etc.
Traditionally, photogrammetry has been used as the main method of producing
DTMs, however, there are cases for which no aerial photography is available.
Recently, with the rapid improvement in remote sensing technology, automated
analysis of stereo satellite data has been used to derive DTM data. Automatic
generation of elevation data from SPOT stereo satellite imagery has been discussed in
[2], [3], and [4]. But even in this case, there are some places that due to some reasons
such as cloud coverage, technical and/or political limitations are not covered by stereo
satellite imagery.
On the other hand, the availability of single satellite imagery for nearly all of the
Earth is taken for granted nowadays. But unfortunately, reconstruction of objects from
monocular images is very difficult, and in some cases, not possible at all. Inverse
rendering or the procedure of recovering three-dimensional surfaces of unknown
objects from two-dimensional images is an important task in computer vision
research. A robust procedure, which can correctly reconstruct surfaces of an object, is
important in various applications such as visual inspection, autonomous land vehicle
navigation, and surveillance and robot control. In the past two decades, there have
been extensive studies of this topic. Shape from defocusing [5], [6], shape from
stereopsis [7], shape from motion [8], shape from texture (SFT) [9], [10], and shape
from shading (SFS) [11] [12], [13] are examples of techniques used for inverse
rendering.
This paper is the result of investigating the use of shape from shading techniques
to improve the quality of the interpolated DTM data with single satellite imagery of
better resolution than the DTM data. The idea is highly motivated by the wide
availability of satellite remotely sensed imagery such as Landsat TM and SPOT HRV
imagery.

2 Shape from Shading
Shape recovery in computer vision is an inverse problem which transforms single or
stereo 2D images to a 3D scene. Shape from stereo, shape from motion, shape from
texture, and shape from shading are examples of methods used for shape recovery in
computer vision. Shape from shading (SFS) recovers the surface shape from gradual
variations of shading in the image. The recovered shape can be expressed either in

Densification of Digital Terrain Elevations Using Shape from Shading

5

�

terrain height z(x,y) or surface normal
N or
surface gradient
(p,q)= (�z / �x, �z / �y ) .
To solve the SFS problem, the first step is to study the image formation process. A
Lambertian model is the simplest one in which it is assumed that the gray level at
each pixel depends on light source direction and surface normal. Assuming that the
surface is illuminated by a distant point source, we have the following equation for
the image intensity:
� �

R ( x, y ) � � N . L = �

p2 � q2 �1
�

�

where

(1)

pl1 � ql 2 � l3

� is the surface albedo, N is the normal to the surface and L � (l1 , l 2 , l3 ) is
�

the light source direction. Even if � and L are known, the SFS problem will still be a
challenging subject, as this is one nonlinear equation with two unknowns for each
pixel in the image. Therefore, SFS is an underdetermined problem in nature and in
order to get a unique solution, if there is any at all, we need to have some constraints.
Based on the conceptual differences in the algorithms, there are three different
strategies to solve the SFS problem: 1. Minimization approaches 2. Propagation
approaches, and 3. Local approaches. The following subsections briefly review these
approaches. A more detailed survey of SFS methods can be found in [14].
2.1 Minimization Approaches
Based on one of the earliest minimization methods, the SFS problem is formulated as
a function of surface gradients, while brightness and smoothness constraints are added
to overcome the underdeterminedness condition [15]. The brightness constraint
ensures the reconstructed shape produce the same brightness as the input image. The
smoothness constraint in terms of second order surface gradients helps in
reconstruction of a smooth surface. The shape at the occluding boundary was used for
initialization to imply a correct convergence [15].
Other minimization approaches use more or less the same logic to deal with the
SFS problem. However, some variations in either formulation of the problem or the
constraints (or both) are usually implemented.
2.2 Propagation Approaches
In this approach there is a characteristic strip along which one can compute the
surface height (object depth) and gradient, provided these quantities are known at the
starting point of the strip. Singular points where the intensity is either maximum or
minimum are usually the starting points. At singular points the shape of the surface is

6

M.A. Rajabi and J.A.R. Blais

either known or can uniquely be determined. The first attempt for solving SFS
problems using this method seems to be mentioned in Horn [16]. In this technique,
shape information is propagated outward along the characteristic strips. The direction
of characteristic strips is toward the intensity gradient.
2.3 Local Approaches
The basic assumption in this approach is that the surface is locally spherical at each
pixel point. Intensity and its first and second derivatives [17] or intensity and only its
first derivative [18] have been used to estimates the shape information. All local
methods suffer from the local spherical assumption which may not be correct in all
cases.
Another local approach uses linearized approximations of reflectance maps to
solve the SFS problem [19]. In this method the reflectance map is formulated in terms
of surface gradient and then the Fourier Transform is applied to the linear function
and a closed form solution for the height (depth) at each point is obtained.
Another method makes use of computing the discrete approximation of the
gradient [20]. Then the linear approximation of reflectance map as a function of
height (depth) is employed. Using a Jacobi iterative scheme, this technique can
estimate the height (depth) at each point. The main problem of the two latter
approaches is with the linear approximation of the reflectance map. If the nonlinear
terms are large, it will diverge.

3 Improvement of DTM Interpolation Using SFS Techniques
The problem under investigation is to improve the accuracy of the interpolated DTM
grid data by applying SFS techniques on the corresponding single satellite imagery.
The assumption is that the satellite imagery has better resolution than the original
DTM data. To keep the problem simple, the resolution difference between the original
DTM grid data and satellite imagery is considered to be one dyadic order. The
original DTM data are used as boundary constraints in the SFS problem.
The assumptions made for this research are: 1) the surface is Lambertian, 2) the
surface albedo is known, 3) the surface is illuminated by a distant point source, and
finally 4) the position of the light source is known.
It is worth mentioning that in our special application of SFS where we are dealing
with satellite imageries, the first assumption is the only one which is questionable.
However, dealing with multispectral satellite imagery, one can get a good estimate of
surface albedo by applying classification techniques. Meanwhile, the light source for
satellite imageries is the Sun which is not only far away from the scene, but also has a
known direction knowing the local time when the satellite is passing over the scene
(which is assumed to be the case).
Our approach deals with a patch located at pixel (i,j) (see Figure 1) with nine points
at a time out of which there are four grid points with known heights (squares) and five
unknown points (circles) for which we want to improve the accuracy of the
interpolation. The method mainly consists of three stages: 1) preprocessing, 2)

Densification of Digital Terrain Elevations Using Shape from Shading

7

processing, and 3) postprocessing. The preprocessing stage itself has two steps. In the
first step, using interpolation (bilinear) techniques, the heights of the unknown points
in the patch are estimated.
In the second step, using the known grid
points, the relative orientation of the patch with
respect to the light source is estimated. If this
(i,j)
relative orientation implies that the patch is in the
shadow, then there would be no useful shading
information to improve the accuracy of the
interpolated heights. Therefore, in this case the
interpolated heights are considered the final
height values.
Otherwise, the processing stage for each patch
Fig. 1. A patch: squares are
consists in solving an overdetermined system of
known grid points and circles
are interpolated points.
equations of type (1) in terms of heights (z).
This is simply done by approximating p and q with finite differences. Writing the
Lambertian reflectance model as a function of heights (z), we have nine nonlinear
equations corresponding to the image intensity (I) of each point in the patch with four
known heights (the grid points) and five unknown heights.
The nonlinear system of equations is solved using nonlinear least squares with the
interpolated heights as the first approximation for the unknowns. Again it is worth
mentioning that in most engineering applications, the DTM grid spacing is based on
terrain roughness analysis, therefore, the interpolated heights are usually good
estimates of heights for initializing the nonlinear solution. Moreover, the nonlinear
least squares solution was constrained by the � 3� condition where � is the
expected standard deviation of the interpolated heights and comes from the DTM
specifications.
The last stage, postprocessing, consists of taking arithmetic means of two solutions
for the unknown heights located on the boundary of patches coming from the
neighboring patches, except for the outsides of the peripheral patches.

4 Numerical Examples
The methodology described in Section 3 has been tested using a number of numerical
examples. One synthetic object and one real DTM data set with their corresponding
synthetic imageries were used in these experiments. The orientation of the light
source was considered as a variable to investigate the effects of relative positions of
the object and the light source on the solution.
The synthetic object under investigation is a convex hemisphere with a radius of 6
units, sampled at each 0.5 unit, i.e., a 33 by 33 pixel object. The corresponding DTM
(one dyadic order less than the object, i.e., 17 by 17 pixels)) was extracted out from
the object. Meanwhile, the corresponding image of the object was created using
Lambertian reflectance model with a much (5 times) denser version of the object. The
resulting image was passed through a smoothing filter to get an image with the same
density as the original object under study.

8

M.A. Rajabi and J.A.R. Blais

The differences between the original object, the Interpolated Grid Solution (IGS)
and the SFS solution were analyzed. Table 1 summarizes these results. The statistics
shown in this table are computed with those pixels which our SFS method was able to
updated their height values. The last row of the table shows the number of patches
which couldn’t be updated by this SFS method. This can be mainly due to two
reasons. Either the patches are located with respect to the light source such that the
average intensity of the patch is zero (patches in the shadow), or the nonlinear least
squares process didn’t converge. In Table 1 nothing has been mentioned about the
azimuth of the light source. The symmetry of the synthetic object under investigation
makes the process independent of the light source azimuth.
Table 1. The convex hemishpere

Object – SFS

Object–IGS

Elevation

30

�

35

�

40

�

45

�

50

�

55

�

60

�

Mean

-0.04

-0.04

-0.01

-0.01

0.00

-0.02

0.01

Std

0.31

0.29

0.28

0.28

0.31

0.35

0.33

Mean

-0.05

-0.07

-0.06

-0.05

-0.05

-0.06

-0.03

Std

0.18

0.20

0.18

0.17

0.17

0.23

0.17

41

39

28

26

19

15

Patches not
updated
(out of 196)

20

Table 1 shows that in comparison to the IGS, the SFS solution has slightly
worsened the mean differences. A detailed examination of the problem showed that
this deterioration comes from the abrupt change of height values along the base of the
hemisphere. Apart from these sections, the SFS solution has been able to improve the
mean differences by an average of 30%. However, the improvement in the standard
deviations of the differences is approximately 40% which is quite considerable.
Meanwhile, for this synthetic object it is seen that the optimum elevation angle of the
light source is about 50 degrees where we have about 45% improvement in standard
deviation. As an example, Figure (2) shows the wiremesh of the object, the
corresponding image and the wiremesh of differences of the original object and IGS,

Densification of Digital Terrain Elevations Using Shape from Shading

9

and the SFS solution where the light source is located at azimuth and elevation angle
�

�

of 135 and 45 respectively.

Fig. 2. A) The Original object; B) The corresponding image; The differences
between the original object and the IGS in (C) and the SFS solution in (D).
The second test object is a real height data set from southern Alberta, Canada,
measured with 25 metre spacing. It is a 1000 by 1000 grid with more than 1300 metre
height difference which was down sampled to 125 metres (i.e., a 200 by 200 grid).
This sampled height data was considered as the object under investigation and the
corresponding DTM (one dyadic order wider, i.e., 250 metre grid) was extracted out
from it. Meanwhile, the corresponding image of the object was created using a
Lambertian reflectance model and the original 25 metre height data. The resulting
image was passed through a smoothing filter to get an image with the same resolution
as the object under study, i.e., 125 metres.
Table 2 summarizes the results of our experiment with this data set, which shows
results similar to the previous case. The SFS solution has slightly worsened the
absolute value of the mean differences and has improved the standard deviation of the
mean differences with the average amount of 40%. It seems that during the data
preparation process the original characteristics of the real data set has been lost.
However, the results show a clear dependency of the SFS solution to the relative
position of the object and the light source. As it can be seen, the worst results have
been obtained with the light source at the azimuth of 180 degrees. Figure (3) shows

10

M.A. Rajabi and J.A.R. Blais

the wiremesh of the object, the corresponding image and the wiremesh of differences
between the original object, IGS, and the SFS solution, where the light source is
�

�

located at azimuth and elevation angle of 135 and 45 respectively.
Table 2. The real height data set

Azimuth

�

45

�

180

60

�

30

�

45

�

�

225

60

�

30

�

45

�

�

60

�

Object - IGS

30

�

Mean
(m)

-0.01

0.09

0.22

0.71

0.41

-0.03

0.08

0.17

0.09

Std
(m)

12.9

13.2

13.6

14.4

17.2

18.8

12.8

12.9

13.4

Object - SFS

Elevation

135

Mean
(m)

0.15

-0.04

0.03

0.26

0.34

0.05

0.13

0.13

0.12

Std
(m)

7.5

7.7

7.9

8.7

10.1

11.5

7.7

7.6

7.9

483

872

1484

4397

3922

3709

493

735

1239

Patches not
updated
(out of 9409)

5 Remarks and Conclusions
The use of a SFS technique to improve the accuracy of the interpolated DTMs has
been investigated and preliminary results are very encouraging with simulated
imageries. The next step is obviously to experiment with real satellite imageries.
Georeferencing, clouds, shadowing, unknown surface albedo, and noise in addition to
non dyadic scale factors between satellite imageries and DTMs seem to be problems
that one has to deal with before solving the SFS problem.
This SFS method is a local method that can be easily implemented by parallel
processing techniques. Considering the resolution of satellite imageries and the area
that they cover, one can see that using local SFS techniques and parallel processing in
our application is a must.
Looking at the results, one also realizes that the success of this SFS technique is
highly dependent on the relative orientation of the patches and the light source. If the

Densification of Digital Terrain Elevations Using Shape from Shading

11

relative orientations of the object and the light source are such that there is no shading
information, the SFS technique cannot improve the interpolation results. Obviously,
one should not forget the morphology of the terrain. This may be another good
criterion in addition to the resolution of the images, to be taken into consideration
when one has different options in selecting satellite imagery for the DTM
densification purposes.

Fig. 3. A) The Original object; B) The corresponding image; The differences between the
original object and the IGS in (C) and the SFS solution in (D).

References
1.

2.
3.

The National Center for Geographic Information and Analysis (NCGIA):
www.ncgia.ucsb.edu/education/curricula/cctp/units
Gugan, D. J., Dowman, I. J.: Topographic Mapping from Spot Imagery.
Photgrammetric Engineering and Remote Sensing 54(10) (1988):1409-1414
Simard, R., Rochon, G., Leclerc, A.: Mapping with SPOT Imagery and
Integrated Data Sets. Invited paper presented at the 16th congress of the
International Society for Photogrammetry and Remote Sensing held July 1988 in
Kyoto, Japan

12

4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.

M.A. Rajabi and J.A.R. Blais

Tam, A. P.: Terrain Information Extraction from Digital SPOT Satellite Imagery.
Dept. of Geomatics Eng., The University of Calgary (1990)
Pentland, A. P.: A new sense for depth of field. IEEE. Trans. Pattern Anal.
Match. Intell. PAMI-9(4) (1987), 523-531
Hwang T., Clark, J. J., Yuille, A. L.: A depth recovery algorithm using defocus
information. IEEE Conference on computer vision and pattern recognition
(1989), pp. 476-481
Medioni, J., Nevatia, R.: Segment-based stereo matching. comput. Vision
Graphics Image Process, 31 July (1985), 2-18
Waxman, A. M., Gurumoothy, K.: Image flow theory: a framework for 3-D
inference from time-varying imagery. Advances in Machine Vision (C Brown,
Ed) (1988), pp. 165-224, Springer-Verlag, New York
Witkin, A. P.: Recovering surface shape and orientation from texture, Artif.
Intell. 17 (1981), 17-47
Kender, J. R.: Shape from texture. Proceedings, 6th International Journal
Conference on Aritficial Intelligence, Tokyo (1979), pp. 562-570
Wei, G.-Q., Hirzinger, G.: Parametric Shape-from-Shading by Radial Basis
Functions. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol
19, No. 4, April (1997)
Horn, B. K. P.: Height and gradient from shading. Int. J. Comput. Vision, 37-5
(1990)
Zhang, R., Tsai, P. S., Cryer, J. E., Shah, M.: Analysis of Shape from Shading
Techniques. Proc. Computer Vision Pttern Recognition (1994), pp. 377-384
Zhang, R., Tsai, P.-S., Cryer, J. E., Shah, M.: Shape from Shading: A Survey.
IEEE Transcation on Pattern Analysis and Machine Intelligence, Vol. 21, No. 8,
August (1999), pp. 690-706
Ikeuchi, K., Horn, B. K. P.: Numerical Shape from Shading and Occluding
Boundaries. Artificial Intelligence, Vol. 17, Nos. 1-3 (1981), pp. 141-184
Horn, B. K. P.: Shape from Shading: A method for Obtaining the Shape of a
Smooth Opaque from One View. PhD Thesis, Massachusetts Ins. of Technology
(1970)
Pentland, A. P.: Local Shading Analysis, IEEE Trans. Pattern Analysis and
Machine Intelligence Vol. 6 (1984), pp. 170-187
Lee, C. H., Rosenfeld, A.: Improved Methods of Estimating Shape from Shading
Using the Light Source Coordinate System. Artificial Intelligence, Vol. 26
(1985), pp. 125-143
Pentland, A.: Shape information from Shading: A theory about Human
Preception. Proc. Int’l Conf. Computer Vision (1988), pp. 404-413
Tsai, P. S., Shah, M.: Shape from Shading Using Linear Approximation, Image
and Vision Computing J., Vol 12, No. 8 (1994), pp. 487-498

