Quality and Performance Evaluation of Ray-Space
Interpolation for Free Viewpoint Video Systems
Fan Liangzhong1,2, Yu Mei1,3, Yu Zhou1, and Jiang Gangyi1,2
1 Faculty

of Information Science and Engineering, Ningbo University,
315211, Ningbo, China
2 Institute of Computer Technology, Graduate School of Chinese
Academy of Sciences, 100871, Beijing, China
3 National Key Lab of Software New Technology, Nanjing University,
Nanjing 210093, China

Abstract. Ray-space is the main technology to realize Free Viewpoint Video
(FVV) systems with complicated scenes. One of the key technologies to make
the ray-space feasible is interpolation. In this paper, two fast interpolation
methods based on feature points and directionality detection are compared with
block based matching method, and the experimental results show that the two
methods improve visual quality as well as PSNRs of rendered virtual viewpoint
image greatly while computational burden is also reduced significantly.

1 Ray-Space Interpolation for Free Viewpoint Systems
In the application scenario of free viewpoint video (FVV) systems, the viewers experience the free viewpoint navigation within the range covered by the shooting cameras. In recent years, image based rendering techniques have been developed to generate novel views of an environment from a set of pre-acquired images. Ray-space
representation, as a new technique of image based rendering, renders arbitrary viewpoint images without complicated object segmentation and 3D modeling. However, in
real world situation, it is difficult to set many cameras very closely, and the ray data
obtained by the camera setup is too sparse in viewpoint axis to apply the ray-space
method [1]. Therefore, it is necessary to generate dense ray data by interpolation
techniques. It should be noted that ray-space slice has strong directionalities, so that
conventional interpolation methods developed for natural image are not suitable anymore. Directionality detection of each pixel to be interpolated becomes very important in ray-space interpolation. Because ray-space interpolation is in fact associated
with arbitrary intermediate view rendering, it is one of the key technologies in rayspace based FVV systems.
The block-based matching method (BMI) consists of searching for corresponding
blocks in the two EPI lines (epipolar lines) to find the best-corresponding pixel pair
for interpolation in the assigned maximum disparity [2]. Our directionality detection
based method (DDI) [3] and feature point growth based method (FGI) [4] are two
feature based interpolation methods. In DDI and FGI, feature pixels are first extracted
from sparse ray-space slice, and their directionalities are determined by block matching technique, then directionality of each pixel to be interpolated in dense ray-space
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part II, LNCS 3992, pp. 367 – 370, 2006.
© Springer-Verlag Berlin Heidelberg 2006

368

L. Fan et al.

slice is linear interpolated with the directionalities of these feature pixels, and then
linear interpolation is done according to directionality of the pixel to be interpolated.
In fact, the so-called feature pixel is the one near edge or within area with fine texture.
Directionality searching is only done for these feature pixels, because these searching
usually can obtain more reliable results compared with processing of non-feature
pixels around which there is no enough texture information for marching. Moreover,
the computational burden is also reduced because the matching is done only for feature pixels but not all pixels to be interpolated. Different from DDI method, FGI
method is proposed to solve the occlusion problem further. In FGI, each of the feature
points grows in the nearby epipolar lines until the direction of the grown feature point
departures from the direction of the initial point, which means that occlusion occurs
or the feature point is in fact a noise.

2 Experimental Results and Analysis
To compare the above three methods, we perform experiments on two test sequences
of real data called “Xmas” and “Cup” as given in Fig.1 on a PC with CPU of 1.8G Hz
and RAM of 256M. “Xmas” sequence is provided by Tanimoto Laboratory, Nagoya
University, 101 viewpoint images are captured synchronously with camera interval of
3mm, the image resolution is 640×480, and the distance between cameras and object
is about 30cm. The “Cup” sequence is captured by a shifted camera with interval of
1mm, the number of viewpoint images and the resolution are the same as “Xmas”
sequence, distance between camera and object is about 20cm, so the maximum disparity in “Cup” sequence is much larger than “Xmas” sequence.

(a) “Xmas”

(b) “Cup”

Fig. 1. The original left-most and right-most viewpoint images of the two test sequences

The EPI obtained from the 101 images is adopted as the dense EPI, while the EPI
transformed from some images with same camera interval is used to simulate the
sparsely sampling. To evaluate the performance of ray-space interpolation method,
the interpolated EPI is compared with the corresponding dense one, and the rendered
intermediate viewpoint images are also compared with the real captured images.
Table 1 gives the average PSNRs of the 480 interpolated EPIs as well as the corresponding average interpolating times. It is clear that the DDI and FGI methods
achieve much higher PSNRs than BMI method. The interpolating time of the BMI
method increases as camera interval increases, but the proposed methods consume
approximately constant time under different camera intervals, and the interpolating time
is much saved compared with BMI method especially under large camera interval.

Quality and Performance Evaluation of Ray-Space Interpolation

369

Table 1. Average PSNR / Interpolating time of 480 EPIs unit: dB / ms

Test sets
Xmas

Cup

Camera interval
15mm
30mm
60mm
75mm
5mm
10mm
20mm
25mm

(a) Original dense EPI

(c) DDI (PSNR=32.03dB)

BMI
39.31 / 97
38.81 / 185
37.72 / 354
36.60 / 438
33.84 / 165
33.11 / 335
31.58 / 672
30.35 / 839

DDI
40.69 / 28
39.59 / 28
38.60 / 29
38.07 / 29
34.27 / 26
33.60 / 25
32.68 / 26
31.36 / 25

FGI
41.03 / 34
40.27 / 36
39.72 / 37
39.50 / 38
34.89 / 36
34.23 / 39
33.50 / 41
31.99 / 41

(b) BMI (PSNR=30.29dB)

(d) FGI (PSNR=32.29dB)

Fig. 2. Results of the interpolated 155th EPI with camera interval 25mm (from “Cup” sequence)

(a) “Xmas”

(b) “Cup”

Fig. 3. Average PSNRs of rendered intermediate viewpoint images

Fig.2 gives an example of ray-space interpolation with the three different methods.
Fig.3 shows average PSNRs of intermediate viewpoint images rendered from the
interpolated ray-space. In the figures, the proposed interpolation methods outperform
BMI method, because it can obtain more accurate directions. Moreover, the proposed
methods run much faster than BMI method because it only searches some feature
points’ directions but not all of the pixels to be interpolated. Fig.4 shows parts of the
rendered viewpoint images with respect to the above three interpolation methods. The
text and the door’s edges on the cup are well kept by the proposed methods, it is
obvious that the proposed methods are much better than BMI method in keeping

370

L. Fan et al.

(a) Original image

(b) BMI (29.35dB)

(c) DDI (30.99 dB)

(d) FGI (32.74dB)

Fig. 4. Part of the rendered 40th virtual view from interpolated ray-space with camera interval
25 mm (from “Cup” sequence)

edges and fine textures of objects. After generating dense ray-space, it is easy to render stereo images by selecting appropriate data.

3 Conclusions
Ray-space representation has superiority in rendering arbitrary viewpoint images of
complicated scene in real-time. Interpolation is one of the key techniques to make the
ray-space based FVV system feasible, and it also determines the cost of application
and the quality of rendered image. In this paper, two fast interpolation methods based
on feature points and directionality detection are compared with block based matching
method, and it is seen that the two methods improve visual quality as well as PSNRs
of rendered virtual viewpoint image greatly while computational burden is also reduced significantly.
Acknowledgment. This work was supported by the Natural Science Foundation
of China (grant 60472100), the Natural Science Foundation of Zhejiang Province
(grant RC01057, Y105577), the Ningbo Science and Technology Project of China
(grant 2003A61001, 2004A610001, 2004A630002), and the Zhejiang Science and
Technology Project of China (Grant 2004C31105).

References
1. Fujii T., Tanimoto M.: Free-viewpoint TV system based on Ray-Space representation. In:
Proceedings of SPIE, vol. 4864. Boston (2002) 175-189
2. Tehrani, M. P., Fujii, T., Tanimoto, M.: Offset Block Matching of Multi-View Images for
Ray-Space Interpolation. The journal of the Institute of Image Information and Television
Engineers. Vol. 58. (2004) 540-548
3. Jiang, G., Yu, M., Ye, Xien.: New method of Ray-Space interpolation for free viewpoint
video. In: Proceedings of International Conference on Image Processing. (2005) 1138-1141
4. Jiang, G., Fan, L.,Yu, M.: Fast Ray-Space Interpolation based on Occlusion Analysis and
FeaturePoints Detection. In: Proceedings of International Conference on Computational Intelligence and Security. Vol. 3802. Xi an, China (2005) 935-940

