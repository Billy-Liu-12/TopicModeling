Available online at www.sciencedirect.com

Procedia Computer Science 9 (2012) 907 – 916

International Conference on Computational Science, ICCS 2012

Probabilistic Change Detection Framework for Analyzing
Settlement Dynamics Using Very High-resolution Satellite Imagery
Ranga R. Vatsavaia,1,∗, Jordan Graessera
a Computational

Sciences and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, USA

Abstract
Global human population growth and an increasingly urbanizing world have led to rapid changes in human settlement landscapes and patterns. Timely monitoring and assessment of these changes and dissemination of accurate
information is important for policy makers, city planners, and humanitarian relief workers. Satellite imagery provides
useful data for the aforementioned applications, and remote sensing can be used to identify and quantify change areas.
We explore a probabilistic framework to identify changes in human settlements using very high-resolution satellite
imagery. As compared to predominantly pixel-based change detection systems which are highly sensitive to image
registration errors, our grid (block) based approach is more robust to registration errors. The presented framework
is an automated change detection system applicable to both panchromatic and multi-spectral imagery. The detection system provides comprehensible information about change areas, and minimizes the post-detection thresholding
procedure often needed in traditional change detection algorithms.
Keywords: Change Detection, pdf, Gaussian Distribution, Clustering

1. Introduction
Urbanization, which has occurred at a rapid rate [1], leads to many changes in an urban landscape. Remote sensing
can be utilized to monitor human settlement land cover and land use change (LCLUC). Whether it is new urban
growth, loss, or change in urban land use, satellite imagery provides valuable information about human settlements.
The integration of remote sensing, GIS, and other modeling and simulation systems can provide valuable assistance to
a comprehensive decision support system. The study reported in [2] shows remote sensing technology has been most
widely utilized in mapping and monitoring of hazards, identiﬁcation of damages, and eﬀects of natural or man-made
disasters. Our objective in this study is twofold. First, we review the state of the art in urban damage assessment
(which largely focuses on land cover changes, speciﬁcally loss or destruction of buildings), and second, we present
our ongoing algorithmic research on change detection as well as a new settlement detection algorithm using very
high-resolution multi-spectral imagery.
∗ Corresponding

author
Email address: vatsavairr@ornl.gov (Ranga R. Vatsavai)
1 Prepared by Oak Ridge National Laboratory, P.O. Box 2008, Oak Ridge, Tennessee 37831-6285, managed by UT-Battelle, LLC for the U. S.
Department of Energy under contract no. DEAC05-00OR22725.

1877-0509 © 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
doi:10.1016/j.procs.2012.04.097

908

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

Figure 1: Change detection framework

Change detection [3] is widely used for rapid assessment of aﬀected areas. Figure 1 shows a generic change
detection framework. First, suitable high-resolution imagery from pre- and post-event dates must be obtained. These
images should then be geo-registered so a one-to-one (pixel) correspondence is established between the two images.
Once the images have been registered, change detection techniques can be applied to obtain a map that shows possible changes (aﬀected regions). Typically, further analysis is needed to accurately identify damages to individual
structures.
Traditionally, damage assessment to individual buildings and other critical infrastructure has been conducted manually by visual interpretation of pre- and post-event aerial photos. Manual photo interpretation is still in use, for
example, in a recent study by the Government of Haiti (2010) in the aftermath of a magnitude 7.0 earthquake on 12
January 2010. Image analysts at UNITAR/UNOSAT categorized buildings into destroyed, severely damaged, moderately damaged, and no visible damage based on the European Macroseismic Scale - 98 deﬁnition [4]. Such detailed
studies are required for accurate assessment of damages; however, it takes much time and eﬀort. More timely damage assessment and delineation of disaster aﬀected areas can be achieved with high-resolution satellite imagery and
automated change detection techniques. One of the most important aspects of human settlement disaster assessment
is rapid estimates of aﬀected regions so rescue and recovery operations can be administered in an eﬀective manner.
Human settlement LCLUC share similar spatial and spectral characteristics to damages inﬂicted by natural disasters. For example, Internally Displaced Person (IDP) camps are typically temporary locations with rapid growth and
changes to the landscape. In this study, we examined a semi-permannent IDP camp near Peshawar, Pakistan. Recent
changes in the camp can be seen in high-resolution imagery. The probabilistic change detection framework presented
in this paper provides an automated procedure to identify these types of settlement changes.
In section two, we brieﬂy describe some of the commonly used change detection techniques often used in damage
assessment studies. The probabilistic framework is described in section three, followed by an experimental evaluation
conducted on high-resolution imagery in Kacha Garhi camp, Pakistan.

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

909

2. Major Change Detection Techniques
Image Diﬀerencing: Image diﬀerencing—part of a more general setting known as image algebra-based change
detection—is one of the most widely used automatic change detection techniques, and involves two steps: 1) given two
univariate images, the ﬁrst image (time 1) is subtracted from the second (time 2), that is, IDi f f (i, j) = I2 (i, j) − I1 (i, j),
where (i, j) refers to the pixel location with respect to the origin, 2) each pixel is assigned a label of change or no
change by thresholding the change magnitude. The main advantage of image diﬀerencing is the technique is computationally cheap. The major disadvantage is setting an appropriate threshold value (typically set in terms of standard
deviations) requires careful ﬁne-tuning and interpretation of results. Additionally, one can use local means instead of
individual pixel values to make diﬀerencing more robust.
Ratio of Means: One limitation of image diﬀerencing is its sensitivity to noise. The ratio of means is another simple
change detection technique that is robust to common multiplicative noise often found in imagery. The ratio of diﬀerj)
μA
ence is given by IRatio (i, j) = II21 (i,
(i, j) , which can also be extended to local means as IRatio (i, j) = μB .
Change Vector Analysis: While image diﬀerencing is limited to univariate (single band) images, change vector analysis is designed to analyze changes in multi-spectral and multi-temporal image sequences. The change vector is the
vector diﬀerence between the time-trajectory of successive time periods. The length of a change vector is given by
(B2 −B1 )
], where B and G are indeS = [(B2 − B1 )2 + (G2 − G1 )2 ] and the direction of change is given by α = arctan [ (G
2 −G 1 )
pendent spectral bands. The length of the change vector indicates the magnitude of change and the direction indicates
the nature of change [5, 6]. Typically, threshold segmentation is carried out on the change vector’s magnitude image.
Inner Product and Spectral Correlation Analysis: In the inner product analysis, the spectral values of a pixel in
an image are considered as vectors (as in change vector analysis). The diﬀerence between two multi-spectral vectors
is measured as the cosine of the angle between them. The basis for using the cosine measure is if two multi-spectral
vectors are coincident with each other, then their inner product is 1. If there is a change between the images, then this
quantity varies between -1 and +1. Spectral correlation analysis is similar to the inner product analysis, with the main
diﬀerence being the correlation method takes into account the means of the multi-spectral vectors. Using the mean
instead of an absolute diﬀerence value has the potential to reduce atmospheric and other imaging eﬀects. The corre(I (i, j)−μ )(I (i, j)−μI1 )
.
lation coeﬃcient, or spectral signature similarity, in the change image is given by: Iρ (i, j) = N1 i, j 2 σI I2σI 1
2
1
This is similar to using a linear model, y = ax + b, where a and b are two constants such that value y can be scaled to
an appropriate non-negative range. The spectral correlation method was used in several land cover change studies [7].
Multi-variate Alteration Detection: The multi-variate alteration detection (MAD) [8] is a widely used multi-variate
change detection algorithm based on canonical correlation analysis. The MAD transformation is the diﬀerence of
canonical variates of the two sets of multi-variate data in reverse order. This algorithm is generic in the sense that it
allows multi-variate images with diﬀerent image modalities. The algorithm attempts to ﬁnd two linear band combinations (one each from the bitemporal images) that maximize correlation, and subtract these two images to obtain the
ﬁrst change band. A second change band is generated by searching for a second set of linear combinations orthogonal
to the ﬁrst one. The process is repeated d number of times, where d is the minimum number of bands in the input
images, resulting in d number of change bands. The algorithm is robust and invariant to radiometric scaling and
shifting, however, it is not applicable to panchromatic imagery.
In this review, we presented only the major categories of change detection techniques. There are many hybrid
techniques [9, 10, 11] which utilize variations of unsupervised, supervised, and object-based techniques. A more
general review of change detection approaches can be found in [12].
2.1. Limitations of existing approaches and our contributions
The ﬁrst major drawback of widely used change detection techniques is they are all point-based, that is, the
comparison (e.g., diﬀerence, ratio, etc.) is done at the individual pixel. Despite eﬃcient image registration techniques
available, it is diﬃcult to establish a pixel-to-pixel correspondence in very high-resolution imagery. Figure 2 illustrates
the practical diﬃculties in establishing an image-to-image (pixel level) correspondence. The ﬁgure illustrates two

910

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

types of problems: 1) there is a registration error (indicated by the red line) of 3 pixels wide between the 2004 and
2009 images, and 2) the shadow orientation. Although both images were acquired by the same satellite, they were
acquired at diﬀerent angles. Pixel-wise comparison methods perform poorly under these circumstances.

(a)

(b)

Figure 2: Registration Errors (left: 2004, and right: 2009)

A second drawback of change detection techniques is they are mostly univariate, and multi-variate techniques
such as MAD produce multi-band change detection maps. In addition, most of these techniques produce a continuous change detection map which requires further processing (e.g., thresholding the change map into various
change categories). We propose a probabilistic framework to identify changes which has the following important
features/improvements:
• It works with image blocks instead of pixels to minimize negative eﬀects of registration errors.
• It works with both panchromatic and multi-spectral imagery, but produces a single band discrete change map.
• The computed changes are automatically grouped into separate change categories.
3. Probabilistic Change Detection Framework
In this section we describe the key components of the proposed probabilistic change detection framework. The
proposed framework consists of the following steps:
1. Divide the image into grids.
2. Model the data from each grid as a Gaussian distribution. Therefore, at each grid i we have two Gaussian
distributions Pt1 (i), Qt2 (i) for time t1 and t2, respectively.
3. For each grid i, compute the distance between Gaussian distributions Pt1 (i), Qt2 (i).
4. Cluster the distance data by modeling it as a statistical distribution, where diﬀerent clusters correspond to
various degrees of change.
We now brieﬂy describe each of these key steps in the algorithm.

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

911

3.1. Grid/Block construction
In the ﬁrst step, we divide the image into regular grids, or blocks. A grid is essentially a square or rectangular block
whose size (pixels x lines) determines the quality and computational cost of the algorithm. If the grid is too large, it
may result in poor change detection. For example, larger grids may contain more than a single object, therefore the
Gaussian distribution ﬁtted to the grid may not have a single peak. However, the computation time drastically reduces
with increases in grid size. On the contrary, if the grid size is too small it would increase the computational cost,
and may also cause model parameter estimation and matrix inversion problems. The optimal size is typically dictated
by the pixel resolution, typical object sizes found in the imagery, and the number of image bands (i.e., dimensions).
Figure 3 shows the grids superimposed on a high-resolution satellite image. In the remaining sections, we refer to the
term grid when referencing this ﬁrst step.

Figure 3: User Deﬁned Grids Superimposed on a High-resolution Satellite Image

3.2. Model each grid as a Gaussian distribution
We model the image data in each grid, that is, all multi-dimensional feature vectors from each pixel in the grid,
are generated by a multi-variate Gaussian distribution described in the following equation.
p(x|y j ) =

1
(2π)−N |Σ

−1

j|

e 2 (x−μ j ) |Σ j |
t

−1

(x−μ j )

(1)

912

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

The standard multi-variate Gaussian distribution is described by the parameters mean (μ) and covariance matrix
(Σ). These parameters are estimated for each grid separately from the corresponding image data.
3.3. Compute distance between Gaussian pairs
We compared grids (same location, say i) from two diﬀerent times by computing the probabilistic distance between
corresponding Gaussian distributions Pt1 (i) and Qt1 (i) (for simplicity, time and grid index subscripts will be omitted
in later discussions). There are various divergence and distance measures readily available from the literature. The
most notable ones are the Kullback-Leibler (KL) divergence, Bhattacharyya distance, and Mahalanobis distance. We
implemented all three measures, but experimentally found KL divergence to be slightly better than the other two. The
KL divergence is a non-symmetric measure of the diﬀerence between two probability distributions P and Q, given by:
DKL (P||Q) =

∞
−∞

p(x) ln

p(x)
dx
q(x)

(2)

For Gaussian distributions, the KL divergence is given by:
|σQ |
1
T −1
[log
+ T r(Σ−1
Q ΣP ) + (μP − μQ ) ΣQ (μP − μQ )]
2
|ΣP |

DKL (P||Q) =

(3)

Unfortunately, KL divergence is not a distance matrix and not scaled between 0 and 1 (Bhattacharyya and Mahalanobis are scaled). However, the symmetric version of KL divergence is easy to compute:
1
(4)
(DKL (P||Q) + DKL (Q||P)
2
As the distance is not scaled, we ﬁtted a Gaussian Mixture Model (GMM) to the KL divergence data generated in
this step.
DKL (P||Q) =

3.4. GMM Parameter Estimation and Component Discovery
To generate the ﬁnal change map, we needed to ﬁnd thresholds on the KL Divergence. One way to do this
is by exploratory analysis, where the KL divergence data is displayed as a histogram and may indicate where to
apply thresholds. However, we present a more principled and automated way to generate the change map. First, we
modeled the KL divergence data as a GMM and applied a clustering technique to generate a change map. Typically,
model-based (e.g., GMM) clustering approaches are not applied on entire data sets given the computational and data
complexity. Rather, a subset of data samples are collected from the full data set, and the model parameters are
estimated using these samples. Once a model is constructed, all the samples (i.e., data points) in the full data set
can then be assigned to one of the clusters based on some distance (or decision) criteria. We now brieﬂy describe an
expectation maximization (EM) based algorithm to learn the GMM parameters.
3.5. Estimating GMM Parameters
Let us now assume that the sample data set D = {xi }ni=1 is generated by the following mixture density.
K

p(xi |Θ) =

α j p j (xi |θ j )
j=1

(5)

Here p j (xi |θ j ) is the pdf corresponding to the mixture j and parameterized by θ j , and Θ = (α1 , . . . , θK , θ1 , . . . , θK )
denotes all unknown parameters associated with the K-component mixture density. For a multi-variate normal distribution (eq. 1), θ j consists of elements of the mean vector μ j and the distinct components of the covariance matrix Σ j .
The log-likelihood function for this mixture density can be deﬁned as: L(Θ) = ni=1 ln M
j=1 α j p j (xi |θ j ) . In general,
L(Θ) is diﬃcult to optimize because it contains the ln of a sum term. However, this equation greatly simpliﬁes in the
presence of unobserved (or incomplete) samples. Normally, we treat the cluster labels as missing (unobserved) data,
and use the expectation maximization technique to estimate the parameters (Θ). The EM algorithm consists of two
steps, called the E-step and the M-step, as given below.

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

913

E-Step: For a multi-variate normal distribution, the expectation E[.], which is denoted by pi j , is the probability that
Gaussian mixture j generated data point i, and is given by:
pi j =

−1/2 − 1 (xi −μˆ j )t Σˆ −1 (xi −μˆ j )
j
e 2
Σˆ j
M
l=1

−1/2 {− 1 (x −μˆ )t Σˆ −1 (x −μˆ )}
e 2 i l l i l
Σˆ l

(6)

M-Step: The new estimates (at the kth iteration) of the model parameters in terms of the old parameters are computed
using the following equations:
n
n
ˆ kj )(xi − μˆ kj )t
n
i=1 pi j (xi − μ
i=1 xi pi j
k
k
1
ˆ
μ
ˆ
=
(8)
Σj =
(9)
n
j
n
=
pi j (7)
i=1 pi j
i=1 pi j
n i=1
The EM algorithm iterates over these two steps until convergence is reached. One way to initialize the EM
algorithm is to assume the number of clusters, K. For example, we can think of two clusters, change versus no change.
A closer look at histogram over KL divergence reveals the number of peaks. In general, we can estimate parameters
for any arbitrary K-component model, as long as there are a suﬃcient number of samples available for each component
and the covariance matrix does not become singular. Then the question remains, which K-component model is better?
This question is addressed in the area of model selection, where the objective is to choose a model that maximizes
a cost function. There are several cost functions available in the literature. The most commonly used measures are
Akaike’s information criterion (AIC), Bayesian information criteria (BIC), and minimum description length (MDL).
The common criteria behind these models is to penalize models that have additional parameters, so BIC and AIC based
model selection criteria follow the principal of parsimony. In this study, we used BIC as a model selection criterion,
which also takes the same form as MDL. We chose BIC because it has been found to be very useful in model based
clustering [13], and it is deﬁned in terms of maximized log-likelihood, which we are computing in our parameter
estimation procedure deﬁned in the previous section. BIC can be deﬁned as, BIC = MDL = −2 log L(Θ) + m log(N),
where N is the number of samples and m is the number of parameters. Typically, the algorithm is run ‘K number of
times, where at each k the data is “partitioned” into k clusters. BIC (or any other suitable cost function) is computed
for each k, and the best model is chosen for which the BIC value is maximum.

αˆ kj

Figure 4: High-resolution imagery of Kacha Garhi camp, Pakistan. The colored regions of interest highlight manually interpreted
settlement change. The type of change (from 2004 to 2009) is indicated by the color of the regions.

914

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

4. Results
We applied our probabilistic change detection framework on bi-temporal high-resolution multi-spectral imagery
over Kacha Garhi camp, Pakistan. Kacha Garhi was a camp established in 1980 for Afghan refugees. Located in West
Peshawar, Pakistan, it was closed to clear space for urban development, which meant thousands of native Afghans
were repatriated. Two QuickBird images acquired circa 2004 and 2009 show the transition in process. The images
contained four spectral bands in the visible and near-infrared wavelengths, and were resampled to a spatial resolution
of 2.4 meters. Image-to-image registration was conducted with a registration error within three pixels. In 2004, before
the closing of the camp, mud structures built by refugees constituted the majority of the camp region. In the western
portion of the 2009 camp region, one can see the displacement of mud houses by new residential development, clearly
of diﬀerent building materials. Mud structures still exist in 2009, but missing rooftop materials indicate dismantling
is still in progress.
Figure 4 illustrates three colored polygons that highlight changes (no change, camp destruction, and new construction) obtained through expert knowledge. For comparison analysis, only major change areas were manually
identiﬁed.
Red polygons show the camp area was already cleared in 2004. In 2009, new housing facilities can be seen in
the same area (cyan color). In contrast, red polygons show old houses constructed of earthen materials in 2004,
but destroyed by year 2009. In addition, the eastern portion of the camp is missing roof materials, which indicates
destruction is still in process. Figure 5 illustrates these changes more clearly.

Figure 5: Major settlement changes identiﬁed by manual interpretation (Kacha Garhi camp, Pakistan).

Figure 6 shows the results of our change detection algorithm. First, one will notice the algorithm accurately
detected all the changes (blue colored grids) highlighted by the human expert (4 polygons). The additional changes
detected were mostly on croplands. By comparing the 2004 and 2009 images (Figure 4), one can easily see all the
ﬁelds are under cultivation (green) in 2004, while many of the plots are not cultivated in 2009.
We also applied pixel-based change detection algorithms described in section 2. Figure 7 shows two change
images obtained after thresholding the outputs of diﬀerence and ratio based changed detection methods. First, as
compared to the probabilistic approach the detected changes were not accurate, and secondly, there are artiﬁcial
changes along the linear features (due to miss registration errors).

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

915

Figure 6: Detected changes (shown in blue) derived from probabilistic change framework: 2004 and 2009. The manually delineated
change areas are overlaid for comparison.

5. Conclusions and Future Directions
In this paper, we presented a probabilistic change detection framework. First, we reviewed major categories of
change detection techniques and identiﬁed various limitations with respect to processing very high-resolution imagery
with common registration errors. One of the major limitations of pixel-based comparisons is overcome by modeling
the image as set of grids, which is much more robust to most registration errors in the image. Though the algorithm
performed well in detecting the changes identiﬁed by the human analyst, one will notice few omission and commission
errors. Additionally, one might notice artiﬁcial edges (artifacts of the block size chosen), which can be easily ﬁxed
by choosing a ﬁner grid size at the cost of computational time. Omission and commission errors can also be ﬁxed
by modeling spatial relationships and incorporating additional features like texture, SIFT, and histogram of gradients.
Currently we are evaluating the algorithm on diﬀerent study sites, especially sites aﬀected by natural disasters. In
addition, our future research will address some of the limitations identiﬁed in this study.
6. Acknowledgments
We would like to thank our colleagues and collaborators B. Bhaduri, M. Tuttle, E. Bright, A. Cheriyadat, and V.
Chandola for various contributions to this research. We would also like to thank anonymous reviewers for valuable

916

Ranga R. Vatsavai and Jordan Graesser / Procedia Computer Science 9 (2012) 907 – 916

(a) Diﬀerence

(b) Ratio

Figure 7: Settlement changes using diﬀerence and ration methods (Kacha Garhi camp, Pakistan).

feedback which greatly improved the quality of this paper.
Prepared by Oak Ridge National Laboratory, P.O. Box 2008, Oak Ridge, Tennessee 37831-6285, managed by
UT-Battelle, LLC for the U. S. Department of Energy under contract no. DEAC05-00OR22725.
7. References
[1] U. Nations, World urbanization prospects: The 2009 revision, Tech. rep., United Nations Department of Economic and Social Aﬀairs:
Population Divison (2010).
[2] P. S. Showalter, Remote sensing in disaster research: A review, Disaster Prevention and Management 10 (1) (2001) 21–29.
[3] A. Singh, Digital change techniques using remotely-sensed data, International Journal of Remote Sensing 10 (6) (1989) 989–1003.
[4] Building damage assessment, in support of post disaster needs assessment and recovery framework (PDNA), http://unosatmaps.web.cern.ch/unosat-maps/HT/EQ20100114HTI/PDNA HTI EQ2010 BuildingDamagePosterA0 v1 LR.pdf (2010).
[5] E. F. Lambin, A. H. Strahler, Change-vector analysis in multitemporal space: A tool to detect and categorize land-cover change processes
using high temporal-resolution satellite data, Remote Sensing of Environment 48 (1994) 231–244.
[6] E. F. Lambin, A. H. Strahler, Indicators of land-cover change for change-vector analysis in multi-temporal space at coarse spatial scales,
International Journal of Remote Sensing 15 (10) (1994) 2099–2119.
[7] Y. Yasouka, T. Yokota, T. Miyazaki, Y. Iikura, Detection of land-cover change from remotely sensed images using spectral signature similarity,
in: 9th Asian Conference on Remote Sensing (ACRS), 1988.
[8] A. A. Nielsen, K. Conradsen, J. J. Simpson, Multivariate alteration detection (mad) and maf postprocessing in multispectral, bitemporal image
data: New approaches to change detection studies, Remote Sensing of Environment 64 (1) (1998) 1 – 19. doi:10.1016/S0034-4257(97)
00162-4.
URL http://www.sciencedirect.com/science/article/pii/S0034425797001624
[9] M. Carlotto, A cluster-based approach for detecting man-made objects and changes in imagery, Geoscience and Remote Sensing, IEEE
Transactions on 43 (2) (2005) 374 – 387.
[10] F. Bovolo, L. Bruzzone, A split-based approach to unsupervised change detection in large-size multitemporal images: Application to tsunamidamage assessment, Geoscience and Remote Sensing, IEEE Transactions on 45 (6) (2007) 1658 –1670. doi:10.1109/TGRS.2007.895835.
[11] J. Im, J. R. Jensen, J. A. Tullis, Object-based change detection using correlation image analysis and image segmentation, Int. J. Remote Sens.
29 (2008) 399–423. doi:10.1080/01431160601075582.
URL http://portal.acm.org/citation.cfm?id=1450990.1450996
[12] R. J. Radke, S. Andra, O. Al-Kofahi, B. Roysam, Image change detection algorithms: a systematic survey, Image Processing, IEEE Transactions on 14 (3) (2005) 294–307. doi:10.1109/TIP.2004.838698.
[13] C. Fraley, A. E. Raftery, Model-based clustering, discriminant analysis, and density estimation, Journal of the American Statistical Association
97 (2002) 611–631.

