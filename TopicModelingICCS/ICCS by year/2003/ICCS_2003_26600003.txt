A Model for Predicting the Optimum
Checkpoint Interval for Restart Dumps
John Daly
Raytheon Intelligence and Information Systems, Garland, TX

Abstract. As the run time of an application approaches the the mean
time to interrupt (MTTI) for the system on which it is running, it becomes necessary to generate intermediate snapshots of the application’s
run state, known as checkpoint files or restart dumps. In the event of
a system failure that halts program execution, these snapshots allow an
application to resume computing from the most recently saved intermediate state instead of starting over at the beginning of the calculation.
In this paper three models for predicting the optimum compute intervals between restart dumps are discussed. These models are evaluated
by comparing their results to a simulation that emulate an application
running on a actual system with interrupts. The results will be used to
derive a simple method for calculating the optimum restart interval.

1

Introduction

When running on a system where the frequency of interrupts is low compared
to the runtime of a particular application, the total wall clock time accumulated
while running that application will simply be the computational solution time.
However, if we can reasonably expect one or more interrupts to occur during
the runtime of an application then we must adopt a strategy such as checkpoint
restart that allows us to write out an image of the current state of the calculation at pre-determined intervals. Qualitatively we can see that checkpointing too
frequently is disadvantageous, because writing a dump file can be time consuming, but not writing often enough might be equally perilous, because all the work
since the last checkpoint will be lost in the event of an interrupt. In this study we
will quantify the optimum restart interval that minimizes the total application
run time, and express the result in terms of a simple analytic approximation.
One strategy for optimizing the compute interval between dumps τ is to generate a cost function Tw (τ ), the total wall clock time to complete the execution
of an application, and find its minima. Quantitatively speaking
Tw (τ ) = Solve Time + Dump Time + Rework Time + Restart Time .

(1)

Solve time is defined as time spent doing actual computational cycles working
towards a final solution. For a system with no interrupts the wall clock time
Tw (τ ) consists entirely of computation time. Dump time is overhead spent writing out the checkpoint files required to restart the application after an interrupt.
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 3−12, 2003.
 Springer-Verlag Berlin Heidelberg 2003

42

J. Daly

Rework time is the amount of wall clock time lost when an application is killed
by an interrupt prior to completing a restart dump. It is the amount of time
elapsed since the last restart dump was successfully written. Restart time is the
time required before an application is able to resume real computational work.
It includes all overhead costs associated with restarting a calculation after an
interrupt.

2

The Models

2.1

A First Order Model

√
John W. Young [8] proposed τopt = 2δM as a useful first order approximation
of the optimum checkpoint interval, where δ is the time to write a checkpoint file,
M is the mean time between system failures, and τopt is the optimum compute
time between writing checkpoint files. We will start with a derivation similar to
Young’s estimate before moving on to deriving more accurate models. To help
us consider how different terms contribute to the total wall clock time, and how
the wall clock time relates to the solve time, consider figure 1 which provides a
conceptual view of an application run encountering a single interrupt.

τ

δ
τ

δ
X
R

τ

δ
τ

Ts = Nt
t=0

δ
τ
Tw(t)

Fig. 1. The application time line broken up into five passed compute segments and
one failed compute segment designated by on X. Passed segments are of three types:
solve-dump, restart-solve-dump, or solve-to-end. An application run is complete when
the accumulated computation time τ of all the passed segments is equal to the total
solution time Ts for the application.

Using figure 1 it is a straightforward to construct the cost function for total
wall clock time. Solve time will be τ n(τ ) where n(τ ) is the number of passed
segments required to complete a calculation. Dump time will be δ(n(τ ) − 1)

A Model for Predicting the Optimum Checkpoint Interval

35

where one is subtracted because there is no dump on the last segment. For
rework time we make the simplifying assumption that an interrupt is equally
likely to occur at any time during a compute segment. This implies that over a
large number of failures the time spent in rework is going to be approximately
half the segment length times the number of interrupts. In other words, rework
time will be described by 21 (τ + δ)N (τ ) where N (τ ) is the expected number of
interrupts over the course of the calculation. Finally, the total restart time is
simply RN (τ ), the amount of time required to restart times the total number
of failures. Combining these terms we construct our basic cost function as
Tw (τ ) = τ n(τ ) + (n(τ ) − 1) δ +

1
(τ + δ) N (τ ) + RN (τ ) .
2

(2)

Next we determine how to express the number of passed segments n(τ ) and
the expected number of restarts N (τ ) as a function of the compute time per
segment. As we see from figure 1, the number of passed segments required to
complete a jobs is just the solve time Ts for the job, which is fixed, divided by
τ . The expected number of restarts, assuming the number of interrupts is in
some sense statistically significant, will be the product of the number of passed
segments required to complete the calculation and the probability of each segment failing. Assuming interrupts arrive according to a Poisson process 1 , and
approximating the exponential term by a first order series expansion, we get
N (τ ) =

τ +δ
Ts
Ts
e M −1 ∼
=
τ
τ

τ +δ
M

for

τ +δ
M

1 .

(3)

We made the simplifying assumption that the contribution of the probability of
failure in a restart-solve-dump or a solve-to-end segment to the total number
of failures is inconsequential compared to the probability of a failure in a solvedump segment. We will need to revisit this assumption in our complete model.
Substituting the terms for n(τ ) and N (τ ) into our cost function gives
Tw (τ ) = Ts +

1
Ts
Ts
−1 δ+
(τ + δ) + R
τ
2
τ

τ +δ
M

.

(4)

Equation 4 will our cost function for the first order model. We are interested in
finding minima for values of τ > 0. To do this we consider solutions of the first
derivative with respect to τ equal to zero.
−

Ts
δTs
+
2
τ
M

δ2
1
δR
− 2− 2
2 2τ
τ

=−

1
2δM − 2δR + δ 2 + 1 = 0 .
τ2

(5)

Thus the minimization problem reduces to a simple quadratic form. Assuming
that the delta squared term in negligible, the assumption we made when we
expanded the exponential failure term in equation 3, we recover Young’s original
solution with an added term for the restart overhead.
τ=
1

See [4] and others.

2δ(M + R)

for

δ

M .

(6)

64

J. Daly

2.2

A Modified Model

The biggest limitation of the linear model is its poor predictive ability for small
values of M . The decision to use the series expansion of the exponential term in
equation 3 was justified by assuming that the elapsed time between restarts is
substantially less than the mean time between failures for the system. However,
as computing moves toward terascale systems, a multiplication of the numbers of
system components is resulting in a proportional decrease in the overall reliability
of the system. 2 In general, we cannot assume that (τ + δ)/M will be negligible.
With this in mind, let us rewrite equation 4 retaining the exponential term.
Tw (τ ) = Ts +

τ +δ
1
Ts
Ts
−1 δ+
(τ + δ) + R
e M −1
τ
2
τ

.

(7)

Using equation 7 as our new cost function, we will find the minima with
respect τ once again setting the derivative to zero.
e

τ +δ
M

τ 2 + (δ + 2R)τ − (δ + 2R)M + 2RM − δM = 0 .

(8)

Instead of expanding the exponential term, recast equation 8 as follows
(δ − 2R) M
τ +δ
= ln 2
M
τ + (δ + 2R)τ − (δ + 2R)M

= ln [g(τ )] .

(9)

We know that (τ + δ)/M is never negative, which means that g(τ ) > 1 for all τ .
So we will try a series expansion for the natural logarithm of g(τ ) as follows:
2

3

g(τ ) − 1 1 g(τ ) − 1
1 g(τ ) − 1
τ +δ
=
+
+
···
M
g(τ )
2
g(τ )
3
g(τ )
.
2
3
1
1
1
1
1
= 1−
+
···
+
1−
1−
g(τ )
2
g(τ )
3
g(τ )

(10)

Since g(τ ) > 1, as we noted in equation 9, it follows that 0 < 1/g(τ ) < 1 and
therefore (1 − 1/g(τ )) < 1. Thus, the series expansion is expected to converge,
albeit slowly for large values of g(τ ). Ignoring higher order terms once again, we
are left with a simple relationship, which can be reduced to a quadratic form.
τ 2 + (δ + 2R)τ − (δ + 2R)M
(δ + 2R)M
⇓
τ 2 + 2δτ − δ 2 − 2δ(M + R) = 0 .

τ +δ
=
M

1−

(11)

Therefore, the value of τ which minimizes equation 7 is approximately
τ=
2

2δ(M + R) − δ .

(12)

For example, preliminary data for the first 10 TeraOP/s segment of the 30 TeraOP/s
ASCI Q machine at Los Alamos National Laboratory indicates M ∼
= 6.7 hours.

A Model for Predicting the Optimum Checkpoint Interval

2.3

57

A Complete Model

With both first order and modified models now derived we will reconsider two
of our assumptions which turn out not to be very accurate for small M . The
first assumption that will cause us difficulty was made in equation 2 where the
fraction of a segment requiring rework is approximated as one-half. In fact, that
was a reasonable approximation for large M , but as M approaches τ + δ the
fraction of rework drops off rather precipitously as depicted in figure 2. For very
small M , the expected failure time is going to actually be shorter than the solvedump segment itself, meaning that the beginning of the segment will see far more
failures than the end of the segment.

Fraction of Interval Completed Prior to Interrupt

0.5

0.45

0.4

0.35
15 Minutes
30 Minutes
0.3

60 Minutes
120 Minutes
240 Minutes

0.25

0.2
0

4

8

12

16

20

24

28

32

Mean Time to Interrupt (Hours)

Fig. 2. The fractional amount of rework required following a system interrupt for
various compute intervals is reported as the mean of multiple simulations for a given
compute interval. Each function represents a different interval between restart dumps,
ranging from 15 minutes to 4 hours.

To better grasp of how these expected failures are behaving, consider that
the probability of a failure occurring halfway through any arbitrary compute
segment is actually the sum of the probabilities of the failure occurring halfway
through the first segment plus the probability of it occurring halfway through the
second interval and so forth. In other words, the distribution function describing
the probability of failure at a time t in any arbitrary compute segment will be
t

f (t) =

1 − t+∆t
1 − t+2∆t
e− M
1 −t
e M +
e M +
e M + ··· =
∆t
M
M
M
M 1 − e− M

.

(13)

86

J. Daly

Therefore, the expected point of failure for a random variable T in the range
0 ≤ T ≤ ∆t in terms of the probability density function f (t) will be given by
E(T ) =

∆t
0
∆t

=

0

M

tf (t) dt
t

t

te− M dt

∆t
1−e− M

=

t

−Mte− M −M 2 e− M

∆t
0

M

∆t
1−e− M

=

Me

∆t
M −M−∆t
∆t
e M −1

(14)

∆t

.
∆t
1−eM
So, instead of 12 , the expected fraction of rework Φ(∆t) over a time interval ∆t
will actually be E(T ) derived in equation 14 divided by the length of the interval
M
1
φ(∆t) =
+
.
(15)
∆t 1 − e ∆t
M
The second difficulty with our simplified models is that the segment size for
a failure is always assumed to be τ + δ, which means a failure never occurs in a
restart-solve-dump segment. Failures occurring in a restart-solve-dump segment
should be represented by a segment length of R + τ + δ in the model. If we
complete the restart-solve-dump segment successfully then the contribution of
the interrupt to the solution wall clock time is the restart time plus the expected
rework time for a solve-dump segment. Otherwise the contribution to wall clock
time is the expected rework time for the restart-solve-dump segment.
Previously, in equation 2, we estimated the contribution of restart and rework
to our cost function as
1
(τ + δ) N (τ ) + RN (τ ) .
(16)
2
Based on the correction for the fraction of rework in equation 15, the distinction
between failed solve-dump segments and restart-solve-dump segments can be
incorporated into equation 16 as
=M+

[φ1 (τ )(τ + δ)N (τ ) + RN (τ )]P (τ ) + φ2 (τ )(R + τ + δ)(1 − P (τ ))N (τ ) .

(17)

where φ1 (τ ) is the fractional rework associated with a solve-dump segment,
φ2 (τ ) is the fractional rework associated with a restart-solve-dump segment,
and P (τ ) is the probability of successfully completing the restart-solve-dump
segment immediately following an interrupt.
Furthermore, in order to allow for the possibility of multiple restarts in a
single compute segment we must redefine N (τ ). Instead of estimating the total
number of failures by the number of compute segments divided by the probability
of a failure in each segment, we will now use the total wall clock time divided
by the mean time between failures. So after we replacing N (τ ) by Tw (τ )/M our
complete model in implicit form becomes
Tw (τ ) = Ts +

Ts
−1 δ +
τ

Tw (τ )
{[φ1 (τ )(τ + δ) + R]P (τ ) + φ2 (τ )(R + τ + δ)(1 − P (τ ))}
M
or, in explicit form, it is

(18)

A Model for Predicting the Optimum Checkpoint Interval

Tw (τ ) =

1−

1
M

79

Ts − δ + δTτ s
{[φ1 (τ )(τ + δ) + R]P (τ ) + φ2 (τ )(R + τ + δ)(1 − P (τ ))}







M
1
+
+δ
τ + δ 1 − e τM
1
M
where
+
φ2 (τ ) =
R+τ +δ


R+τ +δ

1−e M

R+τ

− M+δ
P (τ ) = e
φ1 (τ ) =













(19)
.

The classic method of minimizing such a function numerically is to solve for
zeros of the derivative using an iterative approach such as Newton-Rhapson. In
this case obtaining the derivative analytically is far from trivial, so we will use
a simple bisection method to determine the minimum. Starting with function
evaluations at tlo = and thi = M + R + δ we compute tavg = 21 (tlo + thi ). Then
we compute the derivative at each of the three points using a first order central
difference scheme and compare the signs of the derivatives. The minimum value
of Tw (τ ) is located in whichever of the sub ranges [τlo , τavg ] or [τavg , τhi ] have
derivatives of opposite signs at their endpoints. By successively bisecting subsegments of the range [ , M ] until τhi − τlo < we arrive at an approximation of
τ that minimizes the solution wall clock time.

3

The Simulation

To validate the model results, a simulation was developed that generates pseudorandom interrupts from an exponential deviate. It then simulates the execution
of a real code using these randomly generated interrupts to determine in which
compute segments restarts will occur. By keeping track of both the accumulated
wall clock time and the accumulated solve time we are able to determine the
total wall clock time for solution by cycling through compute segments until the
accumulated solve time from each of the segments is equal to the total solve
time. The simulation is run multiple times and results are reported in terms of
the median wall clock time and a 90% range (represented by the error bars in
figures 3-5).

4

Results

In our first test case illustrated by figure 3 we find excellent agreement between
the first order model, complete model, and simulation results. Notice that median
wall times reported by the simulation increase more slowly for τ > τopt than
for τ < τopt even though the variances are larger. This means that an overly
conservative estimate of the optimum restart interval may actually result in
longer run times than an equivalent over prediction.

10
8

J. Daly

Total Elapsed Wall Clock Time (hours)

650

625

First Order Model
Complete Model
Simulation

600

575

550

525

500
0

20

40

60

80

100

120

140

160

180

200

220

Compute Interval Between Dumps (minutes)

Fig. 3. A comparison of model and simulation results for M = 24 hrs. Ts = 500 hrs,
R = 10 mins, and δ = 5 mins. The complete model predicts τopt = 114 mins.

In figure 4 the MTTI decreases and we see a significant increase in runtime
and shortening of the optimum compute interval. We find that the first order
model is beginning to diverge from the simulation results because the linear
approximation to the exponential is breaking down as τ + δ approaches O(M ).

Total Elapsed Wall Clock Time (hours)

650

625

First Order Model
Complete Model
Simulation

600

575

550

525

500
0

20

40

60

80

100

120

140

160

180

200

220

Compute Interval Between Dumps (minutes)

Fig. 4. A comparison of model and simulation results for M = 6 hrs. Ts = 500 hrs,
R = 10 mins, and δ = 5 mins. The complete model predicts τopt = 56 mins.

Figure 5 represents a pathological case where for some choices of τ the interval
between restart dumps actually exceeds the MTTI for the system. The first order
model fails to predict either the total runtime or the minimum runtime. However,
agreement between the simulation and the complete model is still excellent.

A Model for Predicting the Optimum Checkpoint Interval

11
9

Total Elapsed Wall Clock Time (hours)

2800

2600

2400

First Order Model
Complete Model
Simulation

2200

2000

1800
0

4

8

12

16

20

Compute Interval Between Dumps (minutes)

Fig. 5. A comparison of model and simulation results for M = 15 mins. Ts = 500 hrs,
R = 10 mins, and δ = 5 mins. The complete model predicts τopt = 9 mins.

Finally, figure 6 shows a comparison between the calculated compute interval
τ for all three models. The agreement between the predictions of the modified
model and the complete model are within 5% for all MTTI greater than 1 hour.
180

90

150

75

Modified Model
Complete Model

120

% Error (First Order vs. Complete)
% Error (Modified vs. Complete)

90

60

45

60

30

30

15

0
0.1

1

10

Percent Error

Optimum Compute Interval (Minutes)

First Order Model

0
100

MTTI (Hours)

Fig. 6. A comparison of all three models for predicting the optimum compute interval
between writing checkpoint files. Ts = 500 hrs, R = 10 mins, and δ = 5 mins.

Figures 3-5 show the results of the first order and the complete model compared to the simulation results with error bars to indicate the range in which
90% of the simulation data fell. The main purpose of these is to validate the
complete model against the simulation results. We also find that the first order
model completely fails to predict simulation results for small M . Not only does

12
10

J. Daly

it under-predicted the total wall clock time, it also fails to locate the minimum
because the function has been sufficiently flattened by using the linear term of a
divergent series to represent the exponential. Finally, figure 6 compares the first
order model and the modified model to the complete model. This comparison is
intended to demonstrate that the modified model is in fact an improvement over
the first order model. Empirically, we see that for (τ + δ)/M < 21 we get good
agreement between the τopt predicted by the modified model and that predicted
by the complete model.

5

Conclusions

We considered three models for predicting the runtime and optimum restart
interval. We compared their runtime predictions to the results of a simulation.
Since the complete model agrees with simulation in predicting total application
runtime we used it to establish a baseline for the optimal compute interval.
Then we compared the first order and modified models to the complete model
and concluded that the optimum restart interval estimate given by the modified
model is in fact an improvement over the first order model. In other words, τopt =
2δ(M + R) − δ is an excellent estimator of the optimum compute interval
between restart dumps for values of (τ + δ)/M < 21 .

References
1. Bruno, J., Coffman, E. G.: Optimal Fault-Tolerant Computing on Multiprocessor
Systems. Acta Informatica 34 (1997) 881–904
2. Coffman, E. G., Gilbert, E. N.: Optimal Strategies for Scheduling Checkpoints and
Preventive Maintenance. IEEE Transactions on Reliability 39 (1990) 9–18
3. Dimitrov, B., Khalil, Z., Kolev, N., Petrov, P.: On the Optimal Total Processing
Time Using Checkpoints. IEEE Transactions on Software Engineering 17 (1991) 436–
442
4. Kwak, S. W., Choi, B. J., Kim, B. K.: An Optimal Checkpointing-Strategy for RealTime Control Systems Under Transient Faults. IEEE Transactions on Reliability 50
(2001) 293–301
5. Ling, Y., Mi, J., Lin, X.: A Variational Calculus Approach to Optimal Checkpoint
Placement. IEEE Transactions on Computers 50 (2001) 699–708
6. Magazine, M. J.: A Closed-Form Solution to a Class of Quadratic Knapsack Problems. INFOR 30 (1992) 6–10
7. Vaidya, N. H.: Impact of Checkpoint Latency on Overhead Ratio of a Checkpointing
Scheme. IEEE Transactions on Computers 46 (1997) 942–947
8. Young, J. W.: A First Order Approximation to the Optimum Checkpoint Interval.
Communications of the ACM 17 (1974) 530–531

