Improved Algorithms for Eﬃcient Arithmetic on
Elliptic Curves Using Fast Endomorphisms
Mathieu Ciet1 , Tanja Lange2 , Francesco Sica1 , and
Jean-Jacques Quisquater1
1

UCL Crypto Group
Place du Levant, 3. B-1348 Louvain-la-Neuve. Belgium
{ciet,sica,jjq}@dice.ucl.ac.be − http://www.dice.ucl.ac.be/crypto/
2
Institute for Information Security and Cryptology (ITSC)
Ruhr-Universit¨
at Bochum, Universit¨
atsstraße 150, D-44780 Bochum, Germany
lange@itsc.ruhr-uni-bochum.de − http://www.ruhr-uni-bochum.de/itsc/

Abstract. In most algorithms involving elliptic curves, the most expensive part consists in computing multiples of points. This paper investigates how to extend the τ -adic expansion from Koblitz curves to a larger
class of curves deﬁned over a prime ﬁeld having an eﬃciently-computable
endomorphism φ in order to perform an eﬃcient point multiplication
with eﬃciency similar to Solinas’ approach presented at CRYPTO ’97.
Furthermore, many elliptic curve cryptosystems require the computation of k0 P + k1 Q. Following the work of Solinas on the Joint
Sparse Form, we introduce the notion of φ-Joint Sparse Form which
combines the advantages of a φ-expansion with the additional speedup
of the Joint Sparse Form. We also present an eﬃcient algorithm to
obtain the φ-Joint Sparse Form. Then, the double exponentiation
can be done using the φ endomorphism instead of doubling, resulting
in an average of l applications of φ and l/2 additions, where l is
the size of the ki ’s. This results in an important speed-up when the
computation of φ is particularly eﬀective, as in the case of Koblitz curves.
Keywords. Elliptic curves, fast endomorphisms, Joint Sparse Form.

1

Introduction

Let Fq , with q = p , p prime, be a ﬁnite ﬁeld. In cryptography, one is mainly
interested in the following two cases: q = 2 (binary ﬁelds) or q = p > 3 (prime
ﬁelds). Let E be an elliptic curve deﬁned over Fq and P ∈ E(Fq ) a point of
The work described in this paper has been supported [in part] by the Commission
of the European Communities through the IST Programme under Contract IST1999-12324, http://www.cryptonessie.org/. The information in this document is
provided as is, and no guarantee or warranty is given or implied that the information
is ﬁt for any particular purpose. The user thereof uses the information at its sole
risk and liability. The views expressed are those of the authors and do not represent
an oﬃcial view/position of the NESSIE project (as a whole).
E. Biham (Ed.): EUROCRYPT 2003, LNCS 2656, pp. 388–400, 2003.
c International Association for Cryptologic Research 2003

Improved Algorithms for Eﬃcient Arithmetic on Elliptic Curves

389

large prime order n (typically n > q/5). In elliptic curve cryptography, it is
essential to be able to compute quickly a multiple kP for any k ∈ [1, n − 1]. A
few methods use fast computable endomorphisms φ [9,11,12,14,15,17,19,20,21].
For binary Koblitz curves [11,12,21], it is standard to use as φ the Frobenius
endomorphism over F2 (often denoted τ ). One then gets a decomposition
kP = k0 P + k1 φ(P ) + · · · + km φm (P ) ,

(1)

with the ki = 0, ±1, similar to the signed binary decomposition of k. Using the
fact that φ (P ) = P , one can take m = log2 n .
Over prime ﬁelds, one uses an eﬀective endomorphism φ such that its minimal
polynomial X 2 + rX + s has small coeﬃcients: this is the method of GallantLambert-Vanstone (GLV for short). The GLV method [9,17,19] therefore works
on those elliptic curves over Fp with endomorphism ring having small discriminant. The substance of the GLV method is to decompose kP as
√
(2)
kP = k0 P + k1 φ(P ), with max{|k0 |, |k1 |} = O( n)
and then compute k0 P and k1 φ(P ) “simultaneously” (this is true if one can
parallelize the architecture, otherwise, some speedup can still be obtained√by
Solinas’ Joint Sparse Form√(JSF) [23]). In practice, the constant in the O( n)
estimate is small (around 4s − r2 /4 , see [19]) and in the examples can even
be taken to be 1.
Our ﬁrst contribution is to show that the GLV algorithm is just the ﬁrst
ingredient to get a generalized base-φ expansion leading to the same kind of
decomposition as (1), with ki ∈ R = {−u, . . . , u} and u small – in the examples
we present even u = 1. To use such an expansion one applies Horner’s rule
kP = φ(φ(· · · φ(km P ) + km−1 P ) + · · · + k1 P ) + k0 P . If u is small one can
easily precompute all ui P, 0 ≤ ui ≤ u. Then this computation reduces to m
applications of φ and for each non-zero coeﬃcient ki one table look-up and one
addition.
The eﬃciency of this method relies heavily on the ratio of the costs for curve
doublings and the operation of φ. We show that for the examples these expansions lead to faster scalar multiplication than the binary method and compare
it to the GLV method.
Our second contribution is the development of a fast algorithm to perform
double exponentiations a` la Solinas, when a fast endomorphism is available.
Indeed, there are several occasions where one computes k0 P + k1 Q, e. g. to check
a signature or when applying the GLV method (then Q = φ(P )). The JSF is
a standard tool to speed up this computation. It decomposes the multipliers in
base 2 and achieves a joint density of 1/2.
If the curve is such that there exists an eﬃciently computable endomorphism
φ, we can combine the speed-up gained by using a φ expansion like (1) together
with the JSF in a nontrivial fashion to obtain what we call the φ-JSF. If the
characteristic polynomial of φ is P (X) = X 2 ± X + 2 or P (X) = X 2 + 2 (these
polynomials are the main cases of interest as they occur in the applications) we
obtain the same density of 1/2 and a similar length of the expansion.

390

M. Ciet et al.

Applications are to further speed up the scalar multiplication on Koblitz
curves and to check signatures on them more eﬃciently (Koblitz curves are suggested in the NIST standard [16]). If φ is an endomorphism of a prime ﬁeld
curve then the φ-JSF can similarly be applied and can give better performance
than the GLV method combined with the original JSF. For simplicity, we assume
minimal precomputation. In general, allowing more precomputations additionally speeds up the scalar multiplication, see [2] for an overview of the applications
we consider here.

2

Basic Notations and Preliminaries

Here we brieﬂy introduce elliptic curves and review techniques for binary expansions that are used later on. An elliptic curve over a ﬁnite ﬁeld Fq can be given
by a Weierstraß equation
E : y 2 + (a1 x + a3 )y = x3 + a2 x2 + a4 x + a6 , ai ∈ Fq .
The group one uses consists of the aﬃne points (x, y) ∈ F2q satisfying the equation
along with a point O at inﬁnity. Depending on the implementation environment
diﬀerent systems of coordinates might be advantageous; the following two systems avoid inversions in the group operations. In projective coordinates a point
is represented as (X : Y : Z) with x = X/Z, y = Y /Z, in Jacobian coordinates
(X : Y : Z) stands for the aﬃne point (X/Z 2 , Y /Z 3 ). In aﬃne coordinates an
addition of distinct points takes 1 inversion, 2 multiplications (M) and 1 squaring (S) whereas a doubling takes one more squaring, in projective coordinates an
addition is computed using 12M and 2S and a doubling in 7M and 5S. Jacobian
coordinates lead to 12M and 4S for an addition and 4M and 6S for a doubling.
For more details we refer to [6]. For special choices of the coeﬃcients ai fewer
operations are needed.
We now turn our attention to (signed) binary expansions. By density of an
expansion we mean the number of nonzero coeﬃcients (Hamming weight) divided
by the length of the expansion. The Non Adjacent Form (NAF) of an integer
i
k is a signed binary expansion k =
i ki 2 with ki ∈ {0, ±1} and ki ki+1 =
0 (see e. g. [13,18,21] for algorithms to compute it). The average density of a
NAF expansion is approximately 1/3, for an ordinary binary expansion it is 1/2.
Shamir [7] rediscovered an eﬃcient trick, originally due to Straus [24], to speed
up the evaluation of k0 P + k1 Q (see [3]; also [10] for a survey of exponentiation
algorithms). A naive way for this double scalar multiplication is to compute
both powers separately needing 2l doublings and l additions on average if k0
and k1 have length l. Shamir’s proposal resulted in two methods, one called
simple Straus-Shamir method and the other fast Straus-Shamir method. The
last one requires the precomputation of P + Q and k0 P + k1 Q is evaluated with
l doublings and 3l/4 additions on average.
In [23] Solinas extended the Straus-Shamir method to the case of signed binary expansions, which is useful for groups where negating is cheap, coming up
with the Joint Sparse Form. This is especially useful for jacobians of elliptic and

Improved Algorithms for Eﬃcient Arithmetic on Elliptic Curves

391

hyperelliptic curves, where point inversion is virtually free. He gave an eﬃcient
algorithm to compute the JSF and also proves some properties of this decomposition. Let us brieﬂy recall the axioms deﬁning this decomposition (cf. [23] for
notation):
(JSF 1) Of any three consecutive columns at least one is a zero column.
(JSF 2) It is never the case that ui,j+1 ui,j = −1.
(JSF 3) If ui,j+1 ui,j = 0 then u1−i,j+1 = ±1 and u1−i,j = 0.
Example 1. Let k0 = 403 and k1 = 334, the NAF expansions [13] of k0 and k1
are given (in big endian notation) on the left, while the JSF is on the right.
k0 = 1 0 -1 0 0 1 0 1 0 -1 = 1 0 -1 0 0 1 0 0 1 1
k1 = 0 1 0 1 0 1 0 0 -1 0 = 1 0 -1 -1 0 1 0 0 -1 0
Deﬁne the joint Hamming weight of any joint binary expansion of two integers
written down as in the example to be the number of nonzero columns. The joint
Hamming weight gives the number of additions ±P , ±Q, ±(P + Q) or ±(P − Q)
to perform during the course of the joint double and add algorithm to compute
k0 P + k1 Q. Since the JSF is a generalization of the fast Straus-Shamir method,
it is supposed that P , Q, P + Q and P − Q have been precomputed and stored.
Hence to make the computation less expensive, it is vital to get the lowest
possible joint Hamming weight. In the example, the joint NAF decomposition
has joint Hamming weight 8, whereas the JSF lowers it to 6.
The JSF has many nice properties, which we recapitulate here.
Theorem 1 (from [23]). The Joint Sparse Form of any two integers exists and
is unique. It has minimal joint Hamming weight among all joint signed binary
expansions. If k0 and k1 have maximal length l, then the joint double and add
algorithm computes k0 P + k1 Q from the JSF with an average of l doublings and
l/2 additions of either ±P , ±Q, ±(P + Q) or ±(P − Q).
If one cannot aﬀord to store and precompute 3 points then the best way is
to take k0 , k1 both in NAF representation. The joint density is 5/9 on average.
Of this 5/9 proportion of non-zero columns, 1/9 has two non-zero entries and
4/9 exactly one zero entry. Without precomputation, in the former case the joint
double and add algorithm has to perform two additions at that step while in
the latter one addition is needed. For k0 , k1 both of length l, this amounts to
2l/3 additions and l doublings. Hence, compared to the naive way, the number
of additions remains unchanged but the number of doublings is halved.

3

Key Decomposition: φ-Expansions

The aim of this section is to describe how to obtain a decomposition to the base
of φ. Recall that φ is an endomorphism of the curve with X 2 +rX +s as minimal
polynomial. We assume s > 1. Given z ∈ Z[φ], we want to decompose it as
z = k0 + k1 φ + · · · + km φm

with ki ∈ R .

(3)

We ﬁnd the coeﬃcients k0 , . . . , km inductively. The following lemma is needed.

392

M. Ciet et al.

Lemma 1 (Lemma 5.3 of [12]). Let a, b ∈ Z, then φ divides a + bφ in Z[φ] if
and only if s divides a.
This implies that a choice of R as a complete set of residues modulo s is necessary
and suﬃcient to guarantee the existence and uniqueness of k0 . As taking the
negative of a point is for free, we choose a set of remainders symmetric w. r. t.
zero. When s is odd, a complete choice is R = {−(s − 1)/2, . . . , (s − 1)/2}. In
even characteristic we include both −s/2 and s/2 without enlarging the number
of precomputations. Thus when s is even we take R = {−s/2, . . . , s/2}. From
now on we stick to this choice of R.
Let z = z0 + z1 φ ∈ Z[φ]. To decompose z we put k0 ≡ z0 mod s. Then using
the minimal polynomial X 2 + rX + s of φ, i. e. s = −rφ − φ2 , we get
z = k0 +

z0 − k0
s + z1 φ = k0 + φ
s

k0 − z0
r + z1
s

+

k0 − z0
φ .
s

We then replace z by (z − k0 )/φ and ﬁnd k1 , then replace z by (z − k1 )/φ
and compute the coeﬃcients iteratively. The main question is now to show that
this process stops after ﬁnitely many steps and to bound the length of these
expansions.
Theorem 2. Let s > 1. Then z = z0 + z1 φ ∈ Z[φ] can be expanded as (3) with
m ≤ 2 logs 2 z02 − rz0 z1 + sz12 +3 except when (r, s) = (±2, 2), (±3, 3), (±4, 5)
or (±5, 7). In these cases one has to allow km−1 = ± (s + 1)/2 .
Proof. The proof follows the same lines as the corresponding proofs in [14] and
[20]. The fact that φ is not the Frobenius is not important at this stage. What
really matters is that the complex norm of φ is s. The additional cases of small s
which cannot occur as characteristic polynomial of the Frobenius endomorphism
(e. g. for s not a prime power) have been checked by hand.
Note that for z = k ∈ Z an integer multiplier, these theorems give a decomposition with length approximately 2 logs |k| ≈ 2 logs n for values of k used in
cryptography. This is twice as long as a s-ary expansion. If φ is the Frobenius
one can shorten the length in reducing k modulo φ − 1 before expanding (see
[12,21]). Closing up this gap for prime ﬁeld curves in the fashion of previous
authors is therefore necessary to gain advantage of this decomposition.
However, it is clear from previous research (see the use of λ-Euclidean rings
in [17,20]) that in fact one can cut down the length of the decomposition of the
multiplier k by replacing√
it by z0 + z1 φ, z0 , z1 ∈ Z, such that kP = z0 P + z1 φ(P )
and max(|z0 |, |z1 |) = O( n). But this is precisely the meaning of the GallantLambert-Vanstone (GLV) method for these curves. Then a direct application
of [19, Theorem 1] gives the following.
Theorem 3. Let P be a point of large prime order n on an elliptic curve and
φ a non trivial endomorphism such that φ2 + rφ + s = 0. Then, for an arbitrary 1 ≤ k ≤ n the above algorithm coupled with a GLV reduction gives a
decomposition (1) where ki ∈ R (with the exceptions listed in Theorem 2) and
m ≤ 2 logs 2 1 + |r| + s + logs n + 3.

Improved Algorithms for Eﬃcient Arithmetic on Elliptic Curves

393

In the case where n is the norm of some element of Z[φ] (which is true if Z[φ]
is integrally closed and principal), applying [19, Theorem 3] we can replace
1 + |r| + s by a smaller value. However, for practical purposes the previous
theorem is clearly suﬃcient since now – up to a few constant bits – we can
achieve a decomposition of length logs n.
For s = 1 a φ-expansion must have exponential length. It is not hard
√ to show
in this case that if in (3) we have |ki | ≤ u, then one gets that m > n/(2u) so
that u must be very large in order to get m = O(log n). Therefore, we cannot
apply such a decomposition eﬃciently.
In the well-studied cases, where φ is the Frobenius endomorphism, these
expansions lead to a large speed-up. Application of φ then corresponds to p-th
powering. If the ﬁeld elements are represented with respect to a normal basis, the
application of φ is for free as it is performed via a cyclic shift of the components.
For a polynomial basis these costs cannot be neglected but are signiﬁcantly
less than a group operation, independently of the coordinate system we use to
represent the points.
For other endomorphisms we quote here two examples appearing already
in [5,9,17]. Note that in these examples, Z[φ] is the maximal order and it is
principal, and that s = 2. Using complex multiplication one can construct further
examples. For larger s the expansions get shorter. However, in light of what
follows these examples with s = 2 are of special interest. Here, we compare the
number of operations to compute the endomorphism to those needed for point
doublings in the same set of coordinates. We choose projective coordinates as
then the number of operations needed to compute φ is minimal and the additions
are cheaper than in Jacobian coordinates.
Example 2. Let p > 3 be a prime such that −7 is a quadratic residue modulo
p.
√
Deﬁne an elliptic curve E3 over Fp by y 2 = x3 −3x2 /4−2x−1. If ξ = (1+ −7)/2
and a = (ξ − 3)/4, then the map φ deﬁned in the aﬃne plane by
φ(x, y) =

x2 − ξ y(x2 − 2ax + ξ)
,
− a)
ξ 3 (x − a)2

ξ 2 (x

,
√

is an endomorphism of E3 deﬁned over Fp with Z[φ] = Z[ 1+ 2 −7 ]. Moreover φ satisﬁes the equation φ2 − φ + 2 = 0. In aﬃne coordinates, the formulæ given previously are clearly more expensive, as already noticed in [9,17],
than doubling [1,4]. However, in projective coordinates, φ(X, Y, Z) is given by
φ(X, Y, Z) = (EF, Y (A − 2XD + C), F 2 B) with A = X 2 , B = ξZ, C = BZ,
D = aZ, E = A − C and F = (X − D)ξ.
Then, given a point P = (X, Y, Z) its image by φ is computed with 8 multiplications and 2 squarings compared to 7 multiplications and 5 squarings for point
doubling.
Example 3. Let p > 3 be a prime such that −2 is a quadratic residue modulo p.
Deﬁne an elliptic curve E4 over Fp by y 2 = 4x3 − 30x − 28. The map φ deﬁned
in the aﬃne plane by

394

M. Ciet et al.

φ(x, y) =

−

2x2 + 8x − 1
2x2 + 4x + 9
,− √
y
4(x + 2)
4 −2(x + 2)2

√
is an endomorphism of E4 deﬁned over Fp with Z[φ] = Z[ −2]. Moreover
φ satisﬁes the equation φ2 + 2 = 0. As in the previous example, the endomorphism formulæ are more expensive than those for doubling in aﬃne coordinates. However, in projective coordinates the endomorphism can be com2
puted as φ(X, Y, Z) = (D(2A + 4B + 9Z√
), (2A + 8B − Z 2 ) Y, −4DCZ) with
2
A = X , B = XZ, C = X + 2Z and D = −2 C.
Therefore, this endomorphism is signiﬁcantly faster than a doubling since given
a point P in projective coordinates, φ(P ) can be computed with only 6 multiplications and 2squarings 1 .
Density. We now show that we can lower the density of the φ-expansion, for the
expansions of the examples from the obvious 1/2 to 1/3. For applications with
larger s similar considerations hold but the eﬀects are not that dramatic, however, the length is shorter as a compensation. In [21] Solinas considers expansions
to the base of the Frobenius τ for Koblitz curves. The characteristic polynomial
of τ for the curves y + xy = x3 + ax2 + 1 over F2 is given by X 2 + (−1)a X + 2. He
introduces a τ -Non Adjacent Form (τ -NAF) and states algorithms to compute
kP as kP = i ki τ i (P ) with ki = 0, ±1 and ki ki+1 = 0. Such an expansion has
an average density of 1/3.
This characteristic polynomial coincides with the one of φ in Example 2. Thus
also in this case we can compute a φ-NAF expansion of density 1/3 by exactly
the same algorithm. In the second example we have φ2 = −2. To obtain a lower
density of the expansion we impose a further condition on the ki in the expansion:
given z0 + z1 φ, for z0 ≡ 0 mod 2 choose k0 = 0 as before. Otherwise, put k0 ≡
z0 mods 4, where mods 4 means that one chooses ±1 as representatives modulo
4. This gives 2 | (z0 − k0 )/2, which sets to zero the next but one coeﬃcient;
and thus there is at least one zero coeﬃcient for each nonzero one (in this case
ki ki+2 = 0), again leading to a density of 1/3. In practice, in this case the φ-NAF
expansion is obtained from signed binary expansions of z0 and z1 . We refer to
such expansions as φ-NAFs.
Complexity and comparison with signed binary method. In the examples, the computation of kP using φ-expansions amounts approximately to log2 n
applications of φ and log2 n/3 additions. The expansions are of the same length
and density as the binary expansion but the doublings are replaced by cheaper
applications of φ. For both of these examples we thus obtain that computing
scalar multiples using a φ-expansion is more eﬃcient than via the binary method
as φ(P ) needs less than a doubling. This holds as well if the binary method uses
Jacobian coordinates.
Comparison with GLV method. As already mentioned, the GLV method
leads to a decomposition k = k0 + k1 φ. The binary length of ki is log2 n/2.
Taking both ki in binary NAF form, GLV needs log2 n/3 additions and log2 n/2
1

We count the multiplication of a number by

√

−2 as one multiplication.

Improved Algorithms for Eﬃcient Arithmetic on Elliptic Curves

395

doublings if φ(P ) is precomputed. We remark that our new method works without precomputations and then needs the same number of additions but replaces
the doublings by two times the number of applications of φ. Unfortunately, in
our examples two applications of φ need more operations than a doubling.
Following ideas similar to Solinas [21], one can adjust the computation of the
φ-adic expansion to allow an eﬃcient use of windowing techniques. Thus allowing
one precomputation as in the initial GLV method the number of additions in
our method reduces to log2 n/4.
If we use the JSF of k0 , k1 the number of additions drops down to log2 n/4 in
GLV. Using the JSF however implies that one precomputes 3 points. Using 3 precomputed points with our method as well, the density of the φ-expansion reduces
to 1/5. Applying this to the above examples we notice that the φ-expansion is
slightly slower than the GLV method no matter if GLV uses projective or Jacobian coordinates. However, the next section provides an improvement.

4

On the Joint Sparse Form

We now aim at combining both methods – the φ-expansion with the JSF. If
we need to compute k0 P + k1 Q, as for example in ECDSA [8], on a curve with
eﬃcient endomorphisms we can decompose k0 and k1 in base φ, but so far the
Joint Sparse Form can only be used with a binary expansion. Given the ki
in φ-NAF this leads to 2 log2 n/3 additions and log2 n applications of φ without
precomputations. Using the 2 precomputed values P ±Q the number of additions
drops down to 5 log2 n/9.
In the same spirit as the work of Solinas [23] we introduce the notion of φJoint Sparse Form (φ-JSF), which allows an application of the fast Straus-Shamir
method to φ-adic expansions of the scalars ki .
In the following, we denote by φ any endomorphism having X 2 − X + 2
as characteristic polynomial, with = ±1 (for instance the Frobenius endomorphism on binary Koblitz curves or φ from Example 2). The correct translation
of Solinas’ notion of JSF is as follows.
Deﬁnition 1 (φ-Joint Sparse Form). A joint expansion with coeﬃcients
0, ±1 is in φ-Joint Sparse Form (φ-JSF) if it satisﬁes the following properties:
(φ-JSF 1) Among three consecutive columns at least one is a double zero.
(φ-JSF 2) It is never the case that ui,j+1 ui,j = .
(φ-JSF 3) If ui,j+1 ui,j = 0 then u1−i,j+1 = ±1 and u1−i,j = 0.
Example 4. On the left we give the joint NAF expansion of k0 and k1 , on the
right the φ-JSF ( = 1).
k0 = -1 0 -1 0 -1 0 1 0 1 = -1 0 0 -1 1 0 0 1 -1
k1 = 0 -1 0 -1 0 0 0 1 0 = 0 -1 0 -1 0 0 0 1 0
The φ-Joint Sparse Form satisﬁes properties analogous to the properties of
the binary Joint Sparse Form.

396

M. Ciet et al.

Theorem 4. The φ-Joint Sparse Form of any two elements k0 and k1 of Z[φ]
exists and is unique. If k0 and k1 have maximal length l when written in φ-NAF
expansion, then the joint φ and add algorithm computes k0 P + k1 Q from the
φ-JSF with an average of l + 3 applications of φ and (l + 3)/2 additions of either
±P , ±Q, ±(P + Q) or ±(P − Q).
Proof. The proof will appear in the full version of the paper. It is similar to
Solinas’ proof, cf. [23].
Unfortunately, the minimality of the JSF does not carry over to the φ-JSF, since
the φ-JSF of ( 1, 0, −1 , 0, , 0 ) is ( − , 0, − , 0, − , 1 , 0, 0, 0, 0, , 0 ). However,
for large l, the φ-JSF has joint Hamming weight diﬀering from the minimum joint
Hamming weight at most by a small constant. We now give an algorithm similar
to Solinas’ Algorithm 2 to produce the φ-JSF of k0 and k1 , assuming they are
already written in some φ-adic expansion.
Algorithm 1
Input: k0 = k0,m−1 , . . . , k0,0 , k1 = k1,m−1 , . . . , k1,0 in φ expansion, put
ki,j = 0 for j ≥ m
Output: φ-JSF of k0 and k1
1. initialize:
j←0
For i from 0 to 1 do
Set di,0 ← 0, di,1 ← 0
ai ← ki,0 , bi ← ki,1 , ci ← ki,2
Next i
2. main loop:
while m − j + |d0,0 | + |d0,1 | + |d1,0 | + |d1,1 | > 0 do
a) choose coeﬃcient:
For i from 0 to 1 do
If di,0 ≡ ai mod 2
then set u ← 0
else
Set u ← di,0 + ai + 2(di,1 + bi ) mods 4†
If di,0 + ai − 2(di,1 + bi ) − 4ci ≡ ±3 mod 8
and d1−i,0 + a1−i + 2(d1−i,1 + b1−i ) ≡ 2 mod 4
then set u ← −u
Set ui,j ← u
Next i
b) setup for next step:
For i from 0 to 1 do
†

Here the notation mods 4 means that one chooses ±1 as representatives modulo 4
(for an odd number).

Improved Algorithms for Eﬃcient Arithmetic on Elliptic Curves

397

Set di,0 ← (di,0 + ai − ui,j )/2 + di,1
di,1 ← (di,1 − di,0 )
ai ← bi , bi ← ci , ci ← ki,j+3
Next i
c) Next j

Explanation. This algorithm is heavily inspired from Solinas’ Algorithm 2.
There are two main diﬀerences. The ﬁrst one is that there are two carries for
each line instead of only one. To draw a parallel with Solinas’ algorithm, we
introduce the quantity (complex carry) di = di,1 φ + di,0 . Then updating the
complex carry from step j to step j + 1 (ﬁrst two lines of setup for next step)
is equivalent to replacing these lines with
di ← (di + ai − ui,j )/φ.
The second one lies in imposing the right condition modulo 8. Namely the
condition mod φ3 now reads (by property (φ-JSF 2))
di + φ2 ci + φbi + ai ≡ ±(φ − ) mod φ3
and this is equivalent to di,0 +ai − 2(di,1 +bi )−4ci ≡ ±3 mod 8. Other conditions
modulo 2 and 4 are translations of similar congruences mod φ and φ2 .
When viewing the algorithm as using congruences modulo powers of φ and
leaving the complex carry without splitting it into di,1 and di,0 , one sees the full
appearance of the Solinas algorithm and using Solinas’ method it is straightforward to check that the above algorithm actually gives the φ-JSF of its inputs.
Remark 1. Note that the coeﬃcients ki,j need not necessarily take on values
from {0, ±1}. The algorithm works just as well on larger coeﬃcients ki,j (the
carries are then unbounded). Thus we need not compute a φ-expansion with
coeﬃcients in {0, ±1} prior to applying Algorithm 1. Thus e.g. for signature
veriﬁcation we can apply it directly on the outputs of either the GLV method
or the ki,0 + ki,1 φ ≡ ki mod φ − 1 (which is the output of Solinas’ algorithm to
reduce the length) in the case of Koblitz curves via ki = ki,1 , ki,0 .
Remark 2. The case φ2 = −2 (see Example 3) works in an even simpler way
with the modiﬁcations mentioned in the previous section.

5

Applications and Comparison

Fix the setting that each multiplier has length l and assume that l is even (to
shorten the explanations); all values hold approximately. There are two main
cases where the φ-JSF can be applied eﬃciently. One is obviously in signature
checking. If one point is going to be reused very often such that a costly precomputation is acceptable, precompute φl/2+1 P . Then one can ﬁrst compute a
l/2
l/2
φ-expansion and then split it in halves as i=0 ki φi + φl/2+1 i=0 ki+l/2 φi .

398

M. Ciet et al.

1. φ is the Frobenius. To check a signature k0 P + k1 Q the φ-JSF needs l applications of φ and l/2 additions. Using φ-NAFs of the ki with the same
precomputations and the Straus-Shamir method leads to 5l/9 additions and
again l applications of φ (this is just two squarings that are free if optimal
normal bases are used). Thus the φ-JSF wins over a joint φ-NAF. Also, because φ is very fast compared to doubling, the φ-JSF is much faster than
the binary JSF of k0 , k1 (remember that one ﬁrst reduces the size of ki using
the trick that a power of Frobenius acts trivially on P and Q).
2. φ is the Frobenius. Let φl/2+1 P be precomputed. To compute kP we ﬁrst
compute the φ-adic expansion of k as in [22], then split it and apply the
φ-JSF on both halves. This needs l/2 times φ and l/4 additions with 3
precomputations. The ordinary method needs l times φ and l/5 additions for
3 precomputations. φ-JSF is faster if an addition takes no more than 10 times
φ which holds for polynomial basis and all coordinate systems. (Assuming
that a multiplication takes at most 3 squarings, in aﬃne coordinates this
holds if one inversion takes less than 13 squarings – but otherwise aﬃne
coordinates would not be applied.)
3. φ is an endomorphism of the examples. If we have precomputed φl/2+1 P we
need l/2 times φ and l/4 additions with 3 precomputations. GLV also uses
3 precomputations and needs l/2 doublings and l/4 additions. As doublings
are more expensive, the φ-JSF is faster.
4. φ is an endomorphism of the examples and we check signatures. Let the
GLV method produce ki = ki,0 + ki,1 φ. The input to Algorithm 1 are
ki = ki,1 , ki,0 . This results in l times φ and l/2 additions. Taking a binary
expansion of ki and three precomputations, signature veriﬁcation needs l
doublings and l/2 additions – thus more than φ-JSF.
In this case the GLV method has to deal with a quadruple multiplication.
Using 6 precomputations (grouping together two binary expansions) they
need l/2 additions and l/2 doublings. Thus the φ-JSF is advantageous if
either φ takes less than half a doubling or if the space is more restricted.
Likewise one can compare this to a quadruple φ-expansion using the trick
above which results in l/2 additions and l/2 applications of φ, using 6 precomputations. Thus, if one can aﬀord these expensive precomputations and
the storage, the φ-JSF wins again.
Finally we remark that more precomputations in combination with the φJSF can be used to obtain further speedup. Avanzi [2] shows that allowing 10
precomputations one obtains an expansion needing only 3l/8 additions and l
doublings. His analysis applies also to the φ-JSF.

Acknowledgements. We are grateful to Takakazu Satoh for suggesting us to
extend the GLV method to include φ-NAF expansions. We would also like to
thank Roberto Maria Avanzi for useful comments on the preliminary version of
this paper.

Improved Algorithms for Eﬃcient Arithmetic on Elliptic Curves

399

References
1. IEEE Std 1363-2000. IEEE Standard Speciﬁcations for Public-Key Cryptography.
IEEE Computer Society, August 29, 2000.
2. R.M. Avanzi. On multi-exponentiation in cryptography. Technical Report
2002/154, Cryptology ePrint Archive, Available at:
http://eprint.iacr.org/2002/154, 2002.
3. D.J. Bernstein. Pippenger’s exponentiation algorithm. Available at:
http://cr.yp.to/papers.html, 2002.
4. I. Blake, G. Seroussi, and N. Smart. Elliptic Curves in Cryptography, volume 265
of London Mathematical Society. Cambridge University Press, 2000.
5. H. Cohen. A Course in Computational Algebraic Number Theory, volume 138 of
Graduate Texts in Mathematics. Springer, 1996.
6. H. Cohen, A. Miyaji, and T. Ono. Eﬃcient Elliptic Curve using Mixed Coordinates. In K. Ohta and D. Pei, editors, Advances in Cryptography - Proceedings
of ASIACRYPT 1998, volume 1514 of Lecture Notes in Computer Science, pages
51–65. Springer, 1998.
7. T. ElGamal. A public key cryptosystem and a signature scheme based on discrete
logarithms. IEEE Transactions on Information Theory, 31(4):469–472, 1985.
8. Standard for Eﬃcient Cryptography. Elliptic Curve Cryptography Ver.1.0. Technical report, Certicom, Available at: http://www.secg.org/drafts.html, 2001.
9. R. P. Gallant, J. L. Lambert, and S. A. Vanstone. Faster Point Multiplication
on Elliptic Curves with Eﬃcient Endomorphisms. In J. Kilian, editor, Advances
in Cryptology - Proceedings of CRYPTO 2001, volume 2139 of Lecture Notes in
Computer Science, pages 190–200. Springer, 2001.
10. D. M. Gordon. A Survey of Fast Exponentiation Methods. Journal of Algorithms,
27(1):129–146, 1998.
11. N. Koblitz. CM-curves with good cryptographic properties. In Joan Feigenbaum,
editor, Advances in Cryptology – Proceedings of CRYPTO 1991, volume 576 of
Lecture Notes in Computer Science, pages 279–287, Berlin, 1991. Springer.
12. T. Lange. Eﬃcient Arithmetic on Hyperelliptic Koblitz Curves. PhD thesis, University of Essen, 2001.
13. F. Morain and J. Olivos. Speeding up the Computations on an Elliptic Curve using
Addition-Subtraction Chains. Inform. Theor. Appl., 24:531–543, 1990.
14. V. M¨
uller. Fast Multiplication on Elliptic Curves over Small Fields of Characteristic Two. Journal of Cryptology, 11(4):219–234, 1998.
15. V. M¨
uller. Eﬃcient Point Multiplication for Elliptic Curves over Special Optimal
Extension Fields. In Walter de Gruyter, editor, Public-Key Cryptography and
Computational Number Theory, pages 197–207, Warschau, Poland, September 1115, 2000 (2001).
16. National Institute of Standards and Technology. FIPS-186-2: Digital Signature
Standard (DSS), January 2000. Available at
http://csrc.nist.gov/publications/fips/.
17. Y-H. Park, S. Jeong, C. Kim, and J. Lim. An Alternate Decomposition of an
Integer for Faster Point Multiplication on Certain Elliptic Curves. In D. Naccache
and P. Paillier, editors, Advances in Cryptology – Proceedings of PKC 2002, volume
2274 of Lecture Notes in Computer Science, pages 323–334. Springer, 2002.
18. G.W. Reitwiesner. Binary arithmetic. Advances in Computers, 1:231–308, 1960.

400

M. Ciet et al.

19. F. Sica, M. Ciet, and J-J. Quisquater. Analysis of the Gallant-Lambert-Vanstone
Method based on Eﬃcient Endomorphisms: Elliptic and Hyperelliptic Curves. In
H. Heys and K. Nyberg, editors, Proceedings of Selected Areas in Cryptography
(SAC 2002), Lecture Notes in Computer Science. Springer, 2002. To appear.
20. N.P. Smart. Elliptic Curve Cryptosystems over Small Fields of Odd Characteristic.
Journal of Cryptology, 12(2):141–151, 1999.
21. J. Solinas. Eﬃcient arithmetic on Koblitz curves. Designs, Codes and Cryptography, 19:195–249, 2000.
22. J. A. Solinas. An Improved Algorithm for Arithmetic on a Family of Elliptic
Curves. In Burton S. Kaliski Jr., editor, Advances in Cryptology – Proceedings of
CRYPTO 1997, volume 1294 of Lecture Notes in Computer Science, pages 357–371.
Springer, 1997.
23. J.A. Solinas. Low-Weight Binary Representations for Pairs of Integers. Technical
Report CORR 2001-41, CACR, Available at:
www.cacr.math.uwaterloo.ca/˜techreports/2001/corr2001-41.ps, 2001.
24. E.G. Straus. Addition chains of vectors (problem 5125). American Mathematical
Monthly 70, pages 806–808, 1964.

