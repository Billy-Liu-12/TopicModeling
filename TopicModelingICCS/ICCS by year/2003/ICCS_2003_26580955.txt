Performance Evaluation of the Striped
Checkpointing Algorithm on the Distributed
RAID for Cluster Computer
Yun Seok Chang1 , Sun Young Cho2 , and Bo Yeon Kim3
1

Department of Computer Engineering, Daejin University, Pocheon, Korea
Basic Science Research Institute, Chungbuk University, Chungju, Korea
BK21 Department of Electrical and Computer Engineering, Kangwon National
University Chuncheon, Korea
2

3

Abstract. The distributed RAID for serverless cluster computer is used
to save the checkpoint ﬁles periodically according to the checkpointing
algorithm for rollback recovery. Striped checkpointing algorithm newly
proposed in this paper can adopt the merits of the coordinated and
the staggered checkpointing algorithms. Coordinating enables parallel
I/O on distributed disks and staggering avoids network bottleneck in
distributed disk I/O operations. With a ﬁxed cluster size, we reveal
the tradeoﬀs between these two speedup techniques. The striped checkpointing approach allows dynamical reconﬁguration to minimize checkpointing overhead among concurrent software processes. We demonstrate
how to reduce the overhead by striping and staggering dynamically. For
communication-intensive computational programs, this new scheme can
signiﬁcantly reduce the checkpointing overhead. Linpack HPC Benchmark results prove the beneﬁts of trading between stripe parallelism and
distributed staggering. These results are useful to design eﬃcient checkpointing algorithm for fast rollback recovery from any single node failure
in a cluster computer.

1

Introduction

In the typical cluster computer system, all concurrent processes on diﬀerent
nodes should communicate with each other through message passing. Checkpointing algorithm can maintain the global consistency among the nodes by
saving the checkpoint data to the stable storage. Several checkpointing algorithms have been studied on the cluster computer. Coordinated checkpointing[1]
takes checkpoints from each node simultaneously at every time interval to yield
a consistent recovery globally in case of any failure. The drawback of the coordinated checkpointing is in the loss of freeze time for collecting checkpoints
from nodes at the same time and heavy network created by synchronized checkpointing. Simultaneous writing of checkpoint ﬁles into local disks may cause a
heavy network contention problem and disk IO bottleneck. To solve the disk
contention problem, diskless checkpointing algorithm was introduced[6]. But
the fault coverage is rather limited in a diskless checkpointing algorithm. So,
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2658, pp. 955–962, 2003.
c Springer-Verlag Berlin Heidelberg 2003

956

Y.S. Chang, S.Y. Cho, and B.Y. Kim

staggered checkpointing algorithm was introduced to write checkpoints onto a
central stable storage[8]. It can greatly reduce the storage contention to some extent. But the staggered checkpointing algorithm has to pay additional overhead
to achieve correct rollback recovery to avoid inconsistent states among cluster
nodes. Therefore, if the size of the cluster increases, message logging overhead
also increases. In a serverless cluster system, the distributed RAID system is
suitable for saving distributed checkpoint ﬁles simultaneously in disks attached
to cluster nodes[4]. Based on the distributed RAID, we propose striped checkpointing scheme. This scheme has two advantages. First, simultaneous distribution of the checkpoint ﬁles greatly alleviates the network IO contention problem
by taking advantage of parallel IO. Second, rollback recovery latency is reduced
on a distributed RAID system. So, mean time to repair of cluster is reduced
and high cluster availability can be achieved. To take advantage of parallelism of
the distributed RAID, the staggered checkpointing algorithm can be combined
with striped checkpointing algorithm. Only a subset of disks constitutes a stripe
group to take the checkpoint simultaneously. After one stripe group ﬁnishes
checkpointing, another stripe group starts checkpointing in a staggered manner.
This striped checkpointing algorithm has two beneﬁts. First, when the IO contention is more serious a problem, parallel IO of striped group helps lessening
the problem. Second, if network contention dominates, staggering can reduce it.
To evaluate the performance of the striped checkpointing scheme, we carried out
benchmark tests and compared with other checkpointing algorithm.

2

Distributed RAID and Single IO Space

To build a distributed RAID, all disks embedded in the cluster must establish
the single IO space(SIOS). The SIOS should have high scalability, availability,
and compatibility with IO centric cluster application. These should also imply
a total transparency to the users, who can utilize all disks without knowing the
physical locations of the data blocks. On NFS of centralized cluster ﬁle server,
all checkpoint ﬁles are saved on a network ﬁle system. On SIOS, checkpoint
ﬁles spread over the distributed disks. At the striped checkpointing scheme,
checkpoint ﬁles are saved over the distributed RAID system. Distributed RAID is
crucial to building scalable cluster of computers[5], and SIOS can be implemented
by using cooperative device drivers working at the system kernel[3]. These drivers
work together to establish the SIOS across all physical distributed disks. Once
the SIOS is established, all disks will be used collectively as a single global virtual
disk. Then cluster can be built serverless and oﬀers remote disk access directly
at the kernel level. Parallel IO is made possible on any subset of local disks, since
all distributed disks form SIOS. So, no heavy cross-node or process system calls
are needed to perform remote ﬁle access.

Performance Evaluation of the Striped Checkpointing Algorithm

3

957

Striped Checkpointing Scheme

The original concept of staggered checkpointing allows only one process to store
the checkpoint at a time. Figure 1 shows the timing diagram of staggered checkpoint scheme. Although this scheme introduces non-blocking, lessen IO and network contention, it suﬀers from message logging[2] overhead and many control
messages to avoid the inconsistency problem among nodes. Therefore, staggered
checkpointing scheme increases the checkpoint overhead dramatically according
to the cluster size and causes the traﬃc for stable storage to save message log
information. Simultaneous writing of multiple processes in coordinated checkpointing also causes the network contention and IO bottleneck problem as the
cluster size is increased. Parallel IO capacity of a distributed RAID is applied to

Fig. 1. Staggered checkpointing scheme

achieve fast checkpointing in a cluster system. The striped checkpointing scheme
saves the checkpoint ﬁles over distributed disks that forming a stripe group. A
stripe group is deﬁned as a subset of disks that can be accessible in parallel. Only
the disks in the same stripe group can initiate checkpointing simultaneously. To
alleviate the network contention, staggered writing method is combined with
the striped groups. Figure 2 shows this concept clearly. On the striped checkpointing scheme, each stripe group takes its checkpoints one after another. The
stripe group leads to parallelism and avoids IO contention of the storage. This
scheme can enhance both network utilization and IO performance. There exists
a tradeoﬀ between stripe parallelism and staggering depth. One can reconﬁgure
the relative stripe size and staggering depth to achieve maximum beneﬁts from
it on a particular application. Higher parallelism can lead higher aggregate disk

958

Y.S. Chang, S.Y. Cho, and B.Y. Kim

Fig. 2. Striped checkpointing scheme

bandwidth and higher staggering depth can lessen the contention problem with
the least cost of inconsistency.

4

Performance Evaluation Environment

To evaluate the performance of the striped checkpointing scheme and to compare with other schemes, we choose Linpack HPC Benchmak to carry out the
massive computational cluster experiments with MPI(Message Passing Interface). The size of checkpoint data is used to be proportional to the problem
size of the computational program. The library function program Libckpt[7]
is inserted in Linpack HPC computational program to implement a full-state,
non-incremental checkpoint with the least system load in the Linux cluster environment. The performance is directly indicated by the checkpoint overhead
and IO throughput. Our cluster platform is conﬁgured as 16 system nodes connected through the 100Mbps dedicated ethernet switch. Each node consists of
Pentium-II processor, 128MB main memory, a 4GB local disk in single partition
with Redhat Linux 6.2. Two storage schemes are used for saving checkpoints.
On NFS, checkpoints of all nodes are saved only one disk on a dedicated node.
On SIOS, 8 disks among the 16 disks are participated in the SIOS scheme. In
our experiments, three checkpointing schemes, coordinated checkpoint, staggered
checkpoint and striped checkpoint, are conducted on benchmark program. The
coordinated checkpoint scheme forces all processes to take checkpoints at the
same time. Although the cluster size would not be enough to show the drawback of the coordinated checkpointing scheme, we show the performance just
to compare it’s relative performance with staggered checkpointing scheme. The
staggered checkpoint scheme allows only one node takes checkpoint at a time.

Performance Evaluation of the Striped Checkpointing Algorithm

959

The striped checkpoint scheme takes three stripe conﬁgurations: 2, 4, and 8 disks
in a striped group. The computational problem size of Linpack HPC Benchmark
is varied from 1000 to 5000 to drive various workloads in our cluster system
like light, medium and heavy workload reaches from 2.3 to 12.1Gﬂops during
experiments.

5

Result and Discussion

Through the performance evaluation in various conﬁguration, we had lots of
impressive results. Figure 3 and 4 show the checkpointing overheads vs. problem size for all checkpointing schemes on NFS and 8 disks SIOS conﬁguration.
Checkpointing time represents total IO time including checkpoint ﬁle saving
time, message logging time, and other communication overheads. Figure 5 and
6 also show the IO throughput for all checkpointing algorithm on NFS and SIOS
conﬁguration. IO throughput represents data transfer rate from nodes to NFS
ﬁle server or distributed RAID system for checkpointing ﬁles. The results show
that coordinated checkpointing scheme has the best performance in checkpointing time and IO throughput because of the small cluster size and parallel IO
operation of the distributed RAID at ﬁrst. But coordinated checkpointing will
cause serious network contention when the cluster size in increases enough to
over the network capacity. So, it makes sense to compare striped checkpointing
scheme with staggered checkpointing scheme under our cluster platform.

Fig. 3. Checkpointing overhead on NFS

960

Y.S. Chang, S.Y. Cho, and B.Y. Kim

Fig. 4. Checkpointing overhead on SIOS

On NFS, all checkpointing schemes have not so much diﬀerence among their
checkpointing time and throughput. It shows that IO contention on the cluster
ﬁle server dominates over network contention. Therefore, checkpointing schemes
do not make much sense on the checkpointing performance on NFS. Results on
SIOS show the eﬀect of the distributed RAID system results in its parallel IO
operation. On SIOS, striped checkpointing scheme has better performance than
staggered checkpointing scheme. Moreover, larger stripe group size leads to better performance until parallel IO bandwidth of a stripe group does not exceed
total network capacity. On our cluster platform, 8-striped checkpointing scheme
shows over 4 times better checkpointing time and over 3 times IO throughput
than staggered checkpointing scheme. In the Linpack HPC Benchmark, large
problem size generates a large checkpoint ﬁle. It results in performance gap
between staggered checkpointing scheme and striped checkpointing scheme according to the problem size in checkpointing time.
The IO throughput of the striped checkpointing schemes are slightly down
at the high problem size because of the IO bottleneck at distributed RAID
system and still better performance than staggered checkpointing scheme.
These results prove that maximum size of stripe group within the network
bandwidth can produce the best performance on the distributed RAID system
with SIOS although the cluster size becomes very large enough to stall network
when coordinated checkpointing scheme is applied. This means that striped
checkpointing scheme needs some negotiation between network bandwidth
and size of stripe group. Therefore, a cluster system designed with ate size
of stripe group will pay the least overhead for checkpointing operation under

Performance Evaluation of the Striped Checkpointing Algorithm

961

Fig. 5. Throughput on NFS

Fig. 6. Throughput on SIOS

the striped checkpointing scheme. If the cluster size is increased, we can easily
guess the checkpointing overhead and the throughput would show something
diﬀerent result. We are going to deal the correlation between cluster size and
rollback recovery performance with heavier computational problem at the
further research.

962

6

Y.S. Chang, S.Y. Cho, and B.Y. Kim

Conclusion

The striped checkpointing scheme has been shown eﬀective to perform checkpointing on cluster with SIOS. Striping exploits parallelism across multiple disks.
Staggering alleviates the IO bottleneck on each disk. Therefore, striped checkpointing scheme can show better performance than other checkpointing schemes
when the cluster size becomes large enough to over the IO and network bandwidth limitation. The tradeoﬀ between striping and staggering should be applied
dynamically for diﬀerent applications. The tradeoﬀ results can be applied to yield
the striped checkpointing conﬁguration with the lowest cost for a given application. Higher stripe parallelism can lead to higher aggregate disk bandwidth
and higher staggering depth copes better with the network contention problem. Therefore, the stripe size suitable on a particular application should be
established to get the best checkpointing performance on the distributed RAID
system.

References
1. Cao, G., Singhal, M. : On Coordinated Checkpointing in Distributed Systems. IEEE
Transactions on Parallel and Distributed Systems. 9(12) (1998)
2. Elnozahy, E., Zwaenepoel, W. : On the Use and Implementation of Message Logging.
Proceedings of 24th International Symposium on Fault-Tolerant Computing. (1994)
3. Hwang, K., Jin, H., Ho, R. : RAID-x: A New Distributed Disk Array for I/O-Centric
Cluster Computing. Proceedings of 9th High-Performance Distributed Computing
Symposium. (2000)
4. Hwang, K., Jin, H., Ho, R., Ro, W. : Reliable Cluster Computing with a New
Checkpointing RAID-x Architecture. Proceedings of 9-th Workshop on Heterogeneous Computing. (2000)
5. Hwang, K., Jin, H., Chow, E., Wang, C., Xu, Z. : Designing SSI Clusters with Hierarchical Checkpointing and Single IO Space. IEEE Concurrency Magazine. (1999)
6. Plank, J., Li, K., Puening, M. : Diskless Checkpointing. IEEE Transactions on
parallel and Distributed Systems. (1998)
7. Plank, J., Beck, M., Kingsley, G., Li, K. : Libckpt: Transparent Checkpointing Under
UNIX. Proceedings of USENIX Winter 1995 Technical Conference. (1995)
8. Vaidya, N. : Staggered Consistent Checkpointing. IEEE Transactions on Parallel
and Distributed Systems. 10(7) (1999)

