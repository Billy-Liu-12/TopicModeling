Hypercubic Lattice Reduction and Analysis of
GGH and NTRU Signatures
Michael Szydlo
RSA Laboratories, Bedford, MA, USA
mszydlo@rsasecurity.com
Abstract. In this paper, we introduce a new lattice reduction technique
applicable to the narrow, but important class of Hypercubic lattices,
(L ∼
= ZN ). Hypercubic lattices arise during transcript analysis of
certain GGH, and NTRUSign signature schemes. After a few thousand
signatures, key recovery amounts to discovering a hidden unitary matrix
U , from its Gram matrix G = U U T . This case of the Gram Matrix
Factorization Problem is equivalent to ﬁnding the shortest vectors in
the hypercubic lattice, LG , deﬁned by the quadratic form G. Our main
result is a polynomial-time reduction to a conjecturally easier problem:
the Lattice Distinguishing Problem. Additionally, we propose a heuristic
solution to this distinguishing problem with a distributed computation
of many “relatively short” vectors.
Keywords: Lattice Isomorphism, Lattice Distinguishing Oracle, Distributed Lattice Reduction, Decisional Lattice Problem, Gram Matrix
Factorization, Integral Lattice Embedding Orthogonal Lattice, GGH
Cryptanalysis, NTRUSign.

1

Introduction

This paper discusses lattice reduction of Hypercubic Lattices, which are rotations
of ZN in Euclidean space. The Gram matrix of such a lattice is always of the
form G = U U T , for an integral unitary matrix U . An equivalent formulation of
this problem is: given the Gram matrix G = U U T , recover U , up to a signed
permutation of its coordinates. To approach this problem, we introduce an apriori easier problem: deciding whether two Gram matrices represent isomorphic
lattices. We model the solution to this decisional problem with a Lattice Distinguishing Oracle, (LDO). Our principal result is a new oracle-algorithm to reduce
hypercubic lattices, thus factoring G = U U T , after making a polynomial number
of calls to a Lattice Distinguishing Oracle.
Signature Schemes: The study of hypercubic lattices is motivated by cryptanalysis of two lattice based signature schemes: GGH, and (one version of)
NTRUSign. The ﬁrst, proposed by Goldreich, Goldwasser and Halevi [11] is
based on the hardness of the closest vector problem (CVP) in a relatively general lattice. The second, by Howgrave-Graham, et. al. [12], is also based on the
CVP, but it speciﬁcally chooses a class of lattices which have compactly describable bases. Both signature schemes are related to the corresponding, more well
known, encryption schemes.
E. Biham (Ed.): EUROCRYPT 2003, LNCS 2656, pp. 433–448, 2003.
c International Association for Cryptologic Research 2003

434

M. Szydlo

One measure of the security of lattice based schemes is the diﬃcultly of
reducing the underlying lattice involved. However, neither GGH nor NTRUSign
have a security reduction to the underlying problem. As observed in [10], and
reviewed below, a transcript of valid signatures of each (unmodiﬁed)1 scheme
necessarily leaks important information: the product of the private basis matrix
with its transpose. This information can be used to shift the security to an
apparently easier problem: the reduction of an auxiliary hypercubic lattice.
Combinatoric Approaches: The lattices we consider are not always presented with a basis of vectors with integer coordinates. This motivates a careful
study of lattices presented with a Gram matrix. For such lattices, there is no
Hermite Normal Form, and thus the question of whether or not two lattices are
isomorphic is not easy. Both our reduction proof and discussion of the Lattice
Distinguishing Problem involve novel, combinatoric approaches to special cases
of more well known lattice reduction problems, when the lattices are deﬁned by
Gram matrices.
1.1

Our Contributions

We begin by discussing the equivalence of the hypercubic lattice reduction problem, a case of the Gram matrix factorization problem, and a case of the integral
lattice embedding problem, and introduce the new Lattice Distinguishing Problem, which is of central importance in this paper. Secondly, we present a new
algorithm which can solve the Gram matrix factorization problem by making a
polynomial number of calls to a Lattice Distinguishing Oracle. This is the principal result of the paper. The number or oracle calls is bounded by kN 3 , where
k is the maximum bit length of the entries of the solution matrix U , and N is
the dimension of this matrix. Thirdly, we show how to design a heuristic distinguishing oracle for the cases our algorithm requires. This √
construction requires a
distribution of lattice vectors of length approximately O( N ) times the shortest
vector.
This last construction is of additional interest for several reasons. First, it
suggests√a distributed approach to the Lattice Distinguishing Problem. Second,
this O( N ) bound is of theoretical interest to complexity theory. It relates to
the complexity results
of Ajtai [1], and Micciancio[21] which suggest the SVP
√
and approximate 2 - SVP lattice problems are in general diﬃcult (NP-hard)
problems. It also √
relates to the results of Goldreich and Goldwasser [6] which
suggests that the N approximate vector problem is unlikely to be NP hard.
1.2

Organization

The rest of this paper is organized as follows. In Section 2, we recall some background on lattices and the associated computational problems. We also review
the GGH-NTRUSign cryptanalysis. In Section 3, we formalize the deﬁnition of a
1

There have been a variety of perturbation techniques proposed to reduce, or alter,
the information leaked, see [12].

Hypercubic Lattice Reduction and Analysis of GGH and NTRU Signatures

435

Lattice Distinguishing Oracle, and show how it can be used to solve some interesting problems. In Section 4, we show how this oracle provides a new strategy
for the embedding problem. In Section 5, we present the principal result: a polynomial reduction of SVP in hypercubic lattices to the decisional lattice problem.
In Section 6, we show how to heuristically design an LDO using distributions of
lattice vectors. In Section 7, we conclude with a complexity theoretic interpretation, and we make comments on the ramiﬁcations for the security of the GGH
and NTRUSign signature schemes. Finally, in the Appendix, we provide additional material on theta functions, which describe the vector length distributions
of interest to the LDO design.

2

Background and Notation

In this section we present background on lattices and review how cryptanalysis
of GGH and NTRUSign is related to the Gram matrix factorization problem.
2.1

Lattices

We begin with standard deﬁnitions and some notation used with Lattices. We
deﬁne a general lattice to be discrete subgroup of Euclidean space, RN . A basis
for a lattice is a set of vectors {vi }, i ∈ {1, . . . k ≤ N } such that each lattice
point is a unique integer linear combination of the {vi }. The integer k is the
dimension of the lattice, and usually k = N . These vectors may be described
with the rows of a basis matrix B. Any other basis matrix B is related to B by
a unitary transformation B = U B, where U ∈ SLN (Z) is called the change of
basis matrix.
A basis B also deﬁnes a positive deﬁnite symmetric quadratic form given by
its Gram matrix, G = BB T , where the matrix G = (gi,j ), speciﬁes an inner
product vi · vj = gi,j . Conversely, each positive deﬁnite symmetric matrix, G,
deﬁnes an abstract lattice, LG , as the span of a basis {vi } satisfying the inner
product speciﬁed by G. The Gram Schmidt orthogonalization process eﬃciently
computes an embedding σ : LG → RN , realizing σ(LG ) concretely in RN . Such
an embedding is determined by L up to an element φ ∈ ON (R), the orthogonal
group. Two lattices are isomorphic, (L1 ∼
= L2 ), if there is a distance preserving
map φ : L1 → L2 between them. If both lattices are contained in the same space
RN , such an isomorphism is a rotation, given by an element φ ∈ ON (R).
A lattice is called an integral lattice if it is isomorphic to LG for some integral
Gram matrix G ∈ Mn (ZN ). If a lattice L is N -dimensional and has an integral
embedding: σ : L → ZN , it is called an integer coordinate lattice. Such a lattice
determines the integral embedding up to a signed permutation, φ ∈ ON (Z). Integral lattices are convenient for computation, and some applications only consider
lattices which are subsets of ZN , the trivial lattice. We deﬁne a hypercubic lattice
to be a lattice L ∼
= ZN , i.e., as a subset of RN , it is a rotation of the trivial
lattice.

436

2.2

M. Szydlo

Lattice Problems

We now review some computational lattice problems of interest to cryptography.
Standard Reduction: The problem of Lattice Reduction is the problem of
replacing one basis with a better one [20], whose vector are shorter and more
orthogonal. A reduced basis helps to solve the shortest vector problem (SVP),
which seeks a shortest vector in the lattice, and the closest vector problem (CVP),
which seeks a lattice vector closest to a point p ∈ L ⊗ Q not in the lattice. The
fundamental tools used to solve these and other integer lattice problems are the
LLL reduction algorithm, and its variants [20].
Reducing Gram Matrices: Many implementations of lattice reduction
require an integral basis B as input and output a transformation matrix U ,
and the more reduced basis B , which is equal to U B. However, the reduction
algorithms such as LLL do not require an integral embedding as input; they
operate equally well on lattices LG , deﬁned a the Gram matrix G. These general
reduction algorithms take as input a basis speciﬁed by an integral Gram matrix
G, and produce a transformation matrix U , and the Gram matrix G of the
more reduced basis, so that G = U GU T . For example, the implementation
NTL requires an integral basis, while Pari accepts any integral Gram matrix as
input.
Integral Embeddings: There are other interesting computational problems
for lattices LG deﬁned by Gram matrices G. The Lattice embedding problem
seeks an embedding σ : LG → ZN . This is equivalent to ﬁnding an integral
basis B such that G = BB T , so this problem is also called the Gram matrix
factorization problem. A decisional problem of central interest for this paper
is the Lattice isomorphism problem: Given two lattices LG , and LG , deﬁned
by Gram matrices G, and G , determine if LG ∼
= LG . This is equivalent to
determining whether or not there exists a transformation matrix U such that
G = U GU T , so another appropriate name for this problem is the Decisional
lattice conjugacy problem. Note that the lattice isomorphism problem is much
easier when given integral bases: the lattices are isomorphic if and only if they
have the same Hermite Normal Form (HNF).
Hypercubic Lattice Case: This paper focuses on hypercubic lattices, LG ,
deﬁned by a Gram matrix G. By deﬁnition, a hypercubic lattice is isomorphic to
ZN , so it must have a Gram matrix of the form G = U U T , where U is a unitary
integer matrix. We review three formulations of this problem.
Proposition 1. Hypercubic Lattice Equivalence
Let G = U U T be the Gram matrix of an integral unitary basis matrix U , and let
LG be the associated hypercubic lattice. The following computational problems
are equivalent:
A. Given G, ﬁnd the shortest vectors in LG .
B. Given G, recover U , up to sign and order of the coordinates.
C. Given G, construct an embedding LG → ZN .
We present the simple proof in Appendix A, and note that this equivalence
applies only to these very speciﬁc lattices. In general, when considering compu-

Hypercubic Lattice Reduction and Analysis of GGH and NTRU Signatures

437

tational problems we keep in mind that the diﬃculty depends on the instance
distribution, and that special cases often turn out to be easier.
2.3

GGH and NTRUSign Transcript Application

Here we summarize the observation made in [10] that a transcript of NSS or
NTRUSign essentially recovers a Gram matrix of a certain lattice. In some sense,
the GGH and NTRU Signature schemes are adaptations of the analogous encryption schemes. However, it has been more diﬃcult to link the security of the
signature schemes to the underlying computational lattice problem.
We now review just enough details of the schemes to recall how the transcript
averaging attack works. GGH and NTRUSign are based on the diﬃculty of a
closest vector problem in a certain lattice. The main diﬀerence between GGH
and NTRUSign is that lattices in NTRUSign are chosen from a more restrictive
class (“bi-circulant”) in order to achieve more eﬃcient computation and storage.
Each scheme employs a lattice with a public basis matrix B, and a private basis
matrix M , related by B = U M , where det(U ) = 1. The signing process involves
mapping a hashed message to a vector m ZN , randomly according to some
distribution. The private basis M is used to compute a vector very close to m.
This is essentially accomplished by rounding mM −1 to an integer valued vector
w, and setting s = wM . Since the private basis M is nearly orthogonal, s is
close it m, and the veriﬁer checks that the norm |m − s| is below some threshold.
See [11] and [12] for further details of this process.
One by-product of the projection of random message representatives m is
that, to a suﬃcient approximation, the coeﬃcients of w are symmetrically distributed, and nearly independent. That is, for two diﬀerent coordinates wi , and
wj , the average dot product wi · wj is zero. On the other hand, the average
squared lengths wi · wi are all equal to some positive constant (say K). Armed
with such transcript, the analyst computes the N × N matrix sT s, for each
signature s, (considered as a row vector), and averages them.
Avg(sT s) = Avg(M T wT wM ) = M T Avg(wT w)M.

(1)

To a suﬃcient approximation, the diagonal entries of wT w converge to K, and
the others converge to 0, so the average of wT w is about K times the identity
matrix. The matrix average is KM T M , a multiple of M T M , which is the Gram
matrix of the transpose of M . Thus the adversary obtains the Gram Matrix of
the Private Transpose Basis. Combining this with the public basis B, we can
compute
G = B(M T M )−1 B T = U M M −1 M −T M T U T = U U T .

(2)

If we now let U play the role of a basis matrix, we see that the cryptanalyst has G,
the Gram Matrix of the Transformation Basis U . Because U is the transformation matrix between public and private bases, (B = U M ), key recovery amounts
to factoring G = U U T ,(up to sign and permutation of the coordinates). The
cryptanalyst can also consider the equivalent problems of ﬁnding the shortest
vectors in LG , or ﬁnding an integral embedding σ : L → ZN .

438

3

M. Szydlo

LDO and Parity Testing

We have already introduced the important lattice isomorphism problem above,
and in this section, we formally deﬁne an oracle to solve it. We will see that
this oracle can be used to solve a number of interesting problems. Our oracle
considers two lattices, LG , and LG , deﬁned by Gram matrices G, and G , and
determines if they are isomorphic.
Deﬁnition 1. A Lattice Distinguishing Oracle (LDO)
is an eﬃcient algorithm which computes the following function:
Input: G1 , G2 .
Output: T rue if LG1 ∼
= LG1 , or F alse otherwise.
Notation. We ﬁrst collect some notation to work with the Gram matrix G,
and potential integral embeddings σ : LG → ZN . Recall that LG is deﬁned
as the span of N abstract vectors, denoted {vi }, whose dot products vi · vj
are deﬁned by the entries of G. Note that σ is only determined by G up to a
signed permutation of the coordinates2 . For a particlar embedding, we denote
the images σ(vi ) by vˆi . Since we have no integral coordinates for the {vi }, we
simply record linear combinations w = Σai vi , (ai ∈ Z) with the vector a having
coeﬃcients {ai }. Let T be a matrix whose rows consist of such coeﬃcient vectors.
If the corresponding vectors are independent, T describes a lattice in terms of
the {vi }. Then the Gram matrix of this auxiliary lattice is G(T ) = T GT T .
Information from G. Keeping in mind our interest in factoring G = U U T , we
expect to be able to learn some properties of the rows of U which are invariant
under signed permutation. For example, we know vi · vi , the squared lengths of
of these vectors, from the diagonal of G. We are most interested in certain well
deﬁned “parity” measures of a vector w = Σai vi , (ai ∈ Z), which we deﬁne as
follows:
Parity Measures
ˆ congruent to 1 (mod 2).
Let λ1 (w) be the number of coordinates of w
ˆ congruent to 2 (mod 4).
Let λ2 (w) be the number of coordinates of w
ˆ congruent to 2k−1 (mod 2k ).
Let λk (w) be the number of coordinates of w
Computing λ1 from the LDO. We would like to know how many of the
coordinates of vˆ1 are odd. We remark that we immediately know this number
(mod 4) from its squared length. To learn the actual number we consider the
following auxiliary lattice: the span of the vectors {v1 , 2v2 , . . . 2vN }. We have no
coordinates for this lattice, but we know its Gram matrix Gaux = AGAT , where
A is the diagonal matrix with A1,1 = 1, and Ai,i = 2 for i ≥ 2. We also know that
under any integral embedding σ, one basis of 2LG is twice the identity matrix,
2Id. It is also easy to see that that under any embedding σ, the basis deﬁned
by Gaux has a Hermite Normal Form with a very special form: the ﬁrst row has
only entries in {0, 1}, and all other nonzero entries are 2’s on the diagonal. Up
2

So the σ’s may be also considered as coordinate permutations of the basis U .

Hypercubic Lattice Reduction and Analysis of GGH and NTRU Signatures

439

to isomorphism, there are only N possibilities for the lattice deﬁned by Gaux ,
depending on the number of 1’s. Next we simply “artiﬁcially” create a Gram
matrices for each such lattice, and denote them T esti (1 ≤ i ≤ N ). With these
auxiliary lattices, we can determine λ1 (v1 ) with the following oracle algorithm:
Computing λ1 (Gaux ) with the LDO
For i=1 to N
If LDO(Gaux , T esti ) = T rue, output i.
Loop
Otherwise, output ERROR
Thus, we can obtain λ1 (v1 ) with N oracle calls. The same approach will compute
λ1 (w) for any vector w which is a linear combination of the {vi }. We remark
that by using the knowledge of the squared length (mod 4) the algorithm may
be sped up by a factor of 4.
Secondary Tests: The computation of the other λk quantities can be similarly performed. There is one new detail which appears: In order to limit the
number of isomorphism classes to N , we compute λ2 (w) only for vectors w for
ˆ has only a single coordinate congruent to 1 (mod 4). This way, there
which w
are still only N test lattices needed. and the Gram matrices T esti are created
from the N possible Hermite normal forms of the lattices spanned by the (linearly dependent) {w, 4v1 , 4v2 , . . . 4vN }. As above, the Gram matrix Gaux is
computed by conjugating G with the appropriate transformation matrix. Such
a transformation matrix is easy to ﬁnd, but it does involves removing a linear
dependency.
In this manner, successive quantities λk (w) can also be evaluated for k >
ˆ has one odd
2. In these cases attention is limited to vectors w for which w
coordinate, and the rest congruent to 2k−1 (mod 2k ). Then, as above there will
be N candidate lattices to compare with the lattice spanned by Gaux .

4

The Embedding Strategy

In this section we describe a strategy to embed the vectors vi into ZN by using
the parity testing that the LDO provides us with. Henceforth, we allow ourselves
to compute λk (w) for certain vectors w which are linear combinations of the vi .
To give the reader an intuitive feel for the process, we begin very explicitly,
constructing consistent embeddings of v1 , v2 , and v3 . We also illustrate these
early steps with a numerical example.
We begin the construction of an embedding σ : LG → ZN with v1 , using
knowledge of λ1 (v1 ). We can write down vˆ1 (mod 2) for some σ by simply letting
vˆ1 (mod 2) be the vector whose ﬁrst λ1 (v1 ) coordinates are 1, and the rest zero.
These values must be correct for some integral embedding σ, but not for every
such embedding. By choosing the ﬁrst coordinates of vˆ1 to be equal to 1 (mod
2), we have eﬀectively partially chosen σ. We illustrate this with a toy example
where we take N = 10, and assume λ1 (v1 ) = 6. We then write

440

M. Szydlo

vˆ1 = (1, 1, 1, 1, 1, 1, 0, 0, 0, 0)

(mod 2).

Next we would like to continue, and choose vˆ2 (mod 2), based on λ1 (v2 ).
However, we want to do this consistently with our choice of vˆ1 (mod 2). In
other words, there should exist a single σ which maps v1 to vˆ1 , and also v2 to
vˆ2 . The missing information we need to do this is the number of coordinates
for which both vˆ1 and vˆ2 are odd. We can obtain this additional information
from λ1 (v1 + v2 ), which is clearly λ1 (v1 ) + λ1 (v2 ) minus twice the number of
overlapping odd coordinates.
We continue our example, supposing additionally that λ1 (v2 ) = 5, and
λ1 (v1 + v2 ) = 3. We calculate twice the number of overlapping odd coordinates
to be 5 + 6 − 3 = 8, so there are four. We can then consistently write
vˆ2 = (1, 1, 1, 1, 0, 0, 1, 0, 0, 0)

(mod 2).

Continuing with v3 , we see again that λ1 (v3 ) is not enough information to
write a consistent vˆ3 . We view the previous choices as eﬀectively dividing the N
coordinates into four “regions”, namely the four possibilities for (vˆ1 , vˆ2 ), which
are (1, 1), (1, 0), (0, 1), and (0, 0). We want the number of odd coordinates of vˆ3
in each region, so we deﬁne four variables X1 , X2 , X3 , and X4 to represent these
quantities. Since λ1 (v3 ) determines the total number of 1’s, it provides one constraint, namely X1 +X2 +X3 +X4 . The quantities λ1 (v3 + v1 ), λ1 (v3 + v2 ), and
λ1 (v3 + v2 + v1 ) provide three more constraints. These equations are linearly
independent, so the solutions may be found with Gaussian elimination.
Continuing our example, suppose λ1 (v3 ) = 6, λ1 (v3 + v1 ) = 6,
λ1 (v3 + v2 ) = 7, and λ1 (v3 + v2 + v1 ) = 7. One can check that X1 = 2, X2 = 1,
X3 = 0, and X4 = 3 are the solutions for this example. Thus we can write
vˆ3 = (1, 1, 0, 0, 1, 0, 0, 1, 1, 1)

(mod 2).

The number of region variables may expand up to a maximum N , (one for
each coordinate position) when dealing with the subsequent vectors vi , (i > 3).
Of course, the number of independent constraints collected must equal the
number of variables in order to solve the system. As before, these constraints
come from λ1 (vi ), and enough other values of λ1 (vi + v ) where v ranges over
nonempty sums of the vj , (j < i). Note that one selects appropriate vectors v
which guarantee linear independence before calling the oracle.
The above procedure and example are representative of our strategy to embed
the vectors vi . We essentially use the LDO to obtain selected λk values which
allow us to write down approximate values of {vˆi } which are consistent with an
embedding σ. The procedure explained in this section is a major component of
the full embedding algorithm, which we deﬁne in the next section. In fact we
have provided an oracle algorithm which given G, produces a set of vectors {vˆi }
(mod 2), which are the images σ(vi ), for some embedding σ.
Let us keep in mind the maximum number or oracle calls this step has required. For each of the N vectors vi , up to N values λ1 were required, and each
of these required up to N LDO calls. In total, this step has cost at most than
N 3 LDO calls.

Hypercubic Lattice Reduction and Analysis of GGH and NTRU Signatures

5

441

Hypercubic Embedding Algorithm

In this section we describe further techniques which, when combined with the
step described in the previous section, yield a complete embedding σ : LG → ZN .
This will complete our main result, that the equivalent problems of Hypercubic
lattice reduction, Gram matrix factorization problem, and Embedding problem
are polynomial time reducible to the lattice distinguishing problem. Choosing
one formulation, we prove
Theorem 1. Let U be an N -dimensional unitary matrix, and let k be the maximum bit-length of the entries, and let G = U U T . Then, given G, U may be
recovered, up to sign and order of the coordinates, by making at most than kN 3
calls to a Lattice Distinguishing Oracle.
Notation. We continue to use G, U , vi , vˆi , and λk as deﬁned above, and as
before, σ : LG → ZN , will always be an integral embedding. Additionally, for
each positive integer k, let T (k) be an integer N × N matrix, with elements
(k)
(k)
denoted {ti,j }. Let wi (k) = Σ ti,j vi , and when an embedding σ is implied, we
ˆi (k) = σ(wi (k) ). Finally, let k0 be the maximum bit length of the entries in
let w
U . With this notation in place we can outline the major steps of our algorithm.
Algorithm 2 Embedding Algorithm
Find {vˆi } ∈ ZN | ∃σ with vˆi = σ(vi ) (mod 2).
ˆi (1) = ei (mod 2).
Find T (1) deﬁning wi (1) | ∃σ with w
ˆi (2) = ei (mod 4).
Find T (2) deﬁning wi (2) | ∃σ with w
For each 3 ≤ k ≤ k0 Do,
ˆi (k) = ei (mod 2k ).
ﬁnd T (k) deﬁning wi (k) | ∃σ with w
5. For each pair of indices i, j, compute the dot products di,j =
vj · wi (k0 ) .
6. Output, {vˆi } where the j’th coordinate of vˆi is di,j , reduced to
the smallest representative (mod 2k ).

1.
2.
3.
4.

Step 1. This step has been discussed in detail in Section 4, where the values λ1
were used to ﬁnd vectors {vˆi }. We remark that this step is the most interesting,
due to the linear algebra not required in subsequent steps. We also note that
among the ﬁnite number of possible embeddings, σ, the choices made in this
step have ﬁxed the order of the coordinates. Only the sign ambiguity remains.
Step 2. Consider the matrix V deﬁned by the rows of {vˆi }. As V ’s is congruent
to σ(vi ) (mod 2), and the latter has determinant one, V is invertible when
considered over the ﬁeld of two elements. We let T (1) be the integer matrix
with entries 0 and 1, which represents this inverse. Now T (1) deﬁnes the vectors
(1)
wi (1) = Σ ti,j vi . Thus the images of the wi (1) under σ are the rows of the matrix
ˆi (1) = ei (mod 2).
T (1) V , which is the identity, (mod 2). So we conclude that w
(1)
These vectors wi will be used in subsequent steps.

442

M. Szydlo

Step 3. In this step we will improve the vectors wi (1) , producing vectors wi (2) ,
ˆi (2) = ei (mod 4). For a ﬁxed σ satisfying the conditions of Step 1, and
so that w
our choice of {wi (1) }, the i’th coordinate of σ(wi (1) ) is odd, thus ±1 (mod 4).
However, as of step 1, σ had been only been determined up to sign. Among the
2N choices, there is always one for which the i’th coordinate of σ(wi (2) ) is 1. We
retain this choice of σ throughout the remainder of this algorithm. Therefore,
our choices have also ﬁxed vˆi = σ(vi ).
For each index i, we initially set wi (2) = wi (1) and proceed to modify it.
Recalling Section 3, we learned that the LDO may be used to compute λ2 (wi (2) ),
ˆi (2) meets the stated criteria: One coordinate is equal to 1 (mod 4), and
since w
the rest are equal to 2 or 0 (mod 4). The value λ2 (wi (2) ) lets us measure the
ˆi (2) . Now, for each index j = i, we tentatively add 2wj (1)
number of two’s in w
ˆ j (1) = 2 (mod 4) only in one spot, at the j’th coordinate, so
to it. Notice that 2w
the operation of adding 2wj (1) always modiﬁes λ2 (wi (2) ) by 1. If it decreases we
keep it, otherwise not, and so after all j = i are considered, λ2 (wi (2) ) is reduced
to zero. These vector additions are recorded in terms of integral combinations
of the vi , so eventually we obtain the matrix T (2) deﬁning the ﬁnal wi (2) . Now
ˆi (2) = ei (mod 4), and we proceed to the next step. Notice that Step 3
that w
also completes with at most than N 3 LDO calls.
Step 4. This step consists of a procedure which is repeated for each k ≥ 3 up
to the bound k0 . As with Step 3, the goal is to further improve each of the wi .
Unlike Step 3, however, σ has already been ﬁxed, so when we begin by setting
wi (k) = wi (k−1) , the the i’th coordinate of σ(wi (k) ) can not be automatically
assumed to be congruent to 1 (mod 2k ). Instead, it might be 1 + 2k−1 (mod 2k ),
and this can be easily tested, since then the squared length of wi (k) will not be
1 (mod 2k+1 ). If this happens, the ﬁrst step is to multiply wi (k) by the scalar
2k−1 + 1.
Once in this form, we can evaluate λ3 (wi ). We take the same strategy as
(1)
to it, until λ3 (wi (k) ) is reduced to
above, and add certain vectors 2k−1 wj
(k)
zero, at which point we have our T
deﬁning the ﬁnal wi (k) .
Step 5. In this step we compute the dot products di,j = vj · wi (k0 ) . To do this,
we write each wi (k0 ) as a linear combination of the {vj } according to the rows
of T (k) , and use the fact that we know each vi · vj from the Gram matrix G.
More simply put, we perform a matrix multiplication T (k) G.
Step 6. We now use the fact that σ is an embedding, to reason that vj · wi (k0 ) ,
ˆi (k0 ) , which equals the i’th coordinate of vˆj
which we know, also equals vˆj · w
)
(k
ˆi 0 = ei (mod 2k0 ). But by the assumption on the signed bit
(mod 2k0 ), since w
length of U , we actually know vˆj over Z. We have completed the computation
of σ : LG → ZN , and the algorithm terminates after outputting the exact values
vˆj .
This completes the algorithm and the proof of Theorem 1. All told, at most
kN 3 calls to the lattice distinguishing oracle have been made. The hypercubic

Hypercubic Lattice Reduction and Analysis of GGH and NTRU Signatures

443

lattice reduction problem is polynomial time reducible to the lattice distinguishing problem.

6

Heuristic LDO Implementation

While the focus of this paper is the reduction proof, Theorem 1, it is natural
to ask if such a lattice distinguishing oracle is feasible to implement. In this
section, we discuss a heuristic approach to solving this decision problem for the
speciﬁc lattices required in our reduction. We remark immediately, that even if
the LDO is practical, the potentially very large number, (kN 3 ), of oracle calls
might still leave the hypercubic lattice reduction a diﬃcult problem. This should
not be too disappointing, given the exponential nature of the general algorithms
to compute exact shortest lattice vectors. On the other hand, if only Steps 1 and
2 of the algorithm 2 are completed, the diﬃculty of the original shortest vector
problem can be made signiﬁcantly easier.
So how hard is it to implement an LDO? Our heuristic algorithm to realize
this oracle will not treat the general problem, but instead will focus on the
cases required for our algorithm. In fact, our oracle will only need to distinguish
between N lattices at a time. Recalling the discussion in section 3, we used the
LDO to compare an unknown lattice deﬁned by the Gram matrix Gaux , with
N potential lattices, T esti , (1 ≤ i ≤ N ). This auxiliary lattice deﬁned by Gaux
depends on some input vector deﬁned in terms of the {vi }. On the other hand,
the N matrices {T esti } were speciﬁcally constructed from a known integer basis.
By construction the lattice of Gaux , must be the lattice of one T esti . Because
we know the structure of the candidates, T esti , we directly see in what ways
they diﬀer.
6.1

Modular Tests

Our approach relies on the fact that the N candidate lattices enjoy a diﬀerent
distribution of vectors. For the simplest possible example, it is clear that among
the N possibilities, only T est1 has a vector of length 1. However, it is not easy to
check whether the lattice of Gaux has such a vector. Finding it, at least, requires
the solution of the SVP itself! Fortunately, other distinguishing features of these
distributions can be perceived with larger vectors. The most prominent example
of this considers the lengths of the vector (mod 4). For example, let z be any
vector in the lattice of Gaux which is not in 2LG . If the length of z squared is 1
(mod 4), then the lattice must be isomorphic with that of T esti for some i = 1
(mod 4). The same type of conclusion may be reached if the length squared is
0, 2 or 3 (mod 4). This discussion shows how the isomorphism question may be
easy in certain cases, but in general, these tricks will not be suﬃcient.
6.2

Statistical Tests

We now explain how to exploit the diﬀerence of the distributions in general.
By ﬁxing some bound B, we consider only vectors of length squared less than

444

M. Szydlo

this bound. For now, let us assume that it is possible to collect a large sample
of vectors from the lattice deﬁned by Gaux drawn nearly uniformly among all
vectors in this lattice of squared length less than B. For each of the N possible test lattices, we also compute a similar distribution. We then compare the
frequency distribution of the lengths from our sample drawn from the lattice
deﬁned by Gaux to the distributions corresponding to one of the T esti lattices.
If the frequency distribution between two lattices matches closely enough, the
lattices will be declared isomorphic.

6.3

Collecting Vectors

The remaining question is how the sample distribution is collected. We want
to use LLL or another lattice reduction algorithm to obtain a medium length
vector. In practice, this is feasible for certain vector length bounds. We set our
bound B, and reduce the lattice until a vector shorter than B is found.
This sample distribution of such vector lengths must be created as uniformly
as possible. To encourage this, the basis is randomized before each lattice reduction begins. It is possible that other measures may also be needed. We conjecture
that this procedure will produce a sample of suﬃcient accuracy to decide if two
lattices are isomorphic.

6.4

Calculating Exact Distributions

In Appendix B we show how we can compute the exact distribution of vector
lengths for the test lattices T esti . This slightly simpliﬁes the oracle construction,
and additionally gives us some information about when a (uniformly distributed)
sample size consisting of certain size vectors is likely to be suﬃcient for the
oracle’s decision.

6.5

Experiments

We performed experiments using the techniques in Appendix B to compute theta
functions, which quantify the extent to which the distributions diﬀer.
We tested lattices of dimension 100 and 500 for lattices deﬁned by T esti for
varying i values. We found that when B was reduced below about 3/10N times
the squared length of the shortest vector, the diﬀerences in these distributions
became perceptively diﬀerent, so that a sample size of several thousand vectors
would suﬃce to distinguish lattices of the form T esti from one another.
Our experiments suggested
that a practical bound for the length of the sam√
ple vectors is some O( N ) multiple of the length of the shortest vector. This
bound is merely conjectural, but is intriguing due to the relationship with the
complexity results described in the introduction.

Hypercubic Lattice Reduction and Analysis of GGH and NTRU Signatures

7

445

Conclusions

Our reduction of the hypercubic SVP to certain Lattice Distinguishing Problems
is an interesting connection between a computational and a decisional problem.
A large sequence of correct solutions to the decisional problem combines to solve
the computational problem.
7.1

Security Ramiﬁcations

This work on reduction of hypercubic lattices shows that the transcript attacks
reviewed above are indeed relevant to the security of the schemes. The combination of transcript averaging, and this algorithm, and the potential of a feasible Distinguishing Oracle, suggest a weakness in signature schemes which leak
this speciﬁc kind of information. Currently, the practical security threat to the
schemes is not clear - given the large number of Oracle calls and (albeit easier)
lattice problems behind the LDO. Given the new approaches to the Gram matrix
problem, it seems prudent to always use the perturbation methods with these
schemes. This additional perturbation step may unfortunately reduce eﬃciency.
7.2

Complexity Ramiﬁcations

We hope that the special techniques for SVP hypercubic lattices may have analogues for general
lattices. LDO may be realized given a collection of vectors of
√
size about N times the shortest vector - the same threshold that the work of
Goldwasser suggests may be feasible. Combining these ideas, there is reasonable
evidence to believe that SVP in hypercubic lattices is strictly easier than SVP
in general lattices. Finally, the Lattice Distinguishing Problem may also be of
independent interest and have other applications.
7.3

Further Work

The most relevant open question is still the feasibility of the LDO. For example,
we would like to know if the sampling techniques yield suﬃciently accurate
distributions to realize an LDO.
We suggest a strategy to deal with an LDO which is allowed some chance
of failure. Such a failure may be caught with high probability by repeatedly
applying tests of consistency. One such check is λ(v1 + v2 ) ≤ λ(v1 ) + λ(v2 ).
Proving that such a technique always works would be useful as it would increase
the robustness of algorithms using an LDO.
The collection of sample vectors in our method of implementing an LDO
may be completely distributed. Of course, an important problem would be the
introduction of distributed algorithms for general lattices.
As a general research program, it should also be fruitful to study the diﬃculty of problems involving lattices with special structure. The hypercubic lattice
problem is also a natural special case to consider, given its several equivalent
formulations.

446

M. Szydlo

Acknowledgments. I would like to thank Craig Gentry, Phong Nguyen, and
Jacques Stern for helpful and interesting discussions. I would also like to thank
the anonymous reviewers for useful advice on how to clarify the presentation of
these results.

References
1. M. Ajtai, The shortest vector problem in L2 is NP-hard for randomized reductions,
in Proc. 30th ACM Symposium on Theory of Computing, 1998, 10–19.
2. H. Cohen, A Course in Computational Algebraic Number Theory, Graduate Texts
in Mathematics, 138. Springer, 1993.
3. D. Coppersmith and A. Shamir, Lattice Attacks on NTRU, in Proc. of Eurocrypt
’97, LNCS 1233, pages 52–61. Springer-Verlag, 1997.
4. I. Dinur, G. Kindler, S. Safra, Approximating CVP to within almost-polynomial
factors is NP-hard, in Proc. 39th Symposium on Foundations of Computer Science,
pages 99–109, 1998.
5. N. Elkies, Lattices, Linear Codes, and Invariants, in Notices of the American Math.
Society, 47 pages 1238–1245, Cambridge University Press, 2000.
6. O. Goldreich and S. Goldwasser, On the Limits of Non-Approximability of Lattice,
In Proc. of the 13th ACM Symposium on the Theory of Computing, 1998.
7. O. Goldreich, D. Micciancio, S. Safra, J.P. Seifert, Using Lattice Problem in Cryptography,1999.
8. C. Gentry, J. Jonsson, J. Stern, M. Szydlo, Cryptanalysis of the NTRU signature
scheme, in Proc. of Asiacrypt ’01, LNCS 2248, pages 1–20. Springer-Verlag, 2001.
9. O. Goldreich, D. Micciancio, S. Safra, J.P. Seifert, Approximating shortest lattice
vectors is not harder than approximating closest lattice vectors, Electronic Colloquium on Computational Complexity, 1999.
10. C. Gentry, M. Szydlo, Cryptanalysis of the Revised NTRU signature scheme, in
Proc. of Eurocrypt ’02, LNCS 2332, pages 299–320. Springer-Verlag, 2002.
11. O. Goldreich, S. Goldwasser, S. Halevi, Public-key Cryptography from Lattice Reduction Problems, in Proc. of Crypto ’97, LNCS 1294, pages 112–131. SpringerVerlag, 1997.
12. J. Hoﬀstein, N. Howgrave-Graham, J. Pipher, J.H. Silverman, W. Whyte,
NTRUSign: Digital Signatures Using the NTRU Lattice, December, 2001. Available
from http://www.ntru.com.
13. J. Hoﬀstein, B.S. Kaliski, D. Lieman, M.J.B. Robshaw, Y.L. Yin, Secure user identiﬁcation based on constrained polynomials, US Patent 6,076,163, June 13, 2000.
14. J. Hoﬀstein, D. Lieman, J.H. Silverman, Polynomial Rings and Eﬃcient Public
Key Authentication, in Proc. International Workshop on Cryptographic Techniques
and E-Commerce (CrypTEC ’99), Hong Kong, (M. Blum and C.H. Lee, eds.), City
University of Hong Kong Press.
15. J. Hoﬀstein, J. Pipher, J.H. Silverman. Enhanced encoding and veriﬁcation methods
for the NTRU signature scheme (ver. 2), May 30, 2001. Available from
http://www.ntru.com.
16. J. Hoﬀstein, J. Pipher, J.H. Silverman, NSS: The NTRU Signature Scheme,
preprint, November 2000. Available from http://www.ntru.com.
17. J. Hoﬀstein, J. Pipher, J.H. Silverman, NSS: The NTRU Signature Scheme, in
Proc. of Eurocrypt ’01, LNCS 2045, pages 211–228. Springer-Verlag, 2001.

Hypercubic Lattice Reduction and Analysis of GGH and NTRU Signatures

447

18. J. Hoﬀstein, J. Pipher, J.H. Silverman, NSS: The NTRU Signature Scheme: Theory
and Practice, preprint, 2001. Available from http://www.ntru.com.
19. J. Hoﬀstein, J. Pipher and J.H. Silverman, NTRU: A New High Speed Public Key
Cryptosystem, in Proc. of Algorithm Number Theory (ANTS III), LNCS 1423,
pages 267–288. Springer-Verlag, 1998.
20. A.K. Lenstra, H.W. Lenstra Jr., L. Lov´
asz, Factoring Polynomials with Rational
Coeﬃcients, Mathematische Ann. 261 (1982), 513–534.
21. D. Micciancio, The Shortest Vector in a Lattice is Hard to Approximate to within
Some Constant, in Proc. 39th Symposium on Foundations of Computer Science,
1998, 92–98.
22. P. Nguyen, Cryptanalysis of the Goldreich-Goldwasser-Halevi Cryptosystem from
Crypto ’97, 1999
23. P. Nguyen and J. Stern, Lattice Reduction in Cryptology: An Update, in Proc.
of Algorithm Number Theory (ANTS IV), LNCS 1838, pages 85–112. SpringerVerlag, 2000.
24. C.-P. Schnorr, A Hierarchy of Polynomial Time Lattice Basis Reduction Algorithms, Theoretical Computer Science 53 (1987), 201–224.
25. J.H. Silverman, Estimated Breaking Times for NTRU Lattices, NTRU Technical
Note #012, March 1999. Available from http://www.ntru.com.
26. L. Washington, Introduction to Cyclotomic Fields, Graduate Texts in Mathematics
83, 1982.
27. Consortium for Eﬃcient Embedded Security. Eﬃcient Embedded Security Standard (EESS) # 1: Draft 3.0. Available from http://www.ceesstandards.org.

A

Proof of Proposition 1

As in Proposition 1, let G = U U T be the Gram matrix of an integral unitary
basis matrix U , and let LG be the associated hypercubic lattice. By deﬁnition,
every hypercubic lattice is isomorphic to ZN , so has a Gram matrix of this form.
The three problems to be shown equivalent are:
(A) Given G, ﬁnd the shortest vectors in LG .
(B) Given G, recover U , up to sign and order of the coordinates.
(C) Given G, construct an embedding LG → ZN .
Proof: (A)⇒(B): To know the shortest vectors in terms of the basis represented
by G is to have of a unitary V such that V GV T is the identity. Then G =
V −1 V −T , so V −1 a is solution to G = U U T . As V U is orthogonal, V −1 recovers
U up to sign and order of the coordinates. (B)⇒(C): Given any U such that
G = U U T , the rows of U embed LG into ZN . (C)⇒(A): Since det(G) = 1, the
embedding, LG → ZN is surjective. By Gaussian elimination, we can ﬁnd ei in
terms of the basis deﬁned by G, thus the shortest vectors of LG .

B

Theta Series

The theta series, of a lattice is a lattice invariant, of interest as a tool to distinguish non-isomorphic lattices3 . Given a lattice L, and an integer m, deﬁne
3

Non-isomorphic lattices may have identical theta functions.

448

M. Szydlo

Nm to be the number of lattice points of length squared m. Traditionally, these
lattice invariants are collected into an element of the power series ring Z[[q]] as
follows
∞
Θ(L, q) = 1 + Σi=0
Nm q m .

(3)

A convenient eﬀect of this packaging is the relationship among theta series for
lattices with an orthogonal decomposition (direct sum). Suppose L3 = L1 ⊕ L2 .
Then suppressing q,
Θ(L3 ) = Θ(L1 ) ∗ Θ(L2 ).

(4)

As examples, θ(Z) = 1 + 2q + 2q 4 + 2q 9 . . . , and by Eq.4,
θ(ZN ) = (1 + 2q + 2q 4 + 2q 9 . . . )N .
We are interested in the theta series as a means of understanding how diﬃcult
it is to realize a lattice distinguishing oracle. For the purposes of this paper, we
can focus on the “Test” Gram matrices introduced in Section 3, since these are
the only one used with the lattice distinguishing oracle.
These lattices are particularly simple, so we can easily compute the theta
series by hand. Consider the lattices T esti used to compute λ1 (v). There are N
such lattices, one for each i ∈ {1, 2, . . . , N }. As subsets of ZN , these lattices are
spanned by the rows of twice the identity matrix, and one other vector, with
exactly i odd coordinates. We calculate this theta series by adding together two
power series. The ﬁrst, representing vectors with all even coordinates is:
θ(2ZN ) = (1 + 2q 2∗2 + 2q 4∗4 + 2q 6∗6 . . . )N .

(5)

The second series, θ2 ,represents vectors with i odd coordinates:
θ2 = (2q 1 + 2q 3∗3 + 2q 5∗5 . . . )i · (1 + 2q 2∗2 + 2q 4∗4 + 2q 6∗6 . . . )N −i .

(6)

The second summand of the theta series of this lattices clearly depends on i.
For example, if i = ±1 (mod 4), then the shortest vector of odd squared length
vector has squared length i. We can multiply two power series products above
to any degree of precision and thus obtain Nm , the number of vectors of length
squared m.
Similar calculations for the lattices involved in the computation of λ1 (v),
k ≥ 2 are similarly easy. These calculations provide interesting statistics which
measure ways in which the lattices compared by the LDO diﬀer.

