A Knowledge Discovery Methodology
for Behavior Analysis of Large-Scale
Applications on Parallel Architectures
Elias N. Houstis1,2 , Vassilios S. Verykios1,3 , Ann C. Catlin2 , and John R. Rice2
1

Dept. of Computer and Commun. Engr., Univ. of Thessaly, Volos, GREECE
Dept. of Computer Sciences, Purdue University, West Lafayette, IN, USA
3
Research and Academic Computer Technology Institute, Patras, GREECE
2

Abstract. The focus of this paper is the application and extension of
the knowledge discovery in databases process [5] developed in PYTHIA
recommender system, to analyze the behavior of a DOE ASCI application/hardware pairs in the context of POEMS project[4]. The POEMS
project has built a library of models for modeling scalable architectures
like those in the ASCI program. Moreover, it supports detail simulation
of a variety of state-of-the-art processors and memory hierarchies and
incorporates parallel evaluation of discrete-event simulation. The driver
application used is SWEEP3D.

Keywords: Recommender System, Data Mining, Knowledge Discovery,
Scientific Computing

1

Introduction

One of the basic research issues in designing recommendation services is understanding the fundamental processes by which knowledge about scientific problems and their solutions is created. Some of this knowledge will come directly
from experts - scientists and engineers - in the field. Other knowledge can be
mined from experimental data arising from simulations. Yet, further knowledge
will be learned from the experience gained by the recommendation service itself
as it extracts performance knowledge about software components when these are
running and applied to various problems.
The focus of this paper is the adoption of the knowledge discovery in databases
process [5]of the PYTHIA recommender system, to the knowledge acquisition
process for an ASCI application, in the context of the POEMS project [4].
PYTHIA [7, 10, 8], a “scientific recommender system” whose users are scientists/engineers, is trying to locate software module(s) appropriate to their needs.
Given a scientific problem instance and performance criteria constraints on its solution, PYTHIA recommends an algorithm, estimates its parameters, and identifies a location on the web where a software module implementing the algorithm
This work was supported in parts by NSF grants, EIA-0103688, DMI-0122214, and
EIA-0205663.
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 739−748, 2003.
 Springer-Verlag Berlin Heidelberg 2003

740

E.N. Houstis et al.

can be obtained. The current implementations of PYTHIA address the domains
of numerical quadrature, elliptic partial differential equations (PDEs), domain
decomposition and linear algebra. PYTHIA’s basis for recommendations is a
rule-bank mined by spooling performance trace data for various algorithms on
benchmark scientific problems and correlating variations in performance to specific characteristics of the problem input. In addition, PYTHIA interfaces with
the GAMS software repository on the web, where implementations of the implemented algorithm can be downloaded. In this paper, we specifically concentrate
on the data mining methodology utilized for the design of PYTHIA.
The POEMS project is building an initial library of models, at multiple levels
of granularity, for modeling scalable architectures like those envisaged under the
DOE ASCI program. The project supports evaluation of component behaviors
through application of discrete-event simulation at multiple levels of detail. POEMS supports detailed simulation of a variety of state-of-the-art processors and
memory hierarchies and incorporates parallel evaluation of discrete-event simulation. The project is also building a knowledge base from mining performance data
that can be used to predict the performance properties of hardware/software as a
function of their characteristics. POEMS development is being driven by modeling of the behavior of large-scale complex applications on parallel architectures.
The first driver application is the SWEEP3D program that is being used to
evaluate advanced parallel architectures at Los Alamos National Laboratories.
This paper gives a short introduction of the issues addressed in POEMS
project and presents the design and implementation of the POEMS knowledge
base (POEMSKB) in the context of SWEEP3D application and two computational environments associated with SP2 parallel machine and a cluster of Sun20
workstations. This paper is organized as follows. In Section 2 we describe the
performance methodology we followed in POEMS and the case study used. In
Section 3 we summarize the components of the POEMSKDD approach in terms
of the components of the PYTHIA system and in Section 4 we present the results
of the KDD process for POEMS. Conclusions are listed in Section 5.

2

POEMS Performance Methodology and Sweep3D Case
Study

The major elements of the conceptual framework of POEMS are a general model
of parallel computation and the use of associative objects as the representation
basis for components. The models developed in POEMS span three different
domains: application, operating system, and hardware. The application domain
represents parallel computation as a dynamic task graph where nodes represent
sequential computation units and edges represent dependencies. The operating
system domain provides the models for process and memory management, interprocess communication, and parallel file systems. The hardware domain provides
models for the processor and memory components, where the latter includes
models from cache memory as well as shared memory hierarchies.

A Knowledge Discovery Methodology for Behavior Analysis

741

As a proof of concept, the following performance analysis tools currently are
being integrated in POEMS: an automatic task graph generator [1], the LogGP
[9] and LoPC [6] analytic models, the MPI-SIM simulator [2], and the SimpleScalar instruction level processor/memory architecture [3]. Each tool contains
capabilities for modeling the application domain, software domain, runtime system domain, and hardware domain. Together these tools provide the capability
to analyze the performance of current and future applications and architectures,
for very large and complex configurations and with a fairly high degree of confidence.
2.1

POEMS Driver Application: SWEEP3D

We consider the problem of predicting the performance of an ASCI kernel application called SWEEP3D on large scale parallel architectures such as IBM SP/2
or the SGI Origin2000. The benchmark code SWEEP3D represents the heart of
a real ASCI application. It solves a 1-group time-independent discrete ordinates
(Sn) 3D Cartesian (XYZ) geometry neutron transport problem. The XYZ geometry is represented by an IJK logically rectangular grid of cells. The angular
dependence is handled by discrete angles with a spherical harmonics treatment
for the scattering source. The solution involves two steps: the streaming operator is solved by sweeps for each angle and the scattering operator is solved
iteratively.
This version of SWEEP3D is based on blocks of IJK and angles with a
stride-1 line-recursion in the I-direction as the innermost work unit. The stride1 I-line recursion is good for microprocessors and the blocked domains provide
parallelism opportunities.
2.2

POEMS Performance Database

The POEMS performance database is to provide for the storage, retrieval and
analysis of performance data, actual or estimated, for an application like SWEEP3D.
The data includes: (a) actual measurements of performance, (b) data derived
from actual measurements, e.g., a speedup curve that fits actual data, (c) simulation data derived from the “execution” of a low level simulator of the hardware
and software environment, (d) specification data (for unavailable components
of hardware or software), and (e) data derived from an analytical model, e.g.,
LogGP.
Currently the performance database has been modeled based on the underlying schema of the PYTHIA design. Following we present an instance of the
PERFDATA table because of its major importance in the POEMS context. The
PERFDATA record is shown in Figure 1. Some comments are in order. The
record includes an id (name) and the system that is used for generating the
performance data (PELLPACK). The database that this record correspond to
is also listed (sweep3d), along with the name of the COMPOSITE record that
includes the experiment that generated the data. The perfind set attribute
states the name of the file to be used that contain information related with the

742

E.N. Houstis et al.

name
system
comp_db
composite_id
perfind_set
solverseq
rundata
featurenames
featurevals
nproc
CSwitch
SysCalls
PgFlts
PktsRd
PktsSt
mean_UserStat
mean_KernelStat
mean_WaitStat
mean_IdleStat
std_UserStat
std_KernelStat
std_WaitStat
std_IdleStat
SENDing
RECVing
BCASTing
BARRIER
ALLREDUCINGing
perfproc2names
perfproc2vals
modnames
timeslice
time
total

|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|

sweep3d 50x50x50 experiment SP2-6
pellpack
sweep3d
sweep3d 50x50x50 experiment
sweep3d-std-par-grd
50x50x50 1x2 sweep3d mk=1, mmi=1
IBM SP2 with 18 compute nodes
{"matrix symmetric","problem type"}
{"no","FEM"}
2
{8715, 8638}
{72886, 72790}
{2224, 2215}
{294, 247}
{186, 173}
{98.82, 98.98}
{0.69, 0.53}
{0.11, 0.06}
{0.38, 0.43}
{6.92, 6.87}
{2.61, 2.59}
{2.54, 1.45}
{5.21, 5.76}
{1.1922, 0.748}
{86.891, 5.4036}
{0.0008, 0.1129}
{0.0005, 0.0722}
{0.0005, 0.0722}
{"BytesTo","SendsTo","BytesFrom","RecvsFrom"}
{{{"5760000","14400","5760000","5760000"}},
{{"5760000","14400","5760000","5760000"}}}
{"domain processor","decomposer","triple"}
{"elapsed","communication"}
{{{"0","0"},{"0","0"},{"302.1300049","2.7499979"}},
{{"0","0"},{"0","0"},{"301.7099915","2.7699978"}}}
{"302.1300049","301.7099915"}

Fig. 1. PERFDATA record for a 2-processor configuration in SP2.

data collection process. The particular sequence from the COMPOSITE record
that generated the data is also referenced along with the RUNDATA record.
In some cases, there are features that are dependent neither upon the application nor upon the underlying machine. These features are mostly related with
the specific run, and for this reason have been included in the PERFDATA
record such as the ones included as values for the attributes featurenames and
featurevals. As we said, this record correspond to a parallel run of the SP2

A Knowledge Discovery Methodology for Behavior Analysis

743

system. For this reason, the number of processors of the parallel machine that
the data was collected from is also explicitly stated in the record. In addition to
the above information, there are four groups of metrics whose values are kept
in the PERFDATA record. The first group corresponds to information related
to the processes running in each processor and other system and user specific
information. The second group of measurements include information related to
the number of bytes communicated between every pair of processors. Actually,
the corresponding field is a three dimensional array that states the ids of the
processors communicated along with the number of bytes exchanged in one run
of the application. The third group of measurements include timing information
related to the various modules of the PELLPACK system. The last group include information related to the total timing of the application in per processor
basis. Although PELLPACK allows us to extract timing information for each
module, it does not provide us with the capability to take measurements related
to the performance behavior of the underlying system. For this reason, we have
incorporated into PYTHIA, various profilers that provide us with trace data
from different platforms.

3

Components of POEMSKDD

The implementation of the POEMSKDD follows closely the design of PYTHIA
system. The system consists of all the layers included in the architectural diagram
of PYTHIA system with the only difference that the statistical analysis module
performs a slightly different operation than simply ranking of system modules.
For the POEMSKDD we have made use of a well known clustering tool that
partitions the space of the performance data independently of its dimension. For
the interpretation of the actual meaning of the identified clusters, we use the
decision tree inducer from the pattern extraction module of PYTHIA. After the
classes have been described, the decision tree inducer runs once again in order
to build a classification model to be used for prediction purposes. At this time,
the inducer takes as an input the parameters of the machine/application pair
along with the label assigned to each pair by the clustering tool for building
a model that predicts the performance class of a certain combination of application/machine parameters. Following, we give a detailed description of the
clustering phase for the SWEEP3D raw performance data.
3.1

Clustering of SWEEP3D Performance Data

The information we have collected for the SWEEP3D application, includes application and machine feature data as well as performance data from running
the application in an SP/2 parallel machine. In particular we make use of the
grid size for the three dimensions, x, y and z, the parameter mk (K-planes for
blocking), and mmi (the angles for blocking), the number of processors used for
executing the application, as well as measurements for the elapsed and communication time. Thus, we have generated a feature vector for our study of size 8. We

744

E.N. Houstis et al.

have only used this small number of variables for demonstration purposes and
also because this set adequately reflects the variation in the underlying domain
for observing the interesting relationships.
The first step in discovering knowledge from the collected data is to consider
what kind of task must be applied in this case study. The main problem is
that in such an environment where we are looking for patterns without having
any a-priori knowledge of the trends that exist in them, we need to start the
data analysis by identifying subsets of data with similar characteristics or else
clusters. This is what is usually called as clustering. Clustering, is a common
descriptive task where one seeks to identify a finite set of categories or clusters
to describe the data. For partitioning the performance data space into clusters
in this study we have made use of the AutoClass system, a well-known clustering
tool developed by NASA Ames Research Center.
The classes we are after in this knowledge extraction engagement are related
to the performance of the underlying parallel machine for the various application
parameters. For this reason, the cluster generation process is given as input
only the performance information that is kept in the feature vector mentioned
before. This information include the elapsed and communication time spent for
executing the application in the parallel machine. The model we have selected
for both variables is a Multi Normal model which implements a likelihood term
representing a set of real valued attributes, each with constant measurement
error and without missing values, which are conditionally independent of other
attributes given the class. This is an assumption that we make and is related to
the specific nature of the performance data we use. A pictorial representation of
classes in the 2D space of performance data is given in Figure 2. The clustering
tool identified 6 classes. The visualization tool has re-mapped the identified
classes like follows: 4 to 1, 0 to 2, 1 to 3, 2 to 4, 3 to 5, and 5 to 6.
The performance data along with the corresponding classes identified by AutoClass are provided to a classification tool for the description of the performance
classes. We have once again used the ID3 software and the decision tree produced
is presented in Figure 3.
3.2

Feature-Based Cluster Description

After the identification and description of performance classes, we need to associate them with application/machine features, in order to be able to decide
or predict the performance class of a certain pair of application and machine
configuration based on their static characteristics without having to run the application. This is not only very efficient, but sometimes it is the only feasible way.
For example, in this manner we can investigate how the number of processors
relates to the performance of the system, and based upon the results, we might
decide to change the configuration of the system.
For this step, we use four features. The first feature is the problem size, which
is the product of the 3 grid sizes in the 3 dimensions, the second is the number
of processors (nproc) used for running the application, and the last two the mk
and mmi parameters that are related closely to the application. We consider two

A Knowledge Discovery Methodology for Behavior Analysis
display2.data
6

6

6
66

745

6

6

5

3
3
3
3

3

33

4

3

3
3

3

4

44

3

3

3

3

4
4
4 44
4
4

4

3
33

3
3

3

3

2
4
4 4
4 4
4

44 4
44
4
4 4

33
3 3
3
3
2
222
4
4
4 4
4
4
4
4 4
4

2

33
3

3

3

3
3

3
3 3

3

3

3

3

2

2
2
2
2
2
2
2
2 2
22
2
2
2
4
4
44
44 4
4
4
4

2
2
2
2
2
4

3

3

3

3
3
3

3
3

3
3 3

3

2

2
2
2 22
2 22
2
222
22
2
2

33

3

3

3

3 3
3

3

1
1
2
2

2
2
2

1 1
2 1
1
1 2
22
2
1
1
1
2
1

5
5
55
55 5
55
555
5
5
5
5

1

2

5
5

2
2
2
2

5

5
55
5

2
2

4

1

1

Fig. 2. Pictorial representation of the distribution of classes in the 2D space. The values
of the elapsed time are depicted in the x axis and the values of the communication
time are depicted in y axis.

communication time
62, 65, 48, 24, 18, 7
- 2.589
elapsed time
0, 0, 1, 0, 6, 0
- 141.145
2
0, 0, 32, 0, 0, 0

elapsed time
8, 0, 47, 2, 4, 0

141.145-262.015

2
0, 0, 15, 0, 0, 0

2.589-6.67

262.015-496.205

0
6, 0, 0, 0, 0, 0

6.67-20.735

20.735-645.5575

elapsed time
54, 13, 0, 10, 5, 0

1
1, 12, 0, 0, 0, 0

- 141.145

141.145-262.015

0
19, 1, 0, 0, 0, 0

262.015-496.205

0
25, 0, 0, 0, 0, 0

645.5575+
elapsed time
0, 52, 0, 12, 3, 0

496.205-961.515
0
9, 0, 0, 0, 5, 0

961.515-1336.25
3
0, 0, 0, 10, 0, 0

- 141.145
1
0, 7, 0, 0, 0, 0

5
0, 0, 0, 0, 0, 7

141.145-262.015

1
0, 18, 0, 0, 0, 0

262.015-496.205

1
0, 17, 0, 0, 0, 0

496.205-961.515
1
0, 10, 0, 0, 3, 0

961.515-1336.25
3
0, 0, 0, 12, 0, 0

Fig. 3. Decision tree generated for the description of the performance classes identified
by AutoClass.

of these variables, the number of processors and the problem size as continuous
ones, while we consider the other two as categorical, because they only take
values from a very small set of integers. The result of this classification task by
using ID3 can be observed in Figure 4.

746

E.N. Houstis et al.

problem size
62, 65, 48, 24, 18, 7
- 338937.5
nprocs
25, 29, 43, 0, 10, 7
-3
4
7, 1, 1, 0, 10, 0

3+

2
18, 28, 42, 0, 0, 7

2187500+

3
0, 0, 0, 12, 0, 0

1

10

nprocs
26, 6, 5, 6, 6, 0
-3

3
0, 0, 0, 3, 0, 0

338937.5-2187500

mk
37, 36, 5, 12, 8, 0

mmi
11, 30, 0, 6, 2, 0

3+

0
26, 6, 5, 3, 6, 0

1
nprocs
9, 3, 0, 2, 1, 0
-3

3
0, 0, 0, 1, 0, 0

3+

0
9, 3, 0, 1, 1, 0

3

6

nprocs
2, 13, 0, 2, 1, 0
-3
3
0, 0, 0, 1, 0, 0

nprocs
0, 14, 0, 2, 0, 0
3+
1
2, 13, 0, 1, 1, 0

-3
3
0, 0, 0, 1, 0, 0

3+
1
0, 14, 0, 1, 0, 0

Fig. 4. Decision tree for identifying the performance classes based on static application
and machine characteristics.

4

The Results of the KDD Process on SWEEP3D
Performance Data

The decision tree corresponding to the description of the performance classes
identified by AutoClass and shown in Figure 3 attains strong classification patterns, in the sense that the condition vector (ordered set of values shown inside
a lead node) for the leaf nodes, contains cases/examples that belong to only one
class. For example, we can state that the class 2 is very efficient with respect to
both the communication and elapsed time.
The decision tree generated for predicting the performance classes based on
static application and machine characteristics shown in Figure 4 does not deliver
strong classification because more than one set of examples is covered by most
of the leaves in the induced tree. This is an indication that the decision tree
algorithm did not have enough features for explaining the data. This does not
create any problem though for deriving rules that the recommender system can
use for predicting the performance of a machine with some specific parameter
values.
– A general observation that can be made from the data is that even for the
minimum problem size of applications which were tried in these experiments,
and the maximum number of processors, the application does not exhibit
excessive communication volume, which means that the application scales
really well for the problems sizes and number of processors considered in
this case study.
– Another result which can be derived from the patterns in the decision tree
(Figure 4) is that there is an ordering of the parameters used for explaining

A Knowledge Discovery Methodology for Behavior Analysis

–

–

–

–

–

5

747

the performance behavior. This ordering implies that the problem size has
the highest discriminating power for separating the data into performance
classes, the parameter mk has the second highest, the parameter mmi has
the third highest and the number of processors has the lowest discriminating
power.
Classes 0 and 1 exhibit almost similar performance behavior with only difference that class 1 exhibits higher communication times than class 0. Both
classes exhibit medium to high communication times and small to large
elapsed times. This behavior can be attributed mainly to the large number
of processors.
Class 2 exhibits small communication and elapsed time. The large majority
of the examples are characterized either by small problem size, and a large
number of processors or medium problem size, or by medium problem size,
mk = 1 and large number of processors.
Class 3 exhibits medium to high communication time and a very high elapsed
time. Half of the examples belonging to this class are characterized by large
problem sizes. The other half is distributed equally between mk = 1 and
mk = 10. For those having mk = 10, the examples are furthermore equally
distributed among all the possible values of the parameter mmi. Notice that
for all the previous cases the examples are equally distributed as well between
the two categories for the number of processors.
Class 4 exhibits very stable medium elapsed time but it spans a big range
of communication times from small to medium-high ones. The examples
falling under this class are characterized either by small problem size and
small number of processors, or medium problem size and large number of
processors.
Class 5 exhibits high communication time. All the examples covered by class
5 are characterized by small problem size and large number of processors.
This fact completely explains the high communication volume.

Conclusions

In this paper we have extended the KDD methodology of the PYTHIA system
to address the selection of software/machine pairs and their parameters in the
context of an environment for designing high performance application/machine
pairs and predicting its performance. In this approach, the designer can utilize
different performance models at the application, architecture, and OS levels. The
goal of the KDD methodology in this paper is to identify various relationships of
the system parameters involved with the application parameters. For example,
the system can predict the optimum number of processors for a given machine
out of many application partitionings or the best partitioning of the application
with respect to various levels of grid sizes. PYTHIA has been extended to make
these predictions. The PYTHIA database schema is adequate for accommodating
the needs of various modeling requirements.

748

E.N. Houstis et al.

References
1. V. S. Adve and R. Sakellariou. Application Representations for Multi-Paradigm
Performance Modeling. International Journal of High Performance and Scientific
Applications, 1999. To appear.
2. R. Bagrodia and S. Prakash. Using Parallel Simulation to Evaluate MPI Programs.
In Proceedings of the 1998 Winter Simulation Conference WSC ’98, 1998.
3. Doug Burger and Todd M. Austin. The SimpleScalar Tool Set, Version 2.0. Technical Report Technical Report #1342, Computer Sciences Department, University
of Wisconsin-Madison, June 1997.
4. E. Deelman, R. Bagrodia, A. Dube, J. Browne, A. Hoisie, Y. Luo, O. Lubeck,
H. Wasserman, R. Oliver, R. Teller, D. Sundram-Stukel, M. Vernon, V. Adve,
E. Houstis, and J. Rice. POEMS: End-to-end Performance Design of Large Parallel Adaptive Computational Systems. In Proceedings of the 1st International
Workshop on Software and Performance (WOSP) ’98, October 1998.
5. U. M. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. From Data Mining to Knowledge Discovery: An Overview. In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth,
and R. Uthurusamy, editors, Advances in Knowledge Discovery and Data Mining,
pages 1–34. AAAI Press/MIT Press, 1996.
6. M. I. Frank, A. Agarwal, and M. K. Vernon. LoPC: Modeling Contention in Parallel
Algorithms. In Proceedings of the 6th ACM SIGPLAN Symposium on Principles
and Practices of Parallel Programming (PPoPP ’97), 1997. Las Vegas.
7. E. N. Houstis, S. Weerawarana, A. Joshi, and J. R. Rice. The PYTHIA Project. In
S. K. Aityan, editor, Neural, Parallel, and Scientific Computations, pages 215–218.
Dynamic Publishers., 1995.
8. Elias N. Houstis, Ann C. Catlin, John R. Rice, Vassilios S. Verykios, Naren Ramakrishnan, and Catherine E. Houstis. PYTHIA-II: A Knowledge/Database System for Managing Performance Data and Recommending Scientific Software. ACM
Transactions on Mathematical Software, 26(2):227–253, 2000.
9. A. M. Ionescu, K. E. Schauser, and C. Scheiman. LogGP: Incorporating Long
Messages into the LogP Model. In Proceedings of the 7th Annual ACM Symposium
On Parallel Algorithms and Architectures (SPAA ’95), 1995. Santa Barbara, July.
10. S. Weerawarana, E. N. Houstis, J. R. Rice, A. Joshi, and C. E. Houstis. PYTHIA:
A Knowledge Based System to Select Scientific Algorithms. ACM Transactions on
Mathematical Software, 22(4):447–468, 1996.

