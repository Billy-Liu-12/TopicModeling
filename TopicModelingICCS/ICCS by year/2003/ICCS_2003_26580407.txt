Jointly Performed Computational Tasks in the
Multi-mode System Identiﬁcation
Innokenti Semoushin
Ulyanovsk State University, 42 Leo Tolstoy Str., 432970 Ulyanovsk, Russia
SemoushinIV@ulsu.ru http://staff.ulsu.ru/semoushin/

Abstract. In this paper, we propose a new closed-loop multi-mode system identiﬁcation setup that allows the jointly performed change point
detection, fault diagnosis, supervised training of a bank of signature generators, unsupervised identiﬁcation of the optimal ﬁlter, and monitored
system accommodation on the basis of incomplete noisy data. We validate the setup by simulating numerical examples.

1

Introduction

In the literature on modern control systems, more emphasis is placed on detection [1] and identiﬁcation [2] as separate problems. At the same time, reality
provides evidence that in many cases fault detection-diagnosis must be performed
together with system identiﬁcation and accommodation. In adaptive multi-mode
or hybrid stochastic systems with an uncertain mode switching mechanism, identiﬁcation is to be launched repeatedly every time when a mode switch is detected.
In the equivalent manner, identiﬁcation must be stopped when the identiﬁcation
algorithm provides the highest (or tolerable) pitch of agreement with the observed data. Thus, FDD-SIA is a composite challenging problem needing not
only a theoretical but also computational research.
In this work, we propose a uniﬁed approach to perform FDD-SIA computational tasks simultaneously in a single system. The outline of the paper is as
follows: Section 2 describes the monitored system (MS). In Sect. 3 we formulate
the Statistical Orthogonality Principle (SOP) and refer to the Accessible Indirect Performance Index (AIPI). The SOP-based FDD is described in Sect. 5.
Section 6 shows one of identiﬁcation algorithms (IA) intended to identify the optimal Steady-State Kalman Filter (SSKF) as a substitute for the Feedback Filter
(FF). The MS accommodation is brieﬂy described in Sect. 7. Some experimental
results are shown in Sect. 8. Finally, Sect. 9 concludes the paper.

2

Monitored System

For the monitored system we consider an errors-in-variables (EIV) control system
y(ti )
, i = 1, 2, . . ., composed of the control
with the observed data z(ti ) = u(t
i−1 )
This work was supported in part by the Russian Ministry of Education (grant
No. T02-03.2-3427).
P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2658, pp. 407–416, 2003.
c Springer-Verlag Berlin Heidelberg 2003

408

I. Semoushin

input u ∈ IRq and the measurement output y ∈ IRm . The system is parameterized
by an uncertainty vector θ ∈ IRl and consists of a plant (P), a sensor (S) and a
stabilizing feedback controller(FC) (Fig.1(a)). The P state equation is
(a)
u✲

w

❄
P

v

x

❄

✲

S

SG

(b)
y

✲
MS

✛

FC

z

✲

RG

✲

SM

✲

✛

r

❄✲ζ
✻

{sj }

Fig. 1. (a) Monitored System (MS), and (b) Statistical orthogonality. Legend: P –
plant, S – sensor, FC – feedback controller, RG – residual generator, SM – sensitivity
model, SG – signature generator

x(ti+1 ) = Φθ x(ti ) + Ψθ u(ti ) + w(ti ),

i = 0, 1, . . .

(1)

with x ∈ IRn and a noise w(ti ) where the random initial x(t0 ) at some t0 has a
ﬁnite mean x
¯0 and a ﬁnite covariance P0 ≥ 0 and {u(ti )} is wide-sense stationary
and so E{||u(ti )||2 } < ∞ for all ti . The S equation is
y(ti ) = Hx(ti ) + v(ti ),

i = 1, 2, . . .

(2)

with rank(H) < n and a noise v(ti ). Both {w(ti )} and {v(ti )} are i.i.d. zero
mean mutually independent wide-sense stationary sequences whose covariances
are E{w(ti )w(ti )T } = Qθ ≥ 0 and E{v(ti )v(ti )T } = Rθ > 0 for all ti . The FC,
in compliance with the well-known separation property, is formed by a feedback
ﬁlter (FF) cascaded with a feedback regulator (FR). The FF equations are
¯x(t+ ) + Ψ u(ti ),
x
˜(t−
i+1 ) = Φ˜
i

¯
x
˜(t+
˜(t−
˜(t−
i )=x
i ) + K[y(ti ) − H x
i )]

(3)

¯
with some initials x
˜(t+
0 ), u(t0 ). Constant transition matrix Φ and constant gain
¯
K are chosen in a sense arbitrarily or designed to be optimal in a steady state
(as t0 → −∞) w.r.t. a ﬁxed (fault-free) system mode speciﬁed by a nominal
value θ0 of θ. The FR equation is
¯ ˜(t+ )
x(t+
u(ti ) = fFR [˜
i )] = −GFR x
i

(4)

with a function fFR [·] which can be chosen to satisfy the second equality in (4)
¯ FR . By (3), (4), it is predetermined that u(ti )
with a constant gain matrix G
depends on all available data z(ti1 ) = [z(t1 ), · · · , z(ti )], the latter is a notation
for a composite (stackable) column vector. Note that

w(ti )
v(tj )

is independent of

u(tk ) and x(tk ) for all ti ≥ tk , tj > tk .
The overall closed-loop control system (1), (2), (3), (4) is assumed to be
asymptotically stable in all modes of operating referred to by the subscript θ,

Jointly Performed Computational Tasks

409

and so all the processes within the system are wide-sense stationary at every ti
as t0 → −∞ (the main assumption). The system is designed to operate with a
minimum expected control cost
Jc = lim E{xT (tN +1 )Xf x(tN +1 ) +
j→−∞

N

[xT (ti )Xx(ti ) + uT (ti )U u(ti )]} (5)

i=j

for N > 0, Xf ≥ 0, U > 0, X ≥ 0, and in all modes holds the main properties:
1/2

(Φθ , Qθ ) is stabilizable, (Φθ , X 1/2 ) is detectable, (Φθ , H) is completely observable, and (Φθ , Ψθ ) is completely controllable.
to guarantee the existence of the optimal steady-state parameters for (3), (4).
The system itself can operate in several (ﬁnitely or inﬁnitely many) modes.
This brings the problem to the realm of hybrid or multi-mode systems. The
mode characterized by θ0 can be treated as the main one. The other modes
characterized by some θ1 , θ2 , . . ., θM – for the case of ﬁnitely many modes, –
can be viewed as some alternative modes not obligatory (albeit possibly) faulty.
In this case we have to test the M pairs of hypotheses, in each pair between
H0 = {θ† = θ0 }

and Hµ = {θ† = θµ = θ0 + Υ µ }

(6)

†

where θ is the true value of θ, µ = 1, 2, . . . , M, and Υµ is the µ-th change on θ
(the µ-th alternative mode of operation). Allowing for arbitrary faults, which are
modelled by any sizable change Υ on θ not violating the above main assumption,
we come to the case of inﬁnitely many modes. By this, we generalize the problem
as we have to test the continuum set of pairs of hypotheses
H0 = {θ† = θ0 }

and HΥ = {θ† = θΥ = θ0 + Υ } .

(7)

In both cases (6) and (7) we do not assume a speciﬁc mode switching behavior
(for example, a Markovian one) and view it as deterministic (albeit unknown to
the observer) like controlled by an independent actor.

3

Statistical Orthogonality Principle

Deﬁnition 1. Given l pairs {r, sj }, j = 1, 2, . . . , L, each formed by column
vectors r = r(ti ) and sj = sj (tk ). Then r(ti ) and sj (tk ) are said to be statistically
orthogonal at distance ∆t = tk − ti , that is denoted as r(ti ) ⊥ sj (tk ), if
∀ti , tk , ∆t = tk − ti = const :

E{sTj (tk )r(ti )} = 0

(8)

and r(ti ) is said to be statistically orthogonal to S(tk ) = [s1 (tk ) | · · · | sL (tk )] at
∆t = tk − ti if (8) holds for all given pairs, that is denoted as r(ti ) ⊥ S(tk ).
Let r and S in Deﬁnition 1 be computed by L pairs of parallel blocks RG
and SM as shown in Fig.1(b). By RG and SM are meant Residual Generator
and Sensitivity Model both parameterized by a design parameter θˆ ∈ IRL not
fully but partly being an exact replica of θ, the MS parameter, in its elements’
ˆ and S(tk ) = S(tk , θ).
ˆ
numbering and sense. Thus, r(ti ) = r(ti , θ)

410

I. Semoushin

Deﬁnition 2. Let RG and SM be designed in such a way that in case (6) for
each µ = 0, 1, 2, . . . , M, parameter θˆ takes a speciﬁed value θˆµ such that
∀µ :

†
ˆ ←
ˆ ⊥ S(ti , θ)
{θˆ = θˆµ } ≡ { r(ti , θ)
→ θ = θµ }

(9)

or in case (7) for each Υ , parameter θˆ takes a speciﬁed value θˆΥ such that
∀Υ :

†
ˆ ⊥ S(ti , θ)
ˆ ←
{θˆ = θˆΥ } ≡ { r(ti , θ)
→ θ = θΥ }

(10)

where ←
→ stands for “iﬀ ” (if and only if ). Then (9) and (10) is termed Statistical
Orthogonality Principle.
The parallel blocks in Fig.1(b), RG and SM, may be variously designed to
satisfy Deﬁnitions 1 and 2. However as system (1), (2), (3), (4) is stochastic, the
ˆ is requisite for
presence of an (adaptive) estimator (AE), denote it by g(ti|i−1 , θ),
ˆ
ˆ
ˆ
obtaining a residual r(ti , θ). With it, writing r(ti , θ) ⊥ S(ti , θ) is straightforward
as a necessary (and on occasion, suﬃcient) condition for minimum of
ˆ
ˆ = 1/2 lim E{ r(ti , θ)
J(θ)
tj →−∞

2

| y(tji−1 )} .

(11)

Thus, SOP implementation boils down to the construction of (11) so as to obtain
ˆ
ˆ
ˆ = ∂r(ti , θ) · · · ∂r(ti , θ)
S(ti , θ)
ˆ
ˆ
∂ θ1
∂ θL

4

.

(12)

Identiﬁcation Performance Indices

ˆ the system
Minimum Prediction Error methods [3] oﬀer to predict by g(ti|i−1 , θ)
ˆ
ˆ
output y(ti ) and use r(ti , θ) = y(ti ) − g(ti|i−1 , θ) as a residual. Minimizing (11)
with such residual leads to the biased parameter estimates for the given EIV
ˆ in (11) instead been in one of the following forms
system [4], [5]. Had r(ti , θ)
ˆ = { x(ti ) − g(ti|i−1 , θ)
ˆ or x
ˆ }
ˆOPT (ti|i−1 ) − g(ti|i−1 , θ)
r(ti , θ)

(13)

where x
ˆOPT (ti|i−1 ) is the one-step SSKF predictor for x(ti ), minimizing (11)
would have helped to avoid the bias. Obviously, (13) provides two clear examples
of Direct (but) Inaccessible Residual (DIR) and in this case (11) is an example
of Direct (but) Inaccessible Performance Index (DIPI).
Remark 1. In the limit as t0 → −∞, FF equations (3) assure coincidence
x
˜(t+
ˆOPT (ti|i )
i )=x

and

x
˜(t−
ˆOPT (ti|i−1 )
i )=x

(14)

if optimally designed for the fault-free system mode speciﬁed by θ† = θ0 .
ˆ in (13) contains SSKF, then g(ti|i−1 , θ)
ˆ
Remark 2. If a set of AEs g(ti|i−1 , θ)
minimizing (11) coincides with x
ˆOPT (ti|i−1 ). If a fault occurs, we consider SSKF
a hidden object to be identiﬁed to substitute FF and be used to modify FR.

Jointly Performed Computational Tasks

411

Problem 1. To implement both SOP-based FDD and SSKF identiﬁcation, we
need to construct the Accessible albeit Indirect Residual (AIR) as a substitute
for the DIR in order to change from the DIPI to the Accessible albeit Indirect Performance Index (AIPI) in (11), the latter having the same minimizing
estimator as the DIPI.
Solution 1. Being the system completely observable enables the solution to be
found in the form:
ˆ = DIR(ti , θ)
ˆ + SP(ti ), SP(ti ) ⊥ DIR(ti , θ),
ˆ SP(ti ) = f (θ)
ˆ (15)
AIR(ti , θ)
ˆ = DIPI(θ)
ˆ + Const, Const = 1/2 E{ SP(ti ) 2 | y(ti−1 )} (16)
AIPI(θ)
j
ˆ ] and (16)
where SP(ti ) is a slack process fully independent of θˆ [SP(ti ) = f (θ)
is the half mean squared Euclidean norm of (15) in the limit as tj → −∞.
Remark 3. The solution is given in [6], [7], [8] and thoroughly tested in [9] for
ˆ by ε(ti , θ)
ˆ
identiﬁcation purposes only. In what follows, we denote the AIR(ti , θ)
and use it here for the jointly performed FDD-SIA computational tasks. So from
ˆ serves instead of r(ti , θ)
ˆ in Formulas (8) to (12).
now on, ε(ti , θ)

5

Fault Detection and Diagnosis

In accordance with Deﬁnition 2 and Remark 3, being the k-th expectation
ˆ
ˆ = E{ ∂ε(ti , θ) , ε(ti , θ)
ˆ
ζj (ti , θ)
∂ θˆj

| θˆ = θˆµ or θˆΥ }, j = 1, 2, . . . , L

(17)

of the dot product (· , ·) in the immediate vicinity of zero is equipollent to the
fact that θ† = θµ or θΥ . On this basis we use it as a signature of the fact as it is
shown schematically in Fig. 1(b) where ζ is composed of (17), ζ ∈ IRL .
In FDD, when we test between (6), the theoretical signature
∀ µ and j = 1, 2, . . . , L :

ζj (ti , θˆµ ) = 0

(18)

is checked by the following approximate decision rule:
∀ µ = 1, 2, . . . , M and j = 1, 2, . . . , L :

nµj
0.5 −
N

Hµ
>
<
H0

γj

(19)

where nµj is the number of negative outliers of the process ζˆj (ti , θˆµ ) in the current
sample of size N . Here ζˆj (ti , θˆµ ) is an estimator (for which we recommend the
exponential smoothing) of ζj (ti , θˆµ ) deﬁned for (18) according to (17) for each
µ-th Signature Generator (SG) within the Bank of Signature Generators (BSG),
µ = 1, 2, . . . , M (Fig. 2(a)). Signature Evaluator and Selector (SES) in this setup
operates according to (19), where the sample size N and thresholds γj should

412

I. Semoushin

be determined experimentally to guarantee the maximum decision power with
the limited error probability. If several hypotheses among Hµ , µ = 1, 2, . . . , M,
have been selected, we discriminate between them by the additional rule: select
the Hµ∗ with
L

µ∗ = arg min
µ

j=1

nµj
0.5 −
N

.

(20)

If none Hµ , µ = 1, 2, . . . , M, has been selected, we adopt a decision that H0 is
true.
(a)

(c)
MS

ζˆ✲

z

✲ BSG

SES

Hµ

✲

MS

✻

µ ∈ {0, 1, . . . , M}

(b)
MS

ζˆ✲

z

✲ TBSG

H

SES

✻
θˆµ

✛

AM

oﬀ
AM ✛

✲µ

✻

✲

✻ ζˆ
❄ ˆ
✲ SG✁✁✕ ✲ SES on✲ IA ✲θ
z
✁
✛
update ✛

Fig. 2. (a) Fault detection and diagnosis (discrimination between M + 1 hypotheses).
(b) Fault diagnosis and system accommodation using TBSG. (c) Fault point detection
to switch IA and AM. Legend: MS – monitored system, BSG – Bank of Signature
Generators, TBSG – Trained BSG, SES – Signature Evaluator and Selector, AM –
Accommodation Mechanism, IA – Identiﬁcation Algorithm

6

Optimal Filter Identiﬁcation and BSG Training

To reason what change (or what fault) has occurred, one of two strategies may be
used: parallel or sequential. The ﬁrst one is adequate for Case (6), while the latter
for Case (7). The parallel strategy implies the existence of the BSG as discussed
in Sect. 5. Each SG can be trained beforehand to match the corresponding system
mode, i.e. to satisfy (18). Training algorithms for a single (µ-th) SG are standard
identiﬁcation algorithms for θˆ = θˆµ . For example, one can use the following SLS:
Simpliﬁed Least Squares. For k = 1, 2, . . . and Λ = diag[λ(j) ], j = 1, 2, . . . , L,
with Λ1 = I do (21) and then (22) where k is the step number:
(j)

(j)

λk+1 = λk +

∂ε(ti , θˆk )
∂ θˆj

2

T
ˆ
ˆ
θˆk+1 = θˆk − Λ−1
k+1 E{S (ti , θk )ε(ti , θk )}

(21)
(22)

Jointly Performed Computational Tasks

413

where E{·} is a smoothing algorithm. In the case of exponential smoothing we
ˆ i , θ)
ˆ = E{ζ(ti , θ)}
ˆ from the signature vector ζ(ti , θ)
ˆ = S T (ti , θ)ε(t
ˆ
ˆ
obtain ζ(t
i , θ)
by
ˆ + (1 − β)ζ(ti , θ),
ˆ
ˆ = β ζ(t
ˆ i−1 , θ)
ˆ i , θ)
ζ(t

0≤β<1 .

(23)

In Case (7) we have to use the sequential strategy of Fig. 2(c) with one SG,
one SES and one identiﬁcation algorithm (IA). In this setup, SG is intended
to detect and track all possible abrupt changes as they occur in time in the
monitored system. The SG performs this by means of IA, which may be of
(21)–(22) type or another. The SES tests between hypotheses (7) so that the
rule (19) is implemented with µ = 1. Decision to adopt H1 starts up the IA;
decision to adopt H0 stops it and starts the accommodation mechanism (AM)
in order to bring the feedback of MS and the real situation after change into
better agreement and, in doing so, to adapt the system feedback to suit the new
(after-change) conditions. Figure 3 shows how it is implemented except AM.
Accommodation mechanism is discussed brieﬂy in Sect. 7.

begin i := 0;
for j := 1 to L do
begin nj := 0; sj :=oﬀ; λj := 1 end;
while i ≤ imax do
for j := 1 to l do
begin i := i + 1;
ˆ < 0 then nj := nj + 1;
if ζˆj (ti , θ)
fj := 0.5 − nj /N ;
if i mod N = 0 then
begin nj := 0;
if abs(fj ) < γj then
sj :=oﬀ else sj := on
end;
if sj = on then
begin
λ(j) := λ(j) +

ˆ
∂ε(ti ,θ)
∂ θˆj

2

;

ˆ (j)
θˆ(j) := θˆ(j) − ζˆj (ti , θ)/λ
end else
if i mod N = 0 then λ(j) := 1
end
end.

Fig. 3. Pseudocode sketching the inter-independent parameter identiﬁcation algorithm

414

7

I. Semoushin

Monitored System Accommodation

To accommodate the MS to the newly developed (maybe, faulty) mode, the accommodation mechanism (AM) is expected to be capable to replace parameters
¯ and K
¯ of (3) with the newly identiﬁed matrix Φ and optimal SSKF gain K,
Φ
¯ FR of (4) with the GFR computed by solving the Discrete Algebraic Ricand G
cati Equation, DARE, in compliance with the well known LQG control law using
matrices of (5).

8

Approach Validation

I. System. Dimensions are n = 2, m = 1, q = 1, l = 2. Matrices are as follows:
Φθ =

0
θ1

1
,
θ2

H = 1

0 ,

θ0T = 0.30
¯ =
Φ

0
0.2

0.68 ,
1
,
0.2

Qθ

=Q=

0
0

Rθ = R = 0.1 ,

θT

= θ1

θ2

θΥT = 0.40

ΥT

= 0.10

Ψθ = Ψ =

0
,
1

0.10 ,

¯ = 0.2 ,
K
0.2

¯ FR = 0.5
G

0
1

−0.58
0.5

.

II. Residual Generator. According to Remark 3, RG is composed of AE and AIR:
ˆ = A[g(ti|i−1 , θ)
ˆ + Dη(ti , θ)]
ˆ + Ψ u(ti )
g(ti+1|i , θ)
ˆ = y(ti ) − Hg(ti|i−1 , θ)
ˆ .
η(ti , θ)

(24)
(25)

For AE (24), (25), we have here L = 4 and
A=

0
a1

1
,
a2

D=

d1
,
d2

θˆT = a1

a2

With reference to Remark 3, we construct AIR as

ˆ = N (D)η(ti
ˆ
ε(ti , θ)
i−s+1 , θ),

1
0
 ..
 .
1

N (D) = 
.
..
 dn−1

dn dn−1

d1

d2

0

0

.

(26)




0

 .
1 0

..
. 1
0

(27)

In the ﬁrst formula of (27), s is the greatest partial observability index of the
system and the second formula holds if MS with m = 1 is taken in the standard
observable form [7]. Such is here the case and s = 2,
ˆ = [η(ti−1 , θ)
ˆ η(ti , θ)]
ˆ T .
η(tii−s+1 , θ)

(28)

Jointly Performed Computational Tasks

415

ˆ (27), in view of Remark 3,
III. Sensitivity Model. To obtain (12) from ε(ti , θ),
we have to generate the sensitivity functions having deﬁned them by
ˆ = ∂ g(ti+1|i , θ),
ˆ
µ(j) (ti+1|i , θ)
∂ θˆj

j = 1, . . . , L .

(29)

IV. Pattern for Computational Experiments. The composite algorithm we test
is outlined by Figs. 2(c) and 3. Besides the MS with the above matrices, it
involves: RG – (24), (25), (26), (27) and (28); SM – (12) and (29); SG – (17);
SES – (19) and (20); and IA – (21), (22) and (23). The algorithm is started
¯ K
¯ and G
¯ FR . The SES is expected to
up with the non-optimal parameters Φ,
detect this initial non-optimality and to start up the IA precisely in respect to
the parameters which require optimisation. The IA is expected to eliminate the
initial non-optimality (this is the SG training). After that, at the middle time
instant t8000 , the MS switches from mode H0 to HΥ , cf. (7). The algorithm is
expected to detect this mode switch, to identify the new optimal parameters
and accommodate the MS feedback to the after-switch conditions.
V. Experimental Results. An example of the results is shown in Figs. 4 and 5.
This is one of many results obtained for many diﬀerent conditions [10]. In these
experiments, the following values were chosen: γj = 0.05, N = 2000 and β = 0.1.
The estimates formed by the composite algorithm are thus seen to be satisfactory
enough. This lends support to the validity of the proposed approach.
1.4

1.2
1

1.2

0.8

1

0.6
0.8
0.4
0.6
0.2
0.4

0

0.2
0

−0.2
0

2

4

6

8

10

12

14

3

16 x 10

−0.4
0

2

4

6

8

10

12

14

3

16 x 10

Fig. 4. Tracking the true parameters θ1 and θ2 by a1 (left) and a2 (right) of (26)

9

Conclusions and Future Work

We have shown that statistical orthogonality principle and indirect identiﬁcation
performance index provide the basis for the jointly performed computational
tasks in the multi-mode stochastic system identiﬁcation. Further investigations
of this approach should be made to study all the aspects, both theoretical and

416

I. Semoushin
2

1.8
1.6

1.5

1.4
1.2
1

1

0.8
0.5

0.6
0.4

0

0.2
0
−0.2
0

2

4

6

8

10

12

14

3

16 x 10

−0.5
0

2

4

6

8

10

12

14

3

16 x 10

Fig. 5. Tracking the SSKF parameters k1 and k2 by d1 (left) and d2 (right) of (26)

applied, for instance – to evaluate it in terms of false alarm and missed detection
rates.

References
1. Basseville, M., Nikiforov, I.: Detection of Abrupt Changes: Theory and Applications. Prentice-Hall Inc., New York (1993)
2. Landau, I.D. (ed.): Identiﬁcation des Systemes. Les Bases de l’Identiﬁcation des
Systemes. Hermes, Paris (2001)
3. Caines, P.: Linear Stochastic Systems. John Willey & Sons, New York Chichester
Brisbane Toronto Singapore (1988)
4. Soderstrom, T.: Identiﬁcation of stochastic linear systems in presence of input
noise. Automatica 17 (1981) 713–725
5. Ansay, P., Gevers, M., Wertz, V.: Closed-loop or open-loop models in identiﬁcation
for control? In: Proc. of the European Control Conference (1999) CD-ROM F544
6. Semoushin, I.V.: Adaptive Identiﬁcation and Fault Detection Methods in Random
Signal Processing. Saratov University Publishers, Saratov (1985) [in Russian]
7. Semoushin, I.V.: Adaptive control for stochastic linear plants under conditions
of uncertainty. Nonlinear Dynamical Systems - Qualitative Analysis and Control:
Collected Papers, The Institute for System Analysis of the Russian Academy of
Sciences 2 (1994) 104–110
8. Semoushin, I.V., Tsyganova, J.V.: Indirect error control for adaptive ﬁltering. In:
Neittaanmaki, P., Tiihonen, T., Tarvainen, P. (eds.): Proc. of the 3rd European
Conference on Numerical Mathematics and Advanced Applications. World Scientiﬁc, Singapore New Jersey London Hong Kong (2000) 333–340
9. Semoushin, I., Gorokhov, O.: Computational processes in iterative control design.
In: Sloot, P.M.A., Kenneth Tan, C.J., Dongarra, J.J., Hoekstra, A.G. (eds.): Computational Science – ICCS 2002. Lecture Notes in Computer Science, Vol. 2329.
Springer-Verlag, Berlin Heidelberg New York Barcelona Hong Kong London Milan
Paris Tokyo (2002) 186–195
10. Kondratiev, A.E., Fatyanova, O.A.: Start-stop algorithms for adaptive ﬁltering.
In: Boulyarski, S.V. (ed.): Young Researchers’ Collected Papers of the Ulyanovsk
State University. UlSU Publishers, Ulyanovsk (2001) 6–7

