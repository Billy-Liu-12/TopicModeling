OpenMP and NUMA Architectures I:
Investigating Memory Placement on the SGI Origin 3000
Nathan Robertson and Alistair Rendell
Department of Computer Science
Australian National University
Canberra ACT0200, Australia
Nathanr@nathanr.net, Alistair.Rendell@anu.edu.au

Abstract. The OpenMP programming model is based upon the assumption of
uniform memory access. Virtually all current day large scale shared memory
computers exhibit some degree of Non-Uniform Memory Access (NUMA).
Should OpenMP be extended for NUMA architectures? This paper aims to
quantify NUMA effects on the SGI Origin 3000 system as a prelude to
answering this important question. We discuss the tools required to study
NUMA effects and use them in the study of latency, bandwidth and the solution
of a 2-D heat diffusion problem.

1 Introduction
In the late 1980’s a number of hardware vendors began offering small scale shared
memory parallel architectures comprising a few CPU and memory boards linked via a
shared bus. These systems quickly proved to be very popular not least because the
cost premium of adding CPUs was relatively low compared to the cost of the initial
system. With this new architecture and an expanding user base came a natural interest
to develop applications that could run in parallel, and this was particularly true among
the computational science community.
Although there are several ways to utilize multiple CPUs on a shared memory
architecture, the idea of parallelizing critical loops by adding a few directives to the
source code and letting the compiler do most of the work was particularly attractive.
This was in part because computational scientists had used a similar approach to
successfully exploit vector architectures. To facilitate this, hardware vendors began
implementing and promoting their own set of shared memory parallel programming
compiler directives. Unfortunately, although many of these directives provided
virtually identical functionality their exact form was vendor specific. This situation
existed for a number of years, until in the mid 1990’s there was a move to develop a
standard set of shared memory parallel processing directives that eventually gave rise
to OpenMP for Fortran 77 [1] (released in 1997). The success of this standardization
effort has since led to a number of updates and extensions such that the OpenMP
model now encompasses Fortran 95, C and C++ [1].
A basic premise of OpenMP is a shared memory programming model in which all
CPUs have equal access to all memory locations, i.e. the assumption of Uniform
Memory Access (UMA). While this accurately reflected the early bus based shared

P.M.A. Sloot et al. (Eds.): ICCS 2003, LNCS 2660, pp. 648–656, 2003.
© Springer-Verlag Berlin Heidelberg 2003

OpenMP and NUMA Architectures I

649

memory machines of the late 1980’s and early 1990’s, it is increasingly not true for
large scale shared memory parallel architectures. Thus, virtually all current large scale
parallel machines have some degree of Non Uniform Memory Access (NUMA), e.g.
the SGI Origin 3000, HP GS320, Sun E15k and IBM Regatta.
For computational science the shared memory parallel programming paradigm has
some definite attractions, especially now that there is widespread compiler support for
OpenMP. For many of these applications, however, performance is also critical and
an obvious question arises as to whether the existing UMA OpenMP programming
model should be extended to account for current NUMA architectures, and if so how.
There is also interest in developing OpenMP compilers that generate code for cluster
systems [2,3] – which is an extreme NUMA environment!
NUMA support within OpenMP has received some discussion both in the literature
and at various conference forums [4,5]. There are essentially two opposing views. At
one extreme it is considered that issues relating to memory placement should be
handled by the O/S through sensible page placement and migration. While at the other
extreme it is advocated that the user should be provided with full control over all
memory and thread placement. In the middle there are a number of hybrid schemes,
such as the user initiated page migration model proposed by Nicolopolous et al [6].
Already some vendors, e.g. SGI [7] and Compaq [8], have implemented their own
NUMA extensions to OpenMP. Unfortunately, as in the early days of shared memory
parallel systems, these have different syntax but similar functionality. For application
programmers trying to develop portable programs this provides a major disincentive
to their use. In our view, however, it is premature to be advocating any specific
NUMA extensions to OpenMP. Rather we believe it is first important to gather
information for a variety of applications showing clearly the benefits or otherwise of
different memory placements on overall performance. That is, to quantify what is the
maximum likely difference between the performance obtained when using optimal
memory placement versus that obtained when using the worst possible memory
placement, and then to compare both these results with the typical performance
obtained when running with the default memory placement provided by the O/S.
This paper is a first step towards this goal. Firstly we discuss the basic functionality
that is required to develop application programs that can be used to investigate
NUMA effects. Then we use this functionality to measure the different memory
latencies and bandwidths on a NUMA platform – an SGI Origin 3000 system [9,10].
Finally we investigate the implication of NUMA on the performance on the SGI
Origin of a typical 2-D heat diffusion program.

2 Basic Requirements
Our goal is to place processes or threads on specific CPUs within the NUMA
hardware and have their associated memory reside at specific physical locations. To
achieve this requires the ability to:
• bind a particular process or thread to a specific CPU
• allocate memory pages to specific memory locations without page migration
For verification it is also useful to be able to:

650

N. Robertson and A. Rendell

•
•

determine the physical CPU that a process/thread is currently running on
map any given virtual address to its physical address

In general, in a multi-user shared-memory parallel environment having users tie their
threads or memory to specific hardware resources is undesirable since it substantially
reduces the flexibility of the O/S to efficiently schedule jobs. Thus it is hardly
surprising that for a given hardware platform finding out how to achieve these goals is
not always easy!
The results presented here were obtained from an SGI Origin 3000 system [9]. To
create threads we used the pthreads library and then bound them to specific CPUs
using SGI’s non-standard pthread_setrunon_np library routine. Memory was
allocate and placed at specific locations using the “dplace” utility. To verify thread
placement it is necessary to first issue a call to schedctl(SETHINTS) before
obtaining the CPU id from the get_cpu macro defined in the task.h header file.
To map virtual addresses to physical addresses we used the va2pa routine available
at the SGI technical publication web site [11], although it should be noted that the bits
are shifted by 33 places on the Origin 3000 compared to 32 places on the Origin 2000.

Fig. 1. Schematic diagram of the router and CPU bricks on the SGI Origin 3000 used in this
work. (C-bricks contain 4 600MHz R14K CPUs and 4GBytes of memory).

The physical configuration of the SGI 3000 used in this work is given in Fig.1. It has
64 processors and 64GB of memory. Each CPU board, or C-brick, comprises 4 CPUs
and 4GBytes of memory. The C-bricks are connected to router or R-bricks that are
then connected together in a “bristled” hypercube topology. There are 8 connections
to each R-brick and each is capable of a peak performance of 1.6GB/s bidirectional.
On the machine used for this work the spare R-brick connections that would normally
be used to build a higher dimensional hypercubes have been used to provided
enhanced bandwidth between selected R-bricks. The configuration shown in Fig.1 has
three different levels of NUMA, corresponding to the following memory accesses:

OpenMP and NUMA Architectures I

1.
2.
3.

651

within the same C-brick, e.g. C-brick0 to C-brick0
one R-brick remove, e.g. C-brick0 to C-brick1
two R-bricks removed, e.g. C-brick0 to C-brick11

3 Measuring Memory Latency on NUMA Architectures
The aim here is to measure the memory latency associated with each different class of
memory access. To do this we have developed a modified version of LMBench [12].
The basic idea behind LMBench is pointer chasing, i.e. a memory location is read and
the contents used as a pointer to the location of the next memory address to be read.
By designing each memory reference to be sufficiently well separated from all
previous references it is possible to ensure that all references are to main memory and
not to data that already resides in cache.
To achieve the above goal LMBench was modified to use pthreads. First a
thread is created and bound to a specific CPU. This thread then allocates and
initializes a large block of memory on the same C-brick (using dplace). The first
element of this array is defined as a pointer referencing an element Nsep bytes further
along in the array. This element in turns references another element Nsep bytes further
advanced. This pattern continues until after some point a null pointer is used to
terminate the sequence. After establishing this pointer series, the address of every
element in the array is examined to verify that it is indeed located on the expected Cbrick. The thread is then moved and bound to a CPU on a different C-brick, the
pointer references followed, and the elapsed time taken recorded. (Note that we
initialize the thread on one C-brick and then measure the pointer chasing time on
another to ensure that that there are no caching effects resulting from the array setup
phase). When measurement is complete on this C-brick the thread is moved to another
C-brick and process repeated. A brief summary is given below:
Create thread and bind to specific CPU on given c-brick
Allocate memory on same c-brick and set up pointer array
Move thread to new c-brick
foreach c-brick in system
bind thread to that c-brick
pointer = initial_pointer
start timer
while pointer != NULL
pointer = *pointer
stop timer
print c-brick and time

Next c-brick
The benchmark contains two parameters, the number of bytes separating each pointer
reference (Nsep) and the total number of pointer references (Nref). The results for
Nref=1000 and Nsep=16kbytes are given in Fig. 2. It is immediately obvious from this
that the memory was located on C-brick 2. Accessing this memory from the C-bricks

652

N. Robertson and A. Rendell

connected to the same R-brick (i.e. C-bricks 0, 1 and 3) incurs a latency penalty of ≈
50%, while those located two R-bricks away have roughly twice the latency.
Overall the results shown in Fig. 1 tend to indicate that for memory latency critical
applications there is potentially a factor of two to be gained through careful placement
of thread and memory.

2.50

Relative Latency

2.00
1.50
1.00
0.50
0.00
0

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15

C-brick

Fig. 2. Relative memory latency for accessing memory located on C-brick2 from all C-bricks.
Results obtained on a non-dedicated Origin 3000

4 Measuring Bandwidth on NUMA Architectures
The aim here was to measure memory bandwidth contentions that may arise from
having multiple threads simultaneously accessing various memory locations. To do
this we have used a modified version of the STREAM benchmark [13]. This
benchmark measures the time required to perform the following four vector
operations:
A(1:N)
A(1:N)
A(1:N)
A(1:N)

=
=
=
=

B(1:N)
B(1:N) * const
B(1:N) + C(1:N)
B(1:N) + C(1:N) * const

copy
scale
add
triad

for some large value of N. The results are reported in terms of Mbytes/sec,
representing the amount of data that is transferred between memory and the CPU.
The basic STREAM benchmark was modified to create multiple threads and
multiple sets of the A, B and C vectors. Each set of vectors was allocated entirely
within the memory of a specific C-brick and was used by a unique thread. Treads

OpenMP and NUMA Architectures I

653

were then selectively bound to different C-bricks and synchronized before and after
they had completed each vector operation. The results obtained with up to two threads
and two different memory locations are given in Table 1.

Table 1. Memory bandwidth for Scale and Triad operations with explicit thread and memory
placement for up to 2 threads/memory pairs. Results were obtained from a non-dedicated 64
SGI O3K with 600MHz processors

Exp.
No.

— C-brick Pair 1—
Thread Memory

— C-brick Pair 2 —
Thread
Memory

Scale
Mbytes/Sec

Triad
Mbytes/Sec

1-thread
1.1
0
1.2
0
1.3
0

0
1
9

-

-

676
556
433

637
533
458

2-threads
2.1
2.2
2.3
2.4
2.5

0
0
1
0
0

0
1
1
9
10

0
1
0
0
1

789
1196
1044
750
881

800
1260
1083
736
870

0
0
0
9
9

Although the results were obtained from a non-dedicated machine, we report the best
observed performance from a number of experiments and believe the trends to be
valid. Thus with a single thread we see maximum performance from experiment
number 1.1 – corresponding to co-location of the thread and memory. Separating the
thread and memory by a single R-brick decreases bandwidth (result 1.2) by about
20%. This decreases still further when the thread and memory are separated by two Rbricks (result 1.3). Since the interconnect can support data rates well in excess of the
results obtained above, it seems likely that at least part of this bandwidth reduction
may be due to contention on the network arising from the other jobs running at the
time.
Considering now the results for two threads, if these threads plus their memory are all
located on the same C-brick we see only marginal improvement in bandwidth
compared to the single thread results, i.e. result 2.1 compared to result 1.1. Moving
the threads and memory to different C-bricks (result 2.2) gives a significantly
enhanced bandwidth of nearly twice that of a single thread (result 1.1). Interestingly
having each thread reference memory on the C-brick of the competing thread (result
2.3) produces nearly the same bandwidth as when each thread is accessing local
memory (result 2.2). In experiment 2.4 the threads were both located on the same Cbrick but at the opposite side of the machine to their memory. This produces roughly
the same bandwidth as having all threads and memory on the same C-brick (result
2.1). Finally having all threads and memory on different C-bricks is slightly better
than having them all on one C-brick, i.e. result 2.5 compared to result 2.1.

654

N. Robertson and A. Rendell

In summary for two threads their appears to be the potential for the available memory
bandwidth to vary by a factor of two between the best and worst possible thread and
memory placement.

5 Memory Placement for 2D Heat Diffusion
The above results clearly show a difference between optimal and non-optimal
memory and thread placement. Both cases are, however, extreme examples designed
to illustrate these effects. We now consider a slightly more realistic problem – the
solution of the Laplace equation on a uniform rectangular lattice with Dirichlet
boundary conditions. A typical example of this occurs when calculating the steady
state temperature distribution for a metal plate whose edges are held at a fixed
temperature. The algorithm proceeds by discretizing the domain of the metal plate and
then evaluating a new temperature for each grid point based on an average of the
current temperatures of the four surround grid points. Normally the calculation would
continue in an iterative fashion until some convergence criteria is reached, however in
our benchmark we perform a fixed number of iterations. The algorithm is easily
parallelized using a simple domain decomposition in which, for example, on two
CPUs all the data points in one half of the domain are assigned to one thread while
those in the other half are assigned to the other. Our parallelization was implemented
using pthreads.
In a similar vein to the modified STREAM benchmark the threads and the memory
corresponding to the grid point they will be updating were selectively placed on
different C-bricks. In contrast to the simple STREAM benchmarks, however,
updating the data points at the boundary between the two domains requires both
threads to retrieve a small amount of data from the adjoining domain. The calculation
was run for 25 iterations on a grid size of 1500 by 2048 elements. Results for two
threads are given in Table 2. Although the benchmark was again run in a nondedicated environment timing data was collected from a number of runs performed
over a number of days. We report the best elapsed time as well as the average elapsed
time and standard deviation. The thread and memory placements labeled as “IRIX”
were obtained without using any explicit memory or thread placement.
The “Best” results show a difference of about 40% between the results obtained in
experiment 2.2 compared with those from experiment 2.4. It is also not surprising,
given the STREAM results, that the fastest performance was obtained when each
thread was located on a different C-brick, and the arrays containing their grid points
also resided on the same C-brick. It is also interesting that the results obtained without
any explicit thread or memory placement are close to the worst. Suggesting that, at
very least, a user who blindly uses this system without any thought to thread and data
location is likely to achieve far from optimal performance.

OpenMP and NUMA Architectures I

655

Table 2. Effect of memory and thread placement for parallel 2-D heat diffusion benchmark
using 2 threads. Results elapsed times obtained from a non-dedicated 64 SGI O3K with
600MHz processors

Exp.
No.
2.1
2.2
2.3
2.4
2.5
2.6

— C-Brick Pair 1 —
Thread
Memory
0
0
0
9
9
IRIX

0
0
1
0
0
IRIX

— C-Brick Pair 2 —
Thread
Memory
0
1
1
9
9
IRIX

0
1
0
0
1
IRIX

Best
Sec

Average
Sec

Std.
Dev.

3.2
3.1
4.0
4.6
4.4
4.3

3.8
3.7
4.1
5.0
5.4
4.7

0.63
0.49
0.08
0.45
0.94
0.23

6 Conclusions
We believe that quantitatively studying the effects of NUMA for a range of
applications will provide valuable input into the debate on whether and how to extend
the OpenMP paradigm to account for NUMA. This work is a first step in that
direction. Undertaking NUMA studies requires some means to selectively bind
threads or processes to specific hardware resources and to allocate memory at specific
physical memory locations. One way to do this on the SGI Origin system has been
discussed. Using the SGI we have developed benchmarks that can be used to
accurately measure the differential memory latencies and the effects of bandwidth
contentions. In both cases we have shown that the difference between good and bad
memory/thread placement on the SGI Origin can be quite large (a factor of 2 or
more). Moreover, our results have been obtained on a relatively small system with
just 64 processors and three NUMA levels, going to a larger machine would be
expected to significantly enhance these differences. The importance of these effects
for a model application has been discussed. These results also show that simply
relying on the O/S to perform wise thread and memory placement does not
necessarily produce good results. Work is now in progress to extend these
investigations to involve larger number of threads, more complicated algorithms and
other NUMA architectures.

Acknowledgements. The authors are grateful to Martin Nichols and the SGI staff at
the University of Queensland for their assistance in this work. The support of the
Australian Partnership in Advanced Computing is gratefully acknowledged.

656

N. Robertson and A. Rendell

References
1.
2.

3.
4.

5.

6.

7.

8.

9.
10.
11.
12.
13.

See http://www.openmp.org
A. Basumallik, S-J. Min and R. Eigenmann, Towards OpenMP Execution on Software
Distributed Shared Memory Systems, pp 457–468, Int. Workshop on OpenMP:
Experiences and Implementations (WOMPEI2002), Lecture Notes in Computer Science
#2327, Springer Verlag, May 2002.
Omni OpeMP and SCASH. http://www.pccluster.org
D.S. Nikolopoulos, T.S. Papatheodorou, C.D. Polychronopoulos, J. Labarta and E.
Ayguadé, Is Data Distribution Necessary in OpenMP, Proc. Supercomputing, Dallas, TX
2000, IEEE Press.
J. Bircsak, P. Craig, R. Crowell, Z. Cvetanovic, J. Harris, C.A. Nelson and C.D. Offner,
Extending OpenMP for NUMA Machines, Proc. Supercomputing, Dallas TX 2000, IEEE
Press.
D.S. Nikolopoulos, T.S. Papatheodorou, C.D. Polychronopoulos, J. Labarta and E.
Ayguadé, A Case for User-Level Dynamic Page Migration, Proc. of the 14th ACM Int.
Conf. on Supercomputing, pp 119–130. Santa Fe, NM, May 2000.
See Chapter 8: Tuning for Parallel Processing, Origin 2000 and Onyx2 Performance
Tuning and Optimization Guide (document 007 3430 003), available at
http://techpubs.sgi.com
Tru64 UNIX NUMA Overview, Part Number AA-NUMAG-DE, available at
http://www.tru64unix.compaq.com/docs/base_doc/DOCUMENTATION/V51_HTML/NU
MA/numa.pdf
See http://www.sgi.com/origin/3000/
J.R. Mashey, NUMAflex Modular Design Approach – A revolution in Evolution,
http://www.cwi.nl/~robertl/mash/numaflex, posted in Aug. 2000 on comp.arc.news
See Appendix C, Useful Scripts and Code, Origin 2000 and Onyx2 Performance Tuning
and Optimization Guide (document 007 3430 003), available at http://techpubs.sgi.com
L. McVoy, LMBench – Tools for Performance Analysis,
http://www.bitmover.com/lmbench
J.D. McCalpin, STREAM: Sustainable Memory Bandwidth in High Performance
Computers, http://www.cs.virginia.edu/stream

