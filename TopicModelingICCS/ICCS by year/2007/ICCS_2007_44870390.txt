Eﬃcient and Reliable Execution of Legacy
Codes Exposed as Services
Bartosz Bali´s1 , Marian Bubak1,2 , Kamil Sterna1 , and Adam Bemben1
1
2

Institute of Computer Science, AGH, al. Mickiewicza 30, 30-059 Krak´
ow, Poland
Academic Computer Centre – CYFRONET, Nawojki 11, 30-950 Krak´
ow, Poland
{bubak,balis}@agh.edu.pl
Phone: (+48 12) 617 39 64; Fax: (+48 12) 633 80 54

Abstract. In this paper, we propose a framework that enables fault tolerance and dynamic load balancing for legacy codes running as backends
of services. The framework architecture is divided into two layers. The
upper layer contains the service interfaces and additional management
services, while the legacy backends run in the lower layer. The management layer can record the invocation history or save state of a legacy
worker job that runs in the lower layer. Based on this, computing can be
migrated to one of a pool of legacy worker jobs. Fault-tolerance in the
upper layer is also handled by means of active replication. We argue that
the combination of these two methods provides a comprehensive support
for eﬃcient and reliable execution of legacy codes. After presenting the
architecture and basic scenarios for fault tolerance and load balancing,
we conclude with performance evaluation of our framework.
Keywords: Legacy code, fault tolerance, load balancing, migration.

1

Introduction

Recently developed systems for conducting e-Science experiments evolve into
Service-Oriented Architectures (SOA) that support a model of computation
based on composition of services into workﬂows [4]. Legacy codes nevertheless,
instead of being rewritten or reengineered, are often adapted to new architectures
through exposing them as services or components, and remain the computational
core of the application. Static and dynamic load balancing (LB) as well as fault
tolerance (FT) are highly desired features of a modern execution environment,
necessary to sustain the quality of service, high reliability and eﬃciency. The
workﬂow model, in which the application logic is separated from the application itself, is for this very fact well-suited for LB and FT support, because the
execution progress of a workﬂow is handled by generic services, the enactment
engines. However, the presence of legacy jobs running in the backends of services
complicates this support, as the legacy jobs are often not directly modeled in the
workﬂow and thus not handled by the same generic enactment engines. While
the subjects of FT and LB of parallel and distributed systems [2] are very well
recognized for web services [10] [6] or components [8], similar problems for legacy
codes running in service backends are still not well addressed.
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 390–397, 2007.
c Springer-Verlag Berlin Heidelberg 2007

Eﬃcient and Reliable Execution of Legacy Codes Exposed as Services

391

This paper presents a solution to support FT and LB for legacy codes exposed as services. We propose a generic framework which enables seamless and
transparent checkpointing, migration, and dynamic load balancing of legacy jobs
running as backends of services. The proposed framework is based on our previous work, a system for virtualization of legacy codes as grid services, LGF
(Legacy to Grid Framework) [1] [11]. Unlike our previous work which focused
solely on exposing of legacy codes as services, this paper focuses on the aspects
of reliable and eﬃcient execution of legacy systems. We propose an architecture
for the framework and justify our design choices. We present a prototype implementation of the framework and perform a feasibility study in order to verify
whether our solution fulﬁlls functional (FT and LB scenarios) and non-functional
(performance overhead evaluation) requirements.
The remainder of this paper is as follows. Section 2 presents related work.
Sections 3 and 4 describe the architecture and operation of our FT-LB framework, respectively. We conclude the paper in Section 5 which studies the impact
of FT and LB mechanisms on the overall application performance.

2

State of the Art

Most existing approaches to adapting legacy codes to modern environments focus
on command-line applications and follow a simple adapter pattern in which a web
service or a component (e.g. CORBA [5]) wrapper is automatically generated
for a legacy command line application, based on a speciﬁcation of its input
parameters [9]. Those approaches diﬀer in terms of addressing other aspects
of legacy system’s adaptation such as security [7], automatic deployment or
integration with a framework for workﬂow composition. In some cases even some
brokering mechanisms are taken into account [3].
Of the available tools, relatively most comprehensive solution is presented
by a tool CAWOM [12], wherein one can actually specify the format of legacy
system’s responses (using a formal language) which allows for more complex
interactions with a legacy system, including synchronous and asynchronous calls.
Overall the mentioned tools, whether they oﬀer simple wrapping, or more
advanced frameworks with brokering, automatic deployment and workﬂow composition capabilities, neither take into account nor are designed to support fault
tolerance and dynamic load balancing of legacy systems.
Our framework is designed to ﬁll this gap. The separation into two layers, and
operation of legacy jobs in a client instead of server fashion, solves many issues
and enables ﬂexible solutions of LB and FT problems. We describe those in the
following sections of this paper.

3

LB-FT Framework Architecture

The architecture of our framework, presented in Fig. 1, is comprised of three main
components, namely: Service Client, Service Manager which exposes interfaces,
and Backend System on which the legacy code is actually executed.

392

B. Bali´s et al.

Service Client

create resource
Service Manager

invoke
Resource
Resource

Factory
Internal
Interface

Information
Service

forward
request

External
Interface

Resource
Manager

discover

fetch request

Backend System
submit
register

Worker Job

Fig. 1. Architecture of FT & LB Framework for Legacy Code

The heart of the system is a Service Manager which exposes the legacy code
as a service (External Interface) to be invoked by a Service Client. The central
concept that enables transparent migration of computation, being a prerequisite
for FT and LB, is decoupling of service interface layer from actual legacy code,
the latter being deployed as a job (Worker Job), on a (usually remote) machine
(Backend System). An important design detail is that the legacy Worker Job
acts as a client to the Service Manager and fetches Service Client requests from
Internal Interface in the Service Manager. An alternative option would be to
use notiﬁcations. However, in such a case Worker Jobs would have to act as
servers which would make their deployment and migration much more diﬃcult.
The remaining component in the Service Manager is a Resource Manager whose
main responsibility is to submit Worker Jobs to Backend Systems. In addition, we
support stateful conversation with legacy software through WSRF-like services.
To this end, a client can create a Resource using a Factory service. In this way,
the framework enables stateful, session-based interaction with legacy services.
In the architecture, an external Information System is presented to which
Backend Systems register while the Resource Manager acts as a resource broker
deciding which Backend System to submit a new legacy Worker Job to, based on
a list of available Backend Systems and corresponding monitoring information
(such as current load). Alternatively, the Information Service could be replaced
by an external Resource Broker to which all resource brokerage decisions would
be delegated by the Resource Manager.
Thanks to decoupling of service interfaces and legacy back ends, multiple
legacy worker jobs can be connected to a single service as a resource pool. The
computation can be easily migrated from one back end to another in case of
performance drop (load balancing) or failure (fault tolerance). The framework
supports both history-based and checkpoint-based migration of stateful jobs. For

Eﬃcient and Reliable Execution of Legacy Codes Exposed as Services

393

the former case, the Service Manager records the invocation history of a given
client and in case of migration to another worker job, the invocations can be
repeated. The latter case is supported by allowing a legacy job to periodically
send its state snapshot to the Service Manager; in the event of migration, the
new worker job can restore the last state. The architecture enables both lowlevel and high-level checkpointing to create state snapshots, though the current
implementation supports only the high-level one in which the worker jobs have
to provide an implementation of code to create and restore snapshots.
In our framework, the service interface layer is thin and performs no processing, merely forwarding requests plus other management functions related to migration, state restoration, etc. However, this layer is also subject to failure, e.g.
due to software aging of the underlying application containers. Consequently,
we also take into account the fault-tolerance of this layer using the technique of
active replication. Multiple Service Managers can be assigned to a single interaction between a client and a legacy back end. The client submits all requests
to all Service Managers. Similarly, the backend worker job fetches requests from
all Service Managers. In consequence, requests are received by the worker job
multiple times, however, they are executed only once.

4

Fault Tolerance and Load Balancing Scenarios

Fault tolerance and load balancing scenarios for the backend side diﬀer only in
the way the migration is initiated. Both scenarios are shown in Fig. 2 (a) and
(b) respectively.

(a)

(b)

Fig. 2. Scenarios involving migration: (a) fault tolerance, (b) load balancing

The resource manager fetches a client request (not shown) and assigns a proper
worker (assign client). The worker periodically signals the availability (heartbeat), retrieves the client request (fetch request) and stores checkpoints (store
state). A migration is triggered either by a worker crash (fault tolerance) or
a persistant node overload (load balancing). In the latter case, the worker is

394

B. Bali´s et al.

explicitly destroyed (destroy). In either case, the Service Manager assigns another worker (assign client), which restores the latest state (restore state) and
the operation is carried on as it was.
For fault tolerance and software rejuvenation purposes, we employ the active
replication mechanism at the upper layer. It is based on multiplying every operation on two (or more) service managers. An appropriate scheme is depicted in
Fig. 3. The client calls two service managers at once (1,2). Similarly, the backend
worker job fetches requests from both service managers (3, 5), however, only one
request is actually executed (4). The result is returned to both service managers
(6,7) and they forward it back to the client (8, 9). When one of service manager
crashes (10), the operation is carried on with one service manager only (11-13).

Fig. 3. Sequence of system operations for active replication model

5

Performance Evaluation

This section presents an evaluation of the impact of the framework on the overall
application’s performance. The framework prototype was developed in Java and
it generates WSRF services based on Globus Toolkit 4. The following tests were
conducted: (1) the impact of the interposition management layer on latency and
throughput of a service as compared to direct invocation, (2) the latency of
migration in a fault tolerance and load balancing scenario, and (3) the cost of
active replication in terms of application’s completion time.
For the evaluation, we used a simple algorithm computing a requested number
in the Fibonacci sequence, exposed as a service. In total, four IA-32 machines
with 1 GB RAM and 1.2 GHz CPU, running Linux Debian, Java 1.4 and Globus
3.2.1 were used.
Fig. 4 (a) shows the overhead of the interposition layer. We compared the
performance of two functionally equivalent web services. One of them used
a legacy library while the other was standalone. Both web services exposed a single method that calculated the length of a byte array passed as a parameter.
Latency and bandwidth of both services were obtained based on the formula:
time(length) = length/bandwith + latency

(1)

Eﬃcient and Reliable Execution of Legacy Codes Exposed as Services

395

Using least squares linear regression ﬁtting, we have obtained ﬁgures for both
services. As a result, we observed that while latency was increased 2.4 times,
bandwidth was reduced only by 12%.
In the fault tolerance scenario, the Service Manager loses connection with one
of the workers (at the moment of starting the service on a backend system).
After the timeout, the backend system is considered to have undergone abnormal termination. Process migration is initiated, and the method invocations are
delegated to another node. The result is shown in Fig. 4 (b).

(a)

(b)

Fig. 4. (a) Interposition layer overhead (b) Migration overhead

We used history-based fault tolerance whose cost can be estimated at approximately 1-2 seconds. An additional cost is also connected with the number of
lost heartbeats before a node is considered to be undergoing a failure.
The load balancing scenario is diﬀerent only in terms of the cause which
triggers the migration, which in this case is a node overload over a certain number
of heartbeats. The Service Manager decides to migrate the resources to a node
exposing better performance. The overhead proved to be quite similar and is not
shown here separately.
Finally, we study the active replication scenario. The framework runs with
two service managers present, running in separate containers and performing
identical actions. One Service Manager crashes. The platform continues normal
work; however the invocations are handled by one service manager only.
The overhead in this scenario is caused by additional processing: on the client
side which performs more invocations and has to ﬁlter out redundant results,
and the backend side where redundant requests have to be discarded and the
results has to be returned to more than one Service Manager. Fig. 5 shows
the processing time from a worker perspective, for a single, and for two service
managers. The times for those two cases are practically the same which proves
that the additional processing time – indeed, only limited to more invocations
and discarding redundant operations – does not induce substantial overhead.

396

B. Bali´s et al.

Fig. 5. Active replication overhead

At the same time we observe undisturbed operation of the system despite the
crash of one Service Manager.

6

Conclusion

We have presented a framework for enabling fault tolerance and dynamic load
balancing for legacy codes running in the backend of web services, typically as
parts of e-Science workﬂows. We proposed a two layer architecture in which
a management layer containing service interfaces is decoupled from a computational core which is deployed in separate worker jobs.
We use diﬀerent, complementing strategies for FT & LB in the two system
layers. In the backend layer, we use an eﬃcient method based on a pool of worker
jobs of a certain type among which the computing can be switched when there
is a need to do so. Recovering state from snapshots or repeating of invocation
history can be used in the case of migration of stateful services. In the front-end
layer, we use the active replication of service interfaces. Though this method
is expensive, it does not require further management such as state snapshots
or heartbeat monitoring. Our investigation revealed that thanks to the very
architecture of our framework in which the service layer is thin and contains
no processing, the inherent overhead of active replication is compensated and is
perfectly aﬀordable.
Overall, the performed feasibility study shows the framework fulﬁlls the functional and performance requirements and constitutes a comprehensive solution
for reliable and eﬃcient running of workﬂows that contain legacy code in the
computational back ends, which is important for development of e-Science applications.
The future work encompasses, most importantly, the expansion of our system
into data-centric workﬂows involving streaming between legacy jobs, and support
for load balancing and fault tolerance scenarios for complex legacy systems, such
as parallel MPI applications. Other aspects include integration with a security
infrastructure.

Eﬃcient and Reliable Execution of Legacy Codes Exposed as Services

397

Acknowledgements. This work is partly supported by EU-IST Project CoreGrid
IST-2002-004265, and EU-IST Project Virolab IST-027446.

References
1. Balis, B., Bubak, M., Wegiel, M.: A Solution for Adapting Legacy Code as Web
Services. In Proc. Workshop on Component Models and Systems for Grid Applications. 18th Annual ACM International Conference on Supercomputing, Saint-Malo,
France, Kluwer (July 2004)
2. Cao, J., Spooner, D. P., Jarvis, S. A., Nudd, G. R.: Grid Load Balancing Using Intelligent Agents. Future Generation Computer Systems special issue on Intelligent
Grid Environments: Principles and Applications, 21(1) (2005) 135-149
3. Delaittre, T., Kiss, T., Goyeneche, A., Terstyanszky, G., Winter, S., Kacsuk, P.:
GEMLCA: Running Legacy Code Applications as Grid Services. Journal of Grid
Computing Vol. 3. No. 1-2. Springer Science + Business Media B.V. (June 2005)
75-90
4. E-Science 2006, Homepage: http://www.escience-meeting.org/eScience2006/
5. Gannod, G. C., Mudiam, S. V., Lindquist, T. E.: An Architecture Based Approach
for Synthesizing and Integrating Adapters for Legacy Software. Proc. 7th Working
Conference on Reverse Engineering. IEEE (November 2000) 128-137
6. Hwang, S., Kesselman, C.: A Flexible Framework for Fault Tolerance in the Grid.
Journal of Grid Computing 1(3)(2003) 251-272
7. Kandaswamy, G., Fang, L., Huang, Y., Shirasuna, S., Marru, S., Gannon, D.: Building Web Services for Scientiﬁc Grid Applications. IBM Journal of Research and
Development, Vol. 50. No. 2/3 (March/May 2006) 249-260, .
8. Moser, L., Melliar-Smith, P., Narasimhan, P.: A Fault Tolerance Framework for
CORBA. International Symposium on Fault Tolerant Computing (Madison, WI)
(June 1999) 150-157
9. Pierce, M., Fox, G.: Making Scientiﬁc Applications as Web Services. Web Computing (January/Februray 2004)
10. Tartanoglu, F., Issarny, V., Romanovsky, A., Levy, N.: Dependability in the Web
Services Architecture. Architecting Dependable Systems. LNCS 2677 (June 2003)
11. Wegiel, M., Bubak, M., Balis, B.: Fine-Grain Interoperability with Legacy Libraries
Virtualized as Web Services. Proc. Grid-Enabling Legacy Applications and Supporting End Users Workshop within the framework 15th IEEE HPDC 15, Paris,
France ( June 2006)
12. Wohlstadter, E., Jackson, S., Devanbu, P.: Generating Wrappers for Command
Line Programs: The cal-aggie wrap-o-matic Project. Proc. 23rd International Conference on Software Engineering (ICSE 2001). ACM (2001) 243-252

