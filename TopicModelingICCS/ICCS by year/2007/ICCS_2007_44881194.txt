Processing the Mixed Properties of Light Verb
Constructions
Jong-Bok Kim1 and Kyung-Sup Lim2
1
2

School of English, Kyung Hee University, Seoul, Korea 130-701
Dept. of English and Tourism, Dongsin University, 520-714, Korea

Abstract. One of the most widely used constructions in Korean is the
so-called light verb construction (LVC) involving an active-denoting verbal noun (VN) together with the light verb ha-ta ‘do’. This paper ﬁrst
discusses the argument composition of the LVC, mixed properties of
VNs which have provided a challenge to syntactic analyses with a strict
version of X-bar theory. The paper shows the mechanism of multiple
classiﬁcation of category types with systematic inheritance can provide
an eﬀective way of capturing these mixed properties. An implementation
of the analysis within the LKB (Linguistics Knowledge Building) system
proves its feasibility and eﬃciency.

1

Issues

The ﬁrst main theoretical and computational issue we encounter in the analysis
of the LVC is the status of the light verb and argument composition. One of
the main properties the light verb ha ‘do’ carries is that it does not aﬀect the
argument structure of the VN (verbal noun) it combines with.1
(1) a.

b.

John-i
Mary-eykey cenhwa(-lul hayessta)
John-NOM Mary-DAT phone-ACC did
‘John phoned Mary.’
John-i
Mary-lul myengtan-ey chwuka(-lul hayessta)
John-NOM Mary-ACC list-LOC
addition-ACC did
‘John added Mary to the list.’

As observed here, it is the type of VN that decides the types of arguments in
the given sentence. This has led the literature to view that the light verb has
no argument structure on its own and inherits the argument structure of the
theta-transparent VN.
The second main issue concerns the grammatical status of VNs. It is wellobserved that in terms of the internal properties, VNs behave like verbs, whereas
1

The abbreviations for the glosses and attributes used in this paper are acc (accusative), arg (argument), c-cont (constructional content), dat (dative), decl (declarative), lbl (label), loc (locative), ltop (local top),
nom (nominative), pl (plural), pre (predicate), pst (past), ind (index),
rels (relations), top (topic), etc.

Y. Shi et al. (Eds.): ICCS 2007, Part II, LNCS 4488, pp. 1194–1201, 2007.
c Springer-Verlag Berlin Heidelberg 2007

Processing the Mixed Properties of Light Verb Constructions

1195

in terms of external syntax, they act like nouns. For example, as observed in (1),
VNs select their own arguments and assign verbal cases such as ACC, regardless
of the light verb’s presence. Adverbial modiﬁcation also supports the verbal
properties of VNs: the VN can be modiﬁed by an adverb but not by an adjectival
element.
(2)

catongcha-ul mikwuk-ey
elyepkey/*elyewun swuchwul(-ul hayessta)
car-ACC
America-LOC hard/diﬃcult
export-ACC did
‘(They) exported cars to America with diﬃculty.’

Another main issue in the LVC comes from syntactic variations. It is wellobserved that the VN in the true LVC has frozen eﬀects: it does not undergo
relativization, scrambling, clefting, and topicalization. The VN further cannot
be wh-questioned or pronominlizaed:
(3) a.

b.
c.
d.
e.
f.

John-i
Bill-eykey tocaki-lul senmwul-ul hayssta
John-NOM Bill-DAT china-ACC present-ACC did
‘John gave a china to Bill as a present.’
*John-i Bill-eykey tocaki-lul han senmwul (relativization)
*John-i senmwul-ul Bill-eykey tocaki-lul hayssta. (scrambling)
*John-i Bill-eykey han kes-un senmwul-i-ta (clefting)
*John-i Bill-eykey ku kes-ul hayssni? (pronominalization)
*John-i Bill-eykey mwues-ul hayssni? (wh-question)

Intriguing facts emerge when the VN does not appear with the accusative object. In such cases, the frozen eﬀects disappear: all these syntactic processes
are possible.
(4) a.

b.
c.
d.
e.
f.

John-i
Bill-eykey senmwul-ul hayssta
John-NOM Bill-DAT present-ACC did
‘John gave a present to Bill.’
John-i Bill-eykey han senmwul (relativization)
John-i senmwul-ul Bill-eykey hayssta. (scrambling)
John-i Bill-eykey han kes-un senmwul-i-ta (clefting)
John-i Bill-eykey ku kes-ul hayssni? (pronominalization)
John-i Bill-eykey mwues-ul hayssni? (question)

There have been various attempts to account for these aforementioned properties of LVC constructions. In what follows, we lay out a constraint-based analysis adopting the mechanism of multiple inheritance hierarchies that enables us
to capture the mixed properties as well as other related ones in a much more
streamlined manner.

2
2.1

A Typed Feature Structure Grammar: KPSG
Mixed Properties Within a Multiple Inheritance System

Our grammar KPSG (Korean Phrase Structure Grammar), based on the framework of HPSG (head-driven phrase structure grammar), aims at building a

1196

J.-B. Kim and K.-S. Lim

computationally feasible Korean grammar with a comprehensive coverage. In
the grammar, all the linguistic expressions are types of sign which in turn has
lex-sign (lexical sign) and syn-sign (syntactic sign) as its subtypes. Following
traditional wisdom, the KPSG takes the basic lexical categories of the grammar
(lex-sign) to include verbal, nominal, adverbial, and adnominal as its subtypes
which again are subclassiﬁed according to their properties. The following is a
simpliﬁed hierarchy, representing the relevant part:2
(5)

lex-sign
ff
ffffff
verbal
nominal
ff  
Õ   
ffffff
 
Õ
v-stem
n-lxm
 Õ
ee
eeeee
eeeeee
Õ eee
v-tns-stem
v-free
vn
cn
ff Õ
Õ
ffffff
v-ind

v-dep

v-ger

The key point of capturing the mixed properties of VNs lies in the crossclassiﬁcation and multiple inheritance mechanism.3 As noticed in the hierarchy, the type vn is declared to be the subtype of both verbal and n-lxm, implying
that it will inherit all the constraints of these supertypes. The type verbal is declared to have the value [V +] with a non-empty ARG-ST value, whereas n-lxm
has the value [POS noun]. The inheritance mechanism will then ensure that the
type vn has at least the information in (6)a. This lexical information will then be
enriched as in (6)b when each lexical intance inherits all the relevant constraints
from its supertypes.4

¾

(6)

vn
PHON kongpwu ‘study’

¾

vn

¾

POS noun
SYN | HEAD N +
a.
V+
ARG-ST [ ],...
SEM ...

¿
¿

¾

POS noun
SYN HEAD V +
N+

b. ARG-ST NPi , NPj
¾
INDEX s1
SEM

2

3

4

¾

¿
¿¿

¿

¾
¿
¶ PRED study-rel ·

RELS

ARG0 s1
ARG1 i
ARG2 j

The dot line here means the existence of other types between the two types. The
type glosses mean v-ind(ependent), v-dep(endent), v-ger(undive).
The type v-ger is gerundive verbs like ilk-ess-um ‘read-PST-NMLZ’ which also display mixed properties. See [1].
The semantics we represent here is a simpliﬁed version of a ﬂat semantic formalism
MRS (minimal recursion semantics). See [2] and [3] for details.

Processing the Mixed Properties of Light Verb Constructions

1197

As observed here, the system clearly represents why VNs are in part nominal
([N +]) and are in part verbal ([V +]) though in terms of POS, they are more
like nouns. In addition, by referring to a proper feature value, the grammar can
be ﬂexible enough to capture other related properties. For example, the KPSG
allows an adverb to modify a [V +] element. This would then predict the adverb
modiﬁcation in the LVC we discussed in (2). In addition, since the type vn as
a subtype of n-stem bears [N +] and [POS noun], we naturally predict that
the VNs will act like other nominal elements: the VNs can have case markings
attached to them, have the GEN grammatical case, and can serve as the head
of a relative clause construction like the other [POS noun] elements.
2.2

Argument Composition and the Syntax of the LVC

The argument composition properties between the VN and the following light
verb lead us to take the light verb as a kind of auxiliary verb as given in (7):5
(7)

¾

¿

PHON ha-ta ‘do’
SYN | HEAD | POS verb

¶

LEX +
ARG-ST [INDEX i],
XARG i

·

According to this lexical information, just like an auxiliary verb, the light verb
is syntactically transitive, selecting a subject argument and a VN expression
(lexical or phrasal). The VN forms a well-formed phrase with the light verb in
accordance with the following grammar rule:6
(8)

¾

Head-Lex Rule:
hd-lex-ex
COMPS

A

→

1

LEX +
COMPS

¿

AUX +

A

,H

COMPS

1

The Head-Lex Rule speciﬁes that the auxiliary head combines with a [LEX +]
complement7 , and that to the resulting combination the COMPS value of this
lexical complement is passed up. This kind of argument composition is diﬀerent
from the previous analyses ([5], [6]). mainly in that the composition happens in
syntax rather than in the lexicon. Since the external argument of the light verb
is identical with the ﬁrst argument, it in turn means the subject of the LVC is
determined by the VN.
To check the feasibility of our grammar equipped with the Head-Lex Rule and
other X grammar rules, we implemented this grammar in the LKB (Linguistic
5

6

7

The semantic attribute XARG identiﬁes the semantic index of a phrase’s external
argument, usually the subject of a verb phrase.
This rule generates complex predicate constructions like auxiliary constructions in
Korean. See [4].
The feature LEX is assigned to non-phrasal expressions such as words and complex
predicates.

1198

J.-B. Kim and K.-S. Lim

Knowledge Building System) (cf. [7]). The LKB system is a grammar and lexicon
development environment for use with constraint-based linguistic formalisms
such as HPSG.8 The following is the parsed tree and semantic representation of
sentences like (3a).

Fig. 1. Parsed Tree and MRS for (3a)

The tree structure in the small box indicates that the light verb hayssta ‘did’
here combines with its VN complement senmwul ‘present’, forming a well-formed
hd-lex-ex. This resulting combination also inherits the COMPS value of the VN
in accordance with the Head-Lex Rule in (8). This will then combines with
the argument tocaki ‘china’ whose resulting VP again combines with the dative
argument Bill-eykey.
The bigger box represents the semantics of the sentence in the MRS (Minimal Recursion Semantics), developed by [3]. The MRS is a framework of computational semantics designed to enable semantic composition using only the
uniﬁcation of type feature structures. (See [3] and [2]) We can observe that the
parsed MRS provides enriched information of the sentence. The value of LTOP
is the local top handle, the handle of the relation with the widest scope within
the sentence. The INDEX value here is identiﬁed with the ARG0 value of the
prpstn m rel (propositional message). The attribute RELS is basically a bag of
elementary predications (EP) each of whose value is a relation.9 Each of the
types relation has at least three features LBL, PRED (represented here as a
8
9

The LKB is freely available with open source (http://lingo.stanford.edu).
The attribute HCONS is to represent quantiﬁcational information. See [2].

Processing the Mixed Properties of Light Verb Constructions

1199

type), and ARG0. We can notice that the MRS correctly represents the propositional meaning such that John did the action of giving a china as a present
to Bill.
2.3

Common Noun Usages

VNs can also be used as common nouns when they take no ACC arguments. For
example, the VN-like nouns in (9) are diﬀerent from the argument-taking VNs
even though they combine with the light verb.10
(9) a.

John-i
kongpwu-ul hayessta
John-NOM study-ACC did
‘John studied.’
John-i
Bill-eykey senmwul-ul hayssta
John-NOM Bill-DAT present-ACC did
‘John did an introduction to Bill.’

b.

Unlike the true VNs with the feature [N +, V +], these VNs are common nouns
with the feature [N +, V −]. As noted in (4), they also can be modiﬁed by
an adjectival element and they do not have frozen eﬀects as VNs. In addition,
even though they do not select an ACC argument, they still keep the dative
argument Bill-eykey. To capture these relationships, our grammar posits the
following lexical rule:
(10)

¾

VN-to-CN Lexical Rule:
vn-tr
ARG-ST

1,

] ⊕

[

cn-vn
HEAD | V −
ARG-ST 1 ⊕

→

A

¿
A

This lexical rule turns any transitive VNs selecting two or more arguments into
CNs (cn-vn) with no change in the meaning. However, the output has no verbal
properties any more as indicated from the [V –] value. The following illustrates
an example of this lexical process:
(11)

¾

vn-tr
PHON senmwul

¾

¾

POS noun
SYN HEAD V +
N+

¿

¾

cn-vn
PHON senmwul

¿¿

ARG-ST NPi , NPj , NPk

¾

→

¾

POS noun
SYN HEAD V −
N+

¿

¿¿

ARG-ST NPi , NPk

As noted, the cn-vn is losing the [V +] property and becomes a canonical common
noun. One thing to note here is that even though the output is a common noun,
it still has the identical LEX and semantic value. This output will then allow us
to generate a structure like the following:
10

All the VNs are selecting a subject and an argument which are realized as NOM
and ACC.

1200

J.-B. Kim and K.-S. Lim

Fig. 2. Parsed Tree and MRS for (4a)

As given in the parsed tree, the light verb hayessta combines with senmwul-ul
‘present’, forming a hd-lex-ex since the former has the LEX feature. The resulting
expression also inherits the COMPS value of senmwul-ul, the DAT argument
Bill-eykey. This is a complement sentence with no argument missing in which
senmwul-ul is a canonical NP that can undergo various syntactic processes as
given in (4). We also can observe that the grammar correctly provides a correct
MRS meaning representation.

3

An Implementation and Its Results

In testing the performance and feasibility of the grammar, we ﬁrst built up our
test sets from (1) the SERI Test Suites ’97, (2) the Sejong Project Basic Corpus,
and (3) self-constructed examples adopted from the literature. The SERI Test
Suites ([8], designed to evaluate the performance of Korean syntactic parsers,
consists of total 472 sentences (292 test sentences representing the core phenomena of the language and 180 sentences representing diﬀerent types of predicate).
Meanwhile, the Sejong Corpus have about 2,061,977 word instances with 179,
082 sentences. Of these, we found total 95,570 instances of the combination of a
noun (tagged as NNG) with the light verb ha-ta.11 Some of the nouns with the
higher frequency are given here:

5111
1730
11

/NNG+ /XSV ‘speak’
/NNG+ /XSV ‘begin’

3021
897

/NNG+ /XSV ‘think’
/NNG+ /XS ‘need’

The Sejong Corpus thus does not distinguish general nouns from verbal nouns.

Processing the Mixed Properties of Light Verb Constructions

834
543

/XR+ /XSA ‘important’ 619
/NNG+ /XSV ‘claim’
528

/NNG+
/NNG+

1201

/XSV ‘use’
/XSV ‘begin’

Based on the frequency list, we ﬁrst extracted the most frequently used 100 VNs,
and from these VNs we selected 100 simple sentences (one from each VN type)
that could show us at least the basic patterns of the LVC.
The following shows the results of parsing our test suits:
Corpus Types
SERI Test Suite
Self-designed Test Suite
Ss from the Sejong Corpus
Total LVC Ss

# of S # of Parsed S # of LVC Ss Parsed LVC Ss
472
443 (93.7%) 12
12 (100 %)
350
330 (94.2%) 100
94 (94 %)
179, 082
100
87 (87 %)
212
190 (89%)

As the table shows, our system correctly parsed about 93 percent of the total 472
Seri Test Suite sentences which include those sentences that theoretical literature
have often discussed. The system also parsed about 94% of the self-designed test
sentences most of which are also collected from the major literature on the LVC.
As for the Sejong corpus, the system parsed about 87% of the simple sentences
from the Sejong corpus. Though there is need for extending this current grammar
to the wider range of authentic corpus data that display more complex properties
of the langauge, the parsing results indicate that the current grammatical system
is feasible enough to capture the mixed properties and gives us the possibility of
deep processing for such phenomena.

References
1. Kim, J.B., Yang, J.: Projections from morphology to syntax in the korean resource
grammar: implementing typed feature structures. In: Lecture Notes in Computer
Science. Volume 2945. Springer-Verlag (2004) 13-24
2. Bender, E.M., Flickinger, D.P., Oepen, S.: The grammar matrix: An open-source
starter-kit for the rapid development of cross-linguistically consistent broadcoverage
precision grammars. In Carroll, J., Oostdijk, N., Sutcliﬀe, R., eds.: Proceedings of
the Workshop on Grammar Engineering and Evaluation at the 19th International
Conference on Computational Linguistics, Taipei, Taiwan (2002) 8-14
3. Copestake, A., Flickenger, D., Sag, I., Pollard, C.: Minimal recursion semantics: An
introduction. Manuscript (2003)
4. Kim, J.B.: Korean Phrase Structure Grammar. Hankwuk Publishing, Seoul (2004)
In Korean.
5. Bratt, E.: Argument composition and the lexicon: Lexical and periphrastic
causatives in Korean. PhD thesis, Stanford University (1996)
6. Kim, J.B.: The Grammar of Negation: A Constraint-Based Perspective. CSLI Publications, Stanford (2002)
7. Copestake, A.: Implementing Typed Feature Structure Grammars. CSLI Publications, Stanford (2002)
8. Sung, W.K., Jang, M.G.: Seri test suites 95. In: Proceedings of the Conference on
Hanguel and Korean Language Information Processing. (1997)

