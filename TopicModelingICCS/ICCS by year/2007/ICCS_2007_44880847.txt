Automatic Memory Access Analysis with
Periscope
Michael Gerndt and Edmond Kereku
Technische Universit¨
at M¨
unchen
Fakult¨
at f¨
ur Informatik I10, Boltzmannstr. 3, 85748 Garching
gerndt@in.tum.de

Abstract. Periscope is a distributed automatic online performance
analysis system for large scale parallel systems. It consists of a set of
analysis agents distributed on the parallel machine. This article presents
the support in Periscope for analyzing ineﬃciencies in the memory access
behavior of the applications. It applies data structure speciﬁc analysis
and is able to identify performance bottlenecks due to remote memory
access on the Altix 4700 ccNUMA supercomputer.
Keywords: Performance analysis, supercomputers, program tuning, memory accesses analysis.

1

Introduction

Performance analysis tools help users in writing eﬃcient codes for current high
performance machines. Since the architectures of today’s supercomputers with
thousands of processors expose multiple hierarchical levels to the programmer,
program optimization cannot be performed without experimentation.
To tune applications, the user has to carefully balance the number of MPI
processes vs the number of threads in a hybrid programming style, he has to
distribute the data appropriately among the memories of the processors, has to
optimize remote data accesses via message aggregation, prefetching, and asynchronous communication, and, ﬁnally, has to tune the performance of a single
processor.
Performance analysis tools can provide the user with measurements of the
the program’s performance and thus can help him in ﬁnding the right transformations for performance improvement. Since measuring performance data and
storing those data for further analysis in most tools is not a very scalable approach, most tools are limited to experiments on a small number of processors.
To investigate the performance of large experiments, performance analysis has
to be done online in a distributed fashion, eliminating the need to transport
huge amounts of performance data through the parallel machine’s network and
to store those data in ﬁles for further analysis.
Periscope [5] is such a distributed online performance analysis tool. It consists of a set of autonomous agents that search for performance bottlenecks in a
Y. Shi et al. (Eds.): ICCS 2007, Part II, LNCS 4488, pp. 847–854, 2007.
c Springer-Verlag Berlin Heidelberg 2007

848

M. Gerndt and E. Kereku

subset of the application’s processes and threads. The agents request measurements of the monitoring system, retrieve the data, and use the data to identify
performance bottlenecks. The types of bottlenecks searched are formally deﬁned
in the APART Speciﬁcation Language (ASL) [1,2].
The focus of this paper is on Periscope’s support for analyzing the memory
access behavior of programs. Periscope searches not only for bottlenecks related
to MPI and OpenMP, but also for ineﬃciencies in the memory accesses. Novel
features are the support for identifying data structure-related bottlenecks and
remote memory accesses bottlenecks in ccNUMA systems.
The next section presents work related to the automatic performance analysis
approach in Periscope. Section 3 presents Periscope’s architecture and its special
features for memory access analysis. Section 5 presents several case studies.
Section 6 gives a short summary.

2

Related Work

Several projects in the performance tools community are concerned with the automation of the performance analysis process. Paradyn’s [9] Performance Consultant automatically searches for performance bottlenecks in a running application
by using a dynamic instrumentation approach. Based on hypotheses about potential performance problems, measurement probes are inserted into the running
program. Recently MRNet [10] has been developed for the eﬃcient collection of
distributed performance data.
The Expert [12] tool developed at Forschungszentrum J¨
ulich performs an
automated post-mortem search for patterns of ineﬃcient program execution in
event traces. Potential problems with this approach are large data sets and long
analysis times for long-running applications that hinder the application of this
approach on larger parallel machines.
Aksum [3], developed at the University of Vienna, is based on a source code
instrumentation to capture proﬁle-based performance data which is stored in a
relational database. The data is then analyzed by a tool implemented in Java
that performs an automatic search for performance problems based on JavaPSL,
a Java version of ASL.

3

Architecture

Periscope consists of a graphical user interface based on Eclipse, a hierarchy of
analysis agents and two separate monitoring systems (Figure 1).
The graphical user interface allows the user to start up the analysis process
and to inspect the results. The agent hierarchy performs the actual analysis. The
node agents autonomously search for performance problems which have been
speciﬁed with ASL. Typically, a node agent is started on each SMP node of the
target machine. This node agent is responsible for the processes and threads on
that node. Detected performance problems are reported to the master agent that
communicates with the performance cockpit.

Automatic Memory Access Analysis with Periscope

849

Fig. 1. Periscope currently consists of a GUI based on Eclipse, a hierarchy of analysis
agents, and two separate monitoring systems

The node agents access a performance monitoring system for obtaining the
performance data required for the analysis. Periscope currently supports two
diﬀerent monitors, the Peridot monitor [4] developed in the Peridot project focusing on OpenMP and MPI performance data, and the EP-Cache monitor [8]
developed in the EP-Cache project focusing on memory hierarchy information.
The node agents perform a sequence of experiments. Each experiment lasts for
a program phase, which is deﬁned by the programmer, or for a predeﬁned amount
of execution time. Before a new experiment starts, an agent determines a new set
of hypothetical performance problems based on the predeﬁned ASL properties
and the already found problems. It then requests the necessary performance data
for proving the hypotheses and starts the experiment. After the experiment,
the hypotheses are evaluated based on the performance data obtained from the
monitor.

4

Monitoring Memory Accesses

The analysis of the application’s memory access behavior is based on the EPCache monitor. It allows to access the hardware counters of the machine for
evaluating properties such as the example for L1-cache misses in Figure 2.
The example demonstrates the speciﬁcation of performance properties with
ASL. The performance property shown here identiﬁes a region with high L1cache miss rate. The data model, speciﬁed in ASL too, contains a class SeqPerf
which contains a reference to a program region, a reference to a process, and a
number of cache-related and other metrics. The instance of SeqPerf available in
the property is called the property’s context. It deﬁnes the program region, e.g.,
a function, and the process for which the property is tested.
A novel feature of the EP-Cache monitor is its data structure support. The
node agent can request measurements for speciﬁc data structures via the

850

M. Gerndt and E. Kereku
PROPERTY LC1ReadMissesOverMemRef(SeqPerf s){
CONDITION:
s.lc1_data_read_miss/s.read_access > 0.01;
CONFIDENCE:
1;
SEVERITY:
s.lc1_data_read_miss/s.read_access; }
Fig. 2. This performance property identiﬁes signiﬁcant L1-cache miss rate

Measurement Request Interface (MRI) [6]. The node agent speciﬁes a request
via the MRI Request function. Its parameters determine, for example, that L1cache misses are to be measured for array ACOORD in a speciﬁc parallel loop
in subroutine FOO. The request would be generated for a new experiment after
the property LC1MissRate was proven in the previous experiment.
To enable the node agent to specify such detailed requests, it requires static
information about the program, e.g., it has to know that array ACOORD is
accessed in that loop. This program information is generated by the source-tosource instrumenter developed for Periscope. It generates the information in an
XML-based format called the Standard Intermediate Program Representation
(SIR) [11]. This information is read by the agents when the analysis is started.
At runtime the MRI request for measuring cache misses for a data structure is
translated based on the debug information in the executable into the associated
range of virtual addresses. The measurement is certainly only possible, if the
hardware counters of the target processor do support such restricted counting.
Our main target architecture is the Altix 4700, which was installed at the Leibniz
Computing Centre in Munich. It consists of 4096 Itanium 2 processors which have
a very extensive set of hardware counters. On Itanium 2, such measurements
can be restricted to speciﬁc address ranges and thus can be executed without
program intrusion.
Another feature of the Itanium 2’s hardware counters exploited by Periscope is
its support for counting memory accesses that last more than a given number of
clock cycles. One of these events is DATA EAR CACHE LAT8 for example. This
event returns the number of memory operations with a memory access latency
of more than eight cycles. Similar events return the number of operations with a
memory access latency greater than LAT4, LAT16, ... up to LAT4096 increasing
by powers of 2.
The counters can be used to identify those memory references that go to local
memory on the ALTIX 4700 processor or to remote memory. Since the ALTIX is
a ccNUMA system, all the processors can access all the memory, but, for eﬃcieny
reasons, most of the accesses should be to the processors local memory. Thus it is
very important to identify non-local access behavior. Edmond Kereku speciﬁed
appropriate ASL performance properties for such situation in his dissertation [7].
Based on elementary properties such as the LC1Miss-Property and similar properties for individual data structures and for remote memory accesses,

Automatic Memory Access Analysis with Periscope

851

higher-level properties can be deduced. For example, the Property UnbalancedDMissRateInThreads shown in Figure 3 gives information on the behavior across
multiple threads.
PROPERTY TEMPLATE UnbalancedDMissRateInThreads
<float MissRateParFunc(MRIParPerf, int)>
(MRIParPef mpp){
LET
const float threshold;
float mean = mean_func_t(MissRateParFunc, mpp);
float max = max_func_t(MissRateParFunc, mpp);
float min = min_func_t(MissRateParFunc, mpp);
float dev_to_max = max - mean;
float dev_to_min = mean - min;
float max_exec_time=MAX(mpp.parT[tid] WHERE tid IN mpp.nThreads);
IN
CONDITION : MAX(dev_to_max, dev_to_min) / mean > threshold;
CONFIDENCE : 1;
SEVERITY
: MAX(dev_to_max, dev_to_min) / mean * max_exec_time;
}
PROPERTY UnbalancedDMissRateInThreads<LC1DReadMissRateParFunc>
UnbalancedLC1DReadMissRatePar;
PROPERTY UnbalancedDMissRateInThreads<LC2DReadMissRateParFunc>
UnbalancedLC2DReadMissRatePar;
PROPERTY UnbalancedDMissRateInThreads<LC3DReadMissRateParFunc>
UnbalancedLC3DReadMissRatePar;
Fig. 3. Performance properties with a similar speciﬁcation can be expressed via property templates. This template speciﬁed an unbalanced miss rate across threads in a
parallel OpenMP program.

The template UnbalancedDMissRateInThreads is used to create multiple
properties for the diﬀerent cache levels. The property template is parameterized
by a function which is replaced in the speciﬁcations of the individual properties
with a function returning the appropriate miss rate, i.e., for the L1 cache, L2,
and L3 respectively.

5

Application Experiments

We used Periscope to analyze applications on the Itanium SMP nodes of the
Inﬁniband Cluster at LRR/TUM. Table 1 shows the list of properties which we
searched for during our experiments, the threshold set in the condition of the
properties, and the number of regions on which the property holds for each of the

852

M. Gerndt and E. Kereku

Table 1. The list of properties searched on the test applications running on the Inﬁniband Cluster
Property
Threshold LU FT SWIM PGAUSS
LC2DMissRate
5% 0 14
0
5
LC2DReadMissRate
5% 0 3
0
5
LC3DMissRate
2% 13 3
7
0
LC3DReadMissRate
2% 1 3
2
0

test applications. We did not count the data structures, only the code regions.
The properties hold for a region if the cache miss rate is higher than 5% for LC2
and higher than 2% for LC3. Looking at the table, we can conclude that FT
and PGAUSS have more L2 cache problems, while LU and SWIM have more L3
cache problems.
We present here the results of Periscope’s automatic search for the LU decomposition application in the form of search paths. The paths start from the
region where the search began and go down to the deepest subregion or data
structure for which the property holds. We omit the severities associated with
each evaluated property. Instead, we provide the measured miss rate for each
of the search path’s regions and data structures. The search path which generated the property with the highest severity is marked italic. Please note that
in some of the tests, the region with the highest miss rate does not necessarily have the property with the highest severity. The severity is also dependant
on the region’s execution time, which for presentation reasons is not shown
here.
The results of the automatic search for LU
Region
Application Phase( USER REGION, ssor.f, 109 )
( PARALLEL REGION, ssor.f, 120 )
( WORKSHARE DO, ssor.f, 126 )
rsd( DATA STRUCTURE, ssor.f, 4 )
Application Phase( USER REGION, ssor.f, 109 )
( PARALLEL REGION, ssor.f, 120 )
( LOOP REGION, ssor.f, 149 )
jacld( CALL REGION, ssor.f, 156 )
jacld( SUB REGION, jacld.f, 5 )
( WORKSHARE DO, jacld.f, 39 )
u( DATA STRUCTURE, jacld.f, 5)
Application Phase( USER REGION, ssor.f, 109 )
( PARALLEL REGION, ssor.f, 120 )
( LOOP REGION, ssor.f, 149 )
blts( CALL REGION, ssor.f, 165 )
blts( SUB REGION, blts.f, 4 )

LC3 miss
rate
0.038
0.029
0.029

0.038
0.037
0.030
0.030
0.040

0.038
0.037
0.052

LC3 read
miss rate

0.029

Automatic Memory Access Analysis with Periscope
( WORKSHARE DO, blts.f, 75 )
v( DATA STRUCTURE, blts.f, 4 )

Application Phase( USER REGION, ssor.f, 109 )
( PARALLEL REGION, ssor.f, 120 )
( LOOP REGION, ssor.f, 184 )
buts( CALL REGION, ssor.f, 200 )
buts( SUB REGION, buts.f, 4 )
( WORKSHARE DO, buts.f, 75 )
v( DATA STRUCTURE, buts.f, 4 )
Application Phase( USER REGION, ssor.f, 109 )
( PARALLEL REGION, ssor.f, 120 )
( WORKSHARE DO, ssor.f, 221 )
u( DATA STRUCTURE, ssor.f, 4 )
rsd( DATA STRUCTURE, ssor.f, 4 )

853

0.055
0.025

0.038
0.038
0.051
0.054
0.025
0.038
0.039
0.031
0.062

0.031
0.062

The search for L2 cache problems did not detect any problem, but as the
results show, LU has L3 cache problems. In addition to L3DMissRate, our
search reﬁned to the property L3DReadMissRate too. As the search paths show,
LC3DReadMissRate does not hold on the majority of the regions where
LC3MissRate was proven. This means that most of the L3 cache problems in
LU are write-related problems.
The search path that discovered the most severe problem reﬁned from the
application phase to subroutine buts. The data structure v is the source of the
problem. The most important data structures of LU are u and rsd. In fact, the
variable v is the local name for rsd which is passed to subroutine buts as a
parameter.

6

Summary

This paper presented the automatic memory access analysis support in Periscope.
Periscope’s analysis is automatically running several experiments during a single program execution to incrementally search for performance bottlenecks. If no
repetitive program phases are marked by the user, the application can even be
automatically restarted to perform additional experiments.
Periscope uses this approach to search for data structure-related memory access bottlenecks as well as for remote memory access bottlenecks in ccNUMA
architectures. Due to the limitation in the number of performance counters of
current processors, multiple experiments are required to evaluate all the performance hypotheses for critical program regions.
The overall overhead of the analysis depends on the frequency measurements
are taken. In our tests, the regions to be analyzed where outer loops or parallel regions which have signiﬁcant runtime so that accesses to the performance
counters did not have signiﬁcant overhead.

854

M. Gerndt and E. Kereku

The strategies applied in reﬁning for more detailed performance bottlenecks
can be found in [7] and will be published elsewhere.
Acknowledgments. This work is funded by the Deutsche Forschungsgemeinschaft under Contract No. GE 1635/1-1.

References
1. T. Fahringer, M. Gerndt, G. Riley, and J. Tr¨
aﬀ. Knowledge speciﬁcation for automatic performance analysis. APART Technical Report, www.fz-juelich.de/apart,
2001.
2. T. Fahringer, M. Gerndt, G. Riley, and J.L. Tr¨
aﬀ. Speciﬁcation of performance problems in MPI-programs with ASL. International Conference on Parallel
Processing (ICPP’00), pp. 51 - 58, 2000.
3. T. Fahringer and C. Seragiotto. Aksum: A performance analysis tool for parallel
and distributed applications. Performance Analysis and Grid Computing, Eds. V.
Getov, M. Gerndt, A. Hoisie, A. Malony, B. Miller, Kluwer Academic Publisher,
ISBN 1-4020-7693-2, pp. 189-210, 2003.
4. K. F¨
urlinger and M. Gerndt. Peridot: Towards automated runtime detection of performance bottlenecks. High Performance Computing in Science and Engineering,
Garching 2004, pp. 193-202, Springer, 2005.
5. M. Gerndt, K. F¨
urlinger, and E. Kereku. Advanced techniques for performance
analysis. Parallel Computing: Current&Future Issues of High-End Computing (Proceedings of the International Conference ParCo 2005), Eds: G.R. Joubert, W.E.
Nagel, F.J. Peters, O. Plata, P. Tirado, E. Zapata, NIC Series Volume 33 ISBN
3-00-017352-8, pp. 15-26a, 2006.
6. M. Gerndt and E. Kereku. Monitoring Request Interface version 1.0. TUM Technical Report, 2003.
7. E. Kereku. Automatic Performance Analysis for Memory Hierarchies and Threaded
Applications on SMP Systems. PhD thesis, Technische Universit¨
at M¨
unchen, 2006.
8. E. Kereku and M. Gerndt. The EP-Cache automatic monitoring system. International Conference on Parallel and Distributed Systems (PDCS 2005), 2005.
9. B.P. Miller, M.D. Callaghan, J.M. Cargille, J.K. Hollingsworth, R.B. Irvin, K.L.
Karavanic, K. Kunchithapadam, and T. Newhall. The Paradyn parallel performance measurement tool. IEEE Computer, Vol. 28, No. 11, pp. 37-46, 1995.
10. Ph. C. Roth, D. C. Arnold, and B. P. Miller. MRNet: A software-based multicast/reduction network for scalable tools. SC2003, Phoenix, November, 2003.
11. C. Seragiotto, H. Truong, T. Fahringer, B. Mohr, M. Gerndt, and T. Li. Standardized Intermediate Representation for Fortran, Java, C and C++ programs.
APART Working Group Technical Report, Institute for Software Science, University of Vienna, Octorber, 2004.
12. F. Wolf and B. Mohr. Automatic performance analysis of hybrid MPI/OpenMP
applications. 11th Euromicro Conference on Parallel, Distributed and NetworkBased Processing, pp. 13 - 22, 2003.

