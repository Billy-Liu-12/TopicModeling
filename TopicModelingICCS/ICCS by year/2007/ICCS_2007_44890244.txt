A Dataﬂow-Oriented Atomicity and Provenance
System for Pipelined Scientiﬁc Workﬂows
Liqiang Wang1 , Shiyong Lu2 , Xubo Fei2 , and Jeﬀrey Ram3
1

2

Dept. of Computer Science, University of Wyoming, USA
wang@cs.uwyo.edu
Dept. of Computer Science, Wayne State University, USA
{shiyong, xubo}@wayne.edu
3
Dept. of Physiology, Wayne State University, USA
jeffram@med.wayne.edu

Abstract. Scientiﬁc workﬂows have gained great momentum in recent
years due to their critical roles in e-Science and cyberinfrastructure applications. However, some tasks of a scientiﬁc workﬂow might fail during
execution. A domain scientist might require a region of a scientiﬁc workﬂow to be “atomic”. Data provenance, which determines the source data
that are used to produce a data item, is also essential to scientiﬁc workﬂows. In this paper, we propose: (i) an architecture for scientiﬁc workﬂow
management systems that supports both provenance and atomicity; (ii)
a dataﬂow-oriented atomicity model that supports the notions of commit
and abort; and (iii) a dataﬂow-oriented provenance model that, in addition to supporting existing provenance graphs and queries, also supports
queries related to atomicity and failure.

1

Introduction

Scientiﬁc workﬂow systems are increasingly used to execute scientiﬁc data management and analysis in many disciplines, such as biology, medicine, chemistry,
physics, and astronomy. In contrast to traditional business workﬂows, which are
task-centric and control-ﬂow oriented, scientiﬁc workﬂows are data-centric and
dataﬂow oriented. More speciﬁcally, in a business workﬂow model, the design of
a workﬂow focuses on how execution control ﬂows from one task to another (sequential, parallel, conditional, loop, or event-condition-action triggers), forming
various “control-ﬂows”. In a scientiﬁc workﬂow model, the design of a workﬂow focuses on how the input data are streamlined into various data analysis
steps using data channels to produce various intermediate data and ﬁnal data
products, forming various “dataﬂows”.
Atomicity is an important transactional property, which requires that a transaction either runs in completion or has no partial eﬀect (all-or-nothing). In scientiﬁc workﬂows, some task might fail during execution due to either the failure
of the task itself or inappropriate input to a task. Despite the failure of tasks, a
The ﬁrst two authors contributed equally to this paper.
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 244–252, 2007.
c Springer-Verlag Berlin Heidelberg 2007

A Dataﬂow-Oriented Atomicity and Provenance System

245

domain scientist might require a region of a scientiﬁc workﬂow to be “atomic”
in the sense that either the execution of all the tasks in that region run to completion or none of them has any eﬀect at all. However, traditional techniques
for atomicity in transaction processing systems are inappropriate for complex
long-running processes in distributed and heterogeneous environments. Compensation is generally considered as a proper way to handle rollback in business
workﬂows [6], as it can eliminate eﬀects of already committed transactions. The
atomicity techniques based on compensation in business workﬂows [8,5] are not
suitable for scientiﬁc workﬂows. They often require the explicit deﬁnitions of
transaction boundaries which are obscured in our case due to the data dependency introduced by pipelined execution of workﬂows. Moreover, since scientiﬁc
workﬂows are often computation-intensive, traditional rollback techniques are
ineﬃcient because the intermediate results of aborted transactions, which might
be reusable in the future, are discarded.
Data provenance is closely related to the data lineage problem [3] studied
in the database community, which determines the source data that are used to
produce a data item. However, in scientiﬁc workﬂows, datasets are not necessarily contained in a relational or XML database and data processing cannot
necessarily be accomplished by a database query. Therefore, existing approaches
to the data lineage problem are not suﬃcient for solving the data provenance
problem in scientiﬁc workﬂows. Moreover, although several provenance models
(such as [2]) have been proposed for scientiﬁc workﬂows, none of them supports
the notion of atomicity.
This paper proposes a novel dataﬂow-oriented atomicity and provenance system for scientiﬁc workﬂows. To the best of our knowledge, our system is the
ﬁrst one that supports both atomicity and provenance. It captures dataﬂows in
scientiﬁc workﬂows, where data communications between tasks are modeled as
enqueue and dequeue operations of a recoverable queue [1]. Transaction boundaries are not necessarily deﬁned, instead, data dependencies are tracked and
logged. Our system consists of two subsystems: atomicity management subsystem, which performs commit and abort, and provenance subsystem, which infers
data dependencies and processes queries. The former is contained in the workﬂow
engine; the latter can be outside. Although our system is based on the Kepler
scientiﬁc workﬂow management system [9], our approach is general and can be
extended to other systems.

2
2.1

Background
The Kepler Scientiﬁc Workﬂow Management System

The Kepler system [9] is an open source application to provide generic solutions to scientiﬁc workﬂows. In Kepler, a workﬂow consists of a set of “nodes”
(called actors), which represent components or tasks, and a set of “edges” (called
dataﬂow connections), which connect actors. Actors have input ports and output
ports that provide the communication interfaces to other actors. Actors communicate by passing data tokens (called token for short) between their ports.

246

L. Wang et al.

Each token is unique in the whole workﬂow. A unique feature of Kepler is that
the overall execution and component interactions are coordinated by a separate component called director instead of implicitly deﬁned in actors. Kepler
provides a variety of directors that implement diﬀerent computation models. In
the process network model, each actor is an independent process or thread, and
each dataﬂow connection is an asynchronous and unidirectional channel with
unbounded buﬀers. Such scientiﬁc workﬂows execute in a pipelined fashion; our
atomicity and provenance System is based on such a pipelined workﬂow model.
2.2

A Scientiﬁc Workﬂow in Biology

We implemented a scientiﬁc workﬂow in Kepler for a biological simulation project
which analyzes the response of male worms to pheromone. The movement of a
male worm is aﬀected by chemical stimuli produced by female worms. Fig. 1
shows the workﬂow in Kepler. The actors SampleFactory, EnvironmentFactory,
and ModelFactory provide parameters for simulations of male worms, environment, and their interactions, respectively. The actor Simulation repeatedly
calculates the movement of worms over a time interval and the dispersion of
the chemical. The actor ImageDisplay is used to show the result. The actor
StatisticalAnalysis analyzes the simulations.

Fig. 1. A biological simulation scientiﬁc workﬂow in Kepler

3

The Atomicity Management Subsystem

We ﬁrst deﬁne a formal model for scientiﬁc workﬂows adapted from the Kepler
system [9] introduced in Section 2.1.
This paper makes some assumptions about the scientiﬁc workﬂows that we analyze. First, each actor is “white”, i.e., data dependencies between input tokens
and output tokens are observable. Second, message-send-response relationships
between actors and services are known. Third, each retriable Web service is modeled as a local actor (this is how it is done by Kepler), which calls the remote
Web service on behalf of the user. Thus, the execution of all tasks are performed
in a local machine except the execution of Web or Grid Services.
A workﬂow W = A, E consists of a set A of actors, and a set E of dataﬂow
connections. Each actor a ∈ A has a set of associated data ports, each of which

A Dataﬂow-Oriented Atomicity and Provenance System

247

is either an input or output port. A dataﬂow connection bridges a set of output
ports with a set of input ports.
3.1

Round and Data Dependency

In our atomicity model, a workﬂow execution invokes a series of actors to run.
Each actor maintains a state which stores intermediate results computed from
previous input tokens. A state indicates some data dependencies between the
output tokens and the input tokens.
For example, Fig. 2 shows how the actors in Fig. 1 consume and produce
tokens, and the data dependencies between tokens (which is shown in Fig. 2(d)).
In Fig. 2(a), actor SF (i.e., SampleFactory) consumes tokens f1 (number of
males) and f2 (parameters for males), then produces token s1 (a sample of
males). When SF calls reset(), its state is ﬂushed. Then SF consumes tokens
f3 (number of females) and f4 (parameters for females), and produces token
s2 (a sample of females). Actors EnvironmentFactory and ModelFactory work
similarly, which are not shown. In Fig. 2(b), actor S (i.e., Simulation) consumes
s1, s2, e1 (a set of environment parameters) and m1 (interaction model), saves
s1 and s2 into its state, then produces a1 (a result). Next, S consumes e2 then
produces a2. Before the next simulation starts, reset() is called to ﬂush the
state. In Fig. 2(c), actor A (i.e., StatisticalAnalysis) produces an analysis
result for each simulation. In the meanwhile, it saves the intermediate results in
its state and ﬁnally performs a full analysis based on its state. This procedure
continues after reset() is called.
q1 ... s2 s1
... f4 f3 f2 f1

SF

... s2 s1

q2 ... e2 e1
... m1
q3

(a)

S

... a2 a1
q4

...a100...a3 a2 a1
q4

A

...r’ r100...r3 r2 r1
q5

(c)

(b)
f1

s1

a1

r1

f2

s2

a2

r2

f3

e1

a3

r3

f4

e2
m1

...

...

a100

r100
r’

(d)

Fig. 2. Actors and data dependencies between tokens

A round on an actor is the whole events that happen between two consecutive
(i.e., no other reset events in the middle) reset events. Each round has a unique
identiﬁer in the workﬂow. Thus, an invocation of a workﬂow contains a series
of actor invocations; each invocation of an actor contains one or more rounds.
Round is decided by each actor itself. When an actor calls reset(), it tells the

248

L. Wang et al.

workﬂow engine that the current round has completed. The call of reset() is
a non-blocking operation. A reset event terminates the current round of data
dependencies, and starts a new round of data dependencies. For each output
token in a round, we assume that the actor can tell what input tokens that it
depends on. Note that these dependent tokens might be some of the input tokens
read so far (not the whole), as shown in Fig. 2(b), a2 does not depend on e1.
For a round a.r on an actor a, let input(a.r) and output(a.r) denote its input
and output tokens, respectively.
For two tokens t1 and t2 , if t2 is computed from t1 , we call t2 depends on
t1 , denoted t1 → t2 . For two rounds a.r and a .r , if ∃t.(t ∈ output(a.r) ∧ t ∈
input(a .r )∧a = a ), i.e., a .r consumes the tokens produced by a.r, we call a .r
depends on a.r, denoted a.r ⇒ a .r . Data dependencies are transitive: for token
dependencies, if t1 → t2 and t2 → t3 , then t1 → t3 ; for round dependencies,
if a.r ⇒ a .r , a .r ⇒ a .r , and a = a , then a.r ⇒ a .r . Note that we do
not allow cyclic transitive data dependencies on rounds. It is assumed that the
workﬂows do not contain cyclic dataﬂows.
Let depd-ancestors(a.r) = {a .r |a .r ⇒ a.r} (i.e., all rounds that a round a.r
depends on) and depd-descendents(a.r) = {a .r |a.r ⇒ a .r } (i.e., all rounds that
depend on a round a.r). They can be easily computed from the log introduced
in Section 4.
3.2

Commit and Abort

Formally, we deﬁne the atomicity of a round as follows: the execution of a round
a.r is atomic if either it and all the rounds that depend on a.r run to completion
or none of them has any eﬀect. Thus, users do not need to explicitly deﬁne transaction boundaries as in business workﬂows and database systems. Atomicities
in the whole workﬂow are ensured automatically by our atomicity management
subsystem. Although the atomicity granularity is based on one “round” of execution of a task in this paper, the technique can be readily extended for various
granularities.
For two rounds a.r and a .r , and a.r ⇒ a .r , if a .r consumes only some early
output tokens of a.r, a .r might ﬁnish by calling reset() even when a.r is still
running. Thus, “reset” does not mean “commit” of the round, because we have
to rollback both a.r and a .r if a.r fails. A round a.r commits if a.r has been reset
and every round in depd-ancestors(a.r) has committed. If depd-ancestors(a.r) is
empty, a.r commits once it is reset. Intuitively, a reset event indicates the ending
of the current round and the starting of the next round, and a commit event
makes the results of the round be observable to the users. The left column of Fig.
3 shows how the atomicity management subsystem commits a round a.r. When
a round a.r calls reset(), the atomicity management subsystem writes a reset
event in a log, then repeatedly checks the log to see whether all rounds that a.r
depends on have committed. If the commit condition is satisﬁed, it commits a.r
by writing a commit event in the log.
In our system, each dataﬂow connection is modeled and implemented as an
extended recoverable queue adapted from [1]. An extended recoverable queue

A Dataﬂow-Oriented Atomicity and Provenance System
Commit algorithm for a round a.r
while (a.r has not been reset) continue;
while (true)
boolean toCommit = true;
for all a .r ∈ depd-ancestors(a.r)
if (a .r has not committed)
toCommit = false;
if (toCommit)
commit(a.r);
return;

249

Abort algorithm for a round a.r
if (a.r has already committed)
print(“cannot abort.”);
return;
Stop the execution of a.r if running;
while (true)
boolean toAbort = true;
for all a .r ∈ depd-descendents(a.r)
if (a .r has not aborted)
toAbort = false;
if (toAbort)
for all t ∈ output(a.r)
getRecoveryQueue(t).¬enq(t);
for all t ∈ input(a.r)
getRecoveryQueue(t).¬deq(t);
abort(a.r);
return;

Fig. 3. Commit algorithm and abort algorithm for a round a.r

is a reliable and fault-tolerant queue which supports the following operations:
enqueue pushes a token at the head; dequeue removes a token from the end
and returns the token; ¬enq undoes the operation of enqueue, i.e., deletes an
enqueued token; ¬deq undoes the operation of dequeue, i.e., recovers a token
that has been dequeued. After a round commits, its associated enqueue and
dequeue operations cannot be undone.
When the atomicity management subsystem detects crashing of a round a.r,
it will send failure messages to all actors that execute rounds in depd-descendents
(a.r) to abort the corresponding rounds, which are not necessarily the on-going
rounds. A round a.r aborts if all rounds in depd-descendents(a.r) have aborted.
The abort of a round will delete all output tokens, then recover all input tokens.
Note that the “failure” event occurs only on the actor where a.r runs, and
“abort” events occur on each actor in depd-descendents(a.r) and a.r itself. The
right column of Fig. 3 shows how the atomicity management subsystem aborts
a round a.r. The atomicity management subsystem ﬁrst checks whether a.r has
already committed, if not, tells the actor to stop the execution of a.r if it is still
running. Then, repeatedly check the log to see whether all rounds that depend
on a.r have aborted. During the abortion, the atomicity management subsystem
looks up the log to ﬁnd the corresponding recoverable queue for a given token t
(i.e., by calling getRecoveryQueue(t)); then it commands the recoverable queue
to undo the previous operations. Finally, it writes an abort event in the log.
One optimization for the abort algorithm is: if both a.r and a .r are going
to abort and a.r ⇒ a .r , during aborting a .r , we do not need to recover the
tokens that are the output of a.r and input of a .r because they will be deleted
again during aborting a.r.

4

The Event Log

Our atomicity & provenance system records the following events for supporting
atomicity: enqueue (enq) a token; the counter-operation of enq, i.e., ¬enq; de-

250

L. Wang et al.

queue (deq) a token; the counter-operation of deq, i.e., ¬deq; reset (rst) a state;
failure of an actor; commit (cmt) a round; and abort (abt) a round. These events
are stored in a sequential event log. Each row in an event log contains: event
identifer; time stamp; workﬂow identiﬁer; round identiﬁer (which contains actor
identiﬁer); queue identifer, if the event is an enq, deq, ¬enq, or ¬deq operation;
event type, which is one of event types listed above; token identiﬁer, if the event
is related with a token (such as enqueue or dequeue); and dependent tokens,
which denote all source tokens used for producing the current token, if the event
produces a token.
evt
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15

tm
-

wf
-

rnd
S.r
S.r
S.r
S.r
S.r
A.r
S.r
A.r
A.r
S.r
S.r
S.r
S.r
S.r
S.r

que
q1
q1
q2
q3
q4
q4
q4
q4
q3
q2
q1
q1
-

type
deq
deq
deq
deq
enq
deq
f ail
¬deq
abt
¬enq
¬deq
¬deq
¬deq
¬deq
abt

tok
depdToks
s1
s2
e1
m1
a1 {s1 , s2 , e1 , m1 }
a1
a1
a1
m1
e1
s2
s1
-

evt
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17

tm
...
-

wf
...
-

rnd
S.r
S.r
S.r
S.r
S.r
A.r
A.r
S.r
S.r
S.r
A.r
S.r
A.r
...
A.r
A.r
A.r

que
q1
q1
q2
q3
q4
q4
q5
q2
q4
q4
q5
...
q5
-

type
deq
deq
deq
deq
enq
deq
enq
deq
enq
rst
deq
cmt
enq
...
enq
rst
cmt

tok
depdToks
s1
s2
e1
m1
a1 {s1 , s2 , e1 , m1 }
a1
r1
{a1 }
e2
a2 {s1 , s2 , e2 , m1 }
a2
r2
{a2 }
...
...
r
{a1 , ..., a100 }
-

Fig. 4. A log for an execution of the workﬂow in Fig. 2

Fig. 4 shows a part of the log ﬁle for a run of the workﬂow in Fig. 2. The left
column shows an aborted workﬂow run. Round S.r ﬁrst dequeues s1 , s2 , e1 , and
m1 from queues q1 , q1 , q2 , and q3 , respectively. S.r then enqueues a1 (which is
produced by S based on s1 , s2 , e1 , and m1 ) into q4 . After round A.r dequeues
a1 from q4 , S.r crashes. Thus, we ﬁrst abort A.r by recovering a1 , then abort
S.r by deleting a1 and recovering m1 , e1 , s2 , and s1 . The right column shows a
successful run, where A.r does not commit until S.r commits.

5

The Provenance Subsystem

Based on the event log, we can build token dependency graph, object dependency
graph, round dependency graph as in [2], and token usage graph, which are represented as directed acyclic graphs (DAG). The event log produced by our system
contains all information of the event log in [2]. Therefore, our system can support all provenance queries listed in [2]. In addition, our system can support
the atomicity and failure related queries, which are illustrated in the following
examples.
– What actors ever aborted rounds?
q1 := {a|e ∈ log(τ ) ∧ type(e) = abort ∧ actor(e) = a},

A Dataﬂow-Oriented Atomicity and Provenance System

251

where the expression e ∈ log(τ ) selects an event from the log τ , the expression type(e) = abort checks that the event is an abort, and the expression
actor(e) = a obtains the actor that executes the event.
– When a round a.r runs, what actors simultaneously execute the
rounds that depend on a.r?
q2 (a.r) := {a .r |e ∈ log(τ ) ∧ a .r ∈ depd-descendents(a.r) ∧ round(e) =
a .r ∧ time(e) < reset-time(a.r)}, where reset-time(a.r) denotes the time
when a.r is reset, which is easily obtained based on the log.

6

Related Work

In recent years, scientiﬁc workﬂows have gained great momentum due to their
roles in e-Science and cyberinfrastructure applications. There are a plethora of
scientiﬁc workﬂows covering a wide range of scientiﬁc disciplines. A survey of
various approaches for building and executing workﬂows on the Grid has been
presented by Yu and Buyyaby [12].
Bowers et al. [2] propose the Read-Write-State-Reset (RWS) provenance
model for pipelined scientiﬁc workﬂows within the Kepler framework [9]. The
RWS model assumes that each output token depends on all tokens input so far
in the current round, whereas our model reﬁnes this by assuming actors can tell
what input tokens each output token depends on.
Although several provenance models [7,11,2,4,10] have been proposed for scientiﬁc workﬂows, there has been no work on the provenance system that supports
the notion of atomicity.
Finally, although atomicity is a well studied topic in the context of databases
in transaction processing and business workﬂows, there has been no work on
atomicity in the context of “dataﬂows” and “pipelined execution” in scientiﬁc
workﬂows. The read committed assumption that existing atomicity techniques
are based on does not hold in pipelined scientiﬁc workﬂows, where both task
parallelism and pipelined parallelism are present.

7

Conclusions and Future Work

We have proposed an architecture for scientiﬁc workﬂow management systems
that supports both provenance and atomicity. We have shown that, while our
atomicity system can support the notion of atomicity, currently at the round
level that does not contain cyclic transitive data dependencies, our provenance
system has added value to existing provenance systems as we support atomicity
and failure related queries.
In the future, we will extend current atomicity and provenance models to
various granularities of atomicity and for diﬀerent models of computations. We
will also investigate the atomicity problem for multilevel, distributed, parallel,
and heterogeneous scientiﬁc workﬂows.

252

L. Wang et al.

References
1. P. A. Bernstein, M. Hsu, and B. Mann. Implementing recoverable requests using
queues. In Proc. of the 1990 ACM SIGMOD international conference on Management of data, pages 112–122. ACM Press, 1990.
2. S. Bowers, T. McPhillips, B. Ludascher, S. Cohen, and S. B. Davidson. A model
for user-oriented data provenance in pipelined scientiﬁc workﬂows. In Proc. of the
International Provenance and Annotation Workshop (IPAW’06), Chicago, Illinois,
USA, May 2006.
3. P. Buneman, S. Khanna, and W.-C. Tan. Why and where: A characterization
of data provenance. Proc. of the International Conference on Database Theory
(ICDT), 1973:316–330, 2001.
4. S. Cohen, S. C. Boulakia, and S. B. Davidson. Towards a model of provenance and
user views in scientiﬁc workﬂows. In Data Integration in the Life Sciences, pages
264–279, 2006.
5. W. Derks, J. Dehnert, P. Grefen, and W. Jonker. Customized atomicity speciﬁcation for transactional workﬂows. In Proc. of the Third International Symposium
on Cooperative Database Systems for Advanced Applications(CODAS’01), pages
140–147. IEEE Computer Society Press, 2001.
6. H. Garcia-Molina and K. Salem. Sagas. In SIGMOD ’87: Proceedings of the 1987
ACM SIGMOD international conference on Management of data, pages 249–259.
ACM Press, 1987.
7. P. Groth, S. Miles, W. Fang, S. C. Wong, K.-P. Zauner, and L. Moreau. Recording
and using provenance in a protein compressibility experiment. In Proc. of the
14th IEEE International Symposium on High Performance Distributed Computing
(HPDC’05), Research Triangle Park, North Carolina, U.S.A., July 2005.
8. F. Leymann and D. Roller. Production workﬂow: concepts and techniques. Prentice
Hall, 2000.
9. B. Ludascher, I. Altintas, C. Berkley, D. Higgins, E. Jaeger, M. Jones, E. A. Lee,
J. Tao, and Y. Zhao. Scientiﬁc workﬂow management and the kepler system:
Research articles. Concurr. Comput. : Pract. Exper., 18(10):1039–1065, 2006.
10. S. Miles, P. Groth, M. Branco, and L. Moreau. The requirements of recording and
using provenance in e-science experiments. Journal of Grid Computing, 2006.
11. Y. L. Simmhan, B. Plale, and D. Gannon. A framework for collecting provenance
in data-centric scientiﬁc workﬂows. In Proc. of the IEEE International Conference
on Web Services (ICWS’06), pages 427–436, Washington, DC, USA, 2006.
12. J. Yu and R. Buyya. A taxonomy of scientiﬁc workﬂow systems for grid computing.
SIGMOD Record, 34(3):44–49, Sept. 2005.

