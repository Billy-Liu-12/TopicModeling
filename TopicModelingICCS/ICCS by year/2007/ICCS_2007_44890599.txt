Research on Affective Computing Model in E-Learning
System
Ruiming Zhao1, Zhenhui Ren1, Li Zhang1, and Ruiguo Qin2
1

Mechanical and Electrical College, Hebei Agriculture University, Baoding
071001, China
2
Hebei Baoding TV, Baoding 071050, China
powerzrm@yahoo.com.cn

Abstract. Emotion deficiency was a hot topic research in current E-learning
system. A lot of negative effects were analyzed and corresponding countermeasures were proposed in the paper. Basing on it, affective computing model
was set up and used in the traditional E-learning system. Affective computing
model was constructed by using audiovisual emotion, which took both facial
and audio features as input data. Rough set theory was used in audiovisual
emotion recognition. Our simulation experiment results showed that Rough set
theory was effective in emotion recognition, and a high recognition rate was
resulted.
Keywords: Affective Computing, Emotion recognition, Rough Set, Feature
Selection.

1 Introduction
With the development and widespread of network, E-learning has become one of
most important ways of educating and researching. E-learning can break through the
limit of space and time, reduce learning cost and improve learning efficiency [1].
People pay more and more attention to it.
Although the current E-learning systems have many merits, the phenomenon of
emotion deficiency in the current E-learning system is existed. How to measure
cognitive emotion of learners in the E-learning system and realize harmonious
emotion interaction becomes an important research topic in the distance education [2].
Aiming at the problem of emotion deficiency in E-learning, domestic and abroad
scholars bring forward some strategies as follows:
(1) Designing the emotional network curriculums.
(2) Implementing exploring and cooperative learning.
(3) Implementing blended learning.
(4) Improving learning supporting service system.
The application of above strategies have avoided emotion deficiency in certain
degree, but learner's emotion state cannot be tracked accurately, the corresponding
emotional encouragement and compensation also cannot be provided according to
specific emotion state, which cannot help the learner to solve emotion deficiency
fundamentally.
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 599–602, 2007.
© Springer-Verlag Berlin Heidelberg 2007

600

R. Zhao et al.

Affective computing is a hot topic in Artificial intelligence, it is computing that
related to, arise from, or deliberately influence emotion [3], which is firstly proposed
by Professor Picard at MIT in 1997.Affective computing consists of recognition,
expression, modeling, communicating and responding to emotion [4].in this
components, emotion recognition is one of the most fundamental and important
modules. It is always based on facial and audio information.
Basing on it, affective computing model was set up and used in the traditional Elearning system. Both facial expression recognition and speech emotion recognition
are used to construct affective computing model. Rough set theory was used in
audiovisual emotion recognition.

2 Affective Computing Model
The affective computing model is Fig.1. The system model is composed of several
modules as follows:

Fig. 1. Affective Computing Model

Interface module: affective computing input will be added to human machine
interface of traditional E-learning system (both facial expression recognition input
and emotion recognition of speech input), which collects learners’ emotion feedback
information primarily, thus emotion compensation is realized.
Emotion Recognition algorithm module: emotion recognition algorithm module is
composed of input, pre-processing, feature extraction, feature selection, classification
and output. Firstly, facial image and audio information of human are taken as input
data through some relevant sensors. Then, audio feature and facial feature are
extracted from input data. Furthermore, valuable features from all features are

Research on Affective Computing Model in E-Learning System

601

selected for emotion recognition. Finally, the overall emotion is recognized by using
emotion recognition algorithm based on Rough Set theory.

3 Emotion Recognition Algorithm
3.1 Audio Feature Extraction
The 37 secondary (statistical) speech features listed in table 3 are often used in speech
emotion recognition systems, and the 37 features are taken in our emotion recognition
module [5].
3.2 Facial Feature Extraction
In this paper, AAM is adopted to locate feature points. On the other hand, the MPEG4 standard is a popular standard for feature point selection. It extends FAGS to derive
Facial Definition Parameters (FDP) and Facial Animation Parameters (FAP). FAP has
been used widely in facial animation for its good performance on compression in
recent years. Besides, the FDP and low level FAP constitute a concise representation
of a face. They are adequate for basic emotion recognition because of the varieties of
expressive parameter. In FAP, 66 low level parameters are defined to describe the
motion of a human face. Among 66 parameters, 52 parameters are chosen to represent
emotion in our recognition system as shown in Fig.2, because some parameters have
not much impact on emotion. Thus, a feature point set including 52 feature points is
defined in the image sequence. Based on the feature points, feature distance can be
calculated as the features for emotion recognition.

Fig. 2. Feature points

3.3 Feature Selection
Feature selection is the key part of emotion algorithm recognition module. The
purpose of feature selection is to select valuable features for emotion recognition from

602

R. Zhao et al.

all features. In this module, features for emotion recognition are decreased. Thus, the
complexity and cost for the following classification procedure are reduced. It would
improve the efficiency of the whole system.
In our emotion algorithm recognition module, feature selection is based on the
rough set theory. The attribute reduction algorithm adopted to select features is
introduced in RSFSA, and results of experiment shows the algorithm is effective.
3.4 Classification Module
The classification techniques used in existing emotion recognition algorithm module
include template-based classification, rule-based classification, ANN-based classification,
HMM-based classification, Bayesian classification, SVM-based classification, etc.
In our emotion recognition algorithm module, classification rules created according
to rough set reduction algorithm are taken as the classifier.

4 Conclusion
In this paper, affective computing model was set up and used in the traditional Elearning system. Both facial expression recognition and speech emotion recognition
are used to construct affective computing model. Rough set theory was used in
audiovisual emotion recognition. Depending on these features, an average recognition
rate of 79.2% is achieved. In the future, based on the selected features, other effective
classification method will be used. And multi-module emotion recognition including
facial, audio, and other features such as gesture will be studied [6].

References
1. Luo Qi.: Research on Application of Association Rule Mining Algorithm in Learning
Community. Proceedings of CAAI-11, Wuhan, 2005, 1458-1462.
2. Ma Xirong.: Research on harmonious man-machine interaction model. Computer science,
2005.
3. R.W.Picard.: Affective Computing. Cambridge. MIT Press, 1997.
4. R.W.Picard.: Affective Computing, Challenges. Cambridge. International Journal of Human
Computer studies, 59(1), 2003, 55-64.
5. D.Ververidis, et al.: Automatic emotion speech classification. Proceedings of the
ICASSP2004, 2004, 593-596.
6. Q.Cai, A.Mitche and J.K.Aggarwal.:Track Human Motion in an Indoor Environment.
Proceedings of 2nd international conference Image Processing, 2003.

