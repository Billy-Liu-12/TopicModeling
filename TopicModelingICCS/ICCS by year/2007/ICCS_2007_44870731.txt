Complexity of Monte Carlo Algorithms for a Class of
Integral Equations
Ivan Dimov1,2 and Rayna Georgieva2
1

2

Centre for Advanced Computing and Emerging Technologies
School of Systems Engineering, The University of Reading
Whiteknights, PO Box 225, Reading, RG6 6AY, UK
i.t.dimov@reading.ac.uk
Institute for Parallel Processing, Bulgarian Academy of Sciences
Acad. G. Bonchev 25 A, 1113 Sofia, Bulgaria
ivdimov@bas.bg, rayna@parallel.bas.bg

Abstract. In this work we study the computational complexity of a class of grid
Monte Carlo algorithms for integral equations. The idea of the algorithms consists
in an approximation of the integral equation by a system of algebraic equations.
Then the Markov chain iterative Monte Carlo is used to solve the system. The
assumption here is that the corresponding Neumann series for the iterative matrix
does not necessarily converge or converges slowly. We use a special technique
to accelerate the convergence. An estimate of the computational complexity of
Monte Carlo algorithm using the considered approach is obtained. The estimate
of the complexity is compared with the corresponding quantity for the complexity
of the grid-free Monte Carlo algorithm. The conditions under which the class of
grid Monte Carlo algorithms is more efficient are given.

1 Introduction
Monte Carlo method (MCM) is established as a powerful numerical approach for investigation of various problems (evaluation of integrals, solving integral equations, boundary value problems) with the progress in modern computational systems. In this paper,
a special class of integral equations obtained from boundary value problems for elliptic partial differential equations is considered. Many problems in the area of environmental modeling, radiation transport, semiconductor modeling, and remote geological
sensing are described in terms of integral equations that appear as integral representation of elliptic boundary value problems. Especially, the approach presented in this
paper is of great importance for studying environmental security. There are different
Monte Carlo algorithms (MCAs) for solving integral equations. A class of grid Monte
Carlo algorithms (GMCAs) falls into the range of the present research. The question:
Which Monte Carlo algorithm is preferable to solve a given problem? is of great importance in computational mathematics. That is why the purpose of this paper is to study
Partially supported by NATO grant ”Monte Carlo Sensitivity Studies of Environmental Security” (PDD(TC)-(ESP.EAP.CLG 982641), BIS-21++ project funded by the European Commission (INCO-CT-2005-016639) as well as by the Ministry of Education and Science of
Bulgaria, under grant I-1405/2004.
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 731–738, 2007.
c Springer-Verlag Berlin Heidelberg 2007

732

I. Dimov and R. Georgieva

the conditions under which the class of algorithms under consideration solves a given
problem more efficiently with the same accuracy than other MCAs or is the only applicable. Here we compare the efficiency of grid MCAs with known grid-free Monte
Carlo algorithms (GFMCAs), called spherical process (see [5]). A measure of the efficiency of an algorithm is its complexity (computational cost), which is defined as the
mean number of operations (arithmetic and logical) necessary for computing the value
of the random variable for a transition in a Markov chain.

2 Formulation of the Problem
We consider a special class of Fredholm integral equations that normally appears as an
integral representation of some boundary-value problems for differential equations. As
an example which has many interesting applications we consider an elliptic boundary
value problem:
Mu = −φ(x), x ∈ Ω ⊂ Rd ,
(1)
u = ω(x)
x ∈ ∂Ω,
d

where M =
i=1

∂2
2
∂x(i)

+ vi (x)

∂
∂x(i)

+ w (x),

x = (x(1) , x(2) , . . . , x(d) ).

Definition 1. The domain Ω belongs to the class A(n,ν) if it is possible to associate
a hypersphere Γ (x) with each point x ∈ ∂Ω, so that the boundary ∂Ω can be presented as a function z (d) = ζ(z (1) , . . . , z (d−1) ) in the neighborhood of x for which
ζ (n) (z (1) , z (2) , . . . , z (d−1) ) ∈ C(0,ν) , i.e. |ζ (n) (z1 ) − ζ (n) (z2 )| ≤ const |z1 − z2 |ν ,
(1) (2)
(d−1)
(1) (2)
(d−1)
where the vectors z1 = (z1 , z1 , . . . , z1
) and z2 = (z2 , z2 , . . . , z2
) are
(d − 1)-dimensional vectors and ν ∈ (0, 1].
¯ ∈ A(1,ν) the coefficients of the operator M satisfy the
If in the bounded domain Ω
(0,ν) ¯
¯ ω ∈ C(∂Ω),
conditions vj , w(x) ∈ C
(Ω), w(x) ≤ 0 and φ ∈ C(0,ν) (Ω)∩C(Ω),
2
¯
the problem (1) has an unique solution u(x) ∈ C (Ω) ∩ C(Ω). The conditions for
uniqueness of the solution can be found in [9].
An integral representation of the solution is obtained using the Green’s function for
standard domains B(x), x ∈ Ω (for example - sphere, ball, ellipsoid), lying inside the
domain Ω taking into account that B(x) satisfies required conditions (see [9]). Therefore, the initial problem for solving an elliptic differential task (1) is transformed into
the following Fredholm integral equation of the second kind with a spectral parameter
λ (K is an integral operator, K : Lp −→ Lp ):
k(x, t) u(t) dt + f (x), x ∈ Ω (or u = λ Ku + f ),

u(x) = λ

(2)

B(x)

where k(x, t) and f (x) are obtained using Levy’s function and satisfy:
k(x, t) ∈ Lxp (Ω)

Ltq (B(x)),

f (x) ∈ Lp (Ω),

p, q ∈ Z, p, q ≥ 0,

The unknown function is denoted by u(x) ∈ Lp (Ω), x ∈ Ω, t ∈ B(x).

1 1
+ = 1.
p q

Complexity of Monte Carlo Algorithms for a Class of Integral Equations

733

We are interested in Monte Carlo method for evaluation with a priori given error ε
of linear functionals of the solution of the integral equation (2) of the following type:
J(u) =

for λ = λ∗ .

ϕ(x) u(x) dx = (ϕ, u)

(3)

Ω

It is assumed that ϕ(x) ∈ Lq (Ω), q ≥ 0, q ∈ Z.

3 A Class of Grid Monte Carlo Algorithms for Integral Equations
The investigated grid Monte Carlo approach for approximate evaluating of the linear
functional (3) is based on the approximation of the given integral equation (2) by a
system of linear algebraic equations (SLAE). This transformation represents the initial step of the considered class of grid MCAs. It is obtained using some approximate
cubature rule (cubature method, Nystrom method, [1,7]). The next step is to apply the
resolvent MCA [2,3] for solving linear systems of equations.
3.1 Cubature Method
m
Let the set {Aj }m
j=1 be the weights and the points {xj }j=1 ∈ Ω be the nodes of the
chosen cubature formula. Thus, the initial problem for evaluating of (ϕ, u) is transformed into the problem for evaluating of the bilinear form (h, y) of the solution y of
the obtained SLAE:

y = λ L y + b,

L = {lij } ∈ Rm×m ,

y = {yi }, b = {bi }, h = {hi } ∈ Rm×1 (4)

with the vector h ∈ Rm×1 . The following notation is used:
lij = Aj k(xi , xj ),

yi = u(xi ),

bi = f (xi ), hi = Ai ϕ(xi ), i, j = 1, . . . , m.

The error in the approximation on the first step is equal to:
m

λ

hi ρ1 (xi ; m, k, u) + ρ2 (m, ϕ, u),
i=1

where ρ1 (xj ; m, k, u) and ρ2 (m, ϕ, u) are the approximation errors for the integral in
equation (2) at the node xi and linear functional (3), respectively.
Some estimations for the obtained errors ρ1 , ρ2 from the approximation with some
quadrature formula in the case when Ω is an interval [a, b] ⊂ R are given below. The
errors depend on derivatives of some order of the functions k(x, t) u(t) and ϕ(x) u(x).
Estimations for these quantities obtained after differentiation of the integral equation
and using Leibnitz’s rule are given in the works of Kantorovich and Krylov [7]. Analogous estimations are given below:
¬
¬ ∂j
¬
¬ ∂tj

¬
¬

j

[ k(xi , t) u(t)]¬¬ ≤
l=0
j

|(ϕu)(j) | ≤
l=0

j
l

j
l

j
(j−l)

F (l) Kt

+ |λ|(b − a)
l=0
j

F (l) Φ(j−l) + |λ|(b − a)
l=0

j
l

j
l

(j−l)

Kx(l) Kt

Kx(l) Φ(j−l) U (0) ,

U (0) ,

734

where

I. Dimov and R. Georgieva
(j)

Kx = max

t∈B(x)

∂ j k(x, t)
∂xj

,

(j)

Kt

= max
t∈B(x)

x=xi

∂ j k(xi , t)
,
∂tj

F (j) = max |f (j) (x)|, U (j) = max |u(j) (x)|, Φ(j) = max |ϕ(j) (x)|.
x∈Ω

x∈Ω

x∈Ω

The quantity U (0) , which represents the maximum of the solution u in the interval
Ω = [a, b], is unknown. We estimate it using the original integral equation, where the
maximum of the solution in the right-hand side is estimated by the maximum of the
initial approximation: U (0) ≤ (1 + |λ|(b − a)K (0) ) F (0) .
3.2 Resolvent Monte Carlo Method for SLAE
Iterative Monte Carlo algorithm is used for evaluating a bilinear form (h, y) of the solution of the SLAE (4), obtained after the discretization of the given integral equation (2).
Consider the discrete Markov chain T : k0 −→ k1 −→ . . . −→ ki with m states
1, 2, . . . , m. The chain is constructed according to initial probability π = {πi }m
i=1
and transition probability P = {pij }m
i,j=1 . The mentioned probabilities have to be
normilized and tolerant to the vector h and the matrix L respectively.
It is known (see, for example, [5,11]) that the mathematical expectation of the random variable, defined by the formula
∞
lk k
hk
θ[h] = 0
Wj bkj ,
where W0 = 1, Wj = Wj−1 j−1 j ,
πk0 j=0
pkj−1 kj
is equal to the unknown bilinear form, i.e. Eθ[h] = (h, y).
Iterative MCM is characterized by two types of errors:
– systematic error ri , i ≥ 1 (obtained from truncation of Markov chain) which depends on the number of iterations i of the used iterative process:
|ri | ≤ αi+1 b

2 /(1

− α),

α = |λ| ||L||2 ,

b = {bj }m
j=1 ,

bj = f (xj )

– statistical error rN , which depends on the number of samples N of Markov chain:
rN = cβ σ 2 (θ[h])N −1/2 ,
0 < β < 1, β ∈ R.
The constant cβ (and therefore also the complexity estimates of algorithms) depends
on the confidence level β. Probable error is often used, which corresponds to a 50%
confidence level.
The problem to achieve a good balance between the systematic and statistical error
has a great practical importance.

4 Estimate of the Computational Complexity
In this section, computational complexity of two approaches for solving integral equations is analysed. These approaches are related to iterative Monte Carlo methods and
they have similar order of computational cost. That is why, our main goal is to compare
the coefficients of leading terms in the expressions for complexity of algorithms under
consideration. The values of these coefficients (depending on the number of operations
necessary for every move in Markov chain) allow to determine the conditions when the
considered grid MCA has higher computational efficiency than the mentioned grid-free
MCA.

Complexity of Monte Carlo Algorithms for a Class of Integral Equations

735

4.1 A Grid Monte Carlo Algorithm
To estimate the performance of MCAs, one has to consider the mathematical expectation ET (A) of the time required for solving the problem using an algorithm A (see
[4]). Let lA and lL be the number of suboperations of the arithmetic and logical operations, respectively. The time required to complete a suboperation is denoted by τ (for
real computers this is usually the clock period).
Cubature Algorithm. The computational complexity is estimated for a given cubature
rule:
T (CA) > τ cs (pk + 1)ε−s + c−s/2 (pf + pϕ + pnode)ε−s/2 + pcoef lA ,
where the constant c depends on the following quantities
(r)

c = c (λ, Kx(r) , Kt , F (r) , Φ(r) ),

r = 1, . . . , ADA + 1,

s = s(ADA)

(5)

(ADA is the algebraic degree of accuracy of the chosen cubature formula). The number
of arithmetic operations required to compute one value of the functions k(x, t), f (x)
and ϕ(x) and one node (coefficient) is denoted by pk , pf and pϕ , respectively and by
pnode (pcoef ).
The degree s and the constants pnode and pcoef depend on the applied formula. For
instance:
1 for rectangular and Trapezoidal rule;
s=
(6)
1/2 for Simpson’s rule.
Resolvent Monte Carlo Algorithm. Firstly, the case when the corresponding Neumann series converges (the supposition for slow convergence is allowed) is considered.
The following number of operations is necessary for one random walk:
– generation of one random number : kA arithmetic and kL logical operations;
– modeling the initial probability π to determine the initial or next point in the
Markov chain: μA arithmetic and μL logical operations (E μA + 1 = E μL =
μ, 1 ≤ μ ≤ m − 1);
– computing one value of the random variable: 4 arithmetic operations.
To calculate in advance the initial π and transition P probabilities (a vector and a
square matrix, respectively), it is necessary a number of arithmetic operations, proportional to the matrix dimension m: 2m(1 + m).
To ensure a statistical error ε, it is necessary to perform i transitions in the Markov
process, where i is chosen from the inequality
i > ln−1 α (ln ε + ln (1 − α) − ln b 2 ) − 1 (assuming b 2 > ε (1 − α)),
where α = |λ| L 2 and the initial approximation is chosen to be the right-hand side b.
To achieve a probable error ε, it is necessary to do N samples depending on the
inequality N > c0.5 σ 2 (θ) ε−2 , c0.5 ≈ 0.6745, where θ is the random variable, whose
mathematical expectation coincides with the desired linear functional (3).

736

I. Dimov and R. Georgieva

Therefore, the following estimate holds for the mathematical expectation of the time
required to obtain an approximation with accuracy ε using the considered grid MCA:
E T (RMCA) > τ [(kA + μ + 3) lA + (kL + μ) lL ]
+ 2τ m(m + 1)lA ,

[cβ σ(ξjR [h])]2 (ln3 ε + a)
ε2
ln3 α

√
where a = ln(1 − α) − ln b 2 , m > cs ε−s/2 (the constants are given by (5) and
(6)), and ξjR is the unbiased estimate of the j-th iteration of the matrix L, obtained using
the resolvent MCA.
Consider the case when the corresponding Neumann series does not converge. The
convergence of the Monte Carlo algorithm for solving the SLAE (4) can be ensured (or
accelerated) by application of an analytical continuation of the Neumann series by substituting of the spectral parameter λ (mapping) (see [2,6,7,8,10]). The main advantage
of this approach for acceleration of convergence of an iterative process is its inessential influence over the computational complexity of the algorithm. The computational
complexity on every walk is increased only with one arithmetic operation required for
multiplication by the coefficients gj , j ≥ 0, that ensures convergence (on the supposition that these coefficients are calculated with a high precision in advance). To obtain
the computational complexity of the modified algorithm, it is necessary to estimate the
∞
hk
variation of the new random variable: θ[h] = 0
gj Wj bkj .
πk0 j=0
We will use the following statement for a class of mappings proved in [10]: The
conformal mapping λ = ψ(η) = a1 η + a2 η + . . . has only simple poles on its boundary
¯ |η∗ |/(1 − |η∗ |) < 1, then the
of convergence |η| = 1. If V ar ξkR ≤ σ 2 and q = a
complexity estimate of the algorithm has an order O(|ln ε|4 /ε2 ), where a
¯ is such a
¯, i = 1, 2, . . ., λ∗ is the value of the spectral parameter in the
constant that |ai | ≤ a
integral equation (2) (respectively SLAE (4)) and η∗ = ψ −1 (λ∗ ).
In general, a computational estimate of this class of grid MCAs can be obtained if
the behavior of gj and V ar ξjR is known.
4.2 A Grid-Free Monte Carlo Algorithm
The computational complexity of the grid MCA under consideration is compared with
the computational complexity of a grid-free Monte Carlo approach. This approach is
based on the use of a local integral representation (assuming that such a representation
exists, [9,12]) of the solution of an elliptic boundary value problem. Existence of this
representation allows to construct a Monte Carlo algorithm, called spherical process (in
the simplest case) for computing of the corresponding linear functional. As a first step
of this algorithm an -strip ∂Ω of the boundary ∂Ω is chosen (on the supposition that
the solution is known on the boundary) to ensure the convergence of the constructed
iterative process. The following number of operation is necessary for one random walk:
– generation of n (this number depends on initial probability π) random numbers to
determine the initial point in the Markov chain: n(kA + kL ) operations (kA and kL
are the arithmetic and logical operations necessary for the generation of one random

Complexity of Monte Carlo Algorithms for a Class of Integral Equations

–
–
–
–
–

737

number) or modeling of an isotropic vector that needs of the order of R∗n(kA +kL )
operations (the constant R depends on the efficiency of the modeling method and
transition probability);
calculating the coordinates of the initial or next point: pnext (depends on the modeling method and the dimension d of the domain B(x));
calculating one value of functions: pf ; pπ , pϕ or pk , pP ;
calculating one sample of the random variable: 4 arithmetic operations;
calculating the distance from the current point to the boundary ∂Ω: γA arithmetic
and γL logical operations (depends on the dimension d of the domain Ω);
verification if the current point belongs to the chosen δ-strip ∂Ωδ .

The following logarithmic estimate for the average number Ei of spheres on a single
trajectory holds for a wide class of boundaries [5]:
E i ≤ const |ln δ|,

const > 0,

(7)

where const depends on the boundary ∂Ω.
Calculating the linear functional with a preliminary given accuracy ε and attainment
of a good balance between the statistical and the systematic error is a problem of interest
to us.
Let us to restrict our investigation of the statistical error to the domain Ω ≡ [a, b].
To ensure a statistical error ε, it is necessary to do i transitions in the Markov process,
where i is chosen from the inequality:
i > ln−1 α (ln ε + ln (1 − α) − ln F (0) ) − 1
where α = |λ| VB(x) K,

(assuming F (0) > ε (1 − α)),

K = max |k(x, t)| and the initial approximation is chosen to
x,t

be the right-hand side f (x). On the other hand, the estimate (7) depending on the chosen
-strip of the boundary is done. Then, an expression for δ according to the number
of transition i is obtained from these two estimates: δ ≈ e −i/const . Therefore, the
following estimate holds for the mathematical expectation of the time required to obtain
an approximation with accuracy ε using the considered grid-free MCA:
E T (GF MCA) > τ [(n kA + pnext + pf + pπ + pϕ + γA + 4) lA
+(n kL + γL + 1) lL + ((R n kA + pnext + pf + pk + pP + 4 + γA ) lA
+(R n kL + γL + 1) lL ) ×

(ln ε + ln (1 − α) − ln3 F (0) [cβ σ(ξjS [h])]2
]
.
ε2
ln3 α

Obtained expressions for coefficients in computational complexity for MCAs under
consideration allow us to define some conditions when the GMCA is preferable to the
GFMCA:
– the functions that define the integral equation (2) (k(x, t), f (x), ϕ(x)) have comparatively small maximum norm in the corresponding domain and their values can
be calculated with a low complexity

738

I. Dimov and R. Georgieva

– the initial and transition probability are complicated for modeling (acceptancerejection method)
– large dimension of the integration domain
It has to be noted the fact that the grid MCAs under consideration are admissible
only for integral equations with smooth functions, but some techniques of avoiding
singularities of this kind exist (see [1]).

5 Concluding Discussion
In this paper we deal with performance analysis of a class of Markov chain grid Monte
Carlo algorithms for solving Fredholm integral equations of second kind. We compare
this class of algorithms with a class of grid-free algorithms. Grid-free Monte Carlo uses
the so-called spherical process for computing of the corresponding linear functional.
Obviously, the grid approach assumes higher regularity of the input data since it includes an approximation procedure described in Section 4.1. The (grid-free) approach
does not need additional approximation procedure and directly produces a bias approximation to the solution. But the grid-free algorithm is more complicated and its implementation needs more routine operations (like checking the distance from a given point
to the boundary) that decrease the efficiency of the algorithm. Analyzing the regularity
of the problem one may chose either grid or grid-free algorithm is preferable. Especially, if the input data has higher regularity (k(x, t), f (x), ϕ(x) have comparatively
small maximum norm) than the grid algorithm should be preferred.

References
1. Bahvalov, N.S., Zhidkov, N.P., Kobelkov, G.M.: Numerical Methods. Nauka, Moscow (1987)
2. Dimov, I.T., Alexandrov, V.N., Karaivanova, A.N.: Parallel Resolvent Monte Carlo Algorithms for Linear Algebra Problems. Mathematics and Computers in Simulation 55 (2001)
25–35
3. Dimov, I.T., Karaivanova, A.N.: Iterative Monte Carlo Algorithms for Linear Algebra Problems. In: Vulkov, L., Wasniewski, J., Yalamov, P. (eds.): Lecture Notes in Computer Science,
Vol. 1196. Springer-Verlag, Berlin (1996) 150–160
4. Dimov, I.T., Tonev, O.I.: Monte Carlo Algorithms: Performance Analysis for Some Computer Architectures. J. Comput. Appl. Math. 48 (1993) 253–277
5. Ermakov, S.M., Mikhailov, G.A.: Statistical Modeling. Nauka, Moscow (1982)
6. Kantorovich, L.V., Akilov, G.P.: Functional Analysis in Normed Spaces. Pergamon Press,
Oxford (1964)
7. Kantorovich, L.V., Krylov, V.I.: Approximate Methods of Higher Analysis. Physical and
Mathematical State Publishing House, Leningrad (1962)
8. Kublanovskaya, V.N.: Application of Analytical Continuation by Substitution of Variables
in Numerical Analysis. In: Proceedings of the Steklov Institute of Mathematics (1959)
9. Miranda, C.: Partial Differential Equations of Elliptic Type. Springer-Verlag, Berlin Heidelberg New York (1970)
10. Sabelfeld, K.K.: Monte Carlo Methods in Boundary Value Problems. Springer-Verlag, Berlin
Heidelberg New York London (1991)
11. Sobo`l, I.M.: The Monte Carlo Method. The University of Chicago Press, Chicago (1974)
12. Vladimirov, S.V.: Equations of Mathematical Physics. Nauka, Moscow (1976)

