Media Synchronization Framework for SVC Video
Transport over IP Networks
1

1

2

2

Kwang-deok Seo , Jin-won Lee , Soon-heung Jung , and Jae-gon Kim
1

Computer and Telecommunications Engineering Division, Yonsei Univ., Gangwon, Korea
Kdseo@yonsei.ac.kr
2
Broadcasting Media Research Group, ETRI, Daejeon, Korea
{zeroone,jgkim}@etri.re.kr

Abstract. This paper proposes an efficient media synchronization framework
for SVC video transport over IP networks. To support synchronization between
SVC video and audio signals transported over IP networks, RTP/RTCP protocol
suite is usually employed. To provide a framework for media synchronization,
we suggest an efficient RTP packetization mode and propose a computationally
simple RTCP packet processing method. With the suggested RTP packetization
mode, layer synchronization among scalable layers of the SVC video can be effectively achieved. Also by adopting the computationally simple RTCP packet
processing, we do not need to process every RTCP SR packet for inter-media
synchronization between video and audio signals.
Keywords: media synchronization, SVC, RTP, RTCP.

1 Introduction
SVC (Scalable Video Coding) known as scalable extension of H.264/MPEG-4 AVC
is currently standardized in the JVT (Joint Video Team) of the ISO/IEC MPEG and
the ITU-T Video Coding Experts Group [4]. SVC aims at achieving both high compression performance and adaptation for video delivery over heterogeneous networks.
SVC is based on H.264/MPEG-4 AVC and provides three scalability modes including
temporal, spatial, and quality scalability. Unlike the conventional scalability modes
supported in the MPEG-2, H.263, and MPEG-4, SVC scalability can provide combined scalability mode in which the three scalability modes can be aggregated to a
single SVC bitstream. The general concept for combining temporal, spatial, and SNR
scalability in an SVC bitstream is illustrated in Fig. 1, which shows an example GOP
structure for SVC with two scalable layers. The SVC bitstream contains two spatial
layers: QCIF encoded at 15 fps and CIF encoded at 30 fps. Each spatial layer is composed of one base quality layer and one FGS layer for SNR scalability. The dotted
arrow in Fig. 1 designates inter-layer prediction to remove redundancy between spatial layers. In temporal dimension, each picture belongs to one temporal layer indicated by the number in the middle of each picture.
To transport SVC video encapsulated in NAL (network abstraction layer) units
over Internet Protocol (IP) in real-time, RTP (real-time transport protocol) and RTCP
(RTP control protocol) are usually employed. RTP carries the payload with some
Y. Shi et al. (Eds.): ICCS 2007, Part IV, LNCS 4490, pp. 621–628, 2007.
© Springer-Verlag Berlin Heidelberg 2007

622

K.-d. Seo et al.

additional information like sequence number and RTP timestamp. RTCP serves for
controlling quality of the transmitted data. RTP timestamp begins at a random number
and its rate of increment is proportional to its sampling rate [5]. Thus, they do not
directly give information on absolute time reference. To synchronize audio and video
data, we need to utilize RTCP Sender Report (SR) packet to find out the absolute time
information corresponding to each RTP timestamp carried by each RTP packet.
In this paper, we suggest an efficient RTP packetization mode for layer synchronization among scalable layers of SVC video and propose an efficient inter-media
synchronization between SVC video and audio. In the proposed inter-media synchronization method, we do not need to process every RTCP SR packet for synchronization. Moreover, it does not require any floating-point operations or any divisions at
all. The proposed method will be compared with conventional method [1].

Fig. 1. Combined scalability in an SVC bitstream

2 Suggested RTP Packetization Mode for Layer Synchronization
The concepts of VCL (video coding layer) and NAL in SVC are inherited from
H.264/MPEG-4 AVC. While the VCL creates a coded representation of the source
content, the NAL encapsulates the data generated by the VCL and provides header
information in a way that enables simple and effective customization of the use of the
VCL for a broad variety of systems. For this purpose, the SVC NAL unit header contains the spatial, temporal, and quality coordinates of the NAL unit payload in the
scalability cube which is used for identification and scaling operations of the NAL
units. The NAL unit header is designed to co-serve as the payload header of an RTP
payload format. For more details on the syntax and semantics of the SVC NAL unit
header, you are referred to [3] and [4].
The Audio/Video Transport (AVT) Working Group of the IETF started in November 2005 to draft the RTP payload format for SVC and the signaling for layered

Media Synchronization Framework for SVC Video Transport over IP Networks

623

coding structures [3]. As SVC is a backward compatible extension of H.264, the same
should be the case for its RTP packetization. In particular, it is possible to transport
the base layer utilizing the same packetization scheme of RFC 3984 [2]. Thus, RFC
3984-aware legacy devices are still capable of utilizing an SVC base layer in an RTP
transport environment.
An RTP stream carrying only one layer would carry NAL units belonging to that
layer only. An RTP stream carrying a complete scalable video bitstream would carry
NAL units of a base layer and one or more enhancement layers. In the former case,
however, the system administrator of the server should open a separate UDP port for
each RTP session to carry a single layer. Thus, the server should open as many ports
as required to transport all the layers. System administrators would like to avoid opening too many UDP ports in their firewalls, because of the security risk and the administrative effort. Moreover, for mass deployment to end terminals, it is desirable to
reduce the number of UDP ports in a firewall to the absolute minimum−ideally to a
single one. In this respect, the latter approach is much preferred to the former one.

Fig. 2. SVC streaming scenario based on single RTP session

This line of thought leads to the service scenario as depicted in Fig. 2, where the
server opens only a single RTP session to carry one or more layers. For each terminal,
the server composes a bitstream tailored to the terminal’s needs by aggregating NAL
units of appropriate layers. ‘Single RTP session generator’ is used to aggregate the
extracted contents from potentially more than one scalable layer into a single RTP
stream carrying one or more layers.
In order to support the service scenario shown in Fig. 2, it is necessary to support
encapsulating NAL units from multiple SVC layers into a single RTP packet in the
payload format. The IETF specification on RTP payload format for SVC contains
mechanisms such as STAP (single-time aggregation packet) and MTAP (multi-time
aggregation packet) to aggregate more than one NAL unit into a single RTP packet,
and another mechanism called FU (fragmentation unit) to split overly large NAL unit
into multiple RTP packets [3]. Two fundamentally different packetization modes of
operation are supported in [3]: non-interleaved mode and interleaved mode. Table 1
summarizes the allowed packet types for each packetization mode. In non-interleaved

624

K.-d. Seo et al.

mode, the NAL units should be aggregated in decoding order by adopting STAP-A,
whereas in interleaved mode, NAL units belonging to multiple pictures can be aggregated out of decoding order by adopting STAP-B and MTAP. Non-interleaved mode
is intended to avoid excessive RTP/UDP/IP header overhead that would result when
encapsulating small NAL units in single NAL unit packets, whereas the interleaved
mode provides an error resilience tool against burst errors. STAP-A aggregates NAL
units with identical NALU-time, whereas MTAP aggregates NAL units with differing
NALU-time. Here, NALU-time is defined as the value that the RTP timestamp would
have if that NAL unit would be transported in its own RTP packet. In Fig. 1, pictures
belonging to different spatial layer but having the same picture number (or display
time) must have the same NALU-time. Thus, by adopting STAP-A, it is far more
feasible to provide synchronization between pictures belonging to different spatial
layers but with identical NALU-time. Therefore, Non-interleaved mode is more suitable for systems that require very low end-to-end latency and timely synchronization
among NAL units from multiple SVC layers aggregated in a RTP packet. Furthermore, as shown in Table 1, only non-interleaved mode supports ‘single NAL unit’
type that can contain only a single NAL unit in the RTP payload. As a result, noninterleave mode can be suggested as a mandatory packetization mode for fast and
real-time streaming requiring timely synchronization among SVC layers, and interleaved mode can be considered as an optional mode for error resilience by providing
interleaving function against burst packet loss. In this paper, we employ noninterleaved mode to provide layer synchronization among different scalable layers.
Table 1. Allowed packet types for RTP packetization modes of SVC

NAL Unit
Type
0
1~23
24
25
26
27
28
29
30~31

Packet
Type
undefined
single NAL unit
STAP-A
STAP-B
MTAP16
MTAP24
FU-A
FU-B
undefined

Single NAL
Unit Mode
ignore
yes
no
no
no
no
no
no
ignore

Non-interleaved
Mode

Interleaved
Mode

ignore
yes
yes
no
no
no
yes
no
ignore

ignore
no
no
yes
yes
yes
yes
yes
ignore

3 Conventional Inter-media Synchronization Method
The next problem to resolve for synchronization issue is providing inter-media synchronization between audio and SVC video. According to RFC 3550, it is stated that
separate audio and video streams should not be carried in a single RTP session and
demultiplexed based on the payload type or SSRC fields [5]. However, we cannot
directly use RTP timestamp to synchronize data carried by different RTP sessions for

Media Synchronization Framework for SVC Video Transport over IP Networks

625

the following two reasons. Firstly, RTP timestamp should be initialized to random
offsets at session startup to minimize the risk of breaking encryption. Secondly, RTP
timestamp increases in proportion to the sampling rate of media. Usually the sampling
rates of audio and video data are quite different. Thus, the rates of increase in RTP
timestamp for audio and SVC video sessions are not the same. To circumvent these
problems, RTCP SR packets carrying both the RTP and the NTP timestamp are generally employed.

Fig. 3. RTP/RTCP streams for audio and SVC video sessions
Fig. 3 shows RTP and RTCP streams for audio and SVC video sessions. In Fig. 3,
each RTP packet of SVC video session aggregates NAL units that all share the same
NALU-time. The RTP timestamp of each RTP packet must be set to the NALU-time
of all the NAL units to be aggregated. An aggregation packet can carry as many NAL
units as necessary. However, the total amount of data in an aggregation packet obviously must fit into an IP packet, and the size should be chosen so that the resulting IP
packet is bound by the MTU size of the transport channel.
The superscripts A and V are used to denote audio and SVC video sessions, respectively. For the derivation of the relationship between the RTP timestamp of a specific
RTP packet and the absolute time reference, let us consider the shaded RTP packet in
the audio session shown in Fig. 3. For this RTP packet, TIA ( j A ) is the absolute time
A

reference for RTP timestamp of the jA-th RTP packet after the IA-th RTCP packet has
been received. NTP (Network Time Protocol) tells us how to set the absolute time
information. As a special case, when jA = 0, TIAA (0) is the NTP timestamp contained in
the IA-th RTCP packet. Similarly, M IAA ( j A ) is the RTP timestamp contained in the jA-th

626

K.-d. Seo et al.

RTP packet after the IA-th RTCP packet, and M IAA (0) is the RTP timestamp for the IAth RTCP packet.
Let us assume that the shaded RTP packet in the SVC video session is sampled at
the same time with the shaded RTP packet in the audio session. If the absolute time
reference of this SVC RTP packet is represented by TIV ( jV ) , it is required that
V

TIAA ( j A ) = TIVV ( jV )

for perfect synchronization. However, the transmission rates of RTP

packets are normally not the same for different sessions. Moreover, RTCP packets for
each session may be transmitted at different time. Thus, even if TIA ( j A ) = TIV ( jV ) , IA
A

V

and jA of the audio session may not be equal to IV and jV of the SVC video session,
respectively. Based on this fact, we can compute TIA ( j A ) of a RTP timestamp by using
A

M IAA ( j A ) . M IAA (0)

and TIAA (0) values are also used in the computation, which can be
obtained by the IA-th RTCP packet. In the method proposed in [1], the absolute time
reference TIA ( j A ) is obtained by
A

TIAA ( j A ) = TIAA (1) +

jA

∑

ΔM IAA (k )
RA

k =2

,

(1)

where RA is the sampling rate of audio data. TIAA (1) is obtained by
TIAA (1) = TIAA (0) +

M IA (1) − M IAA (0)
A

RA

.

(2)

In (1), ΔM IAA (k ) is the difference between the RTP timestamps of two adjacent RTP
packets and is given by
ΔM IAA ( k ) = M IAA ( k ) − M IAA (k − 1) .

(3)

Computation of (1) and (3) continues until a new RTCP packet is received. After
receiving the (IA+1)-th RTCP packet, (1) and (2) are computed again using
TIAA +1 (0) and M IAA +1 (0) carried by this RTCP packet. When computing TIA ( j A ) by (1) in
A

Bertoglio’s method, they do not compute the term

jA

∑

ΔM IAA ( k )

k =2

they already know the value of

TIAA ( j A − 1) ,

directly. Instead, since

RA

they compute the value by

TIAA ( j A ) = TIAA ( j A − 1) +

ΔM IAA ( j A )
RA

.

(4)

The same procedure (1)-(4) can be applied to the SVC video session to obtain

TIVV ( jV ) .

When processing jA–th RTP packet for the audio session and jV–th RTP packet for
the SVC video session, Bertoglio’s decision rule based on TIA ( j A ) and TIV ( jV ) for
A

V

synchronization is as follows:
TIVV ( jV ) − TIAA ( j A ) > η +

η + ≥ TIVV
TIVV

( jV ) − TI A ( j A ) ≥ −η −
A

( jV ) − TI A ( j A ) < −η −
A

: SVC video is ahead of audio,
: audio and SVC video are in synch,
: audio is ahead of SVC video,

(5)

Media Synchronization Framework for SVC Video Transport over IP Networks

627

where η + and η − are thresholds used for boundaries of the in-sync region. To apply
this decision rule, it is evident that we need to inspect every RTCP packet for the
computation of (1) through (5).

4 Proposed Inter-media Synchronization Method
Now we will derive the proposed scheme from the conventional method described by
(1)-(5). In this study, we exploit the fact that after a connection has been setup, the
codec type and the sampling rate are usually sustained during the connection.
By canceling out each term in the computation of

jA

∑

ΔM IAA ( k )

in (1) and by using (2),

RA

k =2

we can simplify (1) into the following form
TIAA ( j A ) = TIAA (1) +
= TIAA (0) +

M IAA ( j A ) − M IAA (1)
RA
M IAA ( j A ) − M IAA (0)
RA

(6)
.

Assuming that RA is kept as a constant, we can obtain (7) from the NTP and RTP
timestamps carried by the 0-th and the IA-th RTCP packet as follows
RA =

M IAA (0) − M 0A (0)
TIAA (0) − T0A (0)

.

(7)

Rearranging (7) for TI A (0) and substituting it into (6) yields
A
TIAA ( j A ) = T0A ( 0) +

M IAA ( j A ) − M 0A (0)
RA

.

(8)

Similarly, we can apply this procedure to obtain the relation (9) for the RTP stream of
SVC video session.
TIVV ( jV ) = T0V (0) +

M VIV ( jV ) − M 0V (0)
RV

.

(9)

By subtracting (9) from (8) and applying this result to (5), we can derive the following compact decision rule (10) after some arithmetic,
: SVC video is ahead of audio,
d > η 0 + R A RV η +
A V
A V
: audio and SVC video are in sync, (10)
η0 + R R η + ≥ d ≥ η0 − R R η −
d > η 0 − R A RV η −

: audio is ahead of SVC video,

where the variable d and the threshold constant η0 are defined by
d = R A M VIV ( jV ) − RV M IAA ( j A ) ,
η 0 = R A RV (T0V (0) − T0A (0)) + RV M 0A (0) − R A M 0V (0) .

(11)
(12)

Note that we only need to compute d by (11) when examining the synchronization of
each pair of RTP packet by (10). The reason is that η 0 + R A RV η + and η 0 − R A RV η − in
(10) are needed to be computed just once after receiving the first RTCP packet. Since
all of the RV, RA, M VIV ( jV ) , and M IAA ( j A ) values in (11) are fixed-point numbers themselves, there is no need to utilize floating-point operations at all. Obviously, this is a

628

K.-d. Seo et al.

clear advantage for embedded processors, which usually do not have floating point
units. Moreover, (11) does not require any division operations like the case of (1)-(4).
For ARM processors, avoiding division is a great advantage, since they do not have
any hardware divider. In [1], they reported that truncation round-off errors may accumulate, since their method is computed by repeated divisions and summations.
However, it is obvious that there are no possibilities of error accumulation in the
computation of (11). Note that only two fixed-point multiplications and one subtraction are needed for the computation of d in (11).

5 Conclusions
In this paper, we addressed the problem of synchronization for SVC video transport
over IP networks. The synchronization issue includes layer synchronization among
scalable layers of SVC video and inter-media synchronization between audio and
SVC video. It has first been discussed non-interleaved mode of RTP packetization is
suitable to provide layer synchronization among scalable layers of SVC video. Then,
we proposed a computationally simple RTCP packet processing for inter-media synchronization. The advantageous aspects of the proposed method can be summarized
in three ways. First, the decision rule is far simpler than the conventional method.
Second, it does not require RTCP SR packet processing for synchronization except
first RTCP packet. Finally, the proposed method does not suffer from the accumulation of round-off errors that are inherent in the conventional method.
Acknowledgements. This work was supported in part by the Gangwon-Alberta Research Collaboration Fund.

References
1. Bertoglio L., and Migliorati P.: Intermedia synchronization for video conference over IP.
Signal Processing: Image Communication, Vol. 15, No. 1, (1999) 149-164.
2. Wenger S., Hannuksela M., Westerlund M., Singer D.: RTP payload format for H.264
video. RFC 3984, IETF, (Feb. 2005).
3. Wenger S.: RTP payload format for SVC video. IETF Internet Draft: draft-wenger-avt-rtpsvc-03.txt, (Oct. 2006).
4. Reichel J., Schwarz H., and Wien M.: Scalable video coding- Working Draft 3.

JVT-P201, Poznan, Poland . (July 2005,)
5. Schulzrinne H., Casner S., Frederick R., and Jacobson V.: Real-time transport protocol.
RFC 3550, IETF, (July 2003).

