Emergence of Specialization from Global
Optimizing Evolution in a Multi-agent System
Lei Chai, Jiawei Chen, Zhangang Han, Zengru Di, and Ying Fan
Center for Complexity Research,
Beijing Normal University, Beijing, 100875, P.R. of China
Institute of Social Development and Public Policy,
Beijing Normal University, Beijing, 100875, P.R. of China
{lchai,jwchen,zhan,zdi,yfan}@bnu.edu.cn
http://www.springer.com/lncs

Abstract. A Markov chain model is proposed to describe the evolutionary dynamics of a multi-agent system. Many individual agents search
for and exploit resources to get global optimization in an environment
without complete information. With the selection acting on agent specialization at the level of system and under the condition of increasing returns, agent specialization emerges as the result of a long-term
optimizing evolution.
Keywords: agent specialization, evolutionary dynamics, multi-agent
system.

1

Introduction

Among novel and numerous varieties of collective activities performed by social
insect societies, such as all ants and termites, and some species of bees and
wasps [1], division of labor is a typical example which is classically viewed as an
evolving process led by mutation and selection, and also has emergent properties
of social systems. A lot of work has been done to study the formation of division
of labor and the mechanism for tasks allocation [2,3,4,5]. In this paper, multiagent system simulation has been applied and a framework of pattern formation
has been borrowed to study specialization phenomena in biological, social and
economic systems.
The emergence of collective behaviors in multi-agent systems has become an
interesting area of complexity research [6,7,8,9,10,11]. In a distributed multiagent system, be it natural or social, agents do not have complete information
about the environment where they live, and they have to actively interact with
others to reach collective or individual optimization. Even though the interactions among agents may be simple and local, they can lead to complex dynamics
at the global scale. Studies of computational ecology have shown that when
the agents make choices with imperfect information, the dynamics can give rise
to nonlinear oscillations, clustered volatilities and chaos that drive the system
Corresponding author.
Y. Shi et al. (Eds.): ICCS 2007, Part IV, LNCS 4490, pp. 98–105, 2007.
c Springer-Verlag Berlin Heidelberg 2007

Emergence of Specialization from Global Optimizing Evolution

99

far from optimality [12,13]. Moreover, when the agents in the system have a
hierarchical organization that determines the task allocations, the system as a
whole will be able to manage complex and various changing environments [2,14].
Holland has argued that complexity arises from the self-adaptive properties of individual agents [15] and this approach has been applied to biological ecosystems
and economic systems [16,17,18].
Evolutionary processes and principles are helpful to understand the mechanisms behind the formation of specialization. As to a long-term evolution, selection acting on agent specialization must take place at the level of the colony.
Some colonies survive and reproduce more than others because they have a division of labor that is better adapted to a particular environment [19]. Based
on our previous multi-agent simulation model of agent division [20], this paper presents a Markov Chain model that describes a system of many individual
agents that search for and exploit resources to get global optimization in an environment where they interact locally. Under the condition of increasing returns,
specialization is unfailingly the result from the global optimizing evolution under
certain initial conditions.
The presentation is organized into three major parts. In Section 2, the model
and the results of static analysis are presented. Section 3 gives the Markov chain
model describing the evolutionary dynamics of the system. The ﬁnal steady state
shows the specialization of the agents. The results are well consistent with that
of simulation model. In Section 4, we provide a summary of our results and a
brief discussion of some unresolved issues.

2

The Model and Static Analysis

Consider a system with M individual agents. Every agent is an autonomous
entity which searches for and exploits resources in a given environment. There
is complete information transfer among agents. Each agent knows the information about the resource distribution which is speciﬁed by every other agent’s
forage. For simplicity and without loss any generality, we introduce a simple, non-spatial model of evolutionary dynamics to obtain some mathematical
analytical results.
2.1

Optimal Behavior for Solitary Agent

First, let’s discuss the problem for a solitary agent to deal with an uncertain
environment.
The live space for the agent is composed by the samples of resources valued F0
and 0. In the beginning of every period of time, the agent can choose to search
for new resources with probability q or to take the situation of last period with
probability 1 − q. When the agent determines to search new resource, it will
get the resource F0 with probability P . Then its product is (1 − q)F0 . The cost
for the search is (1−q)C, where the factor 1−q describes the eﬀect of learning by

100

L. Chai et al.

doing[21]. When the agent determines to take the last situation, if the last value
of the resource is Ft−1 , the value of this period is
Ft =

1
Ft−1 , a > 1
a

(1)

where a stands for the depreciation of resources and t denotes the generation
of the system’s evolution. The goal of the agent is to maximize the total net
returns for N periods, which is determined by each agent’s parameter q for a
given distribution of resources that is described by probability P .
In the beginning of searching and exploiting process noted as period 0, the
agent randomly searches. For this period, the expected return is E0 = (1 − q)
(P F0 − C). For period 1, the agent can choose to search for new resources with
probability q. The corresponding expected beneﬁt is E0 . Another choice is to
stay in the situation of last period (with probability 1 − q). The corresponding
expected return is P F0 /a. So the expected return of period 1 is
1
E1 = (1 − q)(qE0 + (1 − q) P F0 )
a

(2)

Let x = (1 − q)/a. From the similar analysis, the expected beneﬁt of period n
can be written as:
En = (1 − q)(qE0 + P F0 (xn + q

x(1 − xn−1 )
))
1−x

Hence the total expected returns from period 0 to period N is
N

N

En = (1 + N )(1 − q)qE0 + P F0 (1 − q)

W =
n=0

= (1 + N )(1 − q)qE0 + P F0 (1 − q)[(1 + N )

(xn + q
n=0

x(1 − xn−1 )
)
1−x

q
1 + xN
qx
+ (1 −
)
] (3)
1−x
1−x 1−x

From the above result, we can obtain the optimal point qM and corresponding
maximum total expected returns W for given set of parameters.
2.2

Optimal Division of Agents for a Colony

Now we turn to the colony of M agents. Each agent is characterized by a parameter qi , which determines the searching probability of the agent. As discussed
in the above solitary agent case, we assume that every searching agent ﬁnds
resources F0 with probability P . Assume there is complete information between
agents. If any agent has found a resource F0 , all the others will go and exploit it.
M
Then the product of the system is i=1 (1 − qi )F0 . The searching cost for each
agent is (1 − qi )C.
Let’s compare the results on the total returns of distributed qi with complete
M
specialization. Hence at every time period, there will be i=1 qi = m agents
searching for new resources. The gross probability of ﬁnding at least one new

Emergence of Specialization from Global Optimizing Evolution

101

resource F0 is the same with when there is m agents specialized in searching.
We denote this gross probability as Pr . For a colony with distributed qi , the
M
expected product of the ﬁrst period is RD = i=1 (1 − qi )F0 Pr = M F0 Pr −
M
F0 Pr M
i=1 qi = F0 Pr (M −m). The cost for searching is CD =
i=1 qi (1−qi )C =
M
M
2
2
mC − C i=1 qi . With qi ≤ 1, i=1 qi is usually less than m. So we usually
have CD > 0. But for the colony with specialized agents, although the expected
F0 Pr = F0 P (M −m) = RD ,
product of the ﬁrst period is the same: RS = M−m
i=1
hence the products of following generations are also the same, and the cost for
search is 0. So the net return of a specialized system is bigger than that of the
distributed one.
Assuming that there are m agents specialized in searching in the colony, all
the others specialized in exploiting the resource. In each period, If any searching
agent has the probability P to ﬁnd the resource F0 , then the probability for m
agents at least ﬁnd one resource F0 is Pr = 1 − (1 − P )m. So the expected returns
of the colony for every period are:
E0 = Pr (M − m)F0
1
E1 = Pr (M − m)F0 + Pr (1 − Pr ) (M − m)F0
A
1
1
E2 = Pr (M − m)F0 + Pr (1 − Pr ) (M − m)F0 + Pr (1 − Pr )2 2 (M − m)F0
A
A
......
Let x = (1 − Pr )/A, where parameter A > 1 is also related to the diminishing
of resource under agents’ exploiting. The return of nth period can be written as
En = E0 (

1 − xn
)
1−x

(4)

So the total returns of N periods is
N −1

W ({Nj }) =

E0
n=0

E0
1 − xN
1 − xn
=
(N − x(
))
1−x
1−x
1−x

=

1 − xN
Pr (M − m)F0
(N − x(
))
1−x
1−x

(5)

By equation 5, it is found that m0 is sensitive to the probability P (as shown in
Figure 1). The results are in good agreement with previous simulation results.

3

Markov Chain Model for the Evolutionary Dynamics

We assume the character space of the agents has k + 1 states corresponding to
the searching probabilities described by parameter qj , j = 0, 1, . . . , k, with q0 = 0
and qk = 1. The distribution of agents in every state describes the situation of the
colony in macroscopic level. Let’s denote this distribution as {Nj , j = 0, 1, ..., k},
k
and we have j=0 Nj = M . For generality Nj is a positive real number instead

102

L. Chai et al.

Fig. 1. Returns (normalized) as a function of number of searching agents m. Except
parameter P (labeled above the corresponding curve), all the other parameters for each
curve are the same.

of a positive integer. From the results in the above discussion, the total product
W {Nj } and total cost CD {Nj } of the colony in one generation with N periods is
W ({Nj }) =

Pr (M −

k
j=0

Nj qj )F0

1−x

(N − x(

1 − xN
))
1−x

(6)

k

CD ({Nj }) = N

Nj qj (1 − qj )C

(7)

j=0
k

where x = (1 − Pr )/A, Pr = 1 − (1 − P )m , and m = j=0 Nj qj . The total
return of the system in one generation is R({Nj }) = W ({Nj }) − CD ({Nj }) .
Within the evolution process between two generations, the state of every agent
will transit among all the k + 1 states. In the simulation model, we only make it
possible for the transition between the nearest neighbors. A Markov chain process
can describe the genetic variation and natural selection model. The dynamical
behavior of this Markov chain is determined by following equations:
Nj (t + 1) = Nj (t) + P (j + 1 → j)Nj+1 (t) + P (j − 1 → j)Nj−1 (t)
−P (j → j − 1)Nj (t) − P (j → j + 1)Nj (t)

(8)

For j = 0 and j = k we have
N0 (t + 1) = N0 (t) + P (1 → 0)N1 (t) − P (0 → 1)N0 (t)
Nk (t + 1) = Nk (t) + P (k − 1 → k)Nk−1 (t) − P (k → k − 1)Nk (t)

(9)

where P (i → j) is the probability for an agent to transit from state i to state j,
and it is determined by the global optimization. Corresponding to the natural
selection process described in the simulation model, the transition probability
can be written as:
1
(10)
P (i → j) = μ[5 + 3 sgn(R(Ni − 1, Nj + 1) − R(Ni , Nj ))]
2

Emergence of Specialization from Global Optimizing Evolution

103

Fig. 2. Evolution of the distribution of agents. The results are qualitative similar to
the computer simulations.

where μ is a parameter related to the probability of mutation. From the above
equations, we can get the results of the optimal evolution of the system from
any given initial conditions, which is shown in Figure 2. The Markov chain
model is carried out under the following parameters. M = 30 agents form a
colony and want to get global optimization in an uncertainty environment. The
probability for every searching agent to ﬁnd resource F0 is P = 0.7. The value of
the resource is F0 = 10 and the searching cost is C = 8. The other parameters
are q = qi+1 − qi = 0.05, A = 4, N = 54, and μ = 0.02. Given any initial
condition, we get the evolution of the distribution of agents. The ﬁnal optimal

Fig. 3. Evolution from diﬀerent initial conditions. (a) Homogeneous initial distribution
with qk =0.1 for every agent. (b) Random initial distribution.

distribution in the Markov chain process is stable and it could be achieved from
any given initial conditions (See Figure 3). We have compared the ﬁnal stable
distribution of the Markov chain process with the average distribution in the
generations of optimal state in our previous simulation model [20]. As shown in
Figure 4, it is notable that the mathematical results are consistent well with the
results of simulations.

104

L. Chai et al.

Fig. 4. Comparison of theoretical predictions (solid lines) and simulation results
(column bars) of the distributions of agents’ number. (a) P =0.7 (b) P =0.4

4

Conclusions

In this paper we have studied the formation of specialization of a simple multiagent model with optimizing evolution behaviors. With a Markov chain model,
the multi-agent system has provided discoveries in a concise way to perceive
the evolution of labor division. First, specialization is a functional structure
in macroscopic level of multi-agent systems. The model has demonstrated how
a global structure emerges from the long-term optimizing evolution under the
mechanism of increasing returns. Second, an evolutionary process given by transition behavior describes the mechanism of mutation and natural selection. We
believe that natural selection may also serve as the basic mechanism in the labor
division in social and economic systems. The last but not the least, the results
reveal that the stochastic properties in the evolutionary process are necessary to
generate macroscopic structure and to reach global optimization.
This work suggests a number of future directions for the study of the optimal
behaviors of multi-agent systems. As mentioned in section 2, the model assumes
that there is perfect information among agents and the goal of the system is
global optimization. These assumptions in fact have suggested that the agents
have already formed a colony. It is interesting to study the relationship between
individual behavior and global optimization, to see how organization emerges
from individual optimum, and to understand how a multi-agent system forms
aggregate units.
Acknowledgments. This work was partially supported by the 985 project and
NSFC under grant No.70471080 and No.70371072.

References
1. Theralauz G. Bonabeau E. and Deneubourg, J., The origin of nest complexity in
social insects. Complexity 3 (1998) 15-25.
2. Gordon D., The Organization of work in social insect colonies. Complexity 8 (2003)
43-46.

Emergence of Specialization from Global Optimizing Evolution

105

3. Robinson G., Regulation of division of labor in insect societies. Annu. Rev. Entomol
37 (1992) 637-665.
4. Bonabeau E., Theraulaz, G. and Deneubourg J., Quantitative study of the ﬁxed
threshold model for the regulation of division of labour in insect societies. Proc.
Roy. Soc. London B 263 (1996) 1565-1569.
5. Wu J., Di Z., and Yang Z., Division of labor as the result of phase transition.
Phasica A 323, (2003) 663-676.
6. Zimmermann G., Neuneier R. and Grothmann R., Multi-Agent market modeling
of foreign exchange rates. Advances in Complex Systems 4 (2001) 29-43.
7. Darbyshire, P., Eﬀects of communication on group learning rates in a multi-agent
environment. Advances in Complex Systems 6 (2003) 405-426.
8. Juanico, D., Monterola, C. and Saloma, C., Cluster formation by allelomimesis in
real-world complex adaptive systems. Phys. Rev. E 71, (2005) 041905.
9. Taylor, P. and Day, T., Behavioural evolultion: cooperate with thy neighbour?
Nature 428 (2004) 643-646.
10. Nowak, M., Sasaki, A., Taylor, C. and Fudenberg, D., Emergence of cooperation
and evolutionary stability in ﬁnite populations. Nature 428 (2004) 646-650.
11. Weiss G. et al. (eds.), Adaption and learning in multi-agent systems. SpringerVerlag, Berlin (1996) 20-35.
12. Kephart J., Hagg T. and Huberman B., Dynamics of computational ecosystems,
Phys. Rev. A 40 (1989) 404-421.
13. Hagg T. and Huberman B., Controlling chaos in distributed systems, IEEE Transactions on Systems, Man, and Cybernetics 21 (1991) 1325-1332.
14. Bonabeau E., and G. Theraulaz, Self-organization in social insects, Trend in Ecology and Evolution 12 (1997) 188-193.
15. Holland J., Hidden Order-how adaptation builds complexity. Addison Wesley: MA
(1995) 230-300.
16. Holland J. and Miller J., Artiﬁcial adaptive agents in economic theory, American
Economic Review 81(2) (1991) 365-370.
17. Andriani P., Diversity, Knowledge and complexity theory: some introductory issues.
International Journal of Innovation Management 5(2) (2001) 257-274.
18. Savage M., and Askenazi M., Arborscapes: a swarm-based multi-agent ecological disturbance model. Technical Report (STF-TR-98-06-056, Santa Fe Institute,
1998).
19. Fontana W., Buss L., The arrival of the ﬁttest: toward a theory of biological organization, Bull. Math. Biol. 56 (1994) 1-64.
20. Di Z., Chen J., Wang Y., Han Z., Agent division as the results of global optimizing evolution, in; Shi Z., He Q. (eds.), Proceedings of International conferebce on
intelligent information technology. Post & Telecom Press Beijing (2002) 40-46.
21. Arrow K.J., The economic implications of learning by doing, Rev. of Economics
Stu. 29 (1962) 155-173.

