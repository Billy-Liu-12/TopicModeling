Detecting Shrew HTTP Flood Attacks for Flash Crowds
Yi Xie and Shun-Zheng Yu
Department of Electrical and Communication Engineering Sun Yat-Sen University,
Guangzhou 510275, P.R. China
xieyicn@163.com

Abstract. Countering network attacks is becoming ever more challenging.
Web-based vulnerabilities represent a substantial portion of the security
exposures of computer networks. In order to detect a new Web-based assault
named shrew Distributed Denial of Service attacks based on HTTP flood,
Principle Component Analysis and Independent Component Analysis are applied
to abstract the multivariate observation vector. A novel anomaly detector based
on hidden semi-Markov model is proposed. Experiment results based on real
traffic trace and emulated attacks show, the scheme can be used effectively to
implement the detection of the shrew HTTP flood attacks embedded in the
normal flash crowd of large-scale Website; and the detection is not dependent on
the intensity of attack traffic.

1 Introduction
In the past ten years, Web-based applications have become a popular way to provide
information and services dynamically. Electronic commerce, ranging from internet
shopping malls to Web-based banking and trading, has become an integral component
of modern society. At the same time, Web servers and Web-based applications are
popular attack targets. CVE [1] reported Web-based vulnerabilities accounted for more
than 25% of the total number of security flaws during 1999 to 2005.
For these reasons, studies have been done to detect Web-based attacks. However, it
isn’t enough for most current works to detect the special new Web-based attacks known
as “Application layer Distribute Denial of Service” (App-DDoS) attacks. The main
difference between the App-DDoS attacks and the traditional DDoS attacks is that they
are protocol-compliant, non-intrusive, and utilize legitimate Web requests to
overwhelm system resources. App-DDoS attacks utilize the weakness enabled by the
standard practice of opening services such as HTTP (TCP port 80) and HTTPS (TCP
port 443) through most firewalls to launch the flood. Many applications and protocols,
both legitimate and illegitimate, can use these openings to tunnel through firewalls by
connecting over standard TCP port 80 (e.g., Code Red virus) or encapsulating in SSL
tunnels (HTTPS). Attack packets aiming at these services pass through the firewall
without being identified. Thus, most current intrusion detections designed for
Web-based attacks and DDoS attacks become invalid when they are used to block this
type of sophisticated attacks. This is especially the case when the attackers secrete the
offensive traffic in the flash crowds of special heavily-accessed Web server
environments (e.g., Olympic Games Website, e-commerce Website).
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 640–647, 2007.
© Springer-Verlag Berlin Heidelberg 2007

Detecting Shrew HTTP Flood Attacks for Flash Crowds

641

This paper focuses on the detection of shrew HTTP flood attacks under unstable and
bursty background traffic (e.g., flash crowd). Shrew HTTP flood is a special type of
App-DDoS attacks which is a compound of shrew attack and HTTP flood. The
difficulties of its detection include: (i) in stead of constantly injecting traffic flows with
huge rates into the network, shrew attackers launch assaults by sending burst pulses
periodically, which has high peak rate while maintaining a low average rate to exhibit
"stealthy" behavior; and (ii) burst traffic and high volume are the common
characteristics of HTTP flood and flash crowd, which make the detection much more
difficult. This paper meets this challenge by a novel detection scheme.
We carry out the anomaly detection by file popularity which has been proved to
have significant temporal stability in [7]. The main contributions of this paper are (i)
development of a new efficient mechanism to detect the shrew HTTP flood attacks
which mimic (or mix with) the normal flash crowds and utilizes legitimate requests to
overwhelm system resources, (ii) applying principal component analysis (PCA) [8] and
independent component analysis (ICA) [9] to abstract multivariate observation vector,
(iii) using hidden semi-Markov model (HsMM) [10] to construct the anomaly
recognizer, and (iv) experimentation of a real traffic of heavily-accessed Web server
and an emulated shrew HTTP flood attack to evaluate the model.
The rest of the paper is organized as follows. In section 2, we describe related work
in Web-based attacks detection. In section 3, we present the rationale of this work. In
section 4, we conduct experiments to validate our detection algorithms. Finally, in
section 5, we conclude our work.

2 Related Work
The detection of Web-based attacks has recently received considerable attention
because of the increasingly critical role that Web-based services are playing, e.g.,
[3][4]. However, current detection systems are mostly misuse-based and therefore
suffer from the problem of not being able to detect new attacks. Recently, Juan [5]
accomplished the detection by analyzing each incoming HTTP payloads, which may
lead to high computational complexity. In [6], Tombini proposed a serial architecture
where Web-related events are first passed through an anomaly detection component.
Then, the events that are identified as neither normal nor intrusive are passed on to a
misuse detection component, but it requires extensive manual analysis to evaluate the
characteristics of the events being analyzed.
A valuable recent work on App-DDoS can be found in [2][11]. In [2], the authors
developed a counter-mechanism which assigns a suspicion measure to a session in
proportion to its deviation from legitimate behavior. However, this work impliedly
assumes the incoming traffic is stable, which is not always true in large-scale
heavily-accessed Websites. In [11], Kandula et al. designed a system to protect a Web
cluster from DDoS attacks by designing a probabilistic authentication mechanism
using “puzzles”. Unfortunately, requiring all users to solve graph puzzles has the
possibility of annoying users and introducing additional service delays for legitimate
users. This also has the effect of denying Web crawlers access to the site and as a result
search engines may not be able to index the content. Finally, new techniques may
render the graphical puzzles solvable using automated methods [12]. Other researchers
have explored the defense of shrew attacks, e.g., [13]. However, authors of these

642

Y. Xie and S.-Z. Yu

literatures merely aimed at the TCP attacks in stead of HTTP flooding attacks.
Furthermore, in contrast to our burst and unstable background traffic of detection
scenario, their common implied hypothesis is that the background traffic is stable,
which may not help in this paper.

3 Detection Algorithms
In contrast to the prior work, the detection scheme proposed in this paper uses passive
detection which applies statistical methods to detect shrew HTTP flood attacks. Our
observation data is file popularity which can be derived from the Web server log easily.
In order to perform efficient, unsupervised, learning-based anomaly detection, this
paper proposes a novel detection scheme based on multivariate statistical analysis and
outlier detection. PCA and ICA are used to abstract the observed data, and then the
HsMM is applied to construct the anomaly detector.
3.1 File Popularity Matrix
We define the N × T dimensional file popularity matrix as:

AN ×T

⎡ a11 a12
⎢
a21 a22
=⎢
⎢" "
⎢
⎢⎣a N 1 a N 2

K T
a1T ⎤ ⎡ a1 ⎤ ⎡ a1 ⎤
⎥ ⎢ ⎥ ⎢K ⎥
" a 2T ⎥ ⎢ a 2 ⎥ ⎢ a 2 ⎥
=
=
" " ⎥ ⎢ " ⎥ ⎢" ⎥
⎥ ⎢ ⎥ ⎢K ⎥
" a NT ⎥⎦ ⎢⎣a N ⎥⎦ ⎢⎣ aT ⎥⎦
"

(1)

where ait denotes the popularity of the ith document at tth time unit, a i = [ai1 " aiT ] is
K

the time series of ith document’s popularity, at = [a1t " a Nt ]T denotes the
popularities of N documents at tth time unit, which forms the N-dimensional
observation vector. Especially, if we consider the documents as a subspace and time as
another subspace, the file popularity matrix reflects the spatial-temporal patterns of all
K
users’ access behaviors. Distribution of at presents the spatial distribution of
popularity at tth time unit while the distribution of ai presents the temporal distribution
of the ith document’s popularity. For brevity of notation, we call them spatial
distribution and temporal distribution, respectively.
In [7], the authors have found, although the domains from which clients access the
popular content are unstable, there is significant temporal stability in file popularity of
busy Website. Thus, file popularity is used as detection signal in this paper.
3.2 HsMM
Because of the high dimensional document space (N), we can not monitor the shrew
HTTP flood attacks merely by checking every document’s popularity distribution.
Furthermore, detection through checking popularity distribution of each document
solely may give wrong warning signals because changes of individual document’s
popularity distribution don’t imply attacks. Hence, we consider the joint distribution of
N-dimensional document space to implement numerical and effective detection in this
paper. We extend the HsMM [10] to capture the dynamics of file popularity matrix and
monitor the shrew HTTP flood attacks during flash crowd event.

Detecting Shrew HTTP Flood Attacks for Flash Crowds

643

HsMM is a Hidden Markov Model (HMM) with variable state duration. It has been
widely used in recognition and detection because it is very suitable to describe most
practical physical signals (e.g., speech recognition, character recognition and DNA
sequences clustering). The HsMM is a stochastic finite state machine, specified by
(S,π,A,P) where S is a discrete set of hidden states with cardinality M; π is the
probability distribution for the initial state πi≡Pr[s1=i] and satisfy ∑iπi=1, st denotes the
state that the system takes at time t and i∈S ; A is the state transition matrix with
probabilities aij≡Pr[st=j|st-1=i] and satisfy ∑jaij=1, i,j∈S; P is the state duration matrix
with probabilities pi(d)≡Pr[τt=d|st=i] and satisfy ∑dpi(d)=1, τt denotes the remaining (or
residual) time of the current state st, i∈S, d∈{1,…,D}, D is the maximum interval
between any two consecutive state transitions. For brevity of notation, we denote the
complete set of model parameters: λ=({πi},{aij},{bi(k)},{pi(d)}). The entropy (En) of
observation fitting to the HsMM and the average logarithmic entropy (ALE) per
observation is defined as the measure criteria as following, respectively:
K
K
En = Pr[o1T λ ] = ∑i ,d Pr[o1T , ( sT ,τ T ) = (i, d ) λ ] ,

(

)

K
ALE = ln Pr[o1T λ ] T ,

(2)
(3)

In our previous work [10], we have developed efficient parameter reestimate algorithm
and dynamic update algorithm for HsMM. Based on the work, HsMM is applied to
construct the anomaly detector for shrew HTTP flood attacks. We consider the file
popularity matrix as an N-dimensional stochastic process which is controlled by an
underlying semi-Markov process. For an HsMM whose parameters are given, hidden
state st of the HsMM can be used to describe a representative spatial distribution of
popularity of N documents at tth time unit. Transitions of the hidden states (i.e., from st-1 to
st) can be considered as the characteristics of access behaviors from one spatial
distribution (st-1) to another spatial distribution (st). Duration (τt) of a hidden state (st) can
be considered as the time unit amount that the current spatial distribution (st) will persists.
Considering the HsMM will be very complex when the observation is a
multidimensional vector with dependent elements, we use the Principal component
analysis [8] to reduce the dimensionality of file popularity matrix and apply the
Independent component analysis [9] to obtain independent vector.
3.3 PCA and ICA
PCA is a well-established technique for dimensionality reduction and multivariate
analysis. Examples of its many applications include data compression, image
processing, visualization, exploratory data analysis, pattern recognition, time series
prediction and distributed sensor network.
PCA aims to find a linear orthogonal transformation:
K
K
yt = Eat ,

(4)

where the rows of E are the eigenvectors of the covariance matrix of the original
K
N-dimensional data x (assumed to have 0 mean, condition that can always be easily
achieved by subtracting the mean estimated over the training set). The jth principal
K
K
component (PC, the jth element of yt ) of a vector at corresponds to its projection along

644

Y. Xie and S.-Z. Yu

the direction of the jth eigenvector of the data covariance matrix, and the principal
components are non-correlated. The eigenvectors are ordered so that, if σ i2 is the
eigenvalue related to the ith eigenvector, then σ 12 ≥ σ 22 ≥ " ≥ σ m2 . The eigenvalue
accounts for the data variance along the direction of the corresponding eigenvector. The
first eigenvector indicates the direction of highest variance in the data, the second one
the direction orthogonal to the first one with the highest variance and so on. Often the
last eigenvectors account for very small variance and the corresponding principal
components can be eliminated. Thus, we choose the first K eigenvectors having the
largest eigenvalues. This implies that K is the inherent dimensionality of the subspace
governing the “signal” while the remaining (N-K) dimensions generally contain noise.
The dimensionality of the subspace K can be determined by:

∑i=1 λi ∑i=1 λi ≥ α ,
K

N

(5)

where α is the ratio of variation in the subspace to the total variation in the original
space. This allows a reduction of the dimensionality making the following anomaly
detector based on HsMM faster and better trainable (the number of parameters is
reduced as it depends on the size of the observation vector). A complete discussion of
PCA can be found in [8].
ICA is a new statistical signal processing technique which is widely used in blind
source separation (BSS). In contrast to the PCA which is sensitive to high-order
relationships, the basic idea of ICA is to represent a set of random variables using basis
function, where the components are statistically independent and non-gaussianity as
possible. The main aim of ICA is to find the linear transformation:
K
K
yt = Wat ,

(6)

where W is called unmixing matrix which satisfies p(yi,yj)=p(yi)p(yj) for i≠j, where yi is
K
the ith element of yt . Many algorithms can be used to solve this non-Gaussian problem
of ICA. This paper uses the FastICA algorithm [9] which has good performance in
simulations and fast convergence during the parameter reestimate.
3.4 Detection Architecture
The overall procedure of our detection architecture is illustrated in Fig. 1. The scheme
includes training phase and detection phase. The training phase includes the following
five steps: (i) compute the file popularities of each document; (ii) input the file
popularity matrix into PCA module and compute the orthogonal transformation E and
PCs; (iii) remain the first K PCs by (5), α=80% in this paper; (iv) input the first K PCs
into the ICA module and compute the unmixing matrix W and ICs; and (v) use the ICs
to estimate the parameters of HsMM.
The detection is implemented as the follows: (i) compute the file popularities of
each document; (ii) compute the first K PCs of the observed data based on E; (iii)
compute the ICs of the first K PCs based on W; and (iv) ompute the entropy of observed
data fitting to the HsMM by (2) and (3);

Detecting Shrew HTTP Flood Attacks for Flash Crowds

Training
data

Compute the
file popularity

PCA

ICA

E

Internet

Incoming
request

Compute the
file popularity

Outcoming
respond Web Server

Model training
HSMM

λ

W

PCA

645

ICA
HSMM
Detection Model

Model on-line update
normal
abnormal Intrusion Decision
Alarm

Fig. 1. Anomaly detector

In the practical implementation, the model is first trained by the stable and low
volume Web workload whose normality can be ensured by most existing anomaly
detection systems, and then it is used to monitor the following Web workload for a
period of T minutes. When the period is past, model will be updated by the new
collected Web workload whose normality is ensured by its entropy fitting to the model.
After the update, the model enters the next cycle for App-DDoS attacks detection. Web
traffic is reported as anomalous if the difference between its entropy and normal level is
larger than the predefined threshold

4 Experiments
We use the trace of FIFA 1998 WorldCup (http://ita.ee.lbl.gov/html/contrib
/WorldCup.html) and emulate shrew HTTP flood attacks to validate the model.
In contrast to the traditional shrew attacks with constant attack parameters, we
emulate a more stealthy type of shrew attacks of HTTP flood whose attack parameters
are all chosen randomly by attack nodes. As shown in Fig. 2, a single source stochastic
pulsing attack is modeled as a square waveform HTTP request stream with an attack
period of T, length of the burst l, and the burst rate H. Among the variables, T, l, H and
Δt are stochastic variables reset by each attack node randomly before it is going to fire
the next pulsing attack, which makes the different attack nodes have different attack
parameters and produces different attack parameters at different attack period. Thus,
the attacks exhibit a fluctuating rate oscillating between different H and zero and
dynamics of a pulsing attack appear as a stochastic ON/OFF pattern.
0

H
l
T
ts ts +Δt
Fig. 2. Shrew HTTP flood attack

H

Entropy

A

C

-5
b
-10
-15

tetime

B

a

0

1000
2000
index of time

Fig. 3. Pulsing rate attack

3000

Y. Xie and S.-Z. Yu
1

94
Detection Rate

Detection Rate (%)

646

92

90

1 2
4
6
8
10
False Positives Rate (%)
Fig. 4. ROC curve

1

0.8 (-5.3,0.9)

0.8

0.6

0.6

0.4

0.4

0.2

(-5.3,0.01) 0.2

0
-12

-9

-6
Entropy

-3

0
0

Fig. 5. Entropy, DR and FPR

Fig. 3 shows the entropy varies with the time, where curve a represents the entropy
of normal flash crowd and curve cluster b represents the entropy of normal flash
crowd embedded with shrew HTTP flood attacks in zone C. As shown in the figure,
although the flash crowd is burst and high volume, the document popularity is stable
because of the steady access behavior of individual Web surfer, thus, the entropy series
is stable. But, when the vicious requests are added into the flash crowd, the original
popularity distribution of documents is destroyed, which cause the entropy series
deviates from the normal level. Thus, the potential shrew HTTP flood attacks can be
detected by the entropy of document popularity fitting to the model.
Fig. 4 is the receiver operating characteristics (ROC) curve showing the
performance of our detection model. Fig. 5 shows, if we take -5.3 for threshold value of
normal Web traffic’s average entropy, the False Negative Ratio (FNR) is about 1%, and
the Detection rate is about 90%.

5 Conclusions and Future Work
Based on PCA, ICA and HsMM, this paper proposes a novel proposal to detect the
shrew HTTP flood attacks occurring during the flash crowd by monitoring the file
popularity of Web server. Experiment results based on a real traffic and emulated
attacks show the model could capture shift of Web traffic caused by the attacks
occurring during flash crowd and might be both practical and helpful for triggering
more focused detection and filtering in victim network.
One disadvantage of our scheme is the technique cannot readily distinguish and
filter the malicious sources from the normal ones, which make it merely serve as an
alert function to trigger more detailed monitoring mechanisms. We will improve it in
our further work.

Acknowledgments
This work was supported by National Natural Science Foundation of China under grant
no. 90304011, Guangdong Natural Science Foundation under grant no. 04009747 and
Higher Education Foundation for Ph.D Program under grant no. 20040558043.

Detecting Shrew HTTP Flood Attacks for Flash Crowds

647

References
1. Common Vulnerabilities and Exposures. http://www.cve.mitre.org/, 2005
2. S. Ranjan, R. Swaminathan, M. Uysal, and E. Knightly. “DDoS-Resilient Scheduling to
Counter Application Layer Attacks under Imperfect Detection” in Proceedings of IEEE
INFOCOM. April 2006. online: http://www-ece.rice.edu/ networks/papers/dos- sched.pdf
3. M. Almgren, U. Lindqvist, “Application-integrated data collection for security monitoring”
in Proceedings of Recent Advances in Intrusion Detection, Davis, CA, October 2001,
LNCS, Springer, 2001, pp.22–36.
4. G. Vigna, W. Robertson, V. Kher, R.A. Kemmerer, “A stateful intrusion detection system
for world-wide Web servers” in the Proceedings of the Annual Computer Security
Applications Conference, Las Vegas, NV, December 2003, pp. 34–43.
5. Juan M. Estévez-Tapiador, Pedro García-Teodoro, Jesús E. Díaz-Verdejo. “Detection of
Web-based Attacks through Markovian Protocol Parsing” in the Proceedings of the 10th
IEEE Symposium on Computers and Communications.
6. E. Tombini, H. Debar, L. Me, and M. Ducasse. “A Serial Combination of Anomaly and
Misuse IDSes Applied to HTTP Traffic” In Proceedings of the Twentieth Annual Computer
Security Applications Conference, Tucson, Arizona, December 2004.
7. Venkata N. Padmanabhan and Lili Qiu. “The content and access dynamics of a busy Web
site: Findings and implications” In the proceeding of ACM SIGCOMM 2000, Stockholm,
Sweden, Aug. 2000.
8. Lindsay I Smith. “A tutorial on Principal Components Analysis” [EB/OL].
http://www.snl.salk.edu/~shlens/pub/ notes/pca.pdf, 2003-03.
9. A. Hyvärinen. “Survey on Independent Component Analysis” Neural Computing Surveys,
1999,2. pp.94-128.
10. S.-Z. Yu, and H. Kobayashi, “An Efficient Forward-Backward Algorithm for an Explicit
Duration Hidden Markov Model” IEEE Signal Processing Letters, Vol. 10, No. 1, January
2003, pp. 11-14.
11. S. Kandula, D. Katabi, M. Jacob, and A. W. Berger. “Botz-4-sale: Surviving organized
DDoS attacks that mimic flash crowds” Technical Report TR-969, MIT., October 2004.
Online: http://www.usenix.org/events/nsdi05/tech /kandula/kandula.pdf
12. G.Mori and J.Malik. “Recognizing objects in adversarial clutter: Breaking a visual captcha”
IEEE Computer Vision and Pattern Recognition, 2003.
13. X. Luo, and R. K. C. Chang, “On a New Class of Pulsing Denial-of-Service Attacks and the
defense,” Network and Distributed System Security Symposium (NDSS’05), San Diego,
CA., Feb. 2-5, 2005.

