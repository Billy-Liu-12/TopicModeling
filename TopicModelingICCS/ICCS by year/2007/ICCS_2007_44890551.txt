E-Learning Assistant System Based on Virtual Human
Interaction Technology
Xue Weimin1,2 and Xia Wenhong1
1

2

Institute of Information Technology, Beijing Union University, Beijing 100101
Department of Computer Science & Technology, Tsinghua University, Beijing 100084
xuewm@mail.tsinghua.edu.cn

Abstract. The virtual human affective interaction is one of the hotspots in
information science and cognitive science today. The importance of emotions in
learning process is more and more acknowledged. This paper introduces a new
virtual human interaction module based on multi-agents. The affective interactive
model is built according to the human cerebrum control pattern. The multimodal
detection agents are able to help tutor to better understand the emotional and
motivational state of the learner throughout the learning process. The results of the
practical application virtual human interaction in E-Learning system indicate that
virtual human technology can improve the interactivity and entertainment for the
E-learners.
Keywords: E-Learning, virtual human, multi-agents model.

1 Introduction
The virtual human with affection is challenging project facing to modern scientists,
especially when those characters interact with real people possessing real affection. In
biological systems, the existence of emotions can have both advantageous and
detrimental effects on the cognitive process [1]. Now a growing amount of studies
support the claim that affection plays a critical role in decision-making and learning
performance as it influences cognitive processes [2]. For example, as suggested by
Goleman [3] “the extent to which emotional upsets can interfere with mental life is no
news to teachers. Students who are anxious, angry or depressed don’t learn; people
who are caught in these states do not take information efficiently or deal with it very
well”. So it is obviously that the user’s affective state plays an important role in
improving the effectiveness of e-learning. The emotional unawareness has been considered one of the main limits of the traditional e-learning tools. In fact, while skilled
teachers can modify the learning path and their teaching style according to the
feedback signals provided by the learners, e-learning platforms cannot generally take
account of these feedbacks resulting often too rigid and weakened [4].This paper
presents our studies on affective interaction between real human and virtual human.
The virtual human can perceive real human affection by recognition of his voices and
facial expressions, and the virtual human can generate his simple affective behavior
autonomously [5].
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 551–554, 2007.
© Springer-Verlag Berlin Heidelberg 2007

552

X. Weimin and X. Wenhong

2 The Virtual Human Affective Interaction Theory
2.1 The Characters of Virtual Human
Affective virtual human is to make virtual human has certain characteristics and
emotion interactive ability (to identify and express emotions and affections), to endow
it with artificial psychological model and the ways to identify and express emotions
and affections. It is the application of artificial psychology theory in the field of
virtual reality. It researches how virtual human recognizes natural human’s emotion
and how virtual human expresses the object’s affection based on its artificial
psychology model. The virtual human can study human interactive skills through
communication with human, and have the same value criterions as human. Its
intelligence is not the intelligence in narrow sense, but it is the intelligence in broad
sense, which is not only including certain intelligence quotient, but also including
certain affection quotient [5]. The virtual human uses an internal model of the agent’s
affective state to guide the conversational dialogue between virtual human and user.
2.2 The Model of Virtual Human
Traditional human machine interaction is normally based on passive instruments such
as keyboard, mouse, etc. It’s impossible for them to understand and express emotions.
Without the ability of emotion processing, the virtual human cannot be expected to be
a human-like agent in the virtual environment, and also cannot be expected to
communicate with humans in a natural and harmonious way.
(1) BDI Agent Architectures
The basic BDI agent architecture designed for the virtual human is presented in
Fig.1. The inputs to the agent are events from the environment and the outputs are the
agent's actions. The interpreter loops and generates an action in each cycle. External
and internal events are always added to an event queue. The agent's beliefs are
adjusted according to those events.

Fig. 1. This shows a basic BDI Agent Architecture

At the beginning of a cycle, plans are chosen from the plan library that specifies
courses of action that may be undertaken in order to achieve the agent's goals. Next,
the deliberator, a component of the interpreter, selects a subset of these plans to be
adopted and adds them to the intention structure. The agent then executes one action
from one plan in the intention structure. The intention and demand structures are

E-Learning Assistant System Based on Virtual Human Interaction Technology

553

modified by dropping successful goals and satisfied intentions, as well as impossible
goals and unrealizable intentions. Hence, due to new external events, the agent can
reactively choose to drop intended plans and/or adopt others.
(2) Affective interaction model
According to the virtual human characters, we adopted the composed structure of
reactive agent and deliberative agent as the basic structure (Fig.2 shows the structure).
The system structure includes two emotional information channels. The deliberative
agent has affective reasoning engine for affective state recognition and modeling. The
reactive agent subsystem can make reaction to the apperception results without
complicated reasoning.

Fig. 2. The Structure of Interaction System

Fig. 3. The structure of the E-Learning system

3 E-Learning System Structure
In the e-learning process there is often one teacher for most students. To promote
effectiveness of learning for the students, each student is assigned to have one virtual
human. The E-Learning system structure is shown as the Fig.3. The virtual human is
represented as a teacher in the e-learning platform. Except for the animate agent
supplied by Microsoft Corporation, we can design a likely character or use the
character from the third one. Each character has supplied a lot of interface function. It
can dialog to the student face to face through the facial expression recognition system
and the voice recognition system. The virtual human can change his facial expression
emotion according to the learner’s emotion state. Thus the e-learning process is
making more and more personalized and humanized.
In the e-learning interactive system, extracting and validating emotional cues
through analysis of users’ facial expressions is very important. The process of the
facial expression subsystem is generally carried out according to following stages:
detection of the face, the automatic extraction of contours of the permanent features
of the face to knowing: the eyes, the eyebrows and the lips. Extracted contours being
sufficiently realistic, we then according to the changes of the facial expression
character points to recognize the six universal emotions on the face (joy, surprise,
fear, disgust, anger and sadness).The video frequency facial expression character
point track and recognition technology is presented in reference [8]. A speech
emotion recognition algorithm was developed based on the statistical and temporal
features of the acoustic parameters for discriminating between emotions. The process
of the speech emotion recognition subsystem is carried out in reference [9, 10].

554

X. Weimin and X. Wenhong

4 Conclusion and Future Work
This paper simply reports our exploratory approach in the teaching computation. The
virtual human interaction has been used in the e-learning system in order to realize the
harmonious emotion interaction. Some technologies and effective arithmetic are used
in the system. This system is able to recognize the emotional state of the learner
according to his facial expression. As a result, it has realized the personalized and
humanized human-machine interactive function. However the virtual human
interactive technology is not mature, especially the facial expression recognition rate
is relatively low, so the system is only an original one. There are many aspects in the
system needing to be improved. In the future we will improve and better our system,
especially in facial expression track speed, recognition rate. With the development of
the virtual human interaction, the virtual human will not only be used in learning in
interaction ,but also capable of direct psychological enrichment tasks, such as mental
therapy and entertainment.
Acknowledgments. This paper is supported by National Natural Science Foundation
of China (No. 60433030) and Excellent Talent Culture Foundation of Beijing City
(No.20051D0502214).

References
1. Picard R. Affective Computing. Cambridge, MA: MIT Press, 1997
2. Kinard, E. M.:. Perceived and actual academic competence in maltreated children. Child
Abuse and Neglect, Vol. 25, 1 (2001) 33-45
3. LeDoux, J..The emotional brain: The mysterious underpinnings of emotional life.
Weiden¬feld & Nicholson, London (1998)
4. Goleman, D.: Emotional intelligence. Bantam Books, New York (1995)
5. Weimin Xue, Zhiliang Wang, Zhehua Wei. A new method for simulating human
emotions[J]. Journal of university of science and technology Beijing. Vol.10, No. 2, April.
2003,10（ 2） ） 72-74
6. Picard, R. W., Papert, S., Bender, W., Blumberg, B., Breazeal, C., Cavallo, D., Machover,
T., Resnick, M., Roy, D., Strohecker, C.: Affective Learning - A Manifesto. BT
Technology Journal Vol. 22, 4 (2004) 253-269
7. Luigi Anolli,etc The Potential of Affective Computing in E-Learning: MYSELF project
experience". Proceedings of INTERACT 2005 Conference - Workshop on eLearning and
Human-Computer Interaction: Exploring Design Synergies for more Effective Learning
Experiences, Rome, 12-15 September 2005.
8. Weimin Xue. Facial Expression Recognition Based on Gabor Filter and SVM. Chinese
Journal of Electronics [J]. October.2006, 15(4A):809~812.
9. Xue Weimin. Research on Speech Interaction of Affective Robot. Proceedings of the 7th
International Conference on Electronic Measurement and Instruments, ICEMI’2005. 16-18
Aug., 2005, Beijing, China, (7) :344~347.
10. Jiang Danning, Cai Lianhong. Speech emotion recognition using acoustic features. Journal
of Tsinghua University (Science and Technology).2006, 46(1):86-89

