Optimization of IG-Based Fuzzy System with the Aid of
GAs and Its Application to Software Process
Sung-Kwun Oh1, Keon-Jun Park1, and Witold Pedrycz2
1

Department of Electrical Engineering, The University of Suwon, San 2-2 Wau-ri,
Bongdam-eup, Hwaseong-si, Gyeonggi-do, 445-743, South Korea
ohsk@suwon.ac.kr
2
Department of Electrical and Computer Engineering, University of Alberta, Edmonton,
AB T6G 2G6, Canada and Systems Research Institute, Polish Academy of Sciences, Warsaw,
Poland

Abstract. We introduce an optimization of information granules (IG)-based
fuzzy model with the aid of genetic algorithms (GAs) to describe projects in
terms of complexity and development time in experimental software datasets.
The proposed fuzzy model implements system structure and parameter identification with the aid of IG and GAs. To identify the structure and the parameters
of fuzzy model we use genetic algorithms. The concept of information granulation was coped with to enhance the abilities of structural optimization of fuzzy
model. Granulation of information realized with Hard C-Means clustering help
determine the initial parameters of fuzzy model such as the initial apexes of the
membership functions in the premise part and the initial values of polynomial
functions in the consequence part of the fuzzy rules. And the initial parameters
are tuned effectively with the aid of the GAs and the least square method. An
aggregate objective function is constructed in order to strike a sound balance
between the approximation and generalization capabilities of the fuzzy model.
The experimental results include well-known software data such as medical imaging system (MIS).

1 Introduction
Fuzzy modeling has been studied to deal with complex, ill-defined, and uncertain
systems in many other avenues. The researches on the process have been exploited for a
long time. Linguistic modeling [2] and fuzzy relation equation-based approach [3] were
proposed as primordial identification methods for fuzzy models. The general class of
Sugeno-Takagi models [4] gave rise to more sophisticated rule-based systems where the
rules come with conclusions forming local regression models. While appealing with
respect to the basic topology (a modular fuzzy model composed of a series of rules) [5]
these models still await formal solutions as far as the structure optimization of the model
is concerned, say a construction of the underlying fuzzy sets—information granules
being viewed as basic building blocks of any fuzzy model. Some enhancements to the
model have been proposed by Oh and Pedrycz [6], yet the problem of finding “good”
initial parameters of the fuzzy sets in the rules remains open.
Y. Shi et al. (Eds.): ICCS 2007, Part IV, LNCS 4490, pp. 1108–1115, 2007.
© Springer-Verlag Berlin Heidelberg 2007

Optimization of IG-Based Fuzzy System with the Aid of GAs

1109

This study concentrates on the central problem of fuzzy modeling that is a development of information granules-fuzzy sets. Taking into consideration the essence of
the granulation process, we propose to cast the problem in the setting of clustering
techniques and genetic algorithms. Information granulation with the aid of C-Means
clustering help determine the initial parameters of fuzzy model such as the initial
apexes of the membership functions in the premise part and the initial values of polynomial function in the consequence part. And the initial parameters are tuned
(adjusted) effectively by means of the genetic algorithms and the least square method.
An aggregate objective function with some weighting factor is proposed so that we
could achieve a sound balance between accuracy and generalization abilities of the
fuzzy model. The model is applied to the medical imaging system (MIS) being widely
used in quantitative software engineering.

2 Information Granules
Roughly speaking, information granules (IG) [7], [8] are viewed as related collections
of objects (data point, in particular) drawn together by the criteria of proximity,
similarity, or functionality. Granulation of information is an inherent and omnipresent
activity of human beings carried out with intent of gaining a better insight into a
problem under consideration and arriving at its efficient solution. In particular,
granulation of information is aimed at transforming the problem at hand into several
smaller and therefore manageable tasks. In this way, we partition this problem into a
series of well-defined subproblems (modules) of a far lower computational
complexity than the original one. The form of information granulation themselves
becomes an important design feature of the fuzzy model, which are geared toward
capturing relationships between information granules.
Clustering is often regarded as a synonym of information granulation. The intent of
clustering is to find a structure in the data and reveal clusters – information granules
in the data set. The clustering algorithms have been used extensively not only to organize and categorize data, but it becomes useful in data compression and model
construction. The C-Means clustering [9] has been applied to a variety of areas, including image and speech data compression, data preprocessing of system modeling.

3 IG-Based Fuzzy Inference System (IG_FIS)
The identification procedure for fuzzy models is usually split into the identification
activities dealing with the premise and consequence parts of the rules. The
identification completed at the premise level consists of two main steps. First, we
select the input variables x1, x2, …, xk of the rules. Second, we form fuzzy partitions of
the spaces over which these individual variables are defined. The identification of the
consequence part of the rules embraces two phases, namely 1) a selection of the
consequence variables of the fuzzy rules, and 2) determination of the parameters of
the consequence (conclusion part). And the least square error method used at the
parametric optimization of the consequence parts of the successive rules.

1110

S.-K. Oh, K.-J. Park, and W. Pedrycz

3.1 Premise Identification
In the premise part of the rules, we confine ourselves to a triangular type of
membership functions whose parameters are subject to some optimization. The CMeans clustering helps us organize the data into cluster so in this way we capture the
characteristics of the experimental data. In the regions where some clusters of data
have been identified, we end up with some fuzzy sets that help reflect the specificity
of the data set. In the sequel, the modal values of the clusters are refined (optimized)
using genetic optimization, and genetic algorithms (GAs), in particular.
x2

y

A22

v22
v21

mk1

A21

μ

v11

μ A11

mk2
vk1

vk2

A12
x1

xk

(a) Clusters formed by C-Means clustering

v12

(b) Fuzzy partition and resulting MFs

Fig. 1. Identification of the premise part of the rules of the system

The identification of the premise part is completed in the following manner.
Given is a set of data U={x1, x2, …, xk ; y}, where xk =[x1k, …, xmk]T, y =[y1, …,
ym]T, k is the number of variables and , m is the number of data.
[Step 1] Arrange a set of data U into data set Xk composed of respective input data
and output data.
Xk=[xk ; y]

(1)

[Step 2] Determine the centers (prototypes) vkg with data set Xk using C-Means
clustering algorithms
[Step 2-1] Categorize data set Xk into c-clusters (in essence this is effectively the
granulation of information)
[Step 2-2] Calculate the center vectors vkg of each cluster.

v kg = {vk1 , vk 2 , …, vkc }

(2)

[Step 3] Partition the corresponding input space using the prototypes of the clusters
vkg. Associate each cluster with some meaning (semantics), say Small, Big, etc.
[Step 4] Set the initial apexes of the membership functions using the prototypes vkg.
3.2 Consequence Identification
We can also identify the structure of the consequence parts of rules by considering the
initial values of polynomial functions based upon the information granulation.
[Step 1] Find a set of data included in the fuzzy space of the j-th rule.
[Step 2] Compute the prototypes Vj of the data set by taking the arithmetic mean of
each rule.

Optimization of IG-Based Fuzzy System with the Aid of GAs

v j = {V1 j , V2 j , …, Vkj ; M j }

1111

(3)

[Step 3] Set the initial values of polynomial functions with the center vectors Vj.
The identification of the conclusion parts of the rules deals with a selection of their
structure that is followed by the determination of the respective parameters of the
local functions occurring there.
The conclusion is expressed as follows.
R j : If x1 is A1c and

and xk is Akc then y j − M j = f j ( x1 ,

, xk )

(4)

Type 1 (Simplified Inference): f j = a j 0
Type 2 (Linear Inference): f j = a j 0 + a j1 ( x1 − V j1 ) +

+ a jk ( xk − V jk )
(5)
Type 3 (Quadratic Inference):
Type 4 (Modified Quadratic Inference):
The calculations of the numeric output of the model, based on the activation
(matching) levels of the rules there, rely on the expression
n

∑
y =
*

n

∑w

w ji yi

j =1
n

∑

=

ji ( f j ( x1 ,

, xk ) + M j )

j =1

w ji

j =1

n

∑

n

=

∑ wˆ

w ji

ji ( f j ( x1 ,

, xk ) + M j )

(6)

j =1

j =1

If the input variables of the premise and parameters are given in consequence
parameter identification, the optimal consequence parameters that minimize the
assumed performance index can be determined. In what follows, we define the
performance index as the mean squared error (MSE).

PI =

1 m
∑ ( yi − yi* )2
m i =1

(7)

4 Optimization of IG-Based FIS
4.1 Genetic Algorithms
It has been demonstrated that genetic algorithms [10] are useful in a global
optimization of such problems given their ability to efficiently use historical
information to produce new and improved solutions. GAs are shown to support robust
search in complex search spaces. In particular, they are stochastic and less likely to
get trapped in local minima as we can witness quite often when dealing with gradientdescent techniques. GAs are population-based optimization techniques. The search of
the solution space is completed with the aid of several genetic operators. There are
three generic genetic operators such as reproduction, crossover, and mutation.
Reproduction is a process in which the mating pool for the next generation is chosen.
Individual strings are copied into the mating pool according to their fitness function
values. Crossover usually proceeds in two steps. First, members from the mating pool

1112

S.-K. Oh, K.-J. Park, and W. Pedrycz

are mated at random. Second, each pair of strings undergoes crossover as follows: a
position l along the string is selected uniformly at random from the interval [1, l-1],
where l is the length of the string. Swapping all characters between the positions k and
l creates two new strings. Mutation is a random alteration of the value of a string
position. In a binary coding, mutation means changing a zero to a one or vice versa.
Mutation occurs with small probability. Those operators, combined with the proper
definition of the fitness function, constitute the main body of the genetic computing.
In this study, in order to identify the fuzzy model we determine such a structure as
the number of input variables, input variables being selected and the number of the
membership functions standing in the premise part and the order of polynomial
(Type) in conclusion. The membership parameters of the premise are genetically
optimized. Figure 2 shows an arrangement of the content of the string to be used in
genetic optimization. Here, parentheses denote the number of chromosomes allocated
to each parameter.
Bits for no. Bits for Type of Bits for no. of input
of input(3) polynomial(3) variable to be selected(30)

1 1 0 1 0 1 0

Bits for no.
of MFs(5)

1 1 1

Bits for MFs apexes(no. of input*no. of MFs*(10~15))

0

100
populations

0 1 1

0 1 1

1 1 0

0 1 0

100
populations

0 1 0 0 1 1 0

1 0 1

0

(a) Data structure for structure identification (b) Data structure for parameters identification
Fig. 2. Data structure of genetic algorithms used for the optimization of fuzzy model

For the optimization of the fuzzy model, genetic algorithms use a binary bit string,
roulette-wheel in the selection operator, one-point crossover in the crossover operator,
and invert in the mutation operator. We also apply elitism to keep the best individual
across generations. Here, we use 150 generations and run the GA of a size of 100
individuals for structure identification. For parameter estimation, GA was run for 300
generations and the population was of size 100. We set up the crossover rate and
mutation probability to be equal to 0.65, and 0.1, respectively.

4.2 Objective Function with Weighting Factor
The objective function (performance index) is a basic mechanism guiding the
evolutionary search carried out in the solution space. The objective function includes
both the training data and testing data and comes as a convex combination of the two
components.
f ( PI , E _ PI ) = θ × PI + (1 − θ ) × E _ PI

(8)

Here, PI and E_PI denote the performance index for the training data and testing
(validation) data, respectively. θ is a weighting factor that allows us to form a sound
balance between the performance of the model for the training and testing data.
Depending upon the values of the weighting factor, several specific cases of the
objective function are worth distinguishing.

Optimization of IG-Based Fuzzy System with the Aid of GAs

1113

5 Experimental Studies
In this section, we consider a medical imaging system [11] subset of 390 software
modules written in Pascal and FORTRAN for modeling. These modules consist of
approximately 40,000 lines of code. To design an optimal model from the MIS, we
study 11 system input variables such as LOC, CL, TChar, TComm, MChar, DChar, N,
∧

N , NF, V(G) and BW. The output variable of the model is the number of changes
Changes made to the software module during its development. When applying any
modeling technique, an assessment of predictive quality is important. Data splitting is
a modeling technique that is often applied to test predictive quality. Applying this
technique, one randomly partitions the data set to produce two data sets. The first
60% data set is used for fitting the models. The remaining 40% data set, the testing
data set, provides for quantifying the predictive quality of the fitted models. We carried out the structure and parameters identification on a basis of the experimental data
using GAs to design IG-based fuzzy model. Table 1 summarizes the performance
index for IG-based fuzzy model.
Table 1. Performance index of IG-based fuzzy model

Model

θ

Identification
Structure

Input
variable
Tcomm
∧

0.0
Parameters

IG_FIS

0.5

Structure
Parameters

N
V(G)
TComm
MChar

No. Of
MFs

Type

2x3x2

Type 1

M_PI

PI

E_PI

33.867 54.841 33.867
26.836 63.005 26.836
2x3

Type 3

35.137 29.957 40.316
30.257 30.519 29.996

Figure 3 shows the partition of the spaces and their optimization for the IG-based
fuzzy model with MFs 2x3 and Type 3 for input variables TComm and MChar. Figure 4
depicts the values of the performance index produced in successive generations of the
genetic optimization at the same case.
HCM

IG based GAs

Small

Big

16.378

88.08

0.0002

106.37

(a) TComm

HCM
Small

IG based GAs

Middle

599.13
2071.2
832.14 1807.4

Big

7611.6
7262.7

(b) MChar

Fig. 3. Initial and optimized membership functions for the IG-based fuzzy model

1114

S.-K. Oh, K.-J. Park, and W. Pedrycz

33

36

30.7
30.65

32.5

35

30.6

34

30.55

32

31.5

E_PI

PI

M_PI

30.5
30.45

31

30.35

31

30.3

30.5

30

30.25

30
0

33
32

30.4

50

100

150
generation

200

250

300

30.2
0

50

100

150
generation

200

250

300

29

0

50

100

150
generation

200

250

300

Fig. 4. Optimal convergence process of performance index for IG-based fuzzy model

Table 2 contains a comparative analysis including the previous model. Regression
models are constructed by a linear equation. The comparative analysis reveals that the
proposed model comes with high accuracy and improved prediction (generalization)
capabilities with smaller rules.
Table 2. Comparison of identification error with previous models

Model

Selected inputs

No. of MFs(Rules)

Regression
Model [11]
SONFN [12]

All
TComm, MChar,
DChar, N
TComm, MChar,
DChar, N

2x2x2x2 (16)

Our model

TComm, MChar

2x3 (6)

Consequence.
Type

PIs

E_PI

40.056

36.322

43.849

38.917

2

39.179

23.864

3

30.519

29.996

6 Conclusions
In this paper, we have developed a comprehensive framework for IG-based fuzzy
system. We also showed how this model is used to apply software data. The
underlying idea deals with an optimization of information granules by exploiting
techniques of clustering and genetic algorithms. We defined some initial membership
functions and the polynomial functions by means of information granulation realized
with the C-Means clustering. The genetic algorithm was used afterwards to tune the
initial values of the membership functions. Genetic algorithms were also used for
further structural and parametric optimization of the fuzzy model. The experimental
studies show that the model is compact while its performance is better than some
other models previously discussed in the literature. Through the use of the certain
form of the performance we were able to achieve a balance between the
approximation and generalization abilities of the resulting model. While the detailed
discussion has been exclusively focused on triangular fuzzy sets, the developed
methodology applies equally well to other classes of fuzzy sets as well as various
types of nonlinear local models. The proposed models scale up quite easily and do not
suffer from the curse of dimensionality encountered in some other architecture of
rule-based systems.

Optimization of IG-Based Fuzzy System with the Aid of GAs

1115

Acknowledgements. This work was supported by the Korea Research Foundation
Grant funded by the Korean Government (MOEHRD)(KRF-2006-311-D00194, Basic
Research Promotion Fund).

References
1. Zadeh, L.A.: Fuzzy sets. Information and Control. 8 (1965) 338-353
2. Tong, R.M.: Synthesis of fuzzy models for industrial processes. Int. J Gen Syst. 4 (1978)
143-162
3. Pedrycz, W.: Numerical and application aspects of fuzzy relational equations. Fuzzy Sets
Syst. 11 (1983) 1-18
4. Takagi, T., Sugeno, M.: Fuzzy identification of systems and its applications to modeling
and control. IEEE Trans Syst, Cybern. SMC-15(1) (1985) 116-132
5. Sugeno, M., Yasukawa, T.: Linguistic modeling based on numerical data. In: IFSA’91
Brussels, Computer, Management & System Science. (1991) 264-267
6. Oh, S.K., Pedrycz, W.: Identification of fuzzy systems by means of an auto-tuning algorithm and its application to nonlinear systems. Fuzzy Sets and Syst. 115(2) (2000) 205-230
7. Zadeh, L.A.: Toward a theory of fuzzy information granulation and its centrality in human
reasoning and fuzzy logic. Fuzzy Sets and Syst. 90 (1997) 111-117
8. Pderycz, W., Vukovich, G.: Granular neural networks. Neurocomputing. 36 (2001)
205-224
9. Krishnaiah, P.R., Kanal, L.N., editors.: Classification, pattern recognition, and reduction of
dimensionality, volume 2 of Handbook of Statistics. North-Holland Amsterdam (1982)
10. Golderg, D.E.: Genetic Algorithm in search, Optimization & Machine Learning, Addison
Wesley (1989)
11. Lyu, M.R.: Handbook of Software Reliability Engineering. McGraw-Hill, New York.
1995 510-514
12. Oh, S.K., Pderycz, W., Park, B.J.: Self-organizing neurofuzzy networks in modeling software data. Fuzzy Sets and Systems. 145 (2004) 165-181
13. Park, H.S., Oh, S.K.: Fuzzy Relation-based Fuzzy Neural-Networks Using a Hybrid Identification Algorithm. International Journal of Control Automation and Systems. 1(3)
(2003) 289-300

