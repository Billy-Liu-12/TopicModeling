Research on Affective State Recognition in E-Learning
System by Using Neural Network
Egui Zhu1, Qizhen Liu1, Xiaoshuang Xu2, and Tinan Lei1
1

2

Faculty of Education, Hubei University, Wuhan 430062, China
College of Computer Science & Technology, Huazhong University of Science and
Technology, Wuhan 430000, China
zhuergui@yahoo.com.cn

Abstract. Aiming at current E-Learning system was not able to estimate the
affective state of the users , an intelligent affective state recognizer that used
facial expression as input was proposed and implemented in the paper. The
recognizer system consists of two neural network classifiers and a fuzzy logic
facial analysis module. The recognizer system had been used in an E-Learning
system to recognize the emotion state. The results manifested that the
recognizer system was effective. However, other bio-signals such as heartbeat,
skin resistance and voice tone could also be used for affective state recognition.
Keywords: E-Learning, Neural Network, Affecting Computing, Emotion
Deficiency.

1 Introduction
E-Learning uses modern educational technologies to implement an ideal learning
environment through integrating the information technology into curriculum, which
can embody the learning styles of students’ main-body function, reform the traditional
teaching structure and the essence of education thoroughly [1].
Although the current E-Learning systems have many merits, many of them only
treat advanced information technology as simple communication tools, and release
some learning contents and exercises in the network [2]. This kind of movable
textbook or electronic textbook is indifferent to the learners, which lacks of the
interaction of emotion. Besides, this kind of learning materials without using of the
superiority of interactive multimedia technology and displaying the function of
network effectively, which leads to the phenomenon of emotion deficiency in the
current E-Learning system.
Emotion recognition is one of the most fundamental and important modules. It is
always based on facial and audio information. At present, many scholars have carried
on a great of researches on facial emotion recognition method. For example, face
detection, face recognition, facial feature extraction, and some attempts at automatic
facial expression analysis have been made [3] [4]. It is only recently that researchers
are starting to integrate these techniques into systems that can make use of the
affective state of the user.
Y. Shi et al. (Eds.): ICCS 2007, Part III, LNCS 4489, pp. 575–578, 2007.
© Springer-Verlag Berlin Heidelberg 2007

576

E. Zhu et al.

The goal of the work presented in this paper is the analysis of people’s facial
expressions from an image using a combination and extension of existing algorithms.
Algorithms for face detection, feature extraction and face recognition were integrated
and extended to develop a facial expression analysis system that is used in current Elearning systems. The new facial expression analysis system uses a neural network
and fuzzy approach to interpret facial expressions. Although recognizing people’s
facial expression is a challenging task, it can lead to many exciting developments in
human-computer interaction.

2 System Framework
Fig.1 shows the overall framework of the intelligent affective state recognizer. The
affective state recognizer is composed of image Grabber, Pre-processing,
classification, feature extraction, and interpretation.

Fig. 1. System Framework

The workflow of system is as follows
The image of the user is captured by a web cam which is then preprocessed by a
neural network so that the position of the face in the image is identified. The next
phase identifies the user based on the database of known users using principle
component analysis. The final two stages consist of a facial feature extraction system
based on. Neural networks and an affective state estimator based on fuzzy logic. All
of the processing is completed at the client application side of the system. This means
that any online implementation of this system will only send the final affective state
of the user to the server side of the system providing only a small overhead. This

Research on Affective State Recognition in E-Learning System

577

chapter discusses in detail the two neural network classifiers used for face detection
and facial feature location and the fuzzy logic based affective state recognizer.

3 Key Technologies
3.1 Neural Network Based Face Detection
A sixteen by sixteen pixel sub-sample of the web cam image is selected and examined
to see if it is the region of the face. This is repeated for all sub-samples choosing the
best candidate face for further processing. A neural network approach is adopted, in
which the 256 pixel sub-sample image is given as input to a neural network that has
been trained to identify face images. There are 256 neurons as input, 40 neurons in
hidden layer one, 16 neurons in hidden layer two, and one output neuron. The transfer
functions are tan-sigmoid functions. The training data is taken from standard face
databases so that it is robust to variations in race, gender and age.
3.2 Eye Detection
Similar to face detection, a neural network was used to detect people’s eyes. An eye
database was extracted from the face database that was use for face detection. The eyes
were normalized to the same size and with the iris in the centre of the eye image. A
feed-forward back-propagation network was created for face detection. The network is
a 3 layers-structure. It has 2 hidden layers and 1-output layer. It also has 1 layer for
input. Each eye image is 18 pixels in width by 12 pixels in height forming a
rectangular image. So, there are 216 neurons as input, 8 neurons in hidden 216 inputs 8
hidden neurons 4 hidden neurons 1 output layer 1, 4 neurons in hidden layer 2, and 1
output neuron. The transfer functions are tan-sigmoid function. Using this approach the
exact position of the eyes in the image can be identified as well as the candidate point
for the eyebrows since they are invariably above the eye for an upright full frontal
image of the face.
3.3 Mouth Detection
Mouth detection is challenging because of the difficulty in modeling the shape of
mouth. Firstly, the lighting of the mouth region is corrected locally. Secondly, noise
in the mouth region of the image is eliminated using a wavelet transformation
algorithm. Thirdly, Sobel edge detection combined with Laplacian edge detection is
used followed by a morphing logic operation to fill in the holes. The largest blob
found by this procedure is the mouth. Once the mouth has been identified candidate
points for the mouth outline are available[5] [6].

4 Conclusion
An intelligent affective state recognizer that used facial expression as input was
proposed in the paper. The facial expression analysis system implemented is based on
a fuzzy approach. Six expressions, namely, happiness, anger, surprise, sadness, puzzled

578

E. Zhu et al.

and disgusted are detected. Fig.2 shows the affective state recognition software. The
bars in the boxes to the right of the image show the result of the intelligent expression
analysis. The longest bar is the best value and if it is significantly larger the other
remaining values a conclusive decision on the affective state of the user can be
estimated.

Fig. 2. Affective State Recognition Software

References
1. He Kekang.: E-Learning Essence- information technology into curriculum. E-education
Research, 105, 1, 2002, 3-4.
2. Wang Jijun.: Emotion deficiency and compensation in distance learning. Chinese network
education, 2005.
3. R.W.Picard.: Affective Computing. Cambridge. MIT Press, 1997.
4. R.W.Picard.: Affective Computing, Challenges. Cambridge. International Journal of Human
Computer studies, 59(1), 2003, 55-64.
5. X. Li and Q. Ji.: Active Affective State Detection and User Assistance with Dynamic
Bayesian Networks. Proceedings of Bayesian Modeling Applications Workshop, 2003.
6. M. Pantic and L.J.M. Rothkrantz.: Automatic Analysis of Facial Expressions, the State of
the Art. IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, 2000,
1424-1445.

