GPU-Accelerated Montgomery Exponentiation
Sebastian Fleissner
Department of Computer Science and Engineering
The Chinese University of Hong Kong
seb@cse.cuhk.edu.hk

Abstract. The computing power and programmability of graphics
processing units (GPUs) has been successfully exploited for calculations
unrelated to graphics, such as data processing, numerical algorithms, and
secret key cryptography. In this paper, a new variant of the Montgomery
exponentiation algorithm that exploits the processing power and parallelism of GPUs is designed and implemented. Furthermore, performance
tests are conducted and the suitability of the proposed algorithm for
accelerating public key encryption is discussed.
Keywords: GPGPU, Montgomery Exponentiation, Encryption.

1

Introduction

Chips on consumer graphics cards have evolved into programmable graphics
processing units (GPUs) capable of delivering real-time, photo-realistic eﬀects
in computer games and multimedia applications. According to an article by
Manocha [1], the computational power of GPUs has a growth rate faster than
Moore’s law as it applies to other microprocessors. As a result, researchers attempt to exploit the processing power and programmability of GPUs for general
purpose computing.
The purpose of this research is to investigate and realize the usage of GPUs for
accelerating the Montgomery exponentiation algorithm, which is used by various
public key encryption schemes, such as RSA and elliptic curves, for performing
modular exponentiation of large integers. In particular, a new, GPU-accelerated
Montgomery exponentiation algorithm is proposed and the performance of its
implementation is evaluated. Furthermore, the suitability of the proposed GPU
algorithm for accelerating public key encryption is discussed.
1.1

Paper Organization

The rest of the paper is organized as follows. Section 2 provides background
information. Sections 3 and 4 specify and evaluate the proposed GPU-accelerated
Montgomery exponentiation algorithm. Section 5 brieﬂy discusses public key
encryption schemes that are likely to beneﬁt from the proposed algorithm.
Y. Shi et al. (Eds.): ICCS 2007, Part I, LNCS 4487, pp. 213–220, 2007.
c Springer-Verlag Berlin Heidelberg 2007

214

2
2.1

S. Fleissner

Background
General Purpose GPU Computations

General purpose GPU computing (GPGPU) [2] refers to the concept of exploiting
the processing power of GPUs for performing general purpose calculations. Examples for GPGPU computing are data processing [3], evolutionary algorithms
[4], and secret key cryptography [5].
A typical GPGPU application consists of two parts. One part, which is denoted as the main program, runs on the computer’s main processor and is responsible for initializing the GPU, providing the GPU with input, and retrieving the
results produced by the GPU. The other part, which is denoted as the fragment
program, runs on the GPU and performs the desired general purpose calculation. The main program provides the operands for multiple calculations that are
performed on the GPU in parallel. Since GPUs have only limited support for
integer values, all data sent to and retrieved from GPUs is encoded using 32-bit
ﬂoating point values.
The main program and fragment program exchange data via textures. Hence,
the ﬁrst step performed by the main program is to create several 2D textures
inside the graphics memory, which serve as input and output buﬀers. After
their creation, the textures serving as input buﬀers are ﬁlled with the operands
for the general purpose calculation. After the textures are prepared, the main
program invokes the fragment program on the GPU by drawing a rectangle
with the same dimension as the textures. The GPU runs multiple instances
of the fragment program in parallel, and each instance retrieves and processes
the operands for a diﬀerent calculation from the input textures. The results
calculated by the fragment program instances are output as one or more 32 bit
ﬂoating point values. These values are passed to the GPU processing pipeline and
automatically stored in one or more designated output textures. The program
on the main processor can then access the output textures to obtain the results.
2.2

The Montgomery Method

The Montgomery method [6] and its various improvements [7,8,9] are algorithms
for eﬃcient computation of modular multiplications x = a×b mod n and modular
exponentiations x = ab mod n, with a, b, n being k-bit large integers and n being
odd.
As described in [10], the Montgomery algorithm consists of following steps:
1. Perform pre-computation
Choose a large integer r as a power of 2, with r > n. Then n is calculated,
so that r × r−1 − n × n = 1. Both r−1 and n can be calculated using the
extended Euclidian algorithm.
2. Obtain Montgomery representation of a and b
This step uses the r generated during the pre-computation step to transform
the operands a and b into Montgomery representation. Their Montgomery
representations are obtained by calculating a
¯ := a × r mod n and ¯b := b ×
r mod n.

GPU-Accelerated Montgomery Exponentiation

215

¯
3. Calculate Montgomery Product x
¯=¯
a×b
This step calculates the Montgomery product MonPro(¯
a, ¯b) = x
¯ := a
¯ ×¯b×r−1
mod n. The Montgomery product is calculated as follows:
(a) t := a
¯ × ¯b
(b) m := t × n mod r
(c) x := (t + m × n)/r
(d) if x ≥ n then set x = x − n
Montgomery Exponentiation. Because of the overhead caused by the precomputation and representation transformation steps, the Montgomery method
is used for modular exponentiation rather than a single modular multiplication.
A common form of the Montgomery exponentiation algorithm, which is described
in [10], uses the so-called binary square-and-multiply method to calculate x = ab
mod n, where a, b, n are k-bit large integers and n is odd. With |b| being the
bit length of operand b, the algorithm consists of the following steps:
Use n to pre-compute n and r.
Calculate a
¯ := a × r mod n.
Calculate x
¯ := 1 × r mod n.
For i := |b| - 1 down to 0 do
(a) Calculate x
¯ := MonPro(¯
x,¯
x)
(b) If the i-th bit of b is set, then calculate x
¯ := MonPro(¯
a,¯
x)
5. Calculate x = MonPro(¯
x,1).

1.
2.
3.
4.

3
3.1

Proposed Algorithm
Overview

This section proposes a new, GPU-accelerated exponentiation algorithm based
on the Montgomery method introduced in section 2.2. This algorithm, denoted as
GPU-MonExp, exploits the parallelism of GPUs by calculating multiple modular
exponentiations simultaneously. The exponentiation operands have a ﬁxed bit
size, which depends on the output capabilities of the GPU hardware.
Like the Montgomery exponentiation algorithm introduced in section 2.2, the
GPU-MonExp algorithm depends on the Montgomery product. As a result, this
section ﬁrst describes a GPU-accelerated variant of the Montgomery product
denoted as GPU-MonPro, which forms the basis of the GPU-MonExp algorithm.
As GPUs have limited support for integer values, the proposed GPU algorithms split large integers into k 24-bit chunks, and store each chunk in a 32-bit
ﬂoating point value. The ﬁrst chunk contains the least signiﬁcant bits and the
last chunk contains the most signiﬁcant bits of the large integer. Hence, the
representation of a large integer x is:
x = x[0], x[1], ..., x[k]

(1)

216

3.2

S. Fleissner

GPU Montgomery Product(GPU-MonPro)

The GPU-MonPro algorithm utilizes the GPU to calculate c Montgomery products in parallel:
(2)
x¯i := a¯i × b¯i × r−1 mod ni , 1 ≤ i ≤ c
The GPU-MonPro algorithm uses large integers with a pre-deﬁned, ﬁxed bit
size. Because of the ﬁxed bit size, the maximum size of the ni operands is known,
and by considering that r > n and r = 2z for some z, the value of the operand r
can be pre-deﬁned as well in order to simplify calculations. As graphics processing units do not provide any eﬃcient instructions for performing bitwise operations, the GPU-MonPro algorithm uses an operand r that is a power of 256.
Thus, multiplication and division operations by r can be implemented via byte
shifting, which can be performed eﬃciently by GPUs. Since the large integers
used by the algorithms in this chapter consist of k 24-bit chunks, the value of r
is pre-deﬁned as r = 2563k .
As r is pre-deﬁned, the input values for the GPU-MonPro algorithm are a¯i , b¯i ,
ni , ni . These input values are supplied by the GPU-MonExp algorithm described
in section 3.3.
The GPU-MonPro algorithm consists of two steps: Texture preparation and
calculation of the Montgomery product.
Step 1: Texture preparation [Main Processor]. The GPU-MonPro algorithm uses multiple two-dimensional input and output textures in RGBA color
format. An RGBA texel (texture element) consists of four 32-bit ﬂoating point
values and can thus be used to encode four 24-bit chunks (96 bit) of a large
integer. The algorithm uses four types of input textures corresponding to the
four types of operands: tex-¯
a, tex-¯b, tex-n, and tex-n . Assuming input textures
with a dimension of w × h to calculate c = w × h Montgomery products, the
GPU-MonPro algorithm uses the following approach to store the operands a¯i ,
b¯i , ni , ni in the input textures:
1. For each 0 ≤ x < w, 0 ≤ y < h do:
2. i := y × w + x
a texture(s)
3. Store a
¯i in the tex-¯
(a) tex-¯
a[0] (x,y) = a
¯i [0, 1, 2, 3] 1
(b) tex-¯
a[1] (x,y) = a
¯i [4, 5, 6, 7]
(c) ...
(d) tex-¯
a[k/4] (x,y) = a
¯i [k − 4, k − 3, k − 2, k − 1]
4. Store ¯bi in the tex-¯b texture(s)
(a) tex-¯b[0] (x,y) = ¯bi [0, 1, 2, 3]
(b) ...
(c) tex-¯b[k/4] (x,y) = ¯bi [k − 4, k − 3, k − 2, k − 1]
5. Store ni in the tex-n texture(s)
(a) tex-n[0] (x,y) = ni [0, 1, 2, 3]
(b) ...
(c) tex-n[k/4] (x,y) = ni [k − 4, k − 3, k − 2, k − 1]
1

The term a
¯i [0, 1, 2, 3] is an abbreviation for the four values a
¯i [0], a
¯i [1], a
¯i [2], a
¯i [3].

GPU-Accelerated Montgomery Exponentiation

217

6. Store ni in the tex-n texture(s)
(a) tex-n[0] (x,y) = ni [0, 1, 2, 3]
(b) ...
(c) tex-n[k/4] (x,y) = ni [k − 4, k − 3, k − 2, k − 1]
Considering a large integer as k 24-bit chunks, the total number of textures
required for storing the operands a¯i , b¯i , ni , ni is k4 4 = k. (There are four operands
and each texel can store four 24-bit chunks). The number of required output
textures is k4 .
After the input and output textures are prepared, drawing commands are
issued in order to invoke the fragment program instances on the GPU.
Step 2: Calculation of Montgomery product [GPU]. Each instance of
the fragment program on the GPU calculates one modular product. Since the
GPU hardware runs multiple instances of the fragment program in parallel,
several modular products are calculated at the same time. Apart from the input
textures containing the a¯i , b¯i , ni , and ni values, each fragment program instance
receives a (X, Y) coordinate pair that indicates which operands a
¯, ¯b, n, and
n should be retrieved from the input textures to calculate the Montgomery
product.
The algorithm performed by the fragment program instances, which is essentially a standard Montgomery multiplication, is as follows:
1. Use the X and Y coordinates to obtain the four operands a¯j , b¯j , nj , and nj
for some speciﬁc j, with 1 ≤ j ≤ c.
2. Calculate t := a¯j × b¯j . Because the maximum bit size of the operands is
pre-deﬁned, multiplication can be implemented eﬃciently on GPUs using
vector and matrix operations, which are capable of calculating multiple partial products in parallel.
3. Calculate m := t × nj mod r. Since r is a multiple of 256, the reduction by
modulo r is achieved by byte shifting.
4. Calculate x
¯ := (t + m × nj )/r. By using the vector and matrix operations
of the GPU, addition can be implemented eﬃciently, since partial sums can
be calculated in parallel. The division by r is achieved by byte shifting.
5. Output x
¯, which is automatically diverted and stored in the output textures.
3.3

GPU Montgomery Exponentiation (GPU-MonExp)

The GPU-MonExp algorithm calculates c modular exponentiations in parallel:
xi = abi mod ni , 1 ≤ i ≤ c

(3)

Each of the c exponentiations uses the same b, but diﬀerent values for each
ai and ni . With |b| denoting the ﬁxed bit size of operand b, the GPU-MonExp
algorithm executes the following steps:

218

S. Fleissner

1. Execute the following loop on the main processor:
For i := 1 to c do
(a) Use ni to pre-compute ni .
(b) Calculate x¯i := 1 × r mod ni .
(c) Calculate a¯i := ai × r mod ni .
2. Execute the following loop on the main processor:
For l := |b| − 1 down to 0 do
(a) Invoke GPU-MonPro to calculate
x¯i := x¯i × x¯i × r−1 mod ni on the GPU in parallel. (1 ≤ i ≤ c)
(b) If the l-th bit of b is set, then invoke GPU-MonPro to calculate x¯i :=
a¯i × x¯i × r−1 mod ni on the GPU in parallel. (1 ≤ i ≤ c)
3. Invoke GPU-MonPro to calculate the ﬁnal results
xi = x¯i × 1 × r−1 mod ni on the GPU in parallel. (1 ≤ i ≤ c)
Step 1 Details. The pre-computation loop, which is executed on the main
processor, calculates a corresponding ni for each ni using the extended Euclidian
algorithm. If all modular products to be calculated use the same n, then only
one n is computed, since n only depends on n and not on the multiplicand and
multiplier. Apart from the ni values, the loop determines the initial values for
all x¯i and the Montgomery representations of all ai .
Step 2 Details. The main loop of the GPU-MonExp algorithm is run on
the main processor and uses the square-and-multiply approach to calculate the
modular exponentiations. The main loop ﬁrst invokes GPU-MonPro with the x¯i
values as texture parameters in order to calculate the squares x¯i × x¯i × r mod
ni on the GPU in parallel. Depending on whether the current bit of operand
b is set, the algorithm invokes GPU-MonPro again with x¯i and a¯i as texture
parameters to calculate the Montgomery products x¯i × a¯i × r mod ni on the
GPU in parallel. After the main loop completes, the ﬁnal results xi = abi mod
ni are transferred back to the main processor.

4
4.1

Algorithm Evaluation
Performance Test Overview

This section introduces and analyzes the results of performance tests, which
were conducted in order to evaluate the potential of the proposed GPU-MonExp
algorithm. In order to obtain representative test data, three diﬀerent hardware
conﬁgurations were used to run the performance tests. The details of these three
test systems, which are denoted as system A, B, and C, are shown in table 1.
The GPU-MonExp performance test works as follows. As a ﬁrst step, the
implementation of the GPU-MonExp algorithm is run with random 192-bit
operands for 1 to 100000 exponentiations. The execution time TGP U is measured
and recorded. Then an implementation of the square-and-multiply Montgomery
exponentiation algorithm described in section 2.2 is run with the same input

GPU-Accelerated Montgomery Exponentiation

219

Table 1. Test Systems
System Processor/Memory/Graphics Bus GPU
A
Intel Pentium 4, 2.66 GHz
NVIDIA GeForce 6500
1 GB RAM, PCI-Express
256 MB RAM
B
Intel Celeron, 2.40 GHz
NVIDIA GeForce FX 5900 Ultra
256 MB RAM, AGP
256 MB RAM
C
Intel Pentium 4, 3.20GHz
NVIDIA GeForce 7800 GTX
1 GB RAM, PCI-Express
256 MB RAM

on the computer’s main processor, and its execution time, denoted as TSQM , is
recorded as well. Using the execution times of both implementations, the following speedup factor of the GPU-MonExp algorithm is determined:
s=

TSQM
TGP U

(4)

If the implementation of the GPU-MonExp algorithm runs faster than the
square-and-multiply Montgomery exponentiation, then its execution time is
shorter and s > 1.
The implementations of the GPU-MonExp and the underlying GPU-MonPro
algorithm are based on OpenGL, C++, and GLSL (OpenGL Shading Language).
The second step of GPU-MonPro described in section 3.2 is implemented as a
GLSL fragment program. The parts of the GPU-MonExp algorithm running on
the main processor are implemented in C++.
4.2

Test Results

Overall, the test results indicate that the GPU-MonExp algorithm is signiﬁcantly
faster than the square-and-multiply Montgomery exponentiation, if multiple
results are calculated simultaneously. When a large amount of modular exponentiations is calculated simultaneously, the GPU-MonExp implementation is
136 - 168 times faster.
Table 2. GPU-MonExp Speedup Factors
Exponentiations System A
1
0.2264
3
1.2462
10
4.0340
50
19.5056
100
33.2646
10000
138.0390
100000
168.9705

System B
0.0783
0.4843
1.2878
6.4544
13.0150
110.9095
136.4484

System C
0.1060
0.8271
2.9767
13.2813
25.6985
138.8840
167.1229

As shown in table 2, GPU-MonExp already achieves a performance gain when
3 to 10 exponentiations are calculated simultaneously. When calculating 100000

220

S. Fleissner

exponentiations simultaneously, the speedup factors are 168.9705 for system A,
136.4484 for system B, and 167.1229 for system C.

5

Conclusions

This paper introduces the concept of using graphics processing units for accelerating Montgomery exponentiation. In particular, a new GPU-accelerated
Montgomery exponentiation algorithm, denoted as GPU-MonExp, is proposed,
and performance tests show that its implementation runs 136 - 168 times faster
than the standard Montgomery exponentiation algorithm.
Public key encryption algorithms that are based on elliptic curves deﬁned over
prime ﬁelds (prime curves) are likely to beneﬁt from the proposed GPU-MonExp
algorithm, which can serve as the basis for GPU-accelerated versions of the point
doubling, point addition, and double-and-add algorithms. Signcryption schemes
based on elliptic curves, such as [11,12], are a possible concrete application for
the GPU-MonExp algorithm.

References
1. Manocha, D.: General-purpose computations using graphics processors. Computer
38(8) (August 2005) 85–88
2. Pharr, M., Fernando, R.: GPU Gems 2 : Programming Techniques for HighPerformance Graphics and General-Purpose Computation. Addison-Wesley (2005)
3. Govindaraju, N.K., Raghuvanshi, N., Manocha, D.: Fast and approximate stream
mining of quantiles and frequencies using graphics processors. In: SIGMOD ’05,
New York, NY, USA, ACM Press (2005) 611–622
4. M. L. Wong, T.T.W., Foka, K.L.: Parallel evolutionary algorithms on graphics
processing unit. In: IEEE Congress on Evolutionary Computation 2005. (2005)
2286–2293
5. Cook, D., Ioannidis, J., Keromytis, A., Luck, J.: Cryptographics: Secret key cryptography using graphics cards (2005)
6. Montgomery, P.L.: Modular multiplication without trial division. Mathematics of
Computation 44(170) (April 1985) 519–521
7. Gueron, S.: Enhanced montgomery multiplication. In: CHES ’02, London, UK,
Springer-Verlag (2003) 46–56
8. Walter, C.D.: Montgomery’s multiplication technique: How to make it smaller and
faster. Lecture Notes in Computer Science 1717 (1999) 80–93
9. WU, C.L., LOU, D.C., CHANG, T.J.: An eﬃcient montgomery exponentiation
algorithm for cryptographic applications. INFORMATICA 16(3) (2005) 449–468
10. Koc, C.K.: High-speed RSA implementation. Technical report, RSA Laboratories
(1994)
11. Zheng, Y., Imai, H.: Eﬃcient signcryption schemes on elliptic curves. In: Proc. of
IFIP SEC’98. (1998)
12. Han, Y., Yang, X.: Ecgsc: Elliptic curve based generalized signcryption scheme.
Cryptology ePrint Archive, Report 2006/126 (2006)

