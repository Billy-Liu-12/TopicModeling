A New Hybrid Optimization Algorithm
Framework to Solve Constrained Optimization
Problem
Huang Zhangcan1 and Cheng Hao2
2

1
School of Science, Wuhan University of Technology, Wuhan 430070, China
School of Mechanical and Electrical Engineering, Wuhan University of Technology,
Wuhan 430070, China
{huangzc,h.cheng}@whut.edu.cn

Abstract. Evolutionary Computation made great success from the theory of natural selection devised by Charles Darwin. It was a process
of randomly searching but not emphasizing each individuals respective
functions. This paper proposed a hybrid optimization algorithm framework trying to incorporate natural selection and survival of the ﬁttest
and birds of a feather ﬂock together. Aiming at balancing search results
and search speed, we adopted the search strategy to classify the individuals by their ﬁtness. Individuals classiﬁcation diﬀerentiated respective
function in search process, thats the excellent individuals mine the local
optimal solution and others explore the search domain to ﬁnd new local
optimal solution. Experimental ﬁndings support the theoretical basis of
the proposed framework.

1

Introduction

Solving a constrained optimization problem with inequality, upper bound, and
lower bound constraints usually includes mathematical model building and algorithm designing. Many methods have been posed from Newton Method, Linear
Search to Evolutionary Computation [1], which has respective characteristics.
Evolutionary computation from the theory of Natural Selection and Survival of
the Fittest has long been accepted as a powerful search tool in both academia and
industry, with numerous applications in varies science and engineering problem.
The Darwinian-type evolutionary computation uses mutation (an asexual reproduction with variation), crossover (a recombination or sexual reproduction)
and selection (survival of the ﬁtness). These operators are simple to execute
and domain-independent [2]. Michalski employs machine learning to generate
new populations, called Learnable Evolutionary Model, brieﬂy LEM. LEM integrated machine learning and evolutionary computation, which focused on why
certain individuals are superior to others [3]. SUN employs similartaxis and dissimilation instead of crossover and mutation operators in Mind Evolutionary
Computation, brieﬂy MEC [4]. For low eﬃciency of conventional methods to
dealing with highly complex problems, more methods like LEM, MEC trying to
Y. Shi et al. (Eds.): ICCS 2007, Part IV, LNCS 4490, pp. 1005–1012, 2007.
c Springer-Verlag Berlin Heidelberg 2007

1006

Z. Huang and H. Cheng

emphasis individuals characteristics. The novel idea proposed in this research
is to incorporate ”birds of a feather ﬂock together”, a universal rule of human
activity and ”natural selection and survival of the ﬁttest”, Darwinian-type EC
together to arrange each individual respective functions.
One of the most critical of these features is perhaps that how to build eﬀective algorithm framework to solve more and more complex mathematical model.
Jim Gray believes a good long-range goal should have ﬁve key properties: Understandable, Challenging, Useful, Testable, Incremental [5]. According to these
rules, we try to build a hybrid optimization algorithm framework which focus
on two goals. One is to unify the optimization problems into a framework and
then use the framework to guide the mathematical models building, the other is
to incorporate diﬀerent algorithms search kernel.
Subsequent sections of this paper deal with this issue of usage of the framework
to design algorithm to solve constrained optimization problem. The organization
of the paper is as follows: In Section 2 deﬁnes the general constrained optimization problems. Section 3 presents the framework and its major functional
aspects. Some experimental results and discussions are presented in Section 4,
while conclusions are drawn in Section 5.

2

Statement of the Problem

The general constrained optimization problem can be deﬁned as follows:
minimize f (x)
subject to gj (x) ≤ 0, j = 1, ..., J
hm (x) = 0, m = 1, ..., M
U
xL
i ≤ xi ≤ xi , i = 1, ..., n

(1)

where f (x) is an objective function, x is the vector of decision variables x =
[x1 , x2 , ..., xn ], J is the number of inequality constraints, and M is the number of
equality constraints (objective function, constraints could be linear or nonlinear).
U
xL
i and xi are the upper bound and the lower bound of xi , respectively. Denote
with F to the feasible region and with S to search space. The feasible solutions
exist in F ⊆ S.

3

Description of Hybrid Optimization Algorithm
Framework

In our previous work, multi-population adaptive-gathering evolutionary algorithm [6] using domains of attraction to separate and gather the initial population automatically to deal with function optimization, which divide the entire
search space of objective function into several domains. In another paper, neighborhood exploring evolutionary strategy [7] consists of assigning neighborhood of
diﬀerent size to diﬀerent solution to deal with multi-objective optimization problem. The population classiﬁcation and neighborhood assignment behind these
ideas are also the foundation of the Hybrid Optimization Algorithm Framework
as our forward work.

A New Hybrid Optimization Algorithm Framework

3.1

1007

Population Classiﬁcation

The ﬁrst critical step in the process of the framework is to calculate the individuals’ ﬁtness at every generation and to sort the population by their ﬁtness.
The individuals are selected randomly and they have their performance, better
or worse. Most Evolutionary Computation algorithms work with population of
ﬁxed size keeping at least the best individual always in the current population
[1]. No signs indicate part of the worse individuals remain in next population
will hinder optimum seeking. If we ignore some worse individuals we lost the
diversity of the population especially in multi-modal objective function space.
Based on this idea, we intend to classify the population into several levels in the
current population. We assign individuals in each level with diﬀerent tasks to
generate new oﬀspring. The individuals in the next population will be selected
from each level. Hence, we arrange each individual respective function and at
the same time keep the diversity of the population.

Fig. 1. Illustration of generating new oﬀspring using (1+λ)-ES. The black dots denote
father individuals and the grey dots denote oﬀspring.

Figure 1 illustrates an example of such classiﬁcation. There are ﬁve solutions
in the solution space that are classiﬁed into three group, 1,2,3,4,5according to
the individual’s ﬁtness. We assign each solution a level, for instance, in Figure 1,
solution 1 in level 1, solution 2, 3 in level 2, solution 4, 5 in level 3.
3.2

Neighborhood Assignment

After population classiﬁcation, the next step is to decide the neighborhood for
every solution in the population. The neighborhood is designed in the decision
variable space and the actual shape of the neighborhood can be various.

1008

Z. Huang and H. Cheng

In this way, we can assign neighborhood to each level. The solutions with
lower levels have small sized neighborhood and vice verse. The solutions in the
same level have same sized neighborhood. For convenience, we use a circle denote
a neighborhood and several diﬀerent neighborhoods are showed in Figure 1.
3.3

(1+λ)-ES (Evolutionary Strategy) Selection

(1+ λ)-ES is an eﬃcient selection method in evolutionary strategy, which generates λ oﬀspring using the information 1 individual in the population [2]. The
(1+λ)-ES can be used to generate new oﬀspring. In this case, the individual in
the level 1 uses (1+1)-ES, level 2 uses (1+2)-ES and level 3 uses (1+3)-ES.
3.4

Hybrid Optimization Algorithm Framework

Evolutionary algorithms deserve a special mention as powerful global optimizers,
but which not emphasis on each individuals’ respective function. It is a main
diﬃcult to balance search speed and result.

Fig. 2. The proposed optimization algorithm framework

We try to arrange the task to each individual from the theory of Birds of a
Feather Flock Together. No matter how the optimization objects and objective
changed, the characters of objectives on optimization objects have two respects.
Firstly, capability similarity, that’s ordinary individuals gather to excellent individuals. Secondly, structure similarity, that’s those individuals with similar
capability have similar structure in some kinds.

A New Hybrid Optimization Algorithm Framework

1009

The Hybrid Optimization Algorithm Framework is based from randomly population search. To explain how the framework works, we consider an optimization problem as the object and the object functions as their characteristics. By
judging each characteristic, we classify the population into diﬀerent level. By
competition among the called ordinary individuals and excellent individuals, we
arrange their respective tasks. That is by cooperation among ordinary individuals to explore hopefully domain with global searching and excellent individuals
to mine the local minima with local searching (see Figure 2).
3.5

Using the Framework to Design Algorithm

Under the guidance of the framework, we can design algorithms to solve constrained optimization problems. The process can be described as following:
Randomly initialize objects S(0)
Evaluate S(0)
t=0
while the termination condition is not satisfied
Classify objects into k levels by the evaluated fitness
Generate new individuals S’ in each level using father
individuals’ level
Add S’ to S
t=t+1
end while
How to classify objects into k levels according to the problem’s complex and
the human personal experience. We consider individuals’ similarity in their characteristic.
f (x∗min ) + kp L < f (xi ) ≤ f (x∗min ) + p+1
k L
(2)
xi ∈ p level, p = 1, 2, ..., k − 1
Where xi ∈ S, f (xi ) is the ﬁtness of each individual (see Equation (3),(4)) and
L is the distance between two individuals (see Equation (5)).

4

f (x∗max ) = maxf (xi )

(3)

f (x∗min ) = minf (xi )

(4)

L = maxf (xi ) − minf (xi )

(5)

Statement of the Problem

Examples mentioned in this chapter are representatives of diﬀerent kinds of
functions. Example 1 is cited from Ref.[8], which has been known that when
n = 2 , the function has 720 local optimal solutions, 18 of which are global
optimal solutions. Example 2 is cited from Ref.[9], which is nonlinear and its

1010

Z. Huang and H. Cheng

global modal is unknown. We adopted real code and the experiment parameters
are: population size N = 20, initialized radius r0 = c2p−1 and level k = 4. Here,
p is the individual’s level, c is a constant, which is set by domain radius.
Example 1: n-demension Shubert function
min f (x1 , x2 , ..., xn ) =

n
i=1

5
j=1

j cos((j + 1)xi + j)
x1 ∈ [−10, 10], i = 1, 2, ..., n

(6)

Fig. 3. (a)Distribution of Initial population and its levels. (b)distribution of the 12th
generation. (c)Curve of convergence.

Table 1. Results observed under diﬀerent contractive ratio c
c
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3

Average
Running
Times
Average
modals found times approaching modals generations running
3
6
5
5
4
3
2
1

10
10
10
10
10
10
10
10

5
9
10
10
10
10
10
10

730
88
46
30
23
17
14
11

Example 1 is a high-dimension function, which have 18 global optimal solutions (see Figure 3). At 12th generation the algorithm obtained global solutions.
To test the eﬀects of the parameters on the algorithm, we varied the ratio
c on Shubert function. The result can be viewed in Table 1. When c = 1, the
searching process is global searching, not decreasing the convergence speed but
found few modals. When c = 0.9, 0.8, 0.7, more modals were found and speed
up the convergence speed. When c = 0.6, 0.5, 0.4, 0.3, modals can be found in
each run quickly, but more modals were failed to ﬁnd. From the above result,
we can see for ordinary optimization problems, the c should be in 0.6 to 1. From
the point of searching, the smaller searching domain is the easier to converge to

A New Hybrid Optimization Algorithm Framework

1011

local minima. When holding a larger c and in a larger searching domain, it is
more easy to ﬁnd global minima. When decrease c, the algorithm has a quick
convergence speed but probably the result is local minima.
Example 2: Bump Function
f (X) = −|
n
i=1

xi ≥ 0.75,

n
i=1

n
i=1

cos4 (xi )−2

√

n
i=1

n
i=1
ix2i

cos2 (xi )

|

xi ≤ 0.75n, 0 ≤ xi ≤ 10, i = 1, 2, ...n

(7)

Table 2. Results of bump function in 20, 50, 100 dimension
Dimensions

20

50

100

Framework -0.803615 - 0.835196 - 0.842786
Ref.[8],[9] -0.8035 - 0. 8352620 -0.8410

Example 2 is a high-dimension bump function, which is very diﬃcult to solve.
Generally, we get satisﬁed results in 20, 50, 100 dimensions (see Table 2).

5

Conclusion and Future Works

In this study, natural selection and survival of the ﬁttest, birds of a feather ﬂock
together, are incorporated into a hybrid optimization algorithm framework by
arranging each individual’s task.
With regards to algorithm from the framework, further work is necessary to
improve the method of individuals’ classiﬁcation and local speed search. Also,
the way of deciding the proper contractive ratio c should be devised. The used
methodc is set to 0.7, but there may be a more appropriate value to enhance
the quality of convergence. It may be desirable to devise a guide to choose the
proper value of c. To test the high dimensional bump function is a remarkable
performance, we just adopted simply acceleration and many excellent methods,
like greedy algorithm, are value to test in the framework, how to make them
cooperate perfectly is our future work.

References
1. Christian Blum, Andrea Roli: Metaheuristics in Combinatorial Optimization:
Overview and Conceptual Comparison. ACM Computing Surveys, 35 (3). ACM,
Inc., New York (2003) 268-308
2. Zbigniew Michalewicz, David B.Fogel: How to Solve it: Modern Heuristics. SpringerVerlag Berlin Heidelberg.(2000)

1012

Z. Huang and H. Cheng

3. Ryszard S.Michalski: Learnable Evolutionary Model: Evolutionary Processes
Guided by Machine Learning. Machine Learning. 38 (1-2). Springer, Netherlands
(2000) 9-40
4. Sun Chengyi, Zhou Xiuling, Wang Wanzhen: Mind Evolutionary Computation and
Applications. Journal of Communication and Computer. 1 (1). USA-China Business
Review (Journal), Inc., USA (2004) 13-21
5. Jim Gray: What Next? A Dozen Information-Technology Research Goals. Journal
of the ACM, 50 (1). ACM, Inc., New York (2003) 41-57
6. Chen Siduo, Huang Zhangcan: Multi-population adaptive-gathering evolutionary
algorithm in function optimization. Proceedings of the 2000 Evolutionary Computation Congress, 1. IEEE (2000) 817-821
7. Hu Xiaolin, Carlos A. Coello Coello, Huang Zhangcan: A New Multi-objective Evolutionary Algorithm: Neighborhood Exploring Evolution Strategy. Engineering Optimization, 37. Taylor and Francis Ltd, UK(2005) 351-379
8. Huang Yuzhen, Kang Lishan, Zhou Aimin: Two-Phase Genetic Algorithm Applied
in the Optimization of Multi-Modal Function. Wuhan University Journal of Natural
Sciences, 8. Wuhan University Journals Press, Wuhan(2003) 259-264
9. Kang Zhuo, Li Yan, Liu Pu, et al: Two Asynchronous Parallel Algorithms for Function Optimization. Wuhan University Journal of Natural Sciences, 48 (1). Wuhan
University Journals Press, Wuhan (2002)33-36

