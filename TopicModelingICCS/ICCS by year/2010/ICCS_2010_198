Procedia
Computer
Science

ProcediaComputer
Computer Science
(2009) 2521–2528
000–000
Procedia
Science 00
1 (2012)

www.elsevier.com/locate/procedia
www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Stereoscopy based 3D face recognition system
Emanuele Zappaa, Paolo Mazzolenia, Yumei Haib*
a

Politecnico di Politecnico di Milano, Dipartimento di Meccanica, via La Masa 34, 20156 Milan, Italy
Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China

b

Abstract
This paper presents an innovative facial recognition algorithm: a stereoscopic calibrated system acquires two images of a subject
that are then separately analyzed by an active appearance model code which extracts from each of them 58 homologous points.
The triangulation of these points allows the construction of a three-dimensional mask of the face of the individual. This mask is
then compared against a database of reference masks. The obtained results are encouraging: preliminary tests on a limited
database showed a false rejection rate identically equal to zero and a false acceptance rate of about 3%.
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝
Keywords:face; biometric; identification; recognition; 3D; active appearance model; AAM

1. Introduction
The capability of correctly recognizing the identity of a person is becoming an increasingly important matter in
the nowadays society. Existing methods can be classified into three main groups: (I) possession, something that you
have, like a key or a badge, (II) knowledge, for example a PIN or a password, and (III) being (biometrics), referred
to all those methods for recognizing humans based upon intrinsic behavioral (e.g. voice analysis, signature
verification) or physical traits, as hand geometry, iris appearance and face based identification. [1,2].
The latter, mainly thanks to its characteristic of low intrusiveness [3], is one of the most studied [4] and the topic
of this work.
Facial recognition systems can be classified macroscopically in two-dimensional (2D), three-dimensional (3D)
and mixed codes [5].
The first type of algorithms (2D) has their main the advantage in requiring, both in the reference database and for
the "new" individual to be compared, simple photographs.

* Corresponding author: Paolo Mazzoleni Tel.: +39 02 2399 8584.
E-mail address: paolo2.mazzoleni@mail.polimi.it

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.285

2522

E. Zappa et al. / Procedia Computer Science 1 (2012) 2521–2528
Zappa, Mazzoleni, Hai/ Procedia Computer Science 00 (2010) 000–000

The main disadvantages are related to the decay in the reliability of the identification changing the position of the
subject with respect to the camera [6] and the intrinsic incapability for the system to distinguish between a real
subject and a picture of him placed in front of the camera.
Three-dimensional recognition systems have generally opposed the pros and cons: on one hand the scan of the
face is very accurate, performed by acquiring hundreds of points of the face with very low uncertainty; on the other
hand, acquisition generally requires time to be executed and this makes these systems in fact inapplicable in a real
context [9].
Mixed systems therefore born [10], where a three-dimensional scan, acquired during the database creation, is
projected onto a classic photo: a reduction of the required time is however associated with loss of part of the
information.
This paper proposes a purely three-dimensional less time consuming approach: this approach consists of the
triangulation of two clouds of points extracted from a stereoscopic image. The acquisition time is the same of taking
a photo but it is however possible to measure the three-dimensional position of a large number of points (58, in this
work). Moreover, the selected points are mostly significant points for the recognition (e.g. eye contour) while all
those areas of the face of little biometric interest are neglected (as the chin surfaces).

2. Proposed Recognition Technique
Many different codes have been developed to analyze images and automatically extract relevant features
positions from them [4]. Between these, Active Appearance Model [7] algorithms proved to be particularly
promising. Active Appearance Model (AAM) method is a statistical deformable model based algorithm of feature
recognition. It belongs to the so called “model based” codes [8]: it tries to find the proper model that can best match
an image. After the matching, we can extract the information of interest: this is a typical top down strategy. The use
of the algorithm imply three different steps: the first one is the deformable model creation, the second one the
adaptation of the model to a new image and the third step is the information extraction from the matched model.
The model creation is done through a statistical approach: in the training images the user labels the different
features simply clicking their position on the screen, creating an opportunely linked “cloud” of points, consistent
from one shape to the next. A principal component analysis on these data allows to extract significant parameters in
terms of variation of geometry and texture among the training images. The resultant model is a compact
representation of most significant available variation of the training images.
The analysis of a new image is done, after an initialization step, by iteratively matching the reference model on
the sample acquired and subsequently extracting the coordinates of the points of interest.
This paper proposes a purely three-dimensional less time consuming approach: a stereoscopic system shoots two
pictures of the individual. Then two different AAM models, one for each cameras, extract the coordinates of 58
corresponding points. Triangulation of these points clouds allows the reconstruction of a simplified threedimensional geometry of the face to be used for recognition.
The code used for the identification of the 58 points in the images is the “AAM-API” developed by
Stegmann[11].

3. Acquisition System
The stereoscopic acquisition system is basically composed by a frame that supports two digital cameras. A trigger
signal ensures the simultaneous acquisition of two devices.
The cameras are aligned along the vertical axis: this configuration seems to be able to minimize the problems
related to undercuts, in particular the ones linked with the nose geometry. The person to be acquired sits in front of
the cameras as shown in Fig. 1.

E. Zappa et al. / Procedia Computer Science 1 (2012) 2521–2528

2523

Zappa, Mazzoleni, Hai/ Procedia Computer Science 00 (2010) 000–000

Fig. 1 Acquisition layout

The geometric parameters and the characteristics of the sensors were optimized iteratively by numerically
simulating the system in order to find the best compromise between working volume and resolution of the system.
The result is shown in Fig. 1
Four screened lamps ensure uniform illumination of the face and a black curtain just behind the subject make a
uniform background, screening possible reflections.
In a three-dimensional stereoscopic system the measurement is obtained essentially triangulating corresponding
points in the images grabbed by different cameras.
The calibration allows this operation (from a pair of 2D images to a 3D measurement) and the compensation of
possible non-ideality of the system (e.g. optical distortions) without requiring precise knowledge of the geometry of
the system. In this work the calibration was performed through the so called direct linear transform, DLT, algorithm
[12, 13, 14].

4. Database Creation
The used database is composed of 27 persons: that is, 27 pairs of images of 27 different individuals were
acquired [15]. The analysis of images framed by the top and bottom cameras was made separately: two different
deformable models were created. As mentioned, the AAM algorithm includes a "training” preliminary step: 15
images of 15 different people recovered from the upper camera were manually "annotated", that is the location of 58
landmarks were manually selected on each of the 15 images.
The choice of which and how many points to consider is related to two different aspects: on the one hand these
points must be significant for the recognition, on the other hand they must include features that allow the model to
easy identify the face within the image. Regarding the latter aspect, all points in the area of eyes and mouth
demarcate parts of the image rich of significant texture and well-defined geometry and they are therefore easily
recognizable by the algorithm. These areas, however, occupy only a small part of the face. It was therefore chosen to
introduce the outlines of the eyebrows and chin in order to facilitate the AAM initialization in terms of location,
scaling and rotation of the model in the picture despite the location of these points is less easily identified uniquely.
How does the choice of these points influences the detection algorithm will be discussed in paragraph 6.
The 58 selected points are shown in Fig. 2.

2524

E. Zappa et al. / Procedia Computer Science 1 (2012) 2521–2528
Zappa, Mazzoleni, Hai/ Procedia Computer Science 00 (2010) 000–000

The manual selection of the 58 points on images allowed to create the deformable reference model, used to
"evaluate”, i.e. finding the 58 points in the image, all 27 images obtained from the upper camera. The same
operation was repeated with the images captured by the lower camera.
So we have 27 pairs of two-dimensional “masks” (that is clouds of 58 points): triangulating them through DLT
parameters, estimated during the calibration, allows to obtain a three-dimensional mask for each one of the 27
persons: these 27 3D-masks represent our database.
Fig. 2 shows an example of this operation: on the left there are the two images with the 2D mask superposed
matched using the AAM algorithm and on the right the obtained three-dimensional mask.

Fig. 2 Example of a pair of annotated images (left) and corresponding 3D mask (right)

5. Comparison with the Database
To analyze the performances of the proposed identification system a new couple of stereoscopic images was
acquired for each person included in the database and the recognition procedure was run for all of them. In particular
a new pair of images of a person already in the database was acquired, say person number j. Repeating the same
process as above (identification of landmarks on each image using the AAM and subsequent triangulation) we get a
new 3D mask (mask j). The comparison of this new mask with those in the database is done following the
subsequent steps: first of all, a mask (say number i) is extracted from the database; the new mask is then rotated and
translated, iteratively minimizing a figure of merit, until it matches as well as possible with mask j. This operation
allows to compensate for differences in position and orientation of the subject with respect to the stereoscopic
system in acquisitions i and j. The average value of the squared distances between homologous points was chosen as
figure of merit in the minimization.

E. Zappa et al. / Procedia Computer Science 1 (2012) 2521–2528

2525

Zappa, Mazzoleni, Hai/ Procedia Computer Science 00 (2010) 000–000

The residue of this minimization, D*ji, is taken as an index of the dissimilarity between the person j to be
identified and the person i in the database. This operation is repeated for all masks of database, obtaining 27 values
D*ji, (with i=1:27 representing the masks in the database).
The same procedure was repeated for all the other 26 new masks. So we have 27 3D masks of 27 different
people in the database and other 27 3D masks of the same group of people, obtained from new pairs of images, to be
uses for the comparison.
6. Use of Weights
Up to now, the proposed algorithm assigns equal importance to each of the 58 points, but it seems reasonable to
weigh differently the various points, according to their reliability in personal identification. This for two different
reasons: first of all there are parts of the face, supported by bones or parts of cartilage particularly stable, whose
position is, for a given individual, sufficiently stable to changes in expression and age, for example exo and endocathion, (the eye lateral points), or subalare (lowest point on the nose where the nose ridge meets the upper lip);
others are, on the contrary, more related to the expression (typically the outline of the mouth) and are therefore less
relevant in the recognition.
In addition, the AAM algorithm does not detect the various points with the same accuracy: in particular the
identification of all those landmarks that are not associated with a sharp changes in texture (as the chin edge) is
affected by higher uncertainty.
Hence the decision to assign different importance to the 58 points.
The weight to be assigned to each landmark was evaluated as follows: the new masks of the 27 persons were
compared with the respective ones of the database (27 comparisons in total, only between an individual and himself)
and the point-by-point squared distance was computed for each of the 58 points of the masks. The inverse of these
58 values were normalized in order to have sum equal to 58 and used as weights attributed to different points.
In Table 1 average weights we find the average weights obtained for different areas of the face:
Table 1 average weights

Chin
Mouth
Nose
Eyes
Eyebrows

Average weight
0.45
0.61
0.67
2.17
0.94

The results confirm what is intuitive: the eyes are the part of the face that is more stable while the contour of the
chin seems to have little significance in the recognition.

7. Results
The same type of comparison described above (realignment through roto-translation and evaluation of mean
square residual distance D*ji) was then applied to all the possible combinations of masks in the database
introducing weights: therefore the average squared distance became an average weighted on the values obtained in
the previous paragraph.
Fig. 3 shows as an example the results obtained in the comparison of the new first-person mask of the database
with the old masks of the entire database.

2526

E. Zappa et al. / Procedia Computer Science 1 (2012) 2521–2528
Zappa, Mazzoleni, Hai/ Procedia Computer Science 00 (2010) 000–000

Results of comparison: person 1 Vs database
5000

D*

1i

4000
3000
2000
1000
0

0

5

10

15
Person number

20

25

30

Fig. 3 Example of comparison against the database

It can be seen that, as expected, the first person in the database has the minimum value of the figure of merit (i.e.
D*11 is the minimum).
This results was confirmed for all the remaining 26 new masks: in all cases considered, the algorithm indicate as
the more "similar" person the copy of the correct one (D*kk, with k=1:27). In other words, the algorithm does not
show any problems, in the considered database, in identifying which person in the database corresponds to the new
acquired mask.
This situation is however simplistic: not always, in a real application, we know a priori that the person is already
in the database. We therefore need a criterion that allows us to discriminate if the person in the database that
minimizes D*ji is actually the same of the new mask or if the person to be recognized is not in the database.
Fig. 4 shows all the comparisons of the new masks with the respective individuals in the database (i.e. 27 D*ji
with j=i, also referred to as intra-personal comparison).
Intra-personal comparison
600

D*ii

400

200

0

0

Fig. 4 Intra-personal comparisons

5

10

15
Person number

20

25

30

It was therefore decided to take the maximum value among the intra-personal D*ii values as a threshold, “TD”:
if a value falls below this threshold the most resembling person of the database is actually the same of the one to be
recognized. So, in an ideal case, we should always find a single person below this value. Fig. 5 show all interpersonal comparisons, that is the 27*27-27=702 values of D*ji with iM

2527

E. Zappa et al. / Procedia Computer Science 1 (2012) 2521–2528
Zappa, Mazzoleni, Hai/ Procedia Computer Science 00 (2010) 000–000

Inter-personal comparison

10000
8000

D*ji

6000
4000
2000
0

0

100

200

300

400

500

600

700

Fig. 5 Inter-personal comparison

The horizontal line represents the value TD of threshold previously defined. About 702 inter-personal
comparisons, we have that in 22 cases, the proposed algorithm gives a value of D*ji less than TD, while in the
remaining 97% D* ji is greater than TD. This means that, although the program can find the correct match between
the person to be recognized and the same person in the database, in 3% of the cases there is another person in the
database that produce a D* ji value below the threshold TD.
8. Conclusions
An Active Appearance Model algorithm, created to detect deformable objects into two-dimensional images, was
here combined with a stereoscopic vision system in order to develop a 3D facial recognition system.
Two separate deformable models analyze the images from two different cameras that frame the subject and
extract 58 corresponding points of the face from each of them. These two-dimensional clouds of points are then
triangulated by a DLT algorithm to reconstruct the position of these points in a three-dimensional space obtaining a
3D mask of the person. The comparison with a reference database is done roto-translating the new cloud of points
on the other reference ones and evaluating for each test the residual mean square distance between homologous
points weighted on coefficients that can reflect the intrinsic variability and the identification problems associated
with different parts of the face.
The result is a highly promising approach: preliminary tests on a limited database showed a F.R.R. (flase
rejection rate, ratio of the number of false rejections divided by the number of identification attempts) identically
equal to zero and a F.A.R. (false acceptance rate, ratio of the number of false acceptances divided by the number of
identification attempts) of about 3%. These results are strictly related to the boolean approach linked with the
definition of a unique threshold for the comparison: in other terms the definition of a single threshold value TD for
the parameter D*ji can only lead to an true / false output.
Future developments will include, in addition to an enlargement of the database for a more solid statistical basis,
the definition of two different thresholds Dup* and Ddown* (where Dup*>Ddown*) defining a warning range: if D*ji
falls inside this range the result will be considered uncertain and the repetition of the acquisition will be suggested.
At the opposite above Dup* the test result will be “person is not in the database” and under Ddown* the test will
produce a recognition judgment.

Acknowledgments
This work has been partially supported by the Italian Ministry of University and Research (MIUR) by a PRIN
grant.

2528

E. Zappa et al. / Procedia Computer Science 1 (2012) 2521–2528
Zappa, Mazzoleni, Hai/ Procedia Computer Science 00 (2010) 000–000

References
1. Ratha, N.K., Senior, A., Bolle, R.M.: Automated Biometrics. In: Proc. of ICAPR, Rio, Brazil, pp.445-454 (1997)
2.
Miller, B.: Vital signs of identity, IEEE Spectrum, February,31(2):22–30 (1994)
3.
Halbertstein, R.: The application of anthropometric indices in forensic photography: three case studies, Journal of Forensic Science,
46(6), 1438–1441 (2001)
4.
Zhao, W., Chellapa, R., Phillips, P.J., Rosefeld, A.: Face Recognition: A Literature Survey, ACM Computing Surveys (CSUR), v.35
n.4, p.399-458, (2003)
5.
Abate, A., Nappi, M., Riccio, D., Sabatino, G.: 2D and 3D face recognition: A survey, Pattern Recognition Letters 28, pp. 1885–1906
(2007)
6.
Tolba, A., El-Baz, A., El-Harby, A.: Face Recognition: A Literature Review, International Journal of Signal Processing, 2(1): 88–
103.
7.
Cootes, T., Edwards, G., Taylor, C.: Active Appearance Models, in Proc. European Conference on Computer Vision, Vol. 2, pp. 484498, Springer (1998)
8.
Heisele, B., Ho, P., Wu, J., Poggio, T.: Face recognition: component-based versus global approach, Computer vision and image
understanding, vol. 91, no. 1–2, pp. 6–21, (2003)
9.
Bowyer, K., Chang, K., Flynn, P.: A survey of approaches and challenges in 3D and multi-modal 3D + 2D face recognition ,
Computer Vision and Image Understanding 101, 1–15 (2006)
10. Mata, F., Berretti, S., Del Bimbo, A., Pala, P.: Using Geodesic Distances for 2D-3D and 3D-3D Face Recognition, Image Analysis
and Processing Workshops, pp. 95-100 (2007)
11. AAM-API, Stegmann, M., http://www2.imm.dtu.dk/~aam/
12. Hartley, R., Zisserman, A.: Multiple view geometry in computer vision, II ed., Cambridge, Cambridge University Press (2003)
13. Aziz, Y., Karara, H.: Direct linear transformation into object space coordinates in close range photogrammetry, Symposium on CloseRange Photogrammetry, Urbana, IL , pp. 1–18A (1971)
14. Chen, C., Armstrong, C., Raftopoulos, D.: An investigation on the accuracy of three-dimensional space reconstruction using the
direct linear transformation technique , Journal of Biomechanics 27, 493-500 (1994)
15. Hai, Y., Tang, S., Automatic 3D Face Recognition based on 2D Face Detection and Features Extraction (2008)

