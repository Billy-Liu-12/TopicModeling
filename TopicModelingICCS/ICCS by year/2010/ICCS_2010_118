Procedia
Computer
Science

Procedia Computer Science 1 (2012) 2013‚Äì2022
Procedia Computer Science 00 (2009) 000¬±000

www.elsevier.com/locate/procedia
www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

A new agent-based paradigm for recognition of free-hand sketches
D.G. Fern√°ndez-Pachecoa, J. Conesaa, N. Aleixosba*

b

a
DEG, Universidad Polit√©cnica de Cartagena, 30202 Cartagena, Espa√±a
Instituto en Bioingenier√≠a y Tecnolog√≠a Orientada al Ser Humano (Universidad Polit√©cnica de Valencia), Espa√±a

Abstract
Currently, important advances are carried out in CAD (Computer Aided Design) applications; however these advances have not
taken place for CAS (Computer Aided Sketching) applications. Although natural interfaces for CAD applications are not solved
yet, works based on sketching devices have been explored to some extent. The recognition paradigm we propose using an agentbased architecture does not depend on the drawing sequence and takes context information into account to help decisions. An
improvement provided is the absence of operation modes, that is, no button is needed to distinguish geometry from symbols or
JHVWXUHVDQGDOVR¬≥LQWHUVSHUVLQJ¬¥DQG¬≥RYHUWUDFLQJ¬¥LVDFFRPSOLVKHG
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
‚Éù
Keywords: Natural interfaces; free-hand sketch recognition; agent-based systems; CAD

1. Introduction
A recent study [1] promoted by the Engineering Design Graphics Division of the American Society for
Engineering EducatiRQ FRQFOXGHG WKDW ZLWKLQ WKH ILHOG RI JUDSKLF FRPPXQLFDWLRQ WKH ¬≥DELOLW\ WR FUHDWH VROLG '
models on a computer" and the "ability to produce free-KDQG VNHWFKHV RI HQJLQHHULQJ REMHFWV¬¥ DUH WKH WZR PRVW
highly valued skills that engineering students should be competent in, and the one sponsored by the American
Society of Mechanical Engineers (ASME) [2] confirm these conclusions. Other authors [3-4] have analyzed the
important role played by the use of sketches during the process of developing new industrial products, concluding
that main advantages of using sketches are the economical materials involved (low cost), their immediacy (tool with
a simple interface) and the ease with which they can be corrected and reviewed (overwriting and deletion).
The arrival of CAD had a profound effect on other phases of the design process but had very little impact on the

* Corresponding author. Tel.: +34-963-879-514; fax: +34-963-87-7519.
E-mail address: naleixos@dig.upv.es

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ‚Éù
doi:10.1016/j.procs.2010.04.225

2014

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022
Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

conceptual design phase, where pencil and paper sketches are still used. The reason because computer-assisted tools
have not really made their way into the conceptual design phase is largely due to the shortcomings of the CAD tools
that are currently available at a commercial and academic level. When tools have been developed with suitable
capabilities, they have proved to be effective. For example, it has been shown that using CAS tools is at least as
useful as conventional pencil and paper for developing spatial vision skills in novel engineering students [5]. We
believe that CAS tools have not been developed as we might have expected because, on the one hand, the hardware
necessary to implement them only recently became available with the introduction of Tablet PCs and UMPCs and,
on the other hand, the limited capabilities they offered (as for instance the strictness in the drawing sequence order
or the low success classification ratio) did not improve on traditional sketching carried out on paper.
Multiple techniques are used in sketch recognition to detect symbols, diagrams, geometric shapes and other user
command gestures. With a classic linear discriminator, Rubine [6] calculates features in order to classify singlestroke sketches as digits, letters and basic commands. Also based on similar features Ayaj et al. [7] distinguish five
simple geometric shapes basing their classification on thresholds to the ratio filters established. Gross [8] describes a
prototype for the recognition of glyphs, but his algorithm requires sketching in a strict order. Other features that
remain invariant with rotation, such as convex hull, perimeter and area scalar ratios, were studied by Fonseca et al.
[9], who use ratio values in fuzzy sets to recognize some shapes. Xiangyu et al. [10] and Zhengxing et al. [11]
recognize simple geometric shapes by calculating the average distance from the vertices of the preset shape to the
vertices of the stroke. Methods based on Fourier descriptors achieve better results than methods based on shape
descriptors as presented above. In this field, Zang et al. [12] use Fourier descriptors to retrieve images from
databases. Fourier descriptors were also used by Harding et al. [13] for recognizing hand gesture trajectories. Other
H[DPSOHV RI DSSOLFDWLRQV WKDW XVH )RXULHU GHVFULSWRUV DUH WKH GHWHFWLRQ RI XVHUV¬∂ KDQG PRYHPHQW LQ D V\VWHP WR
achieve an augmented reality tool (Licsar et al. [14]). Park and Park [15] use Fourier transform to describe
fingerprints that are classified by means of non-linear discriminant analysis.
More and more, traditional techniques are being substituting by new promising ones like systems based on
agents. So, this technology is being used even more for natural interfaces, as for instance Juchmes et al. [16] who
base their freehand-sketch environment for architectural design on a multi-agent system. Also Achten and Jessurum
[17] use agents for recognition tasks in technical drawings and Mackenzie et al. [18] for classifying sketches of
animals. Azar et al. [19] and Casella et al. [20] use agents to interpret sketched symbols. Finally, Hong et al. [21]
describe the drawbacks of sketch recognizers at this time.
In short, the challenge of replacing conventional pencil and paper sketches with a digital sketching environment
exists. This new environment must be designed in such a way that it favors a ¬≥natural¬¥ process that does not hinder
the user, while also producing its output in the form of a digital design model that can be reused in the remaining
phases of the design process. Our interface, suitable for a CAS tool, which we have called ¬≥Scrawl-,¬¥ KDV EHHQ
conceived to fulfill this purpose. In order to situate our field of action, we first need to characterize the different
types of sketches that engineers/designers use in the course of creating a product.
We are going to follow the classification of sketches put forward by Ferguson [22]. Thus, we distinguish between
¬≥WKLQNLQJ VNHWFKHV¬¥ ZKLFK DUH XVHG WR IRFXV DQG JXLGH QRQ-YHUEDO WKRXJKW ¬≥WDONLQJ VNHWFKHV¬¥ ZKLFK SURYLGH D
VXSSRUW IRU WKH FRQVLGHUDWLRQV DERXW WKH GHVLJQ WKDW WDNH SODFH EHWZHHQ FROOHDJXHV DQG ¬≥SUHVFULSWLYH VNHWFKHV¬¥
which are convey instructions to the draughts person, who is the responsible for producing the final version of the
engineering drawings. Our work is focused on both the thinking and prescriptive sketches. The field of SketchBased Interfaces and Modelling (SBIM) is an emerging area of research. Proof of this is the fact that, in Europe, the
forum specialized in this field was only set up 5 years ago. We are referring to the SBIM workshop, which is held
every year in parallel to the EuroGraphics conference (http://www.eg.org/sbm). The current objectives of the SBIM
community are still varying wide-ranging (see Computers & Graphics, special issue 29(6) 2005), but one of the
most active areas of work is the creation of 3D models from thinking sketches.
There are two approaches to the problem of transforming a thinking sketch into a 3D model within the context of
the development of industrial products, namely, those based on geometric reconstruction techniques (that remains

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022

2015

Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

out from our scope) and the so-called gesture-based modeling methods based on interaction with the user through
gestures that are recognized as commands to generate solids from 2D sections (such as the SKETCH system [23],
TEDDY system [24] or GIDeS system [25] for example).
One of the lacks of the previous systems is that they do not consider other important symbols useful to create
sections or 3D geometry, as geometric and dimensional constraints or types of line (like axis of symmetry or
revolution). The main objective of this paper is to propose a recognition paradigm to support an interface that allows
generating geometry from sketches, considering command gestures and other standardized symbols as dimensional/
geometric constraints (in ISO 129), sections and type of lines (in ISO 128). Moreover, we also pretend to eliminate
the annoying change of mode, currently implemented in most CAD applications by a button that changes the input
mode from geometry to gesture or symbol mode, and also editing mode.
2. Recognition process paradigm
The recognition process paradigm has been formulated in order to take advantage of the flexibility and autonomy
of a multi-agent hierarchical architecture. Therefore, a hierarchical breakdown of the symbols must be previously
defined. To introduce the proposed paradigm, first we have to make a similarity between spoken and graphical
languages. In general, the symbols (as though they were ¬≥words¬¥ of a dictionary) are made up of one or several
simple strokes (as though they were ¬≥phonemes¬¥ of an alphabet). One or several phonemes or simple strokes (from
now on ¬≥primitive symbols¬¥) make, in turn, a word or complex symbol (from now on ¬≥combined symbol¬¥) which
belongs to a set of accepted words (a dictionary). In a hierarchical architecture, phonemes remain in a lower level
than words, so the recognition process has to be arranged into two levels: a lower level where the phonemes are
recognized, and an upper level where the words are deduced.
We name Primitive Agents to the agents in charge of the recognition of primitive symbols. And following this
rule the Combined Agents take care of the recognition of combined symbols. In our hierarchical system the
Primitive Agents will reside in the lower level and the Combined Agents will be set in the upper level. We consider
a primitive symbol (phoneme or simple stroke) as a series of points which are digitized by the input device between
a ¬≥pen down¬¥ - ¬≥pen up¬¥ event. Fig 1 shows the proposed phonemes.

Fig. 1. ¬≥Phonemes¬¥ (primitive symbols)

In a CAD environment, we need to define geometry, commands for editing or generating geometry, and depict
geometric/dimensional constraints to keep the geometry constantly evaluated. The combined symbols have been
chosen in order to provide all this functionality to our interface, and in consequence, the primitive symbols have
been established as parts of those combined symbols that can be drawn at once (without rising the pen from paper;
see Fig 1). A small index or ¬≥dictionary¬¥ of symbols has been defined in Fig 2. These symbols under consideration
are the frequently used in modeling tasks, which allow the user to build parametric geometry from sketches, and
create basic solid models. Gestural commands (such as extrusion, crossing, etc), symbols to indicate dimensional
and geometrical restrictions (like collinear, parallel, etc), and symbols to provide geometrical information (like
revolution or symmetry axis, etc) are included.
The phonemes are assembled to form words containing a semantic meaning, in the same way the primitive
symbols are assembled to form combined symbols. This means that the last stroke that makes up a combined symbol
takes place when the recognition process ends with a valid result, but in turn, the system must provide the user with
some freedom when sketching, that is, not forcing the user to introduce the strokes in a specific way. This
functionality implies that all the possible solutions must be searched on the storehouse of strokes/phonemes
(database containing all the user inputs not recognized yet). This term is called ¬≥interspersing¬¥ of strokes from
different objects [26-28], an improvement that has been implemented in this recognizer.

2016

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022
Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

Fig. 2. Dictionary of ¬≥words¬¥ (combined symbols)

2.1. The structure of the multi-agent system
Given that the main aim is to define a paradigm based on agents which allows to design scalable solutions, the
architecture used is divided into three levels: a lower level for the Basic Agents which deal with the user interface,
the pre-processing, and the extraction of the features; an intermediate level for the Primitive Agents in search of
syntactical meaning in each single stroke; and an upper level where the Combined Agents in charge of finding the
semantic content of several strokes forming a symbol lie in.
2.1.1. Basic Agents Level
Four agents work at this level:
x The Broker Agent (BA), which, as its name suggests, assigns the tasks to the agents of the system.
x The Interface Agent (IA), which is in charge of the interaction with the user, and sends the digitized points to the
rest of the basic agents.
x The Preprocessing Agent (PA), which smoothes and eliminates the noise of each introduced stroke in order to be
subsequently analyzed.
x The Feature Agent (FA), which extracts the most important features through image analysis techniques.
The Broker agent will be responsible for assigning all the information sending tasks of the system, such as it is
shown in the functional diagram in Fig 3. When a user draws a stroke, the Interface Agent (IA) shows it and sends
the digitalized points to a data structure. The Broker Agent (BA) receives the notification and sends the points of the
stroke to the Preprocessing Agent (PA). Ideally, these points should be uniformly distributed. However, the faster
the stroke is drawn, the fewer points are digitalized, which causes a variation in the points concentration, as well as
the drawing may be more or less trembling and halting. The Preprocessing Agent (PA) must filter and eliminate that
noise in order to get an ideal stroke ready for the recognition. Once the preprocessing has been completed, the
Broker Agent (BA) requests the FA to extract the features, which, once it has finished, sends back those features to
the BA. With the extracted features the BA sends the information to the corresponding primitive agents, which send
back the results of the first recognition stage to the BA. In possession of these results the BA resends them to the
combined agents, which will take care of the second recognition stage.
The Feature Agent FA has a sequential functioning, in which we have to distinguish two clearly distinctive parts.
On the one hand, the ¬≥segmentation¬¥ of the stroke is carried out extracting the primitive geometrical forms which
make it up (process which is currently a well-known problem in the sketch recognition field [29-30]), and providing
information about them which will be used in the decision stages afterwards. On the other hand, a series of features
or EDVLF¬≥cues¬¥ of the introduced stroke are obtained. These features have been chosen in such a way that they are
invariant to the scale, position and orientation, like circularity [31] and the FFT [32] of the radius signature (also
called polar signature) and of the ¬≥arc length versus cumulative turning angle¬¥ signature (also known as direction

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022

2017

Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

signature) have also been chosen. These features are the input variables of a non-linear discriminant analysis which
will classify the symbol/gesture according to them. Each one of the primitive agents will only use the information
that it considers significant in order to find relevant clues which allow it to recognize the primitive symbol which it
is dealing with.

Fig. 3. Functioning diagram of the broker agent where the levels of basic, primitive and combined agents are represented

2.1.2. Primitive Agents Level
At this level the recognition of the simple strokes or primitive symbols is carried out. At least an agent for each
primitive symbol has been implemented. The name of these agents has been chosen according to the following rules:
the two first characters for the type of phoneme to be recognized followed by an A for Agent. In this way, the
primitive agent in charge of finding a point will be called POA (Point Agent), and so on. These primitive agents
compete with each other in order to give, at least, a valid solution to the combined agents of the next level, using the
features provided by the basic DJHQWV¬∂ level. The quantified information supplied by the primitive agents can be
summarized in two processes:
x A recognition based on the geometry of the stroke that returns a positive or negative coincidence after the
syntactic analysis (Match or No_match of the found vertices and the approximated primitives (see Fig 4).

Fig. 4. Syntactic recognition result for a sample of an ¬≥arrow¬¥ primitive symbol

x A quantitative value as a result of a maximization function based on a non-linear Bayesian discriminatory
analysis whose input parameters are the features extracted by the FA [33].

2018

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022
Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

2.1.3. Combined Agents Level
At this level the recognition of the symbols of the defined dictionary (see Fig 2) is executed. As well as in the
intermediate level, there is, at least, a combined agent for each symbol we want to recognize. The recognition at this
level is called the semantic recognition and takes place as follows:
x If the symbol is made up by just one stroke and it has a full meaning by itself, that is, it does not belong to a more
complex symbol (as is the case of the cross-out and the polygon) it is assigned as a positive result and the current
recognition process ends.
x If it is feasible to belong to other symbols formed by several primitive symbols, then it is added to a storehouse
and the system must wait for the next stroke to be introduced:
≈º If the next stroke is able to form a combined symbol jointly, then a positive result is reached and the
recognition process ends.
≈º If the next stroke is able to belong to, but there is not enough semantic meaning to form a combined symbol,
then it is added to the storehouse and the recognition continues.
≈º If the next stroke is not able to be a part of a combined symbol, two different things can happen:
¬± The stroke can belong to the geometry of the sketch, and then it is analyzed and stored in the corresponding
geometry data structure.
¬± Otherwise it is ignored and the recognition continues.
2.2. Contextual Analysis
The analysis by the primitive agents is not conclusive. The performed stroke can be quite different from one user
to another and the recognition of a primitive agent cannot be correct. Moreover, the maximum value of the
maximization function not always corresponds to the correct phoneme, so it is required to add more information.
The combined agents are responsible for searching this information in order to reach a right decision. The contextual
analysis takes place at three levels:
x Interpretation of the information given by the primitive agents.
x Types of tasks to be done by a symbol, once it has been recognized.
x Semantic interpretation of a set of strokes.
2.2.1. Interpretation of the information given by the primitive agents
We can distinguish up to four cases from the information given by the primitive agents:
x The primitive agent indicates coincidence in the syntactic result and returns the maximum value of the
maximization function in relation to the values given by other primitive agents. The combined agents validate the
symbol corresponding to that primitive agent.
x The primitive agent indicates coincidence in the syntactic result and does not return the maximum value of the
maximization function with regard to the values obtained by other primitive agents. The combined agents analyze
if the value of the maximization function is the second maximum value in relation to the values given by the
other primitive agents. If so, they validate the symbol corresponding to that primitive agent. If this is not
fulfilled, the stroke is considered as a geometric entity if there are not crosses in that stroke; otherwise it is
rejected.
x A primitive agent that indicates no coincidence in the syntactic result returns the maximum value of the
maximization function in relation to the values given by other primitive agents. The combined agents analyze the
context of the stroke (strokes previously introduced and waiting for a final recognition in a storehouse), and
decide whether taking it as a symbol (because it is capable of belonging to a more complete solution, that is, it
belongs to a more complex symbol) or as geometry.
x Any other case which is not considered in the previous points will cause that the system considers the stroke as
geometry if does not contain any crosses; otherwise it is rejected.

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022

2019

Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

2.2.2. Types of tasks to be carried out by a symbol
It is important to distinguish between the different tasks assigned to combined symbols. These actions also
represent contextual information for the combined agents, which can be classified in:
x Modeling agents (extrusion and revolution): they are those whose implementation means immediate actions on a
previously defined surface. The implementation of this type of agents is conditioned by a previously selected
surface. If there is not a prior selection of a surface, the recognition of one of these symbols has no sense. The
broker agent is in charge of informing the combined agents whether there is a selected surface (closed outline).
x Agents with references (parallel, perpendicular, equal dimension, tangency, collinear): they are agents whose
implementation must establish relationships between two geometric entities, that is, the symbol has to be
recognized twice consecutively.
x Independent agents (vertical, horizontal, scratch, radial dimension, dimension, diametral dimension, polygon,
revolution/symmetry axis): they are agents whose recognition denotes an immediate action which is independent
of any other stroke previously introduced, and it does not need a prior selection.
2.2.3. Semantic interpretation of a set of strokes
We must take into consideration that a stroke can either represent a symbol by itself or be part of a more complex
symbol made up by different primitive symbols, and that a particular symbol can be made up by strokes introduced
in a random order (see Fig 5).

Fig. 5. Possibilities of sketching the diametral command gesture

For the implementation of the algorithm (see Fig 6) a storehouse of strokes has been defined so that if a stroke is
not recognized as a symbol of the dictionary, it is stored in order to be analyzed together with subsequent strokes.

Fig. 6. Contextual analysis for each stroke introduced

2020

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022
Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

At this stage of the semantic analysis, the system acts as follows:
1. If the performed stroke cannot be part of a more complex symbol, goes directly to step 3.
2. If the performed stroke can be part of a more complex symbol, it is analyzed if this stroke and the ones
previously introduced waiting for evaluation in the storehouse can be part of a more complex symbol. If so, the
new stroke is added to the storehouse with the previous strokes and waits for the input of a new stroke. Otherwise
the system goes to step 3.
3. It is analyzed if the stroke has a final meaning by itself (cross-out and polygon symbols) and, if so, the stroke is
recognized as a symbol. Otherwise the stroke is identified as geometry or it is rejected if it contains crosses.
In any of the previous cases it is needed to carry out a study of the strokes waiting for being analyzed (strokes in
the storehouse). If the set of strokes in the storehouse has a more complete meaning with the new recognized one,
that is, they form a symbol of our dictionary, then the more complex symbol is recognized. Otherwise the strokes
remain in the storehouse till next input. This implementation provides the interspersing functionality to our
recognizer. In Fig 6 the contextual analysis carried out for each one of the introduced strokes is shown.
An example of the recognition of a diametral symbol followed by a concentric one is schematically represented
in Fig 7a. In this example the first stroke is a primitive symbol of a line, and all possible combined symbols the line
can pertain to are shown in its column. The next input is recognized as an angle, and it is suitable to be associated
with the previous line. At this point, the symbol can be an extrusion/radial dimension or pertain to a diametral or
dimension combined symbol. The next input is other angle, and its position and orientation makes suitable to form a
diametral or dimension combined symbol. The recognition stands till the next input has nothing to do with current
recognition, so the final recognition is reached and the process starts again with the circle. A second circle is drawn
and no more complete meaning is possible, so final recognition is reached for collinear combined symbol and
recognition process starts again. In Fig 7b we show an input sequence of a dimension which is finally rejected
because it does not have a full semantic meaning. In this last case we can consider the interspersing, in which the
user can leave the symbol unfinished and go on with it later, although in this particular case, as it is not completed in
subsequent inputs, it is rejected.

(a)

(b)

Fig. 7. Outline of two examples for decision-making

Notice that each stroke can belong to more than one symbol formed by many strokes, and that the same symbol
can be drawn in different ways, so that the sketching system does not depend on the sequence in which the user

2021

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022
Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

introduces the stroke. Thus, all the possible candidates are scanned in parallel at the same time until one of them
reaches a full semantic meaning. The implemented recognition system is based on the blackboard paradigm [34-35],
in which the decision is made according to series of cues that have the maximum meaning. Also the overtracing has
been taking into account for the functionality of our recognizer. The term ¬≥overtracing¬¥ indicates the use of several
strokes to represent one single line (something similar to the stroke in the artistic drawing [36]). The use of the
contextual information allows analyzing these partially superposed lines to give as final recognition one geometric
line.
3. Experimental work
In the first stage of the paradigm, the Primitive Agents have been implemented and successfully evaluated. The
tests to evaluate the syntactic recognition carried out by the Primitive Agents were conducted with 10 CAD users.
Each user introduced several occurrences of each of the different primitive symbols (a total of 2200 symbols) with
different orientations and sizes.
Sketched
symbols

Recognized
symbols
Angle
Arc
Circle
Line
Arrow
Round Arrow
Point
Scratch
Polygon

Angle
98.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0

Arc
0.0
94.9
7.0
0.0
0.0
0.0
0.0
0.0
0.0

Circle
0.0
0.0
93.0
0.0
0.0
0.0
0.0
0.0
2.1

Line
0.0
2.5
0.0
99.3
0.0
0.0
0.0
1.8
0.0

Arrow

Round
Arrow

0.0
0.0
0.0
0.0
94.2
5.7
0.0
0.0
0.0

0.0
0.0
0.0
0.0
5.8
94.3
0.0
0.0
0.0

Point
0.0
2.5
0.0
0.7
0.0
0.0
100.0
0.0
0.0

Scratch

Polygon

0.0
0.0
0.0
0.0
0.0
0.0
0.0
95.4
0.0

1.4
0.0
0.0
0.0
0.0
2.8
0.0
2.8
97.9

Table. 1. Results for Primitive Symbols recognition

The results of the recognition are shown in Table 1, which shows success ratio in classification for each phoneme
in the diagonal cells (highlighted in black), and the percentage of misclassification. The average success ratio
achieved was of 96.41%. Errors in classification correspond to cases in which the sketched symbol is wrong
digitized. Also errors can be due to symbols that are wrong interpreted as for instance: an unclosed circle that can be
confused with an arc; an arc with high radius value that can be converted to a line; an arrow or round-arrow symbols
that can be confused depending if the main stretch is more or less curved, so the recognition fails; and so on.
4. Conclusions
A new recognition paradigm for a sketch-based environment using an agent-based architecture has been proposed.
The recognition process is supported by two level agents: Primitive Agents which are in charge of the syntactic
recognition, and Combined Agents which carry out the semantic recognition using contextual information. The
proposed recogniser has the advantage to be easily extensible by means of new primitive or combined agents, so
external information can be incorporated to the system. As the combined agents consider the contextual information,
¬≥interspersing¬¥ (the user can leave the symbol unfinished and go on with it later) and ¬≥overtracing¬¥ (the user draws
several strokes to represent one single line) are supported. The proposed recognizer is not dependent on the number
of strokes and neither on the sketching sequence order of user inputs. Moreover, no operation modes are required, in
the way that no buttons are needed to change the input mode to introduce geometry, symbols or commands. A first
implementation of the Primitive Agents has been performed and evaluated by means of several tests, achieving a
success ratio of 96.41%. The Combined Agents are being implemented and tested, revealing good results at this
time.

2022

D.G. Fern¬¥andez-Pacheco et al. / Procedia Computer Science 1 (2012) 2013‚Äì2022
Fern√°ndez-Pacheco et al. / Procedia Computer Science 00 (2010) 000¬±000

Acknowledgements
The Spanish Ministry of Science and Education and the European Union (Project DPI2007-66755) partially
supported this work: DPI2007-66755-C02-01 (CUESKETCH: multi-agents based recognition of ideation sketches)
and DPI2007-66755-C02-02 (PRESKETCH: Computer-aided prescriptive sketches system for engineering design).
References
1. R.E. Barr, The Current Status of Graphical Communication in Engineering Education, 34th ASEE/IEEE Frontiers in Education
Conference, Savannah, 2004, 8-13.
2. A.T. Rose, Graphical Communication Using Hand-Drawn Sketches in Civil Engineering, J. of Professional Issues in Engineering
Education and Practice, 131 (4), 2005, 238-247.
3. B. Tversky, What do Sketches say about Thinking?, AAAI Spring Symposium Series - Sketch Understanding, 2002, 148-152.
4. B. Plimmer and M. Apperley, Computer-Aided Sketching to Capture Preliminary Design, 3rd Austral. Conf. on User interf., 7, 2002, 9-12.
5. M. Contero, F. Naya, P. Company, J.L. Saorin and J. Conesa, Improving visualization skills in engineering education, IEEE Computer
Graphics and Applications, 25 (5), 2005, 24-31.
6. D.H. Rubine, Specifying Gestures by Example, Computer Graphics, 25 (4), 1991, 329-337.
7. A. Ajay, V. Vo and T.D. Kimura, Recognising Multistroke Shapes: An Experimental Evaluation, $&08,67¬∂$WODQWD, 121-128.
8. M.D. Gross, Recognising and Interpreting Diagrams in Design, 3URFHHGLQJVRI$&0$9,¬∂,WDO\, 88-94.
9. M.J. Fonseca and J. Jorge, Using Fuzzy Logic to Recognise Geometric Shapes Interactively, 9th IEEE Conf. Fuzzy Syst., 1, 2000, 291-296.
10. J. Xiangyu, L. Wenyin, S. Jianyong and Z. Sun, On-Line Graphics Recognition. Conf. Computer Graphics and Applicat., 2002, 256-264.
11. S. Zhengxing , W. Liu, P. Binbin, Z. Bin and S. Jianyong, User Adaptation for Online Sketchy Shape Recognition, GREC 2003, 305-316.
12. D. Zang and G. Lu, A Comparative Study of Fourier Descriptors for Shape Representation and Retrieval, 5th ACCV, Australia, 2002, 1-6.
13. P.R.G. Harding and T.J. Ellis, Recognising Hand Gesture Using Fourier Descriptors, 17th I.C. on Pattern Recognition, 3, 2004, 286-289.
14. A. Licsar and T. Sziranyi, Hand Gesture Recognition in Camera-Projector System, L.N in Computer Science, 3058, 2004, 83-93.
15. C.H. Park and H. Park, Fingerprint classification using FFT and non-linear discriminant analysis, Pattern Recog., 38, 2005,495-503.
16. R. Juchmes, P. Leclercq and S. Azar, A freehand-sketch environment for architectural design supported by a multi-agent system,
Computers & Graphics, 29 (6), 2005, 905¬±915.
17. H.H. Achten and A.J. Jessurun, An agent framework IRUUHFRJQLWLRQRIJUDSKLFXQLWVLQGUDZLQJVH&$$'H¬∂:DUVDZ¬±253.
18. G. Mackenzie and N. Alechina, Classifying sketches of animals using an agent-EDVHGV\VWHP&$,3¬∂,Berlin, 2756, 2003, 521¬±529.
19. S.Azar,L.Couvreury,V. Delfosse,B. Jaspartz,C. Boulanger, An agent-based multimodal interface for sketch interpret., MMSP-06, Canada.
20. G. Casella, V. Deufemia, V. Mascardi, G. Costagliola and M. Martelli, An agent-based framework for sketched symbol interpretation,
Journal of Visual Languages and Computing, 19, 2008, 225¬±257.
21. J. Hong, J. Landay et al, Sketch Recognisers from the End-8VHU¬∂VWKH'HVLJQHU¬∂VDQGWKH3URJUDPPHU¬∂s Perspective, AAAI 03.
22. E.S. Ferguson, Engineering and the Mind's Eye, MIT Press, 1992.
23. K. Bloomenthal, R.C. Zeleznik et al., SKETCH-N-MAKE: Automated Machining of CAD Sketches, Proc. of ASME DETC'98, 1-11.
24. T. Igarashi, S. Matsuoka and H. Tanaka, Teddy: a sketching interface for 3D freeform design. $&06,**5$3+¬∂409-416.
25. J. Pereira, J. Jorge et al, Towards calligraphic interfaces: sketching 3D scenes with gestureVDQGFRQWH[WLFRQV:6&*¬∂
26. T.M.Sezgin,T.M.Davis, Sketch recog. in interspersed drawings using timebased graph. models, Comp.and Graphics, 32 (5),2008,500-510.
27. T. Hammond and R. Davis, Tahuti: A geometrical sketch recognition system for UML class diagrams, AAAI 02, 59¬±68.
28. T. Hammond and R. Davis, Recognizing interspersed sketches quickly, Proc.of Graphics Interface 2009, 324, 157-166.
29. J. Pu and D. Gur, Automated Freehand Sketch Segmentation Using Radial Basis Functions, Computer-Aided Design, 2009.
30. P. Company, P.A.C. Varley, A. Piquer et al, Benchmarks for Computer-based Segmentation of Sketches, IAPR-GREC 2009, 103-114.
31. L. Wojnar and K.J. .XU]\G√°RZVNL3UDFWLFDO*XLGHWR,PDJH$QDO\VLV$60,QWHUQDWLRQDO-160.
32. Y. Tao, C.T. Morrow, P.H. Heinemann and H.J. Sommer,Fourier-Based Separation Technique for Shape Grading of Potatoes Using
Machine Vision, Transactions of the ASAE, 38(3), 1995, 949-957
33. D.G. Fern√°ndez-Pacheco, M. Contero et al, A Calligraphic Interface in a Sketch-Based Modelling Environment, INGEGRAF 08.
34. H.M. Barber√°, A Distributed Architecture for Intelligent Control in Autonomous Mobile Robots", Masters thesis, Murcia, 2001
35. J.L. Posadas, J.L. Poza, G. Benet and F. Blanes, Agent-based distributed architecture for mobile robot control, Engineering Applications
of Artificial Intellingence, 21(6), 2008, 805-823
36. D.C. Ku, S.F. Qin and D.K.Wright, Interpretation of Overtracing Freehand Sketching for Geometric Shapes, :6&*¬∂, G41, 263-270.

