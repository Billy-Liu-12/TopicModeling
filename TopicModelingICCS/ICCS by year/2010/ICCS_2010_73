Procedia Computer
Science
ProcediaComputer
Computer Science
Procedia
Science001 (2010)
(2012)1–9
2679–2687

www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Investigation of parallel eﬃciency of an adaptive ﬂow solver
S. Gepnera,∗, J. Rokickia
a Warsaw

University of Technology, The Institute of Aeronautics and Applied Mechanics
Nowowiejska 24, 00-665 Warsaw, Poland

Abstract
Parallel eﬃciency, in a domain decomposition based approach, strongly depends on a partitioning quality. For an
adaptive simulation partitioning quality is lost due to the dynamic modiﬁcation of the computational mesh. Maintaining high eﬃciency of parallelization requires rebalancing of the numerical load. This paper presents numerical
experiment with adaptive and dynamically load balanced ﬂow application. It is shown that through a relatively inexpensive process of repartitioning high parallel eﬃciency is maintained.
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝

Keywords: adaptation, dynamic load balancing, mesh reﬁnement, parallel eﬃciency

1. Introduction
Large scale applications require high eﬃciency of parallelization in order to converge in reasonable time. Commonly used domain decomposition approach requires the computational domain to be partitioned into subdomains,
prior to the simulations. To maximize simulation performance, partitioning should minimize both, processor idle time
and the volume of interprocessor communication. This should be fulﬁlled throughout the simulation run time. To this
end a range of partitioning methods and tools have been developed (see reference [1, 2, 3] for a survey). An example
of an initial partitioning or a ﬁghter airplane geometry is shown in Fig. 1 [4].
Adaptive techniques allow for computation of localized phenomena (boundary layers, shock waves, etc) with
high resolution, while limiting the number of elements in less interesting regions. This increases the eﬀectiveness
of computations, as the necessary amount of resources is kept limited. Two alternative approaches to adaptivity are
commonly used. One, based on global remeshing of the entire computational domain, by making use of an existing
meshing techniques [6, 7, 5, 8, 9, 10]. Or by applying local mesh modiﬁcations to the computational mesh only in
regions of interest [11, 12, 13, 14]. An example of a solution adapted mesh is shown in Fig. 2. Complex shock wave
structure has been captured for Onera M6 wing geometry [5].
In parallel simulations adaptive algorithms introduce signiﬁcant modiﬁcations to the distribution of computational
load. This has a negative inﬂuence on the partitioning quality. And in consequence on the overall parallel eﬀectiveness.
A load balancing algorithm must be used if adaptivity is to be employed in a parallel simulation. Use of dynamic load
balancing algorithms for an adaptive application have been presented in [12, 13, 15].
∗ Coresponding

Author
Email addresses: sgepner@meil.pw.edu.pl (S. Gepner), jack@meil.pw.edu.pl (J. Rokicki)

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.301

2680

S. Gepner, J. /Rokicki
1 (2012) 2679–2687
Procedia/ Procedia
Computer Computer
Science 00 Science
(2010) 1–9

Figure 1: Initial partitioning of a ﬁghter airplane geometry - COOLFluiD project test-case [4].

Figure 2: Surface mesh for Onera M6 wing geometry (left) after a series of adaptations steps, and the resulting Mach ﬁeld (right) [5].

2

S. Gepner, J. Rokicki
/ Procedia
Computer
Science
1 (2012)
/ Procedia
Computer
Science
00 (2010)
1–9 2679–2687

2681
3

Figure 3: Supersonic Wedge test case (Ma = 2.0 at inlet). Initial mesh and the resulting Mach ﬁeld (left). Same case after 5’th adaptation steps
(right).

This paper presents measurements of parallel eﬀectiveness for an adaptive and parallel application. Parallel
speedup and eﬃciency for cases with and without load balancing are presented. The tests are run using the in-house
RED code [6] (a parallel, based on Residual Distribution [16, 17], explicit ﬂow solver).
2. Parallel anisotropic mesh reﬁnement
The adaptation algorithm implemented into the RED solver uses an anisotropic edge-based mesh reﬁnement technique. It operates in the following manner:
1.
2.
3.
4.
5.
6.
7.

Gradient based error estimation is used to localize cell edges suitable for adaptations.
Additional nodes are introduced to the edges marked as adaptable.
Since work is performed in parallel, processes communicate to ensure coherence in the overlap regions.
Cell structure is regenerated. The existing solution is interpolated on to the new mesh.
The communication rules are reset and the overlap is reconstructed.
The solution process is restarted on the adapted mesh.
When appropriate convergence criteria are not met, process is returned to point one.

Figure 3 shows the result of applying the described adaptive algorithm to a standard wedge test case. The calculations were performed for Ma = 2.0 at inlet. On the left the initial mesh and the resulting Mach ﬁeld are shown. The
right hand side shows the mesh and the Mach number ﬁeld obtained after 5 consecutive adaptation steps.
3. Impact of adaptivity on parallel performance
To judge the eﬀectiveness of parallelization there are two main measures. Let p be the number of CPU’s used and
T p the time it took to perform a parallel task. Parallel speedup S p is than deﬁned as:
T1
Tp

(1)

Sp
· 100%
p

(2)

Sp =
and parallel eﬃciency E p as:
Ep =

Linear (or ideal) speedup is obtained when a task performed using p processors requires time T 1 /p to be completed.
To measure the impact of adaptivity on parallel performance two cases were studied. In the ﬁrst case computations
were carried out on an initial unadapted mesh. In the second case a single adaptation step was applied. The number
of mesh points used diﬀer between ﬁrst and the second case due to the adaptation. So does the load balance of
partitioning.

2682

S. Gepner, J. /Rokicki
1 (2012) 2679–2687
Procedia/ Procedia
Computer Computer
Science 00 Science
(2010) 1–9

4

Figure 4: Resulting Mach number ﬁeld for a SCRAMJET geometry (Ma = 3.0 at inlet).





































































Figure 5: Parallel speedup (left) and eﬃciency (right) as a function of the number of computational cores used. Dashed line shows theoretical
values. Squares mark computations performed on the initial not adapted mesh (super linear scaling can be observed). Triangles mark the case
where adaptation was applied

The geometry under investigation is shown in Fig. 4. Initial mesh of 1600054 computational cells was used.
Figure 5 illustrates parallel performance plotted against the number of computational cores used. On both graphs
dashed lines represent theoretical values of parallel performance. Lines marked by squares show values obtained for
the ﬁrst case, where no adaptation is used. For this case a super linear scaling eﬀect can be observed. A discussion on
parallel eﬃciency being greater than unity might be found in [18].
Triangles mark values obtained for the second case where a single adaptation step was carried out. For both cases
times T 1 are diﬀerent (in the second case the numerical workload is larger due to the adaptation). Therefore results in
Fig. 5 present only the inﬂuence of load imbalance.
It should be noted that the drop in parallel eﬃciency, due to adaptation is substantial. Further adaptive steps would
decrease the eﬃciency even more.
4. Repartitioning algorithm
At some point during the run of an adaptive parallel simulation it is necessary to perform dynamic load balancing.
Commonly this event would be triggered when a threshold of acceptable load unbalance is breached (after the adaptation step is taken). Then it is necessary to calculate and apply a new better balanced partitioning. Subsequently the
mesh entities are redistributed between processors according to the obtained coloring.
4.1. Mesh partitioning
To calculate mesh decomposition the ParMETIS [19] graph partitioner was used.
To perform dynamic load balancing, the following steps had to be undertaken:

S. Gepner, J. Rokicki
/ Procedia
Computer
Science
1 (2012)
/ Procedia
Computer
Science
00 (2010)
1–9 2679–2687

2683
5

Figure 6: Partitions are being modiﬁed according to the previously calculated coloring. On the left is the original partitioning and coloring, the
middle picture shows original partitioning with new coloring. On the right is the partitioning after elements have been sent / deleted.

1. Elements of the mesh are given unique numbering throughout the whole domain. This makes mesh elements
easily distinguishable throughout the parallel environment.
2. Grid has to be described as a connectivity graph. When working with ParMETIS the so called distributed CSR
format is used.
3. With graph connectivity ready it is possible to calculate new mesh partitioning (graph coloring).
4. According to the obtained partitioning mesh entities are moved between processors.
Applying the new partitioning introduces massive changes to the simulation data structure. Some mesh entities
have to be send to other computing nodes while some must be removed. The received data has to be added to the data
structure accessible to a given CPU. This process is strongly dependent on the data structure used within the solver.
Once the information is exchanged the solver is ready to restart calculations.
This process is illustrated in Fig. 6 where a three dimensional domain is repartitioned. On the left the initial
partitioning is shown. The middle ﬁgure presents the new coloring obtained during the graph partitioning phase
plotted onto original partitioning. The rightmost picture shows the mesh after appropriate data migration.
5. Impact of dynamic load balancing on parallel performance
As stated in Section 3 the use of adaptation has a negative impact on the parallel performance. To judge the merits
of applying the DLB to an adaptive ﬂow computation such an algorithm was used for the case discussed in section 3
(Fig. 4). Figure 7 shows plots of parallel performance measured for the case in which adaptation was used together
with the DLB algorithm. Solid line marked by squares shows the measured values, while a dashed line shows the
linear speedup values.
It should be noted, that by taking advantage of dynamic rebalancing, parallel eﬃciency of the code is maintained.
Super linear scaling eﬀect is again present.
5.1. Numerical cost of rebalancing
To investigate the cost of a single rebalancing step a three dimensional simulation of the ﬂow around Onera M6
wing was selected. Mesh of 5078927 nodes (32622210 cells) was used. Results were obtained by running the RED
solver on the cluster containing 20 Quad-Core AMD Opteron processors (4 cores per processor) with 2 GB of memory
per core, connected by Fast Ethernet connection. The case is illustrated in ﬁg. 2.
As can be observed in Table 1 numerical cost of rebalancing is relatively small in comparison to the total simulation
time. Table 1 shows comparison of the CPU time required to perform the repartition as a fraction of total simulation
time required to converge an explicit Euler solver on a given number of processors. It is worth noticing that the time
share required for rebalancing decreases as the number of CPU’s grows.

2684

S. Gepner, J. /Rokicki
1 (2012) 2679–2687
Procedia/ Procedia
Computer Computer
Science 00 Science
(2010) 1–9

6





































































Figure 7: Parallel speedup (left) and eﬃciency (right) as a function of the number of computational cores used. Dashed line shows theoretical
values. Solid line represents the values noted for the adapted case, where dynamical balancing was applied. Super linear scaling is again present.

Table 1: Repartition time as a fraction of total simulation time, for a case of 5078927 nodes (32622210 cells).

No of cores
32
72
80

Repart. time / Sim. time
0.213%
0.105%
0.099%

6. Scramjet test case
In this section results of applying an adaptive and dynamically balanced algorithm to a SCRAMJET test case are
presented. The results are compared to a simulation performed on a relatively dense, but uniform mesh (SCRAM4).
The geometry considered is shown in Fig. 4. The test was run in parallel using initial meshes of diﬀerent resolution
(from coarsest to ﬁnest: SCRAM 1-3). Residual Distribution, explicit Euler solver was used.
For the ﬁnest mesh (SCRAM4) consisting of 1600054 isotropic elements, it took 4806 seconds to converge, using
80 computational cores. In this case no adaptation was applied. The results are comparable in quality to results on
coarser but adapted meshes (adapted SCRAM2 and SCRAM3).
The cases SCRAM1-3 were calculated with 5 adaptation steps, consecutive mesh sizes and total runtime for each
case are presented in Table 2. In all cases DLB procedure was applied. The adaptation and partitioning process are
presented in Fig. 8
Table 2: Runtime of an adaptive parallel application obtained for diﬀerent initial meshes (SCRAM1-4).

Test:
SCRAM1
SCRAM2

SCRAM3
SCRAM4

No. cores
16
32
16
32
64
16
32
64
80

Init. mesh size
2878
3094
16572
17159
18028
64709
65816
67503
1600054

1’st adap.
4681
4937
25945
26623
26745
93221
94611
95014
–

5’th adap.
22388
22612
157680
158904
159309
554023
557671
563500
1600054

Total sim. time
721 s
536 s
2920 s
1215 s
798 s
4579 s
2765 s
1931 s
4806 s

S. Gepner, J. Rokicki
/ Procedia
Computer
Science
1 (2012)
/ Procedia
Computer
Science
00 (2010)
1–9 2679–2687

2685
7

Figure 8: Consecutive adaptation steps together with partitioning resulting from applying a DLB algorithm. Run using 64 CPU’s. The initial mesh
is SCRAM2.

2686

S. Gepner, J. /Rokicki
1 (2012) 2679–2687
Procedia/ Procedia
Computer Computer
Science 00 Science
(2010) 1–9

8

7. Conclusions
In sequential ﬂow simulations, adaptation is a very useful tool. However, its negative impact on the parallel
performance makes it almost unusable in a massively parallel ﬂow simulations. In this paper measurements of parallel
eﬃciency for an adaptive ﬂow application have been presented. It was shown that use of adaptivity without proper
load balancing strategy leads to a drastic drop of parallel eﬃciency of the simulation. To remedy this deﬁciency a
dynamically load balancing algorithm have been used.
It was shown that by taking advantage of dynamical rebalancing, parallel eﬀectiveness of the application is restored. Since the numerical overhead necessary to perform load balancing is small in compare to the run time of the
application, the overall time is much decreased.
8. Acknowledgments
This work was supported by the FP6 EU ADIGMA project (Adaptive Higher-Order Variational Methods for
Aerodynamic Applications in Industry), and by MNiSW, grant No: N N516 4280 33, Dynamic load balancing for
adaptive engineering applications in parallel environments (Dynamiczne rownowazenie obciarzenia adaptacyjnych
aplikacji inzynierskich w srodowiskach rownolegÅych i rozproszonych), 2007-2009.
9. Bibliography
[1] B. Hendrickson, K. Devine, Dynamic load balancing in computational mechanics, Computer Methods in Applied Mechanics and Engineering
184 (2-4) (2000) 485 – 500. doi:DOI: 10.1016/S0045-7825(99)00241-8.
URL http://www.sciencedirect.com/science/article/B6V29-3YW270P-J/2/bbdbf31e2be710e61790593b96a2da1b
[2] K. D. Devine, E. G. Boman, R. T. Heaphy, B. A. Hendrickson, J. D. Teresco, J. Faik, J. E. Flaherty, L. G. Gervasio, New challenges in
dynamic load balancing, Applied Numerical Mathematics 52 (2-3) (2005) 133 – 152, aDAPT ’03: Conference on Adaptive Methods for
Partial Diﬀerential Equations and Large-Scale Computation. doi:DOI: 10.1016/j.apnum.2004.08.028.
URL http://www.sciencedirect.com/science/article/B6TYD-4DN14W8-7/2/1ac8891ae10839d973f04a6a9e38f14c
[3] B. Hendrickson, T. G. Kolda, Graph partitioning models for parallel computing, Parallel Computing 26 (12) (2000) 1519 – 1534, graph
Partitioning and Parallel Computing. doi:DOI: 10.1016/S0167-8191(00)00048-X.
URL http://www.sciencedirect.com/science/article/B6V12-48PD5HG-2/2/e37cf883c11b2a59571bae6c90362371
[4] T. Quintino, A. Lani, et al., Coolﬂuid - Computational Object Oriented Library for Fluid Dynamics.
URL http://coolfluidsrv.vki.ac.be/trac/coolfluid
[5] J. Majewski, Anisotropic adaptation for ﬂow simulations in complex geometries, in: 36th Lecture Series on Computational Fluid Dynamics /
ADIGMA course on hp-adaptive and hp-multigrid methods, von Karman Institute for Fluid Dynamics, 2009.
[6] J. Majewski, A. Athanasiadis, Anisotropic solution-adaptive technique applied to simulations of steady and unsteady compressible ﬂows,
in: H. Deconinck, E. Dick (Eds.), Computational Fluid Dynamics 2006 - Proceedings of the 4th International Conference on Computational
Fluid Dynamics, ICCFD4, Ghent, Belgium, July 10-14, Springer, 2006, pp. 353–359.
[7] J. Majewski, An anisotropic adaptation for simulation of compressible ﬂows, Mathematical Modelling and Analysis 7 (2002) 127–134.
[8] P. J. Frey, F. Alauzet, Anisotropic mesh adaptation for transient ﬂows simulations, in: IMR, 2003, pp. 335–348.
URL http://www.andrew.cmu.edu/user/sowen/abstracts/Fr970.html
[9] M. J. Castro-Daz, F. Hecht, B. Mohammadi, O. Pironneau, Anisotropic unstructured mesh adaptation for ﬂow simulation, International
Journal for Numerical Methods in Fluids 25 (1997) 475–491.
[10] F. Alauzet, P. L. George, B. Mohammadi, P. J. Frey, H. Borouchaki, Transient ﬁxed point-based unstructured mesh adaptation, International
Journal for Numerical Methods in Fluids 43 (2003) 729–745.
[11] Z. Zhu, P. Wang, S. Tuo, An adaptive solution of the 3-d euler equations on an unstructured grid, Acta Mechanica 155 (2002) 215–231,
10.1007/BF01176244.
URL http://dx.doi.org/10.1007/BF01176244
[12] F. Alauzet, X. Li, E. S. Seol, M. S. Shephard, Parallel anisotropic 3D mesh adaptation by mesh modiﬁcation, Eng. Comput. (Lond.) 21 (3)
(2006) 247–258.
URL http://dx.doi.org/10.1007/s00366-005-0009-3
[13] Y. M. Park, O. J. Kwon, A parallel unstructured dynamic mesh adaptation algorithm for 3-d unsteady ﬂows, International Journal for Numerical Methods in Fluids 48.
[14] J. Waltz, Parallel adaptive reﬁnement for unsteady ﬂow calculations on 3d unstructured grids, International Journal for Numerical Methods
in Fluids 46 (2004) 37–57, 10.1002/ﬂd.674.
URL http://dx.doi.org/10.1002/fld.674
[15] C. Troyer, D. Baraldi, D. Kranzlmuller, H. Wilkening, J. Volkert.
[16] K. Sermeus, H. Deconinck, Solution of steady euler and navier-stokes equations using residual distribution schemes, in: 33rd Lecture Series
on Computational Fluid Dynamics - Novel Methods for Solving Convection Dominated Systems (LS2003-05), von Karman Institute for Fluid
Dynamics, 2003.

S. Gepner, J. Rokicki
/ Procedia
Computer
Science
1 (2012)
/ Procedia
Computer
Science
00 (2010)
1–9 2679–2687

2687
9

[17] H. Deconinck, K. Sermeus, R. Abgrall, Status of multidimensional upwind residual distribution schemes and applications in aeronautics,
AIAA Conference Proceedings (2000) 2000–2328.
[18] J. L. Gustafson, Fixed time, tiered memory, and superlinear speedup, in: In Proceedings of the Fifth Distributed Memory Computing Conference (DMCC5, 1990.
[19] G. Karypis, Parmetis - parallel graph partitioning and ﬁll-reducing matrix ordering.
URL http://glaros.dtc.umn.edu/gkhome/metis/parmetis/overview

