Procedia Computer
Science
Procedia
Computer Science
Science 001(2010)
1–81571–1578
Procedia
Computer
(2012)

www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Asymptotic optimality of the cross-entropy method for Markov
chain problems
Ad Ridder
Vrije University, Amsterdam, the Netherlands

Abstract
The correspondence between the cross-entropy method and the zero-variance approximation to simulate a rare
event problem in Markov chains is shown. This leads to a suﬃcient condition that the cross-entropy estimator is
asymptotically optimal.
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝
Keywords: Importance sampling, Cross-entropy, Asymptotic optimality

1. Model and problem
We deal with a discrete-time Markov chain (X(t))∞
t=0 on a ﬁnite but large state space X, and with a matrix of
transition probabilities P = (p(x, y)) x,y∈X , i.e., p(x, y) = P(X(t + 1) = y|X(t) = x). The state space is partitioned into
three sets: G is a small set of ‘good’ states, F is a small set of ‘failed’ or ‘bad’ states, and the other states form the
large set of ‘internal’ states T = X \ (G ∪ F ). For each internal state x ∈ T let γ(x) be the probability that the Markov
chain will hit the failure set before the good set when the chain starts in state x. Or, more formally, deﬁne
T = inf{t > 0 : X(t) ∈ G ∪ F },
then γ(x) = P(X(T ) ∈ F |X(0) = x). For ease of notation we assume that the good set consists of a single state, denoted
by 0, and that the Markov chain jumps immediately out of it (but not immediately to a bad state), i.e., p(0, 0) = 0 and
p(0, F ) = 0. We are interested in the probability that when the chain starts in the good state 0, it will hit the failure
set F before returning to 0. The associated event is denoted by A = 1{X(T ) ∈ F }.
In this paper we consider the problem of estimating the hitting probability P(A) by simulation. The typical applications that we have in mind, are system failures in models of highly reliable Markovian system, and excessive
backlogs in product-form Jackson queueing networks. The failure set is a rare event that should occur only with
very small probability, which makes the need for reducing the simulation variance, for instance by importance sampling. Reliability and queueing systems have been studied largely in relation to importance sampling estimation of
the performance measures, we refer to overviews in [9] and in [10].
Email address: aridder@feweb.vu.nl (Ad Ridder)

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.176

1572

A. Ridder / Procedia Computer Science 1 (2012) 1571–1578

Ad Ridder / Procedia Computer Science 00 (2010) 1–8

2

The rare event probability P(A) will be estimated by an importance sampling simulation method that implements
a change of measure P∗ , i.e., the estimator Y is the average of i.i.d. replications of
1{A}

dP
,
d P∗

where d P/d P∗ is the likelihood ratio, and where we assume that 1{A}d P is absolute continuous w.r.t. d P∗ . The issue
is to ﬁnd a good change of measure in terms of performance of the estimator Y. The optimal change of measure would
be
Popt (·) = P(·|A),
for which Y would have zero variance [10]. It is shown in [5, 8] that the associated Markov chain has transition
probabilities
γ(y)
popt (x, y) = p(x, y)
, x ∈ T , y ∈ X,
(1)
γ(x)
and popt (x, y) = p(x, y) for good state x = 0, and bad states x ∈ F . The optimal transition probabilities cannot be
used directly for simulation since they require knowledge of the unknown hitting probabilities, however they suggest
to construct an importance sampling algorithm by approximating or estimating the hitting probabilities γ(x). For
instance, let Π(x) be the set of all sample paths of the Markov chain of the form π = (x = x0 → x1 → · → xk ) with
x0 , . . . , xk−1 ∈ T , xk ∈ F and p(x j , x j+1 ) > 0 ( j = 0, . . . , k − 1), and where k = 1, 2, . . .. The probability of path π to
occur is p(π) = k−1
π∈Π(x) p(π). In [5] it is studied
j=0 p(x j , x j+1 ), and, clearly, the hitting probability becomes γ(x) =
how the approximation
γapp (x) = max p(π)
π∈Π(x)

performs in reliability problems. In a slightly diﬀerent context, [6, Section 4] considers the rare event probability that
a random walk reaches high levels. It is shown that it ﬁts in the Markov chain framework and an approximation of
γ(x) is proposed based on an asymptotic approximation of these probabilities.
Another line of research has been developed in [3, 4] for rare event problems in which the probability of interest
can be approximated via large deviations. In this framework, the decay rate is given in terms of a variational problem,
or an optimal control problem. These problems are related to a family of nonlinear partial diﬀerential equations
known as Hamilton-Jacobi-Bellmann (HJB) equations. It is shown how subsolutions of the HJB equations associated
with rare event problems could be used to construct eﬃcient importance sampling schemes. This method has been
successfully applied to several queueing systems, see [3, 4].
The cross-entropy method for rare event simulation [12] considers to choose a change of measure Pce from a
speciﬁed family of changes of measures that minimizes the Kullback-Leibler distance from the optimal Popt . It has
been shown by [1] that the associated transition probabilities pce (x, y) are of the form
pce (x, y) =

E[1{A}N(x, y)|X(0) = 0]
,
E 1{A} z∈X N(x, z)|X(0) = 0

(2)

where N(x, y) is the number of times that transition (x, y) occurs in a random sample path of the Markov chain until
absorption in one of the good or bad states. Again, these transition probabilities cannot be used directly for simulation
since they contain the unknown variables N(x, y), however, in this case they suggest to estimate the expectations in
expression (2), for instance by simulation. This approach has been applied to queueing systems in [1, 2], and to
reliability systems in [11].
In the following sections we shall give more background on the cross-entropy method and how it results in the
expression (2). More importantly, we shall show that in fact the cross-entropy solution is the zero-variance distribution,
i.e., the matrices of transition probabilities satisfy Pce = Popt . This identity will be the basis to formulate in Section 3
a suﬃcient condition for which the estimated cross-entropy solution is asymptotically optimal.
2. Correspondence cross-entropy and zero-variance
Let (Ω, A, P) be the probability space of the sample paths of the Markov chain X(0), X(1), . . ., and denote by X a
random sample path. Recall that our objective is to execute simulations of the Markov chain for estimating the rare

1573

A. Ridder / Procedia Computer Science 1 (2012) 1571–1578

3

Ad Ridder / Procedia Computer Science 00 (2010) 1–8
∗

event probability P(A) = P(X(T ) ∈ F ), that we execute these simulations under a change of measure P , and that the
optimal change of measure is
1{A}
d P.
(3)
d Popt =
P(A)
Suppose that we consider only changes of measures P∗ under which the Markov property is retained, say with matrix
of transition probabilities P∗ , and suppose that we minimize the Kullback-Leibler distance between these changes of
measures and the optimal one, i.e.,
D(Popt , P∗ ),
inf
∗
P ∈P

where the cross-entropy is deﬁned by
D(Popt , P∗ ) = Eopt log

dPopt
(X)
dP∗

=E

dPopt
dPopt
(X) log
(X) .
dP
dP∗

(4)

Substituting (3), minimizing the cross-entropy, and deleting constant terms yields
sup E[1{A} log d P∗ (X)].

(5)

P∗ ∈P

Since the sample path probability d P∗ (X) is a product of individual transition probabilities, we get
T

d P∗ (X) =
t=1

p∗ (X(t − 1), X(t)) =

p∗ (x, y)N(x,y) ,

(6)

(x,y)∈X×X

where N(x, y) is the number of times transition (x, y) occurring in the random sample path X. Substituting the expression (6) into the cross-entropy optimization program (5), and applying the ﬁrst order condition using a Lagrange
multiplier, gives the solution (2) for the individual transition probabilities.
Notice that the optimal transition matrix Popt is a feasible matrix, i.e., an element of P, and thus it must hold that
it is the cross-entropy solution. We shall give a direct proof of the matrix identity Pce = Popt , based on the expressions
of the transition probabilities. In fact we shall prove a relation between the expected number of transitions from x
to y and the absorption probability γ(y). Denote by v(x) the expected number of visits to state x starting at x before
absorption:
⎡∞
⎤
⎢⎢
⎥⎥
v(x) = E ⎢⎢⎢⎣ 1{X(t) = x} X(0) = x⎥⎥⎥⎦ .
t=0

Proposition 1. For all x, y ∈ X:

E[1{A}N(x, y)|X(0) = x] = v(x)p(x, y)γ(y).

Proof. For ease of notation we assume that we have the equivalent modelling in which all the good and bad states are
absorbing. Introduce probabilities (for any x, y ∈ X)
f (x, y) = P((X(t)) reaches state y|X(0) = x)
g(y) = P((X(t)) reaches bad set F without a transition x → y|X(0) = y).
Notice that we allow x and y to be a good or bad state for which these probabilities are obviously either zero or one.
Consider the event
{N(x, y) = n} ∩ {reach bad set from x},

for n ≥ 1. This event can only occur if (A) n − 1 times (i) a number of times [transition x → y
y followed by a
return to x], followed by (ii) [transition x → y followed by a return to x]; then (A) is followed by (B) which is (iii)
y followed by a return to x], followed by (iv) [transition x → y followed by
a number of times [transition x → y

1574

A. Ridder / Procedia Computer Science 1 (2012) 1571–1578

4

Ad Ridder / Procedia Computer Science 00 (2010) 1–8

reaching the bad set without the transition x → y]. That is,
E[1{A}N(x, y)|X(0) = x]
∞

=

n

n=1

∞

p(x, y ) f (y , x)

k=0

n−1

k

p(x, y) f (y, x)

y y

(ii)
(i)
(A)

∞

×

k=0

p(x, y ) f (y , x)

k

p(x, y)g(y) .

y y

(iv)
(iii)
(B)

Let us work out the summations using geometric series and denoting
p(x, y ) f (y , x);

α=

∞

β=

y y

k=0

Hence,
E[1{A}N(x, y)|X(0) = x] =

k

p(x, y ) f (y , x) .
y y

1
1
p(x, y)g(y).
(1 − β)2 1 − α

(7)

In the same manner we determine the absorption probability

γ(y) = P((X(t)) reaches the bad set |X(0) = y).
Partition this event with respect to the number of transitions x → y:
γ(y) =

∞

P(A; N(x, y) = n|X(0) = y)

n=0

= g(y) +
= g(y) +

∞
n=1
∞

f (y, x)P(A; N(x, y) = n|X(0) = x)
f (y, x)

n=1

×

∞
k=0

= g(y) +

∞

p(x, y ) f (y , x)

k=0

k

n−1

p(x, y) f (y, x)

y y

p(x, y ) f (y , x)

k

p(x, y)g(y)

y y
∞

∞

n=1

k=0

p(x, y ) f (y , x)

k

n

p(x, y) f (y, x) g(y).

y y

When we include the ﬁrst term g(y) as the zero-th term of the summation, we obtain
γ(y) =

1
g(y).
1−β

From the expressions (7) and (8) we see that
E[1{A}N(x, y)|X(0) = x] =

1
1
p(x, y)γ(y).
1−β 1−α

(8)

1575

A. Ridder / Procedia Computer Science 1 (2012) 1571–1578

Ad Ridder / Procedia Computer Science 00 (2010) 1–8

5

To conclude, we calculate the proportionality factor:
1
1
=
1−β 1−α 1−

1
p(x,y) f (y,x)
1−α

1
1−α

1
1
=
1 − α − p(x, y) f (y, x) 1 − y y p(x, y ) f (y , x) − p(x, y) f (y, x)
1
1
=
=
= v(x).
1 − y p(x, y) f (y, x) 1 − f (x, x)

=

The last equality is a well-known relation for Markov chains, e.g., see [7].
Corollary 2. For all x, y ∈ X:

pce (x, y) = popt (x, y).

Proof. The identity follows easily by noting that
E[1{A}N(x, y)|X(0) = 0] = f (0, x)E[1{A}N(x, y)|X(0) = x].

3. Asymptotic optimality
In this section we assume that there is a family of rare events {An } parameterized by n = 1, 2, . . . such that each
An satisﬁes the model assumptions of the previous section, and such that limn→∞ P(An ) = 0. Suppose that Yn∗ is an
unbiased estimator of P(An ) obtained by a change of measure P∗ . Then this estimator is asymptotically optimal if
lim

n→∞

log E∗ [(Yn∗ )2 ]
= 2,
log P(An )

see for instance [9]. Now, recall the cross-entropy representation pce (x, y) in (2) of the zero-variance transition probabilities, and suppose that these are estimated by pˆ ce (x, y). A common approach is to apply an iterative scheme to the
optimization program (5). Since the program involves the rare event, we ﬁrst apply a change of measure:
E[1{X(T ) ∈ F } log dP∗ (X)] = E(0)

dP
1{X(T ) ∈ F } log dP∗ (X) .
dP(0)

(9)

This is done for a probability measure P(0) such that (i) the Markov property is retained; (ii) the associated matrix
of transition probabilities is feasible P(0) ∈ P; (iii) the set F is ‘not so’ rare under P(0) . The program (9) is solved
iteratively by estimation: let X(1) , . . . , X(k) be i.i.d. sample paths of the Markov chain generated by simulating the
states according to a matrix of transition probabilities P( j) until absorption in the good or bad states, then we calculate
for j = 0, 1, . . .
k
1
dP
(X(i) )1{X (i) (T ) ∈ F } log dP∗ (X(i) ).
(10)
P( j+1) = arg max
( j)
∗
P ∈P k
dP
i=1
We repeat this ‘updating’ of the change of measure a few times until the diﬀerence P( j+1) − P( j) is small enough (in
some matrix norm). For details we refer to [12].
In this way we obtain an implementable change of measure Pˆ ce , and its associated importance sampling estimator
is denoted by
dP
(X) 1{An }.
(11)
Yˆ nce =
dPˆ ce
Clearly, this estimator is unbiased, i.e., Ece [Yˆ nce ] = P(An ). We claim that it is asymptotically optimal if the following
condition holds.

1576

A. Ridder / Procedia Computer Science 1 (2012) 1571–1578

6

Ad Ridder / Procedia Computer Science 00 (2010) 1–8

Condition 1. There are ﬁnite posivite constants K1 , K2 such that for all n
K1 ≤ D(Popt , Pˆ ce ) ≤ K2 .
This is a condition on the approximation of the zero-variance measure by the implementation of cross-entropy method.
Actually, a weaker condition for the upper bound suﬃces: D(Popt , Pˆ ce ) = o(log P(An )) for n → ∞.
Theorem 1. Assume Condition 1. Then the cross-entropy importance sampling estimator (11) is asymptotically
optimal.
Proof. Notice that D(Popt , Pˆ ce ) = Eopt [log dPopt /dPˆ ce (X)] ≥ 0. Because log P(An ) → −∞, the upper bound in
Condition 1 ensures that
opt
Eopt log dP
(X)
dPˆ ce
= 0.
lim
n→∞
log P(An )
Furthermore, the lower bound gives
lim sup
n→∞

dPopt
(X)
dPˆ ce

log Eopt

opt

Eopt log dP
(X)
dPˆ ce

< ∞.

Now consider, (using (3) in the third equality in the following lines),
⎡
⎤
2⎥
⎢⎢ dP
⎥
Eˆ ce (Yˆ nce )2 = Eˆ ce ⎢⎢⎢⎣
(X) 1{An } ⎥⎥⎥⎦
dPˆ ce
⎡
⎤
2
2⎥
⎢⎢ dP
dPopt
⎥
(X) 1{An }
(X) ⎥⎥⎥⎦
= Eˆ ce ⎢⎢⎢⎣
dPˆ opt
dPˆ ce
⎡
⎤
2⎥
⎢⎢ dPopt
dPopt
⎥
(X) ⎥⎥⎥⎦ = P(An )2 Eopt
(X) .
= P(An )2 Eˆ ce ⎢⎢⎢⎣
ce
ˆ
dP
dPˆ ce

So, we can conclude

2
opt
log Eˆ ce [(Yˆ nce )2 ] log(P(An )) + log E
=
log P(An )
log P(An )

=2+
with
lim

n→∞

log Eopt

log Eopt

dPopt
(X)
dPˆ ce

log P(An )

dPopt
(X)
dPˆ ce

log P(An )

= lim

n→∞

dPopt
(X)
dPˆ ce

,

log Eopt

dPopt
(X)
dPˆ ce
opt

Eopt log dP
(X)
dPˆ ce

opt

(X)
Eopt log dP
dPˆ ce
log P(An )

= 0.

4. A numerical example
We illustrate the theorem by the simple example of simulating the M/M/1 queue (Poisson-λ arrivals, exponential-μ
services) where λ < μ. We consider its associated discrete-time Markov chain (X(t))∞
t=0 by embedding the continuoustime queueing process at the jump times. The transition probabilities are
λ
λ+μ
μ
q = p(x, x − 1) =
λ+μ

p = p(x, x + 1) =

(x = 0, 1, . . .)
(x = 1, 2, . . .).

1577

A. Ridder / Procedia Computer Science 1 (2012) 1571–1578

7

Ad Ridder / Procedia Computer Science 00 (2010) 1–8

The rare event is hitting state n before returning to the zero state. For this model the optimal (zero-variance) transition
probabilities follow easily from calculating the hitting probabilities
γ(x) = P((X(t)) reaches n before 0|X(0) = x),
for x = 1, . . . , n − 1, by solving the equations
γ(x) = p(x, x − 1)γ(x − 1) + p(x, x + 1)γ(x + 1),
with boundary conditions γ(0) = 0 and γ(n) = 1. Let σ = μ/λ. Then we get
γ(x) =

1 − σx
;
1 − σn

popt (x, x + 1) = p

1 − σ x+1
;
1 − σx

popt (x, x − 1) = q

1 − σ x−1
.
1 − σx

Notice that popt (1, 2) = 1.
The cross-entropy between the optimal probability measure Popt and any other probability measure Q which is
associated with transition probabilities q(x, x + 1) and q(x, x − 1), can be determined as follows (where we apply the
product form (6)):
dPopt
(X)
D(Popt , Q) = Eopt log
dQ
⎡
⎢⎢⎢
popt (x, y)
= Eopt ⎢⎢⎢⎣
log
q(x, y)
(x,y)∈X×X
log

=

(x,y)∈X×X

N(x,y)

⎤
⎥⎥⎥
X(0) = 0⎥⎥⎥⎦

popt (x, y) opt
E [N(x, y)|X(0) = 0].
q(x, y)

We may follow the same reasoning as in the proofs of Propositions 1 and 2 for calculating Eopt [N(x, y)|X(0) = 0].
Notice that under Popt 1{A} = 1, f (0, x) = 1, and γ(y) = 1, thus
Eopt [N(x, y)|X(0) = 0] = f opt (0, x)vopt (x)popt (x, y)γopt (y) = vopt (x)popt (x, y).
Finally, the visiting numbers vopt (x) = 1/(1 − f opt (x, x)) can be calculated numerically via recursion (using f opt (x, x +
1) = 1):
f opt (x, x) = popt (x, x − 1) + popt (x, x + 1) f opt (x + 1, x)
f opt (x + 1, x) =

popt (x + 1, x)
.
1 − popt (x + 1, x + 2) f opt (x + 2, x + 1)

We have implemented the cross-entropy method of Section 3 for queueing parameters λ = 0.8 and μ = 1. The
rare-event state n was increased from n = 10 until n = 250. The cross-entropy updating rule (10) was iterated
ten times, starting from the uniform transition probabilities (the sample sizes k were increased proportionally to n).
After the ten updating iterations we estimated the rare event probability P(An ) with sample size 1000 and collected
ce

the estimated relative errors (RE) Var [Yˆ nce ]/Eˆ ce [Yˆ nce ] of the associated estimators, and the estimated ratios (RAT)
log Eˆ ce [(Yˆ nce )2 ]/ log Eˆ ce [Yˆ nce ]. The ﬁgures below illustrate that D(Popt , Pˆ ce )/P(An ) → 0 as n → ∞, and that RAT is
close to two, meaning that the estimator is asymptotically optimal. The last ﬁgure with the relative errors RE indicates
even strong eﬃciency (bounded RE).

1578

A. Ridder / Procedia Computer Science 1 (2012) 1571–1578

8

Ad Ridder / Procedia Computer Science 00 (2010) 1–8

D(Popt , Pˆ ce )/P(An ).

Estimated ratio RAT.

Estimated relative error RE.

5. Conclusion
After having constructed an importance sampling algorithm for rare-event simulation, a key issue is to assess the
statistical performance of the associated importance sampling estimator. In this paper we have considered rare-event
problems in Markov chains, for which we have used the cross-entropy method as the engine of ﬁnding a change of
measure for executing the importance sampling simulations. We have shown that for these problems the cross-entropy
method coincides with the zero-variance approach. This non-implementable optimal change of measure is estimated
by an implementable change of measure that is returned by the cross-entropy method. Our main result is that we
give a suﬃcient condition for the associated importance sampling estimator to be logarithmically eﬃcient. Further
investigations are undertaken to obtain conditions for strong eﬃciency.
Acknowledgements
The author would like to thank Bruno Tuﬃn for his helpful discussions, and his hospitality during a visit to INRIA
Rennes Bretagne Atlantique.

References
[1] Boer, P.T. de, and Nicola, V.F. 2002. Adaptive state-dependent importance sampling simulation of Markovian queueing networks, European
Transactionson Telecommunications 13, pp. 303-315.
[2] Boer, P.T. de, Nicola, V.F., and Rubinstein, R.Y. 2000. Adaptive importance sampling simulation queueing networks, Proceedings of the 2000
Winter Simulation Conference J.A. Joines, R.R. Barton, K. Kang, and P.A. Fishwick (Eds.), IEEE Press, pp. 646-655.
[3] Dupuis, P., Sezer, D., and Wang, H. 2007. Dynamic importance sampling for queueing networks, Annals of Applied Probability 17, pp. 13061346.
[4] Dupuis, P. and Wang, H. 2007. Subsolutions of an Isaacs equation and eﬃcient schemes for importance sampling. Mathematics of Operations
Research 32, 723-757.
[5] L’Ecuyer, P. and Tuﬃn B. 2009. Approximating zero-variance importance sampling in a reliability setting. To appear in Annals of Operations
Research.
[6] L’Ecuyer, P., Blanchet, J.H., Tuﬃn, B., and Glynn, P.W. 2010. Asymptotic robustness of estimators in rare-event simulation, ACM Transactions on Modeling and Computer Simulation. 20.
[7] Feller, W. 1950. An Introduction to Probability Theory and Its Applications,Volume 1, Third edition, Wiley.
[8] Glynn, P.W. and Iglehart, D.L. 1989. Importance sampling for stochastic simulations, Management Science 35, pp. 1337-1392.
[9] Heidelberger, P. 1995. Fast simulation of rare events in queueing and reliability models, ACM Transactions on Modelling and Computer
Simulation 5, pp. 43-85.
[10] Juneja, S. and Shahabuddin, P. 2006. Rare-event simulation techniques: an introduction and recent advances. In Handbooks in Operations
Research and Management Science, Vol. 13: Simulation. S. Henderson and B. Nelson (Eds.), Elsevier, Amsterdam, pp. 291-350.
[11] Ridder, A. 2005. Importance sampling simulations of Markovian reliability systems using cross-entropy, Annals of Operations Research 134,
pp. 119136.
[12] Rubinstein, R.Y. and Kroese, D.P. 2004. The cross-entropy method: a uniﬁed approach to combinatorial optimization, Monte-Carlo simulation and machine learning, Springer.

