Available online at www.sciencedirect.com

Procedia
Science 00
1 (2012)
1297–1300
ProcediaComputer
Computer Science
(2010) 000–000

Procedia
Computer
Science
www.elsevier.com/locate/procedia
www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Computational optimization, modelling and simulation
– a paradigm shift
Xin-She Yanga,*, Slawomir Kozielb
a
Department of Engineering, University of Cambridge, Trumpington Street, Cambridge CB2 1PZ, UK
Engineering Optimization and Modeling Center, School of Science and Engineering, Reykjavik University, 101 Reykjavik, Iceland.

b

Abstract
Computational optimization forms an integrated part of modern computational science. Any good design should intend to achieve
certain optimality, though optimal solutions are often difficult to find in practice since uncertainty and nonlinearity always
present in almost all real-world problems. As resources, time and money are always limited, optimization becomes even more
important in practice. This workshop on Computational Optimization, Modelling and Simulation (COMS 2010) at ICCS 2010
will summarize the latest developments of optimization and modelling and their applications in science, engineering and
industry.
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝
Keywords: algorithm; black-box modelling; computational optimization; derivative-free method; optimization algorithm; modelling; nonlinear
optimization; surragate-based optimization; simulation;

1. Introduction
Computational modelling is becoming the third paradigm of modern sciences, as predicted by the Nobel Prize
winner Ken Wilson in 1980s at Cornell University. This so-called third paradigm complements theory and
experiment to problem solving. In fact, a substantial amount of research activities in engineering, science and
industry today involves mathematical modelling, data analysis, computer simulations, and optimization. The main
variations of such activities among different disciplines are the type of problem of interest and the degree and extent
of the modelling activities. This is especially true in the subjects ranging from engineering design to oil industry
and from climate changes to economics.
Computational optimization is an important paradigm itself with a wide range of applications. In almost all
applications in engineering and industry, we are always trying to optimize something – whether to minimize the cost
and energy consumption, or to maximize the profit, output, performance and efficiency. In reality, resources, time
and money are always limited; consequently, optimization is far more important [1,2]. The optimal use of available
resources of any sort requires a paradigm shift in scientific thinking, this is because most real-world applications
____________
* Corresponding author, email: xy227@cam.ac.uk

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.144

1298

X.-S. Yang, S. Koziel / Procedia Computer Science 1 (2012) 1297–1300
Yang and Koziel / Procedia Computer Science 00 (2010) 000–000

have far more complicated factors and parameters to affect how the system behave; and subsequently, it is not
always possible to find the optimal solutions. We have to settle for suboptimal solutions or even feasible solutions
which are good enough and practically achievable in a reasonable time scale.
This search for optimality is complicated further by the fact that uncertainty almost always presents in the realworld systems. For example, materials properties such as Young’s modulus and strength always have a certain
degree of inhomogeneous variations. The available materials which are not up to the standards of the design will
affect the chosen design significantly. Therefore, we seek not only the optimal design but also robust design in
engineering and industry [2,3]. Optimal solutions, which are not robust enough, are not practical in reality.
Suboptimal solutions or good robust solutions are often the choice.
Another complication to optimization is that most problems are nonlinear and often NP-hard. That is, the solution
time for finding optimal solutions is exponential in terms of problem size. For such problems, there is no efficient
algorithm of polynomial time exists in general. For example, the travelling salesman problem (TSP) intends to visit
each city exactly once, for a given set of n cities, so as to minimize the overall travelled distance. This is an NPhard problem and the number of combinations of possible solutions is the order of n!. In fact, many engineering
applications are usually NP-hard indeed.
Contemporary engineering design is heavily based on computer simulations. This introduces additional
difficulties to optimization. Growing demand for accuracy and ever-increasing complexity of structures and systems
results in the simulation process being more and more time consuming. In many engineering fields, the evaluation of
a single design can take as long as several days or even weeks. On the other hand, simulation-based objective
functions are inherently noisy, which makes the optimization process even more difficult. Still, simulation-driven
design becomes a must for a growing number of areas, which creates a need for robust and efficient optimization
methodologies that can yield satisfactory designs even at the presence of analytically intractable objectives and
limited computational resources.
This workshop on Computational Optimization, Modelling and Simulations (COMS 2010) at the ICCS 2010
intends to provide an opportunity to review and discuss the latest developments concerning optimization and
modelling with a focus on applications in science, engineering and industry. In the rest of this brief summary paper,
we will briefly consider the type of optimization, algorithms and approximation techniques for objective functions.
We will then introduce the topics and papers in this workshop.
2. Optimization and Modelling

2.1. Optimization and Algorithms
There are many ways to formulate optimization problems. However, it is possible to write a nonlinear
optimization problem in the following generic form
Minimize
Subject to

fi(x),
(i=1,2, …, p),
hj(x)=0, (j=1,2,…, M),
gk(x) ≤0, (k=1,2,…, N),

where x = (x1, x2, …, xn) is the vector of the design or independent variables. Here the objective functions fi(x),
equality constraints hj(x), inequality constraints gk(x) are typically nonlinear. If p=1, there is only a single objective,
and this is the case discussed in most literature. In reality, most optimization problems are multiobjective (p>1), and
different concepts such as the Pareto front come into play. Even for single objective optimization, the algorithms are
as diverse as the optimization itself.
If the objective is linear, and all constraints are linear as well, the optimization becomes a linear programming
problem. Dantzig’s simplex method is an efficient algorithm for solving such problems. For nonlinear optimization,
efficient algorithms only exist for certain special cases such as convex optimization [4]. Under the right conditions,
interior-point or barrier methods are very efficient.
However, in general, we do not have efficient algorithms for solving all nonlinear optimization problems.
There are various algorithms which have certain advantages and disadvantages. Gradient-based algorithms such as

X.-S. Yang, S. Koziel / Procedia Computer Science 1 (2012) 1297–1300

1299

Yang and Koziel / Procedia Computer Science 00 (2010) 000–000

hill-climbing require the problem functions (constraints and objective) are relatively smooth. If there is some
discontinuity, we have to use gradient-free or derivative-free methods such as Nelder-Mead downhill simplex
method and Hooke-Jeeves style pattern search. However, all these methods are local search methods. As most
optimization problems are nonlinear and multimodal, global search methods should be used. Global search
algorithms are mostly heuristic and metaheuristic with stochastic components. Genetic algorithms and particle
swarm optimization are two excellent examples [5,7].
For a given problem, the chosen algorithm may depend on the type of problem, solution quality and available
resources. As the No-Free-Lunch theorems [6] dictate, there is no universally efficient algorithm for all
optimization problems. Therefore, a substantial amount of effort in optimization research is to identify the
appropriate algorithm for a given type of problem.
2.2 Objectives and Simulators
Even with an efficient optimization algorithm, the evaluations of the objective functions are often timeconsuming. In most engineering design and industrial applications, the objective cannot be expressed in terms of
explicit functions, as the dependence of the objective on design variables is complex and implicit. This black-box
type of optimization often requires a numerical simulator such as computational fluid dynamics and finite element
analysis. Such simulators are very computationally expensive. Furthermore, almost all optimization algorithms are
iterative, and require quite many times of function evaluations. Therefore, any technique in improving the
efficiency of simulators or function evaluations is crucially important [7,8].
Surrogate-based and knowledge-based optimization uses certain approximations to the objective so as to reduce
the cost of objective evaluations [8]. The approximations are often local, while the quality of approximations is
evolving as the iterations proceed.
Applications of optimization in engineering and industry are diverse. This is reflected in the papers submitted to
this workshop. The responses and interests to our call for papers are overwhelming; however, due to limited space
and time slots for presentations, many high-quality papers cannot be included in the workshop. The accepted papers
are quite representative and cover almost all important topics of computational optimization and modelling [9].
3. New Developments
The accepted papers of this workshop COMS2010 at ICCS 2010 have spanned a wide range of applications and
reflect the state-of-the-art developments in computational optimization, modeling and simulations. New algorithms
and improved performance are often formulated by hybridization. N. Saadouli presented a computationally efficient
solution algorithm for a large scale stochastic dynamic program, while D. Clever et al. present a combination of an
adaptive multilevel SQP method and a space-time adaptive PDAE solver for optimal control problems. At the same
time, G. A. Gray et al. discuss hybrid optimization schemes for simulation-based problems.
Algorithm development and analysis include a wide range of techniques. From the integer simulation-based
optimization by local search by J. Sklenar and P. Popela, stochastic programming with binary second-stage variables
by T. Shiina, to the election campaign optimization algorithm by W. Lv et al. In addition to these exciting
development, O. Kolb et al. present a modified QR decomposition technique to avoid non-uniqueness in water
supply networks with extension to adjoint calculus, while M. Thaher and T. Takaoka discuss an efficient algorithm
for the k-maximum convex sums, and H. I. Sayed et al. present SWOOP -- an adjustable global optimization
technique. On the other hand, M. Simsek et al. outline the recent developments in knowledge-based neural modeling
with extensive discussion in applications. S. Benhammada and S. Chikhi discuss a semi-formal specification for a
generic model of artificial stock markets.
Applications range from the application of derivative-free methodologies to generally constrained oil production
optimization problems by D. Echeverría Ciaurri et al., to the multi-fidelity design optimization of transonic airfoils
using shape-preserving response prediction by L. Leifsson and S. Koziel, followed by the optimization and data
mining for fracture prediction in geosciences by G. Shi and X. S. Yang. In addition, P. Domschke et al. present an
adaptive model switching and discretization algorithm for gas flow on networks, while G. Gharooni-fard et al.
discuss the scheduling of scientific workflows using a chaos-genetic algorithm.

1300

X.-S. Yang, S. Koziel / Procedia Computer Science 1 (2012) 1297–1300
Yang and Koziel / Procedia Computer Science 00 (2010) 000–000

Meanwhile, F. Li et al. present a rule-based optimization approach for airline load planning system. Furthermore,
D. Lozovanu and S. Pickl study the optimal stationary control of discrete processes and a polynomial time algorithm
for stochastic control problems on networks; K. Wendt et al. present a knowledge-guided genetic algorithm for input
parameter optimization in environmental modeling.
As we have seen, the algorithms and applications of computational optimization and modeling are diverse and
wide-ranging. There is no doubt that new efficient algorithms will emerge, and more and more applications will
appear in the near future. This workshop may well pave the way for further discussions and development in
optimization and modelling.

References
1.
2.
3.
4.
5.
6.
7.
8.
9.

J. Arora, Introduction to Optimum Design, McGraw-Hill, 1989.
K. Deb, Optimization for Engineering Design: Algorithms and Examples, Prentice-Hall, New Delhi, 1995.
E. G. Talbi, Metaheuristics: From Design to Implementation, John Wiley & Sons, 2009.
S. P. Boyd and L. Vandenberghe, Convex Optimization, Cambridge University Press, 2004.
D. E. Goldberg, Genetic Algorithms in Search, Optimization and Machine Learning, Reading, Mass., Addison Wesley, 1989.
D. H. Wolpert and W. G. Macready, No free lunch theorems for optimization, IEEE Trans. Evolutionary Computation, 1, 1997. 6782.
X. S. Yang, Introduction to Computational Mathematics, World Scientific Publishing, Singapore, 2008.
S. Koziel, J. W. Bandler and K. Madsen, Quality assessment of coarse models and surrogates for space mapping optimization,
Optimization and Engineering, 9(4), 2008, 375-391.
Proceedings of International Conference on Computational Science (ICCS 2010), Procedia Computer Science, May 31 – 2 June,
2010. Amsterdam.

