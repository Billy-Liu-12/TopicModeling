Procedia Computer
Science
Procedia Computer
001(2010)
1–9
Procedia
ComputerScience
Science
(2012)
515–523

www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

A proposal for autotuning linear algebra routines on multicore
platforms✩
Javier Cuencaa,1 , Luis P. Garc´ıab , Domingo Gim´enezc
a Departamento

b Servicio

de Ingenier´ıa y Tecnolog´ıa de Computadores, University of Murcia, Spain
de Apoyo a la Investigaci´on Tecnol´ogica, Polytechnic University of Cartagena, Spain
c Departamento de Inform´
atica y Sistemas, University of Murcia, Spain

Abstract
The use of an OpenMP compiler optimized for the corresponding multicore system is a good option, but it is
possible in a system to have access to more than one compiler and different compilers can appropriately optimize
different parts of the code. In this paper we present a proposal for an autotuning system for linear algebra routines that
decides the best compiler for each situation, as well as other parameter values, as, for example, the number of threads
to generate.
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝

Keywords: Linear algebra, Autotuning, Compilers, OpenMP
1. Introduction
The arrival of multicores has made parallel computing more available to the scientiﬁc groups. Today it is possible
to have parallel systems not only in the form of clusters, but also in a personal computer or a laptop. Nowadays,
there is great interest in the scientiﬁc community in using multicore systems efﬁciently to solve problems, but without
the great effort of reprogramming existing sequential codes, which work well [1]. In those multicore platforms it
is easier to develop a parallel code from a sequential one using the shared memory paradigm than to transform the
code into a message-passing code. Using the shared memory paradigm, it is possible to express data parallelism with
explicit threading techniques like Pthreads [2], but it is an invasive process. The computation must be separated into a
function that can be mapped to threads, within which the work must be explicitly divided among the threads. Another
possibility is to describe parallelism to the compiler using OpenMP [3], via a directive-based syntax. It is usual in a
multicore system to have access to more than one OpenMP compiler. In some cases, one compiler generates good
executable code from a sequential code, but another optimizes more the use of multiple threads. It is also possible to
obtain executables which perform well with a lower number of threads than of cores in the node, although when the
number of threads increases, the performance greatly decreases. The existence of more running threads than available
✩ This work has been partially supported by the Conserjer´ıa de Educaci´
on de la Regi´on de Murcia (Fundaci´on S´eneca, 08763/PI/08), and by the
Spanish Ministerio de Ciencia e Innovaci´on (TIN2008-06570-C04-02/TIN)
Email addresses: javiercm@ditec.um.es (Javier Cuenca), luis.garcia@sait.upct.es (Luis P. Garc´ıa), domingo@um.es
(Domingo Gim´enez)
1 Corresponding author

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.055

516

Cuencaetetal.
al.//Procedia
Procedia Computer
J. J.Cuenca
ComputerScience
Science001(2010)
(2012)1–9
515–523

2

cores on a platform could occur when the algorithm needs an appropriate amount of threads for its improvement due
to a better balance of the work between the threads. Another situation of overloaded cores could occur when the
platform is shared by different routines, with the total number of threads being higher than the number of cores.
In previous works [4], we developed an Automatic Tuning System (ATS) for linear algebra routines on distributed
memory environments. Linear algebra functions are widely used in the solution of scientiﬁc and engineering problems,
which means that there is much interest in developing highly efﬁcient linear algebra libraries, and these libraries are
used by non-experts in parallel programming. In recent years several groups have been working on the design of highly
efﬁcient parallel linear algebra libraries. These groups work in different ways: optimizing the library in the installation
process for shared memory machines [5] or for message-passing systems [6], analyzing the adaptation of the routines
to the conditions of the system at a particular moment [7], using poly-algorithms [8] and poly-libraries [9]. For each
routine, the kernel of our ATS contains an execution time model of the routine. The model includes the characteristics
of the platform (hardware + basic installed libraries) like System Parameters (SP), and a set of Algorithmic Parameters
(AP), whose values should be appropriately chosen by the ATS in order to reduce the execution time of the routine:
T exe = f (S P, n, AP).
Our general goal now is to extend the functionality of the ATS, with a Poly-Compilation Engine (PCE) that
generates different executables of each routine (one for each compiler in the system), and, when a particular problem
has to be solved, it selects the executable which best ﬁts the problem characteristics (the idea is a generalization of
well known methods to accelerate the solution of computationally demanding problems: poly-algorithms and polylibraries). In this way, the PCE is an ATS that manages another AP: the selection of the most appropriate compiled
version of the routine, as well as another AP like the number of threads, different block sizes...
This paper is organized in the following way: in section 2 the structure of the PCE is detailed, in section 3 a linear
algebra routine (Strassen matrix multiplication) used like a proof of concept is described; in section 4 the process
of installing, autotuning and running this routine on different systems is shown. Finally, section 5 summarizes the
conclusions and outlines future research.
2. Poly-Compilation Engine
In [10] we introduced the Poly-Compilation Benchmarking tool (PCB), the ﬁrst component of the Poly-Compilation
Engine (PCE). The PCB contains a set of benchmarking routines (BR): simple routines consisting basically of
OpenMP primitives. For each high-level routine X to execute, the PCE will include the corresponding set of data
(the SP information provided by the PCB and the problem size to solve) in the execution time model of X. With this
binomial (theoretical model plus empirical information), the decision engine takes the appropriate decisions, AP (the
compiled version to use and, if possible, the best number of threads), in each situation (Figure 1).
2.1. Benchmarking Routines of the PCB
In this subsection we summarize the description of the basic routines of the set of benchmarking routines (BR)
that make up the tool PCB2 . These routines are designed to test the efﬁciency of OpenMP primitives for creation and
management of threads. These routines are:
2.1.1. R-generate
This routine consists basically of creating a series of threads with a ﬁxed quantity of work per thread. Our aim is
to compare the time for creating and managing threads. When the number of threads generated is less than or equal
to the number of available cores, the execution time can be modeled3 : T R−generate = PT gen + NT work , where P is the
number of threads generated, T gen is the time necessary to generate a thread, N is the problem size and T work is the
working time unit (time to perform an operation in a CPU plus memory time to load the operands and to store the
results). That is, the ﬁrst term corresponds to the time to create the P threads, whereas the second one represents the
2 We have implemented our own benchmarking routines instead of using existing ones, like the EPCC OpenMP constructs benchmark [11] or
SPEC OMP [12], in order to manage their algorithms and, so, the corresponding executing time models.
3 The models proposed in this work do not expect to detail the architectural behavior of the routines, but are just used to compare these routines
with each other and to predict the execution time of these routines in different situations.

J. Cuenca
al. / Procedia
Computer
Science
00 (2010)
1–9
J. Cuenca
et al.et/ Procedia
Computer
Science
1 (2012)
515–523

Figure 1: Working scheme of the PCE for a routine X, on a platform with two compilers: A and B.

3
517

518

4

Cuencaetetal.
al.//Procedia
Procedia Computer
J. J.Cuenca
ComputerScience
Science001(2010)
(2012)1–9
515–523

time that each thread needs (all of them are working in parallel and performing N operations each) to carry out its
work.
The model of the execution time when the number of threads exceeds the available cores is obtained by adding
a new term corresponding to the context switching time among the different threads that share the same core:
sw
T R−generate = PT gen + NT work CP 1 + TTcpu
, where C is the number of available cores ( CP corresponds to the number
of threads assigned per core), and T cpu is the CPU time assigned to each thread between two consecutive switchings.
sw
Finally, T sw is the time necessary to switch the running thread on a core, and, so TTcpu
corresponds to the time increment,
due to thread switchings, per CPU working time unit.

2.1.2. R-pfor
This routine consists of paralleling a simple for loop where there is a signiﬁcant work inside each iteration. Our
aim is to compare the time of dynamically distributing a set of homogeneous tasks between threads.
The model of the execution time of this routine when the number of threads does not exceed the number of
available cores would be: T R−p f or = PT gen + NPt T work , where Nt is the complete problem size. Therefore, the ﬁrst term
corresponds to the time to generate the P threads and the second to the time taken to perform the work by each thread
working in parallel. If there are more threads than cores, the model would be: T R−p f or = PT gen +
where the new parameters (C, T cpu and T sw ) have the same meaning as in the R-generate routine.

Nt
C T work

1+

T sw
T cpu

,

2.1.3. R-barrier
This routine consists basically of a barrier primitive set after a parallel working area. The goal is to compare
the time to perform a global synchronization. The execution model of this routine, for a number of threads less
than or equal to the number of cores, would be: T R−barrier = PT gen + NT work + PT syn , where T syn corresponds to the
synchronization time per thread. When the number of threads exceeds the number of cores, the model would be:
sw
T R−barrier = PT gen + NT work CP 1 + TTcpu
+ PT syn . So, the model of this routine is the same as that for the R-generate
one, but adding the last term corresponding to the synchronization time.

3. Strassen Matrix-Matrix multiplication
Strassen [13] introduced an algorithm to multiply matrices of size n × n which has a lower level complexity than
the classical O(n3 ). It is based on a scheme for the product, C = AB, of two 2 × 2 block matrices:
C11
C21

C12
C22

=

A11
A21

A12
A22

B11
B21

B12
B22

where each block is square. In the ordinary algorithm there are eight multiplications and four additions. The original
algorithm can be reorganized to compute C with just seven multiplications and eighteen additions.
Pre-additions
S 1 = A11 + A22
S 2 = A21 + A22
S 3 = A11 + A12
S 4 = A21 − A11
S 5 = A12 − A22

T1
T2
T3
T4
T5

=
=
=
=
=

B11 + B22
B12 − B22
B21 − B11
B11 + B12
B21 + B22

Recursive Calls
M1 = S 1 × T 1
M2 = S 2 × B11
M3 = A11 × T 2
M4 = A22 × T 3
M5 = S 3 × B22
M6 = S 4 × T 4
M7 = S 5 × T 5

Post-additions
C11 = M1 + M4 − M5 + M7
C12 = M3 + M5
C21 = M2 + M4
C22 = M1 + M3 − M2 + M6

The Strassen algorithm can apply to each of the half-size block multiplications associated with Mi . Thus, if the
original A and B are square matrices of dimension n = 2q , the algorithm can be applied recursively. As a result,
Strassen’s algorithm has a complexity of O(nlog2 7 ) ≈ O(n2.807 ).
In order to build the analytical model of the run time, we identify different parts of the Strassen algorithm with
different basic routines:

5
519

J. Cuenca
al. / Procedia
Computer
Science
00 (2010)
1–9
J. Cuenca
et al.et/ Procedia
Computer
Science
1 (2012)
515–523

• The BLAS3 function DGEMM is used to compute the seven Mi at the lower level. If the recursion level used
is l, the matrix multiplications are made in blocks of size 2nl .
• In the recursion level l, with l = 1, 2, 3, . . ., there are 7l−1 18 matrix additions of size
DAXPY can be used to compute S i , T i and Ci j .

n
.
2l

The BLAS1 function

The execution time for this routine, when the number of threads is less than or equal to the number of cores and
for recursion levels one and two, can be modelled by the formula:
T R−strassen = PT gen + 7

T R−strassen = P1 P2 T gen + 49

2

P

n 3
22

2

n 3
2

P2 P1

T mult +

T mult + 7

18n2
T add
4

18n2
42

P1

T add + 18

(1)
n2
T add
4

(2)

When the number of threads exceeds the number of cores, the model would be:
T R−strassen = PT gen + 7

T R−strassen = P1 P2 T gen + 49

2

n 3
22

C

2

n 3
2

C

T mult 1 +

T sw
18n2
+
T add
T cpu
4

(3)

18n2

T mult 1 +

T sw
T sw
n2
42
+7
+ 18 T add
T add 1 +
T cpu
min(P1 , C)
T cpu
4

(4)

where P1 , P2 correspond to the number of threads for the ﬁrst and for the second recursion level of the algorithm.
T mult is the working time unit for one matrix multiplication, and T add is the working time unit for a matrix addition.
4. The complete autotuning process
This section shows a complete example of how the PCE works, estimating the SP by means of the PCB and
then using these values and the execution time model of a linear algebra routine (the R-strassen routine described in
the previous section) to obtain an approximate image of the behavior of this routine for different problem sizes and
numbers of threads. Thus, for a speciﬁc problem size, the PCE could decide the most appropriate values for the AP
(compiled version and number of threads) of this routine in order to reduce its execution time.
For the experiments performed in this work, the multicore platforms used and their corresponding compilers are:
• P2c: Intel Pentium, 2.8 GHz, 2 cores, 1 MB L2, 2 GB RAM. Linux 2.6, icc 10.1 and gcc 4.1.1.
• X4c: Intel Xeon, 3 GHz, 4 cores, 2 MB L2, 4 GB RAM. Linux 2.6, icc 10.1 and gcc 4.2.3.
• A4c: Alpha EV68CB, 1 GHz, 4 cores, 1.75 MB L2, 16 GB RAM. Tru64 UNIX v5.1, cc 6.3 and gcc 4.3.
• X8c: Intel Xeon, 2 GHz, 8 cores, 4MB L2, 32 GB RAM. Linux 2.6, icc 10.1 and gcc 3.4.6.
In all these platforms the support for hyperthreading is disconnected and the compiler optimizations used were
-O3.
Figure 2 (left) shows the execution times of the R-strassen routine obtained with these four platforms for a problem
size n = 1000. The executions are performed for different numbers of threads for the ﬁrst and for the second level
of the algorithm (P1 and P2 ). Both versions have a similar behavior for a number of threads less than or equal to the
number of available cores on each platform. The differences appear when the number of threads grows, the times
obtained with gcc tend to be better than those with the other compiler. The optimal number of threads per level
changes from one platform to the others, so it is a very complicated task to estimate the optimal selection of P1 and
P2 values without the aid of an autotuning system.

6

Cuencaetetal.
al.//Procedia
Procedia Computer
J. J.Cuenca
ComputerScience
Science001(2010)
(2012)1–9
515–523

520

Figure 2: Experimental (left) and theoretical (right) execution time of the R-strassen routine on the different platforms, for P1 × P2 threads. Problem
size=1000.

Table 1: System Parameters averaged values for different platforms and compilers, obtained by the Poly-Compilation Benchmarking tool at
installation time.

T gen (μs)
T sw
T cpu

T add (ns)
T mul (ps)

P2c
icc
gcc
75
25
2 + 0.01P
7 − 0.01P
20 + 0.05P
20
400 + 100P
400 + 0.1P

X4c
icc
75
0.9 + 0.3P
23 + 0.3P
140 + 10P

gcc
25
0.9 + 0.01P
30 − 0.3P
140 − P

A4c
cc
75
0.8 + 0.2P
40 + P
60

gcc
25
0.8 + 0.02P
40 − 0.1P
60 − 0.5P

X8c
icc
75
6 + 0.05P
10
100

gcc
25
0.5 + 0.01P
10
100

J. Cuenca
al. / Procedia
Computer
Science
00 (2010)
1–9
J. Cuenca
et al.et/ Procedia
Computer
Science
1 (2012)
515–523

7
521

4.1. Calculating SP values
Table 1 shows the SP averaged values obtained by the PCB. The value of T gen on each platform and for each
compiler can be calculated using the execution times obtained with the routines R-generate and R-pfor, for a problem
size N = 1, which means we can disregard the second term of the R-generate and R-pfor models.
The time to generate the threads is similar in the four platforms. Although it varies depending on the compiler
used. This could be because the threads generated from the OpenMP code have different characteristics according to
which compiler is used.
In the next row the value for the quotient of parameters T sw /T cpu is shown, that is, the percentage of increment of
the execution time due to the time of switching running threads on each core. These values depend on the total number
of threads and it can be approximated by a linear function with different coefﬁcients according to each platform and
each compiler. These coefﬁcients have been calculated using a simple linear algebra routine (a vector addition) with a
ﬁxed quantity of work per thread. This routine has been executed for different numbers of threads (from 2 to 64) and
the percentage of increment of the execution time versus the threoretical time of the routine has been obtained. For
the gcc versions this value either grows slowly or, even, decreases a bit. However, for the other compiler there is a
clear growth, that is, the thread management per core is more complicated.
In the third row of the table the values for the T add are shown. This parameter describes the unit cost per arithmetic
operation of two double precision real numbers immersed in an addition of two matrices. A matrix addition has been
used to measure this parameter, incrementing the number of involved threads for a ﬁxed problem size.
Finally, the parameter T mul describes the unit cost per arithmetic operation of two double precision real numbers
immersed in a multiplication of two matrices. Like the previous parameter, a matrix multiplication has been used to
measure this parameter, incrementing the number of involved threads for a ﬁxed problem size.
Regarding these two arithmetic parameters (T add and T mul ) it is noticed that the time to perform a basic operation
inside a matrix multiplication is inferior than inside a matrix addition. This is because the values of these parameters
include not only the CPU time to perform the arithmetic operation but also the time to manage the operands and the
results, moving them across the different memory levels. The matrix multiplication is implemented by blocks, reusing
more data from the higher memory levels (it performs O(n3 ) operations on O(n2 ) data) than the matrix addition (O(n2 )
operations on O(n2 ) data).
It is also important to indicate that, for the gcc versions, T add depends on the number of threads, so, for a ﬁxed
problem size, if the number of threads increments, the value of this parameters tends to decrease, or, at least, it does
not grow as expected due to the collision of more than one thread per core. This could due to a better use of the CPU
resources (the different functional units) by the threads immersed in this vectorial operation. The T mul tends to be
more constant, although it also has a certain tendency to decrease in the gcc versions.
4.2. Obtaining the image of the behaviour of the routine
The next step performed by the PCE after calculating the SP values is to replace them in the theoretical model,
obtaining a theoretical-experimental model that constitutes the image that the PCE has of the behaviour of the routine
for the problem size to solve. Figure 2 shows the model time of the R-strassen routine for a problem size n = 1000,
using the SP values calculated in the previous step (table 1).
Comparing the charts in ﬁgure 2, it can be appreciated how the proposed model does not predict the behavior
of the routine exactly. This was not its goal, but captures the tendencies of the execution time when the AP values
change, in order to get an idea of where the minimal execution times are in the searching space of the values for these
conﬁgurable parameters.
Thus, it is noticed, both in the real execution time and in the theoretical times, that the two compiled versions
have similar behaviors when there are fewer threads than cores. From this point, the times with gcc versions have
certain tendency to reduce, due to the decreases of the values of the arithmetical SP (T add and T mul ), until they reach a
minimum, where they begin to grow or, at least, remain more or less constant. This is due mainly to the increment in
the value of the quotient T sw /T cpu and to the end of the descent of the arithmetical SP values. On the other hand, the
icc/cc versions tend to grow according to the number of threads generated, due to the behavior of the arithmetic SP
for these compilers (table 1).

522

8

Cuencaetetal.
al.//Procedia
Procedia Computer
J. J.Cuenca
ComputerScience
Science001(2010)
(2012)1–9
515–523

Table 2: Algorithmic Parameters values, for the R-strassen routine, taken by the Poly-Compilation Engine for different platforms and compilers
(Problem size=1000).

compiled version (cv)
number of threads for the 1st level (P1 )
number of threads for the 2nd level (P2 )

P2c
gcc
7
7

X4c
gcc
4
1

A4c
gcc
4
1

X8c
gcc
7
2

Table 3: Execution times of the R-strassen routine obtained with different Algorithmic Parameters values sets (times in seconds). Problem
size=1000.

PCE
ORA
HW
SW

P2c
1.19
1.17
1.37
1.22

X4c
0.50
0.49
0.55
1.31

A4c
0.49
0.45
0.65
1.20

X8c
0.16
0.11
0.12
0.32

4.3. Taking decisions: AP values
The last step to be carried out by the PCE, prior to executing the routine, consists of selecting the appropriate
values for the AP. This task is performed by consulting the theoretical-experimental image of the routine (the model
with the SP values and the problem size to solve) and obtaining the minimum of this function.
The AP values taken by the PCE to solve a problem of n = 1000 with R-strassen are shown in table 2. The
compiled version chosen is gcc in the four platforms studied, whereas the selected number of threads per level (P1
and P2 ) is different depending of the platform, that is, it is very difﬁcult to obtain a good selection of these parameters
without an autotuning system.
4.4. Executing the routine
Finally, the PCE executes the R-strassen routine using the AP values chosen in the previous step. In order to test
the PCE, in table 3 a comparative among the real execution time obtained with different AP values sets is shown. The
ﬁrst row shows the execution times obtained with the AP values chosen by the PCE (PCE). The next row shows the
execution times that would be obtained with a perfect oracle which always chooses the best AP values (ORA). In the
third row, we show the times obtained using the AP values chosen by a simulated user that is an expert in the platforms
characteristics (HW). This user chooses the speciﬁc compiler of each platform (icc or cc), and always a number of
threads equal to the available cores (For instance, in a 4-core platform we take the average time with 1 × 4, 2 × 2 and
4 × 1 conﬁgurations). Finally, we show the execution times obtained with the AP values chosen by a simulated user
that is an expert in the algorithm characteristics (SW). This user selects seven threads per level in order to balance the
work among all these threads, and one of the two available compilers (we take the average time of them).
It is seen that for this routine and platforms a knowledge of the platform is more effective than that of the algorithm.
However, obviously, in almost all the cases, the capacity of managing the algorithm information (by means of the
model) and the platform characteristics (by means of the SP values) lets the PCE take the best decisions automatically
(AP values).
5. Conclusions
We have shown how a good choice of series of parameters, like the compiler to use or the number of threads to
generate, in a multicore system could contribute to accelerate the solution of scientiﬁc problems. What the best choice
of values for these parameters is depends on a number of factors: the type of routine, the platform, the problem size...
Therefore, we consider a poly-compiling approach is necessary to decide these parameters automatically according to

J. Cuenca
al. / Procedia
Computer
Science
00 (2010)
1–9
J. Cuenca
et al.et/ Procedia
Computer
Science
1 (2012)
515–523

9
523

all the basic information collected. The information is obtained with a set of benchmarking routines that constitute the
kernel of the Poly-Compilation Benchmarking tool (PCB) -simple routines basically formed by OpenMP primitivesin order to extract information about creating and managing simple threads and performing arithmetic operations.
The PCB empirically calculates the basic System Parameters (SP) values for each pair platform-compiler. After that,
the PCE selects the Algorithmic Parameters (AP) values (the compiled version and the number of threads) in each
situation, through the theoretical model of the execution time of the routine with the SP measurement by the PCB. The
behaviour of the PCE has been shown in this paper, working with the Strassen matrix multiplication. Similar studies
with other linear algebra routines are being performed.
References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]

Akhter, S., Roberts, J.: Multi-Core Programming. Intel Press (2006)
Butenhof, D. R.: Programming with POSIX Threads. Addison-Wesley Professional (1997)
OpenMP: The OpenMP API speciﬁcation for parallel programming. http://openmp.org/wp/
Cuenca, J., Gim´enez, D., Gonz´alez, J.: Architecture of an automatic tuned linear algebra library. Paral. Comp. 30(2) (2004) 187–220
Whaley, R., Petitet, A., Dongarra, J.: Optimization of software and the ATLAS project. Paral. Comp. 27(1-2) (2001) 3–35
Cuenca, J., Gim´enez, D., Gonz´alez, J.: Towards the design of an automatically tuned linear algebra library. In: 10th EUROMICRO Workshop
on Parallel, Distributed and Networked Processing, IEEE (2002) 201–208
Petitet, A., Blackford, S., Dongarra, J., Ellis, B., Fagg, G., Roche, K., Vadhiyar, S.: Numerical libraries and the grid. International Journal of
High Performance Applications and Supercomputing 15 (2001) 359–374
Skjellum, A., Bangalore, P.V.: Driving issues in scalable libraries: Polyalgorithms, data distribution independence, redistribution, local
storage schemes. In: 7th SIAM Conf. on Parallel Proc. for Scientiﬁc Computing. (1995) 734–737
Alberti, P., Alonso, P., Vidal, A., Cuenca, J., Garc´ıa, L.P., Gim´enez, D.: Designing polylibraries to speed up linear algebra computations.
International Journal of High Performance Computing and Networking 1(1-2-3) (2004) 75–84
Cuenca. J., Garc´ıa, L. P., Gim´enez, D., Quesada, M.: Analysis of the inﬂuence of the compiler on multicore performance In: 18th EUROMICRO Conf. Paral. Dist. and Network-Based Comp., to be published.
Bull, J.M., O’Neill, D.: A microbenchmark suite for OpenMP 2.0. In: Third European Workshop on OpenMP (EWOMP’01). (2001) 41–48
Saito, H., Gaertner, G., Jones, W., Eigenmann, R., Iwashita, H., Lieberman, R., van Waveren, M., Whitney, B.: Large system performance of
spec omp2001 benchmarks. In: Proc. 4th Symp. High Perf. Comp., LNCS 2327. (2002) 370–379
Strassen, V.: Gaussian Elimination is Not Optimal. Numerische Mathematik 3(14) (1969) 354–356

