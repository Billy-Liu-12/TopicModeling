Procedia Computer
Science
Procedia
Science
00 (2010)
1–10
ProcediaComputer
Computer
Science
1 (2012)
307–316

www.elsevier.com/locate/procedia

International Conference on Computational Science, ICCS 2010

Raising the order of multivariate approximation schemes using
supplementary derivative data
Dirk Kraaijpoela,∗, Tristan van Leeuwenb
a Climate

and Seismology Department, Royal Netherlands Meteorological Institute (KNMI)
of Civil Engineering and Geosciences, Delft University of Technology

b Faculty

Abstract
We propose a generic procedure to raise the approximation order of multivariate approximation schemes using
supplementary derivative data. The procedure applies to all schemes that reproduce polynomials to a certain degree,
including most common types of (quasi-) interpolation and moving least-squares. For an approximation scheme of
order m and a dataset that provides n supplementary orders of derivative data, the procedure results in an approximation
order of m + n. This is achieved using a modiﬁcation of the Taylor expansion, the reduced dual Taylor expansion, that
is applied to the data prior to the evaluation of the scheme. The procedure is easy to implement in existing schemes
and is expected to be useful immediately in a wide range of applications.
c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
⃝

Keywords: approximation, polynomial reproduction, (quasi-) interpolation, moving least-squares, derivatives,
reduced dual Taylor expansion

1. Introduction
Functional approximation schemes are omnipresent in the computational sciences. The reader is referred to a
number of excellent text books and (review) papers on interpolation and approximation theory [1, 2], spline functions [3], multivariate polynomial interpolation [4, 5], moving least-squares approximation [6], radial basis functions
[7], natural neighbor interpolation [8, 9], polygonal ﬁnite-element interpolants [10], nonlinear approximation [11],
interpolation in signal and image processing [12] and geometric modeling [13].
Usually, the data available to approximation schemes consist of function values at discrete node locations. The
choice in schemes that are able to accommodate derivative data is rather limited. In classical interpolation theory
incorporation of derivative data is well known as the Hermite interpolation problem. In the univariate case, solution
procedures are well established [1]. However, extensions to arbitrary data conﬁgurations in multiple dimensions are
diﬃcult to construct [4, 5], and probably less attractive for routine application. In non-interpolating approximation
schemes, such as quasi-interpolation and moving least-squares, the incorporation of derivative data appears to be
largely unexplored.
∗ To

whom correspondence should be addressed.
Email address: dirk.kraaijpoel@knmi.nl (Dirk Kraaijpoel)

c 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
1877-0509 ⃝
doi:10.1016/j.procs.2010.04.034

308

Kraaijpoel,
van Leeuwen
/ Procedia
Computer
Science
1 (2012)
307–316
DirkD.Kraaijpoel
andT.Tristan
van Leeuwen
/ Procedia
Computer
Science
00 (2010)
1–10

2

In this paper we propose a practical procedure for incorporating supplementary derivative data in existing approximation schemes. The procedure applies generically to all schemes that are based on function values at discrete
nodes and that reproduce polynomials to some degree. This includes most common types of interpolation, quasiinterpolation and moving least-squares. The derivative data must be available at the same nodes as the function
values. An early version of the procedure, limited to linear interpolation schemes, was published in [14, Ch. 4]. Recently came to our attention an independent line of research [15, 16, 17, 18] that achieves similar results in slightly
diﬀerent contexts. With respect to these papers our procedure is broader in scope because it aims at general applicability in a wider class of approximation schemes. Our presentation is geared toward direct implementation in existing
approximation schemes.
The paper is organized as follows. We start by establishing some notation and terminology, including a deﬁnition
of the dual Taylor expansion in Deﬁnition 2.1. Subsequently we motivate our work by showing that this dual Taylor
expansion can — in principle — be used to incorporate supplementary derivative data in arbitrary approximation
schemes. A simple example, however, reveals that the result is sub-optimal. We then proceed by introducing the
central element of our procedure, the reduced dual Taylor expansion in Deﬁnition 4.1. It is this expansion that
allows us to raise the order of arbitrary approximation schemes as proven in Theorem 5.1. In the subsequent section
we provide examples of how the procedure can be applied to scattered data approximation. We ﬁnalize with some
additional remarks and a conclusion.
2. Notation and terminology
Function space and domain
We seek to approximate multivariate functions f : X → R with X ⊂ Rd . Elements of X are denoted by x ≡
(x1 , x2 , . . . , xd ) or anonymous placeholders (.). The class of suitable functions will be denoted by V, such that f ∈ V.
In the context of this paper it is not necessary to be precise on the continuity properties of V, although it must be
suﬃciently diﬀerentiable to allow for the sampling of the derivative information used. For simplicity we will assume
that V ≡ C ∞ [X]. A function that is constructed to approximate f on X is referred to as an approximant to f .
Multi-index notation
A multi-index κ is deﬁned as a tuple of non-negative integers, κ ≡ (κ1 , κ2 , . . . , κd ) ∈ Nd0 . Multi-indices follow the
standard rules for vectorial addition and subtraction and some speciﬁc deﬁnitions for norm: |κ| := di=1 κi , factorial:
κ! := di=1 κi ! and binomial coeﬃcient: λκ := di=1 λκii . For comparison with a second multi-index, say λ, we use
(κ < λ) ⇔ (∀ i : κi < λi ), where < can be replaced by >, ≤, or ≥. For negated comparisons, however, we use
(κ ≮ λ) ⇔ (∃ i : κi ≮ λi ). The summation symbol |κ|≤n stands for summation over all κ ∈ Nd0 with |κ| ≤ n, and can
also be interpreted as nk=0 |κ|=k . We use greek symbols for multi-indices — which may also be used for powers,
degrees, etc. — and latin symbols for scalar indices. It should be noted, however, that in case d ≡ 1 a multi-index
degenerates to a scalar. Multi-indices are used to present multivariate algebra with a quasi-univariate notation. We
have taken special care to allow for a simple univariate interpretation of the formulas — perhaps on ﬁrst reading —
by interpreting the multi-indices as scalars.
Polynomials and partial derivatives
A d-variate algebraic monomial in terms of x ∈ Rd is expressed as: xκ := di=1 xiκi , with κ a multi-index. Each κi is
the degree for dimension i and |κ| the total degree. The linear space Pm ⊂ V of algebraic polynomials with maximum
total degree m is deﬁned in terms of x as Pm (x) := span{xκ κ ∈ Nd0 , |κ| ≤ m}. A partial derivative operator is deﬁned
analogous to a monomial: Dκ := di=1 (∂/∂xi )κi , with κi the order of diﬀerentiation in dimension i and |κ| the total
order. We will use the shorthand f (κ) := Dκ f .

D.
Kraaijpoel,
van
Leeuwen
/ Procedia
Computer
ScienceScience
1 (2012)
307–316
Dirk
KraaijpoelT.and
Tristan
van Leeuwen
/ Procedia
Computer
00 (2010)
1–10

309
3

Taylor expansions
The n-th order truncated Taylor expansion of a function f ∈ V around x ∈ X may be expressed using operator
T xn : V → Pn as:
1
(. − x)κ f (κ) (x).
(1)
T xn [ f ] :=
κ!
|κ|≤n

Formulation (1) corresponds to the most common perception of a Taylor expansion: as a prediction from a ﬁxed point
to its neighborhood. Point x appears as a subscript to indicate its role as a ﬁxed parameter. In the following it will
prove useful to look at the Taylor expansion from the opposite perspective: as a prediction to a ﬁxed point from its
neighborhood. This dual perspective calls for a diﬀerent formulation and notation that we introduce here.
Deﬁnition 2.1. The n-th order truncated dual Taylor expansion is deﬁned using operator T xn : V → V as:
T xn [ f ] :=

1
(x − .)κ f (κ) (.),
κ!
|κ|≤n

(2)

where x again serves as a ﬁxed parameter.
While the “primal” Taylor expansion T xn [ f ] produces an approximant to f on its entire domain X, the dual Taylor
expansion T xn [ f ] assigns to each element of X an approximation of the value of f at the speciﬁc location x. This
property makes the dual Taylor expansion attractive for use in approximation schemes. The duality of T.n and T.n is
illustrated by the identity T xn [ f ](y) = Tyn [ f ](x). Also note that T xn [ f ](x) = f (x).
Approximation schemes
Approximation schemes come in all shapes and sizes. In the scope of this paper it is not necessary to discuss
details of particular approximation schemes. In fact, for our purpose only one property of a scheme is crucial: its
polynomial reproduction order, sometimes referred to as its order of consistency.
We summarize an entire approximation scheme — including, for example, sampling, construction of an approximant, and evaluation at x — by a single functional that maps the function f to its approximated value at x.
Deﬁnition 2.2. An approximator of order m at x is a functional Amx : V → R that satisﬁes
Amx [p] = p(x)

∀

p ∈ Pm ,

(3)

i.e., it reproduces all polynomials of maximum total degree m at x.
3. Motivation and a simple example
Suppose that we have: (a) an approximation scheme that is represented by an approximator Amx as deﬁned in
Deﬁnition 2.2, and (b) a corresponding dataset (or sampling strategy) for a function f ∈ V, such that we can evaluate
an approximation fˆ(x) to f at x using fˆ(x) = Amx [ f ].
Now, consider the case that the dataset provides n orders of derivative data that are supplementary, in the sense
that they are not used in the approximation scheme. It is then attractive to incorporate this information to improve the
approximation. We invoke the truncated dual Taylor expansion (2), and replace f by T xn [ f ] prior to the application of
Amx . This results in an alternative approximation f˜(x) = Amx [T xn [ f ]] that incorporates all available data.
To assess the resulting procedure we study a simple example based on linear interpolation in a univariate setting
(see also [14, Ch. 4], with more details). Let z ∈ [z0 , z1 ] ⊂ R and g : [z0 , z1 ] → R. The linear interpolation scheme
is a ﬁrst order approximator at z, denoted by Iz1 [g] = g(z0 )φ0 (z) + g(z1 )φ1 (z), with φ0 (z) = (z1 − z)/(z1 − z0 ) and
φ1 (z) = (z − z0 )/(z1 − z0 ). Application of the procedure suggested above yields the following interpolation scheme
Iz1 [Tz1 [g]] = [g(z0 ) + (z − z0 )g (z0 )]φ0 (z) + [g(z1 ) + (z − z1 )g (z1 )]φ1 (z).

(4)

Note that the approximation (4) is now quadratic rather than linear in z. Therefore, it is interesting to see what it does
to a second degree polynomial, say p(z) = c0 + c1 z + c2 z2 , with c0 , c1 , c2 ∈ R arbitrary constants. It turns out that

310

Kraaijpoel,
van Leeuwen
/ Procedia
Computer
Science
1 (2012)
307–316
DirkD.Kraaijpoel
andT.Tristan
van Leeuwen
/ Procedia
Computer
Science
00 (2010)
1–10

4

Iz1 [Tz1 [p]] − p(z) = −c2 (z1 − z)(z − z0 ), while Iz1 [p] − p(z) = c2 (z1 − z)(z − z0 ). Apparently the suggested procedure does
not enhance the accuracy; in fact, the errors are equal in size but opposite in sign. This very observation immediately
suggests an attractive alternative: to combine both interpolations. For arbitrary g this results in a new interpolation
scheme
1 1
1
1
(I [g] + Iz1 [Tz1 [g]]) = [g(z0 ) + (z − z0 )g (z0 )]φ0 (z) + [g(z1 ) + (z − z1 )g (z1 )]φ1 (z),
(5)
2 z
2
2
that is able to reproduce p perfectly.
On the right hand sides of (5) and (4) we see that the dual Taylor expansion has been replaced with an alternative
Taylor-like expansion that involves an extra coeﬃcient. We also see that the combination of a ﬁrst order approximation
and a ﬁrst order expansion results in an approximation of second order accuracy.
In the following sections we will show that this principle can be generalized and that it is possible to combine an
m-th order approximation with an n-th order Taylor-like expansion to obtain an eﬀective (m + n)-th order accuracy.
4. The reduced dual Taylor expansion
Deﬁnition 4.1. The n-th order reduced dual Taylor expansion of the m-th kind, Dmn
x : V → V is deﬁned as:
Dmn
x [ f ] :=
with
mn
:=
C|κ|

1 mn
C|κ| (x − .)κ f (κ) (.).
κ!
|κ|≤n
m+n
m

−1

m + n − |κ|
.
m

(6)

(7)

mn
mn
. Note that C|κ|
≤ 1 such that all
The only diﬀerence between (6) and (2) is the insertion of the coeﬃcients C|κ|
terms in expansion (6) are reduced with respect to those in (2), explaining the expansion’s adjective. It is also worth
mn
deﬁned in (7) have been
noting that for m ≡ 0 the original dual Taylor expansion (2) is obtained. The coeﬃcients C|κ|
chosen speciﬁcally for Theorem 5.1 below to hold. To prepare for the proof of Theorem 5.1 we ﬁrst need to establish
the following properties of Dmn
x :

Lemma 4.1. The reduced dual Taylor expansion of a multivariate monomial (.)λ can be expressed as
λ
Dmn
x [(.) ] =

ι λ−ι
Bmn
,
ιλ x (.)

(8)

ι, λ | ι

(9)

|ι|≤n

with coeﬃcients Bmn
ιλ satisfying the following properties:

Bmn
ιλ

=0

∀

Bmn
ιλ = 0 ∀

λ

{ι, λ | (|λ| − |ι| > m) ∧ (|λ| ≤ m + n)}
Bmn
ιλ = 1.

(10)
(11)

|ι|≤n

Proof. Starting from Deﬁnition 4.1, expanding the powers of (x − .), and reordering terms gives
λ
Dmn
x [(.) ] =

mn
(−1)κ−ιC|κ|

|ι|≤n |κ|≤n

λ κ ι λ−ι
x (.) .
κ ι

(12)

From this we identify the coeﬃcients Bmn
ιλ in (8) as
Bmn
ιλ =
|κ|≤n

mn
(−1)κ−ιC|κ|

λ κ
κ ι

(13)

D.
Kraaijpoel,
van
Leeuwen
/ Procedia
Computer
ScienceScience
1 (2012)
307–316
Dirk
KraaijpoelT.and
Tristan
van Leeuwen
/ Procedia
Computer
00 (2010)
1–10

311
5

Next, we invoke a sequence of three established binomial identities (A.1-A.3) for all dimensions successively to arrive
at a simpler expression for Bmn
ιλ . The result is:
Bmn
ιλ =

m+n
m

−1

=

m+n
m

−1

λ m + n − |λ|
ι
n − |ι|

λ m + n − |λ|
.
ι m − |λ| + |ι|

(14a)
(14b)

Properties (9) and (10) follow directly from the second and the third binomial coeﬃcient in (14b) respectively. Refer to Section 2 for the deﬁnition of negated comparison operators for multi-indices. Property (11) follows from
Vandermonde’s identity (A.4) applied to (14a) successively in all dimensions.
5. Raising the approximation order
Theorem 5.1. The combination of n-th order reduced dual Taylor expansion of the m-th kind Dmn
x (6) and m-th order
approximator Amx (3) yields an eﬀective approximation order of m + n:
Amx [Dmn
x [p]] = p(x)

∀

p ∈ Pm+n .

(15)

λ
Proof. From Lemma 4.1, Equations (8) and (10), we see that Dmn
x maps any monomial (.) with |λ| ≤ m + n to a
polynomial of maximum total degree m, because the coeﬃcients for the powers (.)λ−ι with |λ − ι| = |λ| − |ι| > m vanish.
m
Since Dmn
x is a linear operator, this also holds true for any polynomial of total degree |λ| ≤ m + n. Approximator A x
reproduces all polynomials of maximum total degree m (by Deﬁnition 2.2). Therefore, the only thing left to prove
(15) is to verify that Dmn
x [p] replicates p at x. This is easily checked for an arbitrary monomial, using Equations (8)
and (11):
λ
ι λ−ι
Dmn
Bmn
= xλ ,
(16)
x [(.) ](x) =
ιλ x x
|ι|≤n

which ﬁnalizes the proof of Theorem 5.1.
An expression for the approximation error is obtained by [15] and [16] for quasi-interpolation in univariate and
multivariate settings respectively. We translate their result to our situation and generalize it using the unspeciﬁed
approximator Amx :
⎡ 1
⎤
⎢⎢⎢
⎥⎥⎥
m
n m+n+1
⎢⎢
⎥⎥⎥
m
mn
m⎢
m t (1 − t) d
f
(.
+
t(x
−
.))dt
f (x) − A x [D x [ f ]] = A x ⎢⎢ (−1)
(17)
⎥⎥⎦ .
⎣
(m + n)! dtm+n+1
0

This expression is obtained starting with a Taylor expansion of f (κ) around x in (6). Note that setting n = 0 in (17)
reveals the error expression for the Amx itself. Setting m = 0 results in the familiar integral remainder of the Taylor
expansion. Error bounds may be derived from (17) for speciﬁc choices of Amx . We refer to [15] and [16] for some
speciﬁc examples in (quasi-) interpolation.
6. Implementation
The practical consequence of Theorem 5.1 is a generic procedure that we can use to raise the order of multivariate
approximation schemes. An approximation scheme for the value of f at x is basically an operator that takes as
input a number of samples of f , and delivers as output an approximation to f (x). The proposed procedure simply
involves replacing the input samples of f by the corresponding samples of Dmn
x [ f ], which can be constructed using
the supplementary derivative data. The approximation order will then be raised from m to m + n. The result is best
appreciated by comparing (15) to (3). Note that the supplementary derivative data is assumed to be available at the
same locations as the original samples.

312

Kraaijpoel,
van Leeuwen
/ Procedia
Computer
Science
1 (2012)
307–316
DirkD.Kraaijpoel
andT.Tristan
van Leeuwen
/ Procedia
Computer
Science
00 (2010)
1–10

6

Next, we show the eﬀect of the procedure on 2-D scattered data interpolation. We consider a domain X =
[−0.2, 1.2]2 ⊂ R2 , variables x = (x1 , x2 ) ∈ X and a function f (x) = cos(2πx1 ) + x1 sin(2πx2 ) + x22 − x1 to be apN
, and we use shorthands
proximated on [0, 1]2 ⊂ X. Data is scattered over N random node locations {xk ∈ X}k=1
fk := f (xk ). We investigate two diﬀerent approximation techniques for scattered data. To assess their approximation
orders we investigate the decrease of the approximation error as a function of the number of nodes N. Since the nodes
are spread over 2 dimensions, the average distance between neighbouring nodes scales as N −1/2 . Regardless of the
approximation technique used we therefore predict the error of the enhanced approximation to be O(N −(m+n+1)/2 ), with
m and n as deﬁned above.
The ﬁrst approximation f˜ is constructed using a Delaunay triangulation of the nodes and linear (barycentric)
interpolation within each triangle [1]. Let the barycentric weights for location x be denoted by wk (x), then the approximation f˜ can be expressed as
f˜(x) =

N

wk (x) fk .

(18)

k=1

Note that all wk (x) vanish except for those that correspond to the vertices of the triangle that contains x. The incorporation of the derivative data now comes down to the replacement
fk → Dmn
x [ f ](xk )

(19)

in (18). Results are shown in Figure 1. Note that m = 1 in this case.
The second approximation f¯ is constructed using the moving least-squares (MLS) approximation [6]:
⎡
⎢
¯f (x) = ⎢⎢⎢⎢⎣argmin
p∈Pm

N

⎤
⎥
φ (||x − xk ||2 )(p(xk ) − fk ) ⎥⎦ (x),
2

k=0

⎥⎥
2⎥

(20)

where φ : R+0 → R+0 is a positive weighting function that normally peaks at 0 and decreases away from it. For our
example we use φ(r) = exp(−Nr2 ). The incorporation of the derivative data again comes down to the replacement
(19) in (20). Results are shown in Figure 2.
7. Remarks
For multivariate approximation we use the concepts of (maximum) total degree for polynomials and total order
for approximation schemes and derivatives. These are perhaps the most natural — or at least the most symmetric —
generalizations of the univariate concepts of order and degree. As a consequence, both the original and the enhanced
approximation schemes have the same approximation order in all directions. Also, the order of derivative information
must be the same in all directions. We call this the total-degree approach. An alternative is to apply univariate
techniques to all dimensions in succession. This tensor-product approach is well known from, e.g., bilinear and
bicubic interpolation and tensor-product B-splines [1, 2, 3] and is very attractive for rectangular data-conﬁgurations
(grids). It allows the use of diﬀerent approximation orders in diﬀerent dimensions. Our procedure can also be used in
a purely tensor-product fashion, by simply using the univariate version of (15) in each dimension. Now, like the order
m, also the number of (partial) derivatives n may be varied in each dimension. It should be noted, however, that all
(tensor-product) mixed partial derivatives are required as well, and these may not be available. It may then be more
attractive to determine the total approximation order for the original tensor-product scheme and use the corresponding
multivariate kind of (15).
In our motivation we have referred to n orders of derivative data that are supplementary, in the sense that they are
not used in the approximation scheme. It is not necessary for those supplementary orders to be the lowest orders. It
is also possible that some derivative information is accommodated in the original approximation scheme, such as in a
Hermite interpolation. In that case, the supplementary derivative information consists of the next n orders. The total
derivative information, however, should be contiguous from order 0 upwards. The procedure does not change at all.
The reduced dual Taylor expansion should still be of order n. As the approximation scheme samples the derivatives
of (6), the higher order derivative information is introduced automatically.

313
7

D.
Kraaijpoel,
van
Leeuwen
/ Procedia
Computer
ScienceScience
1 (2012)
307–316
Dirk
KraaijpoelT.and
Tristan
van Leeuwen
/ Procedia
Computer
00 (2010)
1–10

0.2

0.2

0.4

0.4
x2

0

x2

0

0.6

0.6

0.8

0.8

1
0

0.2

0.4

0.6

x

0.8

1
0

1

0.2

0.4

x

1

(a)

0.8

1

(b)
0

0

10

0.2

10
relative error

−1

x2

0.4

0.6

−2

10

−3

10

−4

10

0.8

1
0

0.6
1

−5

0.2

0.4

0.6

x

1

(c)

0.8

1

10

1

10

2

10
N

3

10

(d)

Figure 1: Scattered data interpolation using barycentric interpolation on Delaunay triangulation. Figures (a)-(c) represent experiment for N = 75,
i.e. 75 randomly distributed nodes on domain x ∈ [−0.2, 1.2]2 . (a) Test function f (x) = cos(2πx1 ) + x1 sin(2πx2 ) + x22 − x1 , node locations and
triangulation. (b) Approximation to f (x) with m = 1 and n = 0. (c) Approximation to f (x) with m = 1 and n = 1. (d) Log-log plot of relative
rms-error versus N. Solid, dashed and dot-dashed curves correspond to n = 0, n = 1, and n = 2 respectively. Convergence rates are as predicted:
O(N −(m+n+1)/2 )

314

Kraaijpoel,
van Leeuwen
/ Procedia
Computer
Science
1 (2012)
307–316
DirkD.Kraaijpoel
andT.Tristan
van Leeuwen
/ Procedia
Computer
Science
00 (2010)
1–10
1

0.2

0.8

0.4

0.6

0.6

0.4

0.8

0.2

x2

0

8

1
0

0.2

0.4

x1

0.6

0.8

0
0

1

0.2

(a)

0.4

0.6

r

0.8

1

(b)

0.2

0.2

0.4

0.4
x2

0

x2

0

0.6

0.6

0.8

0.8

1
0

0.2

0.4

x1

0.6

0.8

1
0

1

(c)

0.4

x1

0.6

0.8

1

(d)
0

0

10

0.2

10
relative error

−1

x2

0.4

0.6

−2

10

−3

10

−4

10

0.8

1
0

0.2

−5

0.2

0.4

(e)

x1

0.6

0.8

1

10

1

2

10

10
N

3

10

(f)

Figure 2: Scattered data approximation using moving least-squares. Figures (a)-(e) represent experiment for N = 75, i.e. 75 randomly distributed
nodes on domain x ∈ [−0.2, 1.2]2 . (a) Test function f (x) = cos(2πx1 ) + x1 sin(2πx2 ) + x22 − x1 and node locations. (b) MLS weight function
φ(r) = exp(−Nr2 ) (Gaussian). (c) Approximation to f (x) with m = 1 and n = 0. (d) Approximation to f (x) with m = 2 and n = 0. (e)
Approximation to f (x) with m = 1 and n = 1. (f) Log-log plot of relative rms-error versus N. Black and red curves correspond to m = 1 and
m = 2 respectively; solid, dashed and dot-dashed curves correspond to n = 0, n = 1 and n = 2 respectively. Convergence rates are as predicted:
O(N −(m+n+1)/2 )

D.
Kraaijpoel,
van
Leeuwen
/ Procedia
Computer
ScienceScience
1 (2012)
307–316
Dirk
KraaijpoelT.and
Tristan
van Leeuwen
/ Procedia
Computer
00 (2010)
1–10

315
9

Approximation schemes are used for various purposes. In some cases the main goal is accuracy, in other cases
smoothness is more important. In that respect it is good to emphasize that our procedure results in a scheme that has
(at least) the same order of continuity as the original scheme. Therefore, our procedure is an attractive tool for raising
the order of approximation schemes that are designed for smoothness.
8. Conclusion
We have established a generic procedure to raise the eﬀective approximation order of multivariate approximation
schemes by incorporating supplementary derivative data. A particular strength of the procedure is that it is easily
accommodated in existing schemes, as demonstrated with two examples of scattered data interpolation/approximation.
We expect the procedure to be useful immediately in a wide range of applications.
Acknowledgment
A large part of the work presented was carried out while the ﬁrst author was employed at the Faculty of Civil
Engineering and Geosciences, Delft University of Technology, in a project ﬁnanced by the Netherlands Research
Centre for Integrated Solid Earth Science (ISES).
The second author takes part in the research program of the Foundation for Fundamental Research on Matter
(FOM), which is ﬁnancially supported by the Netherlands Organization for Scientiﬁc Research (NWO).
Appendix A. Binomial identities
For ease of reference we provide without proof four (standard) binomial identities using symbols that mimic the
symbols used in the main text. With i, k, l, m, n ∈ N10 we have from [15], p. 174:
l k
l l−i
=
k i
i k−i

(trinomial revision),

(A.1)

and from [15], Eqs. 5.25, 5.14 and 5.22 respectively:
n

(−1)k−i
k=0

(−1)n−i
n
i=0

l−i−m−1
m+n−k l−i
,
= (−1)n−i
n−i
m
k−i

l−i−m−1
m+n−l
=
n−i
n−i

l m+n−l
m+n
=
i
n−i
n

(A.2)

(upper negation),

(A.3)

(Vandermonde’s identity).

(A.4)

References
[1]
[2]
[3]
[4]
[5]
[6]
[7]

P. J. Davis, Interpolation and approximation, Dover Publications, 1975
G. M. Phillips, Interpolation and approximation by polynomials, Springer, 2003
C. de Boor, A practical guide to splines (revised edition), Springer, 2001
R. A. Lorentz, Multivariate Hermite interpolation by algebraic polynomials: A survey, J. Comp. Appl. Math. 122 (2000), 167-201
M. Gasca and T. Sauer, Polynomial interpolation in several variables, Adv. Comp. Math. 12 (2000), 377-410
D. Levin, The approximation power of moving least-squares, Math. Comput. 67 (1998), 1517-1531
M. D. Buhmann, Radial Basis Functions: Theory and Implementations, Cambridge Monographs on Applied and Computational Mathematics,
Cambridge University Press, 2003
[8] R. Sibson, A brief description of natural neighbor interpolation, in Interpreting multivariate data, V. Barnet (Ed.), Wiley, 1981, pp. 21-36
[9] M. Sambridge, J. Braun, and H. McQueen, Geophysical parameterization and interpolation of irregular data using natural neighbors,
Geophys. J. Int. 122 (1995), 837-857
[10] N. Sukumar and E. A. Malsch, Recent advances in the construction of polygonal ﬁnite element interpolants, Arch. Comput. Meth. Engng. 13
(2006), 129-163

316

Kraaijpoel,
van Leeuwen
/ Procedia
Computer
Science
(2012)
307–316
DirkD.
Kraaijpoel
and T.
Tristan
van Leeuwen
/ Procedia
Computer
Science1 00
(2010)
1–10

10

[11] R. A. DeVore, Nonlinear approximation, Acta Numerica 7 (1998), 51-150
[12] P. Th´evenaz, T. Blu, and M. Unser, Image interpolation and resampling, in Handbook of Medical Imaging, Processing and Analysis, Academic Press, 2000, pp. 393-420
[13] M. E. Mortenson, Geometric Modeling, third edition, Industrial Press, 2006
[14] D. A. Kraaijpoel, Seismic ray ﬁelds and ray ﬁeld maps: theory and algorithms, PhD thesis Utrecht University, Faculty of Geosciences, 2003
[15] H. Xuli, Multi-node higher order expansions of a function, J. Approx. Theory 124 (2003), 242-253
[16] A. Guessab, O. Nouisser, and G. Schmeisser, Multivariate approximation by a combination of modiﬁed Taylor polynomials, J. Comput. Appl.
Math. 196 (2006) 162-179
[17] C. Zuppa, Modiﬁed taylor reproducing formulas and h-p clouds, Math. Comput. 77 (2008), 243-264
[18] S. Waldron, Increasing the polynomial reproduction of a quasi-interpolation operator, J. Approx. Theory 161 (2009), 114-126
[19] R. L. Graham, D. E. Knuth, and O. Patashnik, Concrete Mathematics, Addison-Wesley, 1994

