Available online at www.sciencedirect.com

ScienceDirect
Procedia Computer Science 108C (2017) 1251–1260

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich,
Switzerland Method Used in
Improved New Word
Detection

Improved
Detection
Tourism
Field Method
Improved New
New Word
Word
Detection
Method Used
Used in
in
Tourism
Tourism Field
Field
Wei Li1,2,3 , Kun Guo1,2,3,*, Yong Shi2,3,*, Luyao Zhu1,2,3, Yuanchun Zheng1,3
1

Fictitious Economy & Data Science Research Center, Chinese Academy of Science, Beijing,

1,2,3
1,2,3,*
2,3,*
1,2,3
1,3
2,3,*
Wei
Li
Wei
Li1,2,3 ,, Kun
Kun Guo
Guo1,2,3,*,, Yong
Yong Shi
Shi
Luyao Zhu
Zhu1,2,3,, Yuanchun
Yuanchun Zheng
Zheng1,3
China ,, Luyao
1
1Fictitious

2
&
Science
Center,
Academy
of
Fictitious Economy
Economy
& Data
Data
Science Research
Research
Center, Chinese
Chinese
AcademyChina
of Science,
Science, Beijing,
Beijing,
School
of Economics
and Management,
UCAS, Beijing,
China
China Management, Chinese Academy of Sciences
Key Laboratory2of Big Data Mining and knowledge
*2 School of Economics and Management, UCAS, Beijing, China
School of Economics
and Management,
UCAS, Beijing, China
Correspondence:
yshi@gucas.ac.cn;
guokun@ucas.ac.cn
(Guo)
3
3Key Laboratory of Big Data Mining and knowledge Management, Chinese Academy of Sciences
Key Laboratory* of Big Data Mining and knowledge Management, Chinese Academy of Sciences
*Correspondence: yshi@gucas.ac.cn; guokun@ucas.ac.cn (Guo)
Correspondence: yshi@gucas.ac.cn; guokun@ucas.ac.cn (Guo)
3

Abstract
Chinese segmentation has attracted amounts of attention in natural language processing in recent years
Abstract
and
is the basis of web text mining. The article improved statistics-based method EMI, then we use
Abstract
Chinese
attracted
amounts
of
natural
processing
in
improved
approach to has
detect
new words
in tourism
field.in
resultlanguage
demonstrates
that our
methodyears
can
Chinese segmentation
segmentation
has
attracted
amounts
of attention
attention
inThe
natural
language
processing
in recent
recent
years
and
is
the
basis
of
web
text
mining.
The
article
improved
statistics-based
method
EMI,
then
we
use
and is new
the basis
web text mining.
The article
improved
statistics-based
method EMI,
we will
use
detect
wordsofsignificantly,
especially
in detecting
proper
nouns and sentiment
wordsthen
which
improved
to
new
words
tourism
field.
result
demonstrates
method
can
improved
approach
to detect
detect
newsuch
words
in
tourism analysis
field. The
Theand
result
demonstrates
that
our
method this
can
be
helpfulapproach
in subsequent
tasks
as in
sentiment
word
embedding.that
In our
additional,
detect
new
significantly,
in
and
sentiment
words
which
detect analyze
new words
words
significantly,
especially
in detecting
detecting
proper
nouns
andwords
sentiment
wordsAt
which
will
paper
parameters
whichespecially
are influential
on theproper
effectsnouns
of new
detection.
last, will
the
be
helpful
in
subsequent
tasks
such
as
sentiment
analysis
and
word
embedding.
In
additional,
be
helpful
in subsequent
tasks such of
asnew
sentiment
analysis in
and
word embedding.
this
article
discussed
possible application
word detection
sentiment
analysis. In additional, this
paper
paper analyze
analyze parameters
parameters which
which are
are influential
influential on
on the
the effects
effects of
of new
new words
words detection.
detection. At
At last,
last, the
the
©
2017
The
Authors.
Published
by
Elsevier
B.V.
article
discussed
possible
application
of
new
word
detection
in
sentiment
analysis.
Keywords:
EMI, PMI,
onlineapplication
travel, new word
detection
article
discussed
possible
of
new
word
detection
in
sentiment
analysis.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
Keywords:
Keywords: EMI,
EMI, PMI,
PMI, online
online travel,
travel, new
new word
word detection
detection

1 Introduction
1
Introduction
travel has developed dramatically during the past three years in China. Different from
1 Online
Introduction

traditional travel, online travel refers to a travel style in which users look through information of
1
Online
travel
developed
dramatically
during
past
in
from
Online
travel has
has
developed
dramatically
during the
the
past three
three years
years
in China.
China.
Different
from
TheDifferent
online travel
tourist
attractions,
then
gain a tourism
consumption
psychological
satisfaction.
traditional
travel,
online
travel
refers
to
a
travel
style
in
which
users
look
through
information
of
mainly
relies
on travel
website,
theinWorld
is 1dedicated
to travel.
traditional
travel,
online
travel which
refers istoa awebsite
travel on
style
whichWide
usersWeb
lookthat
through
information
of
12 The online travel
tourist
attractions,
then
gain
a
tourism
consumption
psychological
satisfaction.
The online
online travel
The
siteattractions,
may be focused
on travel
reviews,
trip fares, psychological
or a combination
of both. The
tourist
then gain
a tourism
consumption
satisfaction.
mainly
on
which
aa website
on
Wide
that
dedicated
travel.
mainly relies
relies
on travel
travel
website,
which is
is(OTA)
website
on the
the World
World
Wide Web
Web
that is
is
dedicated
tobooking
travel.
service
supplier,
onlinewebsite,
travel agency
specializes
in offering
planning
sources
and to
2
3 be focused on travel reviews, trip fares,
4
5combination6 of both. 2 The online travel
The
site
may
or
a
The online
The site maySome
be focused
travel
reviews,
tripCtrip
fares,
or a combination
of both.thousands
famousontrip
website
such as
, Qunar
and Tuniu provide
of travel
capabilities.
service
online
in
sources
service supplier,
supplier,
online travel
travel agency
agency (OTA)
(OTA) specializes
specializes
in 5offering
offering planning
planning
sources and
and booking
booking
3
4
6
1
3 Some famous trip website such as Ctrip 4, Qunar5 and Tuniu6 provide thousands of travel
capabilities.
http://baike.baidu.com/item/%E5%9C%A8%E7%BA%BF%E6%97%85%E6%B8%B8
Some
famous
trip
website
such
as
Ctrip
,
Qunar
and
Tuniu
provide
thousands
of
travel
capabilities.
2
13
1
24
2
53
3
46
4
5
5
6
6

https://en.wikipedia.org/wiki/Travel_website
"About Expedia.com". Expedia. 2009. Retrieved 20 September 2009.
http://baike.baidu.com/item/%E5%9C%A8%E7%BA%BF%E6%97%85%E6%B8%B8
http://baike.baidu.com/item/%E5%9C%A8%E7%BA%BF%E6%97%85%E6%B8%B8
http://www.ctrip.com/
https://en.wikipedia.org/wiki/Travel_website
https://en.wikipedia.org/wiki/Travel_website
https://www.qunar.com/
"About
"About Expedia.com".
Expedia.com". Expedia.
Expedia. 2009.
2009. Retrieved
Retrieved 20
20 September
September 2009.
2009.
http://www.tuniu.com/
http://www.ctrip.com/
http://www.ctrip.com/
https://www.qunar.com/
https://www.qunar.com/
http://www.tuniu.com/
http://www.tuniu.com/

1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.022

1252	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

products for millions of customers. Like other products such as fast foods, clothes and gifts, travel
product can be purchased online. Customers who purchased travel products tend to post their
comments about the product online which is similar to online shopping comments. However, unlike
online shopping comments and microblog comments, generally speaking, travel product comments are
more formal, and more serious to some extent, and they always offer explicit sentiment polarities and
plenty of details about visitors’ trip. What’s more, there are more than 0.2 billion microblogs and
millions of online shopping comments emerging every day on Internet7 while online travel is still in
infancy. But in the long run, with the development of economic and the booming of tourism industry,
people have been in pursuit of quality and memorable journey. Thus, it is significant for people to
explore effective and useful information from travel product comments.
Travel product comments have strong influence on those who haven’t purchased and are planning
to buy certain travel product because of information asymmetry. Obviously, travel products, as a
special goods, draw more attention from customers and need more participation in tourism reviews.
For example, if a tourist wants to go on a journey to Tibet, you can book a travel product towards
Tibet, then you should gather information as more as possible. Travel product comments about Tibet,
indeed, which can offer more details and practical experiences about journey, rather than complex
literal and theoretical information on Internet, will be powerful and helpful in to tourists’ upcoming
trip.
Huge amounts of comments information can be used to judge whether a certain travel product is
hot or not, find out the main faults of the product and balance their resources in order to gain more
benefits by trip websites. Managers can also track the fluctuations of companies’ reputation, main
trend or essential of a certain product, even evaluation of a certain cicerone. Considering large scale of
information on trip websites, it is costly and time-consuming to extract useful information from
comments manually. In this paper, we try to propose a comprehensive system to extract knowledge
automatically, and effectively in real time.
Sentiment analysis of social media text has been an active research domain in natural language
processing nowadays, which aims at integrating, recognizing, identifying and analyzing users’
sentiments and emotions, or opinions from social network, microblogs or online product reviews.
Nevertheless, there’s still a lot to do in order to improve the level of tackling the sentiment analysis
task. Moreover, application of deep machine learning on sentiment classification has drawn much
attention in recent years. In this case, how to improve accuracy during the process of word embedding,
word segmentation and make good use of deep learning on sentiment classification is an important
task in sentiment analysis of social media text.
The technology on sentiment analysis study mainly consists of two parts, statistical machine
learning, and lexicon-based approach. Domestic and foreign scientists have made a lot of contributions
in the research area.
In the aspect of statistical machine learning, more and more researches pay attention to supervised
learning. Cıcero Nogueira dos Santos and Maıra Gatti(Santos & Gattit, 2014) proposed a deep
convolutional neural network named CharSCNN to extract relevant features from character- to
sentence-level to make sentiment analysis of information from short texts. Talaat Khalil and Samhaa
R. El-Beltagy(Khalil & El-Beltagy) harnessed the ensemble binary classifier consists of CNN and
SVM for aspect category and sentiment extraction. Kai Sheng Tai, Richard Socher, Christopher D.
Manning(Tai, Socher, & Manning, 2015) proposed a tree-LSTM to predict the semantic relevance of
two sentences and for sentiment classification. Zhiting Hu, Xuezhe Ma and Zhengzhong Liu et al.(Hu,
Ma, Liu, Hovy, & Xing, 2016) transformed the FOL rules into the weights of neutral networks and
deployed the CNN and RNN on sentiment analysis (SA) and named entity recognition (NER)
respectively.
7
http://baike.baidu.com/link?url=pQWH2AdAdZ5I2hG4--99QHney039i3NRx9JoWJKnosrRuGXS7ju_mDt24k22e1OBuKRwf_QWjmgW1y9yulJMcGEUkcbJQbKh744Tkrp-qy

	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

Lexicon-based approach includes dictionary-based approach and corpus-based approach, while
some researchers focus on corpus-based approach. Fangzhao Wu, Yongfeng Huang, Yangqiu Song et
al.(Wu, Huang, Song, & Liu, 2016) built a sentiment lexicon via three kinds of sentiment knowledge
by means of detecting new words in microblogs aiming at improving the coverage of the lexicon. In
their work, they constructed sentiment corpus through Point-Wise-Mutual-Information (PMI) and
Enhanced Manual Information (EMI) of statistical approach. Maite Taboada, Julian Brooke, Milan
Tofiloski, et al.(Taboada, Brooke, Tofiloski, Voll, & Stede, 2011) introduced the Semantic Orientation
CALculator applied to polarity classification, taking into consideration valence shifters, including
intensifiers, downtoners, negation and irrealis markers. Heeryon Choa, Songkuk Kim, Jongseo Lee, et
al.(Cho, Kim, Lee, & Lee, 2014) presented a data-driven method of adjusting sentiment lexicons to
various domains via merge, remove, switch operations. Fu Xianghua, Liu Guo, Guo Yanyan, et al.(Fu,
Guo, Guo, & Wang, 2013) introduced an unsupervised method Multi-aspect Sentiment Analysis for
Chinese Online Social Reviews (MSA-COSRs) and used the Latent Dirichlet Allocation (LDA) model
so as to discover multi-aspect global topics of social reviews. Felipe Bravo-Marquez, Eibe Frank,
Bernhard Pfahringer(Bravo-Marquez, Frank, & Pfahringer, 2016) expanded the opinion lexicon in a
supervised fashion considering word-level attributes consisting of morphological information and
associations between words and the sentiment in tweets, which were modelled through statistical
approach, point-wise-mutual-information semantic orientation (PMI-SO), and using stochastic
gradient descent semantic orientation (SGD-SO). Nawaf A. Abdulla1, Nizar A. Ahmed2, Mohammed
A. Shehab al et.(Abdulla, Ahmed, Shehab, & Al-Ayyoub, 2013) compared their proposed
unsupervised approach with supervised approach (SVM, NB, KNN, D-tree) on lexicon construction in
aspects of sentiment classification accuracy.

2 Methodology
The majority of the research of sentiment analysis focuses on English text or corpus. Although
there has been several attempts at researches on Chinese sentiment analysis, it will has some specific
problems. In English, different words are partitioned by blank space while there is no token in Chinese.
The basic element of sentiment analysis is word, that is to say, subsequent tasks such as Word
Embedding, lexicon-based sentiment analysis approach and machine learning approach will depend on
the effect of Chinese word segmentation. Especially, lexicon-based approach needs word dictionary
which contains plenty of sentiment words. In order to get the exact semantic of sentiment words,
researchers should construct sentiment lexicon manually. Actually, many user-invented new words
will not be captured by segmentation tool such as jieba and ANSJ. For instance, “ 萌萌哒” represents
cute or lovely which deliver slight positive sentiment which is not included in jieba dictionary. “纯玩
无购物” represents a trip which guarantee genuine goods at a fair price, which contains slight positive
sentiment when used in tourism comments. Another vital issue is that segmentation tool may not
perform well in practical cases. For example, “魅力湘西” cannot be partitioned correctly by jieba due
to lacking of words in jieba dictionary. “魅力”and “湘西” means lure and a place name when used
respectively. In fact,“ 魅力湘西 ”has special meaning in tourism field, which refers to a kind of
drama in Zhangjiajie, Hunan Province. Besides, there are a lot of exclusive sentiment words in specific
fields. “全五分” represents a positive comment towards a tourism product which is rarely used in other
fields. “跟团游” which is the synonym of package tour, emerging with online tourism, is not a word in
tradition dictionary. Furthermore, “自由活动” does not contain certain sentiment meaning in traditional
sentiment lexicon while it may have delicate sentiment meaning in tourism field. It is difficult for
traditional segmentation tool such as jieba to partition sentence correctly in specific fields due to
above issues. It is hard to do sentiment analysis without quality segmentation results. Other related
work such as word embedding will be affected due to the same reason. In order to overcome the issues
above, we propose a new method to improve the result of word segmentation and detect new

1253

1254	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

sentiment words which will be used to construct sentiment lexicon. Our research pays attention to
Chinese sentiment analysis, especially in word segmentation.
There are some different measures such as pointwise mutual information(PMI)(Church & Hanks,
1990), enhanced mutual information (Zhang, Yoshida, Tang, & Ho, 2009), symmetrical conditional
probability known as SCP (Zhu., 2010), which can be good methods to detect new words in special
field. (Wu, Huang, Song, & Liu, 2015) build micro-specific sentiment lexicon based on improved
segmentation method. The article proposed a method to detect user-invented new words according to
their EMI score of a new word. In this paper, we select enhanced mutual information (EMI) as the
basic method, then we extend the basic method aiming at solving the practical issues above. A word
that is segmented incorrectly by segmentation tool such as jieba will be partitioned as some single
characters and/or words, but sequence of the raw word which is segmented incorrectly will not change.
That is to say, candidate new words, apparently, can be found by union of some successive single
characters and/or words. i.e.,“我们是跟团游” (we are on package tour) will be segmented into “我
们 是 跟 团游”. Segmentation tool jieba cannot identify the new word“跟团游”, actually, the new
word is segmented into“跟”and“团游”which is puzzling. First, I will introduce the basic concepts
of enhanced mutual information (EMI), the definition of EMI score is below:

EMI ( w)  log



T
i 1

nw / N
(nwi  nw ) / N

Formula 1

where w means candidate new word, and w is composed by T single characters and/or words marked
as w1 w1 w2,…, wT. nw is the occurrence number of candidate new word w, while nwi is the occurrence
number of wi . N is the total number of documents(Zhang et al., 2009). The formula measures whether
the candidate word w is a new word or not, which depends on the relative weight of numerator that
measures the frequency of candidate new word w. In a word, if w1 w1 w2,…, wT always occurs in
company with each other while the occurrence number of single character and/or word wi itself
relatively small, then we tend to appoint candidate word w to be a new word. When EMI score of w is
higher, that means w1 w1 w2,…, wT always occurs together compared with single occurrence of wi. In
our opinion, that demonstrates that w is a new word.
Existing statistics-based methods proposed by (Wu et al., 2015) utilize the distribution over texts
and users to compute score of multi-words expression. Different from microblog comments, travel
product comments are more formal to some extent and almost one user just post one comment.
Therefore, utilizing distribution over users as additional information makes no sense. Since one
comment corresponds to one user, distribution over texts also indicates whether a new word is popular
among users or not. Some details corresponding to the basic formula should be taken into
consideration, hence we change the basic formula as follows:



nwj / N

EMI ( w)    log T
j
j

j 


(
n
n
s
_
f
)
/
N
 i 1 wi w



Formula 2


EMI ( w)    log
T
j 


Formula 3




T
j
j
 i 1 (nwi  nw  s _ f ) / N 
nwj / N

The two improved formulas aim at solving two practical issues when used to detect new words in
tourism field. Where s_f is a smoothing factor in order to guarantee the formula robust while n w = nwi.
“妥妥滴”(everything is good) has two different segmentation patterns “ 妥 妥滴” and “妥妥 滴”.
According to the basic formula above, those two different patterns will be computed respectively,

	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

1255

which would decrease the probability under which candidate new words is detected. Taking into
account that different patterns have the same result when combined into a new word, we accumulate
EMI score of a new word among its different patterns. Therefore, j represents jth pattern of a new
j

word; nw represents occurrence number of w in jth pattern; nwi represents occurrence number of

wi

in jth pattern. Denominator has been changed in another formula in order to unify dimension
coinciding with numerator.
Pointwise mutual information (PMI) can only measure relationship of bi-grams, which is defined
as:
p( w1 , w2 )
Formula 4
PMI ( w1 , w2 )  log
p( w1 ) p( w2 )
Unlike PMI, EMI-based method can measure n-grams, but the number of n-grams increase8 fast as
n increases, which calls for huge memory. Therefore in this paper, we set the parameter n to 3 in case
the large number of candidate new words increases fast. In order detect new words as much as
possible, we adopt the iterative method proposed by (Wu et al., 2015), which can also significantly
lower the memory requirement compared with the original method proposed by (Church & Hanks,
1990). Our new word detection method is shown by pseudo code in Algorithm 1.
Each iteration aims at detecting eligible new words, then eligible new words will be added to
customized user dictionary D. In order to accomplish that target, customized user dictionary D would
be modified in each iteration. Some words whose occurrence number is lower than threshold tf will be
discarded while some newly discovered words will be added. Not until the size of customized user
dictionary D maintains constant, would our algorithm stop.

8
We have tested zhiwiki, and there are almost 140 million words while the number of candidate new words are nearly 300
million. https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

1256	

1: Input: Tourism comments corpus C, Chinese segmentation tool jieba, threshold of word
frequency tf and threshold of word EMI score te.
2: Output: Customized user dictionary D.
3: Establish the empty dictionary D, set hyper parameters tf and te, Initialize iteration number
num==0.
4: while the size of customized dictionary D does not maintain constant:
5:

Load customized user dictionary D to jieba.

6:

Clean raw corpus, then segment cleaned corpus C using segmentation tool jieba.

7:

Go through corpus C, then count words’ occurrence numbers, save txt9 file F = {(wi,
ni) | i=1,2,…} and filtered txt file Ff = {(wi, ni) | ni <= tf }.

8:

Filter the words in D according to Ff.

9:

Go through corpus C, find out all the bi-grams and tri-grams, count their occurrence
numbers, and filter them according to tf, save txt file co_count = {(wi, ni) | ni <=
tf }.

10:

Compute EMI score of candidate new words in co_count.

11:

Use te filtering candidate new words in co_count according to their EMI scores, then
add remnant words in co_count to D.

12:

num+=1

13: end
14: Sort customized user dictionary D according to their occurrence number.
15: Return customized user dictionary D.
Algorithm: New word detection algorithm used in tourism field.

3 Experiment
Our proposed word segmentation and new word detection algorithms are universally adaptable in
many cases. Here, we implement them on tourism reviews from Ctrip.com and Qunar.com, which are
large tourism social networks in China.
The reviews, amounting to nearly 20M in storage space, captured by web crawlers range from data
fetched in 2015 to one fetched in 2016, among which 14948 reviews come from Ctrip.com dating
from 29th April, 2012 to 30th June, 2016 and 55581 ones are from Qunar.com dating from 1 st
November, 2012 to 1st March, 2016. Both reviews dataset are processed as our corpus for this research.

3.1 Tourism Reviews Corpus Description
The tourism reviews are users’ opinions on tourism products that are usually different kinds of
traveling routines or some specific single tourism items. The reviews may contain several or nearly on
hundred words at most. The content of tourism reviews can range from tidiness of hotels, quality of
scenic, services from tour guides or servants, to delicacy of local food.

9

Text format will also be essential as the size of corpus increases.

	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

1257

What’s more, the peculiarity of tourism reviews, making it different from serious news or reviews
paper, is that it contains large quantity of colloquial comments. In this case, how to judging the
sentiment tendencies of Chinese words from the informal languages is of vital importance and is the
problem we struggle to overcome in this research.
Last but not least, tourism reviews, different from Sina Microblog or WeChat communication,
usually have no emoticons, which contributes a lot in sentiment classification as a noisy sentiment
label in previous researches. This leads to a higher classification accuracy requirements.

3.2 Experiment result
Below is the experiment result from our improved algorithms for detecting new words. Table 1
shows various index of Top 20 new words detected by our improved algorithms according to their
frequency in the corpus.
No
.
1
2
3
4
5
6
7
8
9
10
11
12

Word

Meaning

F

EMI

I I S S
A P A P

跟团游

Package tours
Eternal love, a large costume show

1052
533

4.51
8.89

O 0
O 0

-

-

T
E
T
1
1

Altitude stress
FIT(Forcign Independent Tourist) group

481
362

5.97
4.75

O 0
O 0

S
-

-1
-

Awesome, amazing, good
Reliable

284
267

5.20
5.68

S
S

1
1

-

Like
High-end and classy

259
243

4.14
3.40

S 1
O 0

Bonfire party
Glass paths built along the face of a cliff

201
196

6.11
7.34

King-size bed room
Wild Elephant Valley

160
160

Pretty cost-effective

千古情
高原反应
散客拼团
棒棒哒
靠谱
点个赞
高大上
篝火晚会
玻璃栈道
大床房

N
C
N
0
0

0
0

1
1

0
0

0
0

-

0
0

1
1

1
1

S

1

0
0

1
1

1
1

O 0
O 0

-

-

1
1

0
0

0
0

5.64
5.35

O 0
O 0

-

-

1
1

0
0

0
0

136

5.01

S

-

-

0

0

0

-

-

1

0

0

-

-

0

1

1

-

-

0

1

1

S
-

-1
-

0
1

0
0

0
0

13

野象谷
性价比超
高

14

隐形消费

Consumption trap

133

3.08

15

无语

Wordless, Disappointment

118

8.00

16

坑爹

Cheating

110

5.47

17
18

雾霾

Fog and haze
Ancient Tea Route

109
105

8.62
20.02

1
S
1
S
1
O 0
O 0

Yunnan province
Flower cake
Genuine tour at a fair price without
consumption lower limit
All five points, good

99
91

14.13
6.31

O 0
O 0

-

-

1
1

0
0

0
0

82

7.73

O 0

S

1

1

0

0

22

鲜花饼
纯玩无购
物
全五分

72

3.64

S

1

1

0

0

23

吐槽

To make complaints

71

7.04

-

-

0

1

1

24

一级棒
美美哒

Excellent, perfect

71

5.14

O 0
S
1
S 1

-

-

0

1

1

S

-

-

0

1

1

19
20
21

25

茶马古道
彩云之南

Very beautiful

71
3.31
Table1：Word detection results (Top 20)

1

S

1

1258	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

As we can see from the table, No. Column is the rank of new words according to frequency in
corpus. Word column is the Chinese new word detected by our algorithms. Meaning Column
corresponds to English representation of the corresponding Chinese new word. Frequency (F) Column
represents the frequency of the detected new words. EMI Column is the important index in improved
algorithms assisting to detect new words. Inherent Attribute (IA) Column is an option on judging
whether the detected word is subjective or objective intrinsically. IP Column is an abbreviation of
Inherent Polarity, referring to the inherent polarity of detected words, with -1 representing negative
affective, 0 representing objective and 1 representing positive emotions. Special Attribute (SA)
Column is S or O if there’s a different transferred meaning of a detected word used in tourism reviews
while whether S or O depends on the transferred meaning tends to subjective or objective; And
Special Attribute (SA) Column is – when there’s no transferred meaning. SP Column, similar to IP
Column, is an abbreviation of Special Polarity, referring to the special polarity of detected words with
transferred meaning, with -1 representing negative affective, 0 representing objective and 1
representing positive emotions. Tourism Exclusive Terms (TET) Column, Networking Neologism
(NN) Column and Colloquialism Column (C) are options judging whether the detected words comes
from tourism exclusive terms, networking neologism or colloquialism respectively, with 1
representing yes and 0 standing for not.
Obviously, the new Chinese words deal with catering, travel products or style, accommodation,
whether and climate, shopping and feelings of tourists. These words mainly aims at tourism and are
hard to learn in other domains.
As is shown, we can derive some statistic result according to the information presented above and
conclude them in the following table. IAO represents the words classified into objective ones in terms
of Inherent Attribute; IAS represents the words classified into subjective ones in terms of Inherent
Attribute. Other abbreviation is the same as Table1.
Attribute
IAO
IAS
SP
TET
NN
C

Count
15
10
5
15
9
9

Proportion
0.60
0.40
0.20
0.60
0.36
0.36

Table 2: word detection results analysis

It is obvious that our improved new word detection algorithms performs well in detecting
subjective ones, transferred-meaning ones, tourism exclusive terms, network neologism and
colloquialism. For example, “ 纯 玩 无 购 物 ” , which means genuine tour at a fair price without
consumption lower limit, usually is an objective word, but it has special transferred meaning while
used in tourism reviews. This usually represents the subjective and positive emotion and can be
included in Tourism Exclusive Terms. “ 点个赞”, expressing likes, comes from Network Neologism and
Colloquialism, which cannot be find in general lexicon or dictionary.

As for IAO, the majority of them may have transferred meaning or come from TET, NN or C. The
results implies that the improved new word detection algorithms contributes to exploring words that
cannot be included in general lexicon.

	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

4 Conclusion
Refer Ctrip.com users express their opinions or sentiment on tourism products via tourism
reviews, which may conclude much information on hotels, tourism routines, local food, or
transportation condition. New word detection technique constructed in our research make it
possible to integrate huge amounts of messages, analyze latent new word in a certain field and
take advantage of useful information to build sentiment lexicon in a specialized field
subsequently. There are plenty of proper nouns in travel reviews, and our method proposed
above aims at overcoming this difficulty. Another import issue is that some words which do not
contain sentiment would be converted to sentiment words in a specialized filed such as travel
field. Our method solves those two issues in some degree.
We will build our tourism-specific Chinese sentiment lexicon on a large tourism review
dataset and other corpus related to tourism. New word detection technique will be the footstone in
building such lexicon.
In our future work, we plan to construct a specific tourism review sentiment lexicon, and
make more accurate inference and classification on tourism products. This would supply local
Travel and Tourism Administration, traveling companies and tourists with more complete
information on traveling products, and assists them to make a better decision in policy-making,
business strategy and social daily life.

Acknowledge
This research is supported by the National Natural Science Foundation of China No.
91546201, No. 71331005 and No. 71501175, Shandong Independent Innovation and
Achievement Transformation Special Fund of China (2014ZZCX03302), and the Open
Project of Key Laboratory of Big Data Mining and Knowledge Management, Chinese
Academy of Sciences.

Reference
Abdulla, N. A., Ahmed, N. A., Shehab, M. A., & Al-Ayyoub, M. (2013). Arabic sentiment
analysis: Lexicon-based and corpus-based. Paper presented at the Applied Electrical Engineering and
Computing Technologies.
Bravo-Marquez, F., Frank, E., & Pfahringer, B. (2016). Building a Twitter Opinion Lexicon from
Automatically-annotated Tweets. Knowledge-Based Systems, 108, 65-78.
Cho, H., Kim, S., Lee, J., & Lee, J. S. (2014). Data-driven integration of multiple sentiment
dictionaries for lexicon-based sentiment classification of product reviews. Knowledge-Based Systems,
71, 61-71.
Fu, X., Guo, L., Guo, Y., & Wang, Z. (2013). Multi-aspect sentiment analysis for Chinese online
social reviews based on topic modeling and HowNet lexicon. Knowledge-Based Systems, 37(2), 186195.
Hu, Z., Ma, X., Liu, Z., Hovy, E., & Xing, E. (2016). Harnessing Deep Neural Networks with
Logic Rules.
Khalil, T., & El-Beltagy, S. R. NileTMRG at SemEval-2016 Task 5: Deep Convolutional Neural
Networks for Aspect Category and Sentiment Extraction.
Santos, C. N. D., & Gattit, M. (2014). Deep Convolutional Neural Networks for Sentiment Analysis

1259

1260	

Wei Li et al. / Procedia Computer Science 108C (2017) 1251–1260

of Short Texts. Paper presented at the International Conference on Computational Linguistics.
Taboada, M., Brooke, J., Tofiloski, M., Voll, K., & Stede, M. (2011). Lexicon-based methods for
sentiment analysis. Computational Linguistics, 37(2), 267-307.
Tai, K. S., Socher, R., & Manning, C. D. (2015). Improved Semantic Representations From TreeStructured Long Short-Term Memory Networks. Computer Science.
Wu, F., Huang, Y., Song, Y., & Liu, S. (2016). Towards building a high-quality microblog-specific
Chinese sentiment lexicon. Decision Support Systems, 87, 39-49.

