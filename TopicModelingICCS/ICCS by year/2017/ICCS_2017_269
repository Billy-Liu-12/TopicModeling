Available online at www.sciencedirect.com

This
This
This
This

ScienceDirect

space is reserved for the Procedia header,
space is reserved for the Procedia header,
space
isComputer
reservedScience
for the
header,
Procedia
108CProcedia
(2017) 515–524
space is reserved for the Procedia header,

do
do
do
do

not
not
not
not

use
use
use
use

it
it
it
it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland
Topology-aware Job Allocation
in 3D Torus-based HPC

Topology-aware
Job
Allocation
in
HPC
Topology-aware
JobHard
Allocation
in 3D
3D Torus-based
Torus-based
HPC
Systems
with
Job
Priority
Constraints
Topology-aware
Job
Allocation
in
3D
Torus-based
HPC
Systems
Hard
Job
Priority
Constraints
Systems with
with
Hard
Job
Priority
Constraints
2
Kangkangwith
Li1 , Maciej
, and Jarek
Nabrzyski11
Systems
HardMalawski
Job Priority
Constraints
2
Kangkang Li11 , Maciej
Malawski
,
and
Jarek
Nabrzyski1
2
1

Kangkang Li , Maciej Malawski , and Jarek Nabrzyski

Department of Computer Science
and Engineering, University of Notre Dame, Indiana, USA
Kangkang Li1 , Maciej Malawski2 , and Jarek Nabrzyski1

2 1 Department of Computer Science and Engineering, University of Notre Dame, Indiana, USA
1Department of Computer Science, AGH University of Science and Technology, Krakow, Poland
DepartmentofofComputer
ComputerScience,
Science AGH
and Engineering,
of Notre
Dame,Krakow,
Indiana,Poland
USA
2
Department
University
ofUniversity
Science and
Technology,
{kli3,naber}@nd.edu,
malawski@agh.edu.pl
21
2

Department
Science,
University
ofUniversity
Science and
Technology,
DepartmentofofComputer
Computer
Science AGH
and Engineering,
of Notre
Dame,Krakow,
Indiana,Poland
USA
{kli3,naber}@nd.edu,
malawski@agh.edu.pl
{kli3,naber}@nd.edu,
malawski@agh.edu.pl
Department of Computer
Science, AGH University
of Science and Technology, Krakow, Poland
{kli3,naber}@nd.edu, malawski@agh.edu.pl

Abstract
Abstract
In this paper, we address the topology-aware job allocation problem on 3D torus-based high
Abstract
In this paper,
we address
the topology-aware
job allocation
3D torus-based
high
performance
computing
systems,
with the objective
of reducingproblem
system on
fragmentation.
Firstly,
In this paper,
we address
the topology-aware
job allocation
problem
on
3D torus-based
high
Abstract
performance
computing
systems,
with thestrategy,
objective
of reducing
system
fragmentation.
Firstly,
we
propose
a
group-based
job
allocation
which
leads
to
a
more
global
optimization
of
performance
computing
systems,
with
the
objective
of
reducing
system
fragmentation.
Firstly,
In this paper,
we address
topology-aware
job
allocation
problem
3D torus-based
high
we
propose
a group-based
jobthe
allocation
strategy,
which
leads to
a moreon
global
optimization
of
resource
allocation.
Secondly,
we
propose
two
shape
allocation
methods
to
determine
the
topowe
propose
a computing
group-based
job we
allocation
which
leads to
a morefragmentation.
global
optimization
of
performance
systems,
with thestrategy,
objective
of
reducing
system
Firstly,
resource
allocation.
Secondly,
propose
two
shape
allocation
methods
to
determine
the
topological
shape
for each
input job,
including
a zigzag
allocation
method
for
communication
nonresource
allocation.
Secondly,
we
propose
two
shape
allocation
methods
to
determine
the
topowe
propose
a
group-based
job
allocation
strategy,
which
leads
to
a
more
global
optimization
of
logical
shape
each
input job,
including
a zigzag
allocation method
for communication
sensitive
jobs,for
and
a convex
allocation
method
for communication
sensitive
jobs. Thirdly,nonwe
logical
shape
for
each
input
job,
including
a
zigzag
allocation
method
for
communication
nonresource
allocation.
Secondly,
we
propose
two
shape
allocation
methods
to
determine
the
toposensitive
and a convex
fortocommunication
sensitive
jobs. Thirdly,
we
propose
ajobs,
topology-aware
joballocation
mapping method
algorithm
reduce the system
fragmentation
brought
sensitive
jobs,
and
a convex
allocation
method
fortocommunication
sensitive
jobs. Thirdly,
we
logical
shape
for
each
input
job,
including
a zigzag
allocation
method
for
communication
nonpropose
a
topology-aware
job
mapping
algorithm
reduce
the
system
fragmentation
brought
in
by theajob
mapping process,
includingalgorithm
a target bin
selection
method
and
a bi-directional
job
propose
topology-aware
job
mapping
to
reduce
the
system
fragmentation
brought
sensitive
jobs,
and
a
convex
allocation
method
for
communication
sensitive
jobs.
Thirdly,
we
in
by the method.
job mapping
including
target bin
selection
method
a bi-directional
job
mapping
Theprocess,
evaluation
resultsa
validate
the
efficiency
of ourand
approach
in reducing
in
by
the
job
mapping
process,
including
a
target
bin
selection
method
and
a
bi-directional
job
propose
a
topology-aware
job
mapping
algorithm
to
reduce
the
system
fragmentation
brought
mapping
method. Theand
evaluation
results
validate
the efficiency of our approach in reducing
system
fragmentation
improving
system
utilization.
mapping
method.
Theand
evaluation
results
the
efficiency
of ourand
approach
in reducing
in
by the
job mapping
process,
including
a validate
target
bin
selection
method
a bi-directional
job
system
fragmentation
improving
system
utilization.
system
fragmentation
and
improving
system
utilization.
Keywords:
Topology-aware,
group-based
job
allocation,
3D
torus,
job
mapping
mapping
method.
The
evaluation
results
validate
the
efficiency
of
our
approach
in
reducing
© 2017 The Authors. Published by Elsevier B.V.
Keywords:
Topology-aware,
group-based
job
allocation,
torus, jobConference
mapping on Computational Science
Peer-review
under
responsibility
the scientificsystem
committee
of the3D
International
system
fragmentation
and of
improving
utilization.
Keywords:
Topology-aware,
group-based
job allocation,
3D torus, job mapping

1
Introduction
Keywords:
Topology-aware, group-based job allocation, 3D torus, job mapping
1
Introduction
1 The
Introduction
torus-based system is one of the largest classes of today’s high performance computing
The
torus-based
system
is one
of the
largest such
classes
today’s
high
computing
1
Introduction
(HPC)
systems,
which
is widely
used
in systems
as of
Blue
Waters
[4],performance
and Blue Gene/Q
[11].
The torus-based
system
is one
of the
largest classes
of
today’s
high
performance
computing

(HPC)
is widelythe
used
in systems
suchofasX,Blue
[4], and Blue
Gene/Q
[11].
On
Bluesystems,
Waters which
for instance,
network
consists
Y, ZWaters
3D dimensions.
Each
dimension
(HPC)
systems,
which
is widely
used
in systems
such
asX,
Blue
Waters
[4],performance
and Blue
Gene/Q
[11].
The
torus-based
system
is one
of
the
largest
classes
of
today’s
high
computing
On
Blue
Waters
for
instance,
the
network
consists
of
Y,
Z
3D
dimensions.
Each
dimension
has
24 Gemini
routers,
makingthe
thenetwork
system consists
a 24*24*24
torus
interconnect.
Each
coordinate
on
On
Blue
Waters
for
instance,
of
X,
Y,
Z
3D
dimensions.
Each
dimension
(HPC)
systems,
which
is
widely
used
in
systems
such
as
Blue
Waters
[4],
and
Blue
Gene/Q
[11].
has
24Z Gemini
routers,
making the
system
a 24*24*24
torusGemini
interconnect.
Each
coordinate
on
X,
Y,
dimensions
is
associated
with
a
Gemini
router.
Each
router
is
directly
associated
has
24Z Gemini
makingthe
the
system
a 24*24*24
torus
interconnect.
Each
coordinate
on
On
Blue
Watersrouters,
forisinstance,
network
consists
of X,
Y, Z
3D dimensions.
Each
dimension
X,
Y,
dimensions
associated
with
a
Gemini
router.
Each
Gemini
router
is
directly
associated
to
two
computing
nodes,
and is connected
to its
six neighbor
routersrouter
alongisX,
Y, Z dimensions.
X,
Y,
Z
dimensions
is
associated
with
a
Gemini
router.
Each
Gemini
directly
associated
has
24
Gemini
routers,
making
the
system
a
24*24*24
torus
interconnect.
Each
coordinate
on
to two
nodes,
and is connected
tothe
its six
routers
along X, Y,
Z dimensions.
Thiscomputing
torus-based
interconnect
influences
wayneighbor
jobs should
be allocated
into
the system.
to two
computing
nodes,
and
is
connected
to
its
six
neighbor
routers
along
X,
Y,
Z
dimensions.
X,
Y,
Z
dimensions
is
associated
with
a
Gemini
router.
Each
Gemini
router
is
directly
associated
interconnect
influences
the way performance
jobs should be
the system.
On This
Blue torus-based
Waters, in order
to improve
the application
andallocated
runtime into
consistency,
the
This
torus-based
interconnect
influences
wayneighbor
jobs should
be
allocated
into
the system.
to two
computing
nodes,
and
is connected
tothe
its six
routers
along
X, Y,
Z dimensions.
On
Blue
Waters,
in
order
to
improve
the
application
performance
and
runtime
consistency,
the
system
adopts
a
contiguous
allocation
strategy
and
a
convex
prism
shape
is
allocated
to
each
On
Blueadopts
Waters,
in order
to allocation
improve
the
application
andshape
runtime
consistency,
the
This
torus-based
interconnect
influences
the and
way aperformance
jobs
should
be
allocated
into
the system.
system
a
contiguous
strategy
convex
prism
is
allocated
to
each
job.
However,
using
this strategy
degrades
the system
utilization.
Onshape
the other
hand, the
nonsystem
adopts
a
contiguous
allocation
strategy
and
a
convex
prism
is
allocated
to
each
On
Blue
Waters,
in
order
to
improve
the
application
performance
and
runtime
consistency,
the
job.
However,
using this
strategy
degrades
system
utilization.but
Onitthe
otherjob
hand,
the noncontiguous
allocation
strategy
improves
thethe
system
utilization,
causes
performance
job.
However,
using
this
strategy
degrades
the
system
utilization.
On
the
other
hand,
the
nonsystem
adopts
a
contiguous
allocation
strategy
and
a
convex
prism
shape
is
allocated
to
each
contiguous
strategy improves
the system
but motivate
it causes us
jobtoperformance
to
go downallocation
due to communication
interference
[4]. utilization,
These reasons
investigate
contiguous
allocation
strategy
improves
thethe
system
utilization,
but
itthe
causes
job
job.
However,
using
this
strategy
degrades
system
utilization.
On
other
hand,
the nonto
go
down
due
to
communication
interference
[4].
These
reasons
motivate
us
toperformance
investigate
various
job
allocation
strategies
on
torus-based
HPC
systems.
to
go
down
due
to
communication
interference
[4].
These
reasons
motivate
us
to
investigate
contiguous
allocation
strategy
improves
the
system
utilization,
but
it
causes
job
performance
various
strategies
on torus-based
systems.
One job
keyallocation
factor to the
low system
utilizationHPC
is system
fragmentation, which includes both
various
job
allocation
strategies
on torus-based
HPC
systems.
to
go
down
due
to to
communication
interference
[4].
These
reasons motivate
us to
investigate
One
key
factor
the
low
system
utilization
is
system
fragmentation,
which
includes
both
internal
and
external
fragmentation.
The
internal
fragmentation
results from
using
the convex
One
key
factor
to
the
low
system
utilization
is
system
fragmentation,
which
includes
both
various
job
allocation
strategies
on
torus-based
HPC
systems.
internal and external fragmentation. The internal fragmentation results from using the convex
internal
and factor
external
internalisfragmentation
results from
using
the convex
One key
to fragmentation.
the low system The
utilization
system fragmentation,
which
includes
both
internal and external fragmentation. The internal fragmentation results from using the convex

1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.016

516	

Topology-aware Job Allocation...
Li, Malawski, Nabrzyski
Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524

prism shape for job allocation, which allocates more nodes to a job than it needs. An example
of convex prism shape is shown in Fig. 1, where a job with a 10 node request is allocated a
convex prism of 12 nodes. The blue area in Fig. 1 indicates the 10 nodes required by the job,
and the grey area of 2 nodes becomes the internal fragmentation. The external fragmentation,
on the other hand, is caused by the contiguous allocation strategy, which separates the free
system resources into smaller, non-contiguous blocks interspersed by allocated resources. This
will lead to the situation when sufficient number of free nodes cannot be contiguously allocated
for a job. To this end, we propose to develop strategies to reduce system fragmentation, which
in turn, can improve system utilization.
The scheduler assigns each waiting job a priority. In this paper,
without loss of generality, we assume the queue is already ordered by
assigned priority. All the jobs must be allocated strictly following the
priority order. Different from the current policy used on Blue Waters, Figure 1: convex prism
which allocates one job at a time, our approach is to group several waiting jobs and allocate
them together into the free space of the system. In that case, we can find a whole large free
block to accommodate all of the grouped jobs. Compared to one job at a time allocation, this
group-based job allocation has the potential to reduce system fragmentation and lead to a more
global optimization of resource allocation, since multiple jobs are allocated together, all at once.
Our approach is generic and can be applied to any 3D torus-based system, but in this paper
we use the traces from the Blue Waters system.
According to the information from system administrators of Blue Waters, all input jobs
on Blue Waters can be classified as either communication sensitive to inter-job interference
(communication sensitive for short) or communication non-sensitive to inter-job interference
(communication non-sensitive for short). Communication sensitive jobs are not tolerant of
inter-job interference, thus they require convex prism shapes. For communication non-sensitive
jobs, the shape requirement can be relaxed and not limited to convex prism only.
Our objective is to design an efficient job allocation strategy to reduce the system fragmentation on a 3D torus-based HPC system, while preserving the performance of jobs. In order to
maintain the job performance to the best achievable degree, we still need to maintain contiguous allocation strategy for input jobs, which means that non-contiguous allocation that
scatters the job’s nodes across the system is not acceptable. As the users on HPC systems,
such as Blue Waters, usually only specify the number of nodes required for their jobs with no
shape specification. Therefore, we also need to determine the shape for each input job.
The paper is organized as follows: we propose a group-based job allocation strategy in
Section 2. Section 3 presents two shape allocation methods to determine the shape for each
input job. We study the job mapping problem and propose a topology-aware job mapping
algorithm in Section 4. In Section 5, we conduct simulations to evaluate the performance of
our approach. The related work is discussed in Section 6. We give our conclusions and future
work in Section 7.

2

Group-based Job Allocation

Similar to our work [8], we propose a group-based job allocation strategy, where we add a
group buffer between the waiting queue and the system, as shown in Fig. 2. The size of the
group buffer is L, which is the number of jobs this group buffer contains. In our approach, the
scheduler allocates jobs in periodical allocation cycles. In each allocation cycle, the scheduler
groups all jobs in the group buffer and allocates them together into the system, which leads to
better resource allocation.
As shown in Algorithm 1, at one allocation cycle s, firstly, the scheduler scans the system and
2

	

Topology-aware Job Allocation...
Li, Malawski, Nabrzyski
Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524

Algorithm 1 Group-based Job Allocation
1: if at one allocation cycle s then
2:
scan the system and detect the set P of N free partitions: P = {p1 , ..., pN }
3:
obtain the set J of L waiting jobs in the group buffer: J = {j1 , ..., jL }
4:
Topology-aware Job Mapping (J, P )
 Algorithm 2
5:
if all jobs in J are allocated then
6:
terminate current allocation cycle s
7:
wait until the next allocation cycle s + 1
8:
else if ji ∈ J is rejected then
9:
terminate current allocation cycle s
10:
calculate the start time of job ji and reserve space for ji
11:
perform EASY backfilling until the start time of ji
WAITING QUEUE
Incoming jobs

GROUP BUFFER
...

…

Allocation

…

...

Buffer size configurable: L

Bin 1

Bin N

Figure 2: Group-based job allocation
detects the set P of free partitions. This set of free partitions represents all available contiguous
resource areas in the system at current allocation cycle s. These areas can be represented as
a set of bins. Each bin is a 3D convex rectangular prism. In this paper, we will use the two
terms (bins and partitions) interchangeably. Secondly, we obtain the set J of L waiting jobs in
the group buffer ordered by priority. Thirdly, we map jobs in J (the set of waiting jobs in the
group buffer) into P (the set of free bins). The detailed mapping process (line 4 in Algorithm
1) is discussed in Section 4.
As shown in Algorithm 1, the mapping process of one allocation cycle s terminates if all jobs
in J are allocated or one job ji ∈ J is rejected. If all jobs in J are allocated, we will terminate
current allocation cycle s, and wait until the next allocation cycle s + 1. Otherwise, if one job
ji ∈ J is rejected, we then terminate current allocation cycle s (line 9 in Algorithm 1). After
that, we calculate the start time of job ji and reserve space for ji (line 10 in Algorithm 1). At
last, we perform EASY backfilling [10] and use best-fit strategy to place “backfilled jobs” into
the system until the start time of ji (line 11 in Algorithm 1).
This group-based job allocation works well when the queue is not short of waiting jobs. In
that case, it is not hard to fill the group buffer with waiting jobs and allocate them together.
However, if the queue is empty or near empty with few jobs, this group buffer leads to an
overhead of waiting time, since we need to wait for the jobs in the buffer to be full, and then
allocate them together. To solve this, we propose to use configurable buffer size, where the
buffer size L is set as an enum variable that has several pre-defined values. When the queue has
plenty of jobs, the value of L will be large, in order to fully utilize the advantage of group-based
job allocation. When the queue is near empty with few jobs, the value of L will be small,
favoring the job performance and reducing waiting time. This setting allows us to intelligently
configure the size of group buffer based on the status of the waiting queue (e.g. the number of
waiting jobs in the queue). Moreover, this group-based job allocation is designed to deal with
jobs with walltimes from a few minutes to 24 hours, as shown in our evaluation.

3

Shape Allocation Methods
As mentioned before, in each allocation cycle, the scheduler detects a set of free bins/parti3

517

J1

J1

J1 J1

J2

J1

J1 J1

J2

J2

J2 J3

J4

J3

J3 J 3

Y dimension
A. Zigzag allocation

X dimension

Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524
Topology-aware Job Allocation...
Li, Malawski, Nabrzyski

X dimension

518	

J1

J1

J1 J1

J1

J1

J1 J1

J2

J2

J2 J2

J3

J3

J3 J3

Y dimension
B. Convex allocation

Figure 3: An illustration of the zigzag allocation and convex allocation
tions for job allocation. As users on HPC systems, such as Blue Waters, usually do not specify
the shapes for their jobs, we propose two different methods to determine the shape of a job in
one of the free bins according to its communication sensitivity.
For a communication non-sensitive job, which does not require a convex prism shape, we
propose a zigzag allocation method to determine its shape in a bin. The zigzag goes from Y
dimension first, followed by X dimension on an XY plane. After one plane is filled, it goes up
to the next layer along the Z dimension. An example of a 2D zigzag allocation is in Fig. 3. A.
In Fig. 3. A, there is a 2D bin with a capacity of 16 nodes. Suppose we have four input
jobs (J1 to J4 ). Job J1 requires 7 nodes, J2 and J3 each requires 4 nodes, and J4 requires 1
node. If all of the four jobs are communication non-sensitive, zigzag allocation can pack all
jobs together in the bin with no internal fragmentation. As shown in Fig. 3. A, the bin with
a capacity of 16 nodes can be fully filled by the four input jobs. Therefore, zigzag allocation
can be considered as an optimal shape allocation method to maximize the system utilization if
all jobs are communication non-sensitive. Moreover, contiguity is still maintained by the
zigzag allocation, where each job is allocated a set of nodes which are physically adjacent.
For a communication sensitive job, a convex prism shape is required, which introduces
internal fragmentation. Take Fig. 3. B for instance, if all of the three jobs (J1 to J3 ) are
communication sensitive jobs using convex shapes, there will be an internal fragmentation of 1
idle node due to using convex shape for J1 (the grey area in the second row of Fig. 3. B). In
that case, J4 with 1 node request will not able to be accepted into the bin.
In fact, the extent of internal fragmentation (the number of idle nodes due to using convex
shape) is different if we map a job in a different bin. We want to map each communication
sensitive job into the target bin that minimizes the internal fragmentation, and thus improves
system utilization. We will discuss the job mapping process in the next section.

4

Topology-aware Job Mapping

In this section, we study the topology-aware job mapping problem, where we map the set J
of L jobs in the group buffer into the set P of free partitions, with the objective of maximizing
system utilization.

4.1

Multiple Knapsack Model

Job mapping into bins/partitions can be expressed as a 3D multiple knapsack problem.
Each bin is considered as a knapsack, and the jobs are the items waiting to be mapped into the
knapsacks. Let J = {j1 , j2 , ...., jL } be the set of L waiting jobs in the group buffer ordered by
priority. Each job ji has weight wi , with profit bi . Let K = {k1 , k2 , k3 , ..., kN } be the set of N
knapsacks, which comes from the free bin set P = {p1 , p2 , p3 , ..., pN } obtained in Algorithm 1.
We want to find a mapping for the L waiting jobs in the group buffer into the set P of free bins,
with the objective of maximizing the total profit. The mathematical formulation is below:
4

	

Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524
Topology-aware Job Allocation...
Li, Malawski, Nabrzyski

J1 J1

J1

J1

J1

J1

J1

J1

J1

J1 J1

J1

J1

J1

J1

J1

J1

J1

J1 J1

J1

J1

Bin 1

Bin 2

Figure 4: Target bin selection: reduce internal fragmentation

M aximize :

L 
N


xij bi

(1)

i=1 j=1

Subject to :

N

j=1

xij ≤ 1,

L

i=1

xij wi ≤ Cj , xij ∈ {0, 1}

(2)

xij = 1 means job ji is mapped into knapsack kj , and xij = 0 means job ji is not mapped
into knapsack kj . The physical meaning of both weight wi and profit bi is the job size, which is
the number of requested nodes of job ji . Each knapsack kj has the capacity of Cj , which will
be reduced as more jobs are mapped into the knapsack.
Based on this multiple knapsack model, maximizing system utilization can be transformed
into maximizing the objective of Eq. 1. As the sizes of the input jobs and capacities of the
free bins are heterogeneous, this multiple knapsack problem is NP-hard and requires a heuristic
solution, which we will discuss in the next subsection.

4.2

Job Mapping Process

The intuition of our heuristic solution is to reduce the system fragmentation brought in by
the job mapping process, including both internal fragmentation and external fragmentation.
4.2.1

Reduce Internal Fragmentation: Target Bin Selection

For a communication sensitive job, it requires a convex prism shape, which could lead to an
internal fragmentation. We define the extent of internal fragmentation as the number of idle
nodes due to using a convex shape. The extent of internal fragmentation is different if we map
the communication sensitive job into different bins. Take Fig. 4 for instance, Bin 1 has a 4*4
topological layout, and job J1 is communication-sensitive with a 10 node request. If we map J1
into Bin 1, it leads to an internal fragmentation of 2 idle nodes (the grey area in the third row
of Bin 1). On the other hand, if we map J1 into Bin 2, it brings in no internal fragmentation
since Bin 2 has a 3*5 topological layout. Therefore, Bin 2 is more preferable than Bin 1 to
accept J1 and minimize the internal fragmentation.
Therefore, for a communication sensitive job, we select the bin that has enough capacity
and leads to the minimal internal fragmentation among all the bins as the target bin to map
the communication sensitive job into.
For a communication non-sensitive job, it leads to no internal fragmentation using zigzag
allocation. Therefore, we adopt best-fit strategy to find the target bin to map the communication non-sensitive job into.
4.2.2

Reducing External Fragmentation: Bi-directional Job Mapping Method

For one input job ji , if the target bin pj is selected, we will map job ji into bin pj . However,
an external fragmentation can occur resulting from a mixed mapping of communication sensitive
and non-sensitive jobs into the same bin.
5

519

J1

J1

J1

J1

J1

J2

J2

J2

J2

J2

J2

Y dimension
A

X dimension

Topology-aware Job Allocation...
Li, Malawski, Nabrzyski
Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524

X dimension

520	

base

J2

J2

J2

J2

J2

J2

J3

J3

J3

J1

J1

J3

J1

J1

J1

end

Y dimension
B

Figure 5: Bi-directional job mapping to reduce external fragmentation
Algorithm 2 Topology-aware Job Mapping
1: Input: the set P of N free bins: P = {p1 , p2 , ..., pN }
the set J of L waiting jobs in the group buffer: J = {j1 , j2 , ..., jL }
2: for i = 1 to L do
3:
if job ji is communication sensitive then
4:
find the target bin pj with minimal internal fragmentation and enough capacity Cj
5:
start from the base side to map ji into pj using convex shape allocation
6:
else if job ji is communication non-sensitive then
7:
find the target bin pj with enough capacity Cj using best-fit strategy
8:
start from the end side to map ji into pj using zigzag shape allocation
9:
if ji cannot be mapped then
10:
reject ji
11:
break
Take Fig. 5. A for instance, suppose there is a 2D bin with a 3*5 topological layout. Let
J1 be a communication non-sensitive job with a 5 node request. Then, the 1 idle nodes on the
second row will be wasted if the next job accepted into the bin is a communication sensitive
job with a node request more than 1 nodes, such as the communication sensitive job J2 with a
6 node request shown in Fig. 5. A. This is the external fragmentation from the mixed mapping
of convex and zigzag shapes. In that case, the communication non-sensitive job J3 with a 4
node request will not be able to be accepted into the bin.
To reduce this external fragmentation, we propose a bi-directional job mapping strategy
to separate, in each bin, the spaces between communication sensitive and non-sensitive jobs.
According to the definition in [2], each cubic bin has a base and an end, which is diagonal to
each other. For a communication sensitive job, once the target bin is selected, we start from
the base side of the target bin to map it using convex shape allocation. For a communication
non-sensitive job, once the target bin is selected, we start from the end side of the target bin
to map it using zigzag shape allocation.
The bi-directional mapping strategy reduces the external fragmentation caused by the mixed
mapping of convex and zigzag shapes. As shown in Fig. 5. B, a communication non-sensitive
job J1 is mapped from the end side, and a communication sensitive job J2 is mapped from the
base side. As such, the external fragmentation of 1 idle nodes in Fig. 5. A is removed, and the
communication non-sensitive job J3 can be accepted into this bin using zigzag shape allocation.

4.3

Summary of Topology-aware Job Mapping

The overall topology-aware job mapping algorithm is in Algorithm 2, which corresponds to
line 4 in Algorithm 1. The input is the set J of L waiting jobs in the group buffer and the
6

	

Topology-aware Job Allocation...
Li, Malawski, Nabrzyski
Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524

set P of N free partitions at one allocation cycle. For each job ji ∈ J, if ji is communication
sensitive, we select the target bin pj that leads to the minimal internal fragmentation among
all the bins and also has enough capacity Cj to accept ji . Once this target bin pj is selected, we
start from the base side of pj to map ji using convex shape allocation. If ji is communication
non-sensitive, we use best-fit strategy to select the target bin pj . After the target bin pj is
selected, we start from the end side of pj to map ji using zigzag shape allocation. When it
comes a job ji that cannot be mapped into P , we reject ji and terminate this mapping process.
After that, we will prepare for EASY backfilling [10], which is described in Algorithm 1.

5

Performance Evaluation

In this section, we conduct simulations to evaluate our approach to reduce system fragmentation, which in turn, improves system utilization. The evaluation is performed using Blue
Waters trace [1] from September 2015. For simplicity and without loss of generality, we generate
synthetic workloads, which represent and preserve trace characteristics.
Based on the study of trace data, we found that the largest job requires 26853 nodes (only a
few jobs like this). As convention, jobs with node requests more than 3000 nodes are classified
as extra-large jobs. These extra-large jobs can cause the system to drain (release nodes) until
enough space is available to accept such jobs. This drainage brings the system utilization down
for a long time. To deal with these extra-large jobs, reducing system fragmentation alone is not
enough as these jobs may require half or more of system’s capacity. Therefore, other approaches,
such as relaxing priority constraints, are necessary to deal with these extra-large jobs.

5.1

Simulation Setup

In this paper, we focus on input workloads that contain jobs with node requests below
300 nodes. These jobs with node requests below 300 nodes constitute 98% of the entire trace
workload. We present the distribution of job size and job walltime throughout the trace in Fig.
6. (a) and Fig. 6. (b). The synthetic workloads are generated strictly following the real trace
distribution characteristics.
We conduct two groups of simulations. In the first group, we study the impact of communication sensitivity distribution on the performance of our approach, which includes a group-based
job allocation strategy and a topology-aware job mapping algorithm. The performance is measured by the system utilization, which is referred to as the ratio of the number of occupied
nodes to the total number of nodes in the system. We fix the group buffer size as 1500 in the
first group of simulations. As the communication sensitivity information is not included in the
Blue Waters traces [1], we will generate different job communication sensitivity distributions for
simulations. In this paper, we also recommend the Blue Waters administrators to put the job
communication sensitivity information in the trace. Based on the distribution characteristics of
real traces on both job size and job walltime, we generate three workloads of jobs with different
communication sensitivity distribution. These three workloads are:
1. All jobs are communication non-sensitive;
2. Communication sensitivity is randomly given to each job so that empirically each job has
equal chance to be communication sensitive or non-sensitive;
3. All jobs are communication sensitive.
In the second group of simulations, we study the impact of group buffer size on the performance of our approach, where we set the buffer size as 300, 900, and 1200. The communication
sensitivity distribution of the workload in the second group of simulations is fixed as random
distribution among all input jobs.
7

521

Topology-aware Job Allocation...
Li, Malawski, Nabrzyski
Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524
5

104

4

number
ofjobs
jobs
number
ofjobs
jobs
number
ofof
number

10

number ofof
jobs
number
jobs
number
of jobs
number
jobs

5

10

3

102

#104

3

2

1

101

100

0
0

0.5

1

1.5

2

2.5

job
size
(number
nodes)
job
size (number
ofrequested
requested nodes)
job
size
(number
of
nodes)
job
size
(number
ofofrequested
requested
nodes)

3

#10

(a) job size distribution

0

500

1000

1500

walltime
/min
jobjob
walltime
job
time /min
/min
job
walltime
/min

4

(b) job walltime distribution

Figure 6: Trace distributions of one month workload

70
60
50
40
30
20
10
0
25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100

system
utilization
system
utilization
%
system
utilization % %

(a) all non-sensitive

80

Baseline
Our Approach

70
60
50
40
30
20
10
0
25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100

system
utilization
system
systemutilization
utilization % %

(b) randomly distribution

percentage
all iterations
iterations
% %%
percentage
of
percentage
ofofall
all
iterations

Baseline
Our Approach

percentageof
of all
all iterations
%
percentage
all
iterations
percentage
iterations
%%

80

90

90

90
percentage
ofall
alliterations
iterations
%
percentage
iterations
percentage
ofofall
%

522	

80

Baseline
Our Approach

70
60
50
40
30
20
10
0
25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100

system
utilization %
%
system
utilization
system utilization %

(c) all communication sensitive

Figure 7: Histogram of utilization under workloads of different communication sensitivity
We compare our approach to the baseline strategy, where we simulate the FCFS (First
Come First Served) + Backfilling strategy and allocate convex shape to each job. For both our
approach and the baseline strategy, using the same initital workload, we run the simulations
for a while to give the system an initial input. After that, we start our performance evaluation
and begin to record the system utilization. Based on our preliminary simulation results, we set
the allocation cycle to 15 minutes. We record the system utilization at each allocation cycle.

5.2

Simulation Results

The results of the first group of simulations are shown in Fig. 7. (a) - Fig. 7. (c).
These results show that, our approach outperforms baseline strategy under all three workloads.
Specifically, our approach achieves a system utilization of around 95% in most time of allocation
iterations, as shown in Fig. 7. (a). This shows that, if all jobs are communication non-sensitive,
our group-based job allocation strategy and zigzag shape allocation greatly improves utilization.
Moreover, as shown in Fig. 7. (b), with random communication sensitivity distribution,
our approach achieves around 90% utilization in most allocation iterations, which is lower than
that in Fig. 7. (a). This is expected since there are communication sensitive jobs with convex
shapes in the workload, leading to internal fragmentation and a lower utilization in the system.
Furthermore, as shown in Fig. 7. (c), when all the jobs are communication sensitive, the
utilization is lower than that in Fig. 7 (a) and Fig. 7. (b) due to the internal fragmentation
caused by using convex shape allocation. However, our approach achieves around 85% to 90%
utilization in most allocation iterations. This indicates the efficiency of our group-based job
allocation strategy in improving system utilization even if all jobs are allocated convex shapes.
8

Topology-aware Job Allocation...
Li, Malawski, Nabrzyski
Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524

percentage of all iterations %

70
60
50
40
30
20
10
0
25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100

system
utilization
%
system
utilization
system
utilization % %

(a) buffer size 300

80

Baseline
Our Approach

70
60
50
40
30
20
10
0
25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100

system
utilization
%
system
utilization
system
utilization % %

(b) buffer size 900

percentageof
of all
all
%
percentage
iterations
%%
percentage
of
alliterations
iterations

Baseline
Our Approach

percentageofofallalliterations
iterations
percentage
%%

80

90

90

90
percentage
iterations %
percentage
of
%
percentage
of ofall
allall iterations
iterations
%

	

80

Baseline
Our Approach

70
60
50
40
30
20
10
0
25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100
systemutilization
utilization
%
system
%
system
utilization
%

(c) buffer size 1200

Figure 8: Histogram of system utilization under workloads of different group buffer size
The results of the second group simulations is shown in Fig. 8. (a) - Fig. 8. (c). We
can see that, as the buffer size increases from 300 to 1200, the utilization of our approach has
also increased. Specifically, when the buffer size is 300, in spite of outperforming the baseline
strategy, our approach achieves a utilization of around 80%, with some iterations being even
low to around 60% to 70% utilization. This is because the buffer size is small and the free
partitions in the system are not fully filled.
When the buffer size is 900 and 1200, the system utilization has significantly improved. With
only the initial allocation iterations being in low utilization, our approach achieves the system
utilization around 85% to 90% in most time of the allocation iterations, which outperforms the
baseline strategy, as shown in Fig. 8. (b) and Fig. 8. (c). Based on this, we conclude that,
a larger buffer size leads to higher system utilization, although a smaller buffer size is more
advantageous to job performance. The source code of our approach is open to community [1].

6

Related Work

An overview process of mapping techniques and algorithms for HPC systems is presented
in [6]. It discusses algorithmic strategies for topology mapping, such as graph partitioning,
mapping enforcement techniques (resource binding and rank reordering), as well as existing
solutions and their implementations. This provides a formal definition of the mapping as an
optimization problem, and discusses the metrics such as dilation or congestion.
The most common heuristic for mapping problems falls into the domain of greedy strategy.
Based on some global criteria or cost metric, the algorithm selects the next task node in the
virtual topology for mapping onto the selected node in physical topology until all task nodes
are mapped. For instance, in [9], a greedy mapping algorithm is designed, where in each step,
the task node with the maximum number of neighbors is selected to map onto a physical node
with the minimum average hop distance to any other node.
Another strategy to solve the mapping problem is based on the duality between graph
and sparse matrix [7]. For instance, bandwidth reduction of a sparse matrix is a well-studied
problem in sparse linear algebra, which can be applied to bring the adjacency matrices of a
communication graph and a physical network graph in a similar shape where their edges are
localized. As this bandwidth reduction problem is NP-hard, Reverse Cuthill McKee (RCM)
heuristic algorithm [3] is applied and proved to be successful for the mapping problem.
In our work [8], in order to reduce the external fragmentation on Blue Waters, a packingbased job scheduling and a migration-based job placement reconfiguration strategies are proposed, where each job is allocated a convex prism shape. In this paper, with the objective of
reducing both the internal fragmentation and the external fragmentation, we classify jobs based
on the communication sensitivity, and then propose different shape allocation and job mapping
9

523

524	

Topology-aware Job Allocation...
Li, Malawski, Nabrzyski
Kangkang Li et al. / Procedia Computer Science 108C (2017) 515–524

methods for communication sensitive and communication non-sensitive jobs, respectively. The
packing-based job scheduling and the buffer-based on-line job scheduling strategies in [8] are
similar to our group-based job allocation strategy proposed in this paper.
Furthermore, bin packing [5] is also a related topic to efficient resource management in HPC
systems. In the bin packing problem, we have a set of bins with a fixed capacity limitation and
a set of items with a given size to be placed into these bins. The objective is to minimize the
number of bins used. The off-line version is NP-hard as well.

7

Conclusions and Future Work

In this paper, we addressed the problem of reducing system fragmentation on 3D torus-based
HPC systems. Firstly, we propose a group-based job allocation strategy. Secondly, we propose
a zigzag shape allocation method for communication non-sensitive jobs, and a convex shape
allocation method for communication sensitive jobs. Thirdly, we propose a topology-aware job
mapping algorithm to reduce the system fragmentation brought in by the job mapping process.
The evaluation results show that our approach performs well in improving the system utilization
when the input jobs are below 300 nodes. In our future work, we will focus on improving system
utilization with the input of extra-large jobs. Moreover, the impact of our algorithm on other
metrics, such as system makepan, will also be studied in our future work.

Acknowledgments
The authors would like to thank Shenglong Zhu, a graduate student of Department of
Computer Science and Engineering at University of Notre Dame, for his contributions in the
design of the bi-directional job mapping method. This work was supported by the National
Science Centre, Poland, grant 2016/21/B/ST6/01497.

References
[1] https://github.com/kangkangkenli/ICCS-2017.
[2] Hyunseung Choo, Seong-Moo Yoo, and Hee Yong Youn. Processor scheduling and allocation for
3d torus multicomputer systems. Parallel and Distributed Systems, IEEE Transactions on, 2000.
[3] E. Cuthill and J. McKee. Reducing the bandwidth of sparse symmetric matrices. In Proceedings of
the 1969 24th National Conference, ACM ’69, pages 157–172, New York, NY, USA, 1969. ACM.
[4] J Enos, G Bauer, R Brunner, and S Islam. Topology-Aware Job Scheduling Strategies for Torus
Networks. In Proceedings of the Cray User Group meeting., 2014.
[5] Michael Randolph Garey and David S. Johnson. Approximation algorithms for np-hard problems.
chapter Approximation Algorithms for Bin Packing: A Survey. Boston, MA, USA, 1997.
[6] Torsten Hoefler, Emmanuel Jeannot, and Guillaume Mercier. An Overview of Process Mapping
Techniques and Algorithms in High-Performance Computing. In High Performance Computing on
Complex Environments. Wiley, jun 2014.
[7] Torsten Hoefler and Marc Snir. Generic topology mapping strategies for large-scale parallel architectures. In Proceedings of the International Conference on Supercomputing, ICS ’11.
[8] Kangkang Li, Maciej Malawski, and Jarek Nabrzyski. Reducing fragmentation on 3d torus-based
hpc systems using packing-based job scheduling and job placement reconfiguration. In Proceedings
of the 16th International Symposium on Parallel and Distributed Computing, ISPDC 2017.
[9] C. Devi Sudheer and Ashok Srinivasan. Optimization of the hop-byte metric for effective topology
aware mapping. In HiPC, pages 1–9. IEEE Computer Society, 2012.
[10] Adam K. L. Wong and Andrzej M. Goscinski. Evaluating the easy-backfill job scheduling of static
workloads on clusters. In IEEE Cluster 2007.
[11] Z Zhou, X Yang, Z Lan, P Rich, W Tang, V Morozov, and N Desai. Improving Batch Scheduling
on Blue Gene/Q by Relaxing 5D Torus Network Allocation Constraints. In IPDPS 2015, 2015.

10

