Available online at www.sciencedirect.com

ScienceDirect

This space is reserved for the Procedia header, do not use it
Procedia
Computer Science
108C
(2017) 475–484
This space
is reserved
for the
Procedia
header, do not use it
This space is reserved for the Procedia header, do not use it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

StoreRush: An Application-Level Approach to Harvesting
StoreRush: An Application-Level Approach to Harvesting
Idle An
Storage
in a Best Eﬀort
Environment
StoreRush:
Application-Level
Approach
to Harvesting
Idle Storage
in a Best Eﬀort
Environment
1
Qing LiuIdle
, Norbert
Podhorszki
, Jong Eﬀort
Choi22 , Jeremy
Logan22 , Matt Wolf22 ,
Storage
in2 a 22Best
Environment
Qing Liu1 , Norbert
Podhorszki
, Jong Choi
3 , Jeremy Logan
4 , Matt Wolf ,
Scott Klasky2 , Tahsin Kurc3 , and Xubin He4
Scott Klasky , Tahsin Kurc , and Xubin He
Qing Liu , Norbert Podhorszki2 , Jong Choi2 , Jeremy Logan2 , Matt Wolf2 ,
2
3
1
TahsinofKurc
, andNewark,
XubinNJHe4
Scott
Klasky
New
Jersey ,Institute
Technology,
1

1
2
2
1
2

New Ridge
JerseyNational
InstituteLaboratory,
of Technology,
NJ
Oak
OakNewark,
Ridge, TN
3
Oak
RidgeBrook
National
Laboratory,
Ridge,
Stony
University,
StonyOak
Brook,
NYTN
3 4 Jersey Institute of Technology, Newark, NJ
New
Stony
Brook
University,
Stony Brook,
Temple
University,
Philadelphia,
PANY
Oak4 Ridge
National
Laboratory,
Oak Ridge,
Temple
University,
Philadelphia,
PA TN
3
Stony Brook University, Stony Brook, NY
4
Temple University, Philadelphia, PA

Abstract
Abstract
For a production HPC system where storage devices are shared between multiple applicaFor
production
where
storagecontention
devices are
shareda between
multiple
applicationsa and
managedHPC
in a system
best eﬀort
manner,
is often
major problem
leading
to
Abstract
tions
and
managed
in
a
best
eﬀort
manner,
contention
is
often
a
major
problem
leading
to
some storage devices being more loaded than others and causing a signiﬁcant reduction in I/O
For
a storage
production
HPC
system
where
storage
devices
are
shared
between multiple
applicasome
devices
being
more
loaded
than
others
and
causing
a
signiﬁcant
reduction
in
I/O
throughput. In this paper, we describe our latest eﬀorts StoreRush to resolve this practical
tions
and managed
a bestweeﬀort
manner,
contention
often a major
problem leading
to
throughput.
In this inpaper,
describe
our latest
eﬀortsisStoreRush
to resolve
practical
issue at the application
level without
requiring
modiﬁcation
to the ﬁle and
storagethis
system.
The
some
storage
devices
being
more
loaded
than
others
and
causing
a
signiﬁcant
reduction
in
I/O
issue
at the
application
without
requiringsystem
modiﬁcation
to the
and storage
system. The
proposed
scheme
uses alevel
two-level
messaging
to harvest
idleﬁle
storage
via re-routing
I/O
throughput.
In this paper,
we describe
our latest eﬀorts
StoreRush
to resolve
this practical
proposed
a two-level
messaging
harvest
idle storage
via re-routing
I/O
requests toscheme
a less uses
congested
storage
location system
so that to
write
performance
is improved
while limissue
at the aapplication
level withoutlocation
requiringsomodiﬁcation
to the ﬁle and
system. The
requests
lesson
congested
that
write performance
is storage
improved
limiting the to
impact
read by storage
throttling re-routing
if deemed
too much. An
analyticalwhile
model
is
proposed
scheme on
uses a two-level
messaging
system
to harvest
storage
via re-routing
I/O
iting
thetoimpact
re-routing
if deemed
tooidle
much.
An analytical
is
derived
guide the read
setupby
of throttling
optimal throttling
factor.
The proposed
scheme
is veriﬁedmodel
against
requeststotoguide
a lessthe
congested
location
so factor.
that write
performance
is improved
while
limderived
setup
of storage
optimal
throttling
The
proposed
scheme
is veriﬁed
against
production applications
Pixie3D,
XGC1
and QMCPack
during
production
windows,
which
very
iting the impact
on readPixie3D,
by throttling
re-routing
if deemed
too
much. Anwindows,
analytical
model
is
production
applications
XGC1
and
during
production
which
very
well demonstrated
the eﬀectiveness
(e.g.,
upQMCPack
to 1.8x improvement
in write) and scalability
of
derived
to guide thethe
setup
of optimal(e.g.,
throttling
factor.
The proposed
scheme
is veriﬁed
against
well
demonstrated
eﬀectiveness
up
to
1.8x
improvement
in
write)
and
scalability
of
our approach (up to 131,072 cores).
production
applications
Pixie3D,
XGC1 and QMCPack during production windows, which very
our approach
(up to 131,072
cores).
Keywords:
High Performance
Computing,
Storage,
well
demonstrated
the eﬀectiveness
up to I/O
1.8x improvement in write) and scalability of
©
2017
The Authors.
Published
by
Elsevier(e.g.,
B.V.
Keywords:
High(up
Performance
Peer-review
under
responsibility
ofComputing,
the scientificStorage,
committeeI/O
of the International Conference on Computational Science
our approach
to 131,072
cores).
Keywords: High Performance Computing, Storage, I/O

1 Introduction
1 Introduction
In high-performance computing (HPC) centers, parallel storage systems have become a viable
1
Introduction
In
high-performance
computing
(HPC)
centers,
parallel
storage systems
become
solution
for managing
big datasets
from
scientiﬁc
simulations.
These have
systems
use aa viable
range

solution
managing
big devices
datasetstofrom
scientiﬁc
simulations.
These systems
use by
a range
of 100s tofor
1000s
of storage
achieve
the throughput
and capacity
demanded
large
In
high-performance
computing
(HPC)
centers,
parallel
storage
systems
have
become by
a viable
of
100s
to
1000s
of
storage
devices
to
achieve
the
throughput
and
capacity
demanded
large
scientiﬁc applications. Despite strong peak performance that were achieved during maintenance
solution
for
managing Despite
big datasets
from
scientiﬁc
simulations.
These systems
use a range
scientiﬁc
applications.
strong
peak
performance
that
were
achieved
during
maintenance
windows when users are disallowed to access the systems and the I/O system is quiet, we have
of
100s towhen
1000susers
of storage
devices to
achieve
thesystems
throughput
and I/O
capacity
demanded
by
large
windows
disallowed
access the
and the
system
is quiet,
weorder
have
seen signiﬁcant
I/O are
ﬂuctuations
in to
production
environments,
observing
as much
as an
scientiﬁc
applications.
Despite
strong
peak
performance
that
were
achieved
during
maintenance
seen
signiﬁcantvariation
I/O ﬂuctuations
in production
environments,
observing
as root
muchcause
as anof order
of magnitude
in throughput
across storage
devices and
runs. A
such
windows
whenvariation
users are in
disallowed
to access
the
systems
and the
system
is quiet,
of
magnitude
throughput
across
storage
devices
andI/O
runs.
root
cause we
of have
such
performance
degradations
and variations
is the
interference
incurred
by Aapplications
running
seen
signiﬁcant
I/O ﬂuctuations
in production
observing
much as an
order
performance
degradations
and variations
is the environments,
interference incurred
by as
applications
running
of magnitude variation in throughput across storage devices and runs. A root cause of such
performance degradations and variations is the interference incurred by applications running1
1
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.005

1

476	

StoreRush

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

Liu, et. al.

simultaneously and sharing storage resources, as shown by previous work [7, 2, 8]. Despite a
multitude of research been done to provide quality of service (QoS) for storage systems [4, 6, 5],
the adoption of these mechanisms in HPC systems is very limited due to the implications in
eﬃciency, which is a key metric that cannot be sacriﬁced for QoS. As a result, the HPC storage is
often designed to be shared between applications in a best eﬀort manner to simplify storage stack
and increase eﬃciency, without explicit mechanisms in place to control the resource allocation
on a per application basis. With the growing size of HPC systems, this problem can become
worse, thus demanding new approaches that can work eﬃciently on the current HPC storage
landscape, and scale up to potentially a large amount of simultaneous clients. Most existing
approaches can be classiﬁed into two broad categories: server-side scheduling and log-structured
ﬁle system (LFS), none of which were adopted to address this problem on HPC systems. This
is mainly due to two reasons: 1) the philosophy and design of the scheduling system, where
the scheduling decision is mostly made by a single entity, limit the I/O scalability and the
number of simultaneous clients, and 2) the usage of large memory space as cache compromises
the resolution and ﬁdelity of numerical calculations.
StoreRush adopts a novel application-level approach, in which clients collectively participate
in the I/O scheduling through lightweight messaging to enable I/O re-routing in the presence
of hotspots. It works on production systems without requiring modiﬁcation to the ﬁle system,
and demonstrates the eﬀectiveness at O(100,000)-core scale. It maintains the maximum I/O
concurrency by allowing applications to access all available storage devices simultaneously. The
remainder of the paper is organized as follows. Section 2 presents the measurement results on
two leadership class systems and motivates the I/O variation problem. Section 3 discusses the
design and implementation details of StoreRush. Section 4 presents performance evaluations,
along with related work and conclusions in the end.

2

Why I/O Variability Is Still Not Solved in HPC?

We present performance measurements collected on two leadership systems and demonstrate
that I/O contention does exist and can be severe even with the ﬁle system level load balancing enabled. The experiments were done on Titan1 at Oak Ridge National Laboratory, and
Hopper/Edison2 , at National Energy Research Scientiﬁc Computing Center (NERSC). Each
machine deploys a massively parallel storage system, comprised of on the order of O(100)O(1,000) storage devices for a given ﬁle system scratch space. For the ﬁrst experiment, in
Figure 1(a) and (b), we write 16 MB blocks to the storage device #0 in the system to test
the perceived speed of an individual storage device. The results were collected over 100 iterations to show the throughput ﬂuctuation over time. For example, on Hopper (Figure 1(b)),
the peak is more than 10x higher than the lowest performance. The results indicate that the
performance of the storage system is indeed very bursty and fairly random. Figure 1(c) and (d)
shows the performance snapshot of 100 storage devices. Although most of the storage devices
oﬀer similar throughput, there are a number of outliers that are signiﬁcantly slower. Here we
list the reasons that the I/O variability is still unsolved: First, the load balancing mechanisms
on HPC systems are very rudimentary. For example, on Lustre, the load balancing only comes
into play during the initial ﬁle placement stage. Once the striping parameters are determined
and ﬁles are created, there are no load balancing during ﬁle write. Second, there are no explicit
storage QoS mechanisms on most HPC systems today. It’s unclear to the HPC system designers
how to sustain the high parallelism on HPC systems, and achieve QoS in the complex storage
1 https://www.olcf.ornl.gov/titan/
2 http://www.nersc.gov/systems/hopper-cray-xe6/

2

16

15

10

20

4060
Runs

80

(a) storage device #0
(Titan)

100

8

8

5

5

12

12

10

10

16

14

15

0

20

4060

Runs

80

(b) storage device #0
(Hopper)

100

6

Throughput (LQMB/sec)

20

Liu, et. al.

20

18

20

25

0

Throughput (LQMB/sec)

30

Throughput (LQMB/sec)

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

StoreRush
Throughput (LQMB/sec)

	

0

20

80
40
60
Storage Device

(c) storage device
#0-#99(Titan)

100

4
0

20

80
4060
Storage Device

100

(d) storage device
#0-#99(Hopper)

Figure 1: performance of storage devices on Lustre ﬁle system (version 2.8.0)

environment that may involve distributed entities. On all leadership class HPC systems that
the authors are aware of, e.g., Titan, Mira, there are no storage QoS mechanisms in place.
The main driver behind this work is that I/O interference has been signiﬁcantly impacting
HPC application performance. The reason is that the majority of scientiﬁc codes require tight
synchronization, in which processes need to synchronize at some point during the calculation
in order to get to a coherent state and prepare for the next iteration of calculations. With
hotspots in the storage system, each process progresses diﬀerently in time and, at some point
during the run, a fast process has to wait for other processes. As a result, the overall I/O
performance is impacted by the slowest process.

3

Harvesting Idle Storage at the Application Level

StoreRush attempts to harvest idle storage by re-directing I/O traﬃc to less loaded storage
locations, thereby reducing the amount of data being written to congested devices. The core
component of I/O re-routing is a virtual messaging layer that serves to disseminate storage state
to each process that participates in I/O. Each process is attached to this messaging layer and
is notiﬁed and re-directed to a new target if its current target becomes heavily congested. On
the other hand, if a target has accepted too much new traﬃc, the messaging layer is responsible
for forwarding a request to another location.

3.1

Virtual Messaging Layer (VML)

Figure 2 illustrates the overall architecture of the messaging layer. Here a group represents a
set of processes that share a common initial storage target location to write (e.g., P4 , P5 , P6
and P7 sharing SD1 ). This target may change when the ensuing I/O re-routing happens. In
this case, the re-routed process will leave its original group and join a new group where the
I/O load is expected to be lighter. VML uses a group-based two-level control framework to
facilitate message exchange. To enable messaging between groups, a global coordinator (GC)
is selected for all groups and a sub-coordinator (SC) is selected to arbitrate the messaging
between the SC and the individual process (P ). The reason for the two-level design is to make
the communication layer more scalable and to avoid having a single entity handle messages
directly from every process, which otherwise would greatly limit the scalability. Implementation
wise, SC/GC can be a process or a pthread launched alongside applications, which allows an
application and VML to run concurrently so that the execution of one doesn’t block the other.
For the convenience of discussion, a process is denoted as Pi where 0 < i < N and N is the
total number of processes. The number of storage devices is M and, without loss of generality,
we also assume N is multiple of M . Therefore the number of processes that each group has
is N/M and hence, for group Gi , the initial process set it contains is [PN/M ·i , PN/M ·(i+1)−1 ].
The SCi is the sub-coordinator for group Gi , which manages exclusively the i-th storage device
3

477

478	

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

StoreRush

 # "
# 
	 # 	


 # 

!




(




)




*

	


+





"
!

(

'

'

Liu, et. al.

)

*

&

'

(

)
+

	&

	'

	(

	)

	*

	+

	,

	-

	.

	/

	'&

	''

	'(

	')

	'*

	'+

 
&

'

(

)

&

'

(

)

Figure 2: StoreRush messaging layer

SDi . The one-to-one mapping between SCi and SDi assumed here is for the convenience of
discussion and in general an SC can write to any SD. Note SCi can be attached to one of the
processes in the group, e.g., PN/M ·i , and GC can be attached to one of the SCs.

3.2

Harvesting Idle Storage via Re-Routing

The StoreRush runtime involves both intra- and inter-group messages to facilitate I/O scheduling. Intra-group messages occur only within a group Gi orchestrated by SCi . Its main functionality is to provide admission control and re-direction to an individual process and update
GC about its status (busy or idle). Before a process can start issuing I/O requests, it must ﬁrst
ask for permission by sending W RIT E SU BM ISSION to its SCi . If there are outstanding
requests at SDi being processed, the permission message is held oﬀ. Otherwise, a DO W RIT E
message is sent to the client process and the I/O operation proceeds. In the case of re-direction,
a remote SCj in group j will issue DO W RIT E to redirect a process to write to SDj .
Inter-group messages are exchanged between two groups, e.g.,Gi and Gj , facilitated by SCi ,
SCj and GC. The StoreRush runtime utilizes this level of messages to discover an idle group
and a busy group and then to oﬄoad tasks from one to another. The I/O re-routing phase is
jumpstarted by SCi issuing W RIT E IDLE message to GC, indicating group Gi (and hence
SDi ) has ﬁnished all its I/O tasks and is in idle state. This only occurs when all pending
processes within Gi ﬁnish writing. GC is a central controller which keeps track of the busy/idle
state of all storage locations and upon receiving a W RIT E IDLE message, GC updates the
state of Gi to idle and searches for a group Gj that is in the busy state. If group Gj is found,
GC then initiates the re-routing process via sending REROU T E REQ to SCj to request
oﬄoading portion of its I/O load. When this request is acknowledged by REROU T E ACK,
GC constructs a W RIT E M ORE message with its payload carrying the re-routed process ID,
Pk , to SCi and re-directs process Pk to write to the new storage device via DO W RIT E. If
REROU T E REJECT is received, for example, due to requests have been oﬄoaded to other
groups as a result of race condition, a new REROU T E REQ will be constructed and sent out
to another group that is busy until all groups are idle. At this point, the re-routing phase is
ended and no group is in idle state. The process of re-routing will start again when there is
a new idle group emerged. When all I/O requests are ﬁnished (i.e., when ﬁle is closed), VML
will be de-attached from each process and then released. An example of the messaging ﬂow is
illustrated in Figure 2.
4

	

StoreRush

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

Liu, et. al.

The StoreRush runtime is aggressive in the sense that it places a large burden on a fast
storage device, and the result is that a varying amount of data is written to each storage device,
depending on the degree of imbalance experienced. This is problematic for data that will be
read back in the future (i.e., post-run processing) when the hotspots may disappear or transition
to a diﬀerent pattern. The overly aggressive nature of re-routing can cause a secondary load
imbalance for reading in terms of data size, i.e., some storage devices have signiﬁcantly more
data to read than the others. To address this, we apply a throttling technique that can limit
how much data is allowed to be re-routed during writing, thus avoiding the hotspots while
lessening the impact of re-routing on read performance. To achieve this, we introduce the
notion of throttling factor (TF) for each SC, which is deﬁned as the ratio of the amount of
data re-routed to the associated group versus the amount of data that originally belonged to
the group and has been written (i.e., local data). For each storage device, TF essentially limits
the size of new I/O requests that can be accepted inbound by an SC. If the current ratio
is no greater than TF, the re-routed request will be granted. Otherwise, the storage device
is considered to have accommodated too many re-routed requests and new requests will be
rejected. In that case GC will look for the next idle SC to help those slow SCs.

3.3

Analytical Modeling of Throttling Factor

An important question of adding throttling to re-routing is how much traﬃc we want to throttle.
This section addresses the question of how to determine the best TF value using a simplistic
analytical model. Although in reality, it is impractical to have a priori knowledge about the
pattern of interference, which aﬀects the value of throttling factor, this section aims to gain
a theoretical understanding of the relationships between the intensity of interference and TF.
Here we leverage the fact that with re-routing, a slow and fast process will approximately ﬁnish
at the same time. Otherwise, more requests will be routed from the slow process. Suppose
the number of interfering processes is Nnoise and the number of storage devices that are under
noise is Mnoise . In the context of this paper, all other processes on the system that compete
for storage resources are deﬁned as interfering processes. Without losing generality, we assume
Nnoise
competing
SD0 to SDMnoise −1 are the ones injected with noise. Therefore there are M
noise
noise streams on each of the interfered storage devices. To simplify the model, we also assume
that noise is continuously streamed into the system and each data block has the same size as the
application requests. The application data block is denoted as Di and the bandwidth of storage
device is B. Without noise, each storage should ﬁnish within Ti = DBi seconds theoretically,
neglecting disk seek overhead. After noise is injected, interfered storage should complete within
Nnoise
Nnoise
Ti = DBi · ( M
+ 1) seconds, 0 ≤ i < M
. If re-routing is enabled, each storage should have
noise
noise
equal or similar timing as a result of oﬄoading, because a slow storage device would continue
to oﬄoad until it catches up with the fast ones. Suppose a slow storage device, SDj , oﬄoads
Dout,j , 0 ≤ j < Mnoise , and a fast device receives Din,i , Mnoise ≤ i < M . Those SDs under
noise should complete I/O at the same time. Therefore,
Di − Dout,i Nnoise
+ 1) =
·(
B
Mnoise

Dj − Dout,j
Nnoise
+ 1),
·(
B
Mnoise

which reduces to
Di − Dout,i = Dj − Dout,j , where 0 ≤ i, j < Mnoise

(1)
5

479

480	

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

StoreRush

Liu, et. al.

Similarly, those SDs that receive re-routed traﬃc should also complete at the same time.
Di + Din,i
=
B

Dj + Din,j
B

which reduces to
Di + Din,i = Dj + Din,j , where Mnoise ≤ i, j < M

(2)

Furthermore, SDs under noise should ﬁnish at the same time as SDs without noise.
Di − Dout,i Nnoise
Dj + Din,j
·(
+ 1) =
B
Mnoise
B

which reduces to
(Di − Dout,i ) · (

Nnoise
+ 1) = Dj + Din,j , where 0 ≤ i < Mnoise , Mnoise ≤ j < M
Mnoise

(3)

Finally the amount of data being oﬄoaded from the slow SDs should equal the amount that
fast SDs receive.
Mnoise
M
 −1

Dout,i =
Din,i
(4)
i=0

i=Mnoise

(1) (2) (3) (4) form a system of linear equations and there are M unknowns with M indeD
. Now for the special case that every process writes equal
pendent equations and T Fi = Din,i
i
amount of data, i.e.,
Di = Dj = D, i �= j
(5)
the system of equations is

(D − Dout,i ) · (

Dout,i = Dout,j , where 0 ≤ i, j < Mnoise

(6)

Din,i = Din,j , where Mnoise ≤ i, j < M

(7)

Nnoise
+ 1) = D + Din,j , where 0 ≤ i < Mnoise , Mnoise ≤ j < M
Mnoise
Mnoise · Dout,0 = (M − Mnoise ) · Din,Mnoise

(8)
(9)

Solving (6) - (9), we have
T Fi =

Nnoise
Din,i
=
Nnoise
−Mnoise
D
Mnoise · (( M
+ 1) · ( MM
) + 1)
noise
noise

(10)

Next in Section 4.3, we will examine the analytical model against the experiment results for
synthetic benchmark and Pixie3D, where the assumption in equation (5) holds. For the heavy
interference setup in this paper, we have Nnoise = 64, Mnoise = 4, M = 16, T Fi = 0.31. And
for the light interference, we have Nnoise = 16, Mnoise = 1, M = 16, T Fi = 0.06.
6

	

StoreRush

4

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

Liu, et. al.

Evaluation

To gauge the eﬀectiveness of StoreRush, we collected measurements on two HPC systems: Titan
and Hopper. Titan is a Cray XK7 machine and has 18,688 compute nodes. Each compute node
contains 16-core 2.2GHz AMD Opteron processes and NIVIDIA GPUs. Each node has 2GB
DDR3 memory per core, and a Gemini inter-connect. We ran applications on Titan Lustre
ﬁle system (version 2.8.0), which has 1,008 storage devices. Hopper is a Cray XE6 machine
and has 6,384 compute nodes each consisting of two twelve-core AMD MagnyCours 2.1 GHz
processors, with 2GB DDR3 memory per core. We conducted the Hopper runs on the Lustre
directory named SCRATCH, which has a total of 156 storage devices. For those runs that have
manual noise injected, by default 16 MB data blocks are continuously written to the ﬁle system,
unless otherwise noted. For the results using StoreRush, TF is set to 0.1 by default. We tested
two simple noise settings: heavy interference and light interference. For heavy interference,
Nnoise = 64, Mnoise = 4. For light interference, Nnoise = 16, Mnoise = 1. By default, each data
point is the average of 20 measurements collected, unless otherwise noted. We ran four sets
of tests: a synthetic benchmark, Pixie3D (kernel) [1], fusion XGC13 (production application)
and QMCPack4 (production application): 1) The synthetic benchmark used in our tests is a
simple MPI-based parallel code that writes and reads conﬁgurable sized data per process, with
no computation involved. 2) Pixie3D is a large Magneto-Hydro-Dynamic (MHD) code that
solves extended MHD equations using fully implicit Newton-Krylov algorithms. The output
from Pixie3D contains eight double-precision 3D cubes, with each sized 32 × 32 × 32. 3) XGC1
is a gyrokinetic particle-in-cell code that simulates the development of an edge pedestal in
the radial density and temperature proﬁles of tokamak fusion plasmas. In general, XGC I/O
outputs both checkpoint and analysis data, with checkpoint period (sml restart write period)
set to 10 timesteps, and analysis output period (diag 3d period) set to 5 timesteps (2 MB
ﬁeld data and 2 KB 2D diagnosis output). 4) QMCPack is a many-body ab initio Quantum
Monte Carlo code for computing the electronic structures. It can be used to perform both
Variational Monte Carlo (VMC) and Diﬀusion Monte Carlo (DMC) simulations. QMCPack
runs are scaled up using weak-scaling, and there are two key parameters: steps, which is the
total number of simulation steps, and blocks, which is the number of VMC/DMC blocks. In
VMC runs, we dump out two 10 × 256 × 3 single-precision ﬂoating point variables from each
process, momentum, and position. In DMC runs, the size of the variables is 531 × 256 × 3.

4.1

Write Performance

Figure 3 shows a set of runs conducted during production windows, in which interference are
stochastic. Figure 3(a) shows the benchmark performance observed during a 2-hour production
window on Titan and Hopper. The static I/O and StoreRush runs were interleaved to achieve
maximum fairness. Here StoreRush yields a much lower variance versus the static I/O (28
versus 16136.29 on Hopper), as well as a lower average I/O time (8.47 secs vs 41.42 secs on
Hopper). Figure 3(c)-(g) similarly shows Pixie3D, XGC1 and QMCPack runs respectively.

4.2

Impact of TF to Write and Read

In Figure 4(a) and (b), we further evaluate the sensitivity of I/O performance with regard to
TF. For Pixie3D runs (Figure 4(b)) the static I/O exhibits a much longer I/O time, particularly
under heavy interference, 290 secs vs. 125 secs of StoreRush, a 57% improvement with TF set
3 http://theorycodes.pppl.wikispaces.net/XGC1
4 http://www.qmcpack.org/

7

481

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

StoreRush

Liu, et. al.

to 0.2. We observed that under light interference, a small TF (i.e., TF=0.1) is suﬃcient to get
the most out of re-routing. Meanwhile, under heavy interference, a relatively larger TF (i.e.,
TF=0.2) is needed to allow a higher percentage of traﬃc being re-routed. This behavior, that a
relatively small TF is suﬃcient to achieve a large performance margin, can be attributed to the
observation that a large fraction of storage devices perform well and only a small percentage
are stragglers, as observed in Figure 1. A low TF is suﬃcient in re-routing the stragglers to fast
storage devices - if one storage device exceeds TF and can’t take more traﬃc, GC can ﬁnd the
next available fast storage devices. However, with the intensity of interference getting stronger,
increasing TF can further lower the I/O time because the speed gap is wider and a larger TF
allows more traﬃc to be rerouted.

13
12
11
0

50

100
150
RunV

200

6

(a) Synthetic (Titan)

20

40

60
RunV

80

5

10
15
RuQV

20

0

25

10

20
RunV

30

(d) Pixie3D (Hopper)
88

Static I/O
6WRUH5XVK

78

6WRUH5XVK



0

(c) Pixie3D (Titan)

Static,2

1

8

12

100

(b) Synthetic (Hopper)



,2WLPHLQVHFV

12

13

2

Static
6WRUH5XVK

14

14

4

0

250

16

Static
6WRUH5XVK

15

I/O Time (LQsecV)

14

Static
6WRUH5XVK

8

I/O Time (LQsecV)

10

Static
6WRUH5XVK

Static I/O
6WRUH5XVK

84

,27WLPHVHFV

15

I/O Time (LQsecV)

I/O Time (sec)

16

74



80

70



76

66
0

         
&KHFNSRLQW,'

5

72

10 15 20 25 30 35 40 45 50
VMC output ID

(f ) VMC I/O
(blocks=50,steps=100,
Titan)

(e) XGC1 (Titan)

0

5

10 15 20 25 30 35 40 45 50
DMC output ID

(g) DMC I/O
(blocks=50,steps=100,
Titan)

Figure 3: Runs performed during production windows




4









	
 

(a) Synthetic (write)

4
3
2

2



1
0

	
 

5

10
Run

0

15

(c) Synthetic (read)

(b) Pixie3D (write)

Static
6WRUH5XVK (TF=0.1)
6WRUH5XVK (TF=0.2)
6WRUH5XVK (TF=0.4)

5

3





Static
6WRUH5XVK (TF=0.1)
6WRUH5XVK (TF=0.2)
6WRUH5XVK (TF=0.4)

5

I/O Time (sec)

	



6WRUH5XVK
6WRUH5XVK

I/O Time (sec)


6WRUH5XVK
 6WRUH5XVK
6WRUH5XVK




 6WRUH5XVK

5

10
Run

15

(d) Pixie3D (read)

Figure 4: Impact of TF

Light Inteference
(Nnoise=16, Mnoise=1, 2MB/write)

15
14
13

$QDO\WLFDO%HVW

12
11

32
30
28
26
24
22
20
18

85

6WRUH5XVK (Experimental)
Heavy Inteference
(Nnoise=64, Mnoise=4, 2 MB/write)

16
14

Analytical Best

12
0

0.02

0.04

0.06
TF

(a) Synthetic (Light)

0.08

0.1

105

6WRUH5XVK (Experimental)

84
83

Light Inteference
(Nnoise=16, Mnoise=1, 256KB/write)

82
81

$QDO\WLFDO%HVW

80

Total I/O Time (secs)

16

Total I/O Time (secs)

6WRUH5XVK (Experimental)

17

Total I/O Time (secs)

18

Total I/O Time (secs)

482	

79
0

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

Heavy Inteference
(Nnoise=64, Mnoise=4, 256 KB/write)

95
90
85

$QDO\WLFDO%HVW

80
75

0

0.02

0.04

0.06

TF

(b) Synthetic (Heavy)

6WRUH5XVK(Experimental)

100

0.08

0.1

TF

(c) Pixie3D (Light)

0.12

0.14

0.16

0

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

TF

(d) Pixie3D (Heavy)

Figure 5: I/O time vs. TF

Figure 4(c) and (d) shows the time of reading the data previously generated under heavy
interference. For benchmark runs, we read the entire datasets that were written previously, i.e.,
mimicking the checkpoint/restart case. For Pixie3D, we extract the 8-th cube from the output
data, i.e., post-processing data retrieval. The read time here shows a tiered separation among
8

	

StoreRush

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

Liu, et. al.

curves with diﬀerent TF values. Although the static I/O is ineﬃcient for write performance in
the presence of interference, it does yield the best performance for reading, as data is evenly
distributed across storage devices. As TF increases, the read time also increases. To achieve
a balance between write and read, one needs to set a relatively small TF (Section 3.3) so that
re-routing can come into play with minimal impact to read.

4.3

Analytical vs. Experimental Results of TF

Figure 5 evaluates the ﬁdelity of the analytical model. The data here show the experimental
results of I/O times with regard to diﬀerent TF as well as the optimal value of TF calculated
from equation (10). For the benchmark runs, to make the assumption in equation (5) valid, i.e.,
that every process writes equal amount of data, the size of data blocks of injected interference
is decreased to 2 MB to match the block size of the synthetic benchmark. It is evident that
the optimal value of TF calculated from the analytical model approximates the experimental
results well. For the Pixie3D runs, the light/heavy interference was adjusted to 256 KB/write
to match the size of Pixie3D 32 × 32 × 32 cube, to make the model assumption valid. In Figure
5(c) and (d), the model-predicted TF yields an error that is below 0.4% for light interference
and 0.6% for heavy interference.

5

Related Work

In the HPC domain, I/O contentions have demonstrated to be at a whole new level simply due
to the level of currency available. With over hundreds of thousands cores available on a HPC
system, the likelihood that two clients compete for the same storage resource is fairly high. The
earlier work [7, 8] made a number of measurements on a few large HPC machines during their
production runs and showed contentions can lead to serious I/O performance degradation in the
system. The prior work on the I/O variability [8] tackled the problem by ﬁrst looking at write
optimization only using a simplistic approach. The design of it doesn’t allow for re-routing, and
more importantly traﬃc throttling is not possible using this approach. Moreover, the proposed
technique uses a single execution thread for both application write and communication on
coordinator and sub-coordinator processes. This entire design limits how eﬀectively and quickly
a coordinator can respond to storage load dynamics, and for light workload, e.g., Pixie3D
small (section 4(b) in [8]), I/O requests cannot be processed responsively, thus adaptive I/O
performance in this case is on par with non-adaptive I/O. This lowers the adaptability of the
system in general when I/O hotspots are present. Very recently, researchers used server-side
scheduling to address the problem [3]. While being quite eﬀective, only small scale has been
looked at so far and it is unclear whether they will work as eﬃciently at larger scale, such as
leadership class (100,000+ cores) being considered in the paper. Work by Gainaru et. al. [3]
leverages application past behaviors to tackle the congestion. However, for exploratory science
where application patterns change, its eﬀectiveness may be limited. In contrast, our work
considers interference as a black box and doesn’t assume that application patterns are known a
priori. Dorier et. al. [2] proposed CALCioM API which allows an application to nicely inform
its I/O intention so that contentions can be managed. Overall the work requires all applications
on a system be CALCioM-compliant in order to be eﬀective, which is impractical in general,
and the added communication overhead between all applications is unclear.
There are also work being done in non-HPC areas using scheduling to reduce contentions
[4, 6]. The most relevant work is BASIL [4], an online storage management system that automatically performs virtual disk placement and load balancing across storage devices. BASIL
formulated sampling-based empirical models to facilitate virtual machine migrations between
9

483

484	

StoreRush

Qing Liu et al. / Procedia Computer Science 108C (2017) 475–484

Liu, et. al.

devices to balance load. Pesto [6], a similar work using enhanced empirical models to schedule
workload, resolved a few unsolved challenges in BASIL, for example the model sensitivity to
workloads. The time scale considered here is relatively large as frequent VM migrations incur high overhead and service disruptions. In addition, explicit QoS scheduling [5] is another
strategy that has gained much tractions over the years.

6

Conclusion

This paper proposes a novel application level approach, StoreRush, to harvesting idle storage on
HPC storage. We adopt a balanced client-assisted re-routing + throttling approach to alleviate
the contention and a theoretical model to guide the setting of throttling factor (TF). This
work tackles two key challenges that haven’t been fully resolved in the past: how to design an
application layer runtime to schedule I/O so that the ﬁle system is not required to be modiﬁed,
and how to design a scheduling system that can scale up to a large amount of cores. The
performance results indicate that the scheme works well, e.g., achieving 1.8x improvement in
write and scaling up to 131,072 cores, for benchmarks as well as production applications on
leadership class systems.

Acknowledgement
This work is supported by the U.S. Department of Energy Advanced Scientiﬁc Computing
Research, Oak Ridge Leadership Computing Facility, and National Energy Research Scientiﬁc
Computing Center.

References
[1] Chacon, L. A non-staggered, conservative, , ﬁnite-volume scheme for 3d implicit extended magnetohydrodynamics in curvilinear geometries. Computer Physics Communications 163, 3 (2004),
143 – 171.
[2] Dorier, M., Antoniu, G., Ross, R., Kimpe, D., and Ibrahim, S. Calciom: Mitigating i/o
interference in hpc systems through cross-application coordination. In IEEE International Parallel
and Distributed Processing Symposium (May 2014), pp. 155–164.
[3] Gainaru, A., and et. al. Scheduling the i/o of hpc applications under congestion. In IEEE
International Parallel and Distributed Processing Symposium, IPDPS’15 (2015).
[4] Gulati, A., Kumar, C., Ahmad, I., and Kumar, K. Basil: automated io load balancing across
storage devices. In Proceedings of the 8th USENIX conference on File and storage technologies
(2010), FAST’10, pp. 13–13.
[5] Gulati, A., Merchant, A., and Varman, P. J. pclock: an arrival curve based approach for qos
guarantees in shared storage systems. In Proceedings of the 2007 ACM SIGMETRICS international
conference on Measurement and modeling of computer systems, SIGMETRICS ’07, pp. 13–24.
[6] Gulati, A., Shanmuganathan, G., Ahmad, I., Waldspurger, C., and Uysal, M. Pesto:
online storage performance management in virtualized datacenters. In Proceedings of the 2nd ACM
Symposium on Cloud Computing (2011), SOCC ’11, pp. 19:1–19:14.
[7] Liu, Q., Podhorszki, N., Logan, J., and Klasky, S. Runtime I/O Re-Routing + Throttling
on HPC Storage. In Proceedings of the 5th USENIX workshop on Hot Topics in Storage and File
Systems (2013), HotStorage’13, pp. 4–4.
[8] Lofstead, J., and et. al. Managing variability in the io performance of petascale storage systems.
In SC ’10: Proceedings of the Conference on High Performance Computing Networking, Storage and
Analysis.

10

