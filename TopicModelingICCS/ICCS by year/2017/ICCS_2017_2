Available online at www.sciencedirect.com

ScienceDirect
Procedia Computer Science 108C (2017) 1552–1561

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

3D
3D Drape
Drape Reconstruction
Reconstruction and
and Parameterization
Parameterization Based
Based
on
Smartphone
Video
and
Elliptical
Fourier
Analysis
3D
Drape Reconstruction
Parameterization
Based
on Smartphone
Video andand
Elliptical
Fourier Analysis
on Smartphone
Video and Elliptical Fourier Analysis
Ge Wu11, Zhicai Yu11, Azmat Hussain11, Yueqi Zhong1,1, 22 **
Ge Wu , 1Zhicai
Yu , Azmat Hussain , Yueqi Zhong
Donghua University, Shanghai 201620, China
1 1Donghua University,
1
1, 2 *
Shanghai
201620,
China
of Textile
Science
Technology,
Ministry
of
Education,
GeLab
Wu
, Zhicai
Yu1and
, Azmat
Hussain
, Yueqi
ZhongChina

2
2Key

Key Lab of Textile
Science and Technology, Ministry of Education, China
1
Donghua University, Shanghai 201620, China
Key Lab of Textile Science and Technology, Ministry of Education, China
Abstract:
Abstract:
In this paper, 3D fabric drape was reconstructed by using video recorded from a smartphone. Elliptical
In
this paper,
3D (EFA)
fabric drape
was reconstructed
using video
recorded
fromtoa parameterize
smartphone. Elliptical
Fourier
Analysis
and Principle
ComponentbyAnalysis
(PCA)
were used
the 3D
Abstract:
Fourier
Analysis
(EFA)
and
Principle
Component
Analysis
(PCA)
were
used
to
parameterize
the
3D
drape
reveal3D
shape
parameters.
cluster analysis
of various
drapesfrom
was implemented
verify
In
thistopaper,
fabric
drape was A
reconstructed
by using
video3D
recorded
a smartphone.toElliptical
drape
to
reveal
shape
parameters.
A
cluster
analysis
of
various
3D
drapes
was
implemented
to
verify
the proposed
method.
Experiment
results
demonstrated
that (PCA)
the 3D were
drapeused
can to
be parameterize
reconstructedthe
and3D
Fourier
Analysis
(EFA)
and Principle
Component
Analysis
the
proposed method.
Experiment
results
demonstrated
that the 3D
drape of
canEFA
be reconstructed
and
parameterized
with
a
mean
error
of
0.52
mm
when
the
harmonic
number
equals
to
25.
The
drape to reveal shape parameters. A cluster analysis of various 3D drapes was implemented to verify
parameterized
with a mean
errornew
of 0.52
mmdetected
when thebyharmonic
number
EFA to
equals
to 25.
The
cluster
result indicated
that the
features
our the
method
wereof
useful
classify
different
the
proposed
method. Experiment
results
demonstrated
that
3D drape
can
be reconstructed
and
cluster
that
the new
features
detected
by our method were useful to classify different
drapes, result
whichindicated
provided
a novel
for 3D
parameterized
with a mean
erroridea
of 0.52
mmdrape
whenanalysis.
the harmonic number of EFA equals to 25. The
drapes, which provided a novel idea for 3D drape analysis.
cluster
result
indicated
that the
new features
detected by our method were useful to classify different
©
2017 Thefabric
Authors.
Published
by Elsevier
B.V.
Keywords:
drape,
smartphone,
3Dfor
reconstruction,
EFA, clustering
drapes,
which
provided
a
novel
idea
3D
drape
analysis.
Peer-review
under drape,
responsibility
of the 3D
scientific
committee
of theclustering
International Conference on Computational Science
Keywords: fabric
smartphone,
reconstruction,
EFA,
2

Keywords: fabric drape, smartphone, 3D reconstruction, EFA, clustering

1
1 Introduction
Introduction
Drape
is a significant aesthetic indicator of textiles. It refers to the 3D deformation of fabrics
1 Drape
Introduction
[1]
[2]
is a significant aesthetic
indicator of textiles. It refers to the 3D deformation
of fabrics

arising from their own weight[1]and affects garment appearance quality profoundly. [2] Measuring and
affects
garment
appearancethings
quality profoundly.
Measuring
and
arising
from their ownbehavior
weight isand
predicting
one
of the
most
important
field which
to
Drape isthea drape
significant aesthetic
indicator
of
textiles.
It refers to in
thetextile
3D deformation
ofhelps
fabrics
]
predicting
the
drape
behavior
of
the
most
important
things
in
textile
field
[1]is[ 3one
[2] which helps to
In practice,
drape
is usually
assessed
visually and
the actual
clothingfrom
design
garment
appearance
quality
profoundly.
Measuring
and
arising
theirand
ownproduction.
weight and
[ 3 ] affects
In practice,
drapeasisfashion,
usuallyhuman
assessed
visually etc.
andTotheinterpret
actual
clothing
design
and
production.
assessment
greatly
depends
uponis different
factors
perception,
predicting
the
drape
behavior
one of the
mostsuch
important things
in textile
field which
helps to
assessment
greatly
depends
upon
different
factors
such
as
fashion,
human
perception,
etc.
To
interpret
]
drape quantitatively,
of works[ 3have
donedrape
to findisanusually
efficient,
accuratevisually
and reliable
method
to
In been
practice,
assessed
and the
actual
clothing
design and lots
production.
drape
quantitatively,
lots ofInworks
have
been
donethat
to find
an efficient,
accurate
and reliable
method to
reflect
the
drape
property.
1930,
Perice
found
the
draping
quality
of
a
fabric
had
a
significant
assessment greatly depends upon different factors such as fashion, human perception, etc. To interpret
reflect
theon
drape
property.length,
In 1930, Perice
found the
thatcantilever
the draping
quality
a fabric
had a significant
influence
the bending
developed
method
forofthe
measurement
of fabric
drape
quantitatively,
lots of worksand
have
been done
to find an efficient,
accurate
and reliable method
to
[4]
influence
on
the
bending
length,
and
developed
the
cantilever
method
for
the
measurement
of fabric
Chu
et
al.
developed
the
standard
F.R.L.
drape-meter
for
the
drape
measurement
bending
properties.
reflect the
drape property.
In
1930,
Perice
found
that
the
draping
quality
of
a
fabric
had
a
significant
[4]
Chu
et al. developed
the
standard
F.R.L. drape-meter
for the
measurement
bending
properties.
Based
on the
principle
of F.R.L,
Cusick
simple for
method
to drape
calculate
the
drape
in
1950.[5]
influence
the bending
length, and
developed
theintroduced
cantilever amethod
the measurement
of fabric
[5]on
[6] drape
Based
on
in
1950.
[4]the principle of F.R.L, Cusick introduced a simple method to calculate the
coefficient
(DC) and Chu
foundet that
it depended
both the
sheardrape-meter
stiffness and
length.
al. developed
theon
standard
F.R.L.
forbending
the drape
measurement
bending properties.
[6] These
These
coefficient
[5] (DC) and found that it depended on both the shear stiffness and bending length.
early
methods
were
consuming
high-skill
Based
on time
the principle
of and
F.R.L,
Cusickrequired.
introduced a simple method to calculate the drape
in 1950.
early
methods
were
time
consuming
and
high-skill
required.
[6]
With the(DC)
development
began
use image
processing
These
coefficient
and found of
thatphotography
it dependedtechniques,
on both theresearchers
shear stiffness
andtobending
length.
With thetodevelopment
of [7-9]
photography
techniques,
researchers
use of
image
processing
methods
involved
a camerabegan
and a to
beam
parallel
light to
technology
studytime
the drape.
early methods
were
consuming
and high-skill
required.
[7-9] These
These
methods
involved
a camera
and a beam of parallel
lightand
to
technology
to study the
capture
of drape.
theofdrape.
By means
of image
analysis,
the drape
such processing
as DC
Withthe
theprojection
development
photography
techniques,
researchers
beganproperties,
to use image
capture
the
projection
of
the
drape.
[7-9] By means of image analysis, the drape properties, such as DC and
node
number,
drape profile
image.
These
methodsand
tooka less
time
had light
a better
methods
involved
a camera
beam
of and
parallel
to
technology
to were
studycomputed
the drape.from These
node number,with
weremore
computed
from drape
profile
image.
These
methods
took less timejust
andbased
had a on
better
repeatability
However,
since
theyanalysis,
estimated
the
capture the projection
ofparameters.
the drape. By
means of
image
thedrape
drapeparameters
properties, such
as DC and
repeatability with more parameters. However, since they estimated drape parameters just based on the
node number, were computed from drape profile image. These methods took less time and had a better
*
author:more
zhyq@dhu.edu.cn
repeatability
parameters. However, since they estimated drape parameters just based on the
*Corresponding with
Corresponding author: zhyq@dhu.edu.cn

*

Corresponding author: zhyq@dhu.edu.cn

1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.057

	

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

top view, lots of the 3D information of the drape was lost. According to previous study, the drape can
be more effectively observed in the front views.[10] Hence, to better analyze and evaluate the fabric
properties, a 3D drape shape would contribute to collect more 3D drape parameters.
As an attempt to obtain the 3D shapes of real drapes, commercial 3D scanners were applied in some
previous researches. [12-12] There were mainly two shortages for these methods. The first one was that
since the 3D scanners were usually expensive and difficult to maintain, they were not widely available
and mainly used in research areas. The second one was that these methods relied on the traditional
drape parameters, which could not fully character the 3D shapes. For example, many fabrics have the
same DC and node number but they differ in the contour profile.[13]
Three works have been done in this paper. (1) A feasible method was proposed to perform the 3D
reconstruction of drapes using video captured by a smartphone. (2) EFA and PCA were applied to
parameterize the 3D drape and find more parameters for characterization. (3) A cluster analysis was
implemented for various drapes to verify the proposed method.

2 Materials & methods
2.1 Experiment materials

(1) Drape-meter: As shown in Figure 1(a), our self-made drape-meter is consisted of a colorful top
disk, a supporting disk and a pillar. The diameters of the disks were 12 cm, which were same to those
of the commercial one (XDP-1). To measure the 3D drape automatically, a 6cm×4cm checkerboard
was stuck to the center of the top disk. The fabric was placed centrally between the top and the
supporting disks in experiment, as shown in Figure 1(b).

(a)
(b)
Figure 1. Self-made drape-meter

(2) Smartphone: All the drape videos were captured by iPhone 6.
(3) Fabrics: As shown in Table 1, 4 common categories of fabrics were used to validate our method.
All the samples were conditioned at 65±2% relative humidity and 20±2°C temperature for 24 hours
before measuring to relieve localized stresses.
Fabric
group
Cotton
Flex
Silk
Wool

2.2 Methods

Table 1. Basic properties of sample fabrics
Yarn
Number of
Thickness
construction
samples
(mm)
Spun
11
0.44-0.60
Spun
11
0.46-0.83
Filament
11
0.15-0.41
Spun
11
0.33-0.81

Weight
(g/m2)
81-159
112-201
36-85
115-256

The pipeline of the proposed method is shown in Figure 2. Given a sequence of video frames, our
method began with feature extraction and matching to construct the tracks. Next, these tracks were

1553

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

1554	

processed using structure from motion (SFM)[14] to compute the locations of 3D points. Then, these
3D points were further processed to reconstruct a drape surface. After aligning the 3D shape, it was
converted to a group of ordered contours. Next, EFA[15] and PCA[16] were applied to parameterize the
contours into drape parameters, which can be used for further cluster analysis. The details involved are
introduced as follows.
Data
collection

Feature
matching

Feature
extraction

Cluster
analysis

PCA

Structure
from motion
EFA

Contour
computing

Figure 2. Pipeline of the proposed method

Surface
reconstruction
3D drape
aligning

2.2.1 3D reconstruction
(1) Data collection: To acquire sufficient data, the drape was videoed by moving the smartphone on
two elliptical paths, as shown in Figure 3. After that, the video was transferred into video frame
sequences at 4 fps. In practice, the time length of the video was 10 s, and the total number of video
frames was 40.

Figure 3. Data collection

(2) Feature extraction and matching: In most image-based 3D reconstruction, the 2D features were
mainly extracted using Scale-Invariant Feature Transformation[17] (SIFT) by considering its robustness
against image resolution, various viewpoints, self-occlusion and clutters.[18] However, SIFT features
were random and difficult to predict. To measure the drape automatically, Harris algorithm[19] was
jointly employed to extract the features in our case. The Harris corner detector is a standard algorithm
for corner detection in computer vision. As shown in Figure 4(a), the red star marks are SIFT features,
and the circle colorful marks are Harris features. After that, the feature matching was carried out
between images based on the nearest neighbor search [ 20 ]. This is a process tries to find
correspondences between images in order to compute the triangulation, as shown in Figure 4(b).

(a)
(b)
Figure 4. Feature extraction and matching: (a) Combined feature of SIFT and Harris (b) Feature matching

	

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

1555

(3) SFM algorithm: SFM was implemented to recover the 3D location for each feature matching. As
shown in Figure 5, the relationship between a 3D point Pw = [X, Y, Z] T and its image projection p = [u0,
v0] T is given by
(1)
p  K[ R|t ]Pw
where [R|t] is the extrinsic parameters which relates the world coordinate system to the camera
coordinate system. K is a constant intrinsic matrix. The relationship between the same feature points
extracted from different images is given by
(2)
p1T Fp 2  0
−T
−1
−T
−1
where 𝐹𝐹 = 𝐾𝐾 𝐸𝐸𝐾𝐾 = 𝐾𝐾 [𝑡𝑡]𝑅𝑅𝐾𝐾 is the fundamental matrix which includes intrinsic and extrinsic
parameters of the camera. Given the initial K, the extrinsic parameters of each image can be estimated
via RANSAC algorithm[21]. Then, all matches were combined into tracks to form a connected set of
key points across multiple images. Since K was an estimated value, the result was not accurate. To
improve its accuracy, Bundle Adjustment [22] was employed refining the intrinsic parameters. It can
minimize the re-projection error between the image locations of observed and predicted image points,
which is given by
min  ( ~xi j  K [ Ri | ti ] X j ) 2
(3)

~
xi j

i

j

is the observed 2D position of jth feature point in the ith image. K [ Ri | ti ] X
corresponding re-projection.

where

j

is its

Figure 5. Camera coordinate system and world coordinate system

(4) Surface reconstruction: The data calculated above consisted of scattered 3D points, which was
not convenient for observation. Ball-Pivoting Algorithm [23] was applied to construct the 3D drape
surface considering its relatively small amount of memory required and time efficiency. After that,
Hendrik’s method [24] was used to register and stitch textures acquired from images onto the surface of
the 3D drape, as shown in Figure 6.

(a) Scattered 3D points
(b) 3D drape surface
(c) Textured 3D drape
Figure 6. Process of surface reconstruction

2.2.2 Contours acquiring
(1) Drape aligning: To process the 3D drapes from the same direction, they should be aligned to
same coordinates. Since the 2D corners of the checkerboard could be detected by Harris algorithm,
their corresponding 3D corners could be indexed by equation (1). Thus, the aligning details are as
follows:

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

1556	

⃗⃗⃗⃗⃗⃗⃗⃗⃗
Step 1: Compute the normal vector of the disc plane as⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗
𝑂𝑂1 𝑃𝑃1 = ⃗⃗⃗⃗⃗⃗⃗⃗⃗
𝑂𝑂1 𝑝𝑝1 × 𝑂𝑂
1 𝑝𝑝2 .
Step 2: Transfer 𝑂𝑂1 to 𝑂𝑂0 and obtain the translation matrix 𝑇𝑇1 , as shown in Figure 7(a).
Step 3: Rotate ⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗
𝑂𝑂1 𝑃𝑃1 around 𝑌𝑌𝐷𝐷 axis clockwise until it coincides to plane 𝑌𝑌𝐷𝐷 𝑂𝑂𝑜𝑜 𝑍𝑍𝐷𝐷 , and obtain the
rotation matrix 𝑅𝑅1 .
Step 4: Rotate⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗
𝑂𝑂1 𝑃𝑃1 around 𝑋𝑋𝐷𝐷 axis clockwise until it coincides to axis 𝑂𝑂𝑜𝑜 𝑍𝑍𝐷𝐷 , and obtain the rotation
matrix 𝑅𝑅2 .
Step 5: Multiply the coordinates of the 3D drape with 𝑇𝑇1 × 𝑅𝑅1 × 𝑅𝑅2.
Step 6: Magnify the 3D drape by 1/𝑙𝑙 times, where l is the distance between the adjacent 3D corners,
as shown in Figure 7(b).
l

(a)

Figure 7．3D drape aligning

(b)

(2) Contours computing: Three basic functions are defined as follows:
P2D = f1 (P3D, Z): Project the 3D points of the drape (P3D) whose z<Z on 𝑋𝑋𝐷𝐷 𝑂𝑂𝑜𝑜 𝑌𝑌𝐷𝐷 plane, and
obtain a 2D points set P2D.
 C = f2 (P2D): Compute the contour C of P2D, which was implemented by:
Step 1: Convert each point (x, y) of P2D from Cartesian coordinates to polar coordinates, as shown in
Figure 8(b) and equation (4).
𝑥𝑥 = 𝜌𝜌cos𝜃𝜃; 𝑦𝑦 = 𝜌𝜌sin𝜃𝜃
(4)
Step 2: Calculate the contour C as (𝜃𝜃’, 𝜌𝜌(𝜃𝜃’)). 𝜃𝜃’ = arg max(𝜌𝜌(𝜃𝜃)), 𝜃𝜃 ∈ [−180°, 180°].
 V = f3 (C): Compute the vertexes of the contour C, which were the local maximums of 𝜌𝜌(𝜃𝜃’).
Thus, the contours of the 3D drape were computed as follows:
Step 1: Input zmax into f1 (P3D, Z) to compute P1 of the 3D drape, where zmax is the maximum of the 3D
drape on ZD axis, as shown in Figure 8(a).
Step 2: Compute the contour and vertexes of P1 as C0 = f2 (P1) and V0 = f3 (C0).
Step 3: Index V0 on ZD axis, and make their minimum as zmin, as shown in Figure 8(a).
Step 4: Initialize f1 by setting Z0 = 2 mm and repeat to compute Ci = f2 (f1 (P3D, Zi)), where Zi = Zi-1 +
𝑍𝑍min −𝑍𝑍0
(𝑖𝑖 − 1)，𝑖𝑖 = 1, … , 𝐾𝐾. In practice, K is set as 8 in this paper.
𝐾𝐾−1
Step 5: Set the Z values of C0 and Ci as the height of the pillar and Zi respectively. Thus, C0 and Ci
were the contours used to characterize the 3D drape.


XD

O0

XD

O
0

ZD

(a) Side view

YD

(b) Polar coordinates

(c) Top view of contours

Figure 8．Compute the contours of the 3D drape

	

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

2.2.3 Parameterization
(1) EFA: EFA was used to parameterize the contours of the 3D drape in our work. Compared to
other morphometric methods, such as finite element analysis and B-spline curve fitting, EFA can
describe any shape of contour accurately with a matrix, which is more suitable for statistical analysis.
The procedure of EFA involved representation of the (x, y) coordinate points on the 2D curve into a
form of a pair of equations written as a function of a third variable t by:
2𝑛𝑛π𝑡𝑡
2𝑛𝑛π𝑡𝑡
𝑥𝑥N (𝑡𝑡) = 𝐴𝐴0 + ∑𝑁𝑁
𝑛𝑛=1 𝑎𝑎𝑛𝑛 cos ( 𝑇𝑇 ) + 𝑏𝑏𝑛𝑛 sin( 𝑇𝑇 )
(5)
2𝑛𝑛π𝑡𝑡
2𝑛𝑛π𝑡𝑡
𝑦𝑦N (𝑡𝑡) = 𝐶𝐶0 + ∑𝑁𝑁
𝑛𝑛=1 𝑐𝑐𝑛𝑛 cos ( 𝑇𝑇 ) + 𝑑𝑑𝑛𝑛 sin( 𝑇𝑇 )
where N is the number of Fourier harmonics. t is the step required to move a unit pixel along the
contour. T is the basic period of the overall steps to traverse the entire contour. Thus, the contour can
be defined as a matrix 𝑬𝑬 = [𝑨𝑨𝟎𝟎 , 𝑪𝑪𝟎𝟎 , 𝒂𝒂𝟏𝟏 , 𝒃𝒃𝟏𝟏 , 𝒄𝒄𝟏𝟏 , 𝒅𝒅𝟏𝟏 ,…, 𝒂𝒂𝒏𝒏 , 𝒃𝒃𝒏𝒏 , 𝒄𝒄𝒏𝒏 , 𝒅𝒅𝒏𝒏 ]𝟏𝟏×(𝟒𝟒𝑵𝑵+𝟐𝟐) which is called the
Elliptic Fourier descriptors (EFDs).
It should be noted that EFA were implemented on 2D contours. To contain all 3D information of the
3D drape, we need to construct a matrix which includes the EFDs of all contours and their
corresponding locations on ZD axis. The procedure is as follows:
Step 1: Convert the drape contours 𝐶𝐶i to EFDs, which were denoted as 𝐸𝐸i , 𝑖𝑖 = 0,1 … 𝐾𝐾.
Step 2: Construct a matrix 𝑅𝑅 to represent the 3D drape with its 𝐸𝐸i and 𝑧𝑧i :
(6)
𝑅𝑅 = [𝐸𝐸1 , 𝑧𝑧1 , ⋯ , 𝐸𝐸K , 𝑧𝑧K ]1×(4N+3)K
where 𝑧𝑧i is the corresponding position of the contour on ZD axis. Then, construct another matrix M
using R of all the 3D drapes (the number is S):
(7)
𝑀𝑀 = [𝑅𝑅1 𝑇𝑇 , … , 𝑅𝑅S 𝑇𝑇 ]𝑇𝑇 (4N+3)K×S
(2) PCA: Since there were (4N+3)K columns in matrix M, which was too complex to find the main
drape parameters, PCA was used to reduce its dimension. In this method, so-called principal
components (PCs) are used to transform a set of interrelated variables into a set of uncorrelated
variables. These PCs are linear combinations of the original variables and are obtained in such a way
that the first PC explains the largest fraction of the original data variability. The second PC explains a
lesser fraction of the data variance than the first PC and so forth. In practice, the matrix M was reduced
to matrix 𝑀𝑀O which had k PCs. The PCs were namely the new drape parameters.
2.2.4 Cluster analysis
To verify our method, a cluster analysis was implemented for the 3D drapes using their PCs. This
cluster analysis was based on the average of the single linkage, which depended on minimum distance
and complete linkage which evaluated maximum distance. [ 25 ] The average linkage hierarchical
clustering method produces a very robust nested series of partitions and it can handle very large data
sets quite efficiently. [26] In average linkage clustering, the distance 𝑑𝑑(𝑟𝑟, 𝑠𝑠) between any two clusters, r
and s, is defined as the mean of distances between all pairs of objects, where each pair is made up of
𝑇𝑇
one object from each group. The 𝑑𝑑(𝑟𝑟, 𝑠𝑠) is computed as 𝑑𝑑(𝑟𝑟, 𝑠𝑠) = 𝑟𝑟𝑟𝑟 , where 𝑇𝑇𝑟𝑟𝑟𝑟 is the sum of all
𝑁𝑁𝑟𝑟 ×𝑁𝑁𝑠𝑠

pairwise distances between clusters r and s, 𝑁𝑁𝑟𝑟 and 𝑁𝑁𝑠𝑠 are the sizes of the clusters 𝑟𝑟 and 𝑠𝑠 respectively.
At each stage of clustering, the clusters r and s, for which 𝑑𝑑(𝑟𝑟, 𝑠𝑠) is a minimum, are merged.

3. Results and discussion
3.1 Reconstruction effect

Three drapes with various colors are presented as examples in Figure 9. The right plot of each group
is drape photo, the left one is the screenshot of the reconstructed drape. To facilitate the reconstruction,
we plotted some lines on the homochromous fabrics to increase their features.

1557

1558	

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

Figure 9. Reconstruction effects of the 3D drapes

3.2 Reconstruction accuracy

To validate the reconstruction accuracy, a commercial 3D scanner was used for comparing. As
shown in Figure 10(a), the drapes scanned by our method (S1) and by the 3D scanner (S2) were aligned
in terms of the Iterative Closet Points[27]. The error was defined as the Euclidean distance from points
on S1 to the closest point on S2. Different magnitudes of the error were coded using different colors. It
is obvious that the largest error between the two drapes is less than 4 mm. The histogram in Figure
10(b) shows that the mean error is 0.8 mm (SD=0.38 mm). Furthermore, almost 95.2% data has an
error less than 1.5 mm.

(a)
(b)
Figure 10. Errors between the reconstructed and the scanned drapes (unit: mm)

3.3 Comparison of the DCs
With the contours of the 3D drape, its DC can be computed as 𝐷𝐷𝐷𝐷 =

𝑆𝑆c
𝑆𝑆f

× 100%. 𝑆𝑆f is the area of the

fabric. 𝑆𝑆c is the area of the lowest contour. (𝑥𝑥𝑖𝑖 , 𝑦𝑦𝑖𝑖 ) is the ith points on the lowest contour(counterclockwise). When i=1, it is the start point with the maximum in X axis, as shown in Figure 11(a).
1
(8)
𝑆𝑆c = ∑𝑘𝑘𝑖𝑖=1(𝑥𝑥𝑖𝑖 𝑦𝑦𝑖𝑖+1 − 𝑥𝑥𝑖𝑖+1 𝑦𝑦𝑖𝑖 ), 𝑖𝑖 = 1,2, … , 𝑘𝑘
2
where k is the number of the points on the lowest contour.
To further validate the reconstruction accuracy, 15 drape samples were randomly selected and their
DCs were measured by our method and the commercial drape-meter XDP-1. As shown in Figure
11(b), their results are highly correlated and the correlation coefficient is 0.988.

(𝑥𝑥𝑖𝑖 , 𝑦𝑦𝑖𝑖 )

(𝑥𝑥1 , 𝑦𝑦1 )

(a)
(b)
Figure 11. Drape contours and correlation between results of standard and our methods.

	

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

3.4 Parameterization result

According to equation (5), the drape contours can be fitted with different harmonic number N. As
shown in Figure 12(a), the fitting errors between the fitted contours and their references decrease with
the increase of the harmonic number. In practice, the harmonic number was truncated at N = 25. The
mean error, the maximum error and the standard deviation was 0.52 mm, 1.69 mm and 1.12 mm
respectively. Since the mean error was smaller than the accuracy of our reconstructed method (0.8
mm), N=25 was good enough for our application. To determine k in PCA, we computed the
component variance of different PCs for the drape contours. As shown in Figure 12(b), with the
increase of the serial number (k) of the PC, its corresponding component variance decreases. To
maintain the majority of features of the 3D drape, the PCs of M were truncated at k = 15, where the
accumulated values reached 92%.
20

MEAN
MAX
SD

Error (mm)

15
10
5
0

0

5

10
15
20
25
Number of harmonic

30

35

(a)
(b)
Figure 12. Parameterization results: (a) Results of PCA for drape contours (b) Relationship between the fitting
errors and the harmonic number N.

3.5 Clustering result

Based on the cluster analysis, it is clear that there are 5 distinct groups, as shown in Figure 13.
These clusters comprise 25.0%, 31.8%, 11.4%, 27.3% and 4.5% of the subjects in cluster 1, 2, 3, 4 and
5 respectively. The statistics of the 3D drapes within different clusters are shown in Table 2. It is seen
that cluster 1 is predominantly the fabrics of low DC and low node number; cluster 2 is predominantly
the fabrics of low DC and high node number; cluster 3 is predominantly the fabrics of high DC and
high node number; cluster 4 is predominantly the fabrics of high DC and low node number; cluster 5
only have 2 special samples which have higher DCs and lower node numbers. Moreover, most of the
silk fabrics belong to cluster 2 due to their relative soft property. Most of the flex fabrics belong to
cluster 4 due to their relative rough property.

1559

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

1560	

Clusters
Cluster 1
Cluster 2
Cluster 3
Cluster 4
Cluster 5

Figure 13 Clustering result of the 3D drapes
Table 2. Statistics of the 3D drapes within different clusters
DC (%)
Node number (n) Cotton Flex Silk
(n)
(n)
(n)
Range
Median
Range Median
42.2~62.7
54.1
3~5
4
3
2
4
54.6~60.5
53.4
5~8
7
4
0
6
59.6~72.0
65.3
3~6
5
0
2
1
65.9~81.4
71.2
3~4
3
2
7
0
85.2, 87.4
3
3
2
0
0

Wool
(n)
2
4
2
3
0

4. Conclusion
In this paper, a new method was introduced to obtain 3D drapes using smartphone video. EFA and
PCA were combined to parameterize the 3D drape and reveal new drape parameters. The average
linkage hierarchical clustering method was applied to verify the effective of these parameters. Three
major conclusions were reached.
(1) A complete 3D drape can be generated accurately by the video collected by smartphone. In our
case, the drape may be reconstructed with a mean error of 0.8 mm, and almost 95.2% data had an error
less than 1.5 mm. The drape coefficient measured by 3D drape had a high correlation with the
traditional method.
(2) The 3D drape can be parameterized by using EFA methods accurately. The mean error, the
maximum error and the standard deviation was 0.52 mm, 1.69 mm and 1.12 mm respectively when the
harmonic numbers N = 25.
(3) The PCs of the drape contours could be used as drape parameters for statistical analysis.
Compared to traditional parameters, the drape parameters revealed by our method contained more 3D
information of the drape, which gave a new idea for 3D drape evaluation in the future.

Acknowledgment
This work is supported by Shanghai Natural Science Foundation (Grant No.14ZR1401100),
Natural Science Foundation of China (Grant No.61572124), Postgraduate Innovation Fund Projects of
Donghua University (CUSF-DH-D-2015013).

Reference
[1] Agrawal S A. Study Of Height Dependency Of Drape Parameters[J]. International Journal of
Engineering Research and Application, 2013, 3(5).
[2] Gersˇak J. Investigations of the impact of fabric mechanical properties on garment appearance[J].
Tekstil, 2003, 52(8): 368-379.
[3] Collier B J. Measurement of fabric drape and its relation to fabric mechanical properties and
subjective evaluation[J]. Clothing and Textiles Research Journal, 1991, 10(1): 46-52.
[4] Peirce F T. 26-The “handle” of cloth as a measurable quantity [J]. Journal of the Textile Institute
Transactions, 1930, 21(9): T377-T416.
[5] Chu C C, Cummings C L, Teixeira N A. Mechanics of elastic performance of textile materials Part
V: A study of the factors affecting the drape of fabrics—The development of a drape meter[J]. Textile
Research Journal, 1950, 20(8): 539-548.

	

Ge Wu et al. / Procedia Computer Science 108C (2017) 1552–1561

[ 6 ] Cusick G E. 46-THE DEPENDENCE OF FABRIC DRAPE ON BENDING AND SHEAR
STIFFNESS[J]. Journal of the Textile Institute Transactions, 1965, 56(11): T596-T606.
[ 7 ] Jeong Y J. A study of fabric-drape behaviour with image analysis part I: Measurement,
characterisation, and instability[J]. Journal of the Textile Institute, 1998, 89(1): 59-69.
[ 8 ] Behera B K, Mishra R. Objective measurement of fabric appearance using digital image
processing[J]. Journal of the Textile Institute, 2006, 97(2): 147-153.
[9] Tsai K H, Tsai M C, Wang P N, et al. New approach to directly acquiringe the drape contours of
various fabrics[J]. Fibres & Textiles in Eastern Europe, 2009.
[ 10 ] Thilagavathi G, Natarajan V. Development of a method for measurement of fabric threedimensional drape and studies on influencing factors[J]. Indian Journal of Fibre and Textile Research,
2003, 28: 41-49.
[11] Shen Y, Zhou H, Yin H. Model ZYF-3 fabric-drape three-dimensional tester[J]. Journal of
Textile Research, 2008, 29(1): 118.
[12] Farajikhah S, Madanipour K, Saharkhiz S, et al. Shadow Moiré aided 3-D reconstruction of fabric
drape[J]. Fibers and Polymers, 2012, 13(7): 928-935.
[13] Gnanavel P, Ananthakrishnan T. Development of a Three Dimensional Approach to Acquire a
Drape Contour and Studies on Influential Factors[J]. Issues, 2016.
[14] Agarwal S, Snavely N, Simon I, et al. Building rome in a day[C]//2009 IEEE 12th international
conference on computer vision. IEEE, 2009: 72-79.
[15] Kuhl F P, Giardina C R. Elliptic Fourier features of a closed contour[J]. Computer graphics and
image processing, 1982, 18(3): 236-258.
[ 16 ] Abdi H, Williams L J. Principal component analysis[J]. Wiley Interdisciplinary Reviews:
Computational Statistics, 2010, 2(4): 433-459.
[17] Lowe D G. Object recognition from local scale-invariant features[C]//Computer vision, 1999. The
proceedings of the seventh IEEE international conference on. IEEE, 1999, 2: 1150-1157.
[18] Park U, Jain A K. 3D model-based face recognition in video[C]//International Conference on
Biometrics. Springer Berlin Heidelberg, 2007: 1085-1094.
[ 19 ] Goldfarb D, Reid J K. A practicable steepest-edge simplex algorithm[J]. Mathematical
Programming, 1977, 12(1): 361-371.
[20] Yianilos P N. Data structures and algorithms for nearest neighbor search in general metric
spaces[C]//SODA. 1993, 93(194): 311-21.
[21] Derpanis K G. Overview of the RANSAC Algorithm[J]. Image Rochester NY, 2010, 4(1): 2-3.
[ 22 ] Triggs B, McLauchlan P F, Hartley R I, et al. Bundle adjustment-a modern synthesis[C]
//International workshop on vision algorithms. Springer Berlin Heidelberg, 1999: 298-372.
[ 23 ] Bernardini F, Mittleman J, Rushmeier H, et al. The ball-pivoting algorithm for surface
reconstruction[J]. IEEE transactions on visualization and computer graphics, 1999, 5(4): 349-359.
[24] Lensch H P A, Heidrich W, Seidel H P. Automated texture registration and stitching for real
world models[C]//Computer Graphics and Applications, 2000. Proceedings. The Eighth Pacific
Conference on. IEEE, 2000: 317-452.
[25 ] Sa’Ed M S. A methodology to redesign heterogeneous product portfolios as homogeneous
product families[J]. Computer-Aided Design, 2007, 39(12): 1065-1074.
[26] Sarle W S. Finding Groups in Data: An Introduction to Cluster Analysis[J]. Journal of the
American Statistical Association, 1991, 86(415): 830-833.
[ 27 ] Besl P J, McKay N D. Method for registration of 3-D shapes[C]//Robotics-DL tentative.
International Society for Optics and Photonics, 1992: 586-606.

1561

