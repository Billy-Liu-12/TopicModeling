Available online at www.sciencedirect.com

ScienceDirect

This space is reserved for the Procedia header, do not use it
This Procedia
space isComputer
reserved
for 108C
the Procedia
header, do not use it
Science
(2017) 2323–2327
This space is reserved for the Procedia header, do not use it
This space is reserved for the Procedia header, do not use it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Curvature-Based
Curvature-Based Feature
Feature Detection
Detection for
for Head
Head Modeling
Modeling
Curvature-Based
Feature Petr
Detection
for
Head
Modeling
Martin
Martı́nek,
and
Ivana
Curvature-Based
Feature Petr
Detection
Modeling
Martin Prantl,
Prantl, Věra
Věra Skorkovská,
Skorkovská,
Martı́nek,for
andHead
Ivana Kolingerová
Kolingerová
Martin
Prantl,of
Věra
Skorkovská,
Martı́nek,
andof
Ivana
Department
Computer
Science andPetr
Engineering,
Faculty
AppliedKolingerová
Sciences,
Department
Computer
Science andPetr
Engineering,
Faculty
AppliedKolingerová
Sciences,
Martin
Prantl,ofof
Věra
Martı́nek,
andofCzech
Ivana
University
WestSkorkovská,
Bohemia, Univerzitnı́
8, 306 14, Plzeň,
Republic
UniversityofofComputer
West Bohemia,
8, 306 14,
Plzeň,ofCzech
Republic
Department
ScienceUniverzitnı́
and
Engineering,
Faculty
Applied
Sciences,
{perry, vskorkov,
petrm,
kolinger}@kiv.zcu.cz
{perry,
vskorkov,
petrm,
kolinger}@kiv.zcu.cz
Department
of
Computer
Science
and
Engineering,
Faculty
of
Applied
Sciences,
University of West Bohemia, Univerzitnı́ 8, 306 14, Plzeň, Czech Republic
University {perry,
of West Bohemia,
Univerzitnı́
8, 306 14, Plzeň, Czech Republic
vskorkov,
petrm, kolinger}@kiv.zcu.cz
{perry, vskorkov, petrm, kolinger}@kiv.zcu.cz

Abstract
Abstract
In the field of 3D head modeling and animation, feature points are often needed to mark
In
the field of 3D head modeling and animation, feature points are often needed to mark
Abstract
important regions of the face and can be used to animate or deform the input model. However,
important
the face
and can be animation,
used to animate
or deform
the
input
Abstract
In
fieldregions
ofdetection
3Dofhead
feature
pointsThis
are paper
often model.
needed However,
toa mark
an the
automatic
ofmodeling
features and
remains a challenging
task.
presents
novel
an
automatic
detection
of
features
remains
a
challenging
task.
This
paper
presents
novel
In
the
field
of
3D
head
modeling
and
animation,
feature
points
are
often
needed However,
toa mark
important
regions
of
the
face
and
can
be
used
to
animate
or
deform
the
input
model.
approach to feature detection based on curvature and its derived descriptors, such as shape
approach
to
feature
detection
based
on
curvature
and
its
derived
descriptors,
such
as
shape
important
regions
of
the
face
and
can
be
used
to
animate
or
deform
the
input
model.
However,
an
automatic
detection
of features
remains
challenging
task. regions
This paper
presentsusing
a novel
index,
curvedness
and Willmore
energy.
Fouraimportant
feature
are detected
the
index,
curvedness
anddetection
Willmore
energy.
Four
feature
regions
are detected
using
the
an
automatic
detection
of features
remains
aimportant
challenging
task.
This
paper
presents
a shape
novel
approach
to
feature
based
on
curvature
and
its
derived
descriptors,
such
as
proposed approach - eyes, nose, mouth, ears. For each region, feature points are detected.
proposed
approach
eyes,
nose,
mouth,
ears.
For
each
region,
feature
points
are
detected.
approach
to
feature
detection
based
on
curvature
and
its
derived
descriptors,
such
as
shape
index,
Willmore
energy.
important
feature regions
arefordetected
Resultscurvedness
show that and
the feature
points
are Four
detected
with sufficient
accuracy
further using
use. the
Results
show
that and
the
feature
points
are Four
detected
with
sufficient
accuracy
fordetected
further
use. the
index,
curvedness
Willmore
energy.
feature
proposed
approach
- eyes,
nose,
mouth,
ears.important
For
each
region,regions
featureare
points
are using
detected.
Keywords:
feature
detection,
head
modeling,
deformations
proposed
approach
eyes,
nose,
mouth,
ears.
For
each
region,
feature
points
are
detected.
©
2017 The
Authors.
Published
by
Elsevier
B.V.
Results
show
thatdetection,
the feature
points
are detected
with sufficient accuracy for further use.
Keywords:
feature
head
modeling,
deformations
Peer-review
underthat
responsibility
of thepoints
scientific
committee
of the
International
Computational
Science
Results show
the feature
are
detected
with
sufficientConference
accuracyonfor
further use.
Keywords: feature detection, head modeling, deformations
Keywords: feature detection, head modeling, deformations

1
1 Introduction
Introduction
1
Introduction
3D models
of faces have been widely used in many areas of computer graphics. The models
3D models
of faces have been widely used in many areas of computer graphics. The models
1
can beIntroduction
created manually in a modeling software or obtained by 3D scanners. However, these

can
be created
manually
in a modeling
software
or obtained
by 3D scanners.
However,models
these
3D
models
of faces
used
in additional
many
areas
of computer
graphics.
models
are static
andhave
needbeen
to bewidely
equipped
with
properties
if they
are to beThe
modified or
models
are
static
andhave
needbeen
toabemodeling
equipped
with
properties
if scanners.
they
are toHowever,
beThe
modified
or
3D models
of faces
widely
used
in additional
many
areas
of computer
graphics.
models
can
be
created
manually
in
software
or
obtained
by
3D
these
animated. A common approach to face modeling is based on feature detection. Once detected,
animated.
A
common
approach
to face modeling
is
on feature
Once
detected,
can be are
created
manually
in
abemodeling
software
or based
obtained
by 3Difdetection.
scanners.
However,
these
models
static
and
need
to
equipped
with
additional
properties
they
are
to
be
modified
or
these areas or points can be further used to edit the model and achieve the desired output.
these
areas
orcommon
points
can
bebe
further
used
to edit
the
model
and achieve
thetodesired
output.
models
are A
static
and need
to
equipped
with
additional
properties
ifdetection.
they are
be modified
or
animated.
approach
to
face
modeling
is
based
on
feature
Once
detected,
For human beings, the task to detect features is quite simple and straightforward. However, to
For
human
thecan
taskbetofurther
detect
features
is
quite
simple
and
straightforward.
However,
to
animated.
Abeings,
common
approach
to face
modeling
isthe
based
on feature
detection.
Once
detected,
these
areas
or
points
used
to
edit
model
and
achieve
the
desired
output.
detect the features automatically can be a challenging task.
detect
the features
automatically
can features
be a challenging
task.
thesehuman
areas
or points
can
betofurther
used
to is
edit
thesimple
modeland
andstraightforward.
achieve the desired
output.
For
beings,
the
task
detect
quite
However,
to
One of the most important points to detect is the tip of the nose. Szeptycki et al. [8] detect
One
of the
mostthe
important
points
to
detect
the tip
of the
nose.
Szeptycki et al.
[8] detect
For
human
beings,
task to detect
features
isisquite
simple
and
straightforward.
However,
to
detect
the
features
automatically
can
be
a
challenging
task.
candidate points in 2.5D data by curvature-derived descriptors. Support vector machine (SVM)
candidate
points
in automatically
2.5D
data by
curvature-derived
descriptors.
Support
vector machine
(SVM)
detect
the
features
can to
be detect
a challenging
task.
One
of
the
most
important
points
is
the
tip
of
the
nose.
Szeptycki
et
al.
[8]
detect
classification from trained data is used to detect the correct nose tip from candidates. Yang et
classification
data
iscurvature-derived
usedtotodetect
detectis the
nose
tip from
candidates.
et
One of thefrom
mosttrained
important
points
the correct
tip of the
nose.
Szeptycki
et al. [8]Yang
detect
candidate
2.5D
data
by
Support
vector
machine
(SVM)
al. [10] usepoints
a list ofincandidates
as well.
Filters based descriptors.
on local structures
and
principal
component
al.
[10]
use
a
list
of
candidates
as
well.
Filters
based
on
local
structures
and
principal
component
candidate
points
in 2.5D data
byiscurvature-derived
descriptors.
Support
vector
machineYang
(SVM)
classification
from
used
detect the
correct nose
tip from
candidates.
et
analysis (PCA)
aretrained
used todata
reject
false to
results.
analysis
(PCA)
are
used todata
reject
falseFilters
results.
classification
from
trained
iswell.
used
to
detect
theoncorrect
nose tip from
candidates.
Yang et
al. [10]
use
a
list
of
candidates
as
based
local
structures
and
principal
component
Global solutions are designed to find more feature points at once. Moreno et al. [6] use signs
Global
solutions
are designed
tofalse
find
morebased
feature
at once. Moreno
et al. [6]
use signs
al.
[10]
use
a list are
of candidates
as well.
Filters
onpoints
local structures
and principal
component
analysis
(PCA)
used
to reject
results.
of principal
curvatures
and
a user-defined
threshold. Colbry et al. [1] use a shape index and
of
principal
curvatures
and
a
user-defined
threshold.
Colbry
et
al.
[1]
use
a
shape
index
and
analysis
(PCA)
are useddesigned
to rejecttofalse
results.
Global
solutions
find
more the
feature
points
at once.
Moreno
al. [6]
signs
thresholding.
In theare
faces oriented
towards
camera
some
feature
pointsetcan
be use
detected
thresholding.
In
the
faces
oriented
towards
the
camera
some
feature
points
can
be
detected
Global solutions
are designed
to find more
feature points
at once.
Moreno
al. [6]index
use signs
of
principal
curvatures
a user-defined
Colbry
al. [1]
use
a etshape
and
easier,
e.g., the
nose is and
the point
closest tothreshold.
the camera.
Theiretmethod
is capable
of handling
easier,
e.g., the
nose
is
the oriented
point
closest
tothreshold.
the
camera.
Their
method
is capable
ofindex
handling
of
principal
curvatures
and
a user-defined
Colbry
etfeature
al. [1] points
use
a shape
and
thresholding.
In
the
faces
towards
the
camera
some
can
be
detected
small rotation of approx. ±15 . Gilani et al. [2] created a solution for the detection of arbitrary
small
rotation
of
approx.
±15
. Gilani
et to
al. the
[2]
for the
detection
of
arbitrary
thresholding.
Innose
the is
faces
oriented
towards
thecreated
cameraa solution
some feature
points
can be
detected
easier,
e.g.,
the
the
point
closest
camera.
Their
method
is
capable
of
handling
points. They use the reference model with predefined points. They create geodesic curves
points.rotation
They
use
theis reference
model
predefined
They
geodesic
curves
easier,
e.g.,
theof
nose
the
point
closest
to
camera.a points.
Their method
isdetection
capable
handling
small
approx.
±15
. Gilani
etwith
al. the
[2]
created
solution
for thecreate
of arbitrary
small
±15 . Gilani
al. [2]
created a points.
solution They
for thecreate
detection
of arbitrary
points.rotation
They of
useapprox.
the reference
modeletwith
predefined
geodesic
curves
points. They use the reference model with predefined points. They create geodesic curves11
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.105

1
1

2324	

Curvature-Based Feature Detection
Prantl,
Skorkovská,
Martin Prantl et al. / Procedia Computer
Science
108C (2017)Martı́nek
2323–2327and Kolingerová

together with a cost function. A morphed model is created and the predefined points are
transferred from the reference model to the current one.
The aim of this paper is to automatically detect features on triangulated models of human
heads for the approach proposed by Martı́nek and Kolingerová [5]. To the best of our knowledge,
the state-of-the-art algorithms are either designed to find only certain feature points of faces
(instead of entire heads) or require training data to be able to find arbitrary features. The
proposed solution is based solely on shapes and ratios between important feature points. The
proposed solution can also detect feature regions in one processing pass.

2

Proposed Solution

In the presented solution, we expect the nose tip (Pnose ) to be pointing in a positive direction
of z-axis and the top of the head Ptop in a positive direction of y-axis. The positive x-axis is
referred to as the right side of the head (and vice versa). The entire head is scaled to the size
1 × 1 × 1, without the shape deformation. All distances and sizes in the following text are scaled
accordingly. A prerequisite is an axis-aligned triangulated model. The symmetry axis (Sipiran
et al. [7]) and Pnose detected with Yang et al. [10] is used to obtain the correct position.
At every vertex Vi , we have to estimate curvatures (see [9]) and curvature-based descriptors,
e.g. mean (KH ) and Gaussian (KG ) curvature, Shape Index (S), Curvedness (C) and Willmore
energy (W ) (see [3] and [4]). To overcome the scale, the descriptors values are linearly mapped
to the interval 0, 1. To reduce the influence of noise, all descriptors are averaged within an
Euclidean neighborhood of the size 0.01.
The solution consist of three phases: detection of main feature points (Pnose , Ptop , Pchin );
detection of feature areas; detection of remaining feature points. The order of detection is
mandatory: Pnose , Ptop , Pchin , eyes, nose, mouth and ears. The already detected parts are
used to improve the detection of the next ones. Pnose is detected with Yang et al. [10], Ptop
has the maximal y-coordinate. Pchin is one of the points within a cone that is centered at
Pnose and facing in negative y-axis. From all the points that satisfy this condition, Pchin is a
point in a spherical neighborhood (radius 0.6) with the maximal distance from Pnose and the
biggest z-coordinate.
The detection of feature areas is described in detail in following subsections. Number N of
the chosen points in the areas depends on the model resolution.

2.1

Eyes

An approximation of the eye regions positions has been set to 60% of the Euclidean distance
between Pnose and Ptop . From the vertices that satisfy this condition, the candidate vertices Vi
have a spherical neighborhood, so their Willmore energy Wi should be minimal. The measure
of resemblance to eyes MEi is calculated as follows:
MEi = Wi |Pnose − Vi |.

(1)

The first N points with the lowest value of MEi belong to the eye regions. The left and right
eye region can be easily distinguished based on the value of the x-coordinate.
The required feature points can be seen in Figure 1. Eye corners E1 and E2 are found as
the points with extremal values in the x-axis. Eyelid points E3 to E6 are selected as the points
with the minimal difference in the x-coordinate from two auxiliary points A1 and A2 (inserted
in equidistant positions to the line segment connecting E1 and E2 ).
2

	

Curvature-Based Feature Detection
Prantl,
Skorkovská,
and Kolingerová
Martin Prantl et al. / Procedia Computer
Science
108C (2017)Martı́nek
2323–2327

N6

E3
E1

A1

E5

N5

E4
A2

E6

E2

N4

N3

N2

R2

N8

N7

R1

R5

M3
M1

M2
R3

M4

N1

R4

Figure 1: Feature points of eye, nose, mouth and ear

2.2

Nose

The feature region is represented by a strip of points located above Pnose with a width set
to 5% of head width in the x-axis. All the vertices Vi within this strip are assigned with the
measure of resemblance to nose MNi :
MNi = Si Ci ,

(2)

where Si stands for the shape index and Ci is the curvedness at the vertex Vi . The first N
points with the smallest value of MNi belong to the nose region.
The feature points (see N1 to N8 in Figure 1) can be extracted. The point N2 = Pnose .
The position of N4 can be predicted (Ppred ) as a center point between the two inner eye corners
(see previous section). For a more precise detection, the measure of resemblance to nose root
MN Ri is calculated for each vertex Vi from the nose feature region:
MN Ri = Si Ci |Ppred − Vi |.

(3)

The distance from Ppred is used to prevent finding points that are located too far away. N4 is
the point with the minimal value of MN Ri .
N3 is the point with the minimal distance from the average of N2 and N4 . N1 has to be
located under N2 , so only a thin strip (width 0.004 in the x-coordinate) of points has to be
searched. To find the correct position of the point N1 , the measure of resemblance to MN B i is
calculated for each vertex Vi from the predefined strip of points:
MN B i =

K Hi
,
di

(4)

where KHi is mean curvature at the vertex Vi and di is the distance between the vertex Vi
and Pnose in the z-coordinate. The distance division is used to reject far points whose mean
curvature is similar to required points. N1 is the point with the maximal value of MN B i .
N5 to N8 (see Figure 1) are localized with KH and the distance from N3 or N4 . The
measure of resemblance to the side point is calculated for each vertex Vi with the Equation 4.
In this case, di is the distance between the vertex Vi and the corresponding feature point (N3
for the detection of N5 and N7 ; N4 for N6 and N8 ).
N3 and N4 are two points with the maximal value calculated from Equation 4. To prevent
finding points on the same side of the nose, the x-coordinate of the detected points is compared
to the x-coordinate of the corresponding feature point.
3

2325

2326	

Curvature-Based Feature Detection
Prantl,
Skorkovská,
Martin Prantl et al. / Procedia Computer
Science
108C (2017)Martı́nek
2323–2327and Kolingerová

2.3

Mouth

The mouth area is detected differently. Four feature points are used (Figure 1). Mouth corners
are detected with Willmore energy. Also, the points must be under Pnose and above Pchin
in the y-coordinate. M3 and M4 are detected as the points with the maximal position in
the z-coordinate and are also the closest to the average of M1 and M2 . The points are
distinguished based on the comparison of the y-coordinate. From the detected points, an axisaligned bounding box (AABB) is created to detect the mouth area.

2.4

Ears

An ear is detected based on its helix with the maximal curvedness and is has also the most
distant points in x-axis from the eye corners. For the left ear, the right eye inner corner is used
(and vice versa). The final weight MRi is calculated for each vertex Vi as:
MRi = Ci |VXi − Ex |,

(5)

where Ex is the x-coordinate of the corresponding eye corner, Ci is the curvedness at the vertex
Vi , and VXi is the x-coordinate of the vertex Vi . The first N points with the maximal value of
MRi belong to the ear region.
To detect the feature points of the ear (see Figure 1), an AABB enclosing the ear feature
region is used. The points R1 to R4 are detected as the closest points to the corresponding
corners of the outer side of the AABB. The point R5 has the minimal distance from the
average of R1 to R4 .

3

Experiments and Results

For the tests, head models created using a 3D modeling software are used. This is due to the
further use of the points for deformations, that can be utilized for example in computer games.
The comparison with an existing state-of-the-art methods cannot be directly conducted.
Existing methods are mostly based on anatomical properties or they detect only certain points,
such as nose. The proposed feature points are based on the deformations used in [5]. The
presented results compare the automatically detected points with the manually selected ones.
Similar to [1], the proposed method is capable of handling a small deviation from the axisaligned state (approx. ±10 ). This is in the limit of the error produced by the alignment
method described in Section 2.
To verify the results of the proposed solution, the results of the proposed algorithm are
compared with the points manually placed by an expert user. The results are captured in
Figure 2. It can be seen that the positions of the detected and the manually inserted points
slightly differ. The intended use of the detected points is for the use in the deformation-based
modeling, therefore the accuracy of the detection is sufficient. The detected feature regions
based on the vertices, which belong to them, are also shown (see Figure 2).

4

Conclusions

A method for feature detection on triangulated models of the entire heads was proposed. It
can be used to automatically locate the areas of interest and feature points, thus eliminating
the need to define them manually. The detection does not require any training data and is easy
4

	

Curvature-Based Feature Detection
Prantl,
Skorkovská,
and Kolingerová
Martin Prantl et al. / Procedia Computer
Science
108C (2017)Martı́nek
2323–2327

Figure 2: Comparison of manually inserted (first sub-image) and automatically detected (second
sub-image) feature points. Detected feature regions are shown in a third and fourth sub-image.

to implement. The algorithm uses only curvature and curvature-based descriptors, smoothed
over a certain neighborhood to improve the precision in the case of a noisy input model. The
input model is expected to be a face without deep wrinkles that can be incorrectly mistaken
for certain areas due to their high curvature. We would like to take a deeper look into this
limitation in a future research.

Acknowledgements
This work has been supported by the project SGS-2016-013 - Advanced Graphical and Computing Systems. We thank J. Dvořák and L. Hruda for the implementation of [7].

References
[1] D. Colbry, G. Stockman, and A. Jain. Detection of anchor points for 3d face veri.cation. In
Computer Vision and Pattern Recognition (CVPR) - Workshops, pages 118–118, 6 2005.
[2] S. Z. Gilani, F. Shafait, and A. Mian. Shape-based automatic detection of a large number of 3d
facial landmarks. In Computer Vision and Pattern Recognition (CVPR), pages 4639–4648, 6 2015.
[3] J. J. Koenderink and A. J. van Doorn. Surface shape and curvature scales. Image and Vision
Computing, 10(8):557 – 564, 1992.
[4] E. Kuwert and R. Schätzle. Willmore functional, pages 1–115. Edizioni della Normale, Pisa, 2012.
[5] P. Martı́nek and I. Kolingerová. Deformation method for 3d identikit creation. In Computer
Graphics Theory and Applications (GRAPP), pages 1–8. IEEE, 2014.
[6] A. B. Moreno, Á. Sánchez, J. Vélez, and J. Dı́az. Face recognition using 3d surface-extracted
descriptors. In In Irish Machine Vision and Image Processing Conference (IMVIP 2003), 2003.
[7] I. Sipiran, R. Gregor, and T. Schreck. Approximate symmetry detection in partial 3d meshes.
Computer Graphics Forum, 33(7):131–140, 2014.
[8] P. Szeptycki, M. Ardabilian, and L. Chen. Nose tip localization on 2.5d facial models using
differential geometry based point signatures and svm classifier. In Biometrics Special Interest
Group (BIOSIG), 2012 BIOSIG, pages 1–12, 9 2012.
[9] L. Váša, P. Vaněček, M. Prantl, V. Skorkovská, P. Martı́nek, and I. Kolingerová. Mesh Statistics
for Robust Curvature Estimation. Computer Graphics Forum, 35(5):271–280, 2016.
[10] J. Yang, Z. W. Liao, and Z. D. Wu. A method for robust nose tip location across pose variety in
3d face data. In 2009 International Asia Conference on Informatics in Control, Automation and
Robotics, pages 114–117, 2 2009.

5

2327

