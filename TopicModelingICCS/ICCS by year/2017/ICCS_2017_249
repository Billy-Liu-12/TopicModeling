Available online at www.sciencedirect.com

ScienceDirect
This
This
This
This

space
is Computer
reservedScience
for the
Procedia
header,
Procedia
108C
(2017) 119–128
space
space is
is reserved
reserved for
for the
the Procedia
Procedia header,
header,
space is reserved for the Procedia header,

do
do
do
do

not
not
not
not

use
use
use
use

it
it
it
it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Spectral Modes of Network Dynamics Reveal Increased
Spectral
Modes
Dynamics
Reveal
Increased
Spectral
Modes of
of Network
Network
Dynamics
Reveal
Increased
Informational
Complexity
Near
Criticality
Spectral
Modes of Network
Dynamics
Reveal
Increased
Informational
Complexity
Near
Criticality
Informational
Complexity
Near
Criticality
Xerxes D.Informational
Arsiwalla1 , Pedro Complexity
A.M. Mediano2 ,Near
and Paul
F.M.J. Verschure1,3
Criticality
1,3
Xerxes D. Arsiwalla11 , Pedro A.M. Mediano22 , and Paul F.M.J. Verschure1,3
Xerxes
D. Arsiwalla , Pedro A.M. Mediano , and Paul F.M.J. Verschure
1
Synthetic Perceptive Emotive
and Cognitive Systems2 (SPECS) Lab, Center of Autonomous
1
1,3
1
Xerxes
D.
Arsiwalla
, Pedro
Mediano
,(SPECS)
and
Paul
F.M.J.
Verschure
Perceptive
Emotive
andA.M.
Cognitive
Systems
Lab,
CenterSpain.
of
Autonomous
1 Synthetic
Systems
and Neurorobotics,
Universitat
Pompeu
Fabra,
Barcelona,
1

Synthetic Perceptive Emotive and Cognitive Systems (SPECS) Lab, Center of Autonomous
Systems
and
Neurorobotics,
Universitat
Pompeu
Fabra,
Barcelona,
Spain.
x.d.arsiwalla@gmail.com
Systems
and
Neurorobotics,
Universitat
Pompeu
Fabra, Lab,
Barcelona,
Synthetic
Perceptive
Emotive and Cognitive
Systems
(SPECS)
CenterSpain.
of Autonomous
2
Department x.d.arsiwalla@gmail.com
of
Computing,
Imperial
College
London.
x.d.arsiwalla@gmail.com
Systems and
Neurorobotics,
Universitat
Pompeu
Fabra,
Barcelona,
Spain.
2
3
of
London.
2 Department
Institució Catalana
de Recerca
i Estudis Imperial
AvançatsCollege
(ICREA),
Barcelona, Spain.
Department
of Computing,
Computing,
Imperial
College
London.
x.d.arsiwalla@gmail.com
3
3 Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain.
2
Institució Catalana
de
Recerca
i
Estudis
Avançats
(ICREA),
Barcelona, Spain.
Department of Computing, Imperial College London.
3

Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain.

Abstract
Abstract
What
does the informational complexity of dynamical networked systems tell us about intrinAbstract
What
does
of
networked
systems
us
intrinsic
mechanisms
and functions complexity
of these complex
systems?
Recent complexity
as
What
does the
the informational
informational
complexity
of dynamical
dynamical
networked
systems tell
tellmeasures
us about
aboutsuch
intrinAbstract
sic
mechanisms
and
functions
of
these
complex
systems?
Recent
complexity
measures
such
as
integrated
information
have
sought
to
operationalize
this
problem
taking
a
whole-versus-parts
sic
mechanisms
and
functions
of
these
complex
systems?
Recent
complexity
measures
such
as
What does the informational complexity of dynamical networked systems tell us about intrinintegrated
information
have
sought
to
operationalize
this
problem
taking
a
whole-versus-parts
perspective,
wherein
one
explicitly
computes
the
amount
of
information
generated
by
a
netintegrated
information
have
sought
to
operationalize
this
problem
taking
a
whole-versus-parts
sic mechanisms and functions of these complex systems? Recent complexity measures such as
perspective,
wherein
one
explicitly
computes
the
amount
of
information
generated
by
work
as a whole
over and
above
thatto
generated
by the
sumproblem
parts
during
state transitions.
perspective,
wherein
one
explicitly
computes
the
amount
of its
information
by aa netnetintegrated
information
have
sought
operationalize
this
taking
agenerated
whole-versus-parts
work
as
a
whole
over
and
above
that
generated
by
the
sum
of
its
parts
during
state
transitions.
While
several
numerical
schemes
for
estimating
network
integrated
information
exist,
it
is
inwork
as
a
whole
over
and
above
that
generated
by
the
sum
of
its
parts
during
state
transitions.
perspective, wherein one explicitly computes the amount of information generated by a netWhile
several
numerical
schemes
for
estimating
network
integrated
information
exist,
it
is
instructive
to
pursue
an
analytic
approach
that
computes
integrated
information
as
a
function
of
While
several
numerical
schemes
for
estimating
network
integrated
information
exist,
it
is
inwork as a whole over and above that generated by the sum of its parts during state transitions.
structive
to
pursue
an
analytic
approach
that
computes
integrated
information
as
a
function
of
network
weights.
Our
formulation
of
integrated
information
uses
a
Kullback-Leibler
divergence
structive
to
pursue
an
analytic
approach
that
computes
integrated
information
as
a
function
of
While several numerical schemes for estimating network integrated information exist, it is innetwork
weights.
Our
formulation
of
integrated
information
uses
a
Kullback-Leibler
divergence
between
the
multi-variate
distribution
on
the
set
of
network
states
versus
the
corresponding
network
weights.
Our
formulation
of
integrated
information
uses
a
Kullback-Leibler
divergence
structive to pursue an analytic approach that computes integrated information as a function of
between
the
multi-variate
on
of
network
states
versus
the
factorized
distribution
overdistribution
its parts.
Implementing
Gaussian
dynamics,
we
perform
between
the
multi-variate
distribution
on the
the set
set
ofstochastic
network
states
versus
the corresponding
corresponding
network weights.
Our formulation
of integrated
information
uses
a Kullback-Leibler
divergence
factorized
distribution
over
its
parts.
Implementing
stochastic
Gaussian
dynamics,
we
perform
computations
for
several
prototypical
network
topologies.
Our
findings
show
increased
informafactorized
distribution
over
its
parts.
Implementing
stochastic
Gaussian
dynamics,
we
perform
between the multi-variate distribution on the set of network states versus the corresponding
computations
for
several
prototypical
network
topologies.
Our
findings
show
increased
informational
complexity
near
criticality,
which
remains
consistent
across
network
topologies.
Spectral
computations
for
several
prototypical
network
topologies.
Our
findings
show
increased
informafactorized distribution over its parts. Implementing stochastic Gaussian dynamics, we perform
tional
complexity
near
criticality,
which
remains
consistent
across
network
topologies.
Spectral
decomposition
of several
the
dynamics
reveals
how informational
complexity
is governed
by
tional
complexity
nearsystem’s
criticality,
which
remains
consistent
across
network
Spectral
computations
for
prototypical
network
topologies.
Our
findings
showtopologies.
increased
informadecomposition
of
the
system’s
dynamics
reveals
how
informational
complexity
is
governed
by
eigenmodes
of
both,
the
network’s
covariance
and
adjacency
matrices.
We
find
that
as
the
decomposition
of
the
system’s
dynamics
reveals
how
informational
complexity
is
governed
by
tional complexity near criticality, which remains consistent across network topologies. Spectral
eigenmodes
of
both,
the
network’s
covariance
and
adjacency
matrices.
We
find
that
as
the
dynamics
of
the
system
approach
criticality,
high
integrated
information
is
exclusively
driven
eigenmodes
of
both,
the
network’s
covariance
and
adjacency
matrices.
We
find
that
as
the
decomposition of the system’s dynamics reveals how informational complexity is governed by
dynamics
of
the
system
approachtocriticality,
high
integrated
information
is
exclusively
driven
by
the eigenmode
corresponding
the
leading
eigenvalue
of the
covariance
while
subdynamics
of of
theboth,
system
high
integrated
information
is matrix,
exclusively
driven
eigenmodes
theapproach
network’scriticality,
covariance
and
adjacency
matrices.
We
find that
as
the
by
the
eigenmode
corresponding
to
the
leading
eigenvalue
of
the
covariance
matrix,
while
subleading
modes
get
suppressed.
The
implication
of
this
result
is
that
it
might
be
favorable
for
by
the
eigenmode
corresponding
to
the
leading
eigenvalue
of
the
covariance
matrix,
while
subdynamics of the system approach criticality, high integrated information is exclusively driven
leading
modes
get
suppressed.
The
implication
of
this
result
is
that
it
might
be
favorable
for
complex
dynamical
networked
systems
such
as
the
human
brain
or
communication
systems
to
leading
modes
get
suppressed.
The
implication
of
this
result
is
that
it
might
be
favorable
for
by the eigenmode corresponding to the leading eigenvalue of the covariance matrix, while subcomplex
dynamical
networked
systems
such
as
the
human
brain
or
communication
systems
to
operate
near
criticality
so
that
efficient
information
integration
might
be
achieved.
complex
dynamical
networked
systems
such
as
the
human
brain
or
communication
systems
to
leading modes get suppressed. The implication of this result is that it might be favorable for
operate
near
criticality
so
that
efficient
information
integration
might
be
achieved.
operate
near
criticality
so
that
efficient
information
integration
might
be
achieved.
complex
networked
systems
as theInformation
human brain
or communication systems to
Keywords:
NetworkPublished
dynamics,
measures,
theory
©
2017 Thedynamical
Authors.
by Complexity
Elsevier
B.V.such
Keywords:
Network
dynamics,
Complexity
measures,
theory
operate near
criticality
so that
efficient
information
might
be achieved.
Peer-review
under
responsibility
of the
scientific committee
of Information
theintegration
International
Conference
on Computational Science
Keywords:
Network
dynamics,
Complexity
measures,
Information
theory
Keywords: Network dynamics, Complexity measures, Information theory

1 Introduction
1
1 Introduction
Introduction
Quantifying informational processes of dynamical networked systems has been increasingly
1
Introduction
Quantifying
informational
of internal
dynamical
networked
has beenthat
increasingly
useful as a unique
window processes
for probing
system
states systems
and mechanisms
underlie
Quantifying informational processes of
useful
window
for
useful as
as a
a unique
unique
window processes
for probing
probing
Quantifying
informational
of
useful as a unique window for probing

dynamical networked
internal
system
states
internal
system
states
dynamical
networked
internal system states

systems has been increasingly
and
that underlie
and mechanisms
mechanisms
underlie
systems
has beenthat
increasingly
1
and mechanisms that underlie
1
1
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
1
10.1016/j.procs.2017.05.241

120	

Network Informational Complexity
Near
Criticality
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128Arsiwalla et al.

observed phenomenological behaviors of many complex systems. Mapping structure-function
relationships in this way by using information theory has paid off for studying both, complex
biological systems such as the brain or engineered systems such as communication networks.
A prominent information-theoretic complexity measure that has shown a recent resurgence of
interest in the wake of consciousness research is integrated information (often denoted as Φ). It
was first introduced in neuroscience as a complexity measure for neural networks, and touted as
a correlate of consciousness [19]. Integrated information Φ is loosely defined as the quantity of
information generated by a network as a whole, due to its causal dynamical interactions, that
is over and above the information generated independently by the disjoint sum of its parts.
As a complexity measure, Φ seeks to operationalize the intuition that complexity arises from
simultaneous integration and differentiation of the network’s structure and dynamics. Integration results in distributed coordination among nodes, while differentiation leads to functional
specializations, thus enabling the emergence of the system’s collective states. The interplay
between integration and differentiation thus generates information that is highly diversified yet
integrated, creating patterns of high complexity. Following initial proposals [17], [18], [19],
several approaches have been developed to compute integrated information [1], [4], [5], [6], [8],
[9], [11], [13], [14] (see also [2], [15], [16], [20] for other related measures). Some of these were
constructed for networks with discrete states, others for continuous state variables. In this
paper, we will consider stochastic network dynamics with continuous state variables because
this class of networks model many biological as well as communication systems that generate
multivariate time-series signals. We want to study the precise analytic relationship between the
information integrated by these networks and the couplings that parametrize their structure
and dynamics. It turns out that tuning the dynamical operating point of a network near the
edge of criticality leads to a high rate of network information integration and that remains
consistent across network topologies. To explain this phenomenon, we analyze the spectrum
of the network’s dynamics. This reveals that integrated information is coupled to the characteristics of the eigenmodes of the system’s covariance matrix, and in turn these are related to
the eigenvalues of the network’s adjacency matrix. In this paper, we make these relationships
precise.

2

Methods

We consider complex networks with linear multivariate dynamics and Gaussian noise. It follows
that the state of each node is given by a random variable pertaining to a Gaussian distribution.
For many realistic applications, Gaussian-distributed variables are fairly reasonable abstractions. The state of the network Xt at time t is taken as a multivariate Gaussian variable with
distribution PXt (xt ). xt denotes an instantiation of Xt with components xit (i going from 1
to n, n being the number of nodes). When the network makes a transition from an initial
state X0 to a state X1 at time t = 1, observing the final state generates information about the
system’s initial state. The information generated equals the reduction in uncertainty regarding
the initial state X0 . This is given by the conditional entropy H(X0 |X1 ). In order to extract
that part of the information generated by the system as a whole, over and above that generated
individually by its irreducible parts, one computes the relative conditional entropy given by the
Kullback-Leibler divergence of the conditional distribution
PX0 |X1 =x (x) of the whole system
n
with respect to the joint conditional distributions k=1 PMk0 |Mk1 =m of its irreducible parts [6].
Here Mkt denotes the state variable of the k th -component of the partitioned system at time t.
2

	

Network Informational Complexity
Near
Criticality
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128Arsiwalla et al.

Denoting the Kullback-Leibler divergence of the above quantities as Φ, we have


n
 

PMk |Mk =m
Φ(X0 → X1 = x ) = DKL PX |X =x 
0

1

0

1

(1)

k=1

where 
for the partitioned system,
n the state variables X0 and X1 can be expressed as formal sums
n
X0 = k=1 Mk0 and X1 = k=1 Mk1 respectively. To have a measure that is independent of
any particular instantiation of the final state x , we average eq.(1) with respect to final states
to obtain
n

Φ (X0 → X1 ) = −H(X0 |X1 ) +
H(Mk0 |Mk1 )
(2)
k=1

This is the definition of integrated information that we will use [6]. The state variable at
each time t = 0 and t = 1 follows a multivariate Gaussian distribution X0 ∼ N (x̄0 , Σ(X0 ))
and X1 ∼ N (x̄1 , Σ(X1 )) respectively. The generative model for this system is equivalent to a
multi-variate auto-regressive process [10]
X 1 = A X0 + E 1

(3)

where A is the weighted adjacency matrix of the network and E1 is Gaussian noise. Taking
the mean and covariance respectively on both sides of this equation, while holding the residual
independent of the regression variables gives
Σ(X1 ) = A Σ(X0 ) AT + Σ(E)

x̄1 = A x̄0

(4)

In the absence of any external inputs, stationary solutions of a stochastic linear dynamical
system as in eq.(3) are fluctuations about the origin. Therefore, we can shift coordinates to set
the means x̄0 and consequently x̄1 to the zero. The second equality in eq.(4) is the discrete-time
Lyapunov equation and its solution will give us the covariance matrix of the state variables.
The conditional entropy for a multivariate Gaussian variable was computed in [11]
H(X0 |X1 ) =

1
1
n log(2πe) − log [det Σ(X0 |X1 )]
2
2

and depends on the conditional covariance matrix. Substituting in eq.(2) yields
 n

k
k
1
k=1 det Σ(M0 |M1 )
Φ (X0 → X1 ) = log
2
det Σ(X0 |X1 )

(5)

(6)

In order to compute the conditional covariance matrix we make use of the identity (proof of
this identity for the Gaussian case was demonstrated in [10])
Σ(X|Y) = Σ(X) − Σ(X, Y)Σ(Y)−1 Σ(X, Y)T

(7)

Computing Σ(X0 , X1 ) = Σ(X0 ) AT and using the above identity, we get
Σ(X0 |X1 )

Σ(Mk0 |Mk1 )

=
=

Σ(X0 ) − Σ(X0 ) AT Σ(X1 )−1 A Σ(X0 )T

−1 
T
Σ(Mk0 ) − Σ(Mk0 ) AT k Σ(Mk1 ) Ak Σ(Mk0 )

(8)
(9)

the conditional covariance for the whole system and that
 for its parts respectively. The variable
Mk0 refers to the state of the k th node at t = 0 and Ak denotes the (trivial) restriction of the
3

121

122	

Network Informational Complexity
Near
Criticality
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128Arsiwalla et al.

adjacency matrix to the k th node. For discrete-time linear systems, a unique fixed point exists as
long as all eigenvalues of A differ from one (in the absence of external inputs). Stable stationary
solutions of this system are obtained when the magnitude of all eigenvalues is less than one. In
that regime, the multivariate probability distribution of states approaches stationarity and the
covariance matrix converges, such that Σ(X1 ) = Σ(X0 ) (here t = 0 and t = 1 refer to timepoints after the system has converged to its fixed point). Then the discrete-time Lyapunov
equation in eq.(4) can be solved for the stable covariance matrix Σ(X0 ). For networks with
symmetric adjacency matrix and independent Gaussian noise, the solution takes a particularly
simple form

−1
Σ(X0 ) = 1 − A2
Σ(E)
(10)
and for the parts, we have


Σ(Mk0 ) = Σ(X0 )k

(11)

given by the restriction of the full covariance matrix on the k th component. Note that eq.(11) is
not the same as taking eq.(10) on the restricted adjacency matrix as that would mean that the
k th node has been explicitly severed from the rest of the network. In fact, eq.(11) is the variance
of the k th node while it is still part of the network and Φ yields the amount of information
that is still greater than that of the sum of these connected parts. Inserting eqs.(8), (9), (10)
and (11) into eq.(6) yields Φ as a function of network weights for symmetric networks1 .

3

Results

Using the mathematical tools described above, we now compute exact analytic solutions for
Φ for the 6 networks shown in Figure 1 below. Each of these networks have 10x10 adjacency
matrices with bi-directional weights (though our analysis applies to directed graphs as well).
We want to determine the characteristics of Φ as a function of network weights, which we keep
as free parameters. However, in order to constrain the space of parameters, we set all weights
to a single parameter, the global coupling strength g. This coupling parameter allows us to
scale network weights from zero until the point that the system’s dynamics becomes unstable.
This gives us Φ as a function of g. The analytic results for each network labeled from 1 to
6 are shown in eqs.(12), (13), (14), (15), (16) and (17) respectively. These are computed for a
time-step when the system transitions from X0 to X1 . Our calculations of Φ are performed
for stable stationary solutions (which we can explicitly obtain from the dynamics).

10
1 − 73g 2
1
log
Φ1 =
(12)
10
2
(1 − 82g 2 + 81g 4 )
A1 · A2 · A3
1
log
(13)
Φ2 =
10
2
(−1 + 18g 2 − 59g 4 + 59g 6 − 15g 8 + g 10 )
where

A1

=

A2

=

A3

=

2 
2

1 − 15g 2 + 35g 4 − 16g 6 + 2g 8
1 − 15g 2 + 32g 4 − 19g 6 + 2g 8
2 
2

1 − 15g 2 + 37g 4 − 27g 6 + 4g 8
1 − 13g 2 + 37g 4 − 30g 6 + 3g 8
2

1 − 14g 2 + 36g 4 − 26g 6 + 4g 8

1 For the case of asymmetric weights, the entries of the covariance matrix cannot be explicitly expressed as
a matrix equation. However, they may still be solved by Jordan decomposition of both sides of the Lyapunov
equation.

4

	

Network Informational Complexity
Near
Criticality
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128Arsiwalla et al.

Network 1

Network 2

Network 3

Network 4

Network 5

Network 6

Figure 1: Network topologies. Graphs of 6 networks, from the most densely connected
(Network 1) to the least densely connected (Network 6).

Φ3

=

Φ4

=


10
1 − 9g 2 + 11g 4
1
log
10
2
(1 − 12g 2 + 28g 4 − 9g 6 )
B1 · B2 · B3
1
log
10
10
2
(1 − 3g 2 + g 4 ) (1 − 21g 2 + 152g 4 − 445g 6 + 441g 8 )
where

Φ5

=

Φ6

=

B1

=

B2

=

B3

=

(14)
(15)

4

1 − 21g 2 + 161g 4 − 563g 6 + 895g 8 − 517g 10
4

1 − 21g 2 + 159g 4 − 535g 6 + 793g 8 − 409g 10
2

1 − 21g 2 + 159g 4 − 533g 6 + 769g 8 − 355g 10


2 
4 
4
1 − 8g 2 + 11g 4
1 − 10g 2 + 26g 4 − 19g 6
1 − 9g 2 + 22g 4 − 16g 6
1
log
8
10
2
(−1 + g 2 ) (1 − 11g 2 + 31g 4 − 25g 6 )


10
1 − 5g 2 + 5g 4
1
log
10
2
(1 − 7g 2 + 13g 4 − 4g 6 )

(16)
(17)

In figure 2 we plot characteristic Φ profiles for each network, based on the above solutions.
This figure highlights a couple of interesting features about integrated information. First of
all, irrespective of topology, all networks approach a pole at some value of g, near which, the
integrated information of that network is extremely high. Furthermore, the location of the pole
is precisely the critical point after which the largest eigenvalue of the network slips outside of
the radius of stability. However, differences in network topologies do play a role in placing
each network’s Φ profile in distinct regions of the coupling phase space. Figure 2 shows an
5

123

124	

Network Informational Complexity
Near
Criticality
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128Arsiwalla et al.

ordering of these profiles: the most densely packed networks lie towards the left end, while the
least densely connected ones are more on the right.

<Φ>
30
25

<Φ> Profiles
Network 1

20

Network 2
Network 3

15

Network 4
Network 5

10

Network 6
5

0.0

0.1

0.2

0.3

0.4

0.5

g

Figure 2: Analytic solutions of Φ. Φ profiles for the networks in figure 1 above. These
profiles display an ordering corresponding to the most densely connected network on the left to
the least densely connected one on the right.

3.1

Spectral Modes

We have seen that the analytic solutions for Φ obtained above have poles at specific values of
g. These poles of complexity are located at critical points of the network’s dynamics. Since the
expressions we have computed are exact analytic, we can analyze stability in the vicinity of these
poles by analyzing the spectral eigenmodes of the network. The eigenvalues of the adjacency
matrix depend on the coupling g (because g scales the weights of the edges). Stability of the
system in the stationary regime is guaranteed if and only if the norm of every eigenvalue of A
is less than one. Unit norm corresponds to critical dynamics. Examining each of the networks
considered above, we find that these poles are located precisely at those values of the coupling g,
where one or more eigenvalues equal unit length (shown in table 1). From the plots of Φ we find
that irrespective of topology, network integrated information sharply increases near criticality
(while still in the stable regime). Solutions of Φ corresponding to stable stationary dynamics
exist for values of coupling g for which all eigenvalues of A are within the interval (−1, 1). As
the eigenvalues increase with increasing value of g, when the largest eigenvalue touches plus
or minus one, the dynamical system becomes critical and hits a pole in Φ. Therefore, stable
solutions are only defined for g from 0 until the point where the first pole appears. After
that point, stationary solutions do not exist, though non-stationary ones may be found. In
this work, we only consider stationary solutions as these refer to fixed points/attractors of
dynamical systems. Non-stationary solutions may be interesting for studying meta-stable or
transient states.
From the computed expressions of Φ, we determine the position of the poles by computing
the roots of the denominators. For our six networks, these poles occur at the values of g
shown in table 1. Now consider the eigenmodes of the adjacency matrix A. As each edge has
weight g, the eigenvalues of A are multiples of the coupling g and are shown for all networks in
6

	

Network Informational Complexity
Near
Criticality
Arsiwalla et al.
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128

Network 1
0.111111
1

Network 2
0.266223
0.659656
0.892236
2.08888
3.05524

Network 3
0.333333
0.618034
1.61803

Network 4
0.333333
0.404394
0.51668
0.618034
0.683715
1.61803

Network 5
0.373813
0.649693
0.823506
1

Network 6
0.5
0.618034
1.61803

Table 1: Pole positions of Φ along the g axis for all six networks.

Network 1
9g
-g
-g
-g
-g
-g
-g
-g
-g
-g

Network 2
3.75626g
-3.75626g
1.51594g
-1.51594g
1.12078g
-1.12078g
0.478725g
-0.478725g
0.327307g
-0.327307g

Network 3
3g
-3g
1.61803g
1.61803g
-1.61803g
-1.61803g
0.618034g
0.618034g
-0.618034g
-0.618034g

Network 4
3g
-2.47283g
1.93543g
-1.61803g
-1.61803g
1.61803g
-1.4626g
-0.618034g
0.618034g
0.618034g

Network 5
2.67513g
-2.67513g
1.53919g
-1.53919g
1.21432g
-1.21432g
g
g
-g
-g

Network 6
2g
-2g
1.61803g
1.61803g
-1.61803g
-1.61803g
0.618034g
0.618034g
-0.618034g
-0.618034g

Table 2: Network spectra showing eigenvalues of A for all six networks.

table 2. Having this, if we now insert the value of g at the first pole for each network into its
corresponding eigenvalues, we find that the largest eigenvalue becomes precisely plus or minus
1 at the first pole and subsequent eigenvalues have norms less than one. After the first pole is
crossed by increasing g, the norm of the largest eigenvalue crosses unit length and subsequent
other eigenvalues start growing as well. The second pole is reached, precisely when the second
largest eigenvalue hits norm 1 and so on until beyond the last pole when all the eigenvalues have
length greater than 1. To understand what happens to the dynamics when eigenvalues of A
approach 1, we examine eq.(10). This tells us that unit eigenvalues of A lead to divergences in
the covariance matrix, thus leading to poles in the corresponding eigenvalues of the covariance
matrix. This is shown in figure 3 below for network 4 and network 5. The eigenvectors of the
covariance matrix are the principle modes of the time-series X and the corresponding eigenvalues
give the variance of these modes. A large variance implies a dominance of that mode. Therefore,
when the system approaches a critical point, the dynamics is completely dominated by that
specific mode. The poles of Φ exactly coincide with the poles of the system’s covariance
eigenmodes and as these leading modes gradually grow towards the critical point, so does Φ.
Also, because stable stationary solutions only exist for g until the first critical point, we see that
after the first critical point, positivity of eigenvalues of the covariance matrix is not guaranteed.
We have checked this numerically. This helps identify the full range of stable solutions of Φ
shown in figure 2.
7

125

80

60

40

20

0

0.0

0.5

1.0

Global Coupling g

1.5

Eigenvalues of Covariance Matrix

Network Informational Complexity
Near
Criticality
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128Arsiwalla et al.

Eigenvalues of Covariance Matrix

126	

80

60

40

20

0

0.0

0.2

0.4

0.6

0.8

1.0

1.2

Global Coupling g

Figure 3: Eigenvalues of the covariance matrix Σ(X). Eigenvalue profiles shown as
a function of coupling g for network 4 (left) and network 5 (right). Each color denotes an
eigenvalue. Some eigenvalues are degenerate and some have multiple poles. The eigenvectors
of Σ(X) are the principle modes of the time-series X and the corresponding eigenvalues shown
above indicate the variance of these eigenmodes. A large variance implies a dominance of that
mode. We see that dynamics of the system near the critical coupling g for each system is
dominated by the leading eigenmode (shown in red).

4

Discussion

This paper analytically investigates why informational complexity of complex networks with
stochastic Gaussian dynamics shows a characteristic strong growth near criticality, and one
which persists across different network topologies. We have used integrated information or Φ
as a candidate complexity measure as its formulation elegantly makes use of both, the network’s
structure and dynamics, while serving as a global measure for the system’s collective states. We
have computed exact analytic solutions for Φ as a function of the network’s overall coupling
parameter g. Concurrent to computing Φ, we have also analyzed the spectral properties
of the network, which shows how the network’s collective eigenmodes contribute to Φ. We
found poles in Φ at point of criticality, leading to high information integration near the edge
of criticality. This indicates that it is not only the network’s topology that determines how
much information it can integrate, but also its dynamical operating point. As a matter of fact,
operating near the edge of criticality (when still within the stable regime) leads to a sharp
increase in Φ, irrespective of network topology.
Looking at the eigenmodes of the network, we found that instances of high integrated information (in the stationary regime) are associated to the strong dominance of the eigenmode
corresponding to the leading eigenvalue of the network’s covariance matrix, while sub-leading
modes get suppressed. High complexity corresponds to a symphony-like state of the network,
rather than a globally synchronized state. Hence, Φ taken as a proxy for a system’s information processing capacity, implies that operating at the edge of criticality can be favorable for
efficient information processing. This can be particularly beneficial in designing communication
networks and also in understanding information processes in biological networks such as the
human brain. And in fact, there has been recent evidence precisely in this direction [12]. The
authors of [12] demonstrate that resting-state dynamics of the human brain network in fact operates precisely at the edge of a bifurcation (this result also holds for higher resolution datasets
[7], [3]). Combining this observation with the results of this paper suggests that the reason
8

	

Network Informational Complexity
Near
Criticality
Xerxes D.
Arsiwalla
et al. / Procedia Computer Science 108C (2017) 119–128Arsiwalla et al.

why the dynamics of the brain might operate at the edge of criticality is to enable efficient
information integration.

4.1

Acknowledgments

This work has been supported by the European Research Council’s CDAC project: ”The Role
of Consciousness in Adaptive Behavior: A Combined Empirical, Computational and Robot
based Approach” (ERC-2013- ADG 341196).

References
[1] X. D. Arsiwalla and P. F. M. J. Verschure. Integrated information for large complex networks. In
The 2013 International Joint Conference on Neural Networks (IJCNN), pages 1–7, Aug 2013.
[2] Xerxes D Arsiwalla. Entropy functions with 5d chern-simons terms. Journal of High Energy
Physics, 2009(09):059, 2009.
[3] Xerxes D Arsiwalla, David Dalmazzo, Riccardo Zucca, Alberto Betella, Santiago Brandi, Enrique
Martinez, Pedro Omedas, and Paul Verschure. Connectomics to semantomics: Addressing the
brain’s big data challenge. Procedia Computer Science, 53:48–55, 2015.
[4] Xerxes D. Arsiwalla and Paul Verschure. Computing Information Integration in Brain Networks,
pages 136–146. Springer International Publishing, Cham, Switzerland, 2016.
[5] Xerxes D. Arsiwalla and Paul F. M. J. Verschure. High Integrated Information in Complex Networks Near Criticality, pages 184–191. Springer International Publishing, Cham, Switzerland,
2016.
[6] Xerxes D Arsiwalla and Paul FMJ Verschure. The global dynamical complexity of the human
brain network. Applied Network Science, 1(1):16, 2016.
[7] Xerxes D. Arsiwalla, Riccardo Zucca, Alberto Betella, Enrique Martinez, David Dalmazzo, Pedro
Omedas, Gustavo Deco, and Paul Verschure. Network dynamics with brainx3: A large-scale
simulation of the human brain network with real-time interaction. Frontiers in Neuroinformatics,
9(2), 2015.
[8] Nihat Ay. Information geometry on complexity and stochastic interaction. Entropy, 17(4):2432–
2458, 2015.
[9] David Balduzzi and Giulio Tononi. Integrated information in discrete dynamical systems: motivation and theoretical framework. PLoS Comput Biol, 4(6):e1000091, 2008.
[10] Adam B Barrett, Lionel Barnett, and Anil K Seth. Multivariate granger causality and generalized
variance. Physical Review E, 81(4):041907, 2010.
[11] Adam B Barrett and Anil K Seth. Practical measures of integrated information for time-series
data. PLoS Comput Biol, 7(1):e1001052, 2011.
[12] Gustavo Deco, Adrián Ponce-Alvarez, Dante Mantini, Gian Luca Romani, Patric Hagmann, and
Maurizio Corbetta. Resting-state functional connectivity emerges from structurally and dynamically shaped slow linear fluctuations. The Journal of Neuroscience, 33(27):11239–11252, 2013.
[13] Virgil Griffith. A principled infotheoretic\ phi-like measure. arXiv preprint arXiv:1401.0978, 2014.
[14] Masafumi Oizumi, Larissa Albantakis, and Giulio Tononi. From the phenomenology to the mechanisms of consciousness: integrated information theory 3.0. PLoS Comput Biol, 10(5):e1003588,
2014.
[15] Karl Petersen and Benjamin Wilson. Dynamical intricacy and average sample complexity. arXiv
preprint arXiv:1512.01143, 2015.
[16] Max Tegmark. Improved measures of integrated information. arXiv preprint arXiv:1601.02626,
2016.

9

127

128	

Xerxes D. Arsiwalla et al. / Procedia Computer Science 108C (2017) 119–128
Network Informational Complexity Near Criticality
Arsiwalla et al.

[17] Giulio Tononi. An information integration theory of consciousness. BMC neuroscience, 5(1):42,
2004.
[18] Giulio Tononi and Olaf Sporns. Measuring information integration. BMC neuroscience, 4(1):31,
2003.
[19] Giulio Tononi, Olaf Sporns, and Gerald M Edelman. A measure for brain complexity: relating
functional segregation and integration in the nervous system. Proceedings of the National Academy
of Sciences, 91(11):5033–5037, 1994.
[20] Thomas Wennekers and Nihat Ay. Stochastic interaction in associative nets. Neurocomputing,
65:387–392, 2005.

10

