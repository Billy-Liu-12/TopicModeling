Available online at www.sciencedirect.com

ScienceDirect
Procedia Computer Science 108C (2017) 1813–1822

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Dynamic load balancing for CAFE multiscale
Dynamic
balancing
for
modelling
methods
for heterogeneous
hardware
Dynamic load
load
balancing
for CAFE
CAFE multiscale
multiscale
modelling
for
infrastructure
modelling methods
methods
for heterogeneous
heterogeneous hardware
hardware
infrastructure
infrastructure
Lukasz Rauch1, Daniel Bachniak1
1

1 Poland
AGH University
Science1and
Technology,
Krakow,
LukaszofRauch
, Daniel
Bachniak
1
1
Lukasz
Rauch
,
Daniel
Bachniak
lrauch@agh.edu.pl
University of Science and Technology, Krakow, Poland
AGH University of Science
and Technology, Krakow, Poland
lrauch@agh.edu.pl
lrauch@agh.edu.pl

1
AGH
1

Abstract
The
paper presents new approach to Static and Dynamic Load Balancing (DBL) for loosely coupled
Abstract
multiscale
modellingnew
methods
executed
in heterogeneous
hardware
infrastructure.
The
most coupled
popular
Abstract
The paper presents
approach
to Static
and Dynamic Load
Balancing
(DBL) for
loosely
configurations
of computing
nodes
composed
of modern
CPUs,
GPUs
andfor
co-processors,
are
The
paper presents
new
approach
to
Static
and
Dynamicmulticore
Load
Balancing
(DBL)
loosely
multiscale
modelling
methods
executed
in heterogeneous
hardware
infrastructure.
The
most coupled
popular
used.
The proposed
load
balancing
approach
takes
into account
previously
determined
computational
multiscale
modelling
methods
executed
in heterogeneous
hardware
infrastructure.
most popular
configurations
of computing
nodes
composed
of
modern
multicore
CPUs,
GPUs
and The
co-processors,
are
configurations
of computing
nodes
composed
of
modern
multicore
CPUs,
GPUs
and co-processors,
are
character
methods
applied
in particular
scales,
which
dependspreviously
on
a size
of input
data,
operational
used.
The of
proposed
load
balancing
approach
takes
into account
determined
computational
used.
The
proposed
load
balancing
approach
takes
into
account
previously
determined
computational
intensity
and
limitations
of
hardware
architecture.
Such
limitations
are
defined
by
the
Roofline
model
character of methods applied in particular scales, which depends on a size of input data, operational
character
of methods
applied
in
particular
scales, Such
which
depends
on
size maximum
of input
operational
and then used
in the algorithm
as boundary
conditions,
allowing
to determine
performance
of
intensity
and
limitations
of hardware
architecture.
limitations
area defined
by thedata,
Roofline
model
intensity
and
limitations
of
hardware
architecture.
Such
limitations
are
defined
by
the
Roofline
model
an
algorithm
for
particular
device.
Multiscale
calculations
based
on
upscaling
approach
are
analysed
by
and then used in the algorithm as boundary conditions, allowing to determine maximum performance of
using
Cellular
Finite
Element
(CAFE)
method.
qualitative
results, are
obtained
after
and
then
usedfor
inAutomata
the
algorithm
as boundary
conditions,
allowing
to
maximum
performance
of
an
algorithm
particular
device.
Multiscale
calculations
basedThe
ondetermine
upscaling
approach
analysed
by
application
offor
proposed
load
balancing
procedure,
aremethod.
discussed
in
paper inapproach
details.
an
algorithm
particular
device.
Multiscale
calculations
basedThe
onthe
upscaling
analysed
by
using
Cellular
Automata
Finite
Element
(CAFE)
qualitative
results, are
obtained
after
using
Cellular
Automata
Element
(CAFE)
qualitative
results, obtained after
application
of proposed
loadFinite
balancing
procedure,
aremethod.
discussedThe
in the
paper in details.
©
2017 Themultiscale
Authors.
Published
by
Elsevierload
B.V.balancing,
Keywords:
modelling,
dynamic
heterogeneous
hardware
application
of
proposed
load
balancing
procedure,
are
discussed
in
the
paper
in
details.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
Keywords: multiscale modelling, dynamic load balancing, heterogeneous hardware
Keywords: multiscale modelling, dynamic load balancing, heterogeneous hardware

1 Introduction
1 The
Introduction
development of modern HPC infrastructures, based on heterogeneous hardware architectures,
1 Introduction

increases
computing performance,
it also
requires new
approaches
to design hardware
and implementation
of
The development
of modern HPC
infrastructures,
based
on heterogeneous
architectures,
numerical
algorithms.performance,
overview
of the
state-of-the-art
in heterogeneous
focusing on
The development
ofWide
modern
HPC
infrastructures,
based
on
heterogeneous
hardware
architectures,
increases
computing
it also
requires
new
approaches
to design computing,
and implementation
of
increases
computing
it also
requires
new approaches
to design computing,
and
of
three
architectures:
theperformance,
Cell Broadband
Engine
Architecture,
graphics
processing
unitsimplementation
(GPUs),
and field
numerical
algorithms.
Wide
overview
of
the
state-of-the-art
in heterogeneous
focusing
on
numerical
algorithms.
Wide
overviewis of
the state-of-the-art
in heterogeneous
focusing
on
programmable
gatethe
arrays
presented
in (Brodtkorb,
Dyken,
Hagen,computing,
Hjelmervik
i Storaalsi,
three architectures:
Cell(FPGAs),
Broadband
Engine
Architecture,
graphics
processing
units
(GPUs),
and field
three
architectures:
the
Cell
Broadband
Engine
Architecture,
graphics
processing
units
(GPUs),
and
field
2010).
Authors
give
a
review
of
the
hardware
as
well
as
implementation
techniques
and
frameworks,
programmable gate arrays (FPGAs), is presented in (Brodtkorb, Dyken, Hagen, Hjelmervik i Storaalsi,
regarding
efficient
of
aofsingle
device.
However,
numerical
simulations
highly
exceeds
programmable
gate
arrays
(FPGAs),
presented
(Brodtkorb,
Dyken, Hagen,
Hjelmervik
i Storaalsi,
2010). Authors
giveusage
a review
the is
hardware
as in
well
asrecent
implementation
techniques
and
frameworks,
capabilities
of
modern
computing
devices.
Multiscale
modelling
composed
of
two
or
more
2010).
Authors
give
a
review
of
the
hardware
as
well
as
implementation
techniques
and
frameworks,
regarding efficient usage of a single device. However, recent numerical simulations highly coupled
exceeds
regarding
efficient
of a scales
single
However,
recent
numerical
simulations
exceeds
solutions
working
inusage
different
isdevice.
a typical
example
of this
case.
Nowadays,
multiscale
capabilities
of modern
computing
devices.
Multiscale
modelling
composed
of twopopular
orhighly
more
coupled
capabilities
of modern
computing
Multiscale
modelling
composed
of two
or
more
coupled
approaches
can
be in
divided
intoscales
twodevices.
groups,
i.e. upscaling
and
concurrent,
which
are
characterized
by
solutions working
different
is a typical
example
of this
case.
Nowadays,
popular
multiscale
solutions
working
different
is a typical
example
of Fine
this
case.
Nowadays,
popular
specific
approach
to
a problem
solution
(dei.e.Borst,
2008).
length
scale
in multiscale
upscaling
approaches
can be in
divided
intoscales
two
groups,
upscaling
and
concurrent,
whichmethods
are
characterized
by
approaches
can be to
divided
into two
groups,
upscaling
andFine
concurrent,
whichmethods
are characterized
by
specific approach
a problem
solution
(dei.e.Borst,
2008).
length scale
in upscaling
specific approach to a problem solution (de Borst, 2008). Fine length scale methods in upscaling
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.043

1814	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

approach are attached to the coarse length scale in specific domain points, usually called integration
points. This approach divides into: (i) semi- or loosely- coupled problems, (ii) fully- or tightly-coupled
solution. CAFE model based on integration of Finite Element Method in macro scale and Cellular
Automata in micro scale is a typical representative of upscaling group of method. This approach is
mostly applied in computational material science, where it is used in modelling of explicitly represented
microstructures of materials. Examples of this concept are presented in (Das, 2010; Wu, Davis,
Shterenlikht i Howard, 2005) for detailed simulations of material phenomena in production processes.
Specifically in the area of materials science, the following works: Davies (Davies, 1995; Madej,
Hodgson i Pietrzyk, 2009; Shterenlikht i Howard, 2006) are notable.
This paper deals with the problem of efficient performance of CAFE method on heterogeneous
hardware architectures, where elementary methods like FE and CA are characterized with different
computing performance on different devices. In particular, the work presented in the paper focuses on
the problem of Load Balancing, which significantly influences final performance of applied multiscale
approach. The problems of initial balancing, imbalance monitoring and re-balancing is analysed in
details for single and multiple computing nodes composed of modern heterogeneous devices.

2 Load Balancing on modern e-infrastructures
Dynamic threshold algorithm for imbalance assessment for multicore system was proposed and
implemented in (Tan, Chai i Hoong, 2013). The procedure was dedicated to inter run queue load
balancing to improve the cache utilization. Its main advantage is based on proper dynamic thresholding
and triggering of load balance algorithm. The proposed method was used for multiscale modelling after
first scheduling of calculations with assumption that migration of tasks is possible only inside single
computing node. The methodology presented in (Acosta, Corujo, Blanco i Almeida, 2010) was
dedicated to dynamic programming techniques, however approach proposed by Acosta et al. fits well to
other problems with similar character. This approach, typical for dynamic programming techniques, was
applied for GPU and multi GPU computing nodes, which gave satisfactory results of speedup. Similarly,
solution proposed in (Zhang, Shu i Wu, 2014) was created for GPU applications. In that work an opensource library for load balancing and characterizing irregular applications on GPUs was proposed.
Topology-aware dynamic load balancing for clustered hierarchical multicore machines was the main
subject in (Pilla i inni, 2014). The idea of load balancing is based on three subsequent steps focused on
the most loaded core selection, assigned tasks selection, minimization of probability functions using
Gibbs energy. Dynamic load balancing algorithm for heterogeneous clusters was the main objective of
(Korkhov, Krzhizhanovskaya i Sloot, 2008). Authors introduced generic technique for adaptive load
balancing and presented case study based on Virtual Reactor application used for simulation of chemical
vapor deposition.
Metrics about performance, energy consumption, quality of data have been studied in (Truong,
Dustdar i Fahring, 2007). The quality of data and its impact on performance were also considered.
However, three pillars of these properties have not been investigated in a systematic way for multiscale
methods. Some of the results were published in (Rauch, Heterogeneous Hardware Implementation of
Molecular Static Method for Modelling of Interatomic Behaviour, 2013), where the problem of
Molecular Static (MS), implemented as single scale method, was analysed to obtain the best
performance on heterogeneous hardware applications. The implemented numerical procedure of MS
was tested with two inter-particle potentials i.e. Lennard-Jones and Sutton-Chen. In the case of latter
potential, the dependency between size of data and computing time occurred to be strongly nonlinear.
In many cases, the user optimization goal is different and the availability, performance and cost of
underlying heterogeneous computing platforms for multiscale method applications are also different.
This justifies investigation of multi-dimensional elasticity mechanisms for multiscale methods, as these
mechanisms allow us to deal with different trade-offs of resources, costs and quality. Currently, such

	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

1815

elasticity mechanisms have not been considered in multiscale methods. On the basis of recent results
investigation, it can be seen that solution of this problem will contribute to minimization of costs spent
on clusters maintenance and improvement of natural environment.

3 Multiscale computational model
In this work loosely coupled models were taken into account. The idea behind this approach is
presented on the example of CAFE method. CAFE integrates FEM calculations in macro scale with CA
modelling in micro scale. The connection between these scales realized loosely allows to execute
calculations simultaneously on different computing nodes or on different computing devices within one
node. Usually in macro scale one FEM approach is performed on huge computational domain, while in
micro scale n smaller computing tasks have to be performed. Schematic representation of this type of
calculations is presented in Figure 1.
Macro scale
FEM

FEM

IDLE

FEM

FEM

I
D

FEM

FEM

FEM
FEM

Micro scale

FEM
FEM

FEM
FEM

FEM

FEM

FEM

FEM

FEM

FEM

FEM

FEM
timeline

CA
CA
CA

CA
CA

IDLE

CA

CA

CA

CA

CA

CA

CA
CA

CA
CA

Figure 1. Realization of loosely coupled CAFE approach.

In case of macro calculations the domain decomposition, based on division of a computing space
into smaller parts, is usually applied to distribute computing jobs onto different nodes. Problem
decomposition for homogenous environment is relatively easy to achieve due to a comparable
performance of different nodes. Many efficient procedures for load balancing of parallel FEM
calculations exist (Hamandi, Lee i Ozguner, 1995) and are available within popular software e.g. Metis
or Scotch. However, these procedures work efficiently mainly for homogeneous hardware architectures,
where each computing node receives specific amount of data assuring minimization of communication
and equalization of computing overheads. Correct estimation of performance in heterogeneous
environment is not a trivial task. Nevertheless, the mentioned software allows to perform weighted
division of a domain, where proportions of a decomposition for different devices are crucial parameters.
Computing time of FEM depends among the others on number of elements used to discretize a
computing domain. Main loop in the typical FEM code is responsible for computing local matrices and
load vectors for each element in the domain, moreover the total number of nodes used in a mesh is
proportional to a size of the system of equations. Therefore, the time required to obtain a solution is

1816	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

highly related to a number of elements used for domain discretization. Approach proposed in this paper
is also based on that principle, while it also takes into account:
• the real device performance based on a numerical tests performed for particular solver and real
problem matrix,
• the character of communication inside a solver,
• the performance of multicore computing devices by using Roofline model,
• bandwidth of PCI Express bus as well as bandwidth of the network connection, which often is
a bottleneck of overall performance of the computational procedure.
The proposed approach is based on the assumptions that:
• the computing nodes do not change during all iterations of computing procedure,
• the problem does not required remeshing, which highly influences computing time for each
device,
• the device is exclusively used by analysed computing procedure.
During configuration of hardware for specific computing task the following parameters have to be
estimated: number of computing nodes, number of threads, time limit or memory limit. In the case of
CAFE method, these parameters can be established on the basis of the following input data:
• Input variables characterizing FEM in macro scale: nn_macro, nn_micro, ndof_macro, ndof_micro – number
of nodes in specific scale, which directly influences memory usage. Usually stiffness matrix is
compressed by one of the popular methods like Compressed Row Storage (CRS), Compressed
Sparse Column (CSC) or quite new one: Sliced ELLPACK (Kreutzer, Hager, Wellein, Fehske
i Bishop, 2014). Such approach reduces the number of elements in sparse matrices by leaving
only non-zero values. This means that dependently on operation system and its configuration,
possibilities of large problems solving drastically increase.
• Input variables characterizing CA approach: lx, ly, lz – dimensions of CA space in 3D, nf –
number of features describing each cell, type of neighborhood, number of iterations for a time
step.
The mentioned parameters influence decomposition of the computing space in different scales,
which determines balancing of the computational load between nodes and between computing devices.
The parameters of the domain decomposition are taken into consideration as the parameters of
optimization procedure executed in each iteration of the multiscale calculations. The related works on
Cellular Automata and Molecular Static on heterogeneous hardware architectures were published in
(Rauch, Heterogeneous Hardware Implementation of Molecular Static Method for Modelling of
Interatomic Behaviour, 2013; Rauch, Bzowski i Rodzaj, OpenCL Implementation of Cellular Automata
Finite Element (CAFE) Method, 2012; Rauch, Madej, Spytkowski i Golab, 2015).

4 Load balancing algorithm for CAFE
The main assumption undertaken in this work was to propose the common approach for static and
dynamic load balancing , but keeping in mind that the proposed method has to be much faster than the
calculations performed in each iteration. Therefore, the leading idea behind the solution proposed in this
paper was application of very fast and easily parallelized nature inspired optimization methods like
Genetic Algorithm (GA), Particle Swarm Optimization (PSO) or Artificial Immune Systems (AIS) to
minimize idle times mentioned in previous section. All of these approaches use concept of specimens,
which represent optimization variables and in subsequent iterations of optimization loop they mutate or
cross to generate new population of specimens. In the algorithm proposed in this paper, the specimen
contains information about division of computing domain into different subdomains performed on the
selected devices. On the basis of such set of pairs, i.e. subdomain-device, the assessment function
determines the approximated error value, which takes into account differences between idle times. The

	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

assessment function analyzes the aspects of computational kernel efficiency and some hardware
constraints like time of communication or device roofline model. The whole procedure is presented
below in details and its sketch is shown in Figure 3.
Static load balancing, the first step of the procedure, is based on the computation complexity
characteristics of the FEM solver. The most difficult part is that the complexity does not only depends
on the solver, but also on the device type (CPU, GPGPU, co-processors), on the input data size and on
the execution parameters like local and global work size on a given computing device. The behavior of
different algorithms used in CAFE modelling, for both FEM and CA approaches, was analyzed in
details. Examples of FEM algorithms for different devices are presented in Figure 2.

Figure 2: Comparison of various FEM algorithms performance on different devices.

According to these measurements it is possible to propose initial partitioning of computational domain
keeping the time of calculations as low as possible. The partitioning takes all available devices and
selects subdomain with specific number of elements for each device. This mean approach results in:

min( 


i

t  t 
i

2

avg

tavg

(1)
where ti is time of calculations for i-th device and tavg is average time of all devices. Both ti and tavg are
predicted on the basis of previously performed benchmarks (Figure 2). Due to such approach we obtain
proposition of division of the computing domain into subdomains and we create subdomain-device
pairs, which are optimization variables used further in description of specimen in optimization algorithm
during DBL. This generates the first population which assures high performance in the first steps of
calculations. However, still unacceptable idle times occur after performance of k iterations of FEM.
Then the work of the algorithm goes into two directions: (i) processing of FEM results and performance
of CA model in microscale, (ii) re-partitioning by using optimization loop. The latter way is based on
already existing population of specimens gathering information on subdomain-device pairs. Mutation
and crossing operations are applied to obtain the proposition of new GA/PSO population, which is
evaluated afterwards. Crossing operation allows to exchange only part of the computational domain
between devices, while mutation extends partition of the mesh on one device and suppress the other.
The evaluation takes into account the whole time required to complete computing procedure based on
FEM numerical procedures performed on heterogeneous hardware architectures.

1817

1818	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

Static Load Balancing – initial generation of GA/PSO population for FEM

Domain partitioning and creation
of pairs subdomain-device

Performance of k iterations of
FEM

Post processing of FEM results

Static load balancing – initial generation of GA/PSO population for CA

Dynamic load balancing –
GA/PSO generation of new population

Re-division of computing domain
(FEM mesh)

Performance of m iterations of CA

Dynamic load balancing –
GA/PSO generation of new population

Re-division of computing domain
(CA space)
Figure 3: Two different used for generation of computational domain.

The time of data preparation i.e. creation of global matrix composed of local matrices is not
considered in the optimization procedures. It is assumed that creation of the global matrix does not
depend on division of computing domain. Therefore, the computing time is composed of the following
components:
• time required to send specific portion of data from master node to particular computing nodes,
• time of data allocation in memory of computing device – communication between host and
computing device on particular computing node,
• time spent on solving the problem on different single-device or multi-device computing nodes,
• time of nodes synchronization between each iteration of the solver (communication between
computing node and master node),
• time of results download from computing device to host together with time of results download
from computing node to master node.
The global time of calculations can be presented as follows:

	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

1819



tg max t p ( j )  talloc (1, j )    talloc (i, j )  tcalc (i, j )  t synch (i, j )   td ( j ) 
i


where j=2,…,m is an identifier of computing node and i=1,…,n is number of iteration,
time spent on data exchange between master and jth computing nodes,
allocation of data on jth computing node in ith iteration,
computing node in ith iteration,

tsynch (i, j )

t ( j)

tcalc (i, j )

talloc (i, j )

t p ( j)

(2)
is a

is time of the

is time of calculations on jth

is time of synchronization between jth computing node and

master node in ith iteration, d
is a time spent on download of results from jth computing node
including download of results from computing device to host. The computing node stays idle while
waiting for synchronization after each iteration. Therefore, the optimization has to assure that
differences between time spent of data allocation and calculation in each iteration of a solver on different
nodes are minimal. However, as presented in equation (1) the first iteration has to be considered
separately, because it includes exchange of data between master and computing nodes, and allocation
of large portion of data. The allocation of data during the subsequent iterations of the solver requires
much less time. It works on the data used for synchronization purposes, which is usually smaller than
originally sent matrices. Therefore, the objective function can be formulated as follows:




 t l   t  k    t l   t  k 
2

l ,k

g1

g1

l ,k

gn

2

gn

where l, k are indexes of all analysed computing nodes and:

t g1  j  
t p  j   talloc 1, j   td  j 

t gn  j   talloc  i, j   tcalc  i, j   tsynch  i, j 

(3)
(4)

(5)
where i=2,...,n is general identifier of the iteration. The calculations of particular components of the
objective function are described in details in previous subsections. The objective function will reach the
smallest value, when execution time on each device would be equal. As a result the suggested division
of computing domain assigned for each device will be obtained. These values can be used as weights
for domain decompositions algorithms. Finally new calculations of FEM procedure are performed,
which simultaneously the same procedure is applied for calculations of CA method. Similar GA/PSO
population is generated, where specimens keep the information on pairs of CA space subdomains and
devices. Then m steps of CA method are performed and dynamic load balancing procedure is applied.
It is also based on mutation and crossing of already existing specimens to obtain proposition of new
division of CA space onto the available devices. If the procedure suggests to make some changes, the
CA space cells are reallocated between computing nodes.

5 Validation of proposed procedure
Two dimensional transient thermal problem was selected as the benchmark. The Fourier law,
described by equation (5), is solved by FEM solvers as a basic Partial Differential Equation (PDE).

  t    t 
t
0

 kx    k y   c p 
x  x  y  x 


(6)

1820	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

Process definitions with geometry and meshes were created using Abaqus software, while
implementation was divided into two parts dedicated to host and computational device. Host code was
implemented in C++ language with in-house codes and ViennaCL (Rupp, 2012) used as a helper library.
Kernels were written using C99 language on the basis of OpenCL programming framework, which
provides flexible environment for programming of heterogeneous systems. In the case of this paper the
selection of programming technology is crucial. It allows to maintain homogeneous implementation,
while using heterogeneous hardware. The flexibility of application development does not always go
hand in hand with equal efficiency on each platform. However, usage of generic computing kernel,
without optimization aimed at specific platform, does not limit the proposed solution to single hardware
manufacturer. Such solution is still able to give performance close to optimal on selected computing
device. FEM fits quite well to OpenCL execution model, where the same instructions are being executed
for different data (SIMD). The main problem is to store all data together into global system of equations.
In presented approach each thread iterates on different rows of global coefficient matrix and adds values
from single elements matrices. Matrices of elements are flattened form of local heat capacity matrices,
which were obtained using numerical integration before. Coefficient matrix of system of equation is
stored in form of Compressed Sparse Row (CRS) format to optimize the usage of the device memory.
The numerical tests were performed on different devices, while NVIDIA Tesla M2090, XEON X5650,
XEON PHI 7110P, representing multicore CPU, GPGPU and Many Integrated Core (MIC) architecture,
were selected for results presentation.
Presented approach was validated for CG and GMRES solvers with uniform Dirichlet boundary
conditions applied on all external edges of computing domain. The matrix with more than n=1.6E+07
of unknowns were generated and the proposed optimization was applied for different distributed
heterogeneous architectures. The results obtained from optimization procedure performed in Static Load
Balancing are shown in table 1. In the configuration of different devices (table 1), the first node on the
list is always master node, which starts distribution of computing tasks and broadcast fractions of the
domain to worker nodes. Afterwards it starts calculations by using its own devices. As the CA model,
naïve grain growth algorithm was used, while each of CA space contained 1E+06 of cells.
Hardware configuration
I) 2 nodes: (1) XEON X5650,
(2) Tesla M2090 connected
with 10Gbit/s, Solver: CG

Static Load Balancing

Final time
Global time – 27.22s,
XEON X5650 – 17.85%
Including 23.86s of calculations on
Tesla M2090 – 82.15%
GPGPU installed on worker node
Forecasted time: 25.14s
II) 2 nodes (1) XEON X5650
Global time – 16.68s,
+ Tesla M2090, (2) XEON
XEON X5650 – 58.35%
Including 13.41s of calculations on
PHI 7110P, connected with
+ Tesla M2090
XEON PHI 7110P installed on
fast 100Gbit/s, Solver: CG
XEON PHI 7110P – 41.65%
worker node
Forecasted time: 14.52s
III) 3 nodes (1) XEON
Global time – 51.67s,
X5650, (2) XEON PHI
XEON X5650 – 4.60%
Including 47.27s of calculations on
7110P, (3) Tesla M2090,
XEON PHI 7110P – 23.85% Tesla M2090 and 46.31s on XEON
connected
with
fast
Tesla M2090 – 71.55%
PHI 7110P on worker nodes
100Gbit/s, Solver: GMRES
Forecasted time: 43.16s
Table 1: Results of SLB forecast and real computing time for first k=100 steps of FEM.

Results obtained for dynamic load balancing in subsequent iterations are presented for the last of
hardware configurations in Figure 4. The objective function is calculated on the basis of equation 2 and
reflects idle times measured during subsequent iterations. The GA optimization procedure was
performed for 50 specimens in population, each composed of combination of subdomain-device pairs.
50% of the best specimens in population were selected for the next iteration and 50% was passed to
crossing and mutation.

	

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

Figure 4: Minimization of idle time between subsequent operations.

6 Conclusions
Presented approach used for static and load balancing is based on GA/PSO optimization procedure,
which takes into account not only computational and memory performance of kernels used by the
analysed solvers, but also time of communication, allocation of data, memory throughput and Roofline
model of multicore devices as optimization boundary conditions. The optimization can be applied
successfully for single- as well as multi-device computing nodes. The times of calculations for different
configurations of devices are forecasted to be equal, however during first iterations the idle times are
quite high in comparison to computing times. Nevertheless, It is clearly seen that the idle times are
minimized during subsequent calculations, but still they can be improved to be equal according to
forecasting values.
The proposed solution does not consider dynamic changes in mesh, e.g. remeshing or adaptation,
during calculations. It narrows the possible applications, however still can be treated as a starting point
in this direction. Moreover, the distribution of data in the global stiffness matrix are not taken into
account. The data in benchmarks are assumed to be in form of band matrix, which in different cases
may influence results of optimization. Therefore, the main direction of further development is analysis
of solvers’ performance in dependence of the character of input data as well as creation of similar
approach for calculations requiring adaptation of meshes.
The method proposed in this paper can be used to find optimal weights for domain decomposition
algorithms, which can be further introduced in dedicated applications like METIS or Scotch. The
method aims at different parallel solvers of linear equations systems performed in distributed
heterogeneous hardware architectures.
Acknowledgement
Financial support of the NCN, project no. 2014/15/B/ST8/00187, is acknowledged.

1821

Lukasz Rauch et al. / Procedia Computer Science 108C (2017) 1813–1822

1822	

References
Acosta, A., Corujo, R., Blanco, V., & Almeida, F. (2010). Dynamic load balancing on heterogeneous
multicore/multiGPU systems. High Performance Computing and Simulation, (pp. 467-476).
Brodtkorb, A. R., Dyken, C., Hagen, T. R., Hjelmervik, J. M., & Storaalsi, O. O. (2010). State-of-theart in heterogeneous computing. Scientific Programming, 18, pp. 1-33.
Das, S. (2010). Modeling mixed microstructures using a multi-level cellular automata finite element
framework. Computational Materials Science, 47, pp. 705-711.
Davies, C. (1995). The effect of neighbourhood on the kinetics of a cellular automata recrystallization
model. Scripta Metallurgica et Materialia, 33(7), pp. 1139-1143.
de Borst, R. (2008). Challenges in computational materials science: Multiple scales, multi-physics and
evolving discontinuities. Computational Materials Science, 43, pp. 1-15.
Hamandi, L., Lee, R., & Ozguner, F. (1995). Review of domain-decomposition methods for the
implementation of FEM on massively parallel computers. IEEE Antennas and Propagation
Magazine, 37(1), pp. 93-98.
Korkhov, V. V., Krzhizhanovskaya, V. V., & Sloot, P. M. (2008). A grid-based virtual reactor: Parallel
performance and adaptive load balancing. Journal of Parallel and Distributed Computing,
68(5), pp. 596-608.
Kreutzer, M., Hager, G., Wellein, G., Fehske, H., & Bishop, A. R. (2014, 03 05). A unified sparce matrix
data format for efficient general sparse matrix-vector multiply on modern processor with wide
SIMD units. arXiv, pp. 1-23.
Madej, L., Hodgson, P. D., & Pietrzyk, M. (2009). Development of the Multi-scale Analysis Model to
Simulate Strain Localization Occurring During Material Processing. Archives of
Computational Methods in Engineering, 16(3), pp. 287–318.
Pilla, L. L., Ribeiro, C., Coucheney, P., Broquedis, F., Gaujal, B., Navaux, P. O., & Méhaut, J.-F. (2014).
A topology-aware load balancing algorithm for clustered hierarchical multi-core machines.
Future Generation Computer Systems, 30, pp. 191-201.
Rauch, L. (2013). Heterogeneous Hardware Implementation of Molecular Static Method for Modelling
of Interatomic Behaviour. Procedia Computer Science, 18, pp. 1057–1067.
Rauch, L., Bzowski, K., & Rodzaj, A. (2012). OpenCL Implementation of Cellular Automata Finite
Element (CAFE) Method. In R. Wyrzykowski, J. Dongarra, K. Karczewski, & J. Waśniewski
(Ed.), Parallel Processing and Applied Mathematics (pp. 381-390). Springer Berlin
Heidelberg.
Rauch, L., Madej, L., Spytkowski, P., & Golab, R. (2015). Development of the cellular automata
framework dedicated for metallic materials microstructure evolution models. Archives of Civil
and Mechanical Engineering, 15(1), pp. 48-61.
Rupp, K. (2012). High-Level Manipulation of OpenCL-Based Subvectors and Submatrices. Procedia
Computer Science, 9, pp. 1857 - 1866.
Shterenlikht, A., & Howard, I. C. (2006). The CAFE model of fracture—application to a TMCR steel.
Fatigue & Fracture of Engineering Materials & Structures, 29, pp. 770-787.
Tan, I., Chai, I., & Hoong, P. (2013). Dynamic threshold for imbalance assessment on load balancing
for multicore systems. Computers and Electrical Engineering, 39, pp. 338–348.
Truong, H.-L., Dustdar, S., & Fahring, T. (2007). Performance metrics and ontologies for grid
workflows. Future Generation Computer Systems, 23(6), pp. 760-772.
Wu, S. J., Davis, C. L., Shterenlikht, A., & Howard, I. C. (2005). Modeling the ductile-brittle transition
behavior in thermomechanically controlled rolled steels. Metallurgical and Materials
Transactions A, 36(4), pp. 989–997.
Zhang, T., Shu, W., & Wu, M. (2014). CUIRRE: An open-source library for load balancing and
characterizing irregular applications on GPUs. Journal of parallel and distributed computing,
74(10), pp. 2951-2966.

