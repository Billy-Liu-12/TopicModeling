Available online at www.sciencedirect.com

ScienceDirect

This space is reserved for the Procedia header, do not use it
This space
reserved
for the
header, do not use it
ProcediaisComputer
Science
108CProcedia
(2017) 1165–1174
This space is reserved for the Procedia header, do not use it

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Investigation
Investigation of
of the
the visual
visual attention
attention role
role in
in clinical
clinical bioethics
bioethics
decision-making
using
machine
algorithms
Investigation
of the visual
role in clinical
bioethics
decision-making
using attention
machine learning
learning
algorithms
Danieldecision-making
L. Fernandes1 , Rodrigo
Siqueira-Batista
Andréia P.algorithms
Gomes33 , Camila R.
using
machine33,learning
Daniel L.3 Fernandes1 , Rodrigo
R.
4 Siqueira-Batista , Andréia
4 P. Gomes , Camila
Souza3 , Israel T. da Costa4 , Felippe da S. L. Cardoso4 , João V. de Assis44 ,
V. de
Souza , Israel T. 1da Costa , Felippe
4 da S. L.3 Cardoso , João1,2
3 Assis ,
R. Cerqueira
Gustavo
H. L. Caetano
Daniel L. Fernandes
, Rodrigo
Siqueira-Batista
, Andréia
P. Gomes
, Camila R.
4 , and Fabio
1,2
,
and
Fabio
R.
Cerqueira
Gustavo
H.
L.
Caetano
3
4
4
,
Israel
T.
da
Costa
,
Felippe
da
S.
L.
Cardoso
,
João
V.
de
Assis4 ,
Souza
1
Graduate
Program
in
Computer
Science,
Universidade
Federal
de
Viçosa,
Minas
Gerais,
Brazil
4
1,2
1
Graduate Program
in Computer
Science, Universidade
Federal
Viçosa, Minas Gerais, Brazil
, and Fabio
R. de
Cerqueira
Gustavo
H. L. Caetano
{daniel.louzada,
fabio.cerqueira}@ufv.br
{daniel.louzada,
fabio.cerqueira}@ufv.br
2
Department of Production
Engineering, Universidade
Federal Fluminense, Rio de
2 1 Graduate Program in Computer Science, Universidade Federal de Viçosa, Minas
2

Janeiro, Brazil
Department of Production Engineering,
Universidade Federal Fluminense, Rio de Gerais,
Janeiro,Brazil
Brazil
frcerqueira@id.uff.br
{daniel.louzada,
fabio.cerqueira}@ufv.br
frcerqueira@id.uff.br
3
Department of Medicine and Nursing, Universidade Federal de Viçosa, Minas Gerais, Brazil
3
Department
of of
Production
Engineering,
Universidade
Federal
Rio deGerais,
Janeiro,
Brazil
Department
Medicine
and Nursing,
Universidade
FederalFluminense,
de Viçosa, Minas
Brazil
{rsbatista,
andreia.gomes,
camila.r.souza}@ufv.br
frcerqueira@id.uff.br
{rsbatista,
andreia.gomes,
camila.r.souza}@ufv.br
4
3 4 Department of Physical Education, Universidade Federal de Viçosa, Minas Gerais, Brazil
Department
ofofMedicine
and
Nursing,Universidade
UniversidadeFederal
FederaldedeViçosa,
Viçosa,Minas
MinasGerais,
Gerais,Brazil
Brazil
Department
Physical
Education,
{israel.teoldo,
felippe.cardoso,
joao.assis, gustavo.caetano}@ufv.br
{rsbatista,
andreia.gomes,
camila.r.souza}@ufv.br
{israel.teoldo,
felippe.cardoso,
joao.assis,
gustavo.caetano}@ufv.br
4
Department of Physical Education, Universidade Federal de Viçosa, Minas Gerais, Brazil
{israel.teoldo, felippe.cardoso, joao.assis, gustavo.caetano}@ufv.br

Abstract
Abstract
This study proposes the use of a computational approach based on machine learning (ML)
This
study toproposes
the use models
of a computational
approach
on machine
learningresults
(ML)
algorithms
build predictive
using eye tracking
data. based
Our intention
is to provide
Abstract
algorithms
to
build
predictive
models
using
eye
tracking
data.
Our
intention
is
to
provide
results
that
thethe
study
medical
investigation
in the decision-making
process
in clinical
This may
studysupport
proposes
useof
a computational
approach
based on machine
learning
(ML)
that
may
support
the study
ofofwork,
medical
investigation
in the decision-making
process
in
clinical
bioethics,
particularly
in
this
in
cases
of
euthanasia.
The
data
used
in
the
approach
algorithmsparticularly
to build predictive
models
using
eye of
tracking
data. Our
intention
is to
provide
results
bioethics,
in
this
work,
in
cases
euthanasia.
The
data
used
in
the
approach
were
collected
from
students
of theinvestigation
nursing undergraduate
course using
an eyein tracker.
that may
support
the75
of medical
in the decision-making
process
clinical
were
collected
from
75study
students
ofthrough
the nursing
undergraduate
courseand
using
an later
eye tracker.
The
available
data
were
processed
feature
selection
methods,
were
used to
bioethics,
particularly
inprocessed
this work,through
in casesfeature
of euthanasia.
The dataand
usedwere
in the
approach
The
available
data
were
selection
methods,
later
used
to
create
models capable
predictingofthe
decision through
ML algorithms.
Statistical
were collected
from 75of
students
theeuthanasia
nursing undergraduate
course
using an eye
tracker.
create
models
capable
of
predicting
the
euthanasia
decision
through
ML
algorithms.
Statistical
experiments
that processed
the predictive
model
resultant
from the
multilayer
(MLP)
The availableshowed
data were
through
feature
selection
methods,
and perceptron
were later used
to
experiments
showed
that
the
predictive
model
resultant
from
the
multilayer
perceptron
(MLP)
algorithm
led
to
the
best
performance
compared
with
the
other
tested
algorithms,
presenting
create models
capable
of predicting
the compared
euthanasiawith
decision
through
ML algorithms,
algorithms. presenting
Statistical
algorithm
led
to
the
best
performance
the
other
tested
an
accuracy showed
of 90.7%that
andthe
a mean
area model
under resultant
the ROCfrom
curve
0.90. Interesting
knowledge
experiments
predictive
theof
perceptron
(MLP)
an
accuracy
ofrules)
90.7%forand
astudied
mean
area
underdecision-making
the ROC curve
ofmultilayer
0.90.
Interesting
knowledge
(patterns
and
the
bioethical
was
extracted
using
simulations
algorithm
led rules)
to the for
best
performance
compared
with the other
tested
algorithms,
presenting
(patterns
and
the
studied
bioethical
decision-making
was
extracted
using
simulations
with
MLP models
and inspecting
thearea
obtained
rules.ofThe
performance
shown
an
accuracy
of 90.7%
and a mean
underdecision-tree
the ROC curve
0.90.good
Interesting
knowledge
with
MLP
models
and predictive
inspecting
the obtained
decision-tree
rules.
The
good
performance
shown
by
the
obtained
MLP
model
demonstrates
that
the
proposed
investigation
approach
(patterns
and rules)
forpredictive
the studied
bioethical
decision-making
was extracted
using simulations
by
the
obtained
MLP
model
demonstrates
that
the
proposed
investigation
approach
may
be
used
to test
scientific
hypotheses
related
to visual attention
decision-making.
with
MLP
models
and
inspecting
the obtained
decision-tree
rules. Theand
good
performance shown
may be
used
to test
scientific
hypotheses
related
to visual attention
and
decision-making.
by
the
obtained
MLP
predictive
model
demonstrates
that
the
proposed
investigation
approach
Keywords:
Visual attention,
Decision-making
in bioethics, Mobile eye tracking, Machine learning
in
©
2017 The Authors.
Published by
Elsevier B.V.
Keywords:
Visual
attention,
Decision-making
in bioethics,
Mobile
eye
tracking,
Machine
learning
in
Peer-review
under
responsibility
of
the
scientific
committee
of
the
International
Conference
on
Computational
Science
may
be
used
to
test
scientific
hypotheses
related
to
visual
attention
and
decision-making.
medicine
medicine
Keywords: Visual attention, Decision-making in bioethics, Mobile eye tracking, Machine learning in
medicine

1
1 Introduction
Introduction
Decision-making and problem-solving capacity represent important cognitive abilities for peo1
Introduction
Decision-making
problem-solving
capacity
represent data
important
cognitive
abilities
for people’s daily lives. and
In the
context of large
raw datasets,
mining
techniques,
particularly
ple’s daily lives. In the context of large raw datasets, data mining techniques, particularly
Decision-making and problem-solving capacity represent important cognitive abilities for peo1
ple’s daily lives. In the context of large raw datasets, data mining techniques, particularly
1
1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.032

1

1166	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

machine learning (ML) algorithms, have become remarkably useful in the decision-making process due to the ability to reveal hidden patterns, converting data into useful information [9].
In clinical practice, in particular in situations that involve bioethical issues, decision-making
by a healthcare professional arises from a complex interaction between the work environment
and neural processes parallel to cognition and emotion, leading to choices and judgments that
take into account knowledge, risk, uncertainty, and regret, among other aspects [3]. Along with
the use of bioethics frameworks in the decision-making process, the adoption of techniques for
investigating and supporting ethical decision-making in healthcare has been discussed [11].
This is the case of mobile eye tracking (MET), a mobile technological device that enables
measuring eye position and movement in order to map visual attention [27]. Recently, this
tool has shown great potential for application in a wide range of fields of knowledge [21], e.g.,
in mental health [11], radiology and diagnostic imaging [26], human-computer interaction [14],
studies of teaching-learning processes [27], and sports [4]. In addition to its broad application,
the main interest in the use of MET is due to the fact that it is widely accepted as a valuable
non-invasive method for studying visual attention characteristics as well as cognitive, emotional,
and sensory status of a subject [11]. Therefore, MET plays an important role in advanced
understanding of human perception, reasoning studies, and strategies for problem solving [26].
It is important to notice that the most challenging part of researches using MET is data
analysis due to the typical small number of participants - in spite of the volume and complexity
of the information produced - and due to imperfect data collection given the interferences
produced in the visual exploration process. Hence, combining methodologies is recommended
to enhance the analysis of the acquired data, thus optimizing the assessment of the influence of
visual aspects in the cognitive process [27]. Although the aforementioned studies have shown
an important evolution in eye-tracking research, they were not carried out in conjunction with
advanced computational support, such as by employing ML techniques, specially in bioethics.
The present investigation was designed based on these considerations aiming to experimentally study the role of visual search - using MET - in the decision-making process in the case of
euthanasia (this project was approved by the Research Ethics Committe of Federal University
of Viçosa - CAAE No. 25353714.8.0-000.5153). Euthanasia, which is clearly a classic theme
in clinical bioethics [12], is defined as mercy killing or dying process of an ill person, i.e, when
someone other than the patient is committed to an action with the goal of alleviating ample and
unbearable suffering of the patient [1]. The idea of studying MET data to relate visual features
to decision-making for such a complex moral issue was first proposed by Siqueira-Batista et al.
(2015) [24], and recommended by Pärnamets et al. (2015) [21]. The present work carries out
the authors’ proposal using advanced computational methods.
The predictive models obtained in this study resulted in interesting patterns that associate
cognition-related visual aspects with the decision-making process. Those results have great
potential for future research aiming to build computational tools to help in the ideal set-up
of medical teams and to support the decision-making procedure in critical situations where no
moral consensus has been established.

2
2.1

Materials and Methods
Machine learning framework

Although this study focuses on the specific case of correlating visual characteristics to the
practice of euthanasia, it is worth pointing out that the overall idea of the procedure hereby
presented may be applied to any field that uses MET resources to associate vision data with
2

	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

results pertaining to the study at hand.
The presented pipeline is similar to that of the process of knowledge discovery in databases
(KDD) [9]. The pipeline is split into four steps, namely: acquisition, preprocessing, data
mining, and knowledge extraction. The first step consists of collecting eye data through MET,
performing the appropriate sampling, and converting the resulting sampled data into a suitable
format. The second step comprises data preprocessing, i.e., improving data quality and choosing
proper variables by attribute selection. The third step includes experiments with ML algorithms
on the resulting training set (TS), and the assessment of the statistical performance of the
generated models. The fourth, and final step, consists of extracting knowledge by obtaining
patterns and tendencies that may lead to plausible hypotheses.

2.2

Dataset

The TS used in this study for building the ML algorithms was created based on data collected
from 75 voluntary students (17 to 47 years old, mean 21.36, 14 of whom males) from the first
to ninth semesters of the nursing undergraduate course of a large Brazilian public university1 .
Data were collected using ASL’s Mobile Eye-XG eye tracker with a frame rate of 30 Hz2 .
MET is a device able to monitor eye behavior by analyzing the central vision of the participants using specialized cameras attached to glasses. To that end, the equipment uses an
infrared light source to determine the minimum and exact central vision fixation sites every
40 milliseconds (ms), besides identifying the image of pupil and cornea [14]. Prior to data
acquisition, the collection environment was duly prepared and the MET device was calibrated.
Next, a 2 min 24 s excerpt of the movie “Million Dollar Baby” (Figure 1) was shown on
the same screen used for MET calibration so that the participants’ eye movements could be
identified. The film tells the story of Maggie Fitzgerald, a boxer that suffered a serious injury
and became tetrapletic after an unfair fight. Over time, several complications occured, which
led Maggie to attempt suicide. After failing, she turned to her coach (Frankie) and asked him
for euthanasia.

(a) Maggie’s scene.

(b) Frankie’s scene.

Figure 1: Screens shots of the movie the participants watched.
After the boxer expressed her will and made the request to the coach, the movie was interrupted at a crucial moment when a decision would be made. The participants in the research
were then inquired about their decision (whether to fulfill or not the request of the boxer) and
were asked to write down their reasons. Those answers remained confidential. By the end of
the experiment, the following data were obtained from each participant: (i) the computational
eye-tracking record and (ii) the answer on the decision along with its justification.
1 Raw data available at: https://drive.google.com/drive/folders/0B8aRarbjcs87VGdLa3FvYnZRVlk?usp=
sharing
2 The equipment used in this research: https://www.youtube.com/watch?v=fvJPVInvsNk

3

1167

1168	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

During TS composition, the justifications in the answers on the participants’ decision-making
were analyzed and it was observed that the decision of some participants was influenced by
matters such as sanctity of life, religion, or the code of ethics of nursing professionals. Therefore,
since one of the goals of this study is to investigate the correlation of eye data with the decisionmaking process, the data coming from those participants were removed from our TS, thus
preventing undesired biases in the predictive models.
At the end, the TS contained 27 positive (would practice euthanasia) instances and 16
negative instances, i.e., 43 participants (17 to 26 years old, mean 20.93, ten of whom males)
who, according to their justifications, were neutral and had none of the influences mentioned
above. After concluding the final TS, it was converted into the ARFF format [15].

2.3

Attributes

The next step, after generating the TS, is attribute selection, i.e., defining which attributes
are relevant and non-redundant among the 35 initial ones. The selection reduces the dataset
complexity, which makes model building quicker and, in many cases, yields better results [5, 19].
First, based on a previous analysis, 14 eye attributes were manually removed for being
clearly redundant (e.g., the same measure is encompassed by two variables, one as a percentage
value and another as an absolute value).
Thus, the dimensionality of the initial set was reduced to 21 numerical attributes: number of fixations on: Maggie’s face, Maggie’s tracheal tube, Maggie’s chest, Maggie’s scene
space, Frankie’s face, Frankie’s chest, Frankie’s scene space, and areas without classification;
total number of fixations during the experiment; duration of fixations (ms) on: Maggie’s face,
Maggie’s tracheal tube, Maggie’s chest, Maggie’s scene space, Frankie’s face, Frankie’s chest,
Frankie’s scene space, and areas without classification; total duration of fixations during the experiment; mean value (pixels) of: overall pupil diameter, horizontal pupil diameter, and vertical
pupil diameter; binary decision class variable (whether to practice or not euthanasia).
Next, we performed a computational attribute selection using a wrapper approach. Wrapper
methods use a classification algorithm to assess the quality of each selected attribute subset
[19]. We used this approach along with an exhaustive search strategy to systematically analyze
all subset possibilities (221 − 1). As a result, the combination of attributes that led to the
ML model with the highest predictive power was the subset: number of fixations on Maggie’s
chest (maggies chest fixation), time of fixations on Maggie’s tracheal tube (tube duration), total
time of fixations during the experiment (total duration), mean value of overall pupil diameter
(overall pupil dilation), and mean value of vertical pupil diameter (vertical pupil dilation).

2.4

Machine learning toolkits

The present study employed two data mining programs, both open-source and multiplatform.
The several ML algorithms that will be mentioned later on in the text were applied using the
software WEKA, which is widely used for classification tasks in several scientific works [15].
The other software used was NICeSim, a simulator that aims at understanding the correlation between the attributes and the class variable [5]. The simulation environment includes
a graphical interface for the researcher to change the values of the attributes to create distinct
scenarios (simulated instances). For each user intervention, the system shows the probability of
the simulated instance to be positive. As a result, tendencies can be extracted according to the
simulated scenarios, which facilitate the study of scientific hypotheses. The simulations performed in NICeSim are based on predictive models built with Support Vector Machine (SVM)
and Multilayer Perceptron (MLP).
4

	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

2.5

Learning algorithms

Several algorithms may be used in the classification task to predict to which class a given
record belongs. The selection of classification algorithms must be based on some criteria such
as precision, robustness, scalability, velocity, and interoperability of the model [9, 25]. In the
present study, some supervised classification algorithms were tested, all widely used in medical
informatics research [6]. A brief explanation of each of these algorithms is given below.
Naı̈ve Bayes (NB) is a classification algorithm that provides a simple and quick approach
based on the Baye’s theorem [18]. In order to estimate the probability of the vector of attributes
conditioned to the class, it is assumed that the attributes are independent, which simplifies the
calculation. As long as there is no dependency, or it is weak, the algorithm results in an accurate
model with quite shorter learning time compared with several other algorithms [18, 25].
Artificial neural networks comprise learning approaches inspired by the functional structure of the biological neural system. MLP is an example used to solve complex classification
problems. An MLP has several layers and intermediate nodes (artificial neurons), also called
hidden nodes, between the input and output layers, and typically uses the sigmoid function as
activation function to produce non-linear outputs. In order to adjust the weights of connections
between neurons, MLPs apply an algorithm called backpropagation during the learning process.
This algorithm uses the difference observed between the value yielded by the network and the
value expected in a certain layer to update the weights of the previous layer [20, 25].
The SVM approach, for linearly separable data, establishes a maximum-margin hyperplane
as decision boundary in order to prevent overfitting. To that end, the SVM goal is formulated as
a quadratic programming problem. When the data are not linearly separable, a kernel function
is employed to map the data to a higher dimension space to make them linearly separable and,
therefore, apply the linear separation method [25]. Sequential Minimal Optimization (SMO)
is an algorithm widely used to solve the SVM quadratic programming problem. SMO uses an
analytical optimizer and linear memory to deal with large datasets [2].
The learning algorithm k -nearest neighbor (k NN) classifies an instance by analyzing its
closest k -neighbors [20]. The class is attributed according to the majority class of the selected
neighbors. In this calculation, the votes often have different weights according to the neighbor
distance, i.e., the closer the neighbor, the higher the weight its class will have in defining the
class of the instance under analysis [20, 25].
Decision trees, such as C4.5, are part of a very popular and easily interpretable classification
method, as the resultant rules that relate the attributes to the class are very easy to extract
[23]. The C4.5 is an evolution of a simple model called ID3. C4.5 presents the following
enhancements: inclusion of numerical attributes, treatment of missing values, and pruning after
building the tree in order to decrease its complexity and minimize the possibility of overfitting
[23, 25].
Random Forest (RF) is an ensemble classification method that uses the result of several
decision trees. The final decision of the class is acquired by a voting schema in which the
majority class obtained from the different trees prevails. To build each tree, a TS sample is
used. Each sample is built by extracting a random subset from the original attributes [22, 25].

3
3.1

Results and Discussion
Model performance evaluation

We used a 10-fold cross validation to assess the resultant ML models. Table 1 summarizes the
performance of each mentioned learning algorithm, with and without cost-sensitive classification
5

1169

1170	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

(CSC), regarding mean accuracy (Ac), precision (Pr), sensitivity (Sn) and, area under the ROC
curve (AUC). It is important to mention that SMO was used with (RBFkernel) and without
(linear classification) kernel. Furthermore, the number of neighbors was set to 3 for k NN.
Except for these modifications, the default parameters of WEKA were kept.
Classifier
NB
MLP
SMO (no kernel)
SMO (RBFKernel)
k NN
C4.5
RF
NB
MLP
SMO (no kernel)
SMO (RBFKernel)
k NN
C4.5
RF

Type
Normal
Normal
Normal
Normal
Normal
Normal
Normal
CSC
CSC
CSC
CSC
CSC
CSC
CSC

Ac
65.1%
90.7%
62.8%
62.8%
72.1%
65.1%
62.8%
58.1%
81.4%
67.4%
44.2%
72.1%
67.4%
60.5%

Pr
64.7%
91.9%
58.4%
39.4%
75.1%
64.7%
61.1%
60.4%
81.4%
71.1%
46.7%
75.1%
71.1%
59.0%

Sn
65.1%
90.7%
62.8%
62.8%
72.1%
65.1%
62.8%
58.1%
81.4%
67.4%
44.2%
72.1%
67.4%
60.5%

AUC
0.660
0.903
0.513
0.500
0.667
0.668
0.686
0.660
0.852
0.690
0.428
0.635
0.667
0.699

Confidence (95%) interval of Ac
[50.16%, 80.04%]
[75.76%, 100.00%]
[47.86%, 77.74%]
[47.86%, 77.74%]
[57.16%, 87.04%]
[50.16%, 80.04%]
[47.86%, 77.74%]
[43.16%, 73.04%]
[66.46%, 96.34%]
[52.46%, 82.34%]
[29.26%, 59.14%]
[57.16%, 87.04%]
[52.46%, 82.34%]
[45.56%, 75.44%]

Table 1: Statistical evaluation (10-fold cross validation) of models generated from several learning algorithms with and without cost-sensitive classification (CSC).
CSC is widely used as a way of dealing with imbalanced datasets with which the generated
model may present a bias toward the majority class [5, 25]. In our case, the positive class is the
majority, but the imbalance is not severe. Still, we decided to also test CSC to check whether
the numerical difference between the classes would cause any sort of bias in the models.
As can be seen, the model generated by the MLP network with homogeneous costs stands
out considerably in comparison with the other models, delivering better performance across
all metrics. The high AUC value demonstrates a high predictive power and means that the
probabilities generated by the model are robust. These probabilities are fundamental to find
the patterns reported in the next section.

3.2

Extracting patterns by means of simulations with MLP models

In the context of knowledge extraction, NICeSim was used to simulate various scenarios by
combining the values of attributes (simulated instances) in order to provide a better understanding of the relation between attributes and the class. After performing the simulations,
five plots were generated showing the relation between the attributes and the probability of
practicing euthanasia.
Figures 2a and 2b illustrate the relation between the duration of fixations and the probability
of practicing euthanasia. The duration of eye fixation is a measure that examines the relation
between the cognitive load and the visualization scene [14]. This measure corresponds to the
duration of the cognitive processing of a person in relation to a determined area of interest
(AOI) [17]. As can be seen in Figure 2a, for fixations lasting around 1400 ms, the participants
present a little over 60% chance of practicing euthanasia. This value is close to 100% when the
duration of fixations goes above 32768 ms. Figure 2b, on the other hand, show that fixations
lasting less than 7768 ms on the tracheal tube (tracheotomy) lead to virtually no chance (0%)
of practicing euthanasia, whereas values above 11652 ms show that the chance is close to 100%.
Both figures show that the longer the overall fixations, the higher the chance of the participants
practicing euthanasia. It is believed that the participants that took longer looking at AOIs 6

	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

(a) Overall duration of fixations.

(b) Duration of fixations on the tracheal tube.

(c) Number of fixation on Maggie’s chest.

(d) Mean vertical pupil dilation.

(e) Mean overall pupil dilation.

Figure 2: Predicted probability of practicing euthanasia versus five key variables.
such as the tracheotomy - became more appalled by the patient’s situation and, consequently,
chose to interrupt the suffering.
Figure 2c indicates that attention to Maggie’s chest is a determinant factor, showing that
this is definitely an AOI, because important elements receive fixations more often [10]. In
this analysis, a low number of fixations (below 32) represent a high probability of practicing
euthanasia (approximately 100%), while values above 44 lower the chance to approximately
0%. At first glance, the tendency shown in Figure 2c seems antagonistic to the conclusions
taken from Figures 2a and 2b. But, it is important to notice that the patient’s chest area has
a string with a crucifix. One plausible explanation is that the more the participants fixated
their eyes on the region of this religious object, seeking information, the more their religious
bias was taken into account. Even though we have removed the participants who declared to
be religious from our dataset, when it comes to cognitive processing, nothing keeps the object
in the frame from perhaps influencing the participants’ decision to some extent.
For pupil behavior, either vertical (Figure 2d) or overall (Figure 2e), the results show that the
larger the pupil diameter, the lower the probability of practicing euthanasia. Values above 312
pixels indicate a very low probability of practicing euthanasia, whereas values below 268 pixels
indicate a chance close to 100%. The pupil accurately represents the cognitive effort as well as
the judgment of one’s interest in carrying out a given task, and it is considered an important
7

1171

1172	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

cognition element [4, 14]. Then, a high pupil dilation indicates a high level of cognitive effort.
When the stimulus decreases, the pupil contracts until returning to its resting size [4] - a process
also known as miosis [16]. In this context, it is believed that the participants’ who had a very
high energy demand opted for a more rational than emotional decision, respecting the oath
and code of ethics of nursing professionals. Furthermore, euthanasia is considered homicide
according to articles 121 and 122 of the Brazilian Penal Code [8].
Our experiments show that the chosen variables are adequate to build predictive models to
the studied ethical decision-making. It was expected, as the components assessed by MET are
associated with the participant’s cognitive and emotional capacities [13]. Therefore, the relation
of these variables to the ethical decision-making shows the significant role that the vision plays
in the studied case.

3.3

Extracting patterns by means of decision tree rules

Although Table 1 shows that C4.5 is far less accurate when compared to MLP, an experiment
was carried out to verify whether the extracted rules of a C4.5 model would match the tendencies
found from the MLP model. Figure 3a and Figure 3b show the rules along with the decision tree
from where the rules could be extracted, and demonstrate that the found patterns matched the
results of the MLP model. Notice that the rules were taken from a cost-sensitive C4.5 approach,
because the C4.5 model, in its original form, presented worse performance (Table 1).

(a) Rules.

(b) Decision tree.

Figure 3: Patterns generated by a cost-sensitive C4.5 model.
The obtained rules show that the attributes referring to vertical pupil dilation and duration
of fixation on the patient’s tracheotomy are factors that best predict the decision to be made.
Pupil dilation may be indicative of the cognitive load at the decision-making moment [13].
The increase in cortical activation in the limbic system, due to the levels of psychological
resources used to solve problems (such as attention, reasoning, and judgment), promotes an
increase in pupillary diameter - related to the activation of the sympathetic nervous system [7]
- a process also known as mydriasis [16]. The result shown in Figure 3 evidences once more a
correlation between pupil dilation and the participant’s decision-making process in the present
experimental protocol, which shows that the cognitive load stimulated by the level of difficulty
of the task primarily influences the participant’s decision making. Namely, according to the
decision tree, to reach a decision ‘yes’, the vertical pupil dilation has to be necessarily high
(meaning high cognitive load).
The results shown in Figure 2 and Figure 3 indicate that it is also very important to analyze
the region where the participant seeks information to make decisions, so that we can understand
whether the cognitive activities are related to emotion or reason. Similarly to Figure 2, the rules
shown in Figure 3 provide evidence that a high cognitive load, signaled by the high number of
8

	

Investigation of the visual attention
role in clinical
...
Fernandes et al.
Daniel L. Fernandes
et al. / bioethics
Procedia Computer
Science 108C (2017) 1165–1174

fixations on the tracheal tube, relates to the decision ‘yes’. In this case, it is likely an emotional
load due to the fact that the tube demonstrates that the patient is indeed suffering, which is
one of the core elements for ethical decision-making in cases of euthanasia [1].

4

Conclusions

The present investigation proposes a computational approach, based on ML and eye tracking
techniques, that aims to investigate eye data generated from the appreciation of a piece of
cinematographic work in order to aid studies investigating the influence of visual search in the
bioethical decision-making process in a very relevant and controversial issue of clinical practice.
To that end, ML algorithms were applied - namely, supervised classification techniques to a TS built from eye data of 75 (although it is apparently low, this number is expressive in
relation to previous studies) students, in order to understand how visual search impacts the
ethical decision-making of those future professionals. For the dataset used, MLP was the most
accurate among all classification algorithms employed, presenting 90.7% of acuraccy and mean
AUC of 0.90.
The computational approach hereby presented proved to be useful for researches on cognition since it builds and validates a highly precise predictive model to simulate the effects the
variables concerning the number of fixations, the duration of fixation on AOIs, and pupil dilation have on the probability of healthcare professionals practicing euthanasia. Therefore, the
results of this study clearly show a connection between cognitive behavior and decision-making.
Unfortunately, the proposed approach could not be compared with any other previous study
since it is a pioneer in the field.
This study involved multiple areas of knowledge, which contributed to reveal the role of
visual attention on the decision-making process, checking to what extent sight is a determining
factor in decision-making, particularly in clinical bioethics when dealing with end-of-life issues.

Acknowledgments
The authors thanks the financial support of CAPES and FAPEMIG, Brazilian research agencies.

References
[1] M. Berghs, B. D. De Casterle, and C. Gastmans. The complexity of nurses’ attitudes toward
euthanasia: a review of the literature. Journal of Medical Ethics, 31(8):441–446, 2005.
[2] L. Bottou and C. Lin. Support vector machine solvers. Large scale kernel machines, pages 301–320,
2007.
[3] T. Brosch, K. R. Scherer, D. M. Grandjean, and D. Sander. The impact of emotion on perception,
attention, memory, and decision-making. Swiss Medical Weekly, 143:1–10, 2013.
[4] F. da S. L. Cardoso and I. T. da Costa. Behavior pupillary as indicative of specific knowledge of
football player (Portuguese). Revista Mineira de Educação Fı́sica, Edição Especial(9):1087–1094,
2013.
[5] F. R. Cerqueira, T. G. Ferreira, A. de P. Oliveira, D. A. Augusto, E. Krempser, H. J. C. Barbosa,
S. do C. C. Franceschini, B. A. C. de Freitas, A. P. Gomes, and R. Siqueira-Batista. Nicesim:
an open-source simulator based on machine learning techniques to support medical research on
prenatal and perinatal care decision making. Artificial Intelligence in Medicine, 62(3):193–201,
2014.

9

1173

in clinical
...
Fernandes et al.
1174	 Investigation of the visual attention
Daniel L. role
Fernandes
et al. /bioethics
Procedia Computer
Science 108C (2017) 1165–1174

[6] H. Chen, S. S. Fuller, C. Friedman, and W. Hersh. Knowledge management, data mining, and
text mining in medical informatics. In Medical Informatics, pages 3–33. Springer, 2005.
[7] H. D. Critchley, J. Eccles, and S. N. Garfinkel. Interaction between cognition, emotion, and the
autonomic nervous system. Handb Clin Neurol, 117:59–77, 2013.
[8] R. E. F. Dodge. Euthanasia - judicial aspects (Portuguese). Revista Bioética, 7(1):1–7, 2009.
[9] U. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. From data mining to knowledge discovery in
databases. AI magazine, 17(3):37, 1996.
[10] P. M. Fitts, R. E. Jones, and J. L. Milton. Eye movements of aircraft pilots during instrumentlanding approaches. Aeronautical Engineering Review, 9:1–6, 1950.
[11] F. Galgani, Y. Sun, P. L. Lanzi, and J. Leigh. Automatic analysis of eye tracking data for medical
diagnosis. In Computational Intelligence and Data Mining, 2009. CIDM’09. IEEE Symposium on,
pages 195–202. IEEE, 2009.
[12] J. R. Goldim. Bioethics: origins and complexity (Portuguese). Revista Hospital de Clı́nicas de
Porto Alegre, 26(2):86–92, 2006.
[13] E. Granholm and S. R. Steinhauer. Pupillometric measures of cognitive and emotional processes.
International Journal of Psychophysiology, 52(1):1–6, 2004.
[14] L. A. Granka, T. Joachims, and G. Gay. Eye-tracking analysis of user behavior in www search. In
Proceedings of the 27th annual international ACM SIGIR conference on Research and development
in information retrieval, pages 478–479. ACM, 2004.
[15] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten. The weka data
mining software: an update. ACM SIGKDD explorations newsletter, 11(1):10–18, 2009.
[16] E. H. Hess and J. M. Polt. Pupil size in relation to mental activity during simple problem-solving.
Science, 143(3611):1190–1192, 1964.
[17] D. E. Irwin. Fixation location and fixation duration as indices of cognitive processing. The interface
of language, vision, and action: Eye movements and the visual world, pages 105–133, 2004.
[18] G. H. John and P. Langley. Estimating continuous distributions in bayesian classifiers. In Proceedings of the Eleventh conference on Uncertainty in artificial intelligence, pages 338–345. Morgan
Kaufmann Publishers Inc., 1995.
[19] R. Kohavi and G. H. John. Wrappers for feature subset selection. Artificial intelligence, 97(1):273–
324, 1997.
[20] R. S. Michalski, J. G. Carbonell, and T. M. Mitchell. Machine learning: An artificial intelligence
approach. Springer Science & Business Media, 2013.
[21] P. Pärnamets, P. Johansson, L. Hall, C. Balkenius, M. J. Spivey, and D. C. Richardson. Biasing
moral decisions by exploiting the dynamics of eye gaze. Proceedings of the National Academy of
Sciences, 112(13):4170–4175, 2015.
[22] J. R. Quinlan. Induction of decision trees. Machine learning, 1(1):81–106, 1986.
[23] J. R. Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers Inc., San
Francisco, CA, USA, 1993.
[24] R. Siqueira-Batista, F. Cardoso, A. P. Gomes, J. de O. Fonseca, A. F. Bernini, L. V. Barros, C. R.
Souza, V. Esperidião-Antonio, and I. T. da Costa. Decision-making in (bio)ethics: a preliminary
study using mobile eye tracking. Revista Brasileira de Educação Médica, 39(4):496–501, 2015.
[25] P. Tan, M. Steinbach, and V. Kumar. Introduction to data mining. Pearson Education, India,
2006.
[26] G. Tourassi, S. Voisin, V. Paquit, and E. Krupinski. Investigating the link between radiologists’
gaze, diagnostic decision, and image content. Journal of the American Medical Informatics Association, 20(6):1067–1075, 2013.
[27] C. Yu, D. Yurovsky, and T. L. Xu. Visual data mining: An exploratory approach to analyzing
temporal patterns of eye movements. Infancy, 17(1):33–60, 2012.

10

