Available online at www.sciencedirect.com

ScienceDirect
Procedia Computer Science 108C (2017) 1672–1681

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland
Case study on: Scalability
of preprocessing procedure

Case study on:
Scalability
of preprocessing
of remote
sensing
in Hadoop procedure
of remote
sensing in† Hadoop ‡
*
Sukanta Roy ,Sanchit Gupta and S N Omkar
1
Indian Institute
of Science, Bangalore,
India
**
†
‡
Sukanta
,Sanchit
Sukanta Roy
Roysukanta@aero.iisc.ernet.in
,Sanchit Gupta
Gupta† and
and S
SN
N Omkar
Omkar‡
1
2 1Indian

Institute of
of Technology,
Science,
India
Indian Institute
Science, Bangalore,
Bangalore,
India
National
Srinagar,
India
sukanta@aero.iisc.ernet.in
sukanta@aero.iisc.ernet.in
sanchit.nitsri@gmail.com
2
2National
3
Srinagar,
India
National
Institute of
of Technology,
Technology,
Srinagar,
India
Indian Institute
Science, Bangalore,
India
sanchit.nitsri@gmail.com
sanchit.nitsri@gmail.com
omkar@aero.iisc.ernet
3
3
Indian
Indian Institute
Institute of
of Science,
Science, Bangalore,
Bangalore, India
India
omkar@aero.iisc.ernet
omkar@aero.iisc.ernet

Abstract
In the field of remote sensing, the recent increase in image sizes has drawn a significant attention on
Abstract these files in a fault tolerant distributed architecture In this regard, Apache Hadoop
Abstract
processing
In the
the field
field of
of
remote an
sensing,
the MapReduce
recent increase
increase
in image
image
sizes
has drawn
drawn
significant attention
attention
on
In
remote
sensing,
the
recent
in
sizes
has
significant
on
architecture
becomes
efficient
model.
In the
satellite
imageaa processing,
large scale
processing
these
files
in
a
fault
tolerant
distributed
architecture
In
this
regard,
Apache
Hadoop
processing
these
files in on
a the
faultsingle
tolerant
distributed
architecture
this regard,
Apache
images
put the
limitation
computer
analysis.
Whereas, In
Hadoop
Distributed
File Hadoop
System
architecture
becomes
an efficient
efficient
MapReduce
model.
Infiles
the satellite
satellite
image
processing,
large scale
scale
architecture
becomes
an
MapReduce
model.
the
processing,
large
(HDFS)
gives
a remarkable
solution
to handle
theseIn
through image
its inherent
data parallelism
images
put
the
limitation
on
the
single
computer
analysis.
Whereas,
Hadoop
Distributed
File
System
images
put
the
limitation
on
the
single
computer
analysis.
Whereas,
Hadoop
Distributed
File
System
technique. This architecture is well suited for structured data, as the structured data can be equally
(HDFS) gives
gives
remarkable
solution
to data.
handle
theseare
files
through as
itsunstructured
inherent data
data
parallelism
(HDFS)
aa and
remarkable
solution
to
handle
these
files
through
its
inherent
parallelism
distributed
easily
access the
relevant
Images
considered
matrix
data in
technique.
This
architecture
isofwell
well
suited
for
structured
data,processing.
as the
the structured
structured
data
can
be equally
equally
technique.
This
structured
data,
as
be
Hadoop and
thearchitecture
whole part is
the suited
data isfor
relevant
for any
It leadsdata
to can
a challenge
to
distributed
easily
and
access
the
are
unstructured
matrix
in
distributed
easily
accesswith
the relevant
relevant
data.
Images
are considered
considered
as
unstructured
matrixadata
data
in
maintain the
dataand
locality
the equaldata.
dataImages
distribution.
In this as
paper,
we introduce
novel
Hadoop
the
part
of
the
is
for
any
leads
aa challenge
to
Hadoop
andwhich
the whole
whole
partthe
of standard
the data
data format
is relevant
relevant
for satellite
any processing.
processing.
It localizes
leads to
to the
challenge
to
technique,and
decrypts
of raw
data andIt
distributed
maintain
the
data
locality
with
the
equal
data
distribution.
In
this
paper,
we
introduce
a
novel
maintain
the data
locality
withsplit
the of
equal
dataindistribution.
thispurpose,
paper, awe
introduce
a novel
preprocessing
step on
the equal
datasets
Hadoop. ForInthis
suitable
modification
technique,
which
decrypts
standard
of
and
the
technique,
whichinterface
decryptsis the
the
standard
format
of raw
raw
satellite
data
and localizes
localizes
the distributed
distributed
on
the Hadoop
proposed.
Forformat
the case
studysatellite
on the data
scalability
of preprocessing
steps,
preprocessing
step
on
the
equal
split
of
datasets
in
Hadoop.
For
this
purpose,
a
suitable
modification
preprocessing
step on
the (SAR)
equal split
of datasets in(MS),
Hadoop.
For this
a suitable
modification
Synthetic
Aperture
Radar
and Multispectral
are used
in apurpose,
distributed
environment.
on
on the
the Hadoop
Hadoop interface
interface is
is proposed.
proposed. For
For the
the case
case study
study on
on the
the scalability
scalability of
of preprocessing
preprocessing steps,
steps,
©
2017 TheAperture
Authors. Published
by Elsevier
B.V.
Synthetic
Radar
(SAR)
and
Multispectral
are
used
aa distributed
environment.
Synthetic
Aperture
Radar
(SAR)
andHDFS,
Multispectral
(MS),
areLV,
used
inVV,
distributed
environment.
Keywords:
MapReduce,
Hadoop,
SAR,
JAI, RH, (MS),
RV, LH,
HH,in
HV
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
Keywords:
Keywords: MapReduce,
MapReduce, Hadoop,
Hadoop, SAR,
SAR, HDFS,
HDFS, JAI,
JAI, RH,
RH, RV,
RV, LH,
LH, LV,
LV, HH,
HH, VV,
VV, HV
HV

1 Introduction
1 InIntroduction
remote sensing, the information about the sensed objects are measured from a distance. For

identification of these objects, highly informative
In
In remote
remote sensing,
sensing, the
the information
information about
about the
the
identification
of
these
objects,
highly
informative
identification
of these objects, highly informative
*

features are always expected.
sensed
sensed objects
objects are
are measured
measured
features
are
always
features are always expected.
expected.

Naturally, the degree
from
from aa distance.
distance. For
For
Naturally,
Naturally, the
the degree
degree

Pursuing PhD in Department of Aerospace Engineering at IISc, Bangalore, Karnataka, India-560012.
Pursuing B.Tech in Computer Science & Engineering at NIT, Srinagar, Jammu & Kashmir, India-190006.
*‡
Chief
Research
in Department
of Aerospace
Engineering
at IISc, Bangalore,
India-560012.
* Pursuing
PhD
Department
of
Engineering
at
Karnataka,
India-560012.
Pursuing
PhD in
inScientist
Department
of Aerospace
Aerospace
Engineering
at IISc,
IISc, Bangalore,
Bangalore,
Karnataka,Karnataka,
India-560012.
†
† Pursuing B.Tech in Computer Science & Engineering at NIT, Srinagar, Jammu & Kashmir, India-190006.
Pursuing
B.Tech
in
Computer
Science
&
Engineering
at
NIT,
Srinagar,
Jammu
&
Kashmir,
India-190006.
‡
‡ Chief Research Scientist in Department of Aerospace Engineering at IISc, Bangalore, Karnataka, India-560012.
Chief Research Scientist in Department of Aerospace Engineering at IISc, Bangalore, Karnataka, India-560012.
†

1877-0509 © 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.042

	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

of diversity and complexity of data sets are to capture more details of the scene in terms of features
and this lead to Big Data in remote sensing [1]. For the proper investigation of a scene, recently data
from different sensors as well as different bands of single sensor data are being analyzed together [2].
On one hand as an active sensor, SAR images with different polarization as well as different modes
become an essential tool to get features of objects in terms of their physical properties [3].
Consequently, the complexity at the encryption level of massive SAR datasets, increases and it is
difficult to process them on a single computer. On the other hand, as a passive sensor, hyper spectral
imaging with huge number of contiguous bands become state of the art for a particular application like
mineralogy, geology, etc. Similarly, the hyper spectral image processing suffers from the curse of
dimensionality [3]. This leads to a lot of research in handling these large datasets for contiguous
dependent processing.
In pattern recognition, the most important early step is the analysis of the proper preprocessing of
raw data, wherein the scalability of the algorithm as well as the architecture is a big issue in research
[4, 5]. Mainly, two views of distributed image processing arise in literature. One view of research
introduces techniques to deal large number of tiny images in Hadoop. Another view of research
introduces techniques to deal with large scale images in Hadoop [6, 7]. From this point of view,
Hadoop architecture is very user friendly, inherently distributed and parallel architecture. This
architecture has two main components i) Hadoop Distributed File System (HDFS) and ii) MapReduce.
HDFS inherently stores large data sets in a distributed manner. MapReduce as a functional
programming operates the parallel tasking on each data split at every node.
In the case of tiny file processing in Hadoop architecture, task initialization leads to a large
overhead. Because of this reason, researchers analyze the large number of small images collectively in
Hadoop [8]. In this regards, conversion of large number of tiny files to sequence files draws a
remarkable interest in Hadoop implementation. This approach has become very popular in medical
image processing field, like for analysis of sequence of microscopic images of live cells, Zhang Chen
et al. introduces a novel technique on the cloud using Hadoop [9]. For this kind of job through
pipelining, a novel interface named HIPI: A Hadoop Image Processing Interface is introduced [10].
This interface also shows a new area of research in another application field of computer vision.
In the case of large-scale image processing, research trends mainly follow divide-and-conquer
strategy on parallelized computing. Unlike this strategy, many processes are also ongoing through the
generation of smart data from large data set and analyse these data in single computer [11]. Following
the technique of data parallelism, a novel MapReduce based approach of nearest-neighbor clustering is
presented in literature [12]. In the analysis of remote sensing big data, it is shown that a non-parallel
approach is not capable of processing more than 1000x1000 pixels for clustering [13]. For this reason,
researchers start to explore the analysis with Hadoop architecture. In this regards, Kenneth Hawk et.
al., introduces various solutions regarding remote sensing big data problems [14]. Similarly, Mark
Powell presents the segmentation procedures of celestial body images by NASA in his paper, though
the accuracy is not assessed in details [15]. In [16], Harold Trease et al., demonstrates the video
processing and subsurface transport in Hadoop, though, the implementation details are not provided
properly.
From the implementation point of view, researchers mainly face challenges regarding the
scalability of the algorithm as well as the data-locality for distributed processing in standardized
Hadoop architecture. The default mechanism and configuration of architecture force to develop the
modification of interfaces as well as embarrassing parallelism in processing. In this paper, the authors
introduce the modification on the logical split of default input interface to implement the
preprocessing step of remote sensing in real time. For the case study, decryption procedure on dat.001
data type of SAR image is carried out and scaled mean filtering is examined on the Geotiff data type of
SAR image. As a preprocessing step, pan sharpening of quickbird multispectral data is implemented
on distributed environment. Authors try to examine the generalization of scalability of preprocessing
in terms of accuracy of the algorithm.

1673

1674	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

This paper is organized as follows. Section II, a detail of Hadoop interfaces at architectural level is
presented. Section III states the problem statement. Section IV, contains the proposed methodology.
The following Section V shows the detailed steps for preprocessing of specific satellite data Types and
the experiment with proposed interface. Section VI discusses the potential of such kinds of research
with the future work.

2 Architectural Details
Hadoop architecture is built up with two main components: data storage memory HDFS and
functional parallel tasking unit MapReduce [17, 18]. The large data are typically stored in HDFS in an
inherently parallel way. In the traditional way, there exists a default interface for creating a record
corresponding the block level splits (128 MB size) of HDFS.
During this procedure, a line wise default recording technique with Line Recorder is introduced in
RecordReader interface. Wherein, the key-value pair of each split corresponding “TextInputFormat”
data is created to be analyzed by MapReduce programming at several nodes [19]. The default value
type and key type are Text and LongWritable respectively in Hadoop. Generally, this architecture
consists of two splitting steps at block level and at record level. The block level splitting method can
be disabled to make the whole dataset as one record using isSplitable() method, which exists in
WholeFileInputFormat class. Depending on the application and algorithmic level demand, one can
create customized value and data type in RecordReader class and introduce the customized split to
main load balancing in the network.

3 Problem Statement
The complexity of Satellite datasets lie in the diversity and various dimensionality of complex data
sets. Generally, these datasets have several data formats which are differently structured with metadata
tags. These different data formats lead to specific operative interfaces and libraries for accessing and
processing. In addition, there exist abundant data with descriptive information of datasets, like
geographic location, data type, the basic size of data sets, etc. These irregular abundant data must be
removed during decryption of data sets.
At this point, the exponential growth as well as data diversity leads to distributed image
processing. In parallel and distributed image processing, a huge complexity arises due to its loading
and transmissions procedures in the network, wherein multidimensional and complex structure of data
sets introduces inefficiency of load balancing in the network. For remote sensing application, data
processing is a contiguous job. These sequences of jobs should be scheduled properly and data locality
should be encountered.
Hadoop is a good choice for this purposeful process. However, the several interfaces in Hadoop
architecture should be modified for large-scale satellite image processing. Owing to this kind of
analysis, scalability should not introduce the deficiency during processing. Hence, it is essential to
address an interface which deals with large, complex data sets and the data locality is maintained at
every node for distributed preprocessing procedure without loss of generality.

4 Proposed Methodology
As discussed in the previous section, one should modify the splitting technique as well as data read
interface in recording level of Hadoop architecture. As per the primary requirement, this interface

	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

should be able to handle two standard data formats Ceos and Geotiff satellite image. To achieve this,
two strategies are introduced separately in the preprocessing step. Apart from this, Java Advanced
Programming (JAI) is used at implementation level and isSplitable() method is disabled to get the
whole data as one record.
------------------------------------------------------------------------@Override
protected boolean isSplitable(JobContext context, Path filename){
return false;}
-----------------------------------------------------------------------

4.1 Modification in "RecordReader" interface for "Geotiff"
SAR datasets are complex. During the cropping of a whole Geotiff image, we do not encounter any
problem and each equally cropped data set is sent to the network as splits.
@Override
public boolean nextKeyValue() throws IOException, InterruptedException{
Path file = split.getPath();
String name = file.toString().split(":");
.................................
int height = image.getHeight();
int cropHeight = height/2;
int width = image.getWidth();
int cropWidth = width/2;
-----------------------------------createlogicalsplit();
-----------------------------------int ct = splitNumber;
key.set(new Text(file.getName()+"-"+"ct"+":"+wt+"_"+ht));
return false;
}
Modification in "RecordReader" interface for "Ceos".

4.2 Modification in "RecordReader" interface for "Geotiff"
During the extraction of byte level information, the header file for each row of CEOS Format
images should be treated properly. Therefore, header file corresponding to each real part and
imaginary part of each row of dat.001 format dataset should be removed.
@Override
public void initialize(InputSplit split, TaskAttemtContext con) throws IOException,
InterruptedException{
this.split = (FileSplit) split;
this.conf = con.getConfiguration();
-------------------removeRedundantdata();
-------------------}
@Override
public boolean nextKeyValue() throws IOException, InterruptedException{
Path file = split.getPath();
String name = file.toString().split(":");

1675

1676	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

FSDataInputStream in = fs.open(file);
pos = headerfilelength;//a prior know information
---------------------------.
createlogicalsplit();
--------------------------call newKeyValuepair();
---------------------------}
In this way, "RecordReader" is modified.

5 Experimental study & results
5.1 Experimental setup
The whole algorithmic flow has been carried out in distributed node environment with two
systems.
Master Node: Hadoop Ver: 2.02 with Ubuntu 14.04.4; CPU: Intel Core i7-4770 CPU @3.40GHz
RAM: 36GiB; Disk: 465GiB
Slave Node: Hadoop Ver: 2.02 with Ubuntu 14.04.4;CPU: Intel Core 2 Quad CPU @3.00GHz;
RAM: 8GiB; Disk: 236.1GiB
In the experiment, the validation of proposed modification on interface is achieved through
comparison of experimental result with respect to HIPI interface. The data decryption of raw dat.001
type is implemented. The output of mean filtering of Geotiff data type is verified with respect to
traditional method of sending whole image as a single input. The correlation factor of pan sharpening
between MS data and panchromatic data is observed in distributed environment of MapReduce model.

5.2 A validation with Face detection job
For validation purpose, HIPI interface is configured in distributed environment. In this experiment,
a standard database is used which is available at http://vis-www.cs.umass.edu/fddb/ . A standard face
detection code is implemented and the result of using proposed interface is verified through result of
HIPI interface. Algorithmic steps for HIPI:
 Step1: Take input raw image and make HIPI Image Bundle (HIB) of the images.
 Step2: Run mapper to:
1. Convert HIPI FloatImage to OpenCV Mat.
2. Detect and count faces in the image bundle.
3. Send the number of detected faces as value and put same key to the each output of
mapper.
 Step3: Run Reducer to:
1. Count number of processed files.
2. Count number of detected faces.
3. Write the number of detected files and faces to output file.

5.3 A case study of Decryption procedure on SAR image
To do this experiment ‘Ceos’ type oil spill data from RISAT-1 in FRS-1 mode, is used. The
RISAT-1 image was taken near Mumbai with circular transmission and linear reception on 09-Oct2013 at 12:48:28 UT at latitude: 19.99N and longitude 72.684E:

	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

The novelty of decryption of ‘CEOS Format’ dataset is checked for the sample image of hybrid
polarized datasets. The specification of data type is collected from Band Metadata. These datasets are
in two polarization modes: RH and RV with 9441 columns and 13660 rows. Band Metadata gives the
specification: 4 bytes per pixel. Each row is encrypted in following manner:
Header: 16252
Bytes

Real part: 9441*4
Bytes

Redundant: 192
Bytes

Table 1: Structure of raw data

Imaginary
part:9441*4 Bytes

Total 16252 byte header file is present before raw data and in between real and imaginary part of
complex data, 192 byte redundant data is present. The decryption accuracy is examined for these two
channel datasets. In figure 2, the combination of RV-RV-RH decrypted image is shown.

Figure 1: RV-RV-RH combination image

Figure 2: RV-RV-RH combination

5.4 A case study of Mean Filtering on “Geotiff” datatype
For experimental purposes, ‘Geotiff’ type dataset of land cover scene of Mysore district of
Karnataka State, India is taken for case study.
Top Left Corner latitude: 12˚10' 20.96“N and longitude: 77˚1’36.75”E. Top Right
Corner:12˚10’58.32”N and 77˚3’6.69 “E. Bottom Left Corner: 12˚8’55.64”N and 77˚0’6.50”E.
Bottom Right Corner: 12˚9’6.83”N and 77˚3’10.40”E. Dual polar metric medium resolution (MRS)
mode of RISAT-1 data (C-band) is utilized.
Initially, the experiment is carried out on this Geotiff Format image in the traditional way of
sending whole image as a single split for MapReduce job and are read by the Mapper as
’BytesWritable’ value. However, authors face ‘heap space’ error for large images in this technique.
Then , authors create split of images first, then filter the image.Using 'HIPI' interface, the same
experiment is done.There is no loss in information after adding the splitted output.

1677

1678	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

Figure 3: Output using HIPI interface

Figure 4: Output using proposed interface

For implementation with HIPI interface, images must be bundled first, then it goes for MapReduce
job. However, this interface is popular for ‘.jpg’ and ‘.png’type images.

Figure 6: Hybrid MRC image (Red-HH,
Green-HV, Blue-HH)

Figure 5: Flowchart for mean
filtering

In the proposed interface, images can be sent as single split as well as multiple splits for
MapReduce job. In the above, image is sent as a single split for comparison. In the next, image is sent
as 4 splits for mean filtering job in Hadoop. The work flow of this job is shown above.
In the proposed interface, the technique must be modified according to requirement of job with the
proper knowledge of “data type”.

	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

1679

5.5 A case study of Pan sharpening on MS data
For this case study, dataset is taken from“QUICKBIRD-2” satellite wherein MS data has 2.8 m and

PAN data has 0.7 m resolution. link: http://glcf.umd.edu/data/quickbird/.

Weighted mean technique for the data fusion is one of the oldest techniques in this research field.
In this paper, we have modified the weighted mean method for pan-sharpening. First, images (multi-

Figure 7: Flowchart for weighted mean sharpening

spectral and panchromatic) are fused together by weighted mean technique. After fusion, B-spline is
implemented in the fused image. B-spline is an effective interpolation technique which leads to the
improvement of image resolution and consequently more data extraction from the fused image. The
correlation coefficient and structural similarity index measurement (SSIM) are chosen as assessment
parameters in distributed processing.
Part
Band1
Band2
Band3
Part0
0.999999
0.999999
0.999999
Part1
0.999996
0.999991
0.999971
Part2
0.999999
0.999999
0.999999
Part3
0.999999
0.999999
0.999999
Table 2: Correlation factor of bands of MS data split wise

Band4
0.999999
0.999998
0.999997
0.999999

Part
Part0
Part1
Part2
Part3

Band4
0.014286
0.069466
0.044410
0.017418

Band1
Band2
Band3
0.014260
0.013127
0.014154
0.146762
0.167638
0.341131
0.014370
0.013291
0.014887
0.029530
0.025877
0.023899
Table 3: SSIM factor of bands of MS data split wise

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

1680	

Part

Whole
Image

Band1

0.999939

Band2

0.999939

Band3

0.999767

Band4

0.999938

Table 4: Correlation factor of bands of MS data for whole image
Part

Whole
Image

Band1

0.018223

Band2

0.018223

Band3

0.017924

Band4

0.018448

Table 5: SSIM factor of bands of MS data for whole image

Results shows that assessment parameters are also preserved in distributed processing.

5.6 Result & Discussion
Using the proposed interface for preprocessing does not alter the image information which has
been shown above, as the assessment parameters are preserved while using proposed interface for
whole image as well as for split image. Hence, the Interface could be helpful for preprocessing in
distributed satellite image processing. In addition, this kind of analysis shows the new path of research
on big data remote sensing in Hadoop Architecture.

6 Conclusion
In the present era of research in big data processing, this paper shows a novel way to decrypt large
synthetic aperture radar image data sets for data preparation and go for further analysis of data sets.
Mainly, two standard encrypted formats of data type is introduced for processing in Hadoop
architecture. Equality in data distribution is maintained, nicely through a network. In the future, the
authors would like to design a more robust interface for any standard type of data format in SAR
image processing.

References
[1] Ma, Yan, Haiping Wu, Lizhe Wang, Bormin Huang, Rajiv Ranjan, Albert Zomaya, and Wei Jie.
"Remote sensing big data computing: Challenges and opportunities." Future Generation
Computer Systems 51 (2015): 47-60.
[2] Toutin, Thierry, and Laurence Gray. "State-of-the-art of elevation extraction from satellite SAR
data." ISPRS Journal of Photogrammetry and Remote Sensing 55, no. 1 (2000): 13-33.
[3] Wang, Lizhe, Weijing Song, and Peng Liu. "Link the remote sensing big data to the image
features via wavelet transformation." Cluster Computing 19, no. 2 (2016): 793-810.
[4] Gamba, Paolo, Peijun Du, Carsten Juergens, and Derya Maktav. "Foreword to the special issue
on “human settlements: A global remote sensing challenge”." IEEE Journal of Selected Topics in
Applied Earth Observations and Remote Sensing 4, no. 1 (2011): 5-7
[5] Zinno, Ivana, Lorenzo Mossucca, Stefano Elefante, Claudio De Luca, Valentina Casola, Olivier
Terzo, Francesco Casu, and Riccardo Lanari. "Cloud computing for earth surface deformation

	

Sukanta Roy et al. / Procedia Computer Science 108C (2017) 1672–1681

analysis via spaceborne radar imaging: A case study." IEEE Transactions on Cloud Computing 4,
no. 1 (2016): 104-118.
[6] Mackey, G., Sehrish, S., & Wang, J. (2009, August). Improving metadata management for small
files in HDFS. In Cluster Computing and Workshops, 2009. CLUSTER'09. IEEE International
Conference on (pp. 1-4). IEEE.
[7] Vora, Mehul Nalin. "Hadoop-HBase for large-scale data." In Computer science and network
technology (ICCSNT), 2011 international conference on, vol. 1, pp. 601-605. IEEE, 2011.
[8] Shini, S. G., Tony Thomas, and K. Chithraranjan. "Cloud based medical image exchange-security
challenges." Procedia Engineering 38 (2012): 3454-3461.
[9] Zhang, Chen, Hans De Sterck, Ashraf Aboulnaga, Haig Djambazian, and Rob Sladek. "Case
study of scientific data processing on a cloud using hadoop." In High performance computing
systems and applications, pp. 400-415. Springer Berlin Heidelberg, 2010.
[10] Sweeney, Chris, Liu Liu, Sean Arietta, and Jason Lawrence. "HIPI: a Hadoop image processing
interface for image-based mapreduce tasks." Chris. University of Virginia (2011).
[11] Cavallaro, Gabriele, Morris Riedel, Matthias Richerzhagen, Jón Atli Benediktsson, and Antonio
Plaza. "On understanding big data impacts in remotely sensed image classification using support
vector machine methods." IEEE journal of selected topics in applied earth observations and
remote sensing 8, no. 10 (2015): 4634-4646.
[12] Liu, Ting, Charles Rosenberg, and Henry A. Rowley. "Clustering billions of images with large
scale nearest neighbor search." In Applications of Computer Vision, 2007. WACV'07. IEEE
Workshop on, pp. 28-28. IEEE, 2007.
[13] Lv, Zhenhua, Yingjie Hu, Haidong Zhong, Jianping Wu, Bo Li, and Hui Zhao. "Parallel k-means
clustering of remote sensing images based on mapreduce." In International Conference on Web
Information Systems and Mining, pp. 162-170. Springer Berlin Heidelberg, 2010.
[14] Hawick, Kenneth A., Paul D. Coddington, and Heath A. James. "Distributed frameworks and
parallel algorithms for processing large-scale geographic data." Parallel Computing 29, no. 10
(2003): 1297-1333.
[15] Powell, Mark W., Ryan A. Rossi, and Khawaja Shams. "A scalable image processing framework
for gigapixel mars and other celestial body images." In Aerospace Conference, 2010 IEEE, pp. 111. IEEE, 2010.
[16] Trease, Harold, Daniel Fraser, Rob Farber, and Stephen Elbert. "Using transaction based parallel
computing to solve image processing and computational physics problems." Online at:
http://www. cca08.org/papers/Poster31-Harold-Trease.pdf.
[17] White, Tom. Hadoop: The definitive guide. “O’Reilly Media, Inc.", 2012.
[18] Lam, Chuck. Hadoop in action. Manning Publications Co., 2010.
[19] Zikopoulos, Paul, and Chris Eaton. Understanding big data: Analytics for enterprise class
hadoop and streaming data. McGraw-Hill Osborne Media, 2011.

1681

