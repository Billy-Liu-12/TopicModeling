Multi-agent System for Recognition of Hand
Postures
Mariusz Flasi´
nski, Janusz Jurek, and Szymon My´sli´
nski
IT Systems Department, Jagiellonian University
Straszewskiego 27, 31-110 Cracow, Poland
http://www.wzks.uj.edu.pl/ksi

Abstract. A multi-agent system for a recognition of hand postures
of the Polish Sign Language is presented in the paper. The system is
based on a syntactic pattern recognition approach, namely on parsable
ETPL(k) graph grammars. An occurrence of a variety of styles of performing hand postures requires an introduction of many grammar productions that diﬀer each from other slightly. This makes a construction
of a grammar within a parsable class ETPL(k) dubious. Dividing a whole
grammar into sub-grammars and distributing them to agents allows one
to solve the problem.
Keywords: pattern recognition, multi-agent system, ETPL(k) graph
grammar.

1

Introduction

Multi-agent systems are used as a useful approach in a pattern recognition area
[11,13,21]. It concerns, especially, real-time applications. However, real-time requirements make a construction of multi-agent systems diﬃcult [15,20,22]. The
results of our recent research has revealed that a syntactic pattern recognition
paradigm together with a multi-agent system approach gives a convenient basis
for solving real-time pattern recognition problems [9,16,17]. At the same time,
it seems that in an aspect of an eﬃciency of a symbolic description processing it
performs better than many other computationally ineﬃcient standard artiﬁcial
intelligence methods [19].
The main idea of syntactic pattern recognition consists in treating a pattern
as a structure of the form of string, tree or graph. A set of patterns to be recognized is treated, in turn, as a formal language (string language, tree language or
graph language) that is generated with a formal grammar. A formal automaton
(syntax analyzer, parser) constructed for the grammar is then used as a recognition algorithm. The ETPL(k) graph grammars (Embedding Transformationpreserving Production-ordered k-Left nodes unambiguous grammars) [2,4,7,10]
have been used as a syntactic pattern recognition model for a variety of applications such, as: a pattern recognition in the industrial robot control system [4],
an analysis of a distributed environment conﬁguration in the software allocation
system [3], a solid modelling and analysis in the CAD/CAM (Computer Aided
G. Allen et al. (Eds.): ICCS 2009, Part II, LNCS 5545, pp. 815–824, 2009.
c Springer-Verlag Berlin Heidelberg 2009

816

M. Flasi´
nski, J. Jurek, and S. My´sli´
nski

Design / Computer Aided Manufacturing) integration system [5], a solid representation for an optimal scaling in the CAE (Computer Aided Engineering)
parallel computation system [6], an analysis of a complex experimental physics
equipment in the real-time expert control system [8,16]. Analogously like in the
last mentioned area (real-time expert control system), we have applied a multiagent approach during our recent research concerning a real-time recognition of
hand postures occurring in the Polish Sign Language. The results of the research
are presented in the paper.
Let us notice that pattern recognition of hand postures is widely investigated
all over the world [12,14,18]. The methods of hand posture recognition can be
applied in the ﬁeld of gesture recognition [1,18]. A distributed recognition approach is also widely used for recognition tasks to boost system performance
and/or recognition rate [1,23,24].
A model of a syntactic pattern recognition-based agent is introduced in the
next chapter. An architecture of the multi-agent system and scenarios of its
functioning are discussed in chapter 4. The ﬁnal chapter contains concluding
remarks.

2

Syntactic Pattern Recognition-Based Agents

We introduce a model of a syntactic pattern recognition-based agent in this
chapter. In section 2.1 we present basic phases of a syntactic pattern recognition
approach to an analysis of hand postures and a formal model based on ETPL(k)
graph grammars [2,4,7,10]. Then, in the same section, we discuss a basic problem
concerning a construction of such a grammar for the Polish Sign Language.
Introducing a multi-agent architecture of a system allows us just to solve the
problem. An internal architecture of a syntactic pattern recognition-based agent
that is deﬁned according to a formal model introduced is presented in section 2.2.
2.1

A Formal Model for a Syntactic Pattern Recognition-Based
Agent

An analysis of hand postures of the Polish Sign Language consists of three main
phases. During the ﬁrst phase of image preprocessing a hand region is identiﬁed
and its contour is approximated with a polygon as it is shown in Figures: 1(a) and
1(b). The region centroid and the polygon vertices constitute the characteristic
points of the image - see Fig. 1(b). The image characteristic points are then
used, at the second phase of a graph description generation, for spanning a
graph structure, which is depicted in Fig. 1(c), and ﬁnally for deﬁning the socalled IE-graph on the basis of this structure - see Fig. 1(d). Let us introduce a
formal deﬁnition of an IE-graph [4,7].
Definition 1. An indexed edge-unambiguous graph, IE graph, over Σ and Γ is a
quintuple
g = (V, E, Σ, Γ, φ),

Multi-agent System for Recognition of Hand Postures

817

Fig. 1. Main phases of a syntactic pattern recognition of hand postures of the Polish
Sign Language

where V is a ﬁnite, non-empty set of nodes that indices have been ascribed to
in an unambiguous way,
Σ is a ﬁnite, non-empty set of node labels,
Γ is a ﬁnite, non-empty set of edge labels,
E is a set of edges of the form (v, λ, w), where v, w ∈ V, λ ∈ Γ , such that index
of v is less than index of w,
φ : V −→ Σ is a node-labelling function,
and g contains a BFS spanning tree, which nodes are indexed in the same way
as nodes of g and its edges are directed in the same way as edges of g.
IE-graphs belong to a parsable class of ETPL(k) graph grammars [2,4,7]. The
ETPL(k) parsing algorithm is of a very good computational complexity, namely
O(n2 ) [4]. The parsing algorithm uses an ETPL(k) graph grammar (constructed
for a given graph language consisting of IE-graphs representing hand postures)
as its control table. Of course, constructing such a grammar ”by hand” is very
diﬃcult in case a language consists of many graphs. Therefore, an inference
algorithm generating, automatically, such a grammar on a basis of a set of IEgraphs has been deﬁned and implemented as the INFERGRAPH system [10].
Such a method has occurred to be very eﬃcient.
In case of a recognition of hand postures performed carefully by signers that
use a standard (model) Polish Sign Language, a very good recognition rate has
been obtained - ca. 95%. However, in case of signers representing a variety of

818

M. Flasi´
nski, J. Jurek, and S. My´sli´
nski

Syntactic Pattern
Recognition-Based
Agent

Hand Posture
Knowledge Base
(Graph Grammar)
Control table
for the parser

Collaboration
Knowledge Base
Results of the
collaboration

Best agents for
the collaboration

Unrecognized
hand posture

Unrecognized
hand posture
Symbolic description
of a hand posture
(a graph)

Hand Posture
Recognition
(Parsing)

Collaboration
Module

Recognized
hand posture

Recognized
hand posture

Communication
with other Syntactic Pattern
Recognition-Based Agents
Result of the
recognition

Fig. 2. A general scheme of a syntactic pattern recognition-based agent

(incorrect, negligent) styles (manners), a grammar should contain a lot of productions that diﬀer each from other slightly. This phenomenon makes a deﬁnition
of a grammar within a parsable class ETPL(k) dubious. In case of an automatic
generation of a grammar with the inference system, it can cause a need of introducing a large number of productions that decreases a time eﬃciency of the
method. In extreme cases, it can cause a generation of a grammar within a
parsable class ETPL(k) even impossible (if we would like to comprise all the
distorted performances of the sign language).
Dividing the whole grammar into sub-grammars corresponding to various
styles and manners of a sign language performance allows us to solve a problem
discussed above. Then, each such a ”speciﬁc” sub-grammar is allocated to a syntactic pattern recognition-based agent that is responsible for recognizing a set
of hand postures performed in one predeﬁned manner. An architecture of such
an agent is discussed in the next section.
2.2

An Architecture of a Syntactic Pattern Recognition-Based
Agent

There are following main elements of a syntactic pattern recognition-based agent
(see Fig. 2):
– a hand posture knowledge base in the form of the ETPL(k) graph grammar
describing a manner (variant) of performing hand postures,
– a parser analyses IE-graph representations of hand postures on a basis of
the ETPL(k) graph grammar (a hand posture knowledge base),

Multi-agent System for Recognition of Hand Postures

819

– a collaboration module is responsible for: collaborating with other syntactic
pattern recognition-based agents (establishing communication, exchanging
data, etc.) and accumulating knowledge concerning results of such a collaboration,
– a collaboration knowledge base stores knowledge concerning results of a collaboration with other syntactic pattern recognition-based agents (constantly
being updated). Let us notice that the collaboration scenarios are described
in details in chapter 3.
An input for an agent is of the form of an IE-graph being a symbolic representation of a hand posture. A recognition of a hand posture is made with parsing
of a received IE-graph (on the basis of an ETPL(k) graph grammar associated
with the agent). The result is outputted to the control agent (see: chapter 3).
When an input IE-graph cannot be recognized by the parser, then the agent
starts a collaboration with other syntactic pattern recognition-based agents (via
collaboration module). The agent sequentially passes the graph to other agents
asking for its recognition until it gets a positive answer, i.e. a result of the
recognition.
Syntactic pattern recognition-based agents are provided with a self-learning
mechanism. Learning is made by a continuous accumulation of knowledge concerning results of the collaboration with other syntactic pattern recognitionbased agents.
Each agent has its own collaboration knowledge base. It is built in the form of
the following table.
Table 1. Collaboration knowledge base of an agent
Agent
id.
A 01
A 02
A 03
...

Technical
(communication)
information
active, port: xxx
inactive, port: yyy
active, port: zzz
...

Number
of queries
2
3
10
...

Number
of positive
answers
1
0
8
...

Percentage
of positive
answers
50%
0%
80%
...

Information about collaboration with a particular agent is stored in the line
of the table. The ﬁrst column of the table contains technical information needed
to communicate with a given agent. The second one contains the number of all
queries send to a given agent. The third column contains the number of queries
which returned a positive answer (a hand posture has been recognized). The last
column contains the percentage of positive answers in case of a given agent.
The table is updated each time the agent asks for the help of another syntactic
pattern recognition-based agent. The knowledge included in the table is a basis
for a collaboration strategy of the particular agent. A collaboration strategy is
described in the next chapter.

820

M. Flasi´
nski, J. Jurek, and S. My´sli´
nski

At the end of this section, we would like to underline the autonomy and prosocial behavior of the syntactic pattern-recognition based agents. Therefore, let
us discuss how the BDI standards (Belief-Desire-Intention) are embedded in the
agents.
– Belief. The belief of an agent is represented by the collaboration knowledge
base. Let us notice that the base can be changed. It reﬂects the fact that
what an agent believes may not necessarily be true (it may change in the
future).
– Desires. The only desire (goal) of an agent is to recognize a hand posture
(being the input data). An agent tries to accomplish the goal by itself or in
collaboration with other agents.
– Intentions. The intention of an agent is to recognize a hand posture as quick
as possible. If its own parsing algorithm fails, then it decides which other
agent is ”the best” to cooperate with. The decision is based on the information stored in the collaboration knowledge base (see: section 3.1).

3

Architecture of the Multi-agent System and Scenarios
of its Functioning

An architecture of the multi-agent system recognizing hand postures is presented
in Fig. 3.
Let us assume that there are n syntactic pattern recognition-based agents,
where each agent is responsible for recognizing hand postures performed in a speciﬁc manner. The multi-agent system consists of: several active syntactic pattern
Active syntactic pattern
recognition-based agents

e
ag d
Im h a n e
r
a
o f ostu
p

Syntactic Pattern
Recognition-Based
Agent

Image
Preprocessing
Agent

Syntactic Pattern
Recognition-Based
Agent

nd
H a re
stu r n
po ntou tatio
co sen
e
pr
re

Syntactic Pattern
Recognition-Based
Agent
Symbolic Description
Generation Agent

c
oli n e
mb tio tur
Sy crip pos
s
)
de and aph
r
a h (a g

of

Syntactic Pattern
Recognition-Based
Agent

Syntactic Pattern
Recognition-Based
Agent

Control Agent

d
i z e re
gn
c o stu
R e d po
n
ha

Syntactic Pattern
Recognition-Based
Syntactic Pattern
Recognition-Based Agent
Agent
Syntactic PatternSyntactic Pattern
Recognition-Based
Recognition-Based
Agent
Agent
Syntactic
Pattern
Syntactic Pattern
Recognition-Based
Recognition-Based
Agent
Agent
Inactive syntactic pattern
recognition-based agents

Fig. 3. Architecture of the multi-agent system

Multi-agent System for Recognition of Hand Postures

821

recognition-based agents, the remaining inactive syntactic pattern recognitionbased agents, the control agent, the image preprocessing agent and the symbolic
description generation agent (the last two agents are responsible for preliminary
phases of image processing that have been discussed in section 2.1).
Active agents are running at processors available for the system. All active
agents can communicate with each other. Inactive agents are not allocated to
the processors. They wait to be activated by the control agent.
The control agent is responsible for the following tasks:
– a communication with the ”outside world” (i.e. collecting hand postures to
be recognized, and outputting the results of a recognition),
– an allocation of syntactic pattern recognition-based agents to the processors,
– a communication with syntactic pattern recognition-based agents (a distribution of hand posture IE-graph representations among agents, and gathering
results of a recognition),
– an evaluation of a performance of syntactic pattern recognition-based agents
and a re-allocation of agents (as a consequence of the evaluation).
In order to perform all tasks mentioned above, the control agent has its own
collaboration knowledge base, which is constructed in the same way like the one
of a syntactic pattern recognition-based agent (see: Table 1). However, a scenario
of supplying the base with new information is diﬀerent from that of syntactic
pattern recognition-based agents.
Now, let us present functioning of the system. Initially, the control agent
starts as much syntactic pattern recognition-based agents as it is possible in the
system. Let m is a number of such agents. Then, the control agent initializes its
own collaboration knowledge base and the bases of all active agents (providing
information on technical ways of a communication — see: column 2 in Table 1).
In the next step, the control agent begins to receive data from the ”outside
world”. The data are consecutive IE-graph representations of hand postures to
be recognized. The agent distributes m hand postures among active syntactic
pattern recognition-based agents and waits for their response. The remaining
received hand postures are buﬀered in the FIFO (ﬁrst-in ﬁrst-out) structure.
In the next two sections we discuss a further functioning of syntactic pattern
recognition-based agents as well as a way of evaluating a performance of these
agents and re-allocating these agents made by the control agent.
3.1

Functioning of Syntactic Pattern Recognition-Based Agents

There are two following scenarios of functioning of a syntactic pattern
recognition-based agent.
Scenario 1. A request to recognize a hand posture is made by the control agent.
Firstly, an agent tries to recognize a hand posture itself. An analysis of the
hand posture is made by a parser of the agent. If a result of the analysis is
positive (the hand posture is recognized), the agent returns information to the
control agent which passes it to the ”outside world”. If the result is negative (the

822

M. Flasi´
nski, J. Jurek, and S. My´sli´
nski

hand posture cannot be recognized), the agent starts a collaboration with other
syntactic pattern recognition-based agents.
A strategy of a collaboration is straightforward. The agent sorts its collaboration knowledge base accordingly to a percentage of positive answers given by
other agents (see: column 4 in Table 1). A request to recognize a hand posture
is ﬁrstly sent to the ”best rated” active agent. If an answer is negative, the request is directed to the next active agent in ranking, and so on. A procedure
is repeated until the agent gets a positive answer or all active agents have returned negative answers. During this process the agent collects all information
about the collaboration in its knowledge base. Finally, information concerning
the responses of the collaborating agents is passed to the control agent.
If a positive answer is ﬁnally achieved, it ends the scenario. Otherwise, the
agent asks the control agent to activate the remaining agents (which are now in
an inactive state) and a recognition process starts again.
Scenario 2. A request to recognize a hand posture is made by another syntactic
pattern recognition-based agent.
The agent tries to recognize a hand posture itself, and returns an answer (positive
or negative) to an agent that has made the request. In this scenario the agent
does not start any collaboration with other agents.
3.2

Functioning of the Control Agent

There are two following scenarios of functioning of the control agent.
Scenario 1. A re-allocation as a result of an evaluation of syntactic pattern
recognition-based agents.
This is a typical scenario. After receiving an answer from a syntactic pattern
recognition-based agent, the control agent updates its collaboration knowledge
base, and checks percentages of positive answers for each active agent (in this
way the performance of each active agent is evaluated). If there is an active agent
A which rank is below a rank of the best inactive agent N , then A is replaced
with N . It means that now A agent becomes inactive, and N agent becomes
active and it starts running at a given processor.
Scenario 2. A re-allocation as a result of the lack of a recognition.
The second scenario takes place, if a hand posture cannot be recognized by
any active agent in the system. In such an unusual situation, the control agent
replaces all active agents with the ”best” inactive agents.

4

Concluding Remarks

A multi-agent system for an identiﬁcation of hand postures of the Polish Sign
Language has been implemented on the basis of a syntactic pattern recognition
approach discussed in the paper. Experimental testing (more than 700 tests) has

Multi-agent System for Recognition of Hand Postures

823

revealed its good characteristics. The average recognition of a hand posture takes
0.13 s (C++, Intel Core Duo, 1.83 GHz, 1GB RAM), and a recognition rate is
of 95%. Including examples of a hand posture performance negligence resulting
from speciﬁc (incorrect) styles of signing to a sample set makes a graph grammar
generating this set very complex and diﬃcult to be maintained.
The main advantage of the use of a multi-agent system approach presented
in the paper consists in a possibility of dividing the graph grammar generating IE-graph representations of hand postures into several sub-grammars. It, in
turns, allows us to handle a problem of a complexity of a control table of the
ETPL(k) parser [4]. Such a distributed control table is, obviously, much easier
to be maintained with the grammatical inference method [10].
The multi-agent approach not only inﬂuences the possibility of constructing
a suitable graph grammar (the quality aspect of the system), but also the eﬃciency of the system. Experiments performed on both single-agent system and
4-agent system show ca. 28% increase in time eﬃciency in favor of the multiagent approach.
There are self-learning mechanisms embedded in a system deﬁned in such a
way. Firstly, the control agent learns, which syntactic pattern recognition-based
agents provide the best results in case of a particular signer performing hand
postures (such agents should use our computing resources ﬁrstly, in case of a
given signer). Secondly, each syntactic pattern recognition-based agent learns
which agents are the best in the collaboration. (It means that the agents can
learn the best strategies of a recognition of hand postures). As we have already
noticed, styles of showing postures can be combined. It means that an agent
that is the best one in a given collaboration is not necessarily the best agent in
the global ranking.
A syntactic pattern recognition method presented in the paper is the deterministic one. In case of hand posture images that are distorted (fuzzy), a
probabilistic or fuzzy graph grammars would give better recognition rates. It
would require to represent also a collaboration knowledge used by the system in
a probabilistics (or fuzzy) way. The results of a research into such an extension
of the method will be a subject of further publications.

References
1. Bauer, B., Kraiss, K.F.: Towards an automatic sign language recognition system
using subunits. In: Wachsmuth, I., Sowa, T. (eds.) GW 2001. LNCS, vol. 2298, pp.
64–75. Springer, Heidelberg (2002)
2. Flasi´
nski, M.: Parsing of edNLC-graph grammars for scene analysis. Pattern Recognition 21, 623–629 (1988)
3. Flasi´
nski, M., Kotulski, L.: On the use of graph grammars for the control of a
distributed software allocation. The Computer Journal 35, A165–A175 (1992)
4. Flasi´
nski, M.: On the parsing of deterministic graph languages for syntactic pattern
recognition. Pattern Recognition 26, 1–16 (1993)
5. Flasi´
nski, M.: Use of graph grammars for the description of mechanical parts.
Computer Aided Design 27, 403–433 (1995)

824

M. Flasi´
nski, J. Jurek, and S. My´sli´
nski

6. Flasi´
nski, M., Schaefer, R., Toporkiewicz, W.: Optimal stochastic scaling of CAE
parallel computations. In: Polkowski, L., Skowron, A. (eds.) RSCTC 1998. LNCS,
vol. 1424, pp. 557–564. Springer, Heidelberg (1998)
7. Flasi´
nski, M.: Power properties of NLC graph grammars with a polynomial membership problem. Theoretical Computer Science 201, 189–231 (1998)
8. Flasi´
nski, M., Jurek, J.: Dynamically programmed automata for quasi context sensitive languages as a tool for inference support in pattern recognition-based realtime control expert systems. Pattern Recognition 32, 671–690 (1999)
9. Flasi´
nski, M.: Automata-based multi-agent model as a tool for constructing
real-time intelligent control systems. In: Dunin-Keplicz, B., Nawarecki, E. (eds.)
CEEMAS 2001. LNCS, vol. 2296, pp. 103–110. Springer, Heidelberg (2002)
10. Flasi´
nski, M.: Inference of parsable graph grammars for syntactic pattern recognition. Fundamenta Informaticae 80, 379–413 (2007)
11. Hakeem, A., Shah, M.: Learning, detection and representation of multi-agent events
in videos. Artiﬁcial Intelligence 171, 586–605 (2007)
12. Holden, E.J., Owens, R.: Visual sign language recognition. In: Klette, R., Huang,
T.S., Gimel’farb, G. (eds.) Dagstuhl Seminar 2000. LNCS, vol. 2032, pp. 270–287.
Springer, Heidelberg (2001)
13. Hongeng, S., Nevatia, R.: Multi-agent event recognition. In: Proceedings of the
Eight International Conference on Computer Vision, Vancouver, Canada, July 07–
14, vol. 2, pp. 84–91 (2001)
14. Huang, T.S., Pavlovic, V.: Hand gesture modeling, analysis and synthesis. In: Int.
Workshop on Automatic Face and Gesture Recognition, Zurich, Switzerland (1995)
15. Julian, V., Carrascosa, C., Rebollo, M., Soler, J., Botti, V.: SIMBA: An approach
for Real-Time Multi-agent Systems. In: Escrig, M.T., Toledo, F.J., Golobardes,
E. (eds.) CCIA 2002. LNCS (LNAI), vol. 2504, pp. 282–293. Springer, Heidelberg
(2002)
16. Jurek, J.: Syntactic pattern recognition-based agents for real-time expert systems.
In: Dunin-Keplicz, B., Nawarecki, E. (eds.) CEEMAS 2001. LNCS, vol. 2296, pp.
161–168. Springer, Heidelberg (2002)
17. Jurek, J.: Grammatical inference as a tool for constructing self-learning syntactic
pattern recognition-based agents. In: Bubak, M., van Albada, G.D., Dongarra, J.,
Sloot, P.M.A. (eds.) ICCS 2008, Part III. LNCS, vol. 5103, pp. 712–721. Springer,
Heidelberg (2008)
18. Kr¨
uger, M., von der Malsburg, C., W¨
urtz, R.P.: Self-organized evaluation of dynamic hand gestures for sign language recognition. In: W¨
urtz, R.P. (ed.) Organic
Computing. Springer, Heidelberg (2008)
19. Negnevitsky, M.: Artiﬁcial Intelligence. A Guide to Intelligent Systems. AddisonWesley, Reading (2002)
20. Niederberger, C., Gross, M.: Hierarchical and heterogenous reactive agents for realtime applications. Computer Graphics Forum 22, 323–331 (2003)
21. Rodin, V., Benzinou, A., Guillaud, A., Ballet, P., Harrouet, F., Tisseau, J., Le
Bihan, J.: An immune oriented multi-agent system for biological image processing.
Pattern Recognition 37, 631–645 (2004)
22. Soto, I., Garijo, M., Iglesias, C.A., Ramos, M.: An agent architecture to fulﬁll
real-time requirements. In: Proceedings of the Fourth International Conference on
Autonomous Agents, Barcelona, Spain, June 03–07, pp. 475–482 (2000)
23. W¨
urtz, R.P. (ed.): Organic Computing. Springer, Heidelberg (2007)
24. Yang, X., Xing, Y., Nguyen, A.: A Web-Based Face Recognition System Using
Mobile Agent Technology. In: The 8th Australian World Wide Web Conference
(2002)

