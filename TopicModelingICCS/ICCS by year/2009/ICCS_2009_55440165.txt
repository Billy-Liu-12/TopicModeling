New Optimal Load Allocation for Scheduling
Divisible Data Grid Applications
M. Othman , M. Abdullah, H. Ibrahim, and S. Subramaniam
Department of Communication Technology and Network,
University Putra Malaysia, 43400 UPM Serdang, Selangor D.E., Malaysia
mothman@fsktm.upm.edu.my, monabdullah@hotmail.com

Abstract. In many data grid applications, data can be decomposed into
multiple independent sub-datasets and distributed for parallel execution
and analysis. This property has been successfully employed by using Divisible Load Theory (DLT), which has been proved as a powerful tool for
modeling divisible load problems in data-intensive grid. There are some
scheduling models have been studied but no optimal solution has been
reached due to the heterogeneity of the grids. This paper proposes a new
model called Iterative DLT (IDLT) for scheduling divisible data grid applications. Recursive numerical closed form solutions are derived to find
the optimal workload assigned to the processing nodes. Experimental results show that the proposed IDLT model obtains better solution than
other models (almost optimal) in terms of makespan.
Keywords: Divisible Load Theory, Data Grid, Load Balancing.

1

Introduction

In the last decade, data grids have increasingly become popular for a wide range
of scientiﬁc and commercial applications [1]. Load balancing and scheduling play
a critical role in achieving high utilization of resources in such environments [2].
Scheduling an application is signiﬁcantly complicated and challenging because
of the heterogeneous nature of a grid system. Grid scheduling is deﬁned as the
process of making scheduling decisions involving allocating jobs to resources over
multiple administrative domains [8,9]. Most of the scheduling strategies try to
reduce the makespan or the maximum completion time of the task which is
deﬁned as the diﬀerence between the time when the job was submitted to a
computational resource and the time it completed. makespan also includes the
time taken to transfer the data to the point of computation if that is allowed by
the scheduling strategy [5].
In other hand, in many data intensive grid applications, data can be decomposed into multiple independent sub datasets and distributed for parallel
The author is also an associate researcher at the Lab of Computational Science
and Informatics, Institute of Mathematical Research (INSPEM), University Putra
Malaysia.
G. Allen et al. (Eds.): ICCS 2009, Part I, LNCS 5544, pp. 165–174, 2009.
c Springer-Verlag Berlin Heidelberg 2009

166

M. Othman et al.

execution and analysis. High Energy Physics (HEP) experiments fall into this
category [7]. HEP data are characterized by independent events, and therefore
this characteristic can be exploited when parallelizing the analysis of data across
multiple sites. In [11], the DLT paradigm has emerged as a powerful tool for modelling data-intensive computational problems incorporating communication and
computations issues [5]. An example of this direction is the work by [3] where the
DLT is applied to model the grid scheduling problem involving multiple sources
to multiple sinks. In that model, they did not consider the communication time.
Whereas, the scheduling in grid applications must consider communication and
computation simultaneously to achieve high performance. Some related materials to the problem addressed in this paper can be found in [4,7,8,9,11].

2

Scheduling Model

We consider the problem of scheduling large-volume loads (divisible loads) within
in multiple sites. Communication is assumed to be predominant between such
cluster nodes and is assumed to be negligible within a cluster node [3,4]. This
section describes the scheduling model, the notations, the cost model, and the
optimality criterion that are used in our research.
We use the scheduling model that was used by [3,4,8]. It can be described as
follows. The target data intensive applications model can be decomposed into
multiple independent sub tasks and executed in parallel across multiple sites
without any interaction among sub tasks [5]. Lets consider job decomposition
by decomposing input data objects into multiple smaller data objects of arbitrary
size and processing them on multiple virtual sites. For example in theory, the
HEP jobs are arbitrarily divisible at event granularity and intermediate data
product processing granularity. Assume that a job requires a very large logical
input data set D consists of N physical datasets and each physical dataset (of
size Lk ) resides at a data source (DSk , for all k = 1, 2, . . . , N ) of a particular
site. Figure 1 shows how D is decomposed onto networks and their computing
resources.
The scheduling problem is to decompose D into datasets (Di for all i =
1, 2, . . . , M ) across M virtual sites in a Virtual Organization given its initial
physical decomposition. We assume that the divisible data can be analyzed at
any site.
2.1

Notations and Definitions

All notations and their deﬁnitions used throughout this paper are shown in
Table 1.
2.2

Cost Model

The execution time cost (Ti ) of a subtask allocated to the site i and the turn
around time (TT urn Around T ime ) of a job J can be expressed as follows

New Optimal Load Allocation for Scheduling Divisible Data

167

Fig. 1. Data decomposition and their processing

Table 1. Notation and Definition
Notation
M
L
αi
Li
wj
Z ini
Z outi
Ti

Definition
The total number of nodes in the system
The loads in data file
The fraction of load that node i will receive from the data file
The amount of load that node i will receive from the data file
The inverse of the computing speed of node i
The link between node i and the data source
The link between node i and the aggrator
The processing time in node i

Fig. 2. The communication and computation of sources within the system (optimal
case)

168

M. Othman et al.

Ti = Tinput

cm (i)

+ Tcp (i) + Toutput

cm (i, d)

and
TT urn

N

Around T ime

= max{Ti },
i=1

respectively. The input data transfer Tinput cm (i), computation Tcp (i), and output data transfer to the client at destination site d, Toutput cm (i, d) are presented
as
1
Tinput cm (i) = Li · , Tcp (i) = Li · wi · ccRatio
Zi
and
Toutput

cm (i, d)

= f (Li ) · Zid

respectively. Where Li = L · αi and the function f (di ) is an output data size
and ccRatio is the non-zero ratio of computation and communication. The turn
around time of an application is the maximum among all the execution times of
the sub tasks.
The problem of scheduling a divisible job onto M sites can be stated as deciding
the portion of original workload (D) to be allocated to each site, that is, ﬁnding
a distribution of αi which minimizes the turn around time of a job. The proposed
model uses this cost model when evaluating solutions at each generation.
2.3

Optimality Criterion

In all literatures related to divisible load scheduling [7,9], an optimality criterion
is used to derive an optimal solution which stated as follows. It states that in order
to obtain an optimal processing time, it is necessary and suﬃcient that all the sites
that participate in the computation must stop at the same time. Otherwise, load
could be redistributed to improve the processing time. The timing diagram for this
distributed system in optimal case is depicted in Fig. 2.

3

Proposed IDLT Model

The load scheduling problem is to decompose D into datasets (Di for all i =
1, 2, . . . , M ) across M virtual sites in a Virtual Organization given its initial
physical decomposition. This model includes two steps
3.1

Initial Solution

The proposed model will start from a good initial solution. ADLT and A2 DLT
models will be used for this purpose. The best solution (minimum makespan)
will be considered as an initial solution of the iterative model. As it is explained
in [8,9,11], ADLT and A2 DLT models produced good results for computation
and communication intensive applications, respectively.

New Optimal Load Allocation for Scheduling Divisible Data

3.2

169

The Iterative Model

The optimality criterion that discussed in section 2.3 will be used in the design
of the load distribution strategy. The IDLT model involves the following steps
1.
2.
3.
4.
5.
6.

First, we divide the load using one of the adaptive DLT models.
Calculate the makespan using the cost model.
If all nodes ﬁnish at the same time, go to step 8 else go to step 4.
Then, we calculate the summation (Sum) of the processing time of the nodes.
Next, we calculate the average time by avg = Sum/M .
After that, we redistribute the load depending on the average (avg) based on
the iterative numerical equation that will be discussed later in this section.
7. Go to step 2
8. The current time is the ﬁnal makespan.
9. End
Here, we will discuss step by step the derivation of a closed form equation
by which one can calculate the optimal fraction of the load that has to be
assigned to each processing node in order to achieve the minimum makespan
and the optimal data allocation for each processor. The processing nodes (wi ),
communication links (Zi )and applications types (ccRatio) were assumed to have
diﬀerent values.
After we calculate the makespan as an initial solution to the IDLT model,
M
we will compute the i=1 Ti where M is the number of the processing nodes.
Based on cost model, we have
Ti = Li · z ini + wi · Li · ccratio + Li · z outi

(1)

where z ini and z outi is the input communication time and output communication time of link i, respectively. Then, compute the average of completion time
as
M
Ti
(2)
avg = i=1 .
M
In any iteration, the makespan of any nodes must equal to (avg) in order to get
the optimal solution. It means that, the load is distributed among the processing
node M equally. While the average time is the processing time of load α that is
calculated by (1), we can recalculate the amount of α if we have the (avg). In
general, if avg is
avg = α · z + α · w
(3)
The load fraction α can be calculated by (4),
avg
(4)
z+w
In this case, for any iteration, after we calculate the time average of processing
any load, we can calculate the amount of this load. Furthermore, if the processing
time of the ﬁrst node to process α1 is
α=

avg = α1 · z in1 + α1 · w1 · ccRatio + α1 · z out1

(5)

170

M. Othman et al.

The α1 will be calculated by:
α1 =

avg
z in1 + (w1 · ccRatio) + z out1

(6)

Consequently, the α2 of the second node will be calculated as
α2 =

avg
z in2 + (w2 · ccRatio) + z out2

(7)

Finally, the αM of the Mth node will be
αM =

z inM + (wM

avg
· ccRatio) + z outM

(8)

Equation (8) is correct only in the last iteration (when we get the optimal solution). But in the ﬁrst iteration, the last node will take the rest of the load only
as
(9)
αM = (1 − (α1 + α2 + · · · + αM−1 )) · L
There are M -1 equations. An additional equation is called a normalization equation, which states that the summation of the all the allocation fractions should
be 1.
(10)
α1 + α2 + · · · + αM = 1
The load of the last node does not equal the load that produces the (avg) time.
Thats means, the last node still does not take the optimal load. Here, we will
compute the new makespan (the makespan will be calculated by cost model
that discussed in Section 2.2 every iteration).
Consequently, we will carry out these steps in the second iteration. In this
iteration, the makespan will be reduced but still not optimal. Therefore, we will
carry out these steps until certain termination condition happens. The termination condition here is the optimality criterion. All nodes must ﬁnish the load
processing at the same time.
The IDLT model for single source produces almost optimal solution after
some iterations. There is a very small diﬀerent among the nodes processing time
(small fractions). In this model, all nodes will take the new load based on the
new average. It means that all nodes will ﬁnish at the same time. For the last
node will take the rest of load without considering the average. For the next
iteration, the new average will be reduced. The last node will take more load
than previous iteration. After some iterations the last node will ﬁnish as same
time as the others.

4

Experimental Results

To measure the performance of the proposed IDLT model against CDLT, ADLT
and A2 DLT models, randomly generated experimental conﬁgurations were used
[5,8,9]. The estimated expected execution time for processing a unit dataset on

New Optimal Load Allocation for Scheduling Divisible Data

171

Table 2. Results IDLT Model: Step-by-Step
Steps
0
5
10
11

Node 1
5643.84
1822.61
1799.71
1799.49

Node 2
1440.41
1822.61
1799.71
1799.49

Node 3
2993.02
1822.61
1799.71
1799.49

Node 4
843.48
1822.61
1799.71
1799.49

Node 5
1108.35
1757.71
1798.61
1799.00

Fig. 3. Comparison of various iterations for IDLT model, (a) initial step, (b) and (c)
intermediate steps, and (d) final step

each site, the network bandwidth between sites, input data size, and the ratio
of output data size to input data size were randomly generated with uniform
probability over some predeﬁned values. The network bandwidth between sites
is uniformly distributed between 1 Mbps and 10 Mbps.
We examined the overall performance of each model by running them under
100 randomly generated Grid conﬁgurations. We varied the parameters, ccRatio
(0.001 to 1000), rcb (10 to 500), and M (1 to 100). Thus, from series of experiments, it can be concluded that the IDLT gives an optimal solution and all nodes
stop at the same time.
Let considers the system and loads with processing nodes M =5 and ccRatio
=0.001, respectively. Using the IDLT model, we have the experimental results as
shown in Table 2 and Fig. 3. In an initial solution, the maximum completion time
or makespan is 5643.84 seconds. It is reduced until makespan 1799 seconds. In
the last step, all nodes ﬁnished the processing at the same time (at 1799 Seconds).
Furthermore, when we increase the number of iteration, all nodes will ﬁnish at
almost the same time (1799.32 seconds) and it is improved approximately 68%.
Figure 3 showed that, the ﬁve processing nodes ﬁnish at almost same time. It
means that, in the last iteration, the load is distributed to the processing node
almost equally.

172

M. Othman et al.

Fig. 4. M akespan vs. ccRatio for CDLT, ADLT, A2 DLT and IDLT(M =100)

Fig. 5. M akespan vs. data file size for CDLT, ADLT, A2 DLT and IDLT(M =100 and
ccRatio=0.001)

To show how these models perform on diﬀerent type of application (diﬀerent
ccRatio=100), we executed the model and plotted all the results as shown in
Fig. 4. From the plotted graph, the IDLT model is the best for any type of
application. As expected, the IDLT model produce the almost optimal solution
from single source.
Diﬀerent size of data ﬁles are used considering large scale data grid. It is varied
from 1 GB to 1 TB. Figure 5 clearly showed that the IDLT model produce better
results for all sizes.
The convergence metric records how the initial makespan value minimized
during the iteration between the initial and optimal solutions. Figure 6 depicts the convergence of the models for the average out of ten executions for
when the ccRatio is equal to 1000. All models have same results, whereas
the result of IDLT model is signiﬁcantly reduced as the number of iteration
increased.

New Optimal Load Allocation for Scheduling Divisible Data

173

Fig. 6. Convergence for IDLT model for single source (ccRatio=1000))

5

Conclusion

In this paper, we have developed an eﬀective iterative model for optimal divisible
load allocation. The IDLT model is proposed for load allocation to processors
and links for scheduling divisible data grid applications. The experimental results
showed that the proposed IDLT model is capable of producing almost optimal
solution for single source scheduling. Hence, the proposed model can balance
the processing loads eﬃciently and can be embedded into the existing data grid
schedulers.

References
1. Tierney, B., Johnston, W., Lee, J., Thompson, M.: A Data Intensive Distributed
Computing Architecture for Grid Applications. Future Generation Computer Systems 16(5), 473–481 (2000)
2. Xiao, Q.: Design and Analysis of a Load Balancing Strategy in Data Grids. Future
Generation Computer Systems 16(23), 132–137 (2007)
3. Tang, M., Lee, B.-S., Tang, X., Yeo, C.-K.: The Impact of Data Replication on
Job Scheduling Performance in the Data Grid. Future Generation Computer Systems 22(3), 254–268 (2006)
4. Wong, H.M., Veeravalli, B., Dantong, Y., Robertazzi, T.G.: Data Intensive Grid
Scheduling: Multiple Sources with Capacity Constraints. In: Proceeding of the
IASTED Conference on Parallel and Distributed Computing and Systems, Marina
del Rey USA, 7-11 (2003)
5. Kim, S., Weissman, J.B.: A Genetic Algorithm Based Approach for Scheduling Decomposable Data Grid Applications. In: IEEE Proceeding of the International Conference on Parallel Processing, Washington DC, USA, vol. 1, pp. 406–413 (2004)
6. Venugopal, S., Buyya, R., Ramamohanarao, K.: A Taxonomy of Data Grids for
Distributed Data Sharing, Management and Processing. ACM Computing Surveys 38(1), 1–53 (2006)
7. Abraham, A., Buyya, R., Nath, B.: Nature’s Heuristics for Scheduling Jobs on
Computational Grids. In: Proceedings of 8th IEEE International Conference on
Advanced Computing and Communications, pp. 45–52 (2000)

174

M. Othman et al.

8. Othman, M., Abdullah, M., Ibrahim, H., Subramaniam, S.: Adaptive Divisible
Load Model for Scheduling Data-Intensive Grid Applications. In: Shi, Y., van Albada, G.D., Dongarra, J., Sloot, P.M.A. (eds.) ICCS 2007. LNCS, vol. 4487, pp.
446–453. Springer, Heidelberg (2007)
9. Othman, M., Abdullah, M., Ibrahim, H., Subramaniam, S.: A2 DLT: Divisible Load
Balancing Model for Scheduling Communication-Intensive Grid Applications. In:
Bubak, M., van Albada, G.D., Dongarra, J., Sloot, P.M.A. (eds.) ICCS 2008, Part
I. LNCS, vol. 5101, pp. 246–253. Springer, Heidelberg (2008)
10. Viswanathan, S., Veeravalli, B., Robertazzi, T.G.: Resource-Aware Distributed
Scheduling Strategies for Large-Scale Computational Cluster/Grid Systems. IEEE
Transaction of Parallel and Distributed Systems 18(10), 1450–1461 (2007)
11. Bharadwaj, V., Ghose, D., Robertazzi, T.G.: Divisible Load Theory: A New
Paradigm for Load Scheduling in Distributed Systems. Cluster Computing 6(1),
7–17 (2003)

