Non-splitting Tridiagonalization
of Complex Symmetric Matrices
W.N. Gansterer1 , A.R. Gruber2 , and C. Pacher3
1

University of Vienna, Research Lab Computational Technologies and Applications
wilfried.gansterer@univie.ac.at
2
University of Vienna, Institute for Theoretical Chemistry
agruber@tbi.univie.ac.at
3
Austrian Research Centers GmbH-ARC, Department of Safety & Security
christoph.pacher@arcs.ac.at

Abstract. A non-splitting method for tridiagonalizing complex symmetric (non-Hermitian) matrices is developed and analyzed. The main objective is to exploit the purely structural symmetry in terms of runtime
performance. Based on the analytical derivation of the method, Fortran implementations of a blocked variant are developed and extensively
evaluated experimentally. In particular, it is illustrated that a straightforward implementation based on the analytical derivation exhibits deﬁciencies in terms of numerical properties. Nevertheless, it is also shown
that the blocked non-splitting method shows very promising results in
terms of runtime performance. On average, a speed-up of more than three
is achieved over competing methods. Although more work is needed to
improve the numerical properties of the non-splitting tridiagonalization
method, the runtime performance achieved with this non-unitary tridiagonalization process is very encouraging and indicates important research
directions for this class of eigenproblems.
Keywords: Tridiagonalization, complex symmetric eigenvalue problems,
complex symmetric reﬂector.

1

Introduction

We discuss an algorithm for tridiagonalizing a complex symmetric (non Hermitian) matrix C ∈ Cn×n . This task is a central component in reduction methods
for solving the complex symmetric eigenvalue problem (EVP)
Cx = λx

with C ∈ Cn×n , C = C .

(1)

Problems of this type are a special case of general non Hermitian complex
eigenproblems. Although they do not occur as frequently in practice as real symmetric or complex Hermitian problems, there are many important applications
where they arise [1]. An example is the numerical solution of Maxwell’s equations
with complex material coeﬃcients (accounting for losses) and/or certain absorbing boundary conditions used in the simulation of optoelectronic devices [2].
G. Allen et al. (Eds.): ICCS 2009, Part I, LNCS 5544, pp. 481–490, 2009.
c Springer-Verlag Berlin Heidelberg 2009

482

W.N. Gansterer, A.R. Gruber, and C. Pacher

Especially for large n, it is pivotal to exploit the (non Hermitian) symmetry
present in problem (1) in order to be able to eﬃciently solve such problems.
Hardly any high quality software is available for complex symmetric eigenproblems. Only Qmrpack [3] contains an implementation of a complex symmetric Lanczos algorithm. General purpose state-of-the-art software libraries for
dense numerical linear algebra computations, such as the Blas [4] and Lapack [5] for sequential computations, or the parallel packages ScaLapack [6]
and Plapack [7], contain very few computational routines which are capable of
speciﬁcally exploiting complex symmetry. No such routine for the complex symmetric eigenvalue problem is currently available in these state-of-the-art software packages. Consequently, the currently most common strategy for solving
problems (1) is to ignore their special properties and to solve them with the
technology available for general non Hermitian problems (for example, using
the routine LAPACK/zgeev): The complex symmetric matrix C is ﬁrst reduced
to Hessenberg form using unitary transformations, from which eigenvalues and
eigenvectors are computed by applying standard methods for unsymmetric matrices. This strategy has obvious disadvantages in terms of computational eﬀort
and in terms of storage requirements.
The main objective of this paper is to investigate a non-splitting approach
for tridiagonalizing C and to compare it on the one hand to standard methods
for general non Hermitian eigenproblems, and on the other hand to the splitting
tridiagonalization method for complex symmetric matrices discussed earlier [2].
Related Work. Various projection methods for solving complex symmetric
EVPs have been proposed, for example, based on modiﬁcations of the nonHermitian Lanczos method [3,8,9], on subspace iteration [10], or on variants of
the Jacobi-Davidson method [11].
For dense matrices and/or if large parts of the spectrum are to be computed,
transformation methods (based on tridiagonalization) can be more eﬃcient [12].
For these methods, the tridiagonalization step tends to be a dominating part
in terms of arithmetic complexity and usually also computation time. Earlier
attempts were based on modifying the conventional Householder-based tridiagonalization for real symmetric or complex Hermitian matrices such that symmetry
is preserved for complex symmetric problems [13]. In [13], the Householder vector
is normalized using a quasi-inner product, which has several implications: The
normalization factor can become a negative or a complex number, and the resulting transformation matrices are not unitary. The idea of tridiagonalizing real
and imaginary part of C separately, connected by complex orthogonal transformations (called splitting method in the following) for tridiagonalizing a complex
symmetric matrix has been investigated in [14,2].
For computing eigenvalues and eigenvectors of the resulting tridiagonal complex symmetric problem, modiﬁcations of the QR algorithm [15,16] and the
routines cmtql1 and inverm [17] have been used.
In this paper, we investigate non-splitting methods as an alternative approach
for tridiagonalizing a complex symmetric matrix C. The basic concept is very
similar to the one mentioned in [13]. However, in [13] neither a discussion of

Non-splitting Tridiagonalization of Complex Symmetric Matrices

483

numerical properties (observed deﬁciencies in accuracy, special techniques for
overcoming them, etc.) nor a quantitative performance evaluation of this approach is given. We provide a comparison of this approach to the splitting method
in terms of numerical properties and runtime performance.
Synopsis. In Section 2 we review general properties of complex symmetric matrices and we summarize the splitting method introduced earlier. In Section 3, we
derive a non-splitting tridiagonalization method for complex symmetric matrices
and relate it to generalizations of unitary Householder reﬂectors. In Section 4, an
experimental evaluation of this non-splitting method and a comparison to other
approaches is summarized, and Section 5 contains conclusions and future work.

2

Background

Mathematically speaking, structural symmetry is not a very distinctive feature
of complex matrices, since every matrix A ∈ Cn×n is similar to a complex symmetric matrix [1]. In contrast to a real symmetric matrix, a complex symmetric
matrix A is not necessarily normal and not necessarily diagonalizable [1]. Nevertheless, the purely algebraic symmetry is of great interest for the development
of space- and time-eﬃcient algorithms. Obviously, half of the information in a
complex symmetric matrix is redundant, and eﬃcient algorithms should be able
to take advantage of this fact in terms of memory requirements as well as in
terms of computational eﬀort.
2.1

Complex Orthogonal Transformations

As a basic guideline, there are two conditions for any transformation used in the
tridiagonalization process of C: (i) It has to be a similarity transformation in order
to preserve the spectrum of C, and (ii) it has to be symmetry-preserving in order
to exploit the structural symmetry. Consequently, given a transformation matrix
G ∈ Cn×n , each transformation needs to be of the form GCG−1 in order to satisfy
the ﬁrst condition and of the form GCG in order to satisfay the second condition.
In summary, the basic transformation matrices used need to satisfy
GG = I,

(2)

which deﬁnes a complex orthogonal transformation [1] (COT) G. Note that G is
not unitary and in general G 2 > 1. Consequently, the application of complex
orthogonal transformations G potentially involves compromising numerical stability. In order to bound the numerical errors in transformation processes using
complex orthogonal matrices, their norms have to be monitored, and, if possible,
kept below some properly chosen threshold.
2.2

The Splitting Method

The splitting method, which has been introduced in [14], is based on separating
the tridiagonalization of the real part R of C from the tridiagonalization of the

484

W.N. Gansterer, A.R. Gruber, and C. Pacher

imaginary part S of C (R and S are both real symmetric matrices) as much as
possible. For example, the part below the subdiagonal of a column of R (say, of
length k) can be eliminated using a real orthogonal transformation matrix QR .
After that, a k − 1 part of the corresponding column of S can be eliminated
without causing any ﬁll-in in R using another real orthogonal matrix QI . Both
of these operations are performed in real arithmetic, and both transformation
matrices have norm one. Eventually, a single nonzero element below the subdiagonal in S remains to be eliminated. This operation has to be performed in
complex arithmetic, using a 2 × 2 complex orthogonal transformation matrix,
whose norm cannot be bounded a priori.
In [2], we have investigated numerical properties and runtime performance
of the splitting method for tridiagonalizing C, and we have pointed out some
algorithmic variants which have not been mentioned in [14]. Our experimental
results showed that the splitting method can achieve good numerical accuracy,
but the runtime performance achieved was often not better than the one achieved
with the routine zgeev from Lapack [5].

3

Non-splitting Tridiagonalization Methods

Non-splitting methods for tridiagonalizing C are characterized by the fact that,
in contrast to the splitting method, they do not split up C into its real and
imaginary parts but operate in complex arithmetic on the complex symmetric
matrix as a whole. The method investigated in this paper can be derived from an
old method proposed by La Budde [18] for tridiagonalizing any real unsymmetric
matrix. In the following, we ﬁrst brieﬂy review La Budde’s method and then show
how it can be modiﬁed to tridiagonalize a complex symmetric matrix.
3.1

La Budde’s Method

In order to eliminate a column vector c ∈ Rn−j below the subdiagonal and a
row vector b ∈ Rn−j right of the superdiagonal in an unsymmetric real n × n
matrix, La Budde [18] determined elimination vectors x, y ∈ Rn−j , such that the
matrices
Mα := In−j + αxy ,
Mβ := In−j + βxy ,

α = 0,
β = 0,

(3)
(4)

constitute a similarity transformation (Mα Mβ = In−j ) and eliminate all entries
except the ﬁrst one in the vectors c and b:
Mα c = τ1 e1 ,
bT Mβ = τ2 eT1 ,
where e1 = (1, 0, . . . , 0)T ∈ Rn−j . Carrying out this process over columns j =
1, 2, . . . , n − 2, the given matrix can be transformed to tridiagonal form.

Non-splitting Tridiagonalization of Complex Symmetric Matrices

485

It turns out that La Budde’s method breaks down when at some point in the
process s := b c = 0. La Budde suggested in [18] to avoid this breakdown by a
proper choice of the parameters α and β in (3) and (4). However, it was pointed
out in [19] that there are at least two categories of matrices where it is not possible to choose α and β such that recovery from s = 0 is possible. Remedies were
proposed for these cases. Parlett [20] has pointed out that La Budde’s procedure
applied to Hessenberg matrices is identical to well-known transformation methods. He also showed that for Hessenberg matrices s is invariant for all permissible
choices of α and β. Therefore, Hessenberg matrices form another class of matrices
where recovery from breakdown is not possible by manipulating α and β.
3.2

Adaptation for Complex Symmetric Matrices

In the complex symmetric case b, c, x, y are complex vectors and c = b, α = β,
x = y. Therefore, Mα = Mβ and Mα = MαT . This yields the following equations:
Mα = In−j + αxxT ,

α = 0,

Mα2 = In−j ,
M α c = τ e1 .

(5)
(6)
(7)

From (5) and (6) and from the fact that in the nontrivial case Mα = In−j we
can conclude α = −2/xT x and thus
Mα = In−j −

2
xxT .
xT x

(8)

Note that in the symmetric case Mα does in fact not depend on α any more and
thus we drop the index α in the following.
Now, the vector x has to be determined so that (7) is satisﬁed. From (7) we
obtain τ 2 = τ eT1 e1 τ = cT M T M c = cT c, where the last equation follows from
M T M = M M = I. Consequently
√
τ = ± cT c,
and the resulting vector

√
τ e 1 = ± cT c e 1 .

Thus, we have
√
M c = ± cT c e 1

⇔

c−

2
xT x

√
(xT c)x = ± cT c e1 ,

which we must solve for x. Note that x can be scaled by any (complex) number
a without changing M . If we scale x such that xT2 x (xT c) = 1 holds, then the
following solutions are easily found:
√
x = c ∓ cT c e 1 .

486

W.N. Gansterer, A.R. Gruber, and C. Pacher

Consequently, we obtain the following equations for the components of the elimination vector x:
√
(9)
x1 = c1 ∓ cT c = c1 − τ,
k = 2, . . . , n.
(10)
xk = ck ,
Note that this is analogous to the deﬁnition of the real Householder reﬂector.
This shows on the one hand that in the real symmetric case La Budde’s method
is identical to real Householder reﬂectors, and on the other hand that in the complex symmetric case it leads to a direct generalization of Householder reﬂectors
in complex arithmetic.
3.3

Numerical Properties

Since for a vector x ∈ Cn−j , x x = 0 is possible even if x = 0, (8) indicates
that ||M || ≥ 1 and that breakdown and numerical problems are possible. For
the splitting method, various recovery transformations for controlling and improving numerical accuracy have already been investigated [14]. Our derivation
above illustrates that the need for monitoring and improving numerical accuracy
also arises in the context of non-splitting methods. The investigation and development of suitable recovery transformations in this context is topic of ongoing
work. In the following section, we evaluate a straightforward implementation of
the basic non-splitting method based on (9) and (10).

4

Experimental Evaluation

For our experiments, we implemented the following routines in Fortran: zsytd2
performs an unblocked non-splitting tridiagonalization of a complex-symmetric
matrix C, zsytrd performs a blocked non-splitting tridiagonalization of complexsymmetric C, zunm2r2 performs an unblocked backtransformation of the eigenvectors of the tridiagonal matrix T to those of C, and zunmtr2 performs a blocked
backtransformation of the eigenvectors of the tridiagonal matrix T to those of
C. The routines compev [17] and inverm [17] were used for computing eigenvalues and corresponding eigenvectors of the complex symmetric tridiagonal matrix.
For comparison, the routine LAPACK/zgeev for general non Hermitian eigenvalue
problems was used.
The codes were run on a Sun Fire v40z with 4 dual-core Opteron 875 CPUs
(2.2 GHz) and 24 GB main memory. Suse Linux Enterprise Server 10, the GNU
Fortran 95 compiler, Lapack version 3.1.1 and Goto Blas 1.20 were used. The
test matrices were created randomly.
4.1

Numerical Accuracy

Denoting with (λi , xi ) the eigenpairs computed by LAPACK/zgeev, and with
˜i, x
(λ
˜i ) the eigenpairs computed by non-splitting tridiagonalization followed by

Non-splitting Tridiagonalization of Complex Symmetric Matrices

487

Numerical Accuracy
1

E (non-splitting)
R (non-splitting)
E (splitting)
R (splitting)
max R (LAPACK/zgeev)

−2

10

10−4
10−6
10−8
10−10
10−12
10−14

100

500

1000

1500

2000

2500

3000

Dimension n

Fig. 1. Residuals and eigenvalue errors for diﬀerent complex symmetric eigensolvers

compev and inverm, an average eigenvalue error E and an average residual error
R have been computed according to
E := averagei

˜ i − λi |
|λ
,
|λi |

R = averagei

˜i In )˜
||(A − λ
xi ||2
,
||A||2

i ∈ {1, . . . , n} .

Fig. 1 illustrates the experimental results. It has already been shown in [2] that
the error introduced by the splitting tridiagonalization (without the solver for the
tridiagonal problem) is only about two orders of magnitudes higher than the one
of LAPACK/zgeev. The ﬁrst straightforward implementation of the non-splitting
method used here looses some more orders of magnitude in accuracy compared
to the splitting method. (Note that for LAPACK/zgeev the maximum residuals
are shown, not their averages.) This indicates the need for improvements of the
numerical properties of the non-splitting tridiagonalization approach, as already
mentioned in Section 3.3. Corresponding eﬀorts are work in progress.
4.2

Runtime Performance

In [2] we have already illustrated that with the Goto Blas, LAPACK/zgeev tends
to outperform the splitting method in terms of runtime performance. Thus, in
Fig. 2 we compare normalized runtimes of blocked non-splitting tridiagonalization followed by compev, inverm and blocked backtransformation (the sum of
these runtimes is denoted by nonsplit) to normalized runtimes of LAPACK/zgeev.
Fig. 2 illustrates the big potential of non-splitting tridiagonalization: Its runtime
performance is signiﬁcantly better than the one of LAPACK/zgeev and consequently also than the one of the splitting method. Despite a similar asymptotic
behavior, the non-splitting approach achieves on average a speed-up of a little
more than three over LAPACK/zgeev.

488

W.N. Gansterer, A.R. Gruber, and C. Pacher
Normalized Runtimes
60
LAPACK/zgeev
nonsplit
zsytrd
zunmtr2
compev

50
40
30
20
10
0
100

500

1000

2000

3000

Dimension n

Fig. 2. Normalized runtimes (T (n)/n2 ) of complex symmetric eigensolver (nonsplit)
based on non-splitting tridiagonalization, of its components, and of LAPACK/zgeev

This underlines the importance of eﬀorts in improving the numerical properties of the non-splitting approach. If they can be improved by some properly
chosen recovery transformations in cases where the naive implementation used
here suﬀers from numerical inaccuracies, then a central building block can be
established for a very competitive method for solving dense complex symmetric
eigenproblems (1).

5

Conclusions and Future Work

A non-splitting tridiagonalization process for complex symmetric matrices which
can be derived from a method for tridiagonalizing unsymmetric matrices originally suggested in [18] has been investigated. It has been shown that this approach leads to a symmetry preserving generalization of complex Householder
reﬂectors. The non-splitting tridiagonalization process and a complex symmetric
eigensolver based on it have been analyzed in terms of numerical properties and
runtime performance.
Compared to the standard Lapack routine for general non Hermitian eigenproblems, LAPACK/zgeev, and to the splitting method proposed and analyzed
earlier [14,2], the naive straightforward implementation of the non-splitting approach exhibits a loss of numerical accuracy (measured in terms of eigenvalue
error and in terms of residual error). Potential sources for this loss of accuracy
are clear, and work on improving the numerical properties of the non-splitting
method is in progress. In terms of runtime performance, a blocked non-splitting
approach shows very promising results. In the experiments summarized in this
paper, on average a speed-up of more than three could be achieved over competing methods. If progress can be made in the numerical aspects, then non-splitting

Non-splitting Tridiagonalization of Complex Symmetric Matrices

489

methods have the potential to become a standard approach for tridiagonalizing
complex symmetric matrices.
The work summarized here motivates various further research directions. As
mentioned before, the improvement of the numerical properties of non-splitting
tridiagonalization is of utmost importance. Once this aspect is sucessfully addressed, it should be possible to develop parallelization strategies analogously
to Householder-based tridiagonalization methods for real symmetric or complex
Hermitian matrices.

References
1. Horn, R.A., Johnson, C.R.: Matrix Analysis. Cambridge University Press, Cambridge (1985)
2. Gansterer, W.N., Schabauer, H., Pacher, C., Finger, N.: Tridiagonalizing complex
symmetric matrices in waveguide simulations. In: Bubak, M., van Albada, G.D.,
Dongarra, J., Sloot, P.M.A. (eds.) ICCS 2008, Part I. LNCS, vol. 5101, pp. 945–954.
Springer, Heidelberg (2008)
3. Freund, R.W., Nachtigal, N.M.: QMRPACK: a package of QMR algorithms. ACM
Trans. Math. Softw. 22(1), 46–77 (1996)
4. Dongarra, J.J., Du Croz, J., Duﬀ, I.S., Hammarling, S.: A set of level 3 basic linear
algebra subprograms. ACM Trans. Math. 16, 1–17, 18–28 (1990)
5. Anderson, E., Bai, Z., Bischof, C.H., Blackford, S., Demmel, J.W., Dongarra, J.J.,
Du Croz, J., Greenbaum, A., Hammarling, S., McKenney, A., Sorensen, D.C.:
Lapack Users Guide, 3rd edn. SIAM Press, Philadelphia (1999)
6. Blackford, L.S., Choi, J., Cleary, A., D’Azevedo, E., Demmel, J.W., Dhillon, I.,
Dongarra, J.J., Hammarling, S., Henry, G., Petitet, A., Stanley, K., Walker, D.,
Whaley, R.C.: ScaLapack Users’ Guide. SIAM Press, Philadelphia (1997)
7. van de Geijn, R.: Using PLapack: Parallel Linear Algebra Package. The MIT Press,
Cambridge (1997)
8. Freund, R.W., Gutknecht, M.H., Nachtigal, N.M.: An implementation of the lookahead Lanczos algorithm for non-hermitian matrices. SIAM J. Sci. Comput. 14(1),
137–158 (1993)
9. Cullum, J.K., Willoughby, R.A.: A practical procedure for computing eigenvalues
of large sparse nonsymmetric matrices. In: Cullum, J.K., Willoughby, R.A. (eds.)
Proceedings of the IBM Europe Institute Workshop on Large Scale Eigenvalue
Problems, pp. 193–223. North-Holland, Amsterdam (1986)
10. Leung, A.Y.T.: Subspace iteration for complex symmetric eigenproblems. J. Sound
Vibration 184(4), 627–637 (1995)
11. Arbenz, P., Hochstenbach, M.E.: A Jacobi–Davidson method for solving complex
symmetric eigenvalue problems. SIAM J. Sci. Comput. 25(5), 1655–1673 (2004)
12. Bai, Z., Demmel, J., Dongarra, J.J., Ruhe, A., van der Vorst, H. (eds.): Templates
for the Solution of Algebraic Eigenvalue Problems: A Practical Guide. SIAM Press,
Philadelphia (2000)
13. Ohnami, K., Mikami, Y.: Resonance scattering in a two-dimensional non-integrable
system. J. Phys. A 25, 4903–4912 (1992)
14. Bar-On, I., Ryaboy, V.: Fast diagonalization of large and dense complex symmetric matrices, with applications to quantum reaction dynamics. SIAM J. Sci.
Comput. 18, 1412–1435 (1997)

490

W.N. Gansterer, A.R. Gruber, and C. Pacher

15. Cullum, J.K., Willoughby, R.A.: A QL procedure for computing the eigenvalues of
complex symmetric tridiagonal matrices. SIAM J. Matrix Anal. Appl. 17, 83–109
(1996)
16. Luk, F., Qiao, S.: Using complex-orthogonal transformations to diagonalize a complex symmetric matrix. In: Luk, F.T. (ed.) Advanced Signal Processing: Algorithms, Architectures, and Implementations VII, Proc. SPIE, vol. (3162), pp. 418–
425 (1997)
17. Cullum, J.K., Willoughby, R.A.: Lanczos Algorithms for Large Symmetric Eigenvalue Computations, vol. 1: Theory, vol. 2: Programs. Birkh¨
auser, Boston (1985)
18. La Budde, C.D.: The reduction of an arbitrary real square matrix to tridiagonal
form using similarity transformations. Math. Comp. 17, 433–437 (1963)
19. Wang, H.H., Gregory, R.T.: On the reduction of an arbitrary real square matrix
to tridiagonal form. Math. Comp. 18, 501–505 (1964)
20. Parlett, B.N.: A note on La Budde’s algorithm. Math. Comp. 18, 505–506 (1964)

