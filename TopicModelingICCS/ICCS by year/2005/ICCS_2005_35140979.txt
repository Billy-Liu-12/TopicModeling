Density-Based Spatial Outliers Detecting
Tianqiang Huang1, Xiaolin Qin1, Chongcheng Chen2, and Qinmin Wang2
1

Department of Computer Science and Engineering,
Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China
tianqianghuang@163.com
2
Spatial Information Research Center in Fujian Province,
Fuzhou, 350002, China
http://www.sirc.gov.cn/

Abstract. Existing work in outlier detection emphasizes the deviation of
non-spatial attribution not only in statistical database but also in spatial database.
However, both spatial and non-spatial attributes must be synthetically considered
in many applications. The definition synthetically considered both was presented
in this paper. New Density-based spatial outliers detecting with stochastically
searching approach (SODSS) was proposed. This method makes the best of
information of neighborhood queries that have been detected to reduce many
neighborhood queries, which makes it perform excellently, and it keeps some
advantages of density-based methods. Theoretical comparison indicates our
approach is better than famous algorithms based on neighborhood query.
Experimental results show that our approach can effectively identify outliers and
it is faster than the algorithms based on neighborhood query by several times.

1 Introduction
A well-quoted definition of outliers is the Hawkin-Outlier [1]. This definition states
that an outlier is an observation that deviates so much from other observations as to
arouse suspicion that it was generated by a different mechanism. However, the notion
of what is an outlier varies among users, problem domains and even datasets[2]: (i)
different users may have different ideas of what constitutes an outlier, (ii) the same user
may want to view a dataset from different “viewpoints” and, (iii) different datasets do
not conform to specific, hard “rules” (if any).
We focus on outlier in spatial database, in which objects have spatial and non-spatial
attributions. Such datasets are prevalent in several applications. Existing work of
Multidimensional outlier detection methods can be grouped into two sub-categories,
namely homogeneous multidimensional and bipartite multi- dimensional methods [3].
The homogeneous multidimensional methods model data sets as a collection of points
in a multidimensional isometric space and provide tests based on concepts such as
distance, density, and convex hull depth. These methods do not distinguish between
spatial dimensions and attribute dimensions (non-spatial dimensions), and use all
dimensions for defining neighborhood as well as for comparison. Another
multidimensional outlier detection method is bipartite multidimensional test which is
designed to detect spatial outliers. They differentiate between spatial and non-spatial
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3514, pp. 979 – 986, 2005.
© Springer-Verlag Berlin Heidelberg 2005

980

T. Huang et al.

attributes. However, they defined outlier as “spatial outlier is spatially referenced
objects whose non-spatial attribute values are significantly different from those of other
spatially referenced objects in their spatial neighbor- hoods [3,4]”, which emphasizes
non-spatial deviation and ignores spatial deviation.
In some application, domain specialist needs detect the spatial objects, which have
some non- spatial attributes, deviation from other in spatial dimension. For example, in
image processing, detecting a certain type vegetable is anomaly in spatial distribution.
The vegetable type is non-spatial attribute, and the vegetable location means spatial
attributes. As another example, government wants to know middle incoming residents
distribution in geo-space. To detect outliers in these instances, spatial and non-spatial
attributes may be synthetically taken into account. For example, there are two type
objects in Fig. 1. The solid points and rings respectively represent two objects with
different non-spatial attribute, such as the solid objects represent one vegetable and the
rings are the other. All objects in Fig. 1 are one cluster when we didn’t consider
non-spatial attribute, but they would have different result when we took spatial and
non-spatial attribute into account. Apparently, when we focus solid objects, the solid
objects in C1 and C2 are clusters, and object a and b are outliers.

Fig. 1. An illumination example

We took into account of spatial and non-spatial attributes synthetically to define the
outliers. If the objects that have some non-spatial attributes are keep away from their
neighbor in spatial relation. We defined them outliers.
The main contributions of this paper are: (1) we propose a novel density-based
algorithm to detect it, which is the quicker than existing algorithms based on
neighborhood query. (2) We evaluate it on both theory and experiments, which
demonstrate that algorithm can detect outlier successfully with better efficiency than
other algorithms based on neighborhood query.
The remainder of the paper is organized as follows: In section 2, we discuss formal
definition of outliers. Section 3 presents the SODSS algorithm. Section 4 evaluates
performance of SODSS. Section 5 reports the experimental evaluation. Finally, Section
6 concludes the paper.

Density-Based Spatial Outliers Detecting

981

2 Density-Based Notion of Spatial Outliers
In this section we present the new definition of outlier, in which spatial and non-spatial
attributes were synthetically taken into account.
Given a dataset D, a symmetric distance function dist, parameters Eps and MinPts,
and variable attrs indicates the non-spatial attributes.
Definition 1. The impact neighborhood of a point p, denoted by INEps(p), is defined
as INEps(p) = {q D | dist(p, q) ≤ Eps and q.attrs satisfy C}.
Definition 2. The Neighbor of p is any point in impact neighborhood of p except p.
Definition 3. If a point’s impact neighborhood has at least MinPts points, the impact
neighborhood is dense, and the point is core point.
Definition 4. If a point’s impact neighborhood has less than MinPts points, the impact
neighborhood is not dense. If a point is a neighbor of core point, but his neighborhood
is not dense, the point is border point.
Definition 5. If a point is core point or border point, and it near a border point p, the
point is near-border point of p.
Definition 6. A point p and a point q are directly density-reachable from each other if
(1) p INEps(q), |INEps(q)| ≥ MinPts or (2) q INEps(p), |INEps(p)| ≥ MinPts.
Definition 7. A point p and a point q are density-reachable from each other, denoted
by DR(p, q), if there is a chain of points p1,…,pn, p1=q, pn= p such that pi+1 is directly
density-reachable from pi for 1 ≤ i ≤ n-1.
Definition 8. A cluster C is a non-empty subset of D satisfying the following
condition: p, q D: if p C and DR(p, q) holds, then q C.
Definition 9. Outlier p is not core object or border object, i.e., p satisfying the
following conditions: P D, | IN(p) | < MinPts, and ∀ q D, if | IN(q)| > MinPts, then
p ∉ IN(q).

∈

∈

∈

∈

∈
∈

∈
∈

3 SODSS Algorithm
In DBSCAN [5] or GDBSCAN [6], to guarantee finding density-based clusters or
outliers, determining the directly density-reachable relation for each point by
examining the neighborhoods is necessary. However, performing all the region queries
to find these neighborhoods is very expensive. Instead, we want to avoid finding the
neighborhood of a point wherever possible. In our method, the algorithm discards these
dense neighborhoods in first, because these objects in it are impossibly outliers. The
algorithm stochastically researched in database but not scan database one by one to find
the neighborhood of every point like DBSCAN, so the algorithm outperform famous
algorithms based on neighborhood query, such as DBSCAN [5], GDBSCAN [6],
LOF [7].
In the following, we present the density-based Spatial Outlier Detecting with
Stochastically Searching (SODSS) algorithm. SODSS is consisted of three segments.
The first (lines 3~17) is Dividing Segment, which divide all object into three parts,
cluster set, candidate set or outlier; The second (lines 19~23) is Near-border Detecting

982

T. Huang et al.

Segment, which detect and record the near-border objects of candidate, i.e., the
neighbors of these border objects that may be labeled candidate, which would be used
to detect these border objects in the third segment; The third (lines 24~31) is Fining
Segment, using the near-border objects to find these border objects and remove them.
SODSS starts with an arbitrary point p and Examine its impact neighborhood
NeighborhoodSet with D.Neighbors(p, Eps) in line 5. If the size of NeighborhoodSet is
at least MinPts, then p is a core point and its neighbors are belong to some clustering, to
put them into clustering set list; otherwise, if the size is 0, p is outlier, so put them into
outlier set; or else p and his neighbor may be outliers, so put them into candidate set.
Lines 19~23 detect neighbors of these that were labeled candidates in Dividing
Segment and include them into candidate set. These objects would be used to detect
border objects that are not outliers from candidate set. Lines 24~31 check every object
in candidate set to remove the border objects.
SODSS algorithm

Algorithm SODSS(D, Eps, MinPts)
1. CandidateSet = Empty;
2.ClusteringSet = Empty;
3.While (!D.isClassified( ) )
4.
{Select one unclassified point p from D;
5.
NeighborhoodSet = D.Neighbors(p, Eps);
6.
if ( | NeighborhoodSet | > MinPts )
7.
ClusteringSet = ClusteringSet ∪ NeighborhoodSet
8.
else
9.
if( | NeighborhoodSet | > 0 )
10.
{NeighborhoodSet.deleateCluserLabledPoit;
11.
CandidateSet = CandidateSet ∪
NeighborhoodSet ∪ p
12.
}
13.
else
14.
OutlierSet = OutlierSet ∪ p
15.
endif;
16.
endif;
17.
} // While !D.isClassified
18. Borders = Empty;
19. While ( !CandidateSet.isLabel )
20.
{ Select one point q from CandidateSet;
21.
q.isLabel;
22.
Borders = Borders ∪ CluseringSet.Neighbors(q,
Eps);
23.
} // While !CandidateSet.isLabel
24. While ( !Borders.isLabel )
25.
{ Select one point b from CandidateSet;
26.
b.isLabel;
27.
Bord_NB = D.Neighbors( b );
28.
if ( | Bord_NB | > MinPts )
29.
CandidateSet.deleate (Bord_NB);
30.
OutlierSet = OutlierSet ∪ CandidateSet;
31.
} // While !Borders.isLabel

Density-Based Spatial Outliers Detecting

983

To understand this algorithm, we give example as Fig. 2. There are two type objects
in Fig. 2. The solid point represented one-type objects and the ring represented the other
type objects. Supposing we focus on solid objects. Apparently, there are two clusters
and two outliers in solid objects in the figure. Clusters are located in center and right
down, and outliers are object a and object d. when algorithm run lines 3~17 to divide
spatial objects to three parts, cluster set, outlier or candidate set. Algorithm may select
object a, and calculate neighborhood A. Supposing object b and c have not been labeled
in any dense neighborhood. They are the neighbors in neighbor hood A, and
neighborhood A is sparse, so they are labeled to candidate. When object b and c is
included in candidate set, the near- border objects near b and c, which include in the red
polygon P in Fig. 2., are also included in candidate set through the Near- border
Detecting Segment in line 19~23. Some of near-border objects in red polygon P are
dense, so object b and c would be removed from candidate set. So SODSS can identify
real outlier.

Fig. 2. Object a and d are outliers. Object b and c would be labeled candidates. The objects in
red polygon P are border objects that are put into candidate set in Near-border Detecting
Segment

4 Theoretical Performance Comparison of SODSS and the Other
Density-Based Algorithm
There are many density-based algorithm that were proposed to detect outliers, but
calculation efficiency is not obviously improved. In the worst case, the time cost of the
algorithms are O(n2). SODSS outperform existing algorithms in calculation efficiency.
The neighborhood query D.Neighbors(p, Eps) in line 5 is the most time-consuming
part of the algorithm. A neighborhood query can be answered in O(logn) time using
spatial access methods, such as R*-trees [8] or SR-trees [9]. When any clusters are
found, their neighbors would not be examine by SODSS again, so SODSS will perform
fewer neighborhood queries and save much time. Clustering objects must much more
than outlier objects, so SODSS can reduce much neighborhood query and then have

984

T. Huang et al.

good efficiency. Supposing SODSS performs k neighborhood queries, its time
complexity is O(klogn), which k is much smaller than n. In the second and third
segment algorithm must query neighborhood again, but these operation are in candidate
set and the number of candidate is very few. The k is related to Eps, so the time
complexity is related to Eps. With increasing of Eps time cost decreases in certain
range, however, the candidates would increase greatly when Eps exceeds the threshold
and the time cost would increase obviously.
4.1 Performance Comparison of SODSS and GDBSCAN
GDBSCAN [6] extended the famous algorithm DBSCAN to apply to spatial database.
GDBSCAN identify spatial outlier through detecting cluster, i.e., the noises are outliers.
This algorithm scans database and examine all objects neighborhoods.
Eps-Neighborhood of GDBSCAN corresponds to impact neighborhood of SODSS,
which is expensive operation. One crucial difference between GDBSCAN and SODSS
is that once SODSS has labeled the neighbors as part of a cluster, it does not examine
the neighborhood for each of these neighbors. This difference can lead to significant
time saving, especially for dense clusters, where the majority of the points are
neighbors of many other points.
4.2 Performance Comparison of SODSS and LOF
LOF [7] calculates the outlier factor for every object to detect outliers. It is the average
of the ratio of the local reachability density of p and those of p’s MinPts-nearest
neighbors. The local reachability density is based on MinPts-nearest neighbors. LOF
must calculate k-distance neighborhoods of all objects, which time costs are equal to
impact neighborhoods query. Calculating k-distance neighborhoods is the main
expensive operation. SODSS detect outlier by removing cluster objects with
stochastically researching. All neighbors in dense neighborhood would not calculate
their neighborhood again, so the region query of SODSS must be less than LOF’s.
Accordingly, SODSS have better efficiency than LOF.

5 Experimental Evaluation
The criteria evaluating outlier detection approaches can be divided into two parts:
efficiency and effectiveness. Good efficiency means the technique should be applicable
not only to small databases of just a few thousand objects, but also to larger databases
with more than hundred thousand of objects. As for effectiveness, a good approach
should have ability to divide exactly outliers from clusters. We have done many
experiments to examine the efficiency and effectiveness, but here limiting to extension
we only presented two. In first, we use synthetic data to explain effectiveness of our
approach. Secondly, we use large database to verify the efficiency. Experiments
showed that our ideas can be used to successfully identify significant local outliers and
performance outperforms the other density-based approaches. All experiments were
run on a 2.2 GHz PC with 256M memory.

Density-Based Spatial Outliers Detecting

985

5.1 Effectiveness
To compare SODSS with GDBSCAN [6] and LOF [7] in terms of effectiveness, we use
the synthetic sample databases which are depicted in Fig. 3. In these datasets, the
non-spatial property for the points is depicted by different symbol, rings and solid
points. Experiment focus on solid objects, and set q.attrs = solid. Fig. 4 shows the
outliers and clusters identified by SODSS. The radius set to 2.1 in SODSS, MinPts set to
3. SODSS and GDBSCAN can identify outliers correctly, because they consider
non-spatial attribute. As shown in Fig. 5, LOF does not find the outliers because it
ignores non-spatial attributes and considers all objects are cluster.

Fig. 3. Synthetic sample databases

Fig. 4. Outlier a and b identified by
SODSS or SDBDCAN

SODSS

GDBSCAN

LOF

Running time(Sec)

2000
1500
1000
500
0
4000

10000 25000 50000 75000 100000
Num ber of points

Fig. 5. LOF can’t identify outliers

5.2

Fig. 6. Time efficiency comparisons between GDBSCAN, LOF and SODSS

Efficiency

For comparison computational efficiency of SODSS and GDBSCAN and LOF, we used
synthetic datasets that are consisted of points from 4000 to 100,000. The Eps is 5, and
MinPts is 10, when SODSS query the neighborhood. They are the same when

986

T. Huang et al.

GDBSCAN run. We set MinPts = 30 and LOF > 1.5. Fig. 6. shows the running time for
SODSS increases with the size of the datasets in an almost linear fashion, and the
performance is obviously better than the other two.

6 Conclusion
In this paper, we formulated the problem of one-type spatial outlier detection and
presented effective and efficient SODSS algorithms for spatial outlier mining. This
algorithm does not calculate neighborhood of very objects but stochastically research.
It discards much region query of cluster, and gained good efficiency.
Acknowledgements. This research supported by the National Nature Science Foundation of China (No. 49971063), the National Nature Science Foundation of Jiangsu
Province (BK2001045), the High-Tech Research of Jiangsu Province (BG2004005)
and the National High-Tech Research and Development Plan of China (No.
2001AA634010-05).

References
1. D. Hawkins. Identification of Outliers. Chapman and Hall, London, 1980
2. H. Dai, R. Srikant, and C. Zhang. OBE: Outlier by Example. In: Proceedings of PAKDD
2004, Sydney, Australia, May 26-28, 2004, LNAI 3056, pages: 222-234, 2004
3. S. Shekhar, C.T. Lu, and P. Zhang. A unified approach to detecting spatial outliers.
GeoInformatica, 7(2): 139-166, 2003
4. C.T. Lu, D. Chen, and Y. Kou. Algorithms for spatial outlier detection. In Proceedings of the
3rd IEEE International Conference on Data Mining (ICDM 2003), December 19-22, 2003,
Melbourne, Florida, USA, pages: 597-600. IEEE Computer Society, 2003
5. M. Ester, H.P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering
clusters in large spatial databases. In: Proceedings of KDD’96, Portland OR, USA, pages:
226-231, 1996
6. J. Sander, M. Ester, H. Kriegel, and X. Xu. Density-based Clustering in Spatial Databases: the
algorithm GDBSCAN and its applications. Data Mining and Knowledge Discovery, val. 2,
no. 2, pages: 169-194, 1998
7. M.M. Breunig, H.P.Kriegel, R.T.Ng, and J. Sander. LOF: Identifying density-based local
outliers. In: Proceedings of SIGMOD’00, Dallas, Texas, pages: 427-438, 2000
8. N. Beckmann, H.P. Kriegel, R. Schneider, and B. Seeger. The R*-Tree: An Efficient and
Robust Access Method for Points and Rectangles. SIGMOD Record, vol. 19, no. 2, pages:
322-331, 1990
9. N. Katayama and S. Satoh. The SR-tree: An Index Structure for High-Dimensional Nearest
Neighbor Queries. SIGMOD Record, vol. 26, no. 2, pages: 369-380, 1997

