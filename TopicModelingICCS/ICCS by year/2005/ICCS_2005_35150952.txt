Experimental Analysis of a New Algorithm for
Partial Haplotype Completion
Paola Bonizzoni1,3 , Gianluca Della Vedova2,3 ,
Riccardo Dondi1,3 , and Lorenzo Mariani1,3
1

3

Dipartimento di Informatica, Sistemistica e Comunicazione
2
Dipartimento di Statistica
Univ. Milano–Bicocca, Via Bicocca degli Arcimboldi 8, 20126 Milano(Italy)
bonizzoni@disco.unimib.it, riccardo.dondi@unimib.it

Abstract. This paper deals with the computational problem of inferring complete information on haplotypes from haplotypes with missing
data. This problem is one of the main issues in haplotyping, as the current DNA sequencing technology often produces haplotypes with missing
bases and thus the complete information on haplotypes has to be inferred
through computational methods. In this paper we propose a new algorithmic approach to the problem that assumes both the Coalescent and
the Minimum Entropy models and we provide an experimental analysis
relating it to the previously investigated approaches. In particular, the
reconstruction of a perfect phylogeny from haplotypes with missing data
is addressed.

1

Introduction

After the completion of the Human Genome Project, one of the main goals of
Molecular Biology is the understanding of the relationship between variants in
the human genome sequence and many common diseases inﬂuenced by multiple
genetic and environmental factors. The main genetic diﬀerences among individuals concern about ten million single DNA sequence sites, referred to as Single
Nucleotide Polymorphisms (SNP s), in which usually two bases are observed
across the population. Therefore, when studying diﬀerences among human DNA
sequences, only the bases at SNP sites are considered and other bases can be
ignored. The sequence of the bases that an individual presents in all or some of
his SNP sites is called a haplotype.
Recent studies [4] have shown that the human DNA sequence can be subdivided into blocks that have been transmitted through evolution without recombination, and that within each block a few (2-5) distinct common haplotypes
that cover about 70-90% of the total observed haplotypes. The National Institutes of Health has launched the Haplotype Map Project [9], whose goal is the
identiﬁcation of the haplotype blocks and the common haplotypes in the genome
of diﬀerent human populations. This project has encouraged the development of
computational methods to address several issues and indeed haplotyping [1] is a
research topic which poses new challenging questions to computer scientists.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 952–959, 2005.
c Springer-Verlag Berlin Heidelberg 2005

Experimental Analysis of a New Algorithm

953

A main issue in haplotyping is the inference of complete haplotypes from
haplotypes with missing data as the current DNA sequencing technology often
produces haplotypes with missing bases at some positions. Combinatorial methods based on inference rules represent a common approach to face this problem
[7]. These methods usually use inference rules based on assumptions on evolutionary model for human haplotypes or statistical analysis of haplotypes frequency.
Two of the main patterns adopted for this problem are the coalescent model
(shortly CM) and the minimum entropy model (shortly MEM). The coalescent
model, proposed in [5] describes the evolutionary relationships between haplotypes, assuming that no recombination occurs between haplotypes and that at
each SNP site a mutation can happen only once during evolution. The minimum
entropy model, proposed in [6], assumes that the frequency distribution of the
haplotypes within the population has a small entropy.
Some existing algorithms assume either CM or MEM. Algorithms assuming both of them, require some strict hypotheses to be satisﬁed (for example,
knowing the phylogenetic tree of the haplotypes) [7]. In this paper we propose
a new algorithm that assumes both CM and MEM, requiring only one complete
haplotype to be known.
Our algorithm consists of two phases. First, it produces a completion of the
partial haplotypes that ﬁts CM, implementing a variant of the “Na¨ıve Algorithm
A” of [10]. Then, it executes a local optimization heuristic. In particular, two
diﬀerent procedures have been designed, implemented and tested for this second
phase: a greedy improvement procedure and a Kernighan-Lin heuristic style.
Various experiments have been performed in order to study the performance
of the algorithm. Experimental results show that the amount of data incorrectly completed is a very low percentage with respect to the amount of total
missing data, suggesting that both the greedy improvement heuristic and the
Kernighan-Lin heuristic are good approaches for the local optimization of the
solution, especially when they are combined. The performance of an algorithm
that adopts either the two heuristics has been compared with those of other effective softwares [7, 6, 3]. The results of the comparison are encouraging, showing
the eﬀectiveness of the new approach proposed.

2

The Partial Haplotype Completion Problem

In diploid organisms like humans only two diﬀerent bases are observed in each
SNP site, leading to a natural {0, 1}-representation. Actually, current sequencing
technology often produces DNA sequences with some missing bases at some
position. Therefore, we must adopt a {0, 1, ?}-representation to denote the values
assumed by each SNP site, where ‘?’ represents the lack of data.
Let S = {s1 , s2 , ..., sn } denote a set of n individuals and let C = {c1 , c2 , ..., cm }
denote a set of m SNP sites observed in a speciﬁed block of the human genome.
Then, a complete haplotype over the SNP sites in C is a {0, 1}m -vector. A partial
haplotype over the SNP sites in C is a {0, 1, ?}m -vector. A partial haplotype ph
is said to be compatible with a complete haplotype ch if and only if ph[i] = ‘?

954

P. Bonizzoni et al.

implies that ch[i] = ph[i], for i = 1, 2, ..., m. Given a matrix K, we denote with
K(i) the i-th row of K and with Kij the entry corresponding to the i-th row
and the j-th column of K. The set of partial haplotypes associated to the set
S of individuals is represented by a {0, 1, ?}-matrix A, called partial haplotypes
matrix, where each row A(i) represents a partial haplotype for individual si ∈ S.
A {0, 1}-matrix M is a complete haplotypes matrix if it is the completion of A
such that each row A(i) is compatible with M(i), for i = 1, . . . , n.
In the partial haplotype inference we assume two models commonly adopted
when dealing with this problem, the coalescent model and the minimum entropy
model, described below.
The coalescent model. Recent studies [4] have shown that the human genome
can be partitioned into blocks that have been transmitted without showing evidence for recombination. Moreover, recurrent mutations at the same SNP site
are rare events in the evolutionary history. Thus, we can assume that the common haplotypes observed in the human population within a genome block ﬁts
the CM[5]. The CM describes the evolutionary relations between haplotypes assuming that: (i) there is no recombination between haplotypes and (ii) at each
SNP site a mutation can happen only once. By the assumptions of the model,
a haplotype with a mutation at a SNP site is a descendant of the ancestor haplotype hi in which the mutation ﬁrst occurred, while a haplotype without the
mutation cannot be a descendant of hi . This implies that the evolutionary history of the collected haplotypes is described by a phylogenetic tree known as
perfect phylogeny.
The problem of ﬁnding a completion of a partial haplotypes matrix so that
the haplotypes in the complete matrix ﬁt the CM is NP-hard [11]. Nevertheless,
it becomes tractable when at least one complete haplotype is known [10]: in this
case it is possible to change the {0,1}-representation of the bases at each SNP
site in such a way that the known complete haplotype is represented by the
all-zero vector. Indeed, in terms of evolutionary tree, this corresponds to ﬁx the
known all-zero haplotype as the root of the perfect phylogeny, which becomes
the so-called directed perfect phylogeny. In what follows we assume that the allzero vector always belong to the perfect phylogeny, i.e. we adopt the directed or
rooted model.
Let A be a partial haplotypes matrix then, given two columns j1 , j2 with
1 ≤ j1 < j2 ≤ m, the set of the valid pairs for j1 and j2 is the set V P (j1 , j2 ) ⊆
{(0, 0), (0, 1), (1, 0), (1, 1)} such that (x, y) ∈ V P (j1 , j2 ) if and only if there exists
the pair aij1 , aij2 of values in a row i, with 1 ≤ i ≤ n, such that (aij1 , aij2 ) =
(x, y).
A characterization of the matrices ﬁtting the CM has been given in [7]. Let
M be a complete haplotype matrix, then M ﬁts the CM if and only if for every
pair of columns j1 , j2 ∈ {1, 2, ..., m} the set of the valid pairs V P (j1 , j2 ) is such
that {(0, 1), (1, 0), (1, 1)} V P (j1 , j2 ).
The minimum entropy model. The minimum entropy model is mainly based
on a parsimony principle suggested by the fact that in many real-life situations
a frequency distribution tends to have a very low entropy value [7, 6].

Experimental Analysis of a New Algorithm

955

Assume that a collection of n partial haplotypes P H ={ph1 , ph2 ,. . . , phn } of
length m is given: these are represented by a partial halpotypes matrix A. Let
α : P H→{0, 1}m be the completion function that assigns each partial haplotype
ph ∈ P H to a complete compatible haplotype α(ph) ∈ {0, 1}m . Thus, let H =
{α(ph) : ph ∈ P H} = {h1 , h2 , ..., hk } ⊆ {0, 1}m be the set of the distinct
complete haplotypes assigned to the partial haplotypes in P H. Let fi be the
number of partial haplotypes in P H that are assigned to the complete haplotype
hi ∈ H: fi = |{ph ∈ P H : α(ph) = hi }| for every i = 1, 2, ..., k, with f1 + f2 +
. . . + fk = n. Thus (f1 /n, f2 /n, ..., fk /n) = (p1 , p2 , ..., pk ) is the distribution
of the relative frequencies of the complete haplotypes assigned to the partial
haplotypes in P H.
Observe that the haplotypes α(ph1 ), α(ph2 ), ..., α(phn ) give the rows of a
complete haplotypes matrix M of size n×m that is the completion of the matrix
A. Then the entropy of M is the entropy of the relative frequency distribution
k
(p1 , p2 , ..., pk ), deﬁned as EN T (M) = EN T (p1 , p2 , ..., pk ) = i=1 −pi log2 pi .
The MEM assumes that the most likely valid completion of the partial haplotypes is the one that minimizes the entropy value EN T (M); it is proved that
ﬁnding such a completion is an APX-hard problem [6].

3

An Algorithm for Partial Haplotype Completion

We propose a new algorithm for the completion of a collection of partial haplotypes, represented as a {0, 1, ?}-matrix, assuming that both the CM and the
MEM hold. More precisely, the use of the two models lead to search for the
partial haplotypes completion that determines the minimum entropy frequency
distribution, within the set of the completions that ﬁt the CM. Formally, each
instance of the Partial Haplotype Completion Problem is a partial haplotype matrix A of size n × m, and the goal is to ﬁnd (if it exists) a matrix M of size n × m
that is a completion of A such that M ﬁts the CM and EN T (M) is minimum.
We do not know whether there is a polynomial-time algorithm to ﬁnd such
a completion matrix M, similarly to the case in which the evolutionary history
of the complete haplotypes is known [7]. Thus, we propose a heuristic algorithm
for the problem composed of two phases: ﬁrst we compute an initial completion
that ﬁts the CM, if it is possible, then such completion is modiﬁed in order to
ﬁnd a completion that still ﬁts the CM and that determines a smaller entropy.
For the ﬁrst phase, we design a variant of the “Na¨ıve Algorithm A” proposed
in [10] for the incomplete directed perfect phylogeny reconstruction and that we
denoted by (pp). When this algorithm is invoked on a {0, 1, ?}-matrix of size
n×m, its computational complexity is O(hnm), where h ≤ min{m, n}.
The results produced in the ﬁrst phase are reﬁned in the second phase of the
algorithm. In particular we use two local optimization heuristic procedures: a
greedy heuristic (gh) and a Kernighan-Lin style heuristic (klh), described below.
In Section 4 we compare the performance of the two procedures when executed
separately or combined.

956

P. Bonizzoni et al.

The greedy heuristic. The greedy heuristic procedure (gh) is inspired by the
greedy algorithm proposed in [6], whose goal is ﬁnding a minimum entropy set
of complete haplotypes compatible with a given collection of partial haplotypes.
Given a partial haplotype matrix A and a completion matrix M of A produced
by (pp), the procedure identiﬁes the distinct complete haplotypes of M and
calculates their frequencies. Then, it simply takes each distinct complete haplotype h of M starting from the most frequent one and ending with the least
frequent one, and assigns it to the not-yet-assigned compatible partial haplotypes of A, deﬁning a new completion matrix M . The goal is to concentrate the
maximum possible number of haplotypes into large sets, reducing the entropy of
their frequency distribution.
The procedure runs in O(n2 m) time, since it takes O(n2 m) time to detect
the distinct complete haplotypes of M and their frequencies, O(n) time to rearrange them in growing order of frequency (with counting sort algorithm) and
O(n2 m) time to assign these complete haplotypes to partial haplotypes of A. In
some cases, a great set of identical haplotypes can be obtained only considering
complete haplotypes diﬀerent from the ones obtained by applying (pp) and for
this goal we have designed a Kernighan-Lin heuristic (klh)[8].
The Kernighan-Lin heuristic. The Kernighan-Lin style heuristic we propose applies a local improvement of the solution based on the iterative inversion (from
‘0’ to ‘1’, or from ‘1’ to ‘0’) of the value of an entry mij of the completion matrix
M that corresponds to a missing data in A, that is aij = ‘? . Note that this
inversion can be applied only if the resulting matrix M still ﬁts the CM. Thus,
before operating the inversion we must check, with respect to the Valid Pairs
Theorem, the valid pairs of each pair of columns of the matrix M that we would
obtain performing the inversion. This operation takes Θ(nm2 ).
Moreover, we must design an eﬃcient function that, given a completion matrix M of matrix A, the complete haplotypes of M and their frequency distribution, calculates the entropy of the frequency distribution that we would obtain
inverting a speciﬁc entry mij (with aij = ‘? ). Identifying the complete haplotypes of M and determining their frequency distribution takes O(n2 m) time.
Calculating the new entropy of the frequency distribution, instead, takes O(nm)
time, since comparing two haplotypes of length m takes O(m) time and such a
comparison is performed for all the complete haplotypes, that are at most n.
The total number of iterations cannot be determined a priori, since it depends
on the random selections at execution time, however the core of the algorithm
runs in O(n2 m2 ) time.

4

Results

Our algorithm has been tested on input data coming from the common haplotypes found in the blocks 1–7 and 10–11 of a region of chromosome 5p31, as
deﬁned by Daly et al. in [2]. Starting with this data, we have constructed 9 complete haplotypes {0, 1}-matrices (matrices C), composed of 86–97 rows and 5–31
columns and then, adding missing data to them, almost 40 partial haplotypes

Experimental Analysis of a New Algorithm

957

Algorithm 1: Kernighan Lin Heuristic (klh)
Data: a {0, 1, ?}-matrix A of size n×m, an integer parameter max iter; a real
number parameter base
compute the distinct complete haplotypes of M, and the frequency distribution;
B = M;
// B=so-far best found completion;
min entropy = entropy of M;
while (number of iterations performed without improvement < max iter) do
foreach ‘?’-entry aij of A do
if the inversion of mij in M is admissible then
new entropy = entropy of M with mij inverted;
p(aij ) = base−new entropy ;
if new entropy < min entropy then
B = M;
// an improvement has been obtained ;
invert bij ;
min entropy = new entropy;
else p(aij ) = 0;
end
with probability p(aij ) for each ‘?’-entry aij of A, select a ‘?’-entry aˆiˆj ;
invert mˆiˆj in M;
update the number of occurrences of all valid pairs for each column pair of
M;
update the distinct complete haplotypes of M, and the frequency distribution;
end
Result: B

{0, 1, ?}-matrices (matrices A) whose rate of unknown data varied from 1% to
50% have been obtained.
The completion of each of these {0, 1, ?}-matrices (matrices M) has been
computed by adopting four diﬀerent approaches: executing the single procedure
(pp); executing (pp) and (gh); executing (pp) and (klh); executing (pp), followed by the execution of (gh) and then (klh) (we denote this algorithm as
(pp)+(gh)+(klh)). For the executions of (klh), diﬀerent values have been assigned to its two parameters: the base of the exponential used to calculate the
inversion probability (from 10 to 100) and the maximum number of iterations
without improvements (from 5 to 25).
For each completion matrix M obtained for an incomplete haplotype matrix
we have evaluated the error rate, that is the number of entries of M that are
diﬀerent from the corresponding entries of C, divided by the total number of
‘?’ entries of A, and the entropy diﬀerence, that is the diﬀerence between the
entropy values of matrices C and M and are reported in Table 1.
Observe that Table 1 shows that some incomplete matrices admit completion
matrices with an entropy lower than that of the complete matrices from which
they have been generated; this fact especially happens when the number of
sampled individuals is small. The Table also suggests that the greedy heuristic

958

P. Bonizzoni et al.
Table 1. Comparing the entropy values of matrices C and M
Approach
(pp)
(pp+klh)
(pp+gh)
(pp+gh+klh)

Entropy diﬀerences
Mean Min Max Std.Dev
0.078 -0.210 0.414 0.160
0.043 -0.210 0.414 0.137
-0.001 -0.210 0.414 0.108
-0.006 -0.210 0.414 0.106

Mean
4.20%
3.42%
2.64%
2.51%

Error rates
Min Max
0.00% 13.63%
0.00% 12.81%
0.00% 11.30%
0.00% 11.30%

Std.Dev
0.0420
0.0400
0.0350
0.0339

produces better results than (klh), but the best performance is obtained by
combining the two algorithms. The recorded execution times have been always
under one second (on a 1.60 GHz processor).
In order to evaluate the scalability of the algorithm, we have tested it on
500 artiﬁcial {0, 1, ?}-matrices composed by 50–250 rows and 50–250 columns.
Although the average entropy diﬀerences and the average error rates show a
behaviour that is similar to the one described above, this experiment shows that
(klh) strongly aﬀects the execution time of the algorithm (determining a running
time up to 600 seconds), when the number of sampled SNP sites is great or when
there is an high rate of missing data. Thus, in cases in which the input instance
has a very great number of SNP sites or an high rate of unknown data, the use
of the (pp+gh) approach seems to be the best solution.
For the above reasons we have tested the (pp+gh) approach on 20 artiﬁcial
{0, 1, ?}-matrices of size 10, 000 × 1, 000, varying the rate of unknown data from
1% to 40%. We have obtained an error rate with range from 0% to 0.000005%
and an error percentage up to 0.000002%. The error rates are very small, since
we have already observed that the error rate tends to quickly decrease as the
number of SNP sites grows. Furthermore, the algorithm has required an average execution time of 54 seconds (ranging from 17 to 113 seconds) on a 1.60
GHz processor; this shows that the (pp+gh) approach scales very well to large
data sets.

5

Discussion

In this section we remark the diﬀerences between (pp+gh+klh) algorithm and
other algorithms proposed for the partial haplotype completion problem. First
of all we discuss the diﬀerences in terms of models and hypothesis assumed.
Two algorithms proposed in [7] assume both CM and MEM, but they both
require that the perfect phylogeny of the complete haplotypes is known, while
our algorithm only requires the knowledge of one complete haplotype.
The algorithm proposed in [6] assumes only the MEM; it is based on a greedy
approach, and runs in exponential time when the complete haplotypes are not
known and the number of SNP sites is not logarithmic with respect to the
number of individuals. Two algorithms proposed in [7], assume only the CM
and require the input data to meet the rich data hypothesis, according to which
each pair columns contains three valid pairs. Under this hypothesis the problem

Experimental Analysis of a New Algorithm

959

of completing the partial haplotypes of A assuming the coalescent model is
polynomial [6]. Next we focus on the comparison between the (pp+gh+klh)
algorithm with other published algorithms, based on experimental data.
On real data, when the rate of missing data is no more than 20%, our algorithm has given an average error rate of 0.85% (with range from 0.00% to 6.52%)
and an average percentage of errors of 0.17% (with range from 0.00% to 1.30%)
with respect to the total number of entries.
We compare these experimental results with those of two algorithms of [7,
3]. Both these algorithms are executed on all the haplotypes found within a
block and not only on the common ones, as our algorithm does. Moreover the
algorithm proposed in [3] considers as input a collection of genotypes rather than
haplotypes, thus it even includes a procedure for the inference of haplotypes from
genotypes. Hence, the performance results that we report do not allow a detailed
comparison, but they still give a new and interesting point of view.
The greedy algorithm proposed in [7] has been executed on real-data matrices
composed by 90–129 rows and 10–31 columns, with missing data rate varying
from 0.5% to 10%; it has given average error rates between 2.8% and 8.1%.
The maximum-likelihood-based algorithm proposed in [3] has been executed
on real-data matrices composed by 129 rows and 5–31 columns, with a missing
data rate of 10.03%; it has given a percentage of errors of 0.23% with respect to
the total number of entries, with a running time of a few seconds.

References
1. P. Bonizzoni, G. Della Vedova, R. Dondi, and J. Li. The haplotyping problem:
a view of computational models and solutions. Journal of Computer and Science
Technology, 18:675–688, 2003.
2. M. J. Daly, J. D. Rioux, S. F. Schaﬀner, and et al. High-resolution haplotype
structure in the human genome. Nat. Genet., 29(2):229–232, 2001.
3. E. Eskin, E. Halperin, and R. M. Karp. Large scale reconstruction of haplotypes
from genotype data. In Proceedings of the 7th RECOMB, pages 104–113, 2003.
4. S. B. Gabriel, S. F. Schaﬀner, and et al. The structure of haplotype blocks in the
human genome. Science, 296:2225–2229, 2002.
5. D. Gusﬁeld. Haplotyping as perfect phylogeny: Conceptual framework and eﬃcient
solutions. In Proceedings of the 6th RECOMB, pages 166–175, 2002.
6. E. Halperin and R. M. Karp. The minimum-entropy set cover problem. In Proceedings of the 31st ICALP, pages 733–744, 2004.
7. E. Halperin and R. M. Karp. Perfect phylogeny and haplotype assignment. In
Proceedings of the 8th RECOMB, 2004.
8. K. Helsgaun. An eﬀective implementation of the Lin-Kernighan traveling salesman
heuristic. European Journal of Operational Research, 126:106–130, 2000.
9. National Institutes of Health. Large-scale genotyping for the haplotype map of the
human genome. RFA (Request For Applications) HG-02-005, 2002.
10. I. Pe’er, T. Pupko, R. Shamir, and R. Sharan. Incomplete directed perfect phylogeny. SIAM Journal on Computing, 33(3):590–607, 2004.
11. M. Steel. The complexity of reconstructing trees from qualitative characters and
subtrees. Journal of Classification, 9:91–116, 1992.

