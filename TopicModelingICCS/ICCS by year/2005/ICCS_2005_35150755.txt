An Eﬃcient Equi-semi-join Algorithm
for Distributed Architectures
M. Bamha and G. Hains
LIFO, Universit´e d’Orl´eans, B.P. 6759, 45067 Orl´eans Cedex 2, France
{bamha, ghains}@lifo.univ-orleans.fr

Abstract. Semi-joins is the most used technique to optimize the treatment of complex relational queries on distributed architectures. However
the overcost related to semi-joins computation can be very high due to
data skew and to the high cost of communication in distributed architectures. In this paper we present a parallel equi-semi-join algorithm for
shared nothing machines. The performance of this algorithm is analyzed
using the BSP cost model and is proved to have asymptotic optimal
complexity and perfect load balancing even for highly skewed data. This
guarantees unlimited scalability in all situations for this key algorithm.

1

Introduction

Equi-join is an expensive and frequently used operation whose parallelization is
highly desirable. The equi-join of two tables or relations R and S on attribute A
of R and attribute B of S is the relation T , written R S, containing the pairs
of tuples from R and S for which R.A = S.B. The equi-semi-join of S by R
is the relation S R composed of the tuples of S which occur in the equi-join of
R and S. Equi-semi-join reduces the size of relations to be joined and satisﬁes
R
S =R
(S R) = (R S)
(S R). The equi-semi-join is generally
called semi-join, and throughout the paper, semi-join refers to equi-semi-join.
The semi-join is useful in relational databases for reducing the time for processing queries involving join operations, by means of selecting only relevant
data and thereby reducing the size of operand relations. Semi-join is also used
to reduce the amount of data transferred over the network and therefore the communication costs in distributed architectures [10, 8]. However eﬃcient semi-join
is very sensitive to the problem of data skew. Data skew can have a disastrous effect on performance [3, 2, 1, 8, 7, 6, 11, 5] due to the high costs of communications
and synchronizations in distributed architectures [2, 1, 10].
Many algorithms have been proposed to handle data skew for join and semijoin operations [8, 7, 6, 10]. Such algorithms are not eﬃcient for many reasons:
– the presented algorithms are not scalable (and thus cannot guarantee linear speedup) because their routing decisions are generally performed by a
coordinator processor while the other processors are idle,
– they cannot avoid load imbalance because they base their routing decisions
on incomplete or statistical information,
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 755–763, 2005.
c Springer-Verlag Berlin Heidelberg 2005

756

M. Bamha and G. Hains

– they cannot solve data skew problem because data redistribution is generally
based on hashing data into buckets and hashing is known to be ineﬃcient.
In this paper, we present a new parallel semi-join algorithm for shared nothing
machines. This algorithm guarantees a perfect balancing of the load of the different processors during all the stages of the semi-join computation because the
data redistribution is carried out jointly by all processors. Each processor deals
with the data associated with a subset of the join attribute values (organized
as histograms) not necessarily its “own” values. Our algorithm uses histogram’s
redistribution to avoid imbalance during semi-join parallel processing. Its performance is analyzed using Bulk-synchronous parallel (BSP) cost model [9] which
allows us to guarantee that histogram management has a negligible cost when
compared to the eﬃciency gains it provides to reduce the communication cost
and to avoid load imbalance between processors.

2

Histograms and Semi-joins Processing: A New
Approach

In this section, we present a new approach to compute semi-joins on shared
nothing machines. This approach is insensitive to data skew, and is based on
an eﬃcient technique for histograms computation, allowing to reduce the net
communication costs to a minimum.
Before carrying out the description of the semi-join algorithm, we present
some results related to histograms computations which we will use thereafter.
An upper bound of the global BSP cost is also given for each step.
We ﬁrst assume that relation R (resp. S) is partitioned among processors by
horizontal fragmentation and the fragments Ri for i = 1, .., p are almost of the
same size, i.e. |Ri | |R|
p where p is the number of processors.
In the rest of this paper, we use the following notation for each relation
T ∈ {R, S}:
– Ti denotes the fragment of relation T placed on processor i,
– Hist(T ) denotes the histogram of relation T with respect to the join attribute
value, i.e. a list of pairs (v, nv ) where nv = 0 is the number of tuples of
relation T having the value v for the join attribute,
– Hist(Ti ) denotes the histogram of fragment Ti ,
– Histi (T ) is processor i’s fragment of the histogram of T ,
– T denotes the number of tuples of relation T , and
– |T | denotes the size (expressed in bytes or number of pages) of relation T .
It will be assumed in the remainder of the article that, for a relation T , T is
suﬃciently large with respect to p and in the rest of the paper, g refers to BSP
communication’s parameter and l the cost for a barrier of synchronization [9].
Proposition 1. Let Hist(Ri )i=1,..,p be the histograms, according to some attribute A, of the fragments Ri of a relation R. If H is a hash function allowing

An Eﬃcient Equi-semi-join Algorithm for Distributed Architectures

757

to distribute in a balanced way the distinct values of the attribute A among the
p processors, then the fragments Histi (R)i=1,..,p can be computed in time:
O min(g ∗ |Hist(R)| + Hist(R) , g ∗

|R|
R
+
)+l .
p
p

Proof : The proof proceeds according to frequency distribution of the attribute
A of the relation R.
1st case: All the values of the attribute A appear in the relation R with a
frequency equal to 1, i.e. the number of tuples of the relation R is equal to the
number of distinct values of the attribute A (and thus Hist(R) = R ).
In this case, the application of the hash function H, distributes the tuples
of relation R (and thus the histogram of R) evenly on the various processors.
Consequently, the redistribution of Hist(Ri ), using the function H, is done in
time:
O g∗

|Hist(R)|
Hist(R)
+
+l
p
p

≤

O g∗

|R|
R
+
+l .
p
p

(1)

The term g ∗ |Hist(R)|
is due to the fact that each processor receives a fragment
p
|Hist(R)|
,
p

of size about equal to
Hist(R)
p

g is BSP communication parameter. The term

is time necessary to form Histi (R)i=1,..,p starting from the blocks
received by each processor, during the redistribution of the local histograms
Hist(Ri )i=1,..,p and l is the cost of a barrier of synchronization.
Inequality (1) is generally true, owing to the fact that |Hist(R)| ≤ |R| since
the histogram contains only pairs of the form (v, nv ) where v are distinct values
of attribute A of R and nv the corresponding frequencies. So the histograms
creation can be carried out in time:
|Hist(R)|
Hist(R)
|R|
R
+
, g∗
+
)+l
p
p
p
p
R
|R|
+
)+l .
O min(g ∗ |Hist(R)| + Hist(R) , g ∗
p
p

O min(g ∗
≤

(2)

2nd case: All the values of the attribute A appear in relation R with a frequency
lower than p. In this case the relation R can be partitioned into p relations R1 ,
R2 , . . ., Rp so that the frequency of each value v in a relation Rj is exactly equal
to 1. By applying the results of the 1st case to each relation Rj , we deduce that
the creation of the fragments Histi (Rj ) of a relation Rj for j = 1, .., p requires
at most:
O min(g ∗

|Hist(Rj )|
Hist(Rj )
|Rj |
Rj
+
, g∗
+
)+l ,
p
p
p
p

and thus the creation of the fragments Histi (R) of relation R requires:
min(g ∗

O
j=1,..p

≤

|Hist(Rj )|
Hist(Rj )
|Rj |
Rj
+
, g∗
+
)+l
p
p
p
p

O min(g ∗ |Hist(R)| + Hist(R) , g ∗

|R|
R
+
)+l ,
p
p

(3)

758

M. Bamha and G. Hains

because the fragment Histi (R) can be created starting from the fragments
Histi (Rj )j=1,..,p by a simple fusion of the histograms Histi (Rj )1≤j≤p in time:
O(

p
j=1

Histi (Rj )
p

) ≤ O(maxi,j ( Histi (Rj ) )) ≤ O( Hist(R) ),

and that i min(ai , bi ) ≤ min( i ai , i bi ). We thus combine the p phases of
communication in only one (the term is not multiplied by p).
The distribution of the relation R into p relations is carried out only to show
the validity of the result. In practice, if a value v appears in Ri with a frequency
k, the application of the hash function to the histogram sends the pair (v, k) to
the processor destination in only one message and not in k messages of the form
(v, 1). This reduces the amount of data exchanged between the processors.
3rd case: All the values of the attribute A appear in the relation R with
frequencies higher than p. In this case, for a given value v, the tuples associated
with v can be distributed on several processors and in the worst case distributed
on p processors. Thus the application of the hash function, H, to the histograms
Hist(Ri )i=1,..,p , sends pairs of the form (v, ki )i=1,..,p to the same processor.
As each processor deals with a block of size Hist(R)
, it receives at most
p

p ∗ |Hist(R)|
= |Hist(R)| data from the other processors, and the cost of the
p
redistribution of the histograms Hist(Ri ) is about:
O g ∗ |Hist(R)| + l

≤

O g∗

|R|
+l .
p

(4)

Inequality (4) holds because all the values of attribute A appear in R with a
and |Hist(R)| ≤ |R|
.
frequency higher than p and thus: Hist(R) ≤ Rp
p
Hist(R) is the time necessary to form, Histi (R), on processor i, starting
from the fragments of Hist(Rj )j=1,..,p received after the redistribution phase
using the hash function H. And thus the creation of the histograms Histi (R)
requires:
O min(g ∗ |Hist(R)| + Hist(R) , g ∗

|R|
R
+
)+l .
p
p

4th case: the general case follows immediately from the three preceding cases.
We partition relation R into two disjoint sub-relations R and R so that the
tuples of the relation R (resp. R ) are associated with frequencies lower (resp.
higher) than p for the attribute A. Thus, using the ﬁrst two cases, the histogram
R can be carried out in time:
O min(g ∗ |Hist(R )| + Hist(R ) , g ∗

|R |
R
+
)+l ,
p
p

(5)

and the creation of the histogram of R , (cf. 3rd case), in time:
O min(g ∗ |Hist(R )| + Hist(R ) , g ∗

|R |
R
+
p
p

)+l

(6)

An Eﬃcient Equi-semi-join Algorithm for Distributed Architectures

759

By making the sum of the terms 5 and 6, we show that the creation of the
histograms Histi (R) requires at most:
O min(g ∗ |Hist(R)| + Hist(R) , g ∗

|R|
R
+
)+l .
p
p

(7)

This is due to the fact that Hist(R) = Hist(R )∪Hist(R ) and that min(a, b)+
min(c, d) ≤ min(a + c, b + d), which proves the required result.

Previous parallel algorithms have used hashing functions to redistribute the relations themselves, not just their histograms. This can lead to imbalance and
disastrous performance.
Remark 1.
In practice, the imbalance of the data related to the use of the
hash functions can be due to:
– a bad choice of the hash function used. This imbalance can be avoided by
using the hashing techniques presented in the literature making it possible to
distribute evenly the values of the join attribute with a very high probability
[4]. In our algorithm, the hash functions we use may be data dependent and
stored in the database index. Otherwise, for a given set of n distinct values
we can ﬁnd, in time of 0(n), a function which redistributes evenly the n
values over p buckets.
– an intrinsic data imbalance which appears when some values of the join
attribute appear more frequently than others. By deﬁnition a hash function
maps tuples having the same join attribute values to the same processor.
There is no way for a clever hash function to avoid load imbalance that
results from these repeated values [5]. But this case cannot arise here owing
to the fact that histograms contain only distinct values of the join attribute
and the hashing functions we use are always applied to histograms.
In the following proposition, we present a method allowing to compute the
semi-joins eﬃciently starting from the histograms. We show thereafter that this
technique of semi-joins computation combined with the methods of histograms
creation guarantees an asymptotic optimal cost for the semi-joins computation.
Proposition 2. Let Hist(Ri )i=1,..,p (resp. Hist(Si )i=1,..,p ) be the histograms,
according to some attribute A, of sub-relation Ri (resp. Si ) of R (resp. S).
If H is a hash function allowing to distribute in a balanced way, the distinct
values of the attribute A among the p processors, then the two semi-joins, R S
and S R, can be computed in time:
T imesj = O min g ∗ |Hist(R)| + Hist(R) , g ∗
+ min g ∗ |Hist(S)| + Hist(S) , g ∗

|R|
R
+
p
p

|S|
S
+
p
p

+ max

i=1,..,p

+ max

i=1,..,p

Ri

Si + l .

760

M. Bamha and G. Hains

Proof : To perform the semi-joins in at most the above time, the semi-joins
computation, R S and S R, is done in ﬁve stages.
a. A stage of creation of Histi (R)i=1,..,p (resp. Histi (S)i=1,..,p ) of R (resp. S):
The fragments Histi (R)i=1,..,p creation is carried out by hashing the local histograms Hist(Ri )i=1,..,p using the hash function H. On each processor i, the application of the function H distributes Hist(Ri ) into p buckets Histj (Ri )i=1,..,p
where Histj (Ri ) is the fragment of Hist(Ri ) which will be sent to processor j.
).
By using Proposition 1, we have: | ∪i Histj (Ri )| ≤ min(|Hist(R)|, |R|
p
j
The fragments Hist (Ri )i=1,..,p are then gathered, on each processor j, to
form Histj (R) in time: O( min( Hist(R) , R
p )).
Hence the creation of the histograms Histi (R)i=1,..,p of relation R requires:
O min(g ∗ |Hist(R)| + Hist(R) , g ∗

|R|
p

+

R
p

) .

Similarly for relation S, the above technique is used to compute the fragments
+ Sp ) .
Histi (S)i=1,..,p in time: O min(g ∗ |Hist(S)| + Hist(S) , g ∗ |S|
p
Therefore, the creation of Histi (R)i=1,..,p and Histi (S)i=1,..,p requires:
|R|
+
p
|S|
+ min(g ∗ |Hist(S)| + Hist(S) , g ∗
+
p

T imestep.a = O min(g ∗ |Hist(R)| + Hist(R) , g ∗

R
)
p
S
)+l .
p

b. A stage of creation of the fragments Histi (R S)i=1,..,p :
S) is computed, on each processor i, by intersecting Histi (R) and
Histi (R
Histi (S) (i.e. by calculating {v|v ∈ Histi (R)} ∩ {v|v ∈ Histi (S)}), in time:
T imestep.b = O maxi=1,..,p (min( Histi (R) , Histi (S) )) .

c. We then compute, on each processor j, the intersections:
j

Hist (Ri ) = Histj (Ri ) ∩ Histj (R
j
Hist (Si ) = Histj (Si ) ∩ Histj (R

in time: O

i

Histj (Ri ) +

i

S) for i = 1, .., p and
S) for i = 1, .., p

Histj (Si ) .
⎧
j
⎨
i Hist (Ri ) ≤ min

In accordance with stage a., one has:

⎩

Hist(R) ,

Histj (Si ) ≤ min

Hist(S) ,

R
) + min( Hist(S) ,
p

S
) .
p

i

R
p
S
p

,

and thus the total cost of this stage is:
T imestep.c = O min( Hist(R) ,

d. A stage of communication where each processor i sends each fragment
j
Hist (Ri ) to processor j: During this stage of communication, each procesj
sor i, receives j |Hist (Ri )| pages of data from the other processors in time

An Eﬃcient Equi-semi-join Algorithm for Distributed Architectures

O(

761

j

j

g ∗ |Hist (Ri )| + l). We point out that: Hist(Ri ) = ∪j Histj (Ri ) and that:

|Hist(Ri )| =

j

|Histj (Ri )| ≥

and thus |Hist(Ri )| ≥

j

j

|Histj (Ri ) ∩ Hist(R

S)|

j |Hist (Ri )|. Consequently the total cost of this stage is

at most: T imestep.d = O g ∗ |Hist(Ri )| + l .
j

Remark 2. ∪j Hist (Ri ) is simply the intersection of Hist(Ri ) and Hist(R
j
S). This intersection is noted: Hist(Ri ) = ∪j Hist (Ri ) = Hist(Ri ) ∩ Hist(R S).
e. A stage of the local semi-joins Ri S and Si R computation:
Owing to the fact that, at the end of stage d., each processor i holds the fragment
Hist(Ri ) = Hist(Ri ) ∩ Hist(R S), the semi-join Ri S (resp. Si R) can be
computed, in parallel on each processor i, by a scan of the fragment Ri (resp. Si )
and consulting the histogram Hist(Ri ) in time O( Ri ) (resp. O( Si )). Thus,
the total cost of this stage is: T imestep.e = O maxi=1,..,p ( Ri + Si ) .
The total cost of the two semi-joins R S and S R computation, is thus
the sum of the above ﬁve stages:
|R|
R
+
) + max Ri
i=1,..,p
p
p
|S|
S
+ min(g ∗ |Hist(S)| + Hist(S) , g ∗
+
) + max Si + l .
i=1,..,p
p
p

T imesj = O min(g ∗ |Hist(R)| + Hist(R) , g ∗

Using the previous results, the following proposition gives an upper bound
the global BSP cost for semi-join computation.
Proposition 3. Let Ri=1,..,p and Si=1,..,p be the fragments of R and S on p
processors. The semi-joins R S and S R can be carried out in time:
T imesemi−joins = O ci/o ∗ max (|Ri | + |Si |) + max
i=1,..,p

i=1,..,p

Ri + max

i=1,..,p

Si + l

R
|R|
+
)
p
p
|S|
S
+ min(g ∗ |Hist(S)| + Hist(S) , g ∗
+
) ,
p
p
+ min(g ∗ |Hist(R)| + Hist(R) , g ∗

where ci /o is the cost to read/write a page of data from disk.
Proof : Starting from the local fragments Ri=1,..,p (resp. Si=1,..,p ) of relation
R (resp. S), the local histograms Hist(Ri )i=1,..,p (resp. Hist(Si )i=1,..,p ) can be
created in parallel by a scan of Ri (resp. Si ) on processor i in time: ci/o ∗
maxi=1,..,p |Ri | (resp. ci/o ∗ maxi=1,..,p |Si |). Hence this step costs:
T imesja = O ci/o ∗ max (|Ri | + |Si |) ,
i=1,..,p

At the end of this step, each processor i holds Hist(Ri ) and Hist(Si ).

762

M. Bamha and G. Hains

By using Proposition 2 and by using an appropriate hashing function (see remark
1), the two semi-joins, R S and S R are computed in time:
T imesjb = O min g ∗ |Hist(R)| + Hist(R) , g ∗
+ min g ∗ |Hist(S)| + Hist(S) , g ∗

|R|
R
+
p
p

|S|
S
+
p
p

+ max

i=1,..,p

+ max

i=1,..,p

Ri

Si + l .

The semi-joins computation has the sum of the above two costs, which completes
the proof of the proposition.
Remark 3. Sequential semi-joins R S and S S require at least the time to
scan input relations R and S: boundinf1 = Ω ci/o ∗ |R| + R + ci/o ∗ |S| + S .
Parallel processing using p processors requires therefore boundinfp = p1 ∗boundinf1 .
We recall that, in all existing parallel semi-join algorithms, semi-joins are
performed in two phases: a redistribution phase (generally based on hashing
functions) according to the values of the semi-join attribute of input relations and
then a sequential scan of local relations. In these algorithms, the redistribution
phase is very sensitive to data skew [2, 3, 1].
Using our approach, the semi-join computation requires only the distribution
of histograms which make it insensitive to data skew. The complexity of our
algorithm is asymptotically optimal owing to the fact that all the terms of the
global BSP cost are of the same order of those of boundinfp .

3

Conclusion

In this paper, we have introduced the ﬁrst parallel semi-join algorithm allowing
to reduce the communication costs to the minimum owing to the fact that only
histograms are redistributed across the network and the sizes of these histograms
are very small compared to the sizes of input relations.
Using the BSP cost model, the algorithm is proved to have an asymptotic
optimal complexity while guaranteeing perfect balancing properties even in the
presence of highly skewed data. This algorithm can be used eﬃciently to optimize
the execution time of complex queries by reducing the amount of input data for
each sub-query and the communication costs.
Future work will consist in studying how histograms could be used to generate eﬃcient query execution plans for complex queries. We also plan to study
how these histograms could help to optimize resource allocation in distributed
architectures.

References
1. M. Bamha and M. Exbrayat. Pipelining a skew-insensitive parallel join algorithm.
Parallel Processing Letters, Volume 3, Number 3, pages 317–328, 2003.

An Eﬃcient Equi-semi-join Algorithm for Distributed Architectures

763

2. M. Bamha and G. Hains. A skew insensitive algorithm for join and multi-join
operation on Shared Nothing machines. In the 11th International Conference on
Database and Expert Systems Applications DEXA’2000, volume 1873, 2000.
3. M. Bamha and G. Hains. A frequency adaptive join algorithm for Shared Nothing machines. Journal of Parallel and Distributed Computing Practices (PDCP),
Volume 3, Number 3, pages 333-345, September 1999.
4. J. Lawrence Carter and Mark N. Wegman. Universal classes of hash functions.
Journal of Computer and System Sciences, 18(2):143–154, April 1979.
5. D. J. DeWitt, J. F. Naughton, D. A. Schneider, and S. Seshadri. Practical Skew
Handling in Parallel Joins. In Proceedings of the 18th VLDB Conference, pages
27–40, Vancouver, British Columbia, Canada, 1992.
6. K. A. Hua and C. Lee. Handling data skew in multiprocessor database computers
using partition tuning. Proc. of the 17th International Conference on Very Large
Data Bases, pages 525–535, Barcelona, Catalonia, Spain, 1991.
7. M. Kitsuregawa and Y. Ogawa. Bucket spreading parallel hash: A new, robust,
parallel hash join method for skew in the super database computer (SDC). 16th
International Conference on Very Large Data Bases, pages 210–221, 1990.
8. M. Seetha and P. S. Yu. Eﬀectiveness of parallel joins. IEEE, Transactions on
Knowledge and Data Enginneerings, 2(4):410–424, December 1990.
9. D. B. Skillicorn, J. M. D. Hill, and W. F. McColl. Questions and Answers about
BSP. Scientific Programming, 6(3):249–274, 1997.
10. Konrad Stocker, Donald Kossmann, Reinhard Braumandl, and Alfons Kemper.
Integrating semi-join-reducers into state-of-the-art query processors. In Proceedings
of the 17th International Conference on Data Engineering, pages 575 – 584, 2001.
11. Joel L. Wolf, Daniel M. Dias, Philip S. Yu, and John Turek. New algorithms
for parallelizing relational database joins in the presence of data skew. IEEE
Transactions on Knowledge and Data Engineering, 6(6):990–997, 1994.

