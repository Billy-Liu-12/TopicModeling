Towards a Bayesian Approach to Robust
Finding Correspondences in Multiple View
Geometry Environments
Cristian Canton-Ferrer, Josep R. Casas, and Montse Pard`
as
Image Processing Group, Technical University of Catalonia,
Barcelona, Spain
{ccanton, josep, montse}@gps.tsc.upc.es

Abstract. This paper presents a new Bayesian approach to the problem of ﬁnding correspondences of moving objects in a multiple calibrated
camera environment. Moving objects are detected and segmented in multiple cameras using a background learning technique. A Point Based Feature (PBF) of each foreground region is extracted, in our case, the top.
This features will be the support to establish the correspondences. A
reliable, eﬃcient and fast computable distance, the symmetric epipolar
distance, is proposed to measure the closeness of sets of points belonging
to diﬀerent views. Finally, matching the features from diﬀerent cameras
originating from the same object is achieved by selecting the most likely
PBF in each view under a Bayesian framework. Results are provided
showing the eﬀectiveness of the proposed algorithm even in case of severe occlusions or with incorrectly segmented foreground regions.

1

Introduction

Multi camera systems are being widely used for image and video analysis tasks
in SmartRooms, surveillance, body analysis or computer graphics. Multiple view
geometry has been addressed in [4, 9] from a mathematical viewpoint, but there
is still work to be done for the eﬃcient fussion of redundant camera views and its
combination with image analysis techniques for object detection and tracking. In
this framework, the current paper addresses the problem of ﬁnding meaningful
correspondences between regions in diﬀerent views.
In multiple camera environments, given an image sequence, the problem is to
ﬁnd the correspondences among feature points across the images that represent
the projection of the same object in the real world in diﬀerent camera views.
Once these correspondences among all feature points are available, they can be
used for object tracking and identiﬁcation, motion analysis and scene analysis.
This material is based upon work partially supported by the IST programme of the
EU through the NoE IST-2000-32795 SCHEMA and IP IST-2004-506909 CHIL and
by TEC2004-01914 project of the Spanish Government.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 281–289, 2005.
c Springer-Verlag Berlin Heidelberg 2005

282

C. Canton-Ferrer, J.R. Casas, and M. Pard`
as

(a)

(b)

Fig. 1. In (a) there is an example frame from a multiview camera environment: SmartRoom at UPC. In (b) the result of a foreground segmentation and extraction of labeled
blobs

The output of a multiview correspondence algorithm is a set of links, ideally
representing how a unique point or an object in the real world corresponds to a
speciﬁc position in each projected image. For applications like particle tracking
or 3D tracking of a number of objects in a cluttered scene with strong occlusions,
the redundancy in the diﬀerent projections should help to overcome occlusion
problems.
For a given frame in the video sequence, a set of N images are obtained from
the N cameras. Each camera is modeled using a pinhole camera model based on
perspective projection. Accurate camera calibration information is available. We
use a segmentation algorithm by [10] based on Stauﬀer-Grimson’s background
learning and substraction technique [12]. In spite of the good performance of this
technique, objects in the scene are oversegmented due to ilumination changes,
reﬂexions and other distorting elements typical in non-controlled environments.
Nevertheless, our algorithm proposes solutions to overcome oversegmentation
problems and still ﬁnds accurate correspondencies.
Once foreground regions are extracted, a labeling process is performed based
on connectivity rules, thus obtaining a set of enumerated disjoint foreground
regions. Let us denote Bki (x, y), the set of pixels belonging to the k-th labeled
foreground region at the i-th camera view and denote this set as blob. The work
presented in this paper addresses the problem of establishing the correspondences among the set of blobs representing the projection of the same object in
the diﬀerent cameras. Once these correspondences are decided, this information
can be used by further video processing modules such as the initialization of a
multiocular tracker [6, 11], body gesture analysis [8] or 3D reconstruction [3].
There are two contributions in this paper. First, the application of a fast and
simple cross-view point-to-point distance based on epipolar geometry, the symmetric epipolar distance, for guessing possible correspondences among views.

Robust Finding Correspondences in Multiple View Geometry Environments

283

Then, a probabilistic approach to select the right geometric correspondences
among blobs present in diﬀerent views. This method takes into account occlusions and solves them by exploiting redundant information in multiple views.

2

Multiple Camera Object Correspondence

In order to compute candidate 3D locations of objects, an algorithm that guesses
which foreground regions from diﬀerent cameras belong to the same object is
required. This grouping of foreground regions is depicted as a correspondence
guess. In order to tell valid correspondence guesses from invalid guesses, a Point
Based Feature (PBF) from each foreground region is extracted. A cross-view
point-to-point distance is introduced to evaluate the validity of each correspondence guess. Correspondence hypotesis are generated by a sequential minimization procedure and, ﬁnally, a Bayesian decision algorithm evaluates the correspondence candidates in order to decide whether they are valid or not.
Existing correspondence algorithms [6, 11] rely on nonlinear least-square solutions or overdetermined linear systems. However, by increasing the views (cameras) or the number of detected objects, these systems turn out to be increasingly
computationally expensive and, therefore, not appropriate for real-time systems.
Other methods [1, 9] rely on homographies between images but, for wide angle
lense cameras (such as the SmartRoom’s case) homographies present signiﬁcant
distortion.
2.1

Symmetric Epipolar Distance

In order to ﬁnd correspondences among blobs in diﬀerent views, a distance that
measures how close are the points of a set of points D(p) = {x0 , x1 , ..., xp−1 }
in p diﬀerent views must be deﬁned. In this case, closeness is understood as
how well these points ﬁt as projections of the same 3D point. This distance
should be accurate, reliable and fast to compute. Under these conditions, symmetric epipolar distance, a 2 -distance between points in diﬀerent views based
on epipolar geometry is employed. This distance was used in [14] to compare
fundamental matrix estimations and has proven to be eﬀective for our purposes.
This distance is presented for the case of two points in two diﬀerent views and
afterwards extended to the general case.
Let l xi , j be the epipolar line generated by the point xi onto view j. We
deﬁne the symmetric epipolar distance between two points dSE (xi , xj ), in the
two views i,j, as:
dSE (xi , xj )

d2 (l(xi , j), xj ) + d2 (l(xj , i), xi ),

(1)

where d(l(xi , j), xj ) is deﬁned as the Euclidean distance between the epipolar
line l xi , j and the point xj as depicted in Fig.2. It can be shown that the
extension of the symmetric epipolar distance for p ≥ 2 points (in p diﬀerent
views) dSE (x0 , x1 , ..., xp−1 ) can be written in terms of the distance deﬁned in
Eq.1 as:

284

C. Canton-Ferrer, J.R. Casas, and M. Pard`
as
p−2

p−1

dSE (x0 , x1 , ..., xp−1 ) ≡ dSE (D(p)) =

dSE (xi , xj ).

(2)

i=0 j=i+1

Hence, if the set D(p) is formed by projections of the same location in the 3D
world, the distance between them should be very small (ideally zero).
The main advantage of this distance is its simplicity in contraposition with
other distances where inverse matrix computations or homography estimation
are required [9, 11]. However, despite this distance does not give a meaningful
measure of a physical distance, it turns out to deal successfully with multiple
view (p ≥ 3) correspondence problems as explained in Sect. 2.3. When p < 3,
two 3D points lying in the same epipolar plane would result in a small distance,
hence the necessity of p ≥ 3 in order to resolve the ambiguity.
View from cam 0

View from cam 1

l( x 1
, 0)

x1
d(l(x0 , 1), x1 )

d(l(x1 , 0), x0 )
x0

0
l(x , 1)

Fig. 2. Symmetric epipolar distance between two points d(x0 , x1 )

2.2

Point Based Features (PBF)

Point based features are those that only take into account a 3D point and the
projection of this point in the existing views. To establish correspondences among
blobs in diﬀerent views, the centroids of blobs have been extensively used as a
feature [6, 7, 11]. In the case of SmartRooms and cluttered scenes in general,
blobs are aﬀected by severe oclusions (due to furniture or other moving objects),
hence their centroids are biased and not suitable as a correspondence feature.
The tops of blobs in each view deﬁned as
tik =

1
2

min min Bki (x, y) + max min Bki (x, y) ,
x

y

x

y

(3)

with i and k being the blob and camera index respectively, have been used as
our PBF. It should be noted that the number of PBFs detected in one view may
be diﬀerent from another view.
In contraposition with other features, blob tops represent a meaningful
point of the object and once correct correspondences are found, it can be used
for forecoming analysis modules of the system (for example, estimating the
height of a person). However, it must be said that for cameras positioned in a
very low position, tops can be slightly biased due to the lack of visibility of the
real top.

Robust Finding Correspondences in Multiple View Geometry Environments

2.3

285

Finding Correspondence Candidates

Once a distance is deﬁned, a method for ﬁnding and evaluating candidate correspondences between PBFs in diﬀerent views is straightforward. Furthermore, if
correct point correspondences can be found, blob correspondences across views
are derived as well.
Let us suppose that a 3D point X, has projections xi on all the N cameras
of our system. Despite this assumption is quite strong, let us deﬁne a method
to ﬁnd the correspondence guess and, afterwards improve it to deal with less
restrictive assumptions. Then, we must choose the set D (N ) that accomplishes
D (N ) = min dSE ({D(N )}),
D(N )

(4)

where {D(N )} is the set of all possible correspondence candidates, that is all PBF
combinations across all views.This process can be acchieved by either browsing
all the possible combinations or reducing the search space with a priori geometric
or probabilistic constraints [13].
In the case where multiple targets are present, M correspondence guesses
should be determined. In this case, a sequential minimization procedure has
been proposed according to [2]. This process is done by selecting the set D (N )
that minimizes the distance at a given iteration and then discarding the N
points chosen for the next step, thus decreasing the search space dimension.
This process is executed until M sets Dk (N ), 1 ≤ k ≤ M , are selected. Results
for this technique applied to ﬁnd the correspondences between N = 4 views with
M = 4 moving objects in a SmartRoom are shown in Fig.3.
In contraposition with the former method, a global minimization method to
ﬁnd the set Dk (N ) fulﬁlling the criteria
M −1

Dk (N ) = min

Dk (N )

dSE (Dk (N )),

(5)

k=0

has also been studied. That is to ﬁnd the M sets Dk (N ) that minimize the
total distance. Unfortunately, this problem turns out to be analogous to the
overcomplete representation problem [5] and therefore an intractable NP-hard
problem.
In the case when the 3D feature X does not have a projection in one or some
of the views, our algorithm can still produce correspondence guesses if there
are at list 3 projections of X available. We can ﬁnd sets D (p), 3 ≤ p ≤ N by
allowing our minimization algorithm to build up the correspondence candidates
D(p) including a null-projection in one or some views. Once a correspondence
˜ of the 3D position of feature X can be estimated
D (p) is found, an estimation X
with a joint estimation back-projected ray with outlier rejection method [4]. By
˜ onto all the camera planes we can obtain the set D
¯ (N ) that
projecting back X
completes the missing projections of D (p) in the case where p < N . Moreover,
since the information contributed by all the views is taken into account in the
˜ this new set D
¯ (N ) reﬁnes the original one diminishing local
estimation X,
errors.

286

C. Canton-Ferrer, J.R. Casas, and M. Pard`
as

Fig. 3. Distance vs. Number of points selected with N = 4 and M = 4. The ﬁrst 4
correspondences present a small and similar distance but, since the ﬁfth corresponcence
and following do not belong to any 3D point, their distances increase noticeably

2.4

Bayesian Correspondence Algorithm

The method proposed in the former subsection is able to produce M correspondence guesses for a given number of cameras p. However, since these parameters
have to be selected manually, an adaptive algorithm that guesses the number of
existing valid correspondences M and selects the optimum number of views p
for each correspondence is required.
As a ﬁrst step of this algorithm, it must be determined whether a correspondence D (p) is formed by projections of the same 3D feature, denoting this
property as belonging to the set V, namely D (p) ∈ V. For this task a Bayesian
approach is employed. The posteriori probability of D (p) ∈ V given its symmetric epipolar distance dSE (D (p)) is formally:
P (D (p) ∈ V|dSE (D (p)) =

P (dSE (D (p)|D (p) ∈ V)P (D (p) ∈ V)
.
P (dSE (D (p))

(6)

Since the priors P (D (p) ∈ V) and P (dSE (D (p)) are wide and uninformative,
Eq.6 can be rewritten as:
P (D (p) ∈ V|dSE (D (p)) ∝ P (dSE (D (p)|D (p) ∈ V),

(7)

where the probability P (dSE (D (p)|D (p) ∈ V) is modeled as a Gaussian distribution N (mp , σp ). Parameters mp and σp are tunable depending on the accuracy
of the segmentation algorithms and the geometry of the environment. This assumption is indeed valid after our observation of the average distribution of
the distance dSE (D (p)). For each value of p, this distribution will be diﬀerent,
obbeying the rule mp ≥ mp−1 since the less views are taken into account for the
correspondence of the projection of X, the less the overall distance. Conversely,

Robust Finding Correspondences in Multiple View Geometry Environments

287

˜ results. Hence,
the less the views employed, the less accurate the estimation X
correspondences with the most views will be preferred. As a direct aplication
of this theory, the implementation of our algorithm is based on the sequential
selection of the sets D (p) with larger p and higher probability in decreasing
order. The algorithm stops when the probability is under a certain threshold α
(for our experiments α > 0.7).

3

Results

In order to evaluate the performance of the proposed algorithm, we used it to set
correspondences in a SmartRoom equiped with 4 fully calibrated cameras where
foreground blobs represented people. A sequence of 2000 frames was recorded
simulating a presentation meeting with 4 atendees.
The images were segmented but, due to oversegmentation, we obtained more
blobs per image than the number of persons. Consequently, the possible combinations grew up to an average of 20000 combinations per set of images. Even in this
harsh conditions, the algorithm was able to perform eﬀectively. For comparison
purposes, Table 1 shows the performance of our algorithm for two types of PBFs,
tops and centroids, where tops outperformed the existing algorithms based on
centroids. Fig. 4 illustrates successful correspondences established among blobs
representing people in a SmartRoom.
Table 1. Results of correct match and conﬁdence (P¯ ) of the correspondence estimation
obtained by applying our correspondence algorithm on 200 frames chosen at random
over a sequence of 2000
Correct Match (%) P¯ (%) Correct Match(%)
P¯ (%)
PBF top
PBF top PBF centroid PBF centroid
Person
Person
Person
Person

4

1
2
3
4

99.8
99.77
96.04
95.8

99.2
98.62
91.3
85.6

11.76
41.18
50.78
44.31

21.3
43.27
37.5
29.0

Conclusions and Future Work

We have presented an algorithm for ﬁnding correspondences between regions in
a multiple camera environment. The algorithm employs a probabilistic criterion
for matching PBFs in diﬀerent cameras, in our case the top of the blobs, and
has proven very reliable, outperforming the existing approaches to this problem.
The results of the algorithm are interesting for the initialization a multiocular
tracking of multiple people system, multiview face or body detection, analysis
and recognition.
Experimental results verify that we can obtain good quantitative 3D parameters from 2D image observations of people in the scene. We have demonstrated

288

C. Canton-Ferrer, J.R. Casas, and M. Pard`
as

(a)

(b)

Fig. 4. Two examples of the application of our correspondence algorithm. Figure (a)
shows its utility for multi-view face detection where the faces of the four people are
being localized in all views providing reliable data for higher level analysis. In (b)
correspondences are being correctly established in the framework of body analysis

that correspondences between blobs belonging to the same physical object can
be found even if the object does not have a projection in some of the views.
Future research perspectives involve the development of robust 2D/3D tracking
of this PBF correspondences.

References
1. Black, J., Ellis, T.: Multi Camera Image Tracking. In Proc. IEEE Work. on Performance Evaluation of Tracking and Surveillance, 2001.
2. Boyd, S., Vandenberghe, L.: Convex Optimization. 1st edn. Cambridge University
Press, 2004.
3. Eisert, P., Steinbach, E., Girod, B.: Multi-hypothesis, volumetric reconstruction of
3D objects from multiple calibrated camera views. In Proc. IEEE Int. Conf. on
Acoustics Speech and Signal Processing, pp. 3509–3512, 1999.
4. Faugeras, O., Luong, Q.T.: The geometry of multiple views. 1st edn. MIT Press,
2001.
5. Figueras, R.M.: Image Coding with Matching Pursuit. MS Thesis, EPFL, 2000.
6. Focken, D., Stiefelhagen, R.: Towards vision-based 3D people tracking in a smart
room. In Proc. IEEE Int. Conf. on Multimodal Interfaces, pp. 400–405, 2002.
7. Fuentes, L.M., Velastin, S.A.: People Tracking in Surveillance Applications. In
Proc. IEEE Work. on Performance Evaluation of Tracking and Surveillance, 2001.
8. Gavrila, D. M., Davis, L. S.: 3D Model Based tracking of humans in action: a
multi-view approach. In Proc. of Computer Vision and Pattern Recognition, pp.
73–80, 1996.
9. Hartley, R.I., Zisserman, A.: Multiple View Geometry in Computer Vision. 2nd
edn. Cambridge University Press, 2004.

Robust Finding Correspondences in Multiple View Geometry Environments

289

10. Landabaso, J.L., Xu, L.Q., Pard`
as, M.: Robust Tracking and Object Classiﬁcation
Towards Automated Video Surveillance. In Proc. Int. Conf. on Image Analysis and
Recognition, pp. 463–470, 2004.
11. Mikic, I., Santini, S., Jain, R.: Tracking Objects in 3D using Multiple Camera
Views. In Proc. Asian Conf. on Computer Vision, pp. 234–239, 2000.
12. Stauﬀer, C., Grimson, W.E.L.: Adaptive background mixture models for real-time
tracking. In Proc. IEEE Int. Conf. on Computer Vision and Pattern Recognition,
pp. 252–259, 1999.
13. Triggs, B.: Joint Feature Distributions for Image Correspondence. In Proc. IEEE
Int. Conf. on Computer Vision, pp. 201–208, 2001.
14. Zhang, Z.: Determining the epipolar geometry and its uncertainty-a review. In Int.
Jour. of Computer Vision, 27(2):161–195,1998.

