Automatic Tuning of Data Distribution Using Factoring
in Master/Worker Applications1
Anna Morajko, Paola Caymes, Tomàs Margalef, and Emilio Luque
Computer Science Department. Universitat Autònoma de Barcelona,
08193 Bellaterra, Spain
{ania, paola}@aomail.uab.es
{tomas.margalef, emilio.luque}@uab.es

Abstract. Parallel/Distributed programming is a complex task that requires a
high degree of expertise to fulfill the expectations of high performance computation. On the one hand, application developers must tackle new programming
paradigms, languages, libraries. On the other hand they must consider all the issues concerning application performance. On this context the Master/Worker
paradigm appears as one of the most commonly used because it is quite easy to
understand and there is a wide range of applications that match this paradigm.
However, to reach high performance indeces it is necessary to tune the data distribution or the number of Workers considering the particular features of each
run or even the actual behavior that can change dynamically during the execution. Dynamic tuning becomes a necessary and promising approach to reach the
desired indeces. In this paper, we show the usage of a dynamic tuning environment that allows for adapting the data distribution applying Factoring algorithm
on Master/Worker applications. The results show that such approach improves
the execution time significantly when the application modifies its behavior during its execution.

1 Introduction
Parallel and distributed systems offer high computing capabilities that are used in
many scientific research fields. These capabilities have taken the evolution of science
to a new step called computational science. This facilitated the determining of the
human genome, computing the atomic interactions in a molecule or simulating the
evolution of the universe. So biologists, chemists, physicians and many other researchers have become intensive users of high performance computing. They submit
very large applications to powerful systems in order to get the results as fast as possible, considering the largest problem size and taking advantage of the resources available in the system. The increasing need of high performance systems has driven scientists towards parallel/distributed systems. Although such systems have their performance limits, they are much more powerful than the rest of the computers and
hence are better for solving scientific problems demanding intensive computation.
1

This work has been supported by the MCyT (Spain) under contract TIC2001-2592 and has
been partially supported by the Generalitat de Catalunya – GRC 2001SGR-00218.

V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 132 – 139, 2005.
© Springer-Verlag Berlin Heidelberg 2005

Automatic Tuning of Data Distribution Using Factoring in Master/Worker Applications

133

Problems covered by computational science usually comprise a lot of calculations
which are easily parallelizable, and consequently applications to solve these problems
can be designed using the Master/Worker (M/W) paradigm [1]. Typically, in the M/W
paradigm a Master process in each iteration distributes data among Worker processes
and waits for their response. Each Worker processes its portion of data independently
of the remaining Workers and returns the results to the Master. When the Master
receives results from the Workers, it may distribute the data again. There are many
cases the Master must synchronize all the results from all the Workers before the next
data distribution. However, heterogeneous computing and communication powers, or
varying the amount of distributed data could cause load imbalance. In these situations
slower or overloaded machines and/or incorrect data distribution may significantly
increase the idle time of processes and influence into the application execution time.
The workload balancing goal therefore is to minimize the idle time and calculate the
right amount of data for each process. Load balancing should be achieved in such a
way that fast computers will automatically process more amount of data than the
slower ones. Moreover, an optimal data distribution may also depend on dynamic
factors such as input data, network load, computer load and so on. Before the application execution, developers do not know these parameters, hence they cannot distribute
the work properly. Therefore, it can be beneficial to dynamically tune the data distribution by adapting it to changing conditions. In this context, our goal is to balance
and distribute data correctly and dynamically among the available processes taking
into account capabilities and load of the machines the application runs on.
In the following sections of this paper, we present a complete performance optimization scenario that considers the data distribution problem in a dynamic approach. In
Section 2, we describe the algorithm used to distribute the data. In Section 3, we analyze the tuning of the data distribution by using the MATE environment that supports
dynamic tuning of parallel applications. In Section 4, we present the results of experiments conducted in the MATE to dynamically tune the data distribution using the
presented algorithm. Finally, Section 5 shows the conclusions of this work.

2 Factoring Data Distribution
The data distribution from a Master process to the Worker ones can be done in several
different ways considering different algorithms. One possibility is to divide the total
data n in p chunks, where p is the number of Workers and distribute one of these
chunks to each Worker. However, if there is any heterogeneity in the system the faster
processors will be waiting for the slower ones. Another possibility is to divide the
total data in m same-size chunks, where m is greater than p. In this case, the Master
distribute the p first chunks to the Workers. When one Worker finishes its work, it
returns the result to the Master and if there are chunks to be processed, the Master
sends to that Worker a new chunk. A third possibility is to create chunks of different
size in such a way that the initial distribution consider bigger chunks and when there
are less data to be processed, the amount distributed is smaller.
One of the algorithms using this third approach is the Factoring Scheduling algorithm [2]. In the factoring algorithm, the work is partitioned according to a factor into
a set of different-size tuples. The Master distributes one tuple to each Worker. If a

134

A. Morajko et al.
Table 1. Examples of tuple sizes for different factors

Work
size (N)

Threshold
(T)

Tuples

1000
1000

Number of Factor
Workers
(f)
(P)
2
1
2
0.5

1
1

1000

2

0.5

16

1000
1000
1000

2
4
4

0.7
1
0.5

1
1
1

1000

4

0.5

16

1000

4

0.7

1

500,500
250,250,125,125,63,63,32,32,16,16,8,8,4,4,
2,2,1,1
250, 250, 125, 125, 62, 62, 32, 32, 16, 16,
16, 16
350, 350, 105, 105, 31, 31, 10, 10, 3, 3, 1, 1
250, 250, 250, 250
125, 125, 125, 125, 62, 62, 62, 62, 32, 32,
32, 32, 16, 16, 16, 16, 8, 8, 8, 8, 4, 4, 4, 4, 2,
2, 2, 2, 1, 1, 1, 1
125, 125, 125, 125, 62, 62, 62, 62, 32, 32,
32, 32, 16, 16, 16, 16, 16, 16, 16, 16
175, 175, 175, 175, 52, 52, 52, 52, 16, 16,
16, 16, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1,

Fig. 1. Execution time in function of factor f (N=1000, P=4, T=1, relative speeds: 1,3,3,3)

Worker has finished its tuple and there are tuples to be processed, then it receives the
next tuple. This cycle is repeated till all the tuples of the work are processed.
Assuming there are P parallel Workers, a threshold T>0 (minimal tuple size) and a
factoring value (0<f<=1), the sizes of factored work tuples are calculated according to
the following algorithm [2]:

Automatic Tuning of Data Distribution Using Factoring in Master/Worker Applications
R0 = N (total work size)
Repeat
For each P
Gi = Ri * f / P
Ri+1 = Ri - (P*Gi)
until Ri < T.

135

//Gi: ith tuple size
//Ri+1: remaining work size

The example tuple sizes calculated according to the presented above factoring algorithm are shown in Table 1.
Figure 1 shows the execution time of an example application in a particular condition considering different values for the factor f. As it can be observed, the value of
the factor f influences strongly the execution time of the application.

3 Tuning Factor f with MATE
To provide dynamic automatic tuning of parallel/distributed applications we have
developed an environment called MATE (Monitoring, Analysis and Tuning Environment) [3]. MATE performs dynamic tuning in three basic and continuous
phases: monitoring, performance analysis and modifications. This environment
dynamically and automatically instruments a running application to gather information about the application behavior. The analysis phase receives events, searches for
bottlenecks, detects their causes and gives solutions on how to overcome them.
Finally, the application is dynamically tuned by applying given solution. Moreover,
while it is being tuned, the application does not need to be re-compiled, re-linked
and restarted.
The knowledge to represent the performance model of each particular performance problem is specified in a component called “tunlet”. Each tunlet includes the
information concerning the measure points to insert instrumentation in the target
application, the performance model to determine the behavior of the application and
the required modifications, and the tuning actions to improve the application performance.
We have been conducted many various practical experiments on parallel/distributed applications to see if our approach really works. We have proven that it
is effective, profitable, and can be used for a real improvement of the program performance. Running applications under control of MATE has allowed for adapting
their behavior to the existing conditions and improving their functionality [4].
To dynamically tune the data distribution we had to consider several issues:
• How to calculate work tuples (factoring algorithm described in previous section).
• How to distribute the data according to the given factor.
• How to calculate the optimal Factor and what is required to calculate this value.
To tune the Factor f applying the MATE environment, the application must be
prepared for the tuning actions and hence it must implement adequately the data
distribution:

136

A. Morajko et al.
For each iteration
//according to the factoring algorithm
Calculate work tuples for a given factor
//first work distribution to all Workers
For each Worker
Send corresponding tuple
//if there are still tuples to be distributed
While distributed tuples < Total number of tuples
Receive results
Send corresponding tuple
//if there are still tuples to be completed
While completed tuples < Total number of tuples
Receive results

During the execution, we can monitor the PVM functions responsible for exchanging messages, e.g. pvm_send() and pvm_recv(). In particular, by monitoring: send
entry/exit, receive entry/exit events in the Master process, and receive entry/exit and
send entry/exit in all Worker processes, we are able to perform all necessary measurements. To find the optimal value of the Factor the performance model must provide the prediction of the iteration time. For this purpose we implemented the simulation of the application iteration time according to the following:
For each processor
Calculate Latency
Calculate Bandwidth
Calculate work unit execution time (i.e. processor speed)
For each Factor f (0<f<=1)
Calculate tuples
Calculate application iteration execution time
While there is work left
For each process (using time counter)
If process is free
Assign tuple for process
Time++
Chose the minimal time of application iteration
Set Factor value to the minimal Factor value

The presented algorithm simulates the execution of the program iteration for each
chosen possible value of Factor f. The simulation uses basic measurements such as
network latency, bandwidth and current speed for each processor. The algorithm
simulates the complete iteration by assigning subsequent work tuples to next free
processor. It takes into account the time for sending the work, time for processing the
work on the selected processor in function of its current speed (i.e. capacity and current load), and time for returning the result. The iteration finishes when all tuples have
been processed, and the simulation records its execution time. After simulating iterations for all chosen factors, the algorithm returns the value f for the iteration with the
shortest execution time.
Considering the algorithm presented above we must receive a set of metrics to calculate the optimal Factor such as, network latency, network bandwidth, average
Worker speed expressed as the work unit processing time. To simplify the implementation, we have assumed network latency to be 1ms. Network bandwidth can be computed using the following formulas:

Automatic Tuning of Data Distribution Using Factoring in Master/Worker Applications

137

Tcomm = Tlatency + n * Tbandwith
Tbandwith = (Tcomm – Tlatency) / n
Tcomm = receive exit time on Master - send entry time on
Master – tuple processing time on a Worker

Work unit processing time is computed as the averaged value of the tuple processing time divided by number of work units per tuple. This is calculated individually
for each Worker. The average is taken for all work units processed during last iteration. This assumes the total iteration time is not very large and the average can express current machine load. If the iteration time is long, this should be changed to an
average taken for a given time window. Each iteration updates the work unit processing time value for each Worker and in this way we can keep track of dynamic variations in the load of the machines. It must be pointed out that this approach is suitable
only if the work unit processing time depends on the work unit size and not on its
content.
If a new value of the Factor is different than the current one, then the tuning action
should be performed. The tuning action includes the modification of the value of
specific predefined application variable. This variable represents the Factor of the
work and its name is well known to the tunlet. When a next iteration is performed in
the application, first, the new value of the Factor should be applied to recalculate the
work tuples, and then the data can be distributed. The variable modification does not
need to be synchronized, as the application will use its value next time the iteration of
work processing starts.

4 Experimental Results
In this section, the experimental results obtained by applying the tuning environment
to a real Master/Worker application are presented.
To conduct the experiments, we selected an intensive computing Forest Fire Propagation application called Xfire [5]. The Xfire application is a Master/Worker PVM
based implementation of the simulation of the fireline propagation. It calculates the
next position of the fireline considering the current fireline position and different
aspects as weather, wind, vegetation, etc.
In every scenario, one Worker was executed in the same machine as Master. Remainder Workers were executed in individuals machines.
Experiments were conducted on a cluster of homogenous Pentium 4, 1.8 Ghz,
(SuSE Linux 8.0) connected by 100Mb/sec network. Each experiment was performed
three times and the average of the execution time for the application was calculated.
We have conducted our experiments in three scenarios:
• In the first scenario, Xfire was executed in dedicated machines without any tuning and it was used as a reference result.
• In the second scenario, Xfire was executed in a non-dedicated environment; in
this case we have introduced a controlled variable load, using our Load Generator tool. We generated 75 % CPU load in a half of machines every eight iterations.

138

A. Morajko et al.

• The third scenario is exactly the same on the third one, but in this case Xfire
was executed under MATE applying the tuning of the data distribution. In this
way, we demanded more adaptability to the load balancing.
Table 2 summarizes the experimental results. These results are also presented in
figure 2.
Table 2. Execution time of Xfire (in seconds) considering different number of Workers
Number of Workers
Scenario
Xfire
Xfire + variable load
Xfire + MATE + variable load

1

2

4

8

16

30

17663

9126
11906
10206

4732
6098
5684

2488
3157
2784

1350
1501
1487

880
1208
1073

Execution time (Sec.)

18000
16000
14000
12000
10000

Xfire

8000
6000

Extra Load

4000

MATE

2000
0

1

2

4

8

16

30

Number of Workers
Fig. 2. Execution time of Xfire considering different number of Workers

This figure shows the execution time of the Xfire application considering different
number of Workers, the execution time of Xfire with additional load and the execution time of Xfire with additional load under the control of MATE. It can be observed
that the introduction of an extra load provokes an increase in the execution time of the
application. This is due to the new extra load, but also to the load imbalance introduced by the wrong Factor distribution in the new situation. The execution under
MATE control is able to detect the load imbalance and correct Factor to improve the
execution time.

5 Conclusions
Parallel and distributed programming offers high computing capabilities to the users
in many scientific research fields. The performance of applications written for such
environments is one of the crucial issues. Data distribution appears as one of the most
significant problems in Master/Worker applications. There are several approaches to

Automatic Tuning of Data Distribution Using Factoring in Master/Worker Applications

139

distribute data, but the main goal is to accomplish that there are no Workers idle waiting for busy ones. One of this approaches is the Factoring Scheduling. However, the
factoring requires the tuning of the Factor f that can change dynamically depending
on system load. In this context we show the applicability of the MATE dynamic tuning environment to improve the data distribution and the application performance by
tuning the value of the Factor f. The experimental results show that the MATE environment is very useful and improves the execution time significantly adapting application to changing conditions.

References
1. César, E., Mesa, J.G., Sorribes, J., Luque, E. “Modeling Master-Worker Applications in
POETRIES”. IEEE 9th International Workshop HIPS 2004, IPDPS, pp. 22-30. April, 2004.
2. Hummel, S.F., Schonberg, E., Flynn, L.E., “Factoring: A method for Scheduling Parallel
Loops”, Communications of the ACM, 35, no 8, August 1992.
3. Morajko, A., Morajko, O., Jorba, J., Margalef, T., Luque, E. “Dynamic Performance Tuning of Distributed Programming Libraries”. LNCS, 2660, pp. 191-200. 2003.
4. Morajko, A., Morajko, O., Margalef, T., Luque, E.. “MATE: Dynamic Performance Tuning
Environment”. LNCS, 3149, pp. 98-107 (2004).
5. Jorba, J., Margalef, T., Luque, E., Andre, J, Viegas, D.X. "Application of Parallel Computing to the Simulation of Forest Fire Propagation", Proc. 3rd International Conference in
Forest Fire Propagation, Vol. 1, pp. 891-900. Portugal, November 1998.

