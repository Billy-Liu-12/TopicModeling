Transaction Routing in
Real-Time Shared Disks Clusters
Kyungoh Ohn, Sangho Lee, and Haengrae Cho
Department of Computer Engineering, Yeungnam University,
Gyungsan, Gyungbuk 712-749, Republic of Korea
hrcho@yu.ac.kr

Abstract. This paper proposes a real-time transaction routing algorithm, which allocates real-time transactions to a node in a shared disks
cluster. Unlike traditional routing algorithms, which consider load balancing and transaction aﬃnity only, our algorithm also considers transaction priorities inherent to real-time applications.

1

Introduction

Although there has been a great deal of independent research in real-time processing and shared disks (SD) cluster, their aggregation has very little attention
[3]. The cluster technology enables highly available real-time database services,
which are the core of many telecommunication services. The cluster can also
achieve high performance real-time transaction processing by exploiting internode parallelism.
This paper proposes a real-time transaction routing algorithm in the SD
cluster. The transaction routing is a process of the front-end router to select an
execution node for an incoming transaction. The traditional transaction routing
algorithms of the SD cluster have two design goals: load balancing and transaction aﬃnity [4, 5, 6]. The load balancing means to avoid overloading individual
node. The transaction aﬃnity means to execute transactions with similar data
access pattern on the same node (aﬃnity node). To support real-time transactions, we have additional goal of transaction priority. This goal means to reduce
the number of transactions missing their deadlines by considering the deadline
as a priority. The contribution of this paper is to extend a well-performed traditional algorithm, named DACA (Dynamic Aﬃnity Cluster Allocation) proposed
by authors [4], to the real-time transaction processing.

2

Algorithm

We propose a new real-time transaction routing algorithm, named P-DACA (Priority conscious DACA). In this section, we ﬁrst describe our underlying model
This research was supported by University IT Research Center Project.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3516, pp. 1012–1015, 2005.
c Springer-Verlag Berlin Heidelberg 2005

Transaction Routing in Real-Time Shared Disks Clusters

1013

and then summarize the basic idea of DACA algorithm [4]. Lastly, we present
P-DACA algorithm that extends DACA for real-time transaction processing.
2.1

Assumption

A transaction router selects an execution node of each incoming transaction.
The node schedules the execution of its transactions with earliest deadline ﬁrst
(EDF) policy [1]. We assume the mixed real-time transaction workload [2], which
consists of real-time transactions and non real-time transactions. A real-time
transaction is assigned with a deadline. Executing the real-time transaction after
its deadline is meaningless.
We assume that the record-level locking is in eﬀect. In real-time applications,
the locking has to handle the priority inversion problem that lower priority
transactions block the execution of higher priority transactions. To prevent the
problem, we consider the locking model of [2]. Speciﬁcally, a real-time transaction aborts non real-time transactions holding locks in conﬂict mode. On the
other hand, a non real-time transaction always waits at lock conﬂict. The same
procedure holds between real-time transactions with diﬀerent priorities. High
priority transactions are always guaranteed to acquire locks without waiting.
2.2

DACA

To alleviate the routing overhead, DACA considers balancing the load of each
aﬃnity cluster (AC) [5]. An AC collects several transaction classes with high
aﬃnity to a given set of tables. The transaction router maintains routing parameters. Speciﬁcally, when a transaction router allocates a transaction of an
aﬃnity cluster ACq to a node Np , it increments both #T(ACq ) and #T(Np ),
which means the number of active transactions at ACq and at Np respectively.
Both counters are decremented when a transaction commits or aborts.
There are two overload types: AC overload and a node overload. The AC
overload implies that transactions of an AC are rushed into the system. The
node overload occurs when a node Np is allocated to several ACs and #T(Np )
is over average. DACA balances the load of each node according to the overload
type. If ACq is overloaded, then DACA allocates more nodes to ACq by node
expansion strategy. If there is no AC overload but Np is overloaded, then DACA
distributes some ACs assigned to Np to other node by AC distribution strategy.
DACA can make an optimal balance between the aﬃnity-based routing and
load balancing as follows. First, DACA tries to reduce the number of nodes allocated to the overloaded AC if the load deviation of each node is not signiﬁcant.
This allows DACA to reduce the frequency of inter-node cache invalidations.
Next, DACA prohibits allocating both an overloaded AC and other ACs to a
node. As a result, DACA can achieve high buﬀer hit ratio for the overloaded
AC. Even though several non-overloaded ACs may be allocated to a single node,
eﬃcient handling of the overloaded AC is more important to improve the overall
transaction throughput.

1014

K. Ohn, S. Lee, and H. Cho

2.3

Priority Conscious DACA (P-DACA)

Before describing the details of P-DACA, we ﬁrst illustrate the problem of DACA
when transactions have priorities. Example 1 shows the problem.
Example 1: Suppose there are two ACs (AC1 , AC2 ) and two nodes (N1 , N2 ).
N1 is an aﬃnity node of AC1 and executes a transaction t1 of priority 100. N2
is an aﬃnity node of AC2 and executes a transaction t2 of priority 60. At this
time, suppose a new transaction t3 of priority 70 arrives, and t3 belongs to AC1 .
Then DACA allocates t3 to its aﬃnity node N1 if N1 does not result in overload
state. However, t3 has lower priority than t1 and cannot be executed until t1
completes. So t3 has a higher probability of missing its deadline. On the other
hand, if t3 is allocated to N2 , then it can be executed immediately. ✷
The goal of P-DACA is (a) to reduce the number of transactions missing
their deadlines, and (b) to take advantages of aﬃnity clustering as DACA. To
achieve this goal, P-DACA performs the following three basic steps sequentially
to decide where a new real-time transaction tr will be routed to.
1. If there is an aﬃnity node of tr where the priority of tr becomes the highest
one, then allocate tr to that node.
2. If there is a non-aﬃnity node of tr where the priority of tr becomes the
highest one, then allocate tr to that node.
3. If there is no node that can execute tr immediately, then allocate tr to one
of its aﬃnity nodes.
The basic steps can be optimized if the transaction router maintains a priority
list for each node. The priority list is a sorted list in descending order of priorities
of active real-time transactions at the node. Then a new real-time transaction
tr has to be allocated to a node where tr can be executed faster than other
nodes. P-DACA checks this condition by comparing the relative position of tr
in the priority list of each node. Suppose P (tr ) means the priority of tr , and tr
is included in the aﬃnity cluster ACr . S(ACr ) is a set of aﬃnity nodes of ACr .
The followings summarize the transaction routing algorithm of P-DACA.
1. #T(ACr ) = #T(ACr ) + 1;
2. If (tr is a real-time transaction) then
(a) If (∃Np ∈ S(ACr ), rank(P (tr ), Np ) < w1 AND rank(P (tr ), Np ) <
rank(P (tr ), Ni ), for all Ni ∈ S(ACr ), i = p) then goto step 4;
(b) Else if (∃Np ∈
/ S(ACr ), rank(P (tr ), Np ) < w2 AND rank(P (tr ), Np ) <
/ S(ACr ), i = p) then goto step 5;
rank(P (tr ), Ni ), for all Ni ∈
(c) Else goto step 3.
3. Select Np , where #T(Np ) is minimum for all Ni ∈ S(ACr );
4. If (ACr is overloaded) then call node expansion(ACr );
5. Else if (Np is overloaded) then call ac distribution(Np );
6. #T(Np ) = #T(Np ) + 1; Insert P (tr ) into the priority list of Np ;
7. Return Np .

Transaction Routing in Real-Time Shared Disks Clusters

1015

At step 2, the function of rank(P (tr ), Np ) returns the number of transactions
whose priorities are higher than P (tr ) at Np . If the function returns 0, tr will
be a transaction with the highest priority at Np . The values w1 and w2 are
windowing constraints that limit the acceptable rank of tr . w1 is usually bigger
than w2 since an aﬃnity node of tr could complete tr faster. Note that if w1 and
w2 are set to 1, the algorithm works similarly to the above basic steps. A non
real-time transaction is allocated to one of its aﬃnity nodes with the lightest load
(step 3). If allocating tr would cause an AC overload or a node overload, then
the resolution strategy of DACA has to be performed (step 4 and 5). Example
2 shows how P-DACA can resolve the problem of Example 1.
Example 2: Suppose that the information of ACs, nodes, and transactions are
same to Example 1. Suppose also that both w1 and w2 are set to 1. Then the
transaction router allocates t3 to N2 that can execute t3 immediately. This is
because (a) the aﬃnity node of t3 is N1 but rank(P (t3 ), N1 ) = 1 = w1 , and (b)
even though N2 is not an aﬃnity node of t3 but rank(P (t3 ), N2 ) = 0 < w2 . Note
that if w1 is set to 2, t3 is allocated to N1 .✷

3

Concluding Remarks

We proposed a new transaction routing algorithm for the real-time SD cluster,
named P-DACA. The notable features of P-DACA are two-fold. First, P-DACA
allocates a real-time transaction to a node that guarantees higher probability
of completing the transaction within its deadline. Even though the transaction
could miss its deadline due to succeeding transactions with higher priority, the
selection strategy is the best choice at the current state. Next, P-DACA tries to
allocate a transaction to its aﬃnity node if possible. So P-DACA can achieve high
buﬀer hit ratio. This reduces the transaction execution time, and the probability
of missing deadline can be reduced as a result.

References
1. Lam, K-Y., Kuo, T-W. (ed.): Real-Time Database Systems: Architecture and Techniques. Kluwer Academic Publishers (2000)
2. Lam, K-Y., Kuo, T-W., Lee, T.: Strategies for resolving inter-class data conﬂicts in
mixed real-time database systems. Journal of Syst. and Soft. 61 (2002) 1-14
3. Lee, S., Ohn, K., Cho, H.: Feasibility and Performance Study of a Shared Disks
Cluster for Real-Time Processing. Lecture Notes in Computer Science 3397 (2005)
518-527
4. Ohn, K., Cho, H.: Cache Conscious Dynamic Transaction Routing in a Shared Disks
Cluster. Lecture Notes in Computer Science 3045 (2004) 548-557
5. Yu, P., Dan, A.: Performance Analysis Clustering on Transaction Processing Coupling Architecture. IEEE Trans. Knowledge and Data Eng. 6 (1994) 764-786
6. Yu, P., Dan, A.: Performance Evaluation of Transaction Processing Coupling Architectures for Handling System Dynamics. IEEE Trans. Parallel and Distributed
Syst. 5 (1994) 139-153

