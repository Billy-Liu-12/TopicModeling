Specifying Complex Systems with Bayesian
Programming. An Alife Application
Fidel Aznar, Mar Pujol, and Ram´
on Rizo
Department of Computer Science and Artiﬁcial Intelligence,
University of Alicante
{fidel, mar, rizo}@dccia.ua.es

Abstract. One of the most important application areas of Artiﬁcial
Life is the simulation of complex processes. This paper shows how to use
Bayesian Programming to model and simulate an artiﬁcial life problem:
that of a worm trying to live in a world full of poison. Any model of a
real phenomenon is incomplete because there will always exist unknown,
hidden variables that inﬂuence the phenomenon. To solve this problem
we apply a new formalism, Bayesian programming. The proposed worm
model has been used to train a population of worms using genetic algorithms. We will see the advantages of our method compared with a
classical approach. Finally, we discuss the emergent behaviour patterns
we observed in some of the worms and conclude by explaining the advantages of the applied method. It is this characteristic (the emergent
behaviour) which makes Artiﬁcial Life particularly appropriate for the
study and simulation of complex systems for which detailed analysis, using traditional methods, is practically non-viable.
Keywords: Bayesian Programming, Complex Systems Modeling, Artiﬁcial Life Formalization Model.

1

Introduction

Initially, Artiﬁcial Life was deﬁned as a broad ﬁeld of work in which attempts
are made to simulate or recreate one or more natural processes using artiﬁcial
methods. Nevertheless, applications in this ﬁeld have quickly exceeded purely
biological applications. The immediate applications of Artiﬁcial Life are in the
simulation of complex processes, chemical synthesis, multivariate phenomena,
etc. Very complex global behaviour patterns can be observed, initiated by simple
local behaviour. It is this characteristic (sometimes called emergent behaviour)
which makes Artiﬁcial Life particularly appropriate for the study and simulation of complex systems for which detailed analysis, using traditional methods,
is practically non-viable. Nevertheless, it is necessary to bear in mind that any
model of a real phenomenon will always be incomplete due to the permanent
This work has been ﬁnanced by the Generalitat Valenciana project GV04B685.
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3514, pp. 828–836, 2005.
c Springer-Verlag Berlin Heidelberg 2005

Specifying Complex Systems with Bayesian Programming

829

existence of unknown, hidden variables that will inﬂuence the phenomenon. The
eﬀect of these variables is malicious since they will cause the model and the
phenomenon to have diﬀerent behavioural patterns. In this way both artiﬁcial
systems and natural systems have to solve a common problem: how each individual within the system uses an incomplete model of the environment to perceive,
infer, decide and act in an eﬃcient way.
Reasoning with incomplete information continues to be a challenge for artiﬁcial systems. Probabilistic inference and learning try to solve this problem using
a formal base. A new formalism, the Bayesian programming (BP) [1], based on
the principle of the Bayesian theory of probability, has been successfully used
in autonomous robot programming. Bayesian programming is proposed as a solution when dealing with problems relating to uncertainty or incompleteness.
Certain parallelisms exist between this kind of programming and the structure
of living organisms as shown in a theoretical way in [2].
We will see a simple example of how to apply BP formalism to a speciﬁc
artiﬁcial life problem. We will deﬁne a virtual world, divided into cells, some of
which contain poison. In this world lives a worm with only one purpose, to grow
indeﬁnitely. In order to grow the worm must move through a certain number of
non poisonous cells in its world. If the worm moves into a poisonous cell then it
will die. The worm has a limited vision of the world, provided by its sensorial
organs, found in its head. These sensors allow the worm to see no further than
the adjacent cell. We believe that this is one of the ﬁrst approaches that uses
Bayesian programming for the formalization of an artiﬁcial life problem as we
haven’t found any evidence of it’s application in this ﬁeld.

2

Bayesian Programming

Using incomplete information for reasoning continues to be a challenge for artiﬁcial systems. Probabilistic inference and learning try to solve this problem using
a formal base. Bayesian programming has been used successfully in autonomous
robot programming [2], [1], [3], [4], [5]. Using this formalism we employ incompleteness explicitly in the model and then, the model’s uncertainty chosen by
the programmer, are deﬁned explicitly too.
A Bayesian program is deﬁned as a mean of specifying a family of probability
distributions. There are two constituent components of a Bayesian program. The
ﬁrst is a declarative component where the user deﬁnes a description. The purpose
of a description is to specify a method to compute a joint distribution. The second
component is of a procedural nature and consists of using a previously deﬁned
description with a question (normally computing a probability distribution of
the form P ( Searched| Known)). Answering this question consists in deciding
a value for the variable Searched according to P ( Searched| Known) using the
Bayesian inference rule:
1
Σ

P ( Searched| Known ⊗ δ ⊗ π) =
P ( Searched ⊗ Unknown ⊗ Known| δ ⊗ π)

×
Unknown

(1)

830

F. Aznar, M. Pujol, and R. Rizo

It is well known that a general Bayesian inference is a very diﬃcult problem,
which may be practically intractable. However, for speciﬁc problems, it is assumed that the programmer would implement an inference engine in an eﬃcient
manner. More details about BP can be found in [1],[2].

3

Specifying the Problem Using Bayesian Programming

We commented above on the existence of a world, composed of n × m cells,
where each cell Cij could be in any one of four diﬀerent states: empty, containing
poison, part of the wall which surrounds this artiﬁcial world or it could be hidden
from view beneath the worm’s tail. In this way a cell Cij = {∅, V, M, L}. The
wall conﬁguration is uniform for each generated world, however, in contrast,
the distribution of poison is random and varies from world to world. Initially,
we asume the amount of poisonous cells to be between 5%-10% of the total.
Within each world lives only a single worm which only objective is to move and
to grow. A worm grows and increases its length by one unit every time it moves
through d cells inside its world. If the worm moves to a cell that is not empty
then it will die. The only information about the world available to the worm
is provided by its sensors, located in its head (see ﬁgure 1a). A sensor is only
able to see the state of cells adjacent to and in front of the worm’s head, no
further.
We assume that each worm has a certain knowledge represented as states.
In this way each worm can stay in one state Et given a reading and a previous
state. Furthermore, a worm could obtain a reading of the world Lt represented
as a binary triplet which speciﬁes if the cell in the position of its components is
occupied ’1’ or not ’0’. Finally, a worm could execute three actions. Go straight
ahead, turn left or turn right At = {u, l, r} the actions will be guided only by a
reading and the actual state of the worm. Once the action At has been executed
the worm can change to a new state Et+1 .
The ﬁrst part of a Bayesian program is to deﬁne the pertinent variables of
the problem. To develop a movement in the world, the worm only needs to know
the reading Lt of it’s sensor and the actual state Et , in addition to the set of
actions A it could develop in the world. As we commented previously, an action
At must be followed by an instant change in state t + 1. In this way we deﬁne
the following variables for each instant t:
Lt = {000, 001, 010, ..., 111} , Lt = 8
Et = {0, 1, 2, ..., k} , Et = k + 1
At = {u, l, r} , A = 3

(2)

The second part of a BP is to deﬁne a decomposition of the joint probability distribution P ( Lt ⊗ Et−1 ⊗ Et ⊗ A| πW ) as a product of simpler terms.
This distribution is conditioned by the previous knowledge πw we are
deﬁning.

Specifying Complex Systems with Bayesian Programming

831

P ( Lt ⊗ Et−1 ⊗ Et ⊗ At | πW ) = P (Lt |πW ) × P (Et−1 |Lt ⊗ πW )×
×P (Et |Et−1 ⊗ Lt ⊗ πW ) × P (At |Et ⊗ Et−1 ⊗ Lt ⊗ πW ) =
= P (Lt |πW ) × P (Et−1 |Lt ⊗ πW )×
×P (Et |Et−1 ⊗ Lt ⊗ πW ) × P (At |Et ⊗ Lt ⊗ πW )

(3)

The second equality is deduced from the fact that an action only depends on
the actual state and the reading taken.
Next, in order to be able to solve the joint distribution, we need to assign
parametrical forms to each term appearing in the decomposition:
P (Lt |πW ) ≡ U nif orm
P (Et−1 |Lt ⊗ πW ) ≡ U nif orm
P (Et |Et−1 ⊗ Lt ⊗ πW ) ≡ G (µ(Et−1 , Lt ), σ(Et−1 , Lt ))
P (At |Et ⊗ Lt ⊗ πW ) ≡ G (µ(Et , Lt ), σ(Et , Lt ))

(4)

We assume that the probability of a reading is uniform because we have
no prior information about the distribution of the world. In the same way we
consider that all possible worm states can be reached with the same probability.
Give a state Et−1 and a lecture Lt we believe that only one state Et would
be preferred. In this way the distribution P (Et |Et−1 ⊗ Lt ⊗ πW ) is unimodal.
However, depending on the situation, the decision to be made may be more or
less certain. This behaviour is resumed by assigning a Gaussian parametrical
form to P (Et |Et−1 ⊗ Lt ⊗ πW ). In the same way, given a state and a reading we
suppose that an action with more or less intensity would be prepared.
We show a set of free parameters which deﬁne the way the worm moves.
These free parameters (that must be identiﬁed), derived from the parametrical
form (means and standard deviations of all the Gaussians Et−1 × Lt and
Et × Lt ), would be the ones to be learned.
Finally we specify the steps that the worm needs to move (using the joint
distribution): to obtain a reading Lt from the worm’s sensors, to answer the
question Draw(P (At |Et ⊗ Lt ⊗ πW )), then the worm will execute the movement
command A and will answer the question Draw(P (Et+1 |Et ⊗ LT ⊗ πW )), ﬁnally
the worm will change to the state Et+1 .

4

Genetic Algorithms

Genetic algorithms (GA) are a global search technique which mimic aspects of
biological evolution. We initially assume that the worm’s parameters are generated randomly. The worm only has previous knowledge provided by its knowledge decomposition. The learning process would be produced generation after
generation, where the longest living worms in the world would be those most
enabled and adapted to reproduce and to maintain their intelligence. Next we
will describe the main parts of our genetic algorithm.
Chromosome Codification. A chromosome is represented using two tables.
The ﬁrst one is formed by 2 · k · 8 components specifying the Gaussians Et−1 ×
Lt which represent P (Et |Et−1 ⊗ Lt ⊗ πW ). The second table is formed by the

832

F. Aznar, M. Pujol, and R. Rizo

same component numbers specifying the Gaussians Et × Lt which represent
P (At |Et ⊗ Lt ⊗ πW ). In this way, each chromosome contains 32 · k gens. In
the described experiments, the initial chromosome population is obtained by
randomly initializing the Gaussian parameters.
Fitness Function. We want to reward the worms that live the longest time
in the world. In this way we describe the ﬁtness function as the number of
iterations that a worm lives in a randomized generated world. In order to avoid
the situation where a simple world produces an overvalued worm, we generate
w random worlds to evaluate each worm’s ﬁtness. All worlds are the same size
and have the same wall disposition, only the quantity and position of poisonous
cells varies, being selected randomly and comprising between 5% and 10% of the
total cells.
Selection, Crossover an Mutation Operators.
– Selection operator. We used a stochastic remainder sampling selector (SRS)
with a two-staged selection procedure. In addition we use elitism (the best
individual from each generation is carried over to the next generation).
– Crossover operator. We use an asexual two-point crossover operator. In this
way the mother genes will be selected until the crossover point where the
father genes will be copied. This process will be done for the two tables (see
ﬁgure 1b) that describe the chromosome.
– Mutation operator. We deﬁne an incremental mutation operator for states,
in this way given a gene x we deﬁne a mutation as: x ∈ [0, k], mut(x) =
x + 1 M OD k. Suppose we have four states, and that q2 = 3, if we mutate
this element we will obtain q2 = 3 + 1 M OD 4 = 0. A random mutation
scheme is used to choose the directions for the worm to take. A new direction
is generated randomly and then substitutes the original gene.
4.1

Used Parameters

Using the operators presented in the previous section we obtain an evolutive
learning process for a worm. Developing empirical tests we arrive at the conclusion that a number of states (k) greater than ﬁve complicates the learning
process of the worm and does not improve the movements made by the worm.
For this reason, in the rest of the experiments, we use a ﬁxed number of states
equal to ﬁve.In addition, for the remainder of tests we use d = 5 (for each ﬁve
cells the worm moves through it will increase it’s size by one unit) and w = 6
(six random worlds will be generated in order to evaluate each worm).
4.2

Worms Evolution

In order to obtain the best individual we use 100 executions for each state with a
population of 250 individuals and 500 generations using the operators speciﬁed
in the previous section. In ﬁgure 1c an example is shown of the executions showing the ﬁtness of the worst and best performing individual as well as the average
results obtained, illustrating the algorithm convergence. For each algorithm execution the evaluation took about 2 minutes using a Pentium IV running at 2Ghz.

Specifying Complex Systems with Bayesian Programming

833

Fig. 1. a) Worm’s vision relating to its head and the direction it has in the world. b)
Asexual two point crossover operator for the worm’s chromosome. c) Evolution of the
worst (bottom line), the average (in the middle) and the best performing individual
(top). The y axis represents the worm’s ﬁtness and the x axis the actual generation.
Until the ﬁrst 50 iterations an improvement is produced in the medium and the worst
individual. Then the graph tends to oscillate although a slight increase is produced
(because the best case increases and maintains it’s level through elitism)

5

Survival Behaviours and Experimentation

In this section we will analyze some characteristics and emergent behaviours that
were observed in the worms. Readers of this paper are invited to test our simulator at the following address http://www.dccia.ua.es/∼fidel/worm.zip. Using Bayesian Programming the worm’s previous knowledge is deﬁned and mechanisms are given to provide new knowledge to the worm. This data is represented
using two sets of discrete Gaussians which were learned using genetic algorithms.
However, we should remember that to get the information of the learned distributions we use the Draw function which randomly extracts a value for the distribution. In this way we obtain a non-deterministic behaviour, which is more adaptable to variations in complex worlds. After training the worm population we
simulate, in a graphical way, the best individual found. It is curious to see diﬀerent behaviour patterns, which provide more survival opportunities. Some of these
patterns even seem to imitate natural behaviour developed in some animals.
One of the most common patterns is to follow the edge of the world while
no poison is found near it (see ﬁgure 2a). This is a good way to move if the
proportion of poison is low near the edges and conﬁgurations don’t exist that trap
the worm between the perimeters and the poison. Another curious behaviour is
the development of a zigzag movement emulating the way some snakes move (see
ﬁgure 2b) so reducing the area that the worm occupies in the world. In addition
it is quite common for the worm to move up and down like a ping-pong ball

834

F. Aznar, M. Pujol, and R. Rizo

Fig. 2. Diﬀerent behavior patterns. a) Follow the edge of the world. b) Zigzag movement. c) Ping-pong behaviour. d) In the movement the worm seems to follow its tail.
The arrow points to the next worm displacement

(see ﬁgure 2c). Finally, we underline the movement of some worms which seem
to move as if trying to reach their tails, so forming a spiral (see ﬁgure 2d). The
behaviour described above (and some others) are repeated and combined with
the obtained worms. These behaviour are not programmed implicitly, they have
been obtained using the proposed brain model and selected using an evolving
process in a population.
5.1

Comparing Our Model with a Clasical One

We can see some advantages of our method if we compare it to a more classical model approach, the ﬁnite states machine (FSM) [6]. This approach has
various drawbacks. First, it assumes a perfect world model, which is false. It is
necessary to know that any model of a real phenomenon is incomplete because
there will always exist non-considered, hidden variables, that will inﬂuence the
phenomenon. The eﬀect of these variables is malicious since they will cause the
model and the phenomenon to show diﬀerent behavioural patterns. Second, a
FSM develop a deterministic behaviour therefore in certain world conﬁgurations it will fail. On the other hand, a Bayesian model has not a deterministic
behaviour and two diﬀerent executions in the same world may have diﬀerent
results, which provide greater adaptability to changes in the environment conﬁguration.

6

Conclusions

In this paper we have seen an application of Bayesian programming in an artiﬁcial life system. The formalism of the artiﬁcial life models is a continuous
ﬁeld of investigation because of the complexity of the systems we work with

Specifying Complex Systems with Bayesian Programming

835

[7],[8]. In addition, we have the added diﬃculty of working with uncertainty and
include it into the model we want to use. The Bayesian programming brings
up a formalism where implicitly, using probabilities, we work with the uncertainly.
In a world with randomly distributed poison lives a worm, which main purpose is to grow up. We propose a formalization of the virtual worm using a
decomposition in terms of a joint probability distribution of their knowledge. In
this way, applying the Bayesian Programming we obtain a versatile behaviour
adaptable to changes and what is more a mathematical description of the probabilistic environment model. We have seen some advantages of our method comparing it to a more classical model approach, the ﬁnite states machine (FSM
[6]) (see section 5.1).The learning process, given a worm population, has been
developed with evolving techniques, using genetic algorithms. The principal reason for using GA was because they are a global search technique which mimic
aspects of biological evolution even though other search techniques could be
picked to select the worms. Each used chromosome is the codiﬁcation of the
two distributions obtained with the previous Bayesian formalism. Satisfactory
results were obtained that prove the validity of the proposed model. Relatively
complex and elaborate behavioural patterns were observed in the movements
of the most highly adapted worms. These behaviour patterns were not implicitly programmed but were obtained in an emergent way using the proposed
model.
Bayesian programming is, therefore, a promising way to formalize both artiﬁcial and natural system models. In this example, we have seen how this paradigm
can be adapted to a simple, artiﬁcial life problem. Future studies will try to model
diﬀerent artiﬁcial life systems using this new formalism.

References
1. Lebeltel, O., Bessire, P., Diard, J., Mazer, E.: Bayesian robots programming. Autonomous Robots 16 (2004) 49–79
2. Bessire, P., Group, I.R.: Survei:probabilistic methodology and tecniques for artefact
conception and development. INRIA (2003)
3. Koike, C., Pradalier, C., Bessiere, P., Mazer, E.: Proscriptive bayesian programming
application for collision avoidance. Proc. of the IEEE-RSJ Int. Conf. on Intelligent
Robots and Systems (IROS); Las Vegas, USA (2003)
4. C. Cou, Th. Fraichard, P.B., Mazer, E.: Using bayesian programming for multisensor data fusion in automotive applications. IEEE Intelligent Vehicle Symposium
(2002)
5. Bellot, D., Siegwart, R., Bessire, P., Cou, C., Tapus, A., Diard, J.:
Bayesian reasoning for real world robotics: Basics, scaling and examples.
Book Chapter in LNCS/LNAI, http://128.32.135.2/users/bellot/files/
David Bellot LNCS LNAI.pdf (2004)
6. Dysband, E.: Game Programming Gems. A ﬁnite-state machine class (237-248).
Charles River Media (2000)

836

F. Aznar, M. Pujol, and R. Rizo

7. Agre, P., Horswill, I.: Lifeworld analysis. Journal of Artiﬁcial Intelligence Research
6 (1997) 111–145
8. Rasmussen, S., L. Barrett, C.: Elements of a theory of simulation. ECAL1995
(Advances in Artiﬁcial Life, Third European Conference on Artiﬁcial Life, Granada,
Spain). (1995) 515–529

