High-Fidelity Simulation of Large-Scale
Structures
Christoph Hoﬀmann, Ahmed Sameh, and Ananth Grama
Department of Computer Sciences, Purdue University, W. Lafayette, IN 47907

Abstract. Active structures capable of responding to external stimulii
represent the emerging frontier in structural design. Robust and real-time
sensing, control, and actuation pose fundamental challenges that must be
addressed in this context. As part of an ambitious project funded by the
National Science Foundation, researchers at Purdue, Rice, Florida State,
and the Catholic (Belgium) Universities have undertaken development of
these core technologies. Over the past 18 months, considerable progress
has been made in the areas of model reduction and control, sensing, and
simulation-based validation. This paper describes our results in highﬁdelity simulations of large structures, subject to various (mechanical
and thermal) stresses.
A high-ﬁdelity simulation infrastructure poses a number of challenges.
These include geometric modeling (generating a suitable mesh for the
structure), physical modeling (developing mathematical models for coupling between various phenomena, specifying material properties), computational modeling (developing eﬃcient numerical schemes and their
parallel formulations), and appropriate visualization techniques. We have
made fundamental contributions in each of these areas. Here, we overview
some of our major contributions, along with sample simulations of existing structures. As part of our ongoing work, we also aim to perform a
high-ﬁdelity simulation of the tragic World Trade Center (WTC) crash.
To this end, we have developed, from available blueprints, a highly resolved geometric model of the WTC. We also aim to complement all of
our computational studies with detailed experimental validation on fullscale structures at the Bowen Lab for Structural Engineering. To the
best of our knowledge, this is the ﬁrst comprehensive eﬀort to fully integrate simulation and modeling with sensing, control, and actuation in an
experimental setting. In this sense, we believe that this project is a novel
realization of the concept of dynamic data-driven application systems in
the realm of large-scale structures.

1

Introduction

Physical processes are described primarily using mathematical models that are
used to simulate the behavior of the underlying processes. Often, they are also
used to modify or control system behavior. In this framework, there is an ever increasing need for improved accuracy, which leads to models of higher complexity.
The basic motivation for system approximation is the need, in many instances,
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 664–671, 2005.
c Springer-Verlag Berlin Heidelberg 2005

High-Fidelity Simulation of Large-Scale Structures

665

for a simpliﬁed model of a dynamical system, which captures the main features
of the original complex model. This need arises from limited computational,
accuracy, and storage capabilities. The simpliﬁed model may then be used in
place of the original complex model, either for simulation, or control. As sensor
networks and embedded processors proliferate our environment, technologies for
such approximations and real-time control emerge as the next major technical
challenge.
As part of an ambitious NSF-funded project, we are exploring eﬃcient and
robust methods for producing reduced order models of large state-space systems,
developing algorithms for real-time control, mechanisms for actuation, and systems infrastructure for aﬀecting sensing, control, and actuation. To this end, we
have made several fundamental contributions in the area of control [6, 5, 4, 3],
sensing [1, 2], and modeling [7, 8].
A critical aspect of our study is the validation of underlying model reduction
and control mechanisms using detailed computational simulations as well as experimental studies. The objectives of this are many-fold – we intend to precisely
quantify errors in model reduction by simulating a hierarchy of progressively
coarser models. To this end, we have developed a series of benchmarks, derived
from a well-known structure (sanitized and shown in Figure 1). These benchmarks, derived from blueprints of the structure, have been made available over
the public domain with the goal of comparing and validating results of control
algorithms and model reduction. A second objective of developing a comprehesive simulation framework is to provide mechanisms for incorporating control
algorithms and variable damping to study structural response. Finally, we have
used our framework as a sophisticated diagnostic/prognostic tool for structural
failure. Our work on analysis of the Pentagon crash (Figure 2) is widely accepted
as a benchmark study in this regard.

Fig. 1. Illustration of one of the benchmark structures used for model reduction and
control

In this paper, we describe major technical challenges in high-ﬁdelity simulations, our approach to addressing these challenges, and our recent results. We
also describe ongoing work and the use of experimental studies to fully validate

666

C. Hoﬀmann, A. Sameh, and A. Grama

(a) Aerial view of damage to the (b) Simulated aircraft impact on
Pentagon building
RC columns in the building
Fig. 2. High ﬁdelity simulation of the Pentagon crash performed in our group has
yielded signiﬁcant insights into structural properties of reinforced concrete and design
of resilient buildings

our computational results. To the best of our knowledge, this is the ﬁrst comprehensive eﬀort to fully integrate simulation and modeling with sensing, control,
and actuation in an experimental setting. In this sense, we believe that this is a
novel realization of the concept of dynamic data-driven application systems in
the realm of large-scale structures.

2

Technical Challenges

A number of technical challenges must be overcome to develop a comprehensive simulation framework. We have addressed these challenges and continue to
explore more eﬃcient techniques. We outline here some of our results in these
areas.
2.1

Geometric Modeling – Meshing

Meshing represents one of the most time-consuming (labor intensive) part of
the simulation process. The ﬁdelity of a simulation is critically inﬂuenced by
the mesh size and quality. A coarse discretization used for the elements of a
Lagrangian mesh reduces the ﬁdelity for contact and yielding behavior. Similarly, a coarse discretization used for the elements of an Eulerian mesh reduces
the ﬁdelity for mass transfer computations for the advection process, EulerLagrangian coupling, and the accuracy of ﬂuid ﬂow. In our simulation framework, we have created our own set of meshing tools and a detailed meshing
methodology. This allows us to balance the desire for high resolution meshes,
and the accuracy so obtained, with the necessity to accommodate the limitations
of the underlying computing platform.
A completely automated meshing program that derives an FEA mesh from
a geometric model is a signiﬁcant undertaking. However, much can be accomplished when the meshing is semi-automatic. Since we typically combine separately meshed parts, we generate the mesh in two passes: the ﬁrst pass generates
a mesh description in an intermediate format that is independent of the underlying simulation engine. A second pass then translates the intermediate representation into a form that is suitable for input to selected simulation engines (in

High-Fidelity Simulation of Large-Scale Structures

667

our case, LS Dyna). Thus, we can easily change the FEA package, for instance
when comparing ﬁdelity and performance of diﬀerent FEA systems. We have
extensive experience with this methodology and have successfully used it to generate meshes for our test structures, benchmark structures, as well as existing
buildings (the Pentagon, Bank One building, and the World Trade Center).
2.2

Physical Modeling – Coupled Simulations

In addition to traditional issues of developing appropriate models for material
behavior and determining suitable material properties, one of the major challenges arises from a coupling of multiple external stimulii. This happens, for
instance, when structural failure is induced by thermal stresses. In such cases, it
is necessary to simulate all of the physical processes in a tightly integrated manner. We show results from one such simulation performed by us in Figure 3. In
this simulation of a ﬁre on the 25th ﬂoor of the Bank One building in downtown
Indianapolis, complete structural failure is caused by failure of a few critical
beams. The underlying challenge is that the temporal and spatial discretizations
associated with various phenomena potentially diﬀer by several orders of magnitude. In the case illustrated here, the ﬁre code used had a much ﬁner spatial
discretization and coarser temporal discretization than the structural counterpart. However, changes in structure critically impact progression of the ﬁre –
namely that changes in structure are critical for providing air for feeding the
ﬁre. A naive coupling of the two codes requires us to solve the Navier-Stokes
equation for compressible ﬂuid ﬂow (air), the combustion model along with the

Fig. 3. Simulation of heat-induced structural failure – a ﬁre on the 25th ﬂoor of
the Bank-One tower in downtown Indianapolis is simulated using a coupled ﬁrestructure code (wireframe model shown here). The entire simulation is available at
http://www.cs.purdue.edu/homes/ayg/SIM

668

C. Hoﬀmann, A. Sameh, and A. Grama

ﬂow of the fuel, the structural model, and the solid body motion (for failed components), each at the ﬁnest granularity. This renders the simulation extremely
computationally expensive.
The approach outlined about corresponds to an explicit timestepping scheme
(which was also used in our simulation). While this scheme is generally easier
to implement when using multiple production codes, stability in such schemes
mandates the use of small timesteps. In contrast, implicit schemes permit use
of larger timesteps, however, they require solution to a more complex system of
equations. Solutions to such systems pose formidable challenges from a numerical
standpoint. We are currently exploring a number of these research issues in the
context of our simulation of the WTC crash (Section 3).
2.3

Computational Modeling – Numerical Methods and
Parallelism

High-ﬁdelity models, of the kind used in our simulations generate extremely large
systems, which are typically solved iteratively. This puts the emphasis of timeto-solution on eﬃcient numerical methods (preconditioners for iterative solvers)
and their parallel formulations.
Our work on preconditioning linear systems arising from our structural simulations has resulted in extremely eﬀective parallizable preconditioners. These
preconditioners, based on our Spike [9] algorithm, are capable of fast convergence, low FLOP counts, and high concurrency. We have characterized the performance of solvers based on our preconditioner for a variety of meshes. We have
studied the impact of various elements (eg., shell, beam, column) on the conditioning of the matrix and overall solution time. We demonstrate the superior
performance of our methods in comparison to various existing solvers.
The size and complexity of systems resulting from our models necessitate the
eﬃcient use of powerful parallel platforms. For example, a single simulation instance of our Pentagon Crash, with one million nodes (3 d.o.f. per ﬁnite element
node) over 0.25 seconds of real time takes over 68 hours on a dedicated 8 processor IBM Regatta SMP. A coarser model with 300K nodes over 0.2s of real time
takes approximately 20 hours. In addition to the IBM SMP, we have also ported
our codes to Linux/Itanium clusters. We have demonstrated excellent parallel
eﬃciency for our codes for a variety of simulations. The computational requirements of these simulations provide strong motivation for eﬀective error-bounded
model reduction.
2.4

Visualization – The Human Interface

Large scale simulations produce massive multidimensional datasets. Although
some scalars can be examined and presented using tables and graphs, 3D visualizations have long been used as powerful means of conveying such results. In
the case of FEA simulations that analyze the mechanical interaction of entities
under the extreme conditions of a high-kinetic-energy impact, visualization is an
indispensable tool. In order to capitalize on high-ﬁdelity ﬁnite element modeling,
material and contact behavior, the visualization must have high ﬁdelity as well.

High-Fidelity Simulation of Large-Scale Structures

669

Fig. 4. Visualization of liquid, including reﬂection and refraction, for fuel ﬂow in an
aircraft crash

To aﬀect a realistic and eﬃcient visualization system, we build upon existing
commercial solutions using plugins for data transfer, selection, material properties, and a variety of novel visualization techniques. We illustrate one such
technique in Figure 4, which shows the ﬂow of fuel through a set of columns.
Such visualizations, developed in collaboration with experts in structural engineering, are very useful in understanding structural failure. More details of these
techniques is provided in [7, 8].

3

Discussion and Ongoing Work

An immediate goal of our study is to perform high-ﬁdelity simulations of the
tragic World Trade Center (WTC) collapse, with a view to understanding, precisely, the structural cause of failure. We have obtained detailed blueprints of the
structure and generated highly resolved geometric models (Figure 5). A major
diﬃculty with this simulation is the coupling of thermal eﬀects with mechanical stresses. This arises from the multitude of phenonema (fuel transport, fuel
combustion including air-ﬂow, combustibles in the building, mechanical impact,
structural failure, etc.), timescales (all of these phenomena span over three orders of magnitude in time), and ambient factors (air-ﬂow, temperature). Drawing
on our initial simulation of the Bank-One building, and our experience in such
simulations, we expect to demonstrate these simulations in the near-term.
A unique aspect of our study is that we aim to validate all of our computational results with detailed experimental studies. This eﬀort relies heavily
on extensive facilities available at the Bowen Lab for Structural Engineering
at Purdue University. Leveraging other grants, we have built a full-scale threestorey test structure (30 × 50 × 35 feet), shown in Figure 6. A number of tests
are planned on this structure, leading to the eventual testing to failure. These
tests include low-frequency high-amplitude lateral and vertical loading (using
hydraulic rams), low-amplitude tests for validating modes, and ﬁnally, impact
of active damping on structural characteristics.
Our immediate goal in this area is to develop a real-time sensing network
for measuring displacements, acceleration, and strain, at various points in the
structure. For sensing displacements, we use laser sensors from Acuity Research
(http://www.acuityresearch.com/contact-us.shtml). These sensors have a range

670

C. Hoﬀmann, A. Sameh, and A. Grama

Fig. 5. A high-resolution mesh of the World Trade Center (WTC), developed using
detailed blueprints (of the kind shown in bottom panel), which will be used for highﬁdelity coupled ﬁre-structure simulation of the WTC collapse

Fig. 6. Image of the test structure (30 × 50 × 35 feet) at the Bowen Lab for
Structural Engineering at Purdue University. The structure will be subject to a
variety of external loads and responses will be used to validate model reduction
and simulation frameworks. A live web-cam image of this structure is posted at
http://newton.ecn.purdue.edu/ ce/Bowen/Webcam/

from 11.5” to 27.5” with a resolution of 0.0048 inches at a frequency of 1250 Hz.
These sensors provide RS232 outputs, which we network using RS232/BlueTooth
interfaces. Accelerations are measured using the Crossbow Mica2 motes. These
devices are networked to an XScale device, which is also equipped with suitable
BlueTooth and 802.11b interfaces. The entire network is organized hierarchically

High-Fidelity Simulation of Large-Scale Structures

671

into a scalable, robust, and eﬃcient network. Initial testing of this setup has
been completed and the network is now being deployed on the test structure.
In the process of this testing and deployment, we have also addressed a number
of problems in sensor networking, including multiclass routing, resource-based
routing, suitable operating system abstractions and programming interfaces, and
power-aware resource management.

Acknowledgements
The authors would like to acknowledge Prof. Voicu Popescu and Dr. Sami Kilic
for their help in generating some of the images in this paper. This work is
supported by NSF contract ITR ACI-0324944.

References
1. B. Carbunar, A. Grama, and J. Vitek. Distributed and dynamic voronoi overlays
for coverage detection and distributed hash tables in ad-hoc networks. ICPADS,
2004.
2. B. Carbunar, A. Grama, J. Vitek, and O. Carbunar. Coverage preserving redundancy elimination in sensor networks. In Proceedings of the 1st IEEE International
Conference on Sensor and Ad Hoc Communications and Networks (SECON), Santa
Clara, October 2004.
3. Y. Chahlaoui and P. Van Dooren. Benchmark examples for model reduction of linear
time invariant dynamical systems. In P. Benner et al., editor, Model Reduction of
Dynamical Systems. Springer Verlag, 2004.
4. Y. Chahlaoui and P. Van Dooren. Model reduction of time-varying systems. In
P. Benner et al., editor, Model Reduction of Dynamical Systems. Springer Verlag,
2004.
5. Y. Chahlaoui, D. Lemonnier, A. Vandendorpe, and P. Van Dooren. Second-order
balanced truncation. Lin. Alg. Appl., 2005. to appear.
6. K. Gallivan, A. Vandendorpe, and P. Van Dooren. Model reduction of mimo systems
via tangential interpolation. SIAM J. Matrix Anal. Appl., 26(2):328–349, 2004.
7. C. Hoﬀmann, S. Kilic, V. Popescu, and M. Sozen. Integrating modeling, visualization and simulation. IEEE Computating in Science and Engineering, pages 52–60,
January/February 2004.
8. C. Hoﬀmann and V. Popescu. Fidelity in visualizing large-scale simulations.
Computer-Aided Design, 2005. to appear.
9. S.Kilic, F.Saied, and A.Sameh. Eﬃcient iterative solvers for structural dynamics
problems. Computers & Structures, 82(28):2363–2375, 2004.

