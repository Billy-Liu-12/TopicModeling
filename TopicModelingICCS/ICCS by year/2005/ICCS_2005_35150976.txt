Integrating Text Chunking with Mixture Hidden Markov
Models for Effective Biomedical Information Extraction
Min Song, Il-Yeol Song, Xiaohua Hu, and Robert B. Allen
College of Information Science & Technology Drexel University,
Philadelphia, PA 19104
(215) 895-2474, 01
{min.song, song, thu, rba}@drexel.edu

Abstract. This paper presents a new information extraction (IE) technique,
KXtractor, which integrates a text chunking technique with Mixture Hidden
Markov Models (MiHMM). KXtractor is differentiated from other approaches
in that (a) it overcomes the problem of the single Part-Of-Speech (POS) HMMs
with modeling the rich representation of text where features overlap among
state units such as word, line, sentence, and paragraph. By incorporating
sentence structures into the learned models, KXtractor provides better
extraction accuracy than the single POS HMMs do. (b) It resolves the issues
with the traditional HMMs for IE that operate only on the semi-structured data
such as HTML documents and other text sources in which language grammar
does not play a pivotal role. We compared KXtractor with three IE techniques:
1) RAPIER, an inductive learning-based machine learning system, 2) a
Dictionary-based extraction system, and 3) single POS HMM. Our experiments
showed that KXtractor outperforms these three IE systems in extracting proteinprotein interactions. In our experiments, F-measure for KXtractor was higher
than ones for RAPIER, a dictionary-based system, and single POS HMM
respectively by 16.89%, 16.28%, and 8.58%. In addition, both precision and
recall of KXtractor are higher than those systems.

1 Introduction
The proliferation of the biomedical literature available on the Web is overwhelming.
While the amount of data available to us is constantly increasing, our ability to absorb
and process this information remains a challenging task. The biomedical research
domain has recently become a target domain that information extraction (IE) can be
spotlighted on. IE is the process of scanning text for information relevant to some
interest, including extracting entities, relations, and events. In this paper, we propose a
novel IE technique, called KXtractor, Mixture Hidden Markov Models (MiHMMs)
combined with a Support Vector Machine (SVM)-based text chunking technique.
MiHMM is defined as a mixture of Hidden Markov Models (HMMs) organized in
a hierarchical structure to help the IE system cope with data sparseness. MiHMM
takes a set of sentences with contextual cues that were identified by a Support Vector
Machine-based text chunking technique. MiHMM then learns a generative
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3515, pp. 976 – 984, 2005.
© Springer-Verlag Berlin Heidelberg 2005

Integrating Text Chunking with MiHMM

977

probabilistic model of the underlying state transition structure of the sentence from a
set of tagged training data. Given a trained probabilistic mixture model of the data,
the system is able to apply this model to new unseen input documents to predict
which portions of these sentences are likely targets according to the training data
template. The paper investigates relationships between structure and performance of
HMMs applied to information extraction problems.
KXtractor is different from existing HMMs as follows: (a) It employs probabilistic
mixture of HMMs that are hierarchically structured. (b) It incorporates contextual and
semantic cues into the learned models to extract knowledge from the unstructured text
collections without any document structures. (c) It adopts an SVM text chunking
technique to partition sentences into grammatically related groups. Thus, using
KXtractor for extracting biomedical entities has the following advantages over other
approaches: (a) it overcomes the problem of the single POS HMMs with modeling the
rich representation of text where features overlap among state units such as word,
line, sentence, and paragraph. By incorporating sentence structures into the learned
models, KXtractor provides better extraction accuracy than the single POS HMM
does. (b) it resolves the issues with the single POS HMMs for IE that operate only on
the semi-structured data such as HTML documents and other text sources in which
language grammar does not play a pivotal role.
With this novel and robust IE technique, we have extracted protein-protein pairs
from abstracts in MEDLINE. We have compared the system performance of
KXtractor with other IE techniques such as a rule-based learning, a dictionary-based,
and single POS HMM techniques. Our experimental results show that KXtractor is
superior to these techniques in most cases. The rest of the paper is organized as
follows: Section 2 describes the overall architecture of KXtractor. Section 3 describes
the evaluation. Section 4 reports on the experiments. Section 5 concludes the paper.

2 The System Architecture
Figure 1 illustrates the system architecture of KXtractor. The system consists of two
major components: 1) sentence chunking by an SVM component and 2) relation
extraction by MiHMM component.
In the sentence chunking by an SVM component, input data is plain text consisting
of titles and abstracts. The input data is separated into sentences. A set of regular
expression rules are applied to parse sentences. For a parsed sentence, we applied an
integrated POS tagging technique proposed by Song et al. [9] to tag sentences with
POS. With SVM-based text chunking technique, these POS tagged sentences are then
grouped into chunks of different phrase types such as noun, verb, and preposition
chunk. In the relation extraction by MiHMM component, MiHMM is applied to the
grouped phrases by the SVM text chunking technique. The results of running
KXtractor are a set of tuples related to protein-protein pairs. KXtractor stores these
tuples in the knowledge base and resets the token statistics for the next input data. The
detailed description of the components is provided in the sub-sections below. Figure 2

978

M. Song et al.
S e n te n c e C h u n k in g b y
S V M co m p o n e n t

R a w d a ta

M o d e lin g s e n te n c e
s t r u c tu r e

C h u n k in g s e n te n c e s

T a g g in g s e n te n c e w it h P O S

M a r k in g u p tr a in in g d a ta

C h u n ke d se n te n ce
{ N oun group,
Verb group,
P r e p o s it io n g r o u p ,
C o n ju n c tio n g r o u p ,
A d ve r b g r o u p }

P O S ta g g e d s e n te n c e

E x tr a c t e d ta r g e t
noun groups

T r a in in g m o d e ls

T r a in d a t a

T e s t d a ta

E x tr a c tin g th e t a r g e t o b je c t

E x tr a c tin g th e ta r g e t s t a te
w it h M iH M M

U p d a tin g K B
K n o w le d g e B a s e ( K B )
fo r e x tr a c te d tu p le s

L o o k- u p

T r a in e d H M M
m o d e ls

R e la t io n E x tr a c t io n b y
M iH M M c o m p o n e n t

Fig. 1. System architecture of KXtractor

Fig. 2. A procedure of sentence parsing JJ denotes adjective, IN denotes preposition, DT
denotes determiner, CD cardinal number, NN denotes singular noun, NNP denotes proper noun,
VBZ denotes verb, VBN denotes verb, and RB denotes adverb

illustrates the procedure of converting a raw sentence from PubMed to the phrasebased units grouped by the SVM text chunking technique. The top box shows a
sentence that is part of abstracts retrieved from PubMed. The middle box illustrates

Integrating Text Chunking with MiHMM

979

the parsed sentence by POS taggers. The bottom box shows the final conversion made
to the POS tagged sentence by the SVM based text chunking technique.
2.1 Sentence Chunking by an SVM Component
Text chunking is defined as dividing a text in syntactically correlated parts of words
[5]. Chunking is recognized as a series of the processes - first identifying proper
chunks from a sequence of tokens (such as words), and second classifying these
chunks into some grammatical classes. Major advantages of using text chunking over
full parsing techniques are that partial parsing such as text chunking is much faster,
more robust, yet sufficient for IE. Text chunking based on Support Vector Machines
(SVMs) was reported to produce the highest accuracy in the text chunking task [5].
The SVMs-based approaches such as other inductive-learning approaches take as
input a set of training examples (given as binary valued feature vectors) and find a
classification function that maps them to a class. SVMs are known to robustly handle
large feature sets and to develop models that maximize their generalizability. This
makes them an ideal model for IE.
Generalizability in SVMs is based on statistical learning theory and on the
observation that it is useful to misclassify some of the training data so that the margin
between other training points is maximized [4]. This is particularly useful for real
world data sets that often contain inseparable data points. Although training is
generally slow, the resulting model is usually small and runs quickly. This is because
only the patterns that help define the function that separates positive from negative
examples. In addition, SVMs are binary classifiers and so we need to combine SVM
models to obtain a multiclass classifier. Due to the nature of the SVM as a binary
classifier it is necessary in a multi-class task to consider the strategy for combining
several classifiers. In this paper, we use Tiny SVM [4] in that Tiny SVM performs
well in handling a multi-class task.
2.2 Relation Extraction by MiHMM Component
Figure 3 is a schematic representation of how our MiHMM works. Our phrase group
includes 14 phrase types. Our models are constructed with the assumption that the
model is fully connected, which means that the model emits a segment of any type at
any given position within the sentence. Bold boxes in Figure 3 indicate the target
noun group that contains either proteins or a protein-protein pair. Each box represents
a phrase group and the circles inside the box show the POS tags assigned to words in
order, which appears in the sentence. The model is trained maximum likelihood
parameter estimation. From the sentence training set we can easily obtain the
information concerning the frequency that a given state or observation occurred and
the frequency with which a state transition or observation emission was made. The
parameters of the model are the transition probabilities P ( q → q ′ ) that one state
follows another and the emission probabilities P ( q ↑ q ′) that a state emits a
particular output symbol. The probability of a string x being emitted by an HMM is
computed as a sum over all possible paths by:

980

M. Song et al.

Fig. 3. Noun phrase based Mixture Hidden Markov ModelsN denote noun, P denotes
preposition, T denotes target, and V denote verb

Fig. 4. Graphic representation of MiHMM. BKG denotes Background

P(x | M ) =

l +1

∑ ∏

q 1 ,... q t ∈ Q

l

k =1

P ( q k −1 → q k ) P ( q k ↑ x k )

where q 0 and q l 1 are restricted to be q I and q F respectively, and is an end-ofstring token. The forward algorithm can be used to calculate this probability [7]. The
observable output of the system is the sequence of symbols that the states emit, but
the underlying start sequence itself is hidden. One common goal of learning problems

Integrating Text Chunking with MiHMM

981

that use HMMs is to recover the state sequence V ( x | M ) that has the highest
probability of having produced an observation sequence:
V ( x | M ) = arg max
q 1 ... q t ∈ Q l

l +1

∏

k =1

P ( q k −1 → q k ) P ( q k ↑ x k )

Determining this state sequence is efficiently performed by dynamic programming
with the Viterbi algorithm [10].

3 Evaluation
To evaluate KXtractor, we compare it with three other well-known IE methods: 1) the
dictionary-based extraction, 2) RAPIER, a rule-based machine learning extraction,
and 3) single POS HMM. Performance of these IE systems is measured by precision,
recall, and F-measure. The data used for experiments are retrieved from MEDLINE.
3.1 Data Collection

The IE task conducted in this paper is a multiple slot extraction task. The goal of our
IE task is to extract instances of n-ary relations; that is, protein-protein interactions.
The protein-protein interaction data sets are composed of abstracts gathered from the
MEDLINE database [6]. MEDLINE contains bibliographic information and abstracts
from more than 4000 biomedical journals. From this huge text corpus, we combined
and utilized MEDLINE data sets provided by [8] and [2]. The data sets consist of
1700 MEDLINE records. These data sets characterize physical interactions between
pairs of proteins. In terms of sentences, the data sets consist of 6417 positive and
46123 negative sentences. It contains 10123 instances of 913 protein-protein pairs. To
label the sentences in these abstracts, we matched the target tuples to the words in the
sentence. A sentence that contained words that matched a tuple was taken to be a
positive instance. Every other sentence was considered to be a negative instance.
3.2 Dictionary-Based Extraction

We developed a Dictionary-based extraction system proposed by Blaschke et al. As
described in [2], the following six steps were taken to extract protein-protein
interactions: 1) the protein names are collected from the Database of Interacting
Proteins (DIP) and Protein-Protein Interaction Database (PPID) databases. The
synonyms of the target proteins are manually provided. 2) The 14 verbs, indicating
actions related to protein interaction, are used. 3) Abstracts are provided from
MEDLINE. 4) The passages containing target proteins and actions are identified. 5)
The original text is parsed into fragments preceding grammatical separators. 6) The
final step is to build protein-protein pairs.
3.3 RAPIER

To evaluate the performance of KXtractor, we compare KXtractor with RAPIER.
RAPIER [3] is a well-known IE system that was developed with a bottom-up

982

M. Song et al.

inductive learning technique for learning information extraction rules. In order to use
the slot-filling IE systems like RAPIER for extracting relations, we adapt the Rolefiller approach proposed by Bunescu et al. [2]. The Role-filler approach allows for
extracting the two related entities into different role-specific slots. For protein
interactions, Bunescu et al. [2] name the roles interactor and interactee. As indicated
by the role names, protein-protein interactions are defined with the assumption that
proteins appear in the same sentence.
3.4 Single POS HMM

In order to verify that our MiHMM models are superior to the plain HMM, we
develop a plain HMM, based on single terms and a single model that incorporate less
grammatical information. We implemented single-level HMMs whose states emit
words, but are typed with part-of-speech (POS) tags so that a give state can emit
words with only a single POS. The Viterbi algorithm extracts information from
documents modeled by an HMM. With the fix structure, the objective of learning is
to give high probabilities to training documents. The result of learning is estimated
probabilities for vocabularies and transitions.

4 Experiments
We conducted experiments to evaluate the performance of KXtractor on the task of
protein-protein interaction extraction. In experiments the machine learning systems
were trained using the abstracts with proteins and their interactions, processed by the
text chunking technique. With these set of data, the IE systems extract interactions
among these proteins. This gives us a measure of how the extraction systems for
protein-protein pairs perform alone. Performance is evaluated using ten-fold cross
validation and measuring recall and precision. As the task of interest is only to extract
interacting protein-pairs, in our evaluation we do not consider matching exact position
and every occurrence of interacting protein-pairs within the abstract.To evaluate our
IE systems, we construct a precision-recall graph. Recall denotes the ratio of the
number of slots the system found correctly to the number of slots in the answer key,
and precision is the ratio of the number of correctly filled slots to the total number of
slots the system filled.
Our experiments show that RAPIER produces relatively high precision but low
recall. The similar results are observed in the dictionary-based extraction method
which gives also high precision but low recall. Single POS HMM produces the
second best results, although recall is relatively lower than precision. Among these
three systems, KXtractor outperforms RAPIER, Dictionary, and single POS HMM in
terms of precision, recall, and F-measure. As shown in Table 1, F-Measure of
KXtractor is 52.38% whereas RAPER is 35.49%, dictionary is 36.10%, and single
POS HMM is 43.80%. Figure 5 shows the precision-recall graphs of KXtractor,
RAPIER, Dictionary, and single POS HMM-based extraction for the protein-protein
interaction data set. The curve for KXtractor is superior to the curves for RAPIER,
Dictionary, and single POS HMM.

Integrating Text Chunking with MiHMM

983

Table 1. Comparison of extraction system performance
Extraction System

Precision

Recall

F-Measure

Dictionary-based extraction

62.31%

32.81%

36.10%

RAPIER

60.17%

34.12%

35.49%

Single POS HMM

67.40%

47.23%

43.80%

KXtractor

70.23%

51.21%

52.38%

80

70

60
KXtractor

Recall (%)

50

RAPIER

40

Dictionary
Single POS HMM

30

20

10

0
0

10

20

30

40

50

60

Precision (%)

Fig. 5. Precision-recall graph for extracting protein-protein pairs

5 Conclusion
In this paper, we proposed a novel and high quality information extraction system,
called KXtractor, a noun phrase-based Mixture Hidden Markov Models (MiHMM)
system. KXtractor consists of two major components: 1) text chunking and 2) Mixture
Hidden Markov Models (MiHMM) component. KXtractor is differentiated from other
approaches in that (a) It overcomes the problem of the single POS HMMs with
modeling the rich representation of text where features overlap among state units such
as word, line, sentence, and paragraph. By incorporating sentence structures into the
learned models, KXtractor provides better extraction accuracy than the single POS
HMMs. (b) It resolves the issues with the single POS HMMs for IE that operate only
on the semi-structured data such as HTML documents and other text sources in which
language grammar does not play a pivotal role.
We compared KXtractor with three well-known IE techniques: 1) RAPIER, a rulebased machine learning system, 2) Dictionary-based extraction system which was
proposed by [2], and 3) single POS HMM. Our experiments showed that KXtractor
outperforms other IE techniques such as RAPIER, dictionary-based, and single POS
HMM in extracting protein-protein interactions in terms of F-measure. The F-

984

M. Song et al.

Measure of KXtractor is 52.38% whereas RAPER is 35.49%, dictionary is 36.10%,
and single POS HMM is 43.80%. In addition, both precision and recall of KXtractor
are higher than those of RAPIER, Dictionary, and single POS HMM. In our follow-up
paper, we will apply KXtractor to other types of relation extractions such as
subcellular-localization relation extraction. We also plan to compare KXtractor with
other IE systems such as MaxEnt and SVM.

References
1. Blaschke, C., Andrade, M.A., Ouzounis, C., and Valencia, A. (1999). Automatic
Extraction of Biological Information from Scientific Text: Protein-Protein Interactions, In
Proceedings of the Seventh International Conference on Intelligent Systems for Molecular
Biology, Heidelberg, Germany, 60-67.
2. Bunescu, R., Ge, R., Kate, R.J., Marcotte, E.M., Mooney, R.J., Ramani, A.K., and Wong,
Y.W. (2004). Comparative Experiments on Learning Information Extractors for Proteins
and their Interactions. To appear in Journal Artificial Intelligence in Medicine (Special
Issue on Summarization and Information Extraction from Medical Documents).
3. Califf, M.E. and Mooney, R.J. (1999). Relational Learning of Pattern-Match Rules for
Information Extraction. Proceedings of the Sixteenth National Conference on Artificial
Intelligence (AAAI-99), Orlando, FL, 328-334.
4. Cortes, C. and Vapnik, V. (1995). Support-Vector Networks. Machine Learning, 20(3):
273-297.
5. Kudo, T. and Matsumoto, Y. (2000). Use of Support Vector Learning for Chunk
Identification. In Proceedings of CoNLL- 2000 and LLL-2000, Saarbruncken, Germany,
142-144.
6. National Library of Medicine (2003). The MEDLINE database,
http://www.mcbi.nlm.nih.gov/PubMed/.
7. Rabiner, L. R. (1989). A Tutorial on Hidden Markov Models and selected applications in
speech recognition. Proceedings of the IEEE, 77:257-286.
8. Skounakis, M., Craven, M., and Ray, S. (2003). Hierarchical Hidden Markov Models for
Information Extraction. Proceedings of the 18th International Joint Conference on
Artificial Intelligence, Acapulco, Mexico, August, 427-433.
9. Song, M, Song, I-Y., and Hu, X. (2003). KPSpotter: A Flexible Information Gain-based
Keyphrase Extraction System, Fifth International Workshop on Web Information and Data
Management (WIDM'03), New Orleans, Lousiana, 50-53.
10. Viterbi, A. J. (1967). Error bounds for convolutional codes and an asymptotically optimal
decoding algorithm. IEEE Transactions on Information Processing, 13:260-269.

