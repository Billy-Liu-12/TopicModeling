Design and Implementation of DAG-Based
Co-scheduling of RPC in the Grid
JiHyun Choi1 , DongWoo Lee2 , R.S. Ramakrishna3 ,
Michael Thomas4 , and Harvey Newman5
1,2,3

Department of Information and Communication,
Gwangju Institute of Science and Technology, Republic of Korea
{jhchoi80, leepro, rsr}@gist.ac.kr
1,4,5
California Institute of Technology, Pasadena, CA91125, USA
{jchoi, thomas, newman}@hep.caltech.edu

Abstract. Eﬀective scheduling in the Grid consisting of heterogeneous
and distributed resources is imperative in order to counter unacceptably
large overheads of the Grid. We proposed the grid middleware (pyBubble) supporting the DAG based co-scheduling for improving the performance of the RPC mechanism. DAG based co-scheduling reduces redundant transmission of input and output data from execution of the
sequence of related client requests, thereby decongesting the network.
We demonstrate the eﬃciency of DAG based co-scheduled RPC in
experiments compared with the overhead of the traditional RPC
mechanism.

1

Introduction

The Grid is the Internet-connected computing and data management infrastructure. Computing and data resources are geographically dispersed in diﬀerent
administrative domains with diﬀerent policies for security and resource usage.
The computing resources are highly heterogeneous, ranging from single PCs and
workstations, cluster of workstations, to large supercomputers[5]. With the technology of the Grid we can construct large-scale and scientiﬁc applications over
these distributed and heterogeneous resources. There are many critical issues
that need to be eﬃciently resolved to support the ever-increasing number of
applications that can beneﬁt from the Grid Computing infrastructure.
GridRPC[8] is a programming model based on client-server remote procedure
call(RPC), with features added to allow easy programming and maintenance
of code for scientiﬁc applications on the Grid. Application programmers write
parallelized client programs using simple and intuitive GridRPC APIs that hide
most of the complexities involving Grid programming. As a result, programmers
lacking experience in parallel programming, let alone the Grid, can still construct
Grid Applications eﬀortlessly[3]. Most applications in Grid Computing generally
have large input data sets and intricate data dependency. Moreover, data transfer
in large distributed systems can add an unacceptable amount of overhead. The
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3516, pp. 196–204, 2005.
c Springer-Verlag Berlin Heidelberg 2005

Design and Implementation of DAG-Based Co-scheduling of RPC

197

goal of this research is to devise simple and eﬀective strategies for dealing with
these issues.

2

Related Works

Grid programming involves the Interface and the Run-time system. WS-Resource
Framework deﬁnes Web service convention to enable the discovery of, introspection on, and interaction with stateful resources in standard and interoperability
ways. Many enhanced interfaces for grid computing such as Grid MPI and Grid
RPC have been developed. With regard to Message Passing Interface(MPI), several systems, notably, MPICH-G2, MPI Connect1 , PACX-MPI, MagPIe2 and
Stampi3 have been studied for connecting diﬀerent MPI implementations. Conventional parallel programming is implemented by these MPI-like systems in
tightly coupled high performance parallel computing networks or network of
workstations. MPI needs middleware to interact with the global grid.
The other programming paradigm of importance is RPC (Remote Procedure
Call)[2]. It is used for calling remote functions through a simple programming
interface. To a user, RPC presents a transparent interface to a remote function.
RPC is the most promising candidate for Grid programming interface due to
its simplicity and user friendliness. With this interface, the grid middleware can
invoke a remote grid resource via RPC calls. Ninf-g[9], NetSolve-G(Grid Solve)4 ,
OmniRPC[7] and so forth provide Grid RPC interface to their systems.
pyBubble[6] provides DAG(Directed Acyclic Graph)-based co-scheduling as a
mechanism to minimize repeated interactions among resources. Unlike Ninf and
NetSolve, our system can store the applications task dependencies in DAGs.
These DAGs allow pyBubble to schedule communications with a functionalitybased scheduling algorithm. Our DAG-based Grid Runtime with RPC programming interface exhibits substantial performance improvements in terms of the
execution time of related RPC requests. This eﬃciency increases in larger distributed systems that suﬀer from large data transfer overheads.

3

Motivation

In the traditional RPC paradigm, individual RPCs are processed independently.
The actual scheduling of the remote invocation is unilaterally determined by
the remote service receiving the RPC request. Clients, however, may have to
meet scheduling constraints. If a remote call entails submitting a batch job or a
sequence of related tasks, the client may at least want to know what the queue
1
2
3
4

MPI Connect, http://icl.cs.utk.edu/projects/mpi-connect
MagPIe, http://www.cs.vu.nl/albatros
Stampi, http://ssp.koma.jaeri.go.jp/en/index.html
GridSolve, http://www.nsf-middleware.org/documentation/NMI-R4/0/gridsolve

198

J. Choi et al.

length is, or have some notion of the expected time of completion. Clients may
also need to co-schedule multiple RPCs if the input and output parameters of
these multiple RPCs are interrelated. Co-scheduling will help avoid the transmission of redundant data, resulting in an overall shortened response time and
reduced network congestion. The total processing time can also be shortened by
executing modules concurrently whenever possible. However, GridRPC systems
do not support any mechanism to co-schedule GridRPC that targets heterogeneous and loosely-coupled systems over wide-area networks. This work is an
attempt to ﬁll this gap.
Figure1[1] illustrates two kinds of data ﬂow involving multiple RPCs. The
client invokes the services of three servers for processing a job consisting of three
tasks. There is ample opportunity to reduce redundant network traﬃc between
clients and servers when we execute this series of related RPCs. In the left
diagram, servers always return the result to the client after the execution of
their tasks. But, in the co-scheduled system, servers don’t need to return the
intermediate results to the client, but instead send the intermediate results to
other servers directly as their inputs. In the right diagram, server3 executes the
ﬁnal task, and sends only the ﬁnal result back to the client.

Fig. 1. Data ﬂow compared with co-scheduling

Grid Computing usually involves the processing of very large amounts of
data using distributed resources over wide area. When we take the overhead of
the data transfer time into consideration, decongestion of network traﬃc by coscheduling in the Grid can substantially contribute toward reducing the overall
response time of multiple RPCs.

4

Framework: The pyBubble

Our system, pyBubble, is a web service-based Grid middleware for parallel and
distributed computation. This system intends to be a GridRPC system that
uses XML-based RPC for the interactions between the client application and
remote computing resources. pyBubble is written in the Python programming
language to support portability across multiple platforms. pyBubble uses SOAP
as the transport encoding and supports DAG based co-scheduling and a restart
protocol for improving the dependability of the system.

Design and Implementation of DAG-Based Co-scheduling of RPC

4.1

199

SOAP-based Implementation

pyBubble[6] uses SOAP for performing remote procedure calls. SOAP provides
an envelope that encapsulates XML data for transfer through the Web infrastructure with a convention for Remote Procedure Call (RPCs) and a serialization
mechanism based on XML Schema data type. We note that other RPC mechanisms for Grids are possible, including XML-RPC5 which also uses XML over
HTTP. While XML provides tremendous ﬂexibility, it currently has poor support for binary data due to a signiﬁcant encoding cost[4]. Therefore, we compress
the xml documents before they are transferred in order to reduce the overhead
caused by the substantial encoding overhead of XML.
4.2

pyBubble Architecture and General Scenario

Figure 2 shows each of these components of pyBubble and illustrates the relationship and data ﬂow between the components. pyBubble consists of the client, the
resource broker, and resource servers. We can get metadata of available servers
by intergrating monitoring services, but we can use speciﬁc host conﬁguration
information collected from servers in this work.
Resource
Broker

DAG_Submit

SOAP
Dispatcher

DAG
Scheduler

Scheduler
Policy

DAG
Launcher

Dispatcher

Dispatcher

Dispatcher

SOAP
Server

SOAP
Server

SOAP
Server

DAGCall

DataPool

Server

Server

DAG
Object
Builder

DAGCall

DataPool

Server

Client
Client
Client

Monitoring
Sensors

MedaData

DAGCall

DataPool

Fig. 2. The architecture of pyBubble consisting of client, broker and servers

We can assume that the user has several tasks targeted to distributed servers.
First, the user sends the tasks to the pyBubble broker with the programming
interface for DAG-based co-scheduling which constructs the DAG from client’s
tasks, subject to constraints. The client speciﬁes the input data, the result labels
and the function names with the programming interface. The tasks to be sent to
5

XML-RPC, http://www.xml-rpc.com

200

J. Choi et al.

the broker should be a sequence of interrelated requests. The broker ranalyzes
the relationships of input and output data within tasks, and then checks the
precedence or dependency between tasks. It then constructs the DAG. The DAG
has the information about intra-task relationships.
Tasks are assigned to the right server based on the scheduling algorithm
because the broker has the information about available servers. To execute the
tasks, ﬁrst, the broker submits root tasks in the DAG. The root tasks are assigned
to multiple servers to be executed in parallel. They call the respective child tasks
in sequence according to the DAG. They also send the result, the scheduling
information for the child task, and the DAG to the child tasks. After all the
tasks are completed, the server executing the ﬁnal task sends its result to the
broker.

5
5.1

DAG-Based Co-scheduling of RPC
The DAG Model and Application Encoding Using DAG

The DAG is a generic model of a parallel program consisting of a set of interdependent processes (nodes). A node in the DAG represents a task. The graph
also has directed edges representing a partial order among the tasks. The partial
order creates a precedence-constrained directed acyclic graph[20]. For scheduling
purposes, tasks are described by a DAG. A DAG incorporates all the precedence
relationships among tasks and information about the assigned task in order
to make scheduling decisions. After scheduling, the DAG includes information
about which task is assigned to which server.
5.2

DAG-Based Co-scheduling Algorithm with Function
Availability

After constructing the DAG, the broker schedules the DAG tasks based on function availability since the broker can get information of conﬁguration ﬁles speciﬁed on each server and knows which resource can execute which function. Figure
3 shows the pseudocode of DAG-based co-scheduling by functional availability. The function deﬁnition procedure assists in ﬁnding the available resources
oﬀering the requested function and this returns the candidate set of the resources. The variable DAG is the collection of the requests described in DAG,
and Rmax is the number of resources. ResourcePool includes the information
about available resource to which the broker assigns some task. Each task in the
DAG ﬁnds the cadidate resources set oﬀering the function called by the method
FindResHavingFunc. In the candidate resource set, one resource is selected for
assignment to the task. After ﬁnding the root tasks, they are executed with the
Execute method.

Design and Implementation of DAG-Based Co-scheduling of RPC

201

Fig. 3. Pseudocode of scheduling by functional availability

6

Experiment Results

The experiments compare co-scheduled RPC with conventional RPC. The performance criteria are data size, number of processors, and the CPU power. The
eﬃciency of DAG-based co-scheduling can vary with these factors.
6.1

Application: Image Processing

Image Processing is appropriate for studying the eﬃciency of co-scheduling. In
this experiment, images can be very large, on the order of several gigabytes
in size. The execution of a series of transformations - in a speciﬁc order - on
an image is common in image processing. This experiment shows the improved
eﬃciency of DAG-based co-scheduling. The results of experiments depend of the
combination of the function set and the DAG construction.
Comparison with increasing image size. Figure 4 shows that the execution
time of conventional RPC increases sharply when the data size increases due to
network traﬃc overhead. But the increase in the execution time of co-scheduled
RPC is not as drastic. Parallel processing of concurrent tasks and the resulting
reduction in redundant network traﬃc contribute to this improved performance.
Comparison on the basics of CPU Performance. This experiment uses
CPU power as the performance criterion: the high performance group and the low

202

J. Choi et al.
600
Cos-Sched
One
500

Elapsed Time(sec)

400

300

200

100

0
0

10

20

30

40

50

60

70

80

90

100

Image Index

Fig. 4. Execution time of Co-scheduled RPC and Conventional RPC

performance group. Figure 5 compares co-scheduled RPC with conventional RPC
in both the server groups. the performance of the low performance group is not
improved signiﬁcantly with co-scheduled RPC because that has large overhead
for co-scheduling tasks and is not less aﬀtected by reducing network overhead.
Performance Comparision of 1:1 and Co-scheduled RPC with CPU Capability
1800
Cos-Sched with High CPU
One with High CPU
Cos-Sched with Low CPU
One with Low CPU

1600
1400

Elapsed Time(sec)

1200
1000
800
600
400
200
0
0

10

20

30

40

50
Image Index

60

70

80

90

100

Fig. 5. Comparison of conventional and co-scheduled RPC in low performance CPU
group and high performance RPC group

Comparison with the diﬀerent number of processors. In ﬁgure 6, the
single processor records the worst performance as expected. Two and three processors achieve the best performance. The DAG has three root tasks and two
child tasks and hence two or three are just the right numbers. Two processors
return a performance below that of three processors. This is understandable in
light of the fact that there are three (concurrent) root tasks in the DAG. Four
and ﬁve processors also exhibit good performance until the number of images
reaches 80. Thereafter, the performance degrades due to heavy network traﬃc
induced by large sized images.

Design and Implementation of DAG-Based Co-scheduling of RPC

203

Performance Comparision of Co-scheduled RPC with Increading the Number of Processors
800
1 Processor
2 Processors
3 Processors
4 Processors
5 Processors

700

Elapsed Time(sec)

600

500

400

300

200

100

0
10

20

30

40

50
60
Image Index

70

80

90

100

Fig. 6. Performance comparison of co-scheduled RPC with increasing of processor

7

Conclusion

In this paper we have proposed a DAG based co-scheduling technique as a tool
for eﬃcient RPC programming in the Grid. Co-scheduling intends to avoid redundant transmission of inputs and outputs in order to reduce network traﬃc
congestion. The system supports a portable programming interface for DAG
based co-scheduling as a user facility. DAG-based applications are scheduled using functionality- and input output data location-based co-scheduling algorithm.
Image processing applications were used for test purposes and have proved that
DAG based co-scheduling exhibits considerable performance improvements over
conventional RPC.

References
1. Dorian C. Arnold, Dieter Bachmann, and Jack Dongarra. Request sequencing:
Optimizing communication for the grid. In Euro-Par, pages 1213–1222, 2000.
2. Gregory L. Field Lola Gunter Thomas Klejna Shankar Lakshman Alexia Prendergast Mark C. Reynolds David Gunter, Steven Burnett and Marcia E. Roland.
Client/Server Programming With Rpc and Dce. Que, 1995.
3. GlobalGridForum. http://www.ggf.org.
4. M. Govindaraju, A. Slomenski, V. Choppella, R. Bramley, and D. Gannon. Requirements for and evaluation of rmi protocols for on the performance of remote
method invocation for scientiﬁc computing. In Proc. of the IEEE/ACM International Conference on Supercomputing (SC 2000), November 2000.
5. Ian Foster, Carl Kesselman, editor. The GRID2: Blueprint for New Computing
InfrastructureMeyers. Morgan Kaufmann, 2003.
6. DongWoo Lee and JiHyun Choi. http://pybubble.sourceforge.net, 2004.
7. Mitsuhisa Sato, Taisuke Boku, and Daisuke Takahashi. Omnirpc: a grid rpc ystem
for parallel programming in cluster and grid environment. In CCGRID, pages 206–,
2003.

204

J. Choi et al.

8. Keith Seymour, Hidemoto Nakada, Satoshi Matsuoka, Jack Dongarra, Craig A.
Lee, and Henri Casanova. Overview of gridrpc: A remote procedure call api for grid
computing. In GRID, pages 274–278, 2002.
9. Y. Tanaka, Hidemoto Nakada, Satoshi Sekiguchi, Toyotaro Suzumura, and Satoshi
Matsuoka. Ninf-g: A reference implementation of rpc-based programming middleware for grid computing. J. Grid Comput., 1(1):41–51, 2003.

