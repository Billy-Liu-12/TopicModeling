Resource Partitioning Algorithms in a
Programmable Service Grid Architecture
Pieter Thysebaert, Bruno Volckaert, Marc De Leenheer,
Filip De Turck, Bart Dhoedt, and Piet Demeester
Department of Information Technology, Ghent University - IMEC,
Sint-Pietersnieuwstraat 41, B-9000 Gent, Belgium
{pieter.thysebaert, bruno.volckaert}@intec.ugent.be
Abstract. We propose the use of programmable Grid resource partitioning heuristics in the context of a distributed service Grid management architecture. The architecture is capable of performing automated
and exclusive resource-to-service assignations based on Grid resource status/properties and monitored service demand. We present two distinct
approaches for the partitioning problem, the ﬁrst based on Divisible Load
Theory and the second built on Genetic Algorithms. Advantages and
drawbacks of each approach are discussed and their performance is evaluated using NSGrid. Results show that automated resource-to-service
partitioning simpliﬁes scheduling decisions, improves service QoS support and allows eﬃcient computational/network resource usage.

1

Introduction

As more and more application-types are being ported to Grid environments,
an evolution from pure computational and/or data Grids to full-scale service
Grids [1] is taking place. A “service Grid” denotes a Grid infrastructure capable of supporting a multitude of application types with varying QoS levels.
With widespread Grid adoption also comes the need for automated distributed
management of Grids, as the number of resources oﬀered on these Grids rises
dramatically. Automated self-conﬁguration/optimization of Grid resource usage
can greatly reduce management complexity, and at the same time achieve better
resource utilization [2]. In this paper, the focus is on the automated deployment
of resource partitioning algorithms, which intelligently (i.e. based on current
service needs and Grid status) assign Grid resources (network, computing and
data/storage resources) to a particular service class for exclusive use during a
speciﬁed time frame. In doing so, we wish to improve service class priority support and Grid resource utilisation while at the same time simplifying scheduling
decisions. Well-known service-driven Grid scheduling frameworks such as AppLeS [4] and GrADS [5] diﬀer from our approach in that we use a Service Management Architecture which operates independent of the scheduling system and
actively monitors application behaviour at runtime.
In order to compare the performance of a service managed Grid versus a nonservice managed Grid we use NSGrid (reported upon in [3]), an ns-2 based Grid
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3516, pp. 250–258, 2005.
c Springer-Verlag Berlin Heidelberg 2005

Resource Partitioning Algorithms

251

simulator capable of accurately modeling diﬀerent Grid resources, management
components and network interconnections. More speciﬁcally, we evaluated both
GA-based and DLT-based resource partitioning strategies, both when network
aware and when network unaware scheduling algorithms are used.
The remainder of this paper is structured as follows: section 2 gives an
overview of the service management architecture. Section 3 elaborates on the
diﬀerent resource partitioning strategies, while their evaluation in a typical Grid
topology is discussed in section 4. Concluding remarks are presented in section 5.

2

Service Management Architecture

We regard a Grid as a collection of Grid Sites interconnected by WAN links.
Each Grid Site has its own resources (computational, storage and data resources
abbreviated as CR, SR and DR respectively) and a set of management components, all of which are interconnected by means of LAN links. Management
components include a Connection Manager (capable of bandwidth reservation
support, and responsible for monitoring available link bandwidth), an Information Service (IS) (storing the properties and status of the registered resources)
and a Scheduler. Every resource in our model is given an associated service class
property (stored in the Information Services). The basic unit of work in our
model is a job, which can roughly be characterised by its length (execute time
on a reference processor), required input data, the amount of output data and
the service class to which it belongs. Each Grid Site has one or more Grid Portals
through which users can submit their jobs. Once submitted, a job gets queued at
the Scheduler, which in turn queries both local and foreign ISs for resources adhering to the job’s requirements. Once the results of those queries are returned,
the Scheduler applies one of its scheduling algorithms and (if possible) selects one
or more DRs (for input data), together with one or more SRs (for storing output
data) and a CR (for processing). If the scheduling algorithm is network aware,
the Connection Manager is queried for information about available bandwidth
on paths between resources and, once a scheduling decision is made, attempts
to make connection reservations between the selected resources.
A distributed service management architecture was implemented in NSGrid
in order to evaluate the performance of diﬀerent resource partitioning strategies.
Each Grid Site has a local Service Manager interacting with the local IS, Connection Manager and Service Monitor. The Service Monitor component monitors
local characteristics of each service class; it stores inter-arrival times, I/O data
requirements and processing length of jobs. At speciﬁed intervals, the Service
Monitor sends the collected information to all known foreign Service Monitors,
so they can keep their ‘foreign service characteristics’ information up-to-date.
The Service Manager queries the local Service Monitor for information regarding the diﬀerent services. When the monitored service characteristics do not
diﬀer (with regard to a certain threshold) from the ones used to partition the
Grid resources in a previous run, no repartitioning will occur. If this is not the
case, or if no partitioning has been done yet, the Service Manager will query the

252

P. Thysebaert et al.

ISs for Grid resource properties/status. Once the answer to these queries has
been received, one of the resource partitioning algorithms (detailed in section 3)
is applied to the resource set, and the resulting solution is sent back to the ISs,
which in turn change the service-exclusive attribute of their stored resources.

3

Partitioning Strategies

Recall that we are trying to partition resources into service class resource pools.
A solution to this problem is a mapping from resource to a particular service
type, and this for all resources returned from the Service Manager - IS queries.
A resource can also be assigned service type ‘0’, meaning it can be used by
any service type. Exhaustively searching for a cost function optimum quickly
becomes infeasible, as the number of solutions that needs to be evaluated is
(#servicetypes + 1)#resources . To ﬁnd a suitable solution in reasonable time, we
used two distinct approaches: one uses Divisible Load Theory while the other
uses a Genetic Algorithm to obtain a resource-to-service mapping.
3.1

DLT-Based Partitioning

Whenever a Grid reaches a steady state (e.g. a Grid processing a periodic load),
stochastic parameters regarding the distributions of job IAT, duration and I/Oneeds can be derived for each Service Type by the Service Monitoring Architecture. These parameters can then be used to fuel an ILP designed to
1. Assign an exclusive Service Type to each Computational Resource.
2. Determine the optimal schedule of the periodic workload over the Grid’s
resources, taking into account the Service Type assignation.
An approximation used to limit the number of integer variables in this problem
is to treat the aggregate workload as arbitrarily divisible (hence the name “Divisible Load Theory”) [6]. In this context, values of interest are arrivalsns - the
load per time unit arriving at site s and belonging to service type n, Setsn and
Sizen - the datasets available to service type n jobs and their respective sizes.
Main decision variables in the problem are xc,n (binary, assigning resource type
c
(real-valued, amount of service type n load per time unit
n to CR c) and αi,n
processed at CR c which arrived at site i). Auxiliary variables needed to fulﬁll
routing constraints on the input datasets and generated output data have been
dubbed inln,j (bandwidth needed on link l for transport of dataset j of service
type n) and outls (bandwidth needed on link l for transport of output to SR s).
Using the Divisible Load approach, the resource-to-service assignation can
now be modeled as a cost minimization problem with several classes of constraints1 . The capacity constraints to be observed are
∀c∈CR.

1

i∈Sites

n∈ST

αci,n ≤Capc

(1)

Abbreviations used:GW = Gateways, L+ = outgoing links, L− = incoming links.

∀l∈L.

n∈ST

j∈Setsn

Resource Partitioning Algorithms

253

outls ≤Capl

(2)

inln,j +

s∈SR

Network traﬃc is routed according to following constraints:
∀n∈ST,j∈Setsn .

d∈DR:j∈Setsd

∀c∈CR,n∈ST,j∈Setsn .
∀c∈CR,s∈SR.
∀s∈SR.

+
l∈Lc

−
l∈Ls

−
l∈Lc

n∈ST

n∈ST

∀g∈GW,n∈ST,j∈Setsn .
∀g∈GW,s∈SR.

inln,j =

outls =

outls =

αc ×Sizen
i∈Sites i,n
|Setsn |

αcSites ,n ×Sizen

arrivalsn
Sites ×Sizen

−
l∈Lg

−
l∈Lg

arrivalsn
s ×Sizen
s∈Sites
|Setsn |

inln,j =

+
l∈L
d

inln,j =

outls =

+
l∈Lg

+
l∈Lg

inln,j

outls

(3)
(4)
(5)
(6)
(7)
(8)

A feasible schedule is obtained by
∀i∈sites,n∈ST.

αci,n =arrivalsn
i

c∈CR

(9)

Constraints concerning the exclusive reservation of each CR:
∀c∈CR.
∀c∈CR,n∈ST.

n∈ST

i∈Sites

(10)

xc,n =1

αci,n ≤xc,n ×Capc

(11)

The “cost” to be minimized can take on several forms; for instance, the total
amount of data traveling over network links per unit of time (in the steady-state
Grid) can be described in terms of problem variables as
l∈L

n∈ST ,j∈Setsn

inln,j +

s∈SR

outls

(12)

Using this cost function in the ILP results in a workload schedule and Service
Type assignation yielding minimal aggregate network load for a given arrival
process. Alternatively, one can choose to minimize the maximal unused CR fraction, which results in an “even” workload distribution across all CRs according
to their respective capacities. This can be modeled by adding the constraints
∀c∈CR,n∈ST.cost≥

3.2

xc,n ×Capc −

i∈Sites
Capc

αc
i,n

(13)

GA-Based Partitioning

The resource type assignment can easily be encoded into an n-tuple of service
type IDs, where n equals the number of resources. These chromosomes can then
be fed to a Genetic Algorithm which evaluates the ﬁtness of each chromosome
(i.e. possible service type assignment) w.r.t. a cost function (see algorithm 3.1).
Unlike an ILP, this cost function need not be “linear” in the decision variables,
giving this approach more expressive power than the DLT-based partitioning.

254

P. Thysebaert et al.

Algorithm 3.1: Genetic Algorithm(resources)
populationinitial ←(b(1,0) ,...,b(m,0)), t←0
while

do

stopcondition false
⎧
for i←1 to m comment: proportional selection
⎪
⎧
⎪
⎪
x←rand[0,1], k←1
⎪
⎪
⎪
⎨
f (bj,t )
k
⎪
⎪
while k<m and x<
m
⎪
j=1
⎪
do
f (bj,t )
⎪
j=1
⎪
⎪
⎪
⎩ do k←k+1
⎪
⎪
⎪
bi,t+1 ←bk,t
⎪
⎪
⎪
for i←1 to m−1 step i+2 comment: two-point crossover
⎪
⎧
⎪
⎪
if rand[0,1]≤ρC
⎪
⎪
⎨
⎧
⎪
⎪
⎨
pos1←rand[1,m], pos2←rand[1,m]
⎪
⎨if pos1>pos2
⎪
do
⎪
⎪
then switch(pos1,pos2)
then
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
⎩
⎪
for k←pos1 to pos2
⎪
⎪
do switch(bi,t+1 [k],bi+1,t+1 [k])
⎪
⎪
⎪
⎪
for i←1 to m comment: mutation
⎪
⎪
for k←1 to m
⎪
⎪
⎪
if rand[0,1]<ρM
do
⎪
⎪
do
⎪
then bi,t+1 [k]←rand[0,#ST ]
⎪
⎩
t←t+1

Global Service CR Partitioning. This cost function takes into account the
computational processing needs and priority of the diﬀerent service types (ST ).
The Service Manager queries the ISs for all local CRs and calculates average
ptime ST
service processing needs ∀ST ·ppowerreqST = sitesST × IATref
. Average proST
cessing time of a job from service class ST on a reference processor is denoted
by ptimerefST , while sitesST denotes the amount of Grid portals launching
jobs from this service class. The relative processing power assigned to a service
speedCR
× ptimerefST .
type is then given by: ∀ST · ppowerasgST = ∀CR∈ST speed
CR
ref

The importance of assigning resources to foreign service types can be adjusted
by the local Service Manager by tweaking the foreign service policy ρSTf oreign .
Once CR query answers have been received, GA 3.1 will be started with cost
function 3.2 (GA equivalent of equation 13), with an objective to assign each
service type a same amount of processing power relative to their requested processing power.
Network Partitioning. Since the Service Monitor keeps track of I/O data
characteristics of each service, data intensiveness relative to the other services
can be calculated. This in turn can be used to perform per-service network
bandwidth reservations. We have implemented a proof-of-concept network partitioning strategy, in which the Service Manager calculates average data requirement percentages for each service class bwreqi =

bwinput +bwoutput
i
i
IATi
bwinput +bwoutput
j
j

∀j∈ST

IATj

and passes this information to the Connection Manager, which will make service type bandwidth reservations on all network links for which it is responsible.

Resource Partitioning Algorithms

255

Algorithm 3.2: fCRpartglobal (x)
result←
for

ppowerasg
0
2

, maxAllocover ←0, maxAllocunder ←0

i∈ST
⎧ local ∪STf oreign
⎪aux←ppowerreqi −ppowerasgi

⎪
⎪
⎪
if aux<0
⎪
⎪
⎪
⎪
⎪
⎪
then
⎪
⎪
⎪
⎪
⎪
⎨

do

if

−aux>maxAllocover
then maxAllocover ←−aux

aux←ppowerasgi
aux

>maxAlloc

under
ppowerreq
i
⎪
aux
⎪
then maxAllocunder ← ppower
else
⎪
reqi
⎪
⎪
⎪
⎪
aux←ppowerasgi −aux
⎪
⎪
⎪
if i∈STf oreign
⎪
⎪
then aux←aux×ρST
⎪
f oreign
⎪
+
⎪result←
priorityi
⎩
×aux
if

(

−

j∈ST

priorityj )

result←maxAllocover +maxAllocunder

4
4.1

Performance Evaluation
Simulation Setup

A ﬁxed Grid topology was used for all simulations. First, a WAN topology (containing 8 core routers with an average out-degree of 3) was instantiated. Among
the edge LANs, we chose 12 of them to represent a Grid site. Each site’s resources and management components are connected through 1Gbps LAN links,
while Grid site interconnections consist of dedicated 10Mbps WAN links. We
have assigned 3 CRs to each Grid Site. To reﬂect the use of diﬀerent tiers in
existing operational Grids, not all CRs are equivalent: the least powerful CR has
two processors (operating at reference speed). A second class of CRs has four
processors, and each processor operates at twice the reference speed. The third
CR type contains 6 processors, each operating at 3 times the reference speed.
Conversely, the least powerful CR is 3 times as common as the most powerful
CR, and twice as common as the middle one. We have assumed that SRs oﬀer
“unlimited” disk space. Each site has at its disposal exactly one such SR. Each
site’s DR contains 6 out of 12 possible data sets. These data sets are distributed
in such a way that 50% of the jobs can have local access to their needed data.
We used 2 equal-priority service classes (each accounting for half of the total
job load); one is more data-intensive, while the other is more CPU-intensive
(see table 4.2). Jobs were scheduled using one of two scheduling algorithms; the
ﬁrst algorithm only uses available CR capacities to make decisions, while the
second also takes into account network link loads [7]. Once suﬃcient statistical
data about the job parameters had been gathered by the Service Monitor, the
Service Manager was instructed to apply a partitioning algorithm to the Grid’s
resources. We measured average job response time (JRT) and network usage.

256

P. Thysebaert et al.

4.2

Comparison of DLT- and GA-Based Partitioning

In general, our GA-based partitioning strategy provides more functionality, as it
is able to support diﬀerent priority schemes, shared resource and local vs. foreign
service diﬀerentiation. Its main drawback is the time needed to complete a GA
run (with reasonable results); on our sample scenario, this takes about 800s,
while the DLT-based approach needs only 10s. For the GA approach, we used
Grefenstette’s settings, with an initial population of 30, ρC = 0.9 and ρM = 0.01,
and a stop condition of 100 runs.
450
No SM
GA
DLT CR
DLT Network

400

CPU-Job Data-Job
Input(GB)
0.01-0.02
1-2
Output(GB)
0.01-0.02
1-2
IAT(s)
30-40
30-40
Ref. run time(s) 100-200
40-60

Average Job Response Time (s)

350

300

250

200

150

100

50

0
All

Data ST

CPU ST

Fig. 1. Job Class Properties & Non-Network Aware Scheduling: Metrics

4.3

Non-network Aware Scheduling

Using a non-network aware scheduling algorithm over all Grid partition strategies results in average JRTs as shown in ﬁgure 4.2. Clearly, the use of Grid
partitioning based on accurate job characteristic predictions has a positive inﬂuence. This behavior is due to resources being reserved for exclusive use by a
service class, forcing the scheduler not to assign jobs to less-optimal resources
(e.g. non-local access to needed input data), but to keep the job in the scheduling queue until a service-assigned resource becomes available. Optimizing the
Grid partitions for minimal network usage does not yield a signiﬁcant improvement, as the scheduling algorithm does not take into account network loads and
diverges from the workload distribution as proposed by the DLT ILP.
4.4

Network Aware Scheduling

Values for average JRT and network usage observed when jobs are scheduled
using a network aware algorithm are shown in ﬁgure 2. Again, when partitioning
for optimal CPU usage, average JRTs are improved when compared to JRTs
obtained when no partitioning strategy is used2 . In analogy, after partitioning
for minimal network utilization, network resources are less loaded.
2

GA stands for GA-based computational partitioning, while GA-CONN denotes GAbased computational partitioning + network partitioning.

Resource Partitioning Algorithms

100

No SM
GA
GA-CONN
DLT CR
DLT Network

11200

No SM
GA
GA-CONN
DLT CR
DLT Network

11000
Total Network Resource Usage (MB)

Average Job Response Time (s)

90

257

80

70

60

50

10800

10600

10400

10200

40

10000
All

Data ST

(a) Job Response Time

CPU ST

(b) Network Utilization

Fig. 2. Network Aware Scheduling: metrics

We measured the time it takes to calculate a scheduling decision and noticed
a decrease in scheduling time of 28% when comparing the service managed Grid
to the non-service managed Grid (i.e. from an average 12.71s in the non service
managed case to 9.13s in the service managed Grid). This can be explained by
the fact that when resources are partitioned among services, less resource query
results will be returned to the scheduler, allowing easier scheduling decisions.

5

Conclusions

In this paper we proposed a distributed service management architecture, capable of monitoring service characteristics at run-time and partitioning Grid
resources among diﬀerent priority service classes. Two speciﬁc partitioning algorithms were discussed, and we indicated how our architecture dynamically
invokes each algorithm with suitable parameters. We evaluated these algorithms
using NSGrid: besides easing the process of schedule making decisions, Service
Partitioning does not lead to a deterioration of Grid performance, both when job
response times or network resource utilization is measured. A possible preference
of one algorithm over the other depends on the trade-oﬀ between the size of the
needed feature set and the algorithm’s computational complexity.

References
1. I. Foster, C. Kesselman, J.M. Nick, S. Tuecke, “Grid services for distributed system
integration”, IEEE Computer, Vol. 35-6, pp. 37-46, 2002
2. J.O. Kephart, D.M. Chess, “The vision of autonomic computing”, IEEE Computer,
Vol. 36-1, pp. 41-50, 2003
3. B. Volckaert, P. Thysebaert, F. De Turck, P. Demeester, B. Dhoedt, “Evaluation
of Grid Scheduling Strategies through a Network-aware Grid Simulator ”, Proc. of
PDPTA 2003, Vol. 1, pp. 31-35, 2003

258

P. Thysebaert et al.

4. F. Berman et al., “Adaptive Computing on the Grid Using AppLeS ”, IEEE Transactions on Parallel and Distributed Systems, Vol. 14-4, pp. 369-382, 2003
5. H. Dail, F. Berman, H. Casanova, “A Decoupled Scheduling Aproach for Grid Application Development Environments”, Journal of Parallel and Distributed Computing,
Vol. 63-5, pp. 505-524, 2003
6. P. Thysebaert, F. De Turck, B. Dhoedt, P. Demeester, “Using Divisible Load Theory
to Dimension Optical Transport Networks for Computational Grids”, in Proc. of
OFC/NFOEC 2005
7. P. Thysebaert, B. Volckaert, F. De Turck, B. Dhoedt, P. Demeester, “Network
Aspects of Grid Scheduling Algorithms”, Proc. of PDCS 11, pp. , 2004

