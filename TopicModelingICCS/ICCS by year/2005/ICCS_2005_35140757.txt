Machine Efficient Adaptive Image Matching Based on
the Nonparametric Transformations
Bogusław Cyganek
AGH – University of Science and Technology
Al. Mickiewicza 30, 30-059 Kraków, Poland

Abstract. The paper presents machine efficient area-based image matching
method that is based on a concept of matching-regions that are adaptively
adjusted to image contents. They are in a form of square windows which grow
to convey enough information for reliable matching. This process is controlled
by local image contents. The images, however, are transformed into
nonparametric representation. Such a liaison of information-theoretic models
with nonparametric statistics allows for compensation for noise and
illumination differences in the compared images, as well as for better
discrimination of compared regions. This leads to more reliable matching in
effect. Machine efficient implementation is also discussed in the paper. Finally
the experimental results and conclusions are presented.

1 Introduction
The area-based image matching algorithms are ubiquities in image processing
systems. They all operate in the similar fashion: the image regions of the same shape
and size are compared by means of some measure. Then based on a result of this
comparison the regions are pronounced to be matched or not. There are also many
improvements to this basic scheme, since in practice the method is not always
reliable. One of the most cumbersome problems is choice of the matching regions
beforehand. Their shape and size determine quality of matching and unfortunately
depend greatly on image contents, as well as on noise, texture, and image distortions.
One of such improvements consists of adaptively adjusted matching regions to
accommodate diverse image contents. There are different strategies that control this
process. One of the very original solutions with a statistical model was proposed by
Kanade and Okutomi [8]. The appropriate window is selected by evaluating the
variations in intensity and disparity. Their method is based on the observation that at
discontinuities the intensity and disparity variations are larger, unlike at the positions
of surfaces. However, the implementation of this method is quite complicated.
The adaptive window technique developed by Lotti [9] for matching aerial images
bases on window adjusting that is limited by edges and statistical contents of the
matching regions. However, this technique is quite time consuming and rather limited
to special class of images.
There are also many other techniques [3], such as multiple windowing [6] or a
variable window concept for integral images proposed by Veksler [10].
V.S. Sunderam et al. (Eds.): ICCS 2005, LNCS 3514, pp. 757 – 765, 2005.
© Springer-Verlag Berlin Heidelberg 2005

758

B. Cyganek

In this paper we present an extension to the adaptive window growing technique
(AWG) originally proposed in [3]. This method tries to adjust size of the matching
window in order to conveyed enough information for more reliable matching. At the
same time size of a window is kept as small as possible. However, in respect to [3],
the technique has been simplified for easier implementation and speed up.
It can be shown that the AWG technique is equivalent to computation of signal
entropy in a window, however in a more efficient way. This is achieved thanks to the
prior image transformation into nonparametric representation which is more resistive
to noise and local lighting incompatibilities. Such domain allows for fast information
assessment since this nonparametric signal representations conveys mutual relation
among neighboring pixels.

2

The Adaptive Window Concept for Image Matching

Zabih and Woodfill proposed the nonparametric Rank and Census transforms for
computation of correspondences. The Census, used in the presented method, returns
an ordered stream of bits, defined as follows: a bit at a given position is ‘1’ if and only
if an intensity value at a pixel is greater or equal to the central pixel; otherwise a bit is
set to ‘0’. Local neighborhood of pixels is usually 3×3 and 5×5 square window [11].
The consecutive image matching, in the nonparametric domain, is usually done by
means of Hamming measure used to compare different image areas [11][1], although
other measures are possible as well [5]. The AWG technique presented in this paper
allows for better control of the size of matching windows (whereas size of the Census
transform is fixed to 3×3 neighborhoods and should not be confused hereafter).
For a given central pixel at (i,j) and surrounding n×n square neighbourhood, the
corresponding Census measure IC(i,j) can be defined as a series of bits [3][5]:
IC (i , j ) = b

n 2 −1

[

]

… b … b3 b2 b1b0 , where k ∈ 0, … , n 2 − 1 /
k

{ ⎣n2 ⎦ }.
2

(1)

The bk parameter can be expressed as follows:
bk = 1 if

⎛ ⎢n⎥ ⎢k ⎥
⎞
⎢n⎥
I ⎜⎜ i − ⎢ ⎥ + ⎢ ⎥, j − ⎢ ⎥ + k mod n ⎟⎟ ≥ I (i, j ) , 0 otherwise,
⎣2⎦
⎝ ⎣2⎦ ⎣n⎦
⎠

(2)

where I (i, j ) denotes the intensity value for an image at a point at (i,j) in image
coordinates, ⎣k n ⎦ integer division of k by n, k mod n modulo n division.
Let us examine some 3×3 pixel neighbourhoods and their Census representations
(Fig. 1). Not knowing values of pixels surrounding this neighbourhood, the complete
Census value can be estimated only for the central pixel from the neighbourhood of
interest. Therefore all the other pixels have their Census values assessed only in
respect to their closest neighbouring pixels belonging to this 3×3 neighbourhood. All
other values are left undefined and marked as ‘x’ (don’t care). Such bits can be
assigned ‘0’ or ‘1’ depending on intensity values of other pixels, lying in other 3×3
neighbourhoods, where the given pixel in turn lies in their centre. The function q(‘b’)
in Fig. 1 returns number of bits with value ‘b’ (i.e. number of ‘0s’ or ‘1s’).

Machine Efficient Adaptive Image Matching Based on Nonparametric Transformations

759

The question arises on distribution of the Census values, computed in local 3×3
neighborhoods for the whole image, in respect to the distribution of intensities in the
input image. It is well known that the latter greatly influences any subsequent
matching, no matter what matching criteria are taken into consideration. The answer
to this question is fundamental to the AWG technique described in this paper.
Based on definition (1) we observe that neighborhoods with constant intensity
produce bit streams with all bits set to ‘1’ (Fig. 1a). That is data has zero entropy and
the conveyed information is too unreliable for matching. However, in Fig. 1b and Fig.
1c we notice that with an increase of spatial distribution – counted as an entropy of
intensity values – q(‘0’) increases as well. For exemplary values in Fig. 1 the entropy
of data in selected 3×3 regions increases conveying more information that in
consequence allows for more reliable matching.
For any n×n neighborhood it is evident that the following relation holds:

q('0' ) + q('1' ) + q (' x' ) = Bn 2 ,

(3)

where B stands for number of bits assigned for Census representation of a pixel.
Therefore maximization of q(‘0’) can be achieved by keeping q(‘1’) at minimum and
when undefined bits ‘x’ become ‘0’. This feature is used in implementation.
Pixel neighborhoods in the input image
(intensity values set for example)

j-1
j

99

78

78

j+1

91

78

78

i-1

i

99
13

254 101

254

xxxx1x00
x01x0x00
x10x0xxx

i-1

i

i+1

xxxx1x11

xxx00000

xxx1x11x

x11x0x10

01011010

10x0x10

x11x1xxx

00100xxx

11x1xxxx

i-1

i

i+1

xxx00000

xxx1x00x

11111111

11x1x11

11111xxx

11x1xxxx

q('0') =15
q('1') =25
q('x') =32

i+1

61

78 101
101

x11x1xxx

q('0') =0
q('1') =40
q('x') =32

i+1

79

65

j-1

i

11x1xxxx

j

i-1

11111xxx

j+1

78

j-1

78

11x1x11x

j

78

11111111

x11x1x11

j+1

78

i+1

xxx1x11x

j-1

78

i

xxx11111

j

j

78

i-1

xxxx1x11

j+1

j-1

78

j-1

c)

78

j

b)

i+1

78

j+1

a)

i

j+1

i-1

Pixel neighborhoods after 3x3 Census
transformation

45

q('0') =18
q('1') =22
q('x') =32

Fig. 1. Some 3×3 neighborhoods and their Census representations. q(‘b’) returns number of bits
with value ‘b’. Intensity values set only as an example – relevant are only their mutual relations

760

B. Cyganek

Disambiguation of all Census values in any 3×3 neighborhood requires knowledge
of intensity values of all pixels surrounding this neighborhood. Such a situation with
some exemplary intensity values is presented in Fig. 2. We notice that an increase of
the q(‘0’) entails a further increase of the entropy of data in the pixel neighbourhoods
of interest. For 3×3 neighborhoods around a point at indexes (i,j) in Fig. 2, the
entropies are respectively (from the top): 0.29, 0.41, and 0.55.
Pixel neighborhoods in the input image
(intensity values set for example)

i-1

j-1
j

11111111

j+1

10100101

j-1

10100101

00001011

j

11111111

00101001

j+1

i+1
11111111

01101000

j-1

i
10100101

11111111

00001000

86

01100011

100 111

100 87

00001000

91

89

78 254

78 254

78 254

78

78 254

i-1

i

80

81

82 83

j-1

95

100 111

j

94

111

j+1

93

100 111

100 87

92

91

90

89

i-1

i

i+1

80

81

82 83

j-1

95

100 111

94

99

93
92

i+1
84

100 85

254 111 86

86

90

q('0') =16
q('1') =56

78

j

78 254

j+1

c)

i-1

10100101

78 254

b)

78

11111111

78 254

78 254
254

i+1

78 254

j

254

i

j+1

j+1

a)

j

j-1

78 254

Pixel neighborhoods after 3x3 Census
transformation

i

i+1

00000111

00010110

00000000

10010100

11100000

11010000

q('0') =48
q('1') =24

88

84

100 85
99

i-1

i-1

i

i+1

00000000

00010000

11111111

11000110

00000000

00010000

q('0') = 52
q('1') = 20

88

Fig. 2. The specific 3×3 pixel neighborhoods and their Census transformations. Relevant are
relations of intensity values (set for example here)

From the definition (1) and from the mutual relation between the central point ‘X’
and all its closest neighbors ‘a’ – ‘h’ in Fig. 3 we see that if only an intensity value of
the point ‘X’ is different from all values of the points ‘a’ – ‘h’ we have met the
condition for maximum entropy for this point arrangement, and at the same time the
maximum number of ‘0’s is achieved. There exists yet an another type of the mutual
pixel relation – the relation among three consecutive pixels, such as ‘a’, ‘b’, and ‘d’ in
Fig. 3. For each pair of neighboring pixels from such a triple, a bit with value ‘0’ can
be assigned if and only if any pair of intensity values is different. In such a case, for
each pair of pixels from such a triple, one Census representation obtains ‘1’ at the
corresponding bit position, while the same bit position – but in the complementary
pixel from this pair – holds ‘0’. This is clear from (2) since there is an exclusive

Machine Efficient Adaptive Image Matching Based on Nonparametric Transformations

761

relation. Thus, if only the abutted pixels have different values, at the pertaining bit
position the only possibility is: bit ‘1’ in the first Census pixel of a pair and ‘0’ for the
second one.

j-1

i+1

a

b

c

j

i

d

X

e

j+1

i-1

f

g

h

Fig. 3. Relations among pixel values in the Census transformation

The rules for the maximum number of ‘0s’ – and in consequence entropy increase
– in a Census representation of any 3×3 neighborhood (see Fig. 3) are as follows:
1. A value of the central pixel X is irrelevant provided that it is different than any
other pixel from its closest neighborhood (i.e. from the all pixels a, b, c, d, e, f, g,
and h in Fig. 3):

∀p ∈ N − {X } : I ( p ) ≠ I ( X ) ,

(4)

where I(p) is an intensity value of a pixel at index p (see Fig. 1b) from the 3×3
neighborhood N.
2. Pixel values of any corner-triple (such as e.g. a, b, d in Fig. 3) must be different,
i.e.:

I (a ) ≠ I (b) ≠ I (c) .

(5)

3. All other pixels bordering with pixels from the neighborhood N must have their
intensity values less than their direct pixels-neighbors from N. For example, for the
pixel b in Fig. 3 these would be pixels at indexes: (j-2,i-1), (j-2,i), and (j-2,i+1).
The upper bound for any 3×3 Census neighbourhood qmax(‘0’) = 52 can be easily
found from the conditions 1-3 and after observing Fig. 3. This with (3) corresponds
with lower bound qmin(‘1’) = 20. The lower bound for data entropy (LBE) in any 3×3
Census neighbourhood that preserves the conditions 1-3 is obtained by taking only
four different values and can be easily found from (4) to be: LBE=-4/9∗log4/92∗2/9∗log2/9-1/9∗log1/9≈0.55. The upper bound for the entropy in any 3×3
neighbourhood is MBE=log(9)≈0.95 (i.e. nine different values). Thus, any 3×3
neighbourhood of pixels that preserve conditions 1-3 guarantee almost 58% of
maximum possible entropy in this neighbourhood. Concluding we can state that the
set of conditions 1-3 guarantying the maximum number of ‘0’s (or equivalently the
minimal number of ‘1’s) in any 3×3 Census neighborhood leads to at least LBE.
Therefore the sought size n of a matching square window can be found as to

762

B. Cyganek

maximize the averaged (per pixel) value of qav(‘0’) in a window of interest with a
constraint qtot ('0') > ϑ0 = 0 :

n:

max

nmin ≤ n ≤ nmax

q av ('0') ∧ qtot ('0') > ϑ0 = 0

(6)

where nmin and nmax set the lower and upper bound of size of the matching window, θ0
is a certain threshold for a total minimal amount of ‘0s’ in a window of interest; θ0
usually is set to 0. Thus, applying (6) we obtain the minimal size of the matching
window that is adapted to convey as much as possible of information to allow a more
reliable matching. Otherwise, in a case of a constant intensity we obtain information
that there is no such a window that can guarantee a reliable matching.
The other possibility is to allow window growing up to such a minimal size n for
which the achieved average qtot(‘0’) reaches a predefined threshold value ϑ1 :

min(n ) : q av ('0') > ϑ1

(7)

Similarly, one can search for such a minimal size n for which the total qtot(‘0’) reaches
a predefined threshold value ϑ 2 as follows:

min(n ) : qtot ('0') > ϑ2

(8)

Computations of (7) and (8) are simpler and in consequence faster than (6).
However they require an arbitrary setting of the threshold values.

3 Experimental Results
Experimental results and discussion of the image matching based on AWG operating
in accordance with (6) can be found in [3]. In this section we present results that help
compare different versions of the AWG given by (6)-(8). The computational platform
consists of the IBM PC with Pentium 4 with 3.4 GHz, 2GB, implementation in C++,.
Fig. 4 presents results of the AWG technique applied to match the “PCB”
stereo pair of size 253×193 (a). The disparity map obtained in accordance with (6) is

a

b

c

Fig. 4. The AWG technique applied to the “PCB” stereo image (253×193): left image of a
pair (a), disparity map from formula (6) (b), disparity map from formula (7) and θ1=2 (c)

Machine Efficient Adaptive Image Matching Based on Nonparametric Transformations

763

depicted in (b) while disparity from (7) with θ1=2 in (c). Execution times are 1.75 and
1.68 s, respectively. Parameter θ1 was chosen based on prior experiments. Allowable
window growing spanned: nmin=3 to nmax=30.
Fig. 5 contains results of the AWG applied to the “Mask” 450×375 pair (a).
Disparity map from (6) is shown in (b) and with formula (7) with θ1=2 in (d), formula
(8) with θ2=15 in (e), and θ2=150 in (f). Execution times are as follows: 2.05 for (b),
1.99 for (d), 0.83 for (e), and 4.22 for (f). The latter caused by the fact of much higher
matching windows due to high θ2. However, execution of (e) compared to (d) is
match faster, because total amount of ‘0s’ is easier to compute than their average.

a

b

c

d

e

f

Fig. 5. The AWG technique applied to the “Mask” pair (450×375): left image of a pair (a),
disparity map (6) (b), visualization of adaptive windows (lither places denote bigger windows)
(c), disparity map with formula (7) and θ1=2 (d), disparity map with formula (8) and θ2=15 (e),
disparity map with formula (8) and θ2=150 (f)

For each pixel location the size of a matching window is determined with the AWG
technique defined by (6). Disparity values are found for each pixel by matching
square windows of sizes appropriately set in the previous step. As a matching
measure the Hamming distance is computed from the Census representation of each
pair of candidate windows. Matching is done with a fast block matching algorithm
based on the winner-update strategy with hashing table [2]. The visible limited
occlusions are due to a simple stereo algorithm without the cross-checking [12]. In
Fig. 5(d-f) we notice also many occluding areas due to large displacement between
images of this stereo pair. However, the details were preserved due to adaptively
chosen matching windows.
The worst case time complexity of the AWG algorithm (6)-(8) can be estimated as
follows:

764

B. Cyganek

(

2
O NMnmax

)

(9)

for image of size N×M pixels, where nmax is the maximum allowable matching
window. However, the arithmetic operations are limited only to integer comparisons
and summations. Therefore the technique fits well hardware implementations.

4 Conclusions
The paper presents the image matching technique with adaptively changed matching
areas. The whole matching is performed after changing the original images into
nonparametric domain by means of the Census transformation. The basics of the
AWG technique were presented which can be summarized as follows: an increase of
the zero-value-bits q(‘0’) in any Census neighborhoods indicates increase of entropy
in this neighborhood of pixels. Different mutations (6)-(8) of the method allow for
adjustment of the matching region at different computational cost. In effect, the
subsequent matching is much more reliably than in a case of fixed windows [3].
The experimental results with the AWG technique applied to the stereo matching
showed robustness of this technique. The main purpose of avoiding low-textured
areas was achieved by means of very simple integer arithmetic. Therefore the AWG
method seems to be appropriate for hardware and real-time implementations.

Acknowledgement
This paper has been sponsored by the Polish Committee of Scientific Research (KBN)
grant number: 3T11C 045 26.

References
1. Banks J., Bennamoun M., Corke P.: Non-Parametric Techniques for Fast and Robust
Stereo Matching. CSIRO Manufacturing Science and Technology, Australia (1997)
2. Chen, Y-S., Hung, Y-P., Fuh, C-S.: Fast Block Matching Algorithm Based on the WinnerUpdate Strategy. IEEE Trans. On Image Processing, Vol. 10, No. 8, (2001) 1212-1222
3. Cyganek, B.: Adaptive Window Growing Technique for Efficient Image Matching.
Technical Report, AGH-University of Science and Technology, Krakow, Poland (2004)
4. Cyganek, B., Borgosz, J.: Maximum Disparity Threshold Estimation for Stereo Imaging
Systems via Variogram Analysis. ICCS 03, Russia/Australia (2003) 591-600
5. Cyganek, B.: Comparison of Nonparametric Transformations and Bit Vector Matching for
Stereo Correlation. Springer LNCS 3322 (2004) pp. 534-547
6. Fusiello, A. et.al.: Efficient stereo with multiple windowing. CVPR 858–863 (1997)
7. Haykin, S.: Neural Networks. A Comprehensive Foundation. Prentice-Hall (1999)
8. Kanade, T., Okutomi, M.: A stereo matching algorithm with an adaptive window: Theory
and experiment. PAMI, 16(9) (1994) 920–932
9. Lotti, J-L., Giraudon, G.: Adaptive Window Algorithm for Aerial Image Stereo. INRIA
Technical Report No 2121 (1993)

Machine Efficient Adaptive Image Matching Based on Nonparametric Transformations

765

10. Veksler, O.: Fast Variable Window for Stereo Correspondence using Integral Images.
Computer Vision and Pattern Recognition (2003)
11. Zabih, R., Woodfill, J.: Non-Parametric Local Transforms for Computing Visual
Correspondence. Proc. Third European Conf. Computer Vision (1994) 150-158
12. Zhengping, J.: On the Mutli-Scale Iconic Representation for Low-Level Computer Vision.
Ph.D. Thesis. The Turing Institute and University of Strathclyde (1988) 114-118

