Parallel Importance Separation for Multiple
Integrals and Integral Equations
Soﬁya Ivanovska and Aneta Karaivanova
IPP – Bulgarian Academy of Sciences
Acad. G. Bonchev St., Bl.25A, 1113 Soﬁa, Bulgaria
{sofia,anet}@parallel.bas.bg

Abstract. In this paper we present error and performance analysis of
a Monte Carlo variance reduction method for solving multidimensional
integrals and integral equations. This method, called importance separation, combines the idea of separation of the domain into uniformly small
subdomains with the approach of importance sampling. The importance
separation method is originally described in our previous works, here we
generalize our results and discuss the performance in comparison with
crude Monte Carlo and importance sampling. Based on our previous investigation we propose eﬃcient parallelizations of the importance separation method. Numerical tests implemented on PowerPC cluster using
MPI are provided. The considered algorithms are carried out using pseudorandom numbers.

1

Introduction

Multidimensional numerical quadratures are of great importance in many practical areas, ranging from atomic physics to ﬁnance. The crude Monte Carlo method has rate of convergence O(N −1/2 ) which is independent of the dimension
of the integral, and that is why Monte Carlo integration is the only practical
method for many high-dimensional problems.
Much of the eﬀorts to improve Monte Carlo method (MCM)are in construction of
variance reduction methods which speed up the computation. Importance sampling is probably the most widely used Monte Carlo variance reduction method,
[11,6,13,14]. One use of importance sampling is to emphasize rare but important events, i.e., small regions of space in which the integrand is large. One of
the diﬃculties in this method is that sampling from the importance density is
required, but this can be performed using acceptance-rejection.
In [8] a method called importance separation (IS) was introduced. This method
combines the ideas from importance sampling and stratiﬁcation. The IS method
has the best possible rate of convergence for certain class of functions but its
disadvantage is that it gives better accuracy only for low dimensions and its
increased computational complexity. This method was applied for evaluation of
multidimensional integrals [3] and for solving integral equations [5].
In this paper we consider both problems, solving multiple integrals and integral
equations through uniﬁed point of view converting the problem of solving of
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3039, pp. 499–506, 2004.
c Springer-Verlag Berlin Heidelberg 2004

500

S. Ivanovska and A. Karaivanova

integral equations into approximate calculation of a ﬁnite number of integrals
(linear functionals of iterative functions), then importance separation is applied
to the each of the integrals. We also describe the parallel implementation of the
two algorithms based on IS; it has some diﬃculties due to hierarchical structure
of the method.

2
2.1

Formulation of the Problem
Calculation of Multidimensional Integrals

Consider the problem of approximate calculation of the multiple integral
f (x)p(x) dx, G ≡ [0; 1]d

I=

(1)

G

where f (x) is an integrable function for any x ∈ G ⊂ Rd and p(x) ≥ 0 is a
probability density function, such that G p(x) dx = 1.
The Monte Carlo quadrature formula is based on the probabilistic interpretation
of an integral. If {xn } is a sequence in G sampled with density p(x), then the
Monte Carlo approximation to the integral is, [12],
I ≈ IN [f ] =

1
N

with the integration error εN = |I − IN | ≈
2.2

N

f (xn )
n=1
V ar(f )
.
N

Solving Integral Equations

Consider the Fredholm integral equation of the second kind:
u(x) =

k(x, x )u(x ) dx + f (x)
Ω

or
u = Ku + f (K is an integral operator),

where

k(x, x ) ∈ L2 (Ω × Ω), f (x) ∈ L2 (Ω) are given functions and u(x) ∈ L2 (Ω) is an
d
unknown function, x, x ∈ Ω ⊂ R (Ω is a bounded domain).
We are interested in Monte Carlo method for evaluation of linear functionals of
the solution of the following type:
J(u) =

ϕ(x)u(x) dx = (ϕ, u).

(2)

It is assumed that ϕ(x) ∈ L2 (Ω). We can apply successive approximation method
for solving integral equations:
i

K(j) f = f + Kf + . . . + K(i−1) f + K(i) f,

u(i) =
j=0

i = 1, 2, . . .

(3)

Parallel Importance Separation for Multiple Integrals

501

where u(0) (x) ≡ f (x). It is known that the condition K L2 < 1 is a suﬃcient
condition for convergence of the Neumann series. Thus, when this condition is
satisﬁed, the following statement holds:
u(i) −→ u
Therefore,



J(u) = (ϕ, u) = lim (ϕ, u(i) ) = lim ϕ,
i→∞

i → ∞.

as

i→∞

i


K(j) f  = lim

i→∞

j=0

i

ϕ, K(j) f .
j=0

An approximation of the unknown value (ϕ, u) can be obtained using a truncated
Neumann series (3) for suﬃciently large i:
(ϕ, u(i) ) = (ϕ, f ) + (ϕ, Kf ) + . . . + (ϕ, K(i−1) f ) + (ϕ, K(i) f ).
So, we transform the problem for solving integral equations into a problem for
approximate evaluation of a ﬁnite number of multidimensional integrals. We will
use the following denotation (ϕ, K(j) f ) = I(j), where I(j) is a value, obtained
after integration over Ω j+1 = Ω × . . . × Ω, j = 0, . . . , i. It is obvious that
the calculation of the estimate (ϕ, u(i) ) can be replaced by evaluation of a sum
of linear functionals of iterative functions of the following type (ϕ, K(j) f ), j =
0, . . . , i, which can be presented as:
(ϕ, K(j) f ) =

ϕ(t0 )K(j) f (t0 ) dt0 =
Ω

(4)
ϕ(t0 )k(t0 , t1 ) . . . k(tj−1 , tj )f (tj ) dt0 . . . dtj ,

=
G

. If we denote by F (t) the integrand
where t = (t0 , . . . , tj ) ∈ G ≡ Ω j+1 ⊂ R
function
F (t) = ϕ(t0 )k(t0 , t1 ) . . . k(tj−1 , tj )f (tj ), t ∈ Ω j+1 ,
d(j+1)

then we will obtain the following expression for (4):
I(j) = (ϕ, K(j) f ) =

F (t) dt,

t∈G⊂R

d(j+1)

.

(5)

G

So, from now on we will consider the problem for approximate calculation of
multiple integrals of the type (5). We will ﬁrst review brieﬂy the most widely
used Monte Carlo methods for integrals and integral equations. It is well-known
that Monte Carlo methods reduce the problem to the approximate calculation of
mathematical expectation which coincides with the unknown functional deﬁned
by (2).

3

Importance Separation for Integrals

The importance separation is a Monte Carlo method which combines the idea of
separation of the domain of integration into uniformly small subdomains (stratiﬁcation, [4]) and the Kahn approach to implement more samples in those subdomains where the integrand is large (importance sampling for integrals, [7], and

502

S. Ivanovska and A. Karaivanova

for integrals equations, [2,9]). This method has the best rate of convergence for
the class of functions with bounded derivatives (see [1]).
One approach how to make a partition of the given domain into subdomains was
studied in [8] where the problem for evaluation of the integral I(j) = G F (t) dt
is considered. The suggested there partition scheme of the domain G = [a; b] into
M subintervals (one-dimensional case) is the following one:
M

G=

Gl ≡ [xl−1 , xl ],

Gl ,

l = 1, . . . , M − 1,

l=1

Ci =

1
[F (xi−1 ) + F (xM )](xM − xi−1 ),
2

i = 1, . . . , M − 1,
(6)

Ci
xi = xi−1 +
,
F (xi−1 )(M − i + 1)
It is known (see [12]) that
where
∗
(j) =
θN

x0 = a, xM = b.

∗
EθN
(j) = I(j),
M

i=1

V(Gi )
Ni

Ni

M
(i)

Ni = N,

F (ξl ),
i=1

l=1

(i)

and ξl is a random point in the i-th subdomain of G.
In the general case of multidimensional integrals (G ⊂
gration error (the probable error) holds [8]:
rN ≤

√

1
2n
N

Rn ) the following inte-

1
2

N

(Lˆi c1i cˆ2i )

2

1

1

N−2−n ,

M = N,

(7)

i=1

where n is the dimension of the domain of integration, M is the number of subdomains, the integrand is a positive function F (t), which belongs to W (1) (L, G).
This means that F (t) is continuous on G with partially continuous ﬁrst derivatives and
∂F
≤ Lil , l = 1, . . . , d, t ∈ Gi , Li = (Li1 , . . . , Lid ), Lˆi = max Lil .
l
∂tl
The constants c1i (i = 1, . . . , M ) and the vectors of constants c2i ∈ R are
determined from the requirement the subdomains Gi , i = 1, . . . , M have to be
uniformly small in probability and in geometrical size, and it is also assumed
that cˆ2i = max c2il .
d

l

From (7) it is clear that the error of the importance separation method which has
the order O(N −1/2−1/n ) asymptotically goes to O(N −1/2 ) for large dimensions
n. This estimation of integration error shows that importance separation can be
considered as a good method for approximate calculation of integrals only if n
is not very large. Therefore when we translate this conclusion in the terms of
integral equation, it means that the von Neumann series has to converge quickly.

Parallel Importance Separation for Multiple Integrals

4

503

Parallel Implementation

In this section we present the parallel importance separation for evaluation of
multiple integrals and solving integral equations. The crude Monte Carlo possesses inherent parallelism which is based on the possibility to calculate simultaneously realizations of the random variable on diﬀerent processors. For our
algorithm (importance separation) we have some additional work: partitioning
of the domain. We consider a multiprocessor conﬁguration with p nodes.
N uniformly distributed random points xi ∈ [0; 1]d , i = 1, . . . , N are used to
obtain an approximation with given accuracy of the integral (1). For generation
of d−dimensional random point we need d random numbers. To estimate the
performance of the parallel algorithms we use:
ETp (A) mathematical expectation of time, required for a set of p processing
elements to solve the problem using algorithm A
ET1 (A)
Sp (A) =
speed-up
ETp (A)
Sp (A)
Ep (A) =
parallel eﬃciency.
p

5

Numerical Experiments

We present the numerical results (accuracy, CPU-time in seconds, parallel eﬃciency, speed-up) for the considered algorithm, importance separation, applied
to solving of multidimensional integrals and integral equations using pseudorandom number sequences. The numerical tests are implemented on a cluster of 4
two-processor computers Power Macintosh using MPI.
5.1

Calculation of Integrals

Here we present the results of solving of a multidimensional integral, which is
used as a test example in [10].
Example 1. This example is Monte Carlo integration over I 5 = [0, 1]5 of the
function
5
5
2 + sin( j=1,j=i xj )
,
f1 (x) = exp
ai x2i
2
i=1
where a = (1, 12 , 15 , 15 , 15 ). The numerical results for the accuracy of the described
methods for computing the multidimensional quadratures are presented in Table
1. The results are presented as a function of N , number of samples, and as a
function of the error, which is computed with respect to the exact solution. The
importance separation method leads to smaller errors. The most important fact is
that using importance separation we have very good accuracy even using small
sample. The superior behavior of importance separation is illustrated also by
Figure 1. Table 2 presents the achieved eﬃciency of the parallel implementation
(using MPI) for the considered method. The speed-up is almost linear and the
eﬃciency grows with the increase number of samples.

504

S. Ivanovska and A. Karaivanova

Table 1. Comparison between Crude MCM, Importance sampling, Importance separation for Example 1 (calculations are implemented on one processor)
N

Crude MCM
|I − IN | T1
100 0.009532 0.001
500 0.092960 0.004
2500 0.009027 0.020
10000 0.006611 0.076
50000 0.008443 0.386

Imp. sampling
|I − IN | T1
0.081854 0.008
0.007102 0.036
0.006381 0.175
0.004673 0.697
0.003212 3.489

Imp. separation
|I − IN | T1
0.000316 6
0.000003 31
0.000068 152
0.000061 610
0.000021 3047

Table 2. Implementation of IS for Example 1 using MPI (I = 2.923651)

p
1
2
3
4
5
6

5.2

Importance separation
N = 1000
N = 10000
IN
Ep p
IN
Ep
2.923604 1 1 2.923590 1
2.923603 0.979 2 2.923573 0.985
2.920636 0.967 3 2.923336 0.983
2.923804 0.941 4 2.923638 0.980
2.923463 0.934 5 2.923602 0.979
2.911825 0.925 6 2.922537 0.977

Solving Integral Equations

We use the following integral equation as a test Example 2:
u(x) =

k(x, x )u(x ) dx + f (x),

where

Ω

k(x, x ) =

0.055
+ 0.07,
1 + e−3x

f (x) = 0.02(3x2 + e−0.35x ),

( K

L2

≈ 0.2)

(8)

Ω ≡ [−2; 2].

This kind of equation describes some neuron networks procedures. We are
interested in an approximate calculation of (ϕ, u), where ϕ(x) = 0.7((x +
1)2 cos(5x) + 20). The results for parallel eﬃciency are presented as a function
of the number of nodes p. The importance separation algorithm is constructed
so that only one sample of the random variable is chosen in every subdomain.
The number of iterations d is ﬁxed, but it has been chosen in advance according
to the L2 -norm of the kernel (8). For the approximate computation of any integral I(j), j = 0, . . . , i diﬀerent number of samples are used in order to have
error balancing. The proposed parallel algorithm for importance separation shares the obtained subdomains among the processors. Thus, every node processes
the corresponding set of subdomains independently. This fact and insigniﬁcant
quantity of data that is transferred determine comparatively high parallel eﬃciency of the algorithm. The results for the achieved eﬃciency are given in Table
3, which illustrates the inherent parallelism of Monte Carlo methods.

Parallel Importance Separation for Multiple Integrals

505

Table 3. Relative error, CPU-time (in seconds) and parallel eﬃciency in the approximate calculation of (ϕ, u) for Example 2. The number of samples used for calculation
of each of the integrals I(j), j = 0, . . . , 5 is denoted by Nj

p
1
2
3
4
6

N0 = 240, N1 = 182
N2 = 123 , N3 = 64
N4 = 65 , N5 = 66
Rel. error Time Ep
0.1221 0.63
1
0.1079 0.31 0.997
0.0994 0.21 0.988
0.0272 0.16 0.976
0.1986 0.11 0.962

p
1
2
3
4
6

N0 = 480, N1 = 242
N2 = 183 , N3 = 124
N4 = 65 , N5 = 66
Rel. error Time Ep
0.0014 0.81
1
0.0016 0.40 0.997˙
0.0036 0.27 0.989
0.0122 0.21 0.979
0.0046 0.14 0.967

1.4

p
1
2
3
4
6

N0 = 480, N1 = 302
N2 = 243 , N3 = 124
N4 = 125 , N5 = 66
Rel. error Time Ep
0.0009 3.18
1
0.0005 1.59 0.999
0.0005 1.06 0.996
0.0010 0.80 0.994
0.0036 0.53 0.990

Importance separation method
Crude Monte Carlo method
Importance sampling method

Error [%]

1.0

0.6

0.2

−0.2

1000

10000

100000

Number of points

Fig. 1. Comparison of the accuracy of Crude MCM, Importance sampling, and Importance separation for Example 1

Acknowledgments. This work is supported by Center of Excellence BIS-21
Grant ICA1-2000-70016 and by the Ministry of Education and Science of Bulgaria under Grants # I 1201/02 and # MM 902/99.

References
1. N. S. Bahvalov. On the optimal estimations of convergence of the quadrature processes and integration methods, Numerical Methods for Solving Diﬀerential and
Integral Equations, Nauka, Moscow, 5–63, 1964, (in Russian).
2. I. Dimov. Minimization of the probable error for some Monte Carlo methods,
Mathematical Modelling and Scientiﬁc Computations, Andreev, Dimov, Markov,
Ulrich (Eds.), Bulgarian Academy of Sciences, Soﬁa, 159-170, 1991.
3. I. Dimov, A. Karaivanova, R. Georgieva, and S. Ivanovska, Parallel Importance
Separation and Adaptive Monte Carlo Algorithms for Multiple Integrals, Numerical Methods and Applications (I. Dimov, I.Lirkov, S. Margenov, and Z. Zlatev Eds.), LNCS 2542, 99-107, Springer, 2003.

506

S. Ivanovska and A. Karaivanova

4. V. Dupach. Stochasticke pocetni metody, Cas. pro pest. mat. 81(1), 55-68, 1956.
5. Rayna Georgieva and Soﬁya Ivanovska. Importance Separation for Solving Integral
Equations, Large-Scale Scientiﬁc Computing (I. Lirkov, S. Margenov, J. Wasniewski, and P. Yalamov - Eds.), LNCS 2907, 144-152, Springer, 2004.
6. T. Hesterberg. Weighted average importance sampling and defensive mixture distributions, Technometrics, 37(2), 185–194, 1995.
7. H. Kahn. Random sampling (Monte Carlo) techniques in neutron attenuation problems, Nucleonics 6(5), 27-33, 1950; 6(6), 60-65, 1950.
8. A. Karaivanova. Adaptive Monte Carlo methods for numerical integration, Mathematica Balkanica, 11, 391–406, 1997.
9. G. A. Mikhailov. Optimization of the ”weight” Monte Carlo methods, Moskow,
1987.
10. B. Moskowitz and R. E. Caﬂisch. Smoothness and dimension reduction in quasiMonte Carlo methods, J. Math. Comput. Modeling, 23: 37–54, 1996.
11. A. Owen and Y. Zhou. Safe and eﬀective importance sampling, Technical report,
Stanford University, Statistics Department, 1999.
12. I. M. Sobol. Monte Carlo Numerical Methods, Nauka, Moscow, 1973, (in Russian).
13. E. Veach and L. J. Guibas. Optimally combining sampling techniques for Monte
Carlo rendering, Computer Graphics Proceedings, Annual Conference Series, ACM
SIGGRAPH ‘95, 419–428, 1995.
14. E. Veach. Robust Monte Carlo Methods for Light Transport Simulation, Ph.D.
dissertation, Stanford University, 1997.

