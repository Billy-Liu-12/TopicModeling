Karhunen–Loeve Representation of Periodic
Second-Order Autoregressive Processes
Didier Lucor, Chau-Hsing Su, and George Em Karniadakis
Division of Applied Mathematics, Brown University, Providence, RI 02912, USA.

Abstract. In dynamic data driven applications modeling accurately the
uncertainty of various inputs is a key step of the process. In this paper,
we ﬁrst review the basics of the Karhunen-Lo`eve decomposition as a
means for representing stochastic inputs. Then, we derive explicit expressions of one-dimensional covariance kernels associated with periodic
spatial second-order autoregressive processes. We also construct numerically those kernels by employing the Karhunen-Lo`eve expansion and
making use of Fourier representation in order to solve eﬃciently the associated eigenvalue problem. Convergence and accuracy of the numerical
procedure are checked by comparing the covariance kernels obtained from
the Karhunen-Lo`eve expansions against theoretical solutions.

1

Introduction

In many application of dynamic data driven systems there is a signiﬁcant degree
of uncertainty associated with the various inputs due to inaccuracy of measurements, gappy data, or incomplete knowledge. We can incorporate this uncertainty directly into the models by formulating stochastic algorithms, but a
signiﬁcant ﬁrst step is to represent accurately and eﬃciently all stochastic inputs.
The Karhunen-Lo`eve (KL) expansion is a very powerful tool for representing stationary and non-stationary random processes with explicitly known covariance
functions [1]. In a few cases, the eigen-solutions of the covariance function can
be obtained analytically but in most cases they have to be obtained numerically
[2]. The KL representation is optimal as both the deterministic basis functions
and the corresponding random coeﬃcients are orthogonal. If the random process is assumed stationary and the ratio between the length of the domain and
the correlation length is inﬁnite or periodic boundary conditions are imposed,
the KL representation becomes a spectral expansion with uncorrelated random
coeﬃcients [3].
One of the simplest and most used random processes is the ﬁrst-order Markov
process, which relates to the Brownian motion of small particles and the diﬀusion
phenomenon. It is a unilateral type of scheme extended only in one direction. The
covariance kernel associated with that one-dimensional ﬁrst-order autoregressive
process takes an exponential form [2]. However, realistic models of random series
in space require autoregressive schemes with dependence in all directions. In
some cases, it has been shown that schemes of bilateral type in one dimension
can be eﬀectively reduced to a unilateral one [4].
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3038, pp. 827–834, 2004.
c Springer-Verlag Berlin Heidelberg 2004

828

D. Lucor, C.-H. Su, and G.E. Karniadakis

In the current work, we derive explicit expressions of one-dimensional covariance kernels associated with periodic second-order autoregressive processes.
We then represent numerically those kernels using a KL representation where
we make use of the Fourier series representation in order to compute eﬃciently
the associated eigenvalue problem. Convergence and accuracy of the numerical
method are checked against theoretical solutions for the kernels.

2

The Karhunen-Lo`
eve Expansion

The KL expansion is based on the spectral expansion of the covariance function
c(t1 , t2 ) of the process v(t, θ), where t1 and t2 are two temporal coordinates and
time is from a to b. The KL expansion then takes the following form:
∞

v(t, θ) = v¯(t) + σv

λi ψi (t)ξi (θ),

(1)

i=1

where v¯(t) denotes the mean of the random process, σv denotes the standard
deviation of the process, and ξi (θ) is a set of independent random variables
with a given random distribution; they form an orthonormal random vector
(throughout this paper, we will use the symbol ξ to denote a random variable
with zero mean and unit variance.) Obviously, truncated expansions will be
used in practice. Also, ψi (t) and λi are the eigenfunctions and eigenvalues of the
covariance function, respectively, i.e.,
b
a

c(t1 , t2 )ψi (t2 )dt2 = λi ψi (t1 ) .

(2)

The KL expansion minimizes the mean-square error resulting from a ﬁnite-term
representation of the process [2]. Its use, however, is limited as the covariance
function of the solution process is not known a priori. Nevertheless, the KL expansion still provides a powerful means for representing input random processes
when the covariance structure is known. Some numerical experiments regarding
the accuracy of truncated KL representation for diﬀerent covariance kernels have
been reported in [5,6]. The rate of convergence of the KL expansion is closely
related to the smoothness of the covariance kernel and to the ratio between the
length of process T and the correlation length A. For instance, for the particular
case of a ﬁrst-order Markov process, given by c(t1 , t2 ) = σv2 e−|t2 −t1 |/A , an upper
bound for the relative error in variance of the process represented by its KL
expansion is such that:
≤

4 1T
1T
≈ 0.4053
.
2
nA
π nA

(3)

T
, where T is the length of the time domain,
We see that it depends on the ratio A
and it is inversely proportional to the number of retained terms. The dependence
in ( n1 ) is related to the rate of convergence of the Fourier decomposition for this
particular kernel, which has a discontinuity in its ﬁrst derivative at the origin [6].

Karhunen–Loeve Representation

3

829

Fourier Series Representation of the Integral Equation

If the random process is stationary with respect to t, then the covariance satisﬁes:
c(t, t1 ) = v(t)v(t1 ) = c(t − t1 ).

(4)

The corresponding integral equation (2) for the eigenfunctions and eigenvalues
used in the KL representation can be cast into a spectral form by taking a Fourier
series representation of the kernel function c(t − t1 ) and the eigenfunctions ψ(t).
The Fourier series representation provides a natural way of solving the problem if
it is periodic, i.e. both the kernel function c and the eigenfunctions ψ are periodic
functions with period T . In this case, the integral equation can be solved exactly.
With both ψ(t) and c(t) being periodic functions of period T, we represent
them in terms of their Fourier series as follows:
∞

ψ(t) =

ψco
2nπ
2nπ
ψcn cos
+
(t − a) + ψsn sin
(t − a) ,
2
T
T
n=1

c(t) =

2nπ
2nπ
cco
+
ccn cos
t + csn sin
t ,
T
T
2
n=1

(5)

∞

(6)

with
ψcn =
ccn =

b

2
T

dtψ(t) cos

a

2nπ
(t − a),
T

T /2

2
T

−T /2

dtc(t) cos

2nπ
t,
T

ψsn =

csn =

2
T

1
T

b

a
T /2

−T /2

dtψ(t) sin

dtc(t) sin

2nπ
(t − a) (7)
T

2nπ
t
T

(8)

In most applications c(t) is an even function and thus csn = 0. Substituting
equations (5-6) into equation (2), we obtain:
λ−

cco
T
2

∞

ccn
ψco
λ−
+
T
2
2
n=1

ψcn cos

2nπ
2nπ
(t − a) + ψsn sin
(t − a) = 0. (9)
T
2

We derive the set of eigenvalues and eigenfunctions as:
1. λ = λ0 =
2. λ = λn =
(n)

T
2 cco ,
T
2 ccn ,

ψ1 (t1 ) =

ψc0 = 0, ψcn = ψsn = 0 for n = 0 and ψ (0) = √1T .
ψcn = 0, and ψsn = 0, ψcm = ψsm = 0 for m = n, and
2nπ
2
cos
(t1 − a),
T
T

(n)

ψ2 (t1 ) =

2nπ
2
sin
(t1 − a).
T
T

(10)

The KL representation of the periodic random process v(t, ξ) is:
v(t, ξ) =

λo
ξco +
T

2
T

∞

λn ξcn cos
n=1

2nπ
2nπ
(t − a) + ξsn sin
(t − a) ,
T
T
(11)

830

D. Lucor, C.-H. Su, and G.E. Karniadakis

where
λn =

T
ccn =
2

T /2
−T /2

c(t) cos

2nπ
t dt = 2
T

T /2

c(t) cos
0

2nπ
t dt.
T

(12)

Given a covariance function c(t), one can solve these integrals using appropriate
numerical quadrature methods. The corresponding covariance function which
can be obtained directly from equation (11):
∞

v(t, ξ)v(t1 , ξ) =

cco
2nπ
ccn cos
+
(t − t1 ) = c(t − t1 ),
2
T
n=1

(13)

is just the Fourier series representation of the covariance function c.
It is worthwhile to note that this approach can also be used as an approximation for non-periodic cases if the domain T of the problem is much larger
than the correlation length A. The range of the functions ψ(t) and ψ(t1 ) is (a, b)
while that of c(t − t1 ) is (−T, T ) where T = b − a. In order to represent the
extended functions as Fourier series, i.e., we need to take the period to be 2T.
However, if c(t − t1 ) has a compact support, or if it is diﬀerent from zero only for
|t − t1 | ≤ A for some ﬁnite A, then in cases where A
T , the relative error in
using the period being T rather than 2T is of the order of A/T. In the literature,
this approximation is sometime refered to as spectral approximation [7,8].
Notations and more detailed derivations for Section 3 can be found in the
work of Lucor [9].

4

Second-Order Autoregressive Processes

For space series, a bilateral autoregression takes the form:
vi = γvi−1 + δvi+1 + i or
b
(14)
vi = (vi−1 + vi+1 ) + af ξi ,
2
where it is intuitively clear that γ and δ cannot be too large. Let us denote
by L the spatial length of the periodic domain and take L = 1 without loss of
generality. We discretize the domain with 2m + 1 equidistant points, so that we
have: m = L/2∆x. The expression for vi , due to the homogeneity of the system
based on the assumed periodicity, reduces to:
2m−1

vi =

αj ξi+j .
j=0

The coeﬃcients are such that:
 af

=1
for j = 0

b2

 1− Dm


αj = αj−1 /Dm−i+1 for 0 < j ≤ i with D1 = 1; Dk = 2 − b2 /Dk−1 ; 1 < k ≤ m






0
for j > i

Karhunen–Loeve Representation

831

Because we take α0 = 1, the variance of the process is conserved and is constant
for each point in the domain, so we have: af = 1 − b2 /Dm . The covariance vi vj
between two points of the grid is obtained from the dynamical system:
2m−1

vi vj =

αj αj+i−k .

(15)

j=0

Let us deﬁne the mode number q that represents the number of waves that
one could ﬁt within the domain L; the corresponding wave number is k = 2πq/L.
There exists an analogy between a second-order regressive dynamical system of
type (14) and the discrete version of a non-homogeneous second-order ordinary
equation [10]:
vi+1 − 2vi + vi−1
± k 2 vi = F (xi ).
∆x2

(16)

Indeed, the system of equations (14) can be transformed into equation (16) by
setting b = 1/(1 ± 12 (k∆x)2 ) and af ξi = −F (xi )∆x2 /(2 + (k∆x)2 ). This gives
in the continuous limit of ∆x going to zero:
2

1

1

b = e± 2 (k∆x) = e± 2 (

2πq
2
L ∆x)

(17)

The wave number k has the dimension of the inverse of a correlation length A,
A = 1/k. The coeﬃcient b tends to unity as ∆x (grid size) tends to zero. The
plus or minus signs in equation (17) indicate that b can approach unity from
above or below. This distinction gives totally diﬀerent results for the covariance
kernel form.
2
1
If b = e− 2 (k∆x) < 1, which corresponds to equation (16) with a negative
sign, and under the assumption that the domain is periodic, the covariance of
the solution is:
v(x), v(y) =

1
4k 2 sinh2

L
kL
2

0

L

F (x1 )F (x2 ) cosh k |x − x1 | −

0

cosh k |y − x2 | −

L
dx1
2

L
dx2 .
2

(18)

If the variance of the forcing function is conserved for each point of the domain,
i.e. F (x)F (y) = σF2 δ(x − y), it becomes:
v(x), v(y) =

σF2
4k 2 sinh2

L
kL
2

0

cosh k |x − x1 | −

L
L
cosh k |y − x1 | −
dx1 .
2
2
(19)

The normalized covariance kernel becomes in this case:
c(x, y) =

1
2α + sinh (2α) + α|x − y|(cosh (2α) − 1) cosh (α|x − y|)
2α + sinh (2α)

+ 1 − cosh (2α) − α|x − y| sinh (2α) sinh (α|x − y|)

; α = qπ
(20)

832

D. Lucor, C.-H. Su, and G.E. Karniadakis
0.8

1
q=1.0
q=2.5
q=5.0

q=3
q=0.5
q=2.5
q=5.5

0.9

0.7

0.8
0.6
0.7

Eigenvalues: λi

Eigenvalues: λi

0.5

0.4

0.3

0.6

0.5

0.4

0.3
0.2
0.2
0.1

0

0.1

1

2

3

4

5

6
i

7

8

9

10

0

11

1.5

1

2

3

4

5

6
i

7

8

9

10

11

2
st

st

1 Eigenfunction
nd rd
2 /3 Eigenfunctions
th th
4 /5 Eigenfunctions
th th
6 /7 Eigenfunctions

1 Eigenfunction
nd rd
2 /3 Eigenfunctions
th th
4 /5 Eigenfunctions
th th
6 /7 Eigenfunctions

1.5

1

Eigenfunctions: f (x)

i

Eigenfunctions: fi(x)

1
0.5

0

0.5

0

−0.5
−0.5

−1
−1
−0.5

−0.4

−0.3

−0.2

−0.1

0
x

0.1

0.2

0.3

0.4

0.5

−0.5

−0.4

−0.3

−0.2

−0.1

0
x

0.1

0.2

0.3

0.4

0.5

Fig. 1. Left column: Kernel1. Right column: Kernel2. Top row: Eigenvalues λi for
various values of the correlation length, here given by q, with q = L/(2πA) and L = 1.
Bottom row: First four-pairs eigenfunctions fi (x) with |x| ≤ L/2 and L = 1 and
q = 2.5.
(b)

(a)

1

0.15
0.5

0.1

0

0.05

−0.5

0.5

0.5

0

0

0.5

0.5

0

0
−0.5

−0.5

−0.5

−0.5

(c)

(d)

−3

x 10
1

5

0.8

4

0.6

3

0.4

2

0.2

1

0
0.5

0.5

0

0
0.5

0.5

0
−0.5

−0.5

0
−0.5

−0.5

Fig. 2. Approximation of Covariance Kernel1 with q = 2.5; k = 5π. (a): n = 5-term
KL approximation (b): n = 5-term absolute error (c): n = 21-term KL approximation
(d): n = 21-term absolute error.

Karhunen–Loeve Representation
(a)

833

(b)

1
0.3
0.5
0.2
0

0.1

−0.5
0.5

0.5

0

0
0.5

0.5

0
−0.5

0
−0.5

−0.5

−0.5

(c)

(d)

−4

x 10
1
0.5

6

0

4

−0.5

2

−1
0.5

0.5

0

0
0.5

0.5

0
−0.5

−0.5

0
−0.5

−0.5

Fig. 3. Approximation of Covariance Kernel2 with q = 2.5; k = 5π, (a): n = 5-term
KL approximation (b): n = 5-term absolute error (c): n = 21-term KL approximation
(d): n = 21-term absolute error.

In the following, we will refer to the covariance kernel given by equation (20) as
Kernel1. We show a close approximation to this kernel in Figure 2. This kernel
is periodic, as expected, and the decay rate is controlled by the correlation length
value. The kernel decays faster for smaller correlation lengths.
Similarly and under the same assumptions as in the previous case, if b =
2
1
e 2 (k∆x) > 1, which corresponds to equation (16) with a positive sign, it can be
shown that the covariance kernel is similar to Kernel1 and becomes:
c(x, y) =

1
2α + sin (2α) + α|x − y|(cos (2α) − 1) cos (α|x − y|)
2α + sin (2α)
+ 1 − cos (2α) + α|x − y| sin (2α) sin (α|x − y|).
(21)

In the following, we will refer to the covariance kernel given by equation
(21) as Kernel2. We show a close approximation to this kernel in Figure
3. This kernel decays faster for smaller correlation lengths. Interestingly, if q
is an integer, the covariance kernel given by equation (21) simply becomes
c(x, y) = cos (α|x − y|). Since all those kernels are periodic, it is possible to employ the Fourier decomposition method of the integral equation described in the
previous paragraph, in order to build a KL representation of the corresponding
processes. In this case, the time dimension is treated as a spatial dimension without loss of generality. We obtain the eigenvalues and eigenfunctions of the kernels
from equations (10) and (7-8). The integrals of equations (12) for Kernel1 and

834

D. Lucor, C.-H. Su, and G.E. Karniadakis

Kernel2 are computed numerically using numerical quadratures, except for the
case of Kernel2 with q being an integer. In that case, we can directly derive
exact expressions for the eigenvalues and eigenfunctions of the kernel. We only
have one double eigenvalue corresponding to two eigenfunctions:
2
2
L
; ψ (0) =
cos(kx) and ψ (1) =
sin(kx)
(22)
2
L
L
Figure 1-top shows the eigenvalues for Kernel1 (left) and for Kernel2 (right)
for diﬀerent correlation lengths A. Note that the smaller the value of A, the more
contribution is from terms associated with smaller eigenvalues.
Figure 1-bottom shows the ﬁrst seven eigenfunctions for Kernel1 (left) and
Kernel2 (right) for q = 2.5. As seen in equations (10), each eigenvalue λn is
(n)
(n)
associated with a pair of eigenfunctions ψ1 and ψ2 corresponding to a cosine
and sine contributions, respectively. Figures 2 and 3 show the 5-term and 21term KL approximations of Kernel1 and Kernel2 for q = 2.5 and the associated
errors. We notice that the kernels obtained from the KL representations tend to
the corresponding exact kernels as the number of terms n increases. For both
cases with identical mode number q, the 21-term approximation does much better
than the 5-term approximation. It is interesting to notice that the convergence is
not monotonic, and the maximum absolute error is about one order of magnitude
lower for Kernel2 than for Kernel1 for the 21-term approximation, see Figures
2-(d) and 3-(d).
λ 0 = λ1 =

Acknowledgements. This work was supported by the DDDAS program of the
National Science Foundation under the supervision of Dr. Frederica Darema.

References
1. M. Lo`eve. Probability Theory, Fourth edition. Springer-Verlag, 1977.
2. R.G. Ghanem and P. Spanos. Stochastic Finite Elements: a Spectral Approach.
Springer-Verlag, 1991.
3. H. Stark and W.J. Woods. Probability, Random Process, and Estimation Theory
for Engineers. Prentice-Hall, Inc., Englewood Cliﬀs, New Jersey, 1994.
4. P. Whittle. On stationary processes in the plane. Biometrika, 41:434–449, 1954.
5. S.P. Huang, S.T. Quek, and K.K. Phoon. Convergence study of the truncated
Karhunen-Loeve expansion for simulation of stochastic processes. Int. J. Numer.
Methods Eng., 52:1029–1043, 2001.
6. D. Lucor, C.-H. Su, and G.E. Karniadakis. Generalized polynomial chaos and
random oscillators. Int. J. Numer. Methods Eng., in press, 2004.
7. M. Shinozuka and G. Deodatis. Simulation of the stochastic process by spectral
representation. ASME Appl. Mech. Rev., 44(4):29–53, 1991.
8. M. Grigoriu. On the spectral representation method in simulation. Probabilistic
Engineering Mechanics, 8(2):75–90, 1993.
9. D. Lucor. Generalized Polynomial Chaos: Applications to Random Oscillators and
Flow-Structure Interactions. PhD thesis, Brown University, 2004.
10. C.H. Su and D. Lucor. Derivations of covariance kernels from dynamical systems
and PDEs. In ICOSAHOM-04, Brown University, Providence USA, June 21-25,
2004.

