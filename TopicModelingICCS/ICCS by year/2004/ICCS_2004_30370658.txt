Extraction of Document Descriptive Terms with
a Linguistic-Based Machine Learning Approach
Javier Fern´
andez, Elena Monta˜
n´es, Irene D´ıaz, Jos´e Ranilla, and
El´ıas F. Combarro
Artiﬁcial Intelligence Center – University of Oviedo (Spain)
ir@aic.uniovi.es

Abstract. In this paper we present a method for extracting relevant
words from a document taking into account linguistic information. Form
a set of words manually labelled as relevant or not and with the aid of a
Machine Learning algorithm, we build a classiﬁer which is able to decide
which words from a unseen document must be regarded as relevant. This
system is compared with some classical methods (based just on statistical
information).

1

Introduction and Previous Work

One of the main processes in Information Retrieval (IR) and Text Categorisation (TC) is that of transforming documents into a form suitable for automatic
processing. The most used representation consists of identifying each document
with a vector whose components measure the importance of the diﬀerent words.
This representation is known as bag of words (see [1]). It is interesting to study
methods for the removal of non-informative features. This paper explores the
use of linguistic knowledge in this process.
A widely adopted approach to feature reduction consists of ordering the
words according to a measure of their relevance and selecting those with the
highest score. For instance, one can count the total number of appearances (tf)
of each word in the corpus and then keep only the most frequent words. The
dispersion of the word in the corpus can also be considered with tfxidf deﬁned
N
by tf xidf = tf log( df
) where N is the total number of documents and df is the
number of diﬀerent documents in which the word appears. If the corpus is a set
of categorised documents the distribution of a word over the diﬀerent categories
can be considered. This is the case of information gain (IG) [2].
All these approaches have in common the use of mainly statistical information. However, including the syntactic and grammatical function of the words
and the location in which they appear, may help to successfully determine the
importance of the words in the documents. Some authors [3,4] do use some lexical
information, but usually only a quite restricted one.
This research has been supported under MCyT and Feder grant TIC2001-3579.
The author acknowledges the support of FICYT grant PR-01-GE-15.
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3037, pp. 658–661, 2004.
c Springer-Verlag Berlin Heidelberg 2004

Extraction of Document Descriptive Terms

2

659

The System and the Experiments

Our system builds a binary classiﬁer to decide whether a word can be regarded as
a descriptive term for a certain document or not. This inductive process starts
from a set of attributes of a set of words that have been previously classiﬁed
either as descriptive or not. In this work we use two Machine Learning (ML)
systems to perform this task: Arni-rules [5] and C4.5-rules [6].
Each word is represented by a set of attributes which provide linguistic information of such word in the context of each document under study. Linguistic
information is divided into POS-tagging information, representing the lexical functions that a word can play in a document (obtained with Eric Brill’s
tagger [7]); and term location, including information about the position of the
word in the document (the word appears in the title, at the beginning of the
document,...). The values of these attributes can be boolean or numerical. The
inﬂuence of word frequency (tf ) is also taken into account.
The attributes of a word in the diﬀerent documents need to be aggregated.
We have adopted two diﬀerent methods to perform this task. The ﬁrst one
consists of adding the values of the attributes. We will call tf-agg this type of
aggregation. The second one involves performing the tf-agg and then multiplying
N
). This kind of aggregation will be called tfxidf-agg.
it by log( df
The experiments have been conducted with two corpora: Reuters-21578,
which contains short news related to economy published by Reuters during 1987;
and Ohsumed.91, which covers all references from 270 medical journals of 1991.
We have used all the documents of the categories Alum and Cocoa from Reuters21578 and 60 documents of the category C06 from Ohsumed.91.

3

Results

To quantify the performance we use precision and recall. Precision (P ) is the
percentage of words classiﬁed as descriptive which really are, and recall (R) is
the percentage of descriptive terms recognized by the system. They are combined
1
by means of F1 (cf. [8]) deﬁned by F1 = 1 +
1 . The experiments are performed
2P
2R
using stratiﬁed cross validation with 10 folds and 5 repetitions.
In Tables 1, 2 and 3 we present the averaged F1 obtained in the experiments. Results both without stemming (WS) and with stemming (S) according
to Porter [9] are reported. We denote POS-tagging attributes by “L”, boolean
term location attributes by “B” and numeric term location attributes by “N”.
The general trends in the three categories and with both systems are similar.
First of all, it is clear, with few exceptions, that the use of stemming results
in an improvement. On the other hand, the tfxidf-agg shows, in general, better
results than the tf one. The combination of POS-tagging and term location
seems to improve the performance in many cases, while the inclusion of tf has
little impact (in many cases the result is exactly the same). In addition, although
the results of Cocoa, Alum and C06 follow the same trend, the F1 of the ﬁrst
two is remarkably lower, possibly due to an overﬁtting problem.

660

J. Fern´
andez et al.
Table 1. Resulting F1 (in %) in Alum
Attributes
L
L+Tf
L+B
L+B+Tf
L+N
L+N+Tf

Arni-rules
tf -agg.
tfxidf -agg.
WS
S
WS
S
40.16 42.40 43.40 44.83
40.16 45.54 43.40 47.51
34.72 41.33 35.33 39.94
34.72 42.65 35.33 40.87
39.20 42.74 40.55 38.70
39.20 43.54 40.55 40.08

C4.5-rules
tf -agg.
tfxidf -agg.
WS
S
WS
S
44.87 34.27 43.83 50.34
44.87 32.49 43.83 49.54
41.22 46.01 38.36 51.23
41.61 44.29 39.19 49.85
39.85 40.82 37.10 45.94
39.78 38.91 37.11 44.99

Table 2. Resulting F1 (in %) in Cocoa
Attributes
L
L+Tf
L+B
L+B+Tf
L+N
L+N+Tf

Arni-rules
tf -agg.
tfxidf -agg.
WS
S
WS
S
16.67 23.82 18.00 21.14
13.79 23.11 14.97 22.75
20.93 23.36 27.74 27.46
20.69 22.48 26.15 28.39
21.32 27.60 25.25 26.98
21.88 26.65 25.71 26.60

C4.5-rules
tf -agg.
tfxidf -agg.
WS
S
WS
S
13.10 15.33 24.94 19.17
13.31 16.40 24.46 16.20
26.42 27.86 30.14 28.57
26.27 19.07 28.72 27.27
11.63 23.81 22.42 22.38
12.77 17.96 21.92 19.81

The proposed method is compared with 3 measures of word relevance: tf ,
tf xidf and IG. Using them, we rank the words and calculate the resulting F1
when the words with highest values are considered as descriptive terms. The
results are presented in Table 4, where the ﬁltering level indicates the percentage
of words that are supposed to be non-informative. The ﬁltering level obtained
with our system ranges from 75% to 90% in Alum, from 90% to 98% in Cocoa
and from 70% to 88% in C06, so only the corresponding levels are presented.
If we use both POS-tagging and term location data, stemming is performed,
the aggregation is tfxidf-agg and the ML system is C4.5-rules, then the performance of the system is better than that of the traditional measures at all the comparable ﬁltering levels. Namely, we obtain F1 = 51.31% (ﬁltering level of 75.39%)
in Alum, F1 = 28.57% (ﬁltering level of 93.01%) in Cocoa and F1 = 56.97% (ﬁltering level of 77.47%) in C06. For other choices of parameters the results are
also better than those of the traditional measures for most ﬁltering levels.

4

Concluding Remarks and Future Work

We have presented a system for the extraction of informative words from a document which takes into account POS-tagging, term location and statistical information. When comparing the results obtained by traditional ﬁltering measures
with those got with a good selection of parameters in our system we ﬁnd that
our method performs better. Additionally, with this system it is not necessary
to select the ﬁltering level since it is automatically obtained.
However, some overﬁtting problems must be solved. Hence it is necessary to
study which is the most appropriate number of examples. As an extension of this

Extraction of Document Descriptive Terms

661

Table 3. Resulting F1 (in %) in C06
Attributes

L
L+Tf
L+B
L+B+Tf
L+N
L+N+Tf

tf -agg.
tfxidf -agg.
Arni-rules
WS
S
WS
S
48.57 48.05 41.97 54.35
48.81 48.91 42.31 53.99
48.57 53.46 50.10 54.57
48.57 53.60 49.99 55.01
54.08 58.32 53.60 59.30
54.60 58.73 54.16 58.76

tf -agg.
tfxidf -agg.
C4.5-rules
WS
S
WS
S
34.64 47.83 51.65 59.96
34.64 51.38 51.62 59.22
49.27 55.47 49.45 56.97
49.02 54.29 49.84 57.49
57.14 60.57 57.34 62.19
57.14 61.14 57.24 62.62

Table 4. F1 (in %) of tf , tf xidf and IG
Category Filtering Level
Alum
75%
80%
85%
90%
Cocoa
90%
95%
C06
70%
75%
80%
85%
90%

tf
41.28
39.29
35.53
33.44
22.29
21.20
40.21
45.78
39.86
32.98
25.93

tfxidf
44.04
39.29
36.68
33.44
24.80
20.60
53.12
48.19
44.90
39.63
31.89

IG
32.99
32.65
32.66
28.20
19.10
16.00
33.80
30.45
27.85
24.20
18.78

work, we are also interested in studying the impact of considering syntactical
information of the words. We would also like to check whether extracting words
with the system proposed improves the overall performance of TC.

References
1. Salton, G., McGill, M.J.: An introduction to modern information retrieval. McGrawHill (1983)
2. Yang, T., Pedersen, J.P.: A comparative study on feature selection in text categorisation. In: Proceedings of ICML’97, 14th International Conference on Machine
Learning. (1997) 412–420
3. Barker, K., Cornacchia, N.: Using noun phrase heads to extract document
keyphrases. Lecture Notes in Computer Science 1822 (2000) 40–52
4. Turney, P.D.: Learning algorithms for keyphrase extraction. Information Retrieval
2 (2000) 303–336
5. Ranilla, J., Bahamonde, A.: Fan: Finding accurate inductions. International Journal
of Human Computer Studies 56 (2002) 445–474
6. Quinlan, J.R.: Constructing decision tree in c4.5. In: Programs of Machine Learning.
Morgan Kaufman (1993) 17–26
7. Brill, E.: A Corpus-Based Approach to Language Learning. PhD thesis, Philadelpha,
PA (1993)
8. Sebastiani, F.: Machine learning in automated text categorisation. ACM Computing
Survey 34 (2002)
9. Porter, M.F.: An algorithm for suﬃx stripping. Program (Automated Library and
Information Systems) 14 (1980) 130–137

