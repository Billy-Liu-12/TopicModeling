A Note on Data-Driven Contaminant Simulation
Craig C. Douglas1,2 , Chad E. Shannon1 , Yalchin Efendiev3 , Richard Ewing3 ,
Victor Ginting3 , Raytcho Lazarov3 , Martin J. Cole4 , Greg Jones4 ,
Chris R. Johnson4 , and Jennifer Simpson4
1

4

University of Kentucky, Department of Computer Science, 325 McVey Hall,
Lexington, KY 40506-0045, USA
{craig.douglas,ceshan0}@uky.edu
2
Yale University, Department of Computer Science, P.O. Box 208285
New Haven, CT 06520-8285, USA
douglas-craig@cs.yale.edu
3
Texas A&M University, ISC, College Station, TX, USA
{efendiev,ginting,lazarov}@math.tamu.edu, richard-ewing@tamu.edu
Scientiﬁc Computing and Imaging Institute, University of Utah, Salt Lake City,
UT, USA
{gjones,mjc}@sci.utah.edu{crj,simpson}@cs.utah.edu

Abstract. In this paper we introduce a numerical procedure for performing dynamic data driven simulations (DDDAS). The main ingredient of our simulation is the multiscale interpolation technique that maps
the sensor data into the solution space. We test our method on various
synthetic examples. In particular we show that frequent updating of the
sensor data in the simulations can signiﬁcantly improve the prediction
results and thus important for applications. The frequency of sensor data
updating in the simulations is related to streaming capabilities and addressed within DDDAS framework. A further extension of our approach
using local inversion is also discussed.

1

Introduction

Dynamic data driven simulations are important for many practical applications.
Consider an extreme example of a disaster scenario in which a major waste
spill occurs in a subsurface near a clean water aquifer. Sensors can now be used
to measure where the contamination is, where the contaminant is going to go,
and to monitor the environmental impact of the spill. One of the objectives
of dynamic data driven simulations is to incorporate the sensor data into the
real time simulations. Many important issues are involved in DDDAS for this
application (see [1,2]).
Subsurface formations typically exhibit heterogeneities over a wide range of
length scales while the sensors are usually located at sparse locations and sparse
data from these discrete points in a domain is broadcasted. Since the sensor data
usually contains noise it can be imposed either as a hard or a soft constraint.
To incorporate the sensor data into the simulations, we introduce a multiscale
interpolation operator. This is done in the context of general nonlinear parabolic
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3038, pp. 701–708, 2004.
c Springer-Verlag Berlin Heidelberg 2004

702

C.C. Douglas et al.

operators that include many subsurface processes. The main idea of this interpolation is that we do not alter the heterogeneities of the random ﬁeld that drives
the contaminant. Instead, based on the sensor data, we rescale the solution in
a manner that it preserves the heterogeneities. The main idea of this rescaling
is the use of local problems. This interpolation technique ﬁts nicely with a new
multiscale framework for solving nonlinear partial diﬀerential equations. The
combination of the interpolation and multiscale frameworks provides a robust
and fast simulation technique that is employed in the present paper.
We have tested our method on some synthetic examples by considering both
linear and nonlinear cases. We compare the numerical results for simulations
that employ both updating the data at sensor location and the simulations that
do not update the locations. Our numerical studies bear out that simulations
that do not use the update or use it very infrequently produces large errors.
Finally, we discuss the extension of the approach that uses some inversion of the
local data.
In a real ﬁeld, the sensors are typically in wells at diﬀerent depths. A nice,
tensor product mesh does not ﬁt the reality of sensor locations. We are forced to
work with unstructured, quite coarse grids if we want the sensors to be nodes on
a mesh. The sensor data comes in the form of telemetry. The sensors can provide
information at speciﬁed times, when speciﬁc conditions occur, be polled, or any
number of combinations. We have developed a virtual telemetry package that is
now part of SCIRun [1,2,3,4] so that we can simulate a ﬁeld while computing
remotely, as is typical in a real ﬁeld simulation.

2

Data Driven Simulations

In this section we discuss the mapping of the sensor data to the ﬁnite dimensional
space where the solution is calculated. This procedure is nontrivial in general
since the solution space usually has high dimension while the sensors are located
only at few locations. To demonstrate this in Fig. 1 we schematically plot a gray
scale image of a 121 × 121 heterogeneous ﬁeld with exponential variogram and
the correlation lengths lx = 0.2 and lx = 0.01. Sensors in Fig. 1 are marked by an
X. Due to uncertainties in the data, the random ﬁelds used for the simulations
and the true ﬁeld can diﬀer signiﬁcantly. Thus, we must be able to reconcile the
streamed data from the sensors with that produced by our simulations.
Our simpliﬁed approach presented in this paper consists of passing the sensor
data to the simulations and its use for the next time step simulations. Since the
sensor data represents the solution only at few coarse locations we have to modify
the solution conditioned to this data. We call this step multiscale interpolation.
It consists of mapping the sensor data to the solution space. Before discussing
the mapping, we demonstrate the main idea of our general approach handling
dynamic data. It is depicted in Fig. 2 and consists of the following: At each time
step the sensor data is received by the simulator. We can treat the data either
as a hard or soft constraint. The latter means the data contains some noise and
need not be imposed exactly.

A Note on Data-Driven Contaminant Simulation

703

4

3

2

1

0

−1

−2

−3

Fig. 1. Permeability ﬁeld with spherical variogram and correlation lengths lx = 0.2,
lz = 0.02. The locations of the sensors are marked.

ti

t i+1
C(ti+1|Mi+1)

...

C(t i| M i )

UPDATE

...

C(t i+1|M i)
Propogate
time
Fig. 2. Schematic description of data driven simulations. C(ti |Mi ) designates the quantity of interest, such as the concentration, at time ti , conditioned to some data Mi .
In our basic methodology we consider Mi to be the sensor data. In the extension of
our basic method the local heterogeneous ﬁeld is also updated at each time based on
sensor readings.

Consider the hard constraint case. At the beginning of each time step the
sensor data needs to be mapped to the discrete solution space. This is performed
using our DDDAS mapping operator, whose main goal is not to alter the heterogeneous ﬁeld, i.e., at each time we update the data while not seeking the error
source.
The proposed mapping for the sensor data is very general and applicable to
various classes of equations. We consider general nonlinear parabolic equations
of the form
Dt u = div(a (x, t, u , Dx u )) + a0, (x, t, u , Dx u ), in Q0 × [0, T ],

(1)

704

C.C. Douglas et al.

where Q0 refers to the spatial domain and indicates the presence of small scale
heterogeneities. Equation (1) includes various physical processes that occur in
subsurfaces.
Assume the domain is divided into a coarse grid such that the sensor points
are nodal points of the coarse grid. Note that we do not require all nodal points to
be sensor locations. Further denote by S h the space of piecewise linear functions
on this partition,
Sh = {vh ∈ C 0 (Q0 ) : the restriction vh is linear for each triangle K ∈ Πh }.
Note that the K’s are the coarse elements.
Our objective now is to map the function deﬁned on S h to the ﬁne grid
that represents the heterogeneities. This grid is obtained from a priori information about the ﬁeld using geostatistical packages. Denote by the operator E the
mapping from the coarse dimensional space into the ﬁne dimensional space:
E : Sh → V h,
which is constructed as follows: For each element in uh ∈ S h at a given time tn
we construct a space-time function u ,h (x, t) in K × [tn , tn+1 ] that satisﬁes
Dt u

,h (x, t)

= div(a (x, t, η, Dx u

,h ))

(2)

in each coarse element K, where η is the average of uh . u ,h (x, t) and is calculated
by solving (2) on the ﬁne grid, and thus is a ﬁne scale function.
To complete the construction of E we need to set boundary and initial conditions for (2). We can set diﬀerent boundary and initial conditions, giving rise
to diﬀerent maps that only diﬀer from each other slightly. The main underlying
property of our map is that it is constructed as a solution of local problems. The
latter guarantees that the solution is consistent with prescribed heterogeneities.
In our numerical simulations we take the boundary and initial condition for
the local problems to be linear with prescribed nodal values. The nodal values
are obtained from the sensor data, if available. If the sensor data is unavailable at
some location we use the values obtained from the simulations at previous time.
Note that we cannot impose the values of the solutions directly at some locations
since it can cause artiﬁcial discontinuities in the solution. See [5] for mathematical aspects of this interpolation operator, including convergence properties.
Once the solution at time t = tn is computed its values with sensor data at
the sensor locations can be compared. After changing the values of the solution
we interpolate it to the ﬁne grid and use it for the next time step. At the last step
we use a multiscale approach which is computationally eﬃcient. In particular,
the solution at the next time step is calculated based on

Q0

tn+1

(uh (x, tn+1 ) − uh (x, tn ))vh dx +
K

tn

K

((a (x, t, η, Dx u

,h ), Dx vh )

+

tn+1

a0, (x, t, η, Dx u

,h )vh )dxdt

=
tn

Q0

f vh dxdt.
(3)

A Note on Data-Driven Contaminant Simulation

705

Recall that Q0 refers to the spatial domain and the K’s are the coarse elements.
This approach, combined with the interpolation technique, has great CPU advantages over just a ﬁne scale calculations (see [5]).

3

Numerical Examples

We now present numerical results that demonstrate the accuracy and limitations
of our proposed method. We have explored both linear and nonlinear heterogeneous diﬀusion cases. Due to space limitations here, we only provide a representative example. We will provide more examples and discussions in a future work.
The systems we consider are intended to represent cross sections (in the x-z
plane) of the subsurface. For that reason we take the system length in x (Lx ) to
be ﬁve times the length in z (Lz ). All of the ﬁne grid ﬁelds used in this study are
121 × 121 realizations of prescribed overall variance (σ 2 ) and correlation structure. The ﬁelds were generated using GSLIB algorithms [6] with an exponential
covariance model. In the examples below, we specify the dimensionless correlation lengths lx and lz , where each correlation length is nondimensionalized by
the system length in the corresponding direction. For example, lx = 0.3 means
that the actual correlation length of the permeability ﬁeld is 0.3Lx .
In our calculations, we consider (1) with a ﬁxed concentration at the inlet
edge of the model (x = 0) and a ﬁxed concentration at the outlet edge (x = Lx )
of the model. The top and bottom boundaries are closed to ﬂow. Initially zero
contaminant concentration is assumed in the domain. For comparison purposes
most results are presented in terms of cross sectional averages and l2 norm errors.
The computations are carried out until the ﬁnal time t = 0.1 with a diﬀerent
frequency of updating.
We have tested both linear and nonlinear problems and observed similar
numerical results. Here we will only present numerical results for the nonlinear
case which represents simpliﬁed Richards’ equation. Consider
Dt u = div(a (x, u )Dx u ),
where a (x, η) = k (x)/(1 + η)α (x) . k (x) = exp(β (x)) is chosen such that β (x)
is a realization of a random ﬁeld with the exponential variogram and with some
correlation structure. α (x) is chosen such that α (x) = k (x) + const with the
spatial average of 2. For the numerical examples we will only specify β (x).
In all of the ﬁgures, solid line designates the true solution, dotted line designates the solution obtained using our simulations with some number of updates,
and the dashed line designates the solution that has not been updated.
For the ﬁrst example we consider the true ﬁeld to be a random ﬁeld with exponential variogram and with lx = 0.2, lx = 0.02, and σ = 1. For our simulations
we use the same ﬁeld with σ = 2. In Fig. 3 we compare the average solutions for
the case with 20 updating, i.e., the simulated solution is updated 20 times during the course of the simulations. Fig. 3 demonstrates that the predictions that
do not use the sensor data perform very poorly. The l2 -norm of the diﬀerence

706

C.C. Douglas et al.
1

0.46
fine solution
updated
non−updated

0.9

fine solution
updated
non−updated

0.44

0.8
0.42
averaged solution

averaged solution

0.7
0.6
0.5
0.4
0.3

0.4

0.38

0.36

0.2
0.34
0.1
0
0

1

2

3

4

0.32
0

5

0.2

0.4

x

0.6

0.8

1

z

Fig. 3. Comparisons of the average solutions across x and z directions for nonlinear
case. The true ﬁeld is a realization of a random ﬁeld with lx = 0.2, lz = 0.01, σ = 1,
while the random ﬁeld used for the simulations has σ = 2.
1

0.46
fine solution
updated
non−updated

0.9

fine solution
updated
non−updated

0.44

0.8
0.42
averaged solution

averaged solution

0.7
0.6
0.5
0.4
0.3

0.4

0.38

0.36

0.2
0.34
0.1
0
0

1

2

3
x

4

5

0.32
0

0.2

0.4

0.6

0.8

1

z

Fig. 4. Comparisons of the average solutions across x and z directions for nonlinear
case. The true ﬁeld is a realization of a random ﬁeld with lx = 0.2, lz = 0.01, σ = 1,
while random ﬁeld used for the simulations has σ = 2.

between the solutions for the data that are frequently updated is 2.5% while the
data that is not updated is 14%.
In our next example we ran the same case with less frequent updating. In
particular, we use 4 updates during the simulations. The results are depicted in
Fig. 4. The l2 -errors of the solution that is updated is 5.7% while the l2 error of
the non-updated solution is still 14%.
Finally we have considered a case where three diﬀerent heterogeneous ﬁelds
with exponential variograms are used with diﬀerent probabilities. In particular
the true ﬁeld consists of lx = 0.1, lz = 0.02 with probability 0.1, lx = 0.2,
lz = 0.02 with probability 0.8, lx = 0.4, lz = 0.02 with probability 0.1. For
all these ﬁelds we take σ = 1. For our simulations we use these random ﬁelds
with σ = 2 and with diﬀerent probabilities. In particular, we take the ﬁeld with

A Note on Data-Driven Contaminant Simulation

707

lx = 0.1, lz = 0.02 with probability 0.3, lx = 0.2, lz = 0.02 with probability
0.4, lx = 0.4, lz = 0.02 with probability 0.3. This is a typical ﬁeld scenario
when one does not know the probability distributions of the random ﬁelds. Our
numerical results showed that the l2 error between true and updated solution is
5%, while the error between the true solution and non-updated solution is 9%.
The numerical results with frequent updates demonstrated higher accuracy.

4

Fixing Error Sources Using Inversion

So far we have presented a numerical method that incorporates the sensor data
from sparse locations into the simulations. Currently we are working on the
possible extension of the methodology that involves some kind of inversion during
the simulations.
In the methodology described previously we only correct the solution without
ﬁxing the error source. One of the error sources is the incorrect heterogeneous
diﬀusion ﬁeld.
Consider the linear heterogeneous diﬀusion model Dt u = div(a (x)Dx u ).
Our objective is to compare the misﬁt of the data from the sensors and the data
from our simulator. If this misﬁt is larger than a certain threshold for some sensor points we perform an inversion in the neighborhood of the sensor point by
modifying the diﬀusion ﬁeld a (x) in the neighborhood of the sensor point. By
considering the neighborhood of the sensor location as a coarse block we determine the eﬀective diﬀusivity, a∗sim , corresponding to the existing heterogeneous
diﬀusivity ﬁeld. This quantity is determined such that the local problem with a
single diﬀusion coeﬃcient, a∗sim , will give the same response as the underlying
ﬁne heterogeneous diﬀusion ﬁeld.
Our next goal is to ﬁnd an a∗true that will give us the same response as the
one from the sensor data. This is done using some classical inversion, such as
parameter estimation. Since we only have to ﬁt one parameter this problem can
be easily handled without extensive computations.
Now we can impose a∗true both as a soft as well as a hard constraint. For the
hard constraint we must rescale the local heterogeneous ﬁeld based on the ratio
a∗sim /a∗true . Note that the hard constraint does not change the structure of the
local heterogeneities and can be easily implemented since it only requires local
rescaling.
For the soft constraint we use Bayesian framework (see [7]). Assume the a
priori distribution for the local coarse heterogeneous ﬁeld is given. Our objective
is to generate ﬁne-scale random diﬀusivity ﬁelds conditioned on the coarse-scale
data. Denote ac and af to be coarse and ﬁne scale diﬀusivity ﬁelds respectively.
Using Bayes theorem we obtain
P (af |ac ) ∝ P (af )P (ac |af ),

(4)

where P (af ) is the probability distribution for the ﬁne-scale ﬁeld. In (4) P (af )
is a priori distribution of the ﬁne-scale ﬁeld which is prescribed.

708

C.C. Douglas et al.

To impose the coarse-scale data as a soft constraint we take ac = J(af ) + ,
where J is a local upscaling operator and is a random noise, ∼ N (0, σ 2 ).
The local upscaling operator involves the solution of the local partial diﬀerential equations similar to (2). A soft constraint assumes that the coarse scale
information is not accurate. Note that letting σ → 0 we get a hard constraint.
The realizations from the posterior distribution (4) is generated using Markov
Chain Monte Carlo (MCMC) [8]. This approach is known to be very general and
can handle complex posterior distributions. The main idea of MCMC is to use
a Markov Chain with a speciﬁed stationary distribution. The random drawing
from the target distribution can be accomplished by a sequence of draws from
full conditional distribution. Since the full conditionals have non-explicit form
involving local problems Metropolis-Hastings algorithm is used.
We have tested our methodology with both soft and hard constraint on simple
examples using Markov Random Fields as prior distributions for ﬁne scale ﬁelds.
Our numerical results indicated very good correspondence between the true and
simulated diﬀusion ﬁelds on the coarse level. Further research into this area is
warranted.

References
1. Douglas, C.C., Efendiev, Y., Ewing, R., Lazarov, R., Cole, M.R., Johnson, C.R.,
Jones, G.: Virtual telemetry middleware for DDDAS. Computational Sciences ICCS 2003, P. M. A. Sllot, D. Abramson, J. J. Dongarra, A. Y. Zomaya, and Yu.
E. Gorbachev (eds.) 4 (2003) 279–288
2. Douglas, C.C., Shannon, C.E., Efendiev, Y., Ewing, R., Lazarov, R., Cole, M.R.,
Johnson, C.R., Jones, G., Simpson, J.: Virtual telemetry middleware for DDDAS. In
Darema, F., ed.: Dynamic Data-Driven Application Systems. Kluwer, Amsterdam
(2004)
3. Johnson, C., Parker, S.: The scirun parallel scientiﬁc computing problem solving
environment. In: Ninth SIAM Conference on Parallel Processing forScientiﬁc Computing, Philadelphia, SIAM (1999)
4. SCIRun: A Scientiﬁc Computing Problem Solving Environment. Scientiﬁc Computing and Imaging Institute (SCI), http://software.sci.utah.edu/scirun.html, 2002.
5. Efendiev, Y., Pankov, A.: Numerical homogenization of nonlinear random parabolic
operators. SIAM Multiscale Modeling and Simulation (to appear) Available at
http://www.math.tamu.edu/∼yalchin.efendiev/ep-num-hom-parab.ps.
6. Deutsch, C.V., Journel, A.G.: GSLIB: Geostatistical software library and user’s
guide, 2nd edition. Oxford University Press, New York (1998)
7. Lee, S.H., Malallah, A., Datta-Gupta, A., Higdon, D.: Multiscale data integration
using markov random ﬁelds. SPE Reservoir Evaluation and Engineering (2002)
8. Gilks, W., Richardson, S., Spegelhalter, D.: Markov Cain Monte Carlo in Practice.
Chapman and Hall/CRC, London (1996)

