Edge Preserving Filters on Color Images
Vinh Hong1 , Henryk Palus2 , and Dietrich Paulus1
1
2

Institut f¨
ur Computervisualistik, Universit¨
at Koblenz-Landau, Universit¨
atsstr. 1,
56070 KOBLENZ – Germany, {hong,paulus}@uni-koblenz.de
Institute of Automatic Control, Silesian University of Technology, Akademicka 16,
44-100 GLIWICE – Poland, hpalus@polsl.gliwice.pl

Abstract. In this contribution we present experiments on color image
enhancement for several diﬀerent non-linear ﬁlters which originally were
deﬁned for gray-level images. We disturb sample images by diﬀerent
types of noise and measure performance of the ﬁlters. We provide
signal-to-noise measurements as well as perceived color diﬀerence in ∆E
as deﬁned by the CIE. All images and test programs are provided online
on the internet so that experiments can be validated by arbitrary users
on any image data.
Keywords: color image enhancement, edge-preserving ﬁlters, ∆E, performance measures.

1

Introduction

Color images as processed in various applications are recorded by diﬀerent acquisition devices. Cameras as well as scanners have their speciﬁc noise characteristics. Image transmission may as well introduce noise into the image data.
Typical models for noise are either Gaussian or salt-and-pepper noise; Gaussian
noise is used as a model for sensor errors, drop-outs during transmission and
errors on the CCD chip can be modelled by salt-and-pepper noise.
In our contribution we use images from a data base [3] and disturb them by artiﬁcial noise of varying degree and type. In Sect. 2.1 we describe some non-linear
smoothing ﬁlters, such as edge preserving smoothing algorithm [8], and extend
them to color images where they were deﬁned for gray-level images originally.
We apply these ﬁlters to the disturbed input images and compare each result
with its corresponding original image to compute diﬀerence measures. Standard
measures are the signal-to-noise ratio (SNR) and maximum diﬀerences for color
vectors. As all disturbances are modelled in RGB, we compute these measures in
RGB as well. More important for human perception than SNR is the so-called
∆E diﬀerence [12] which describes the perceived color diﬀerence (Sect. 3). In
Sect. 4 we conclude our contribution with a summary of the evaluation and the
prospective work.

M. Bubak et al. (Eds.): ICCS 2004, LNCS 3039, pp. 34–40, 2004.
c Springer-Verlag Berlin Heidelberg 2004

Edge Preserving Filters on Color Images

2

35

Color Image Processing

Color image processing has become a central part of automatic image analysis
as color can provide valuable cues for identiﬁcation and localization of objects
[11].
2.1

Color Filters

In research and literature there exist several ﬁlters that can be classiﬁed into
linear and non-linear ﬁlters. Filters can either operate in the spatial or in the
frequency domain [5]. In the following we compare non-linear ﬁlters in the spatial
domain and additionally use an AMF (arithmetic mean ﬁlter).
Linear Filters. A huge number of ﬁlters for single band images has been proposed in the long history of image processing. As color images became aﬀordable
with respect to sensors, memory and processor speed, some of these ﬁlters have
been extended to color.
If a linear ﬁlter, such as a Gaussian or mean ﬁlter, is applied to each channel of
an RGB image separately, the resulting image will contain usually color triplets
which are not present in the input image. Such artifacts yield perceptional diﬀerences which can be avoided by non-linear ﬁltering. On the other hand, additive
noise, such as additive Gaussian noise, can be removed by a low-pass ﬁlter which
averages color vectors.
Non-linear Filters. Filters which are quoted to smooth homogeneous areas
while preserving edges are the
–
–
–
–

EPS (Edge preserving smoothing), presented for gray-level images in [8],
SNN (Symmetric Nearest Neighbour Filter) described in [9,6],
K-N (Kuwahara-Nagao Filter) proposed in [7,8] for gray-level images,
VMF (Vector Median Filter, also known as CVF (Color Vector Median)),
presented in [10,1].

EPS Filter. In the so-called edge preserving smoothing algorithm introduced in
[8], the selection of gray-level pixels for averaging is done based on statistical
principles. The algorithm uses nine diﬀerent 5 × 5 masks for each pixel; three of
them are shown in Fig. 1. The pixels marked in the neighborhood are used for
the following computations. The symmetrical use of 1 (a) and (b) results in eight
diﬀerent masks. Each of these masks includes seven points for the calculation of
the new gray-level. The contrast mask (c) includes nine elements for the following
computations. For each mask we compute the variance. The mask with the lowest
variance is selected. The central pixel gets the mean value of all points marked
in this mask.
To extend this algorithm to color, we compute the color covariance matrix
inside each mask. We decide for that mask for which the Frobenius norm of
the covariance matrix is minimal and compute the mean color vector for the
resulting pixel. This may, of course, introduce artifacts.

36

V. Hong, H. Palus, and D. Paulus

(a)

(b)

(c)

Fig. 1. Masks for edge preserving smoothing

SNN Filter. The SNN is a ﬁlter related to the mean and median ﬁlters but
with better edge-preserving properties. The neighbours of the central pixel in a
window are considered as four pairs of symmetric pixels (N-S, W-E, NW-SE and
NE-SW). For each pair the pixel closest in color to the central pixel is selected.
The colors of these four selected pixels are averaged and the mean color value is
a new color for central pixel. The mask for the SNN ﬁlter is shown in Fig. 2.

NW

N

R2

R3

R4

E

W
SW

R1

NE

S

SE

Fig. 2. Mask for SNN ﬁlter

Fig. 3. Mask for Kuwahara-Nagao ﬁlter

K-N Filter. The 3 × 3 mask shown in Fig. 3 is split into four 2 × 2 slightly
overlapping windows with the mask’s central pixel as a common part. For each
window in a gray-level image, the variance is calculated. The mean value of the
window with minimal variance (maximal homogeneous region) is used as the
output value of the central pixel.
As in the case of the edge-preserving smoothing, we extend this ﬁlter to color
as we compute the color covariance matrix and use the Frobenius norm.
Recently the gray-level version of K-N ﬁlter has been generalized for round
windows [2] and it has been shown that the ﬁlter is composition of linear diﬀusion
and morphological sharpening [14].
Vector Median Filter. The deﬁnition of the vector median of a set of color vectors
fi in a window W is given in [10] as
fv = argminfi ∈W

||fi − fj || .
fj ∈W

(1)

Edge Preserving Filters on Color Images

37

In our experiments we use f1 , . . . , f9 in a square 3 × 3 window and apply the
Euclidean norm on the diﬀerence color vector in (1). As this ﬁlter does not
include averaging, it is the only ﬁlter described here which does not introduce
color artifacts.

3

Experiments

Signal-to-noise ratio A measure for the accuracy of a ﬁlter is given by the signalto-noise ratio (SNR). For color images pairs we deﬁne the SNR by a quotient of
means:

SNR = 10 log10

E[fi T fi ]
E[ni T ni ]

,

(2)

where fi is the color vector and ni is the noise vector computed by the vector
diﬀerence of the two pixels.
Color Metric To measure perceptual color distances between two color stimuli
several metrics such in color spaces such as CIELUV, CIELAB, CIE94, etc. can
be used [13,15]. In this paper we will prefer the CIE-recommended color metric
CIE94 (see equation (6) below). That is a modiﬁcation of the CIELAB color
diﬀerence formula (3):
∆E∗ab =

(∆L∗ab )2 + (∆a∗ab )2 + (∆b∗ab )2

.

(3)

A value of ∆E∗ab = 1 resp. ∆E∗CH = 1 corresponds to the human’s eye minimal
perceivable diﬀerence between two colors. The greater the color diﬀerence between two stimuli is, the greater is its ∆E∗ value [4]. The CIELAB color metric
from the CIE (International Commission on Illumination) describes the color
diﬀerence between two color points in the uniform L∗ a∗ b∗ space. The axes of
this color space compound of the lightness-axis L∗ , the red-green-axis a∗ and
the yellow-blue-axis b∗ [13]. In this color space the Euclidean distance between
two points corresponds to perceived diﬀerence[16]. The symbols ∆L∗ab , ∆a∗ab and
∆b∗ab represent the componentwise diﬀerences (lightness, the red-green and the
yellow-blue) between the two colors.
The color diﬀerence (3): has several drawbacks in practice [16]. So the CIE
introduced an improved color metric called CIE94 which computes the weighted
Euclidian distance between two points in the uniform L∗ C∗ H∗ space. This color
space uses the polar coordinates chroma C∗ and hue H∗ rather than the cartesian
coordinates a∗ and b∗ of the L∗ a∗ b∗ space. In comparison to the L∗ a∗ b∗ space
the L∗ C∗ H∗ space is a more intuitive representation of color, because for example
hue can be uniquely computed [16]. Chroma can be computed by
C∗ab =

(a∗ )2 + (b∗ )2

,

(4)

and hue can be caculated from
H∗ab = arctan

b∗
a∗

.

(5)

38

V. Hong, H. Palus, and D. Paulus

CIE94 computes the color diﬀerence between two colors in the L∗ C∗ H∗ space
by
∆E∗CH =

∆L∗ab
kL SL

2

+

∆C∗ab
kC SC

2

+

∆H∗ab
kH SH

2

.

(6)

The symbols ∆L∗ab , ∆C∗ab and ∆H∗ab represent the diﬀerences between the two
given colors corresponding to those lightness, chroma and hue attributes. SL , SC
and SH represent parameters calculated from the chroma coordinates of the two
color stimuli. kL , kS and kH are parameters those take speciﬁc experimental
conditions into account[16]
We use the following parameter conﬁguration [16]:
kL = kS = kH = SL = 1
SC = 1 + 0.045µC∗ab
SH = 1 + 0.015µC∗ab

(7)
(8)
(9)

The values SC and SH are computed from the mean chroma value µC∗ab of
the two given color stimuli.
Noise model An ideal color image f consisting of color vectors fi is disturbed
by additive noise βi and multiplicative noise γi
gi = γi · fi + βi

(10)

to yield the observed image g. We added zero-mean Gaussian noise β with varying σ to images in a test data base where the noise was statistically independent
for the color channels. In another experiment we introduced impulsive noise
which can be considered as a multiplicative noise γ with γi = 0 for drop-outs,
γi = 1 for undisturbed image information, and γi = 255 to introduce white
spots; with a given probability p white and black spots are created, each with
probability 0.5. All test images can be found in a public image data base.1 For
each corrupted image we applied the ﬁlters described in Sect. 2.1. An example
is shown in Fig. 4.
We then compared original and ﬁltered image and computed SNR and mean
∆E∗CH . Of course, if little noise is added to the image, the values for ﬁltered
images are worse than for the unﬁltered noisy image, as can be seen from Fig. 5
and Fig. 6. The higher the corruption is, the higher the improvement can be by
ﬁltering.

4

Conclusion. Prospective Work

The vector median ﬁlter outperforms the other ﬁlter methods for impulsive noise,
if we use ∆E∗CH as a measure. This is as expected, as a measure for perceived
color diﬀerences should be sensitive to color artifacts. The vector median ﬁlter
1

http://www.uni-koblenz.de/˜puma

Edge Preserving Filters on Color Images

39

Fig. 4. Example image “peppers” (left), corrupted image (center), ﬁltered image
(right)

30

20

un-ﬁltered image
EPS
K-N
VMF
SNN
AMF

25
20

15

SNR

∆E∗CH

30

un-ﬁltered image
EPS
K-N
VMF
SNN
AMF

25

15

10

10

5

5

0

0
0

0.05

0.1

0.15
p

0.2

0.25

0.3

0

0.05

0.1

0.15

0.2

0.25

0.3

p

Fig. 5. Example image “peppers” corrupted by impulsive noise

also outperforms the other ﬁlters in the case of the SNR-measure, if the SNR of
the input image is low.
Naturally, linear ﬁltering reduces Gaussian noise better than rank-order ﬁlters. The Arithmetic Mean ﬁlter returns the best ∆E∗CH for Gaussian noise. In
general, the Vector Median ﬁlter outperforms the other ﬁlters for both distance
measures.
Both measures SNR and ∆E∗CH are consistent for extreme cases, i.e. very
little or very large noise as they mostly have the same ordering for a qualitative
judgement of the ﬁlters. Details in the medium range noise reveal diﬀerences of

Fig. 6. Example image “peppers” corrupted by additive Gaussian noise

40

V. Hong, H. Palus, and D. Paulus

the measurements. For example, the arithmetic mean ﬁlter is judged diﬀerently
for impulsive noise as it yields similar SNR but considerably diﬀerent ∆E∗CH .
As a conclusion we realize that better looking images (as quantitatively
judged by ∆E∗CH ) will not always be best suited for further processing, as they
may contain less information (as quantitatively judged by SNR) than images
appearing worse visually.

References
1. Jaakko Astola, Pekka Haavisto, and Yrjo Neuvo. Vector median ﬁlters. Proceedings
of the IEEE, 78:678–689, 1990.
2. Peter Bakker, L.J. van Fliet, and Piet W. Verbeek. Edge preserving orientation
adaptive ﬁltering. In Proc. 5th Annual Conference of the Advanced School for
Computing and Imaging, pages 207–213, 1999.
3. Serge Chastel, Guido Schwab, and Dietrich Paulus. Web interface for image processing algorithms. In Simone Santini and Raimundo Schettini, editors, Internet
Imaging V San Jose, 1 2004. Proc. of SPIE. volume 5304.
4. Rolf Gierling. Farbmanagement. Moderne Industrie Buch AG & Co. KG, Bonn
2001.
5. Rafael C. Gonzalez and Richard E. Woods. Digital Image Processing. Prentice
Hall, second edition, 2001.
6. David Harwood, Murali Subbarao, H. Hakalahti, and L. Davis. A new class of
edge-preserving smoothing ﬁlters. Pattern Recognition Letters, 5:155–162, 1987.
7. M. Kuwahara, K. Hachimura, S. Eiho, and M. Kinoshita. Digital Processing of
Biomedical Images, chapter Processing of ri-angiocardiographic images, pages 187–
202. Plenum Press, New York, USA, 1976.
8. M. Nagao and T. Matsuyama. Edge preserving smoothing. Computer Graphics
and Image Processing, 9:394–407, 1979.
9. M. Pietikainen and David Harwood. Advances in Image Processing and Pattern
Recognition, chapter Segmentation of color images using edge-preserving, pages
94–99. North Holland, Amsterdam, Netherlands, 1986.
10. Konstantinos N. Plataniotis and Anastasios N. Venetsanopoulos. Color Image Processing and Applications. Springer Verlag, 2000.
11. Volker Rehrmann, editor. Erster Workshop Farbbildverarbeitung, Universit¨
at
Koblenz–Landau, 1995.
12. Manfred Richter. Einf¨
uhrung in die Farbmetrik. Walter de Gruyter, Berlin, New
York, 2 edition, 1981.
13. Stephen J. Sangwine and R. E. N. Horne. The Colour Image Processing Handbook.
Chapman Hall, London 1998.
14. Rein van den Boomgaard. Decomposition of the Kuwahara-Nagao operator in
terms of linear smoothing and morphological sharpening. In Proc. of the 6th International Symposium on Mathematical Morphology, pages 283–292, 2002.
15. G¨
unter Wyszecki and W. S. Stiles. Color Science: Concepts and Methods, Quantitative Data and Formulas. John Wiley & Sons, second edition, 1982.
16. Xuemei Zhang and Brian A. Wandell. Color image ﬁdelity metrics evaluated using
image distortion maps. Signal Processing, 70(3):201–214, 11 1998.

