Function Fitting Two–Step BDF Algorithms for
ODEs
Liviu G. Ixaru1 and Beatrice Paternoster2
1

2

Institute of Physics and Nuclear Engineering, Bucharest, Romania
Dipartimento di Matematica e Informatica, Universit´
a di Salerno, Italy

Abstract. We investigate the problem of how big would be the additional accuracy gain from a two-step bdf algorithm for ordinary diﬀerential
equations if its weights are constructed via function ﬁtting. We ﬁnd that
(i) the order of the algorithm is increased by three units (from two to
ﬁve), (ii) this enhancement can be achieved not only in the frame of
the traditional exponential ﬁtting but also in the frame of a new, more
general approach, which results more ﬂexible and safer than the other
one.

1

Introduction

It is well known that the quality of a multistep algorithm to solve ﬁrst order
ODEs depends on the set of reference functions chosen for the determination
of the algorithm weights. The classical form of these algorithms is constructed
in terms of power functions but other functions may be used as well, such as
exponential functions or mixtures of power and exponential functions, see e.g.
[3], [1], [8], [11], and the references therein.
The old problem of how the frequencies of the exponential functions should
be tuned in order to obtain a maximal gain in accuracy received a pertinent
answer only recently, [6]. (According to the usual terminology in the ﬁeld, the
frequency is the parameter λ in the function exp(λx).) In this paper our main
interest consists in searching for alternatives to the exponential ﬁtting. Multistep
algorithms based on other functions than the power and/or exponential functions
were published before, mainly in connection with the Schr¨
odinger equation (see
[2] for functions of the form xl+k , l > 0, k = 1, 2, . . . (i.e. an ad hoc subset
of power functions) or [7,9,10] for the Bessel and Neumann functions). Now we
choose these functions in terms of the behaviour of the derivatives of the solution,
implementing the function ﬁtting technique to derive a ﬁfth order version of the
method.

2

Preliminaries

Let X be some point on the real axis and [X − h, X + h] an interval around it,
[X − h, X + h]. We consider the third order linear and homogeneous diﬀerential
equation, where αm (x), m = 0, 1, 2, are low degree polynomials:
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3039, pp. 443–450, 2004.
c Springer-Verlag Berlin Heidelberg 2004

444

L.G. Ixaru and B. Paternoster

y (3) + α2 (x)y + α1 (x)y + α0 (x)y = 0, X − h ≤ x ≤ X + h,

(1)

We denote the three linear independent solutions of equation (1) as φ1 (x),φ2 (x)
and φ3 (x). Each of them is constructed by solving the initial value problem for
a speciﬁed set of initial conditions at x = X. We take:
y(X) = 1, y (X) = 0, y (X) = 0
y(X) = 0, y (X) = 1, y (X) = 0
y(X) = 0, y (X) = 0, y (X) = 2

for φ1 (x),
for φ2 (x),
for φ3 (x).

The solution of eq.(1) can be constructed through a power series expansion
around X:
yn ∆n ,

y(x) =

with ∆ = x − X, ∆ ∈ [−h, h].

(2)

n=0

We are interested only in ﬁve particular cases; each of these cases leads to a
speciﬁc set of weights in the two–step bdf algorithm. The case abbreviated below
as C0 leads to the classical algorithm, C1, C2 and C3 provide three versions
which form together the new, ﬂexible ﬁtting algorithm while C4 leads to a typical
exponential ﬁtting algorithm.
C0 . This is the particular case of eq.(1) when α0 (x) = α1 (x) = α2 (x) = 0.
In this case the three solutions are simply φ1 (x) = 1, φ2 (x) = x − X and
φ3 (x) = (x − X)2 .
C1 . This is α2 (x) = p0 + p1 ∆ + p2 ∆2 , α1 (x) = 0, α0 (x) = 0, where p0 , p1
and p2 are real constants. Eq.(1) reads
y (3) + (p0 + p1 ∆ + p2 ∆2 )y = 0.

(3)

Upon inserting (2) in (3) and conveniently organizing the terms, the following
recurrence relation is obtained:
1
yn+3 = − (n+3)(n+2)(n+1)
[(n + 2)(n + 1)p0 yn+2
+ (n + 1)np1 yn+1 + n(n − 1)p2 yn ], n = 0, 1, 2, . . .

Since in this case we have φ1 (x) = 1 and φ2 (x) = x − X directly, the recurrence relation has to be used only for the construction of φ3 (x). The starting
values consistent with the mentioned initial value set for φ3 (x) are:
y0 = 0, y1 = 0, y2 = 1.
C2 . This corresponds to α2 (x) = 0, α1 (x) = p0 + p1 ∆ + p2 ∆2 , α0 (x) = 0,
where again p0 , p1 and p2 are real constants. Eq.(1) now becomes
y (3) + (p0 + p1 ∆ + p2 ∆2 )y = 0.
We have φ1 (x) = 1 directly, while for φ2 (x) and φ3 (x) we use the recurrence
formula
yn+3 = −

1
[(n + 1)p0 yn+1 + np1 yn + (n − 1)p2 yn−1 ], n = 0, 1, . . .
(n + 3)(n + 2)(n + 1)

with the starting values

Function Fitting Two–Step BDF Algorithms for ODEs

y0 = 0, y1 = 1, y2 = 0
y0 = 0, y1 = 0, y2 = 1

445

for φ2 (x),
for φ3 (x),

and y−1 = 0 by default.
C3 . This corresponds to α2 (x) = 0, α1 (x) = 0, α0 (x) = p0 + p1 ∆ + p2 ∆2 ,
where, as before, p0 , p1 and p2 are real constants. Eq.(1) reads
y (3) + (p0 + p1 ∆ + p2 ∆2 )y = 0.
with the folllowing recurrence relation for φ1 (x), φ2 (x) and φ3 (x):
yn+3 = −

1
[p0 yn +np1 yn−1 +n(n−1)p2 yn−2 ], n = 0, 1, 2, . . .
(n + 3)(n + 2)(n + 1)

with the starting values
y0 = 1, y1 = 0, y2 = 0,
y0 = 0, y1 = 1, y2 = 0,
y0 = 0, y1 = 0, y2 = 1,

for φ1 (x),
for φ2 (x),
for φ3 (x),

(4)

and with the default values y−2 = y−1 = 0 in all these.
C4 . Here α0 (x) = q0 , α1 (x) = q1 , α2 (x) = q2 , where q0 , q1 and q2 are
real constants. The solution of
y (3) + q2 y + q1 y + q0 y = 0

(5)

is given by the recurrence relation
yn+3 = −

1
[(n + 2)(n + 1)q2 yn+2 + (n + 1)q1 yn+1 + q0 yn ],
(n + 3)(n + 2)(n + 1)

n = 0, 1, 2, . . . with the starting values (4).
This case admits also an analytic solution. Three linear independent solutions
are exp(λ1 x), exp(λ2 x) and exp(λ3 x), where λ1 , λ2 and λ3 are the roots of the
polynomial P (λ) = λ3 + q2 λ2 + q1 λ + q0 . Our φ1 (x), φ2 (x) and φ3 (x) are some
linear combinations of these exponential functions. For all cases C1, C2, C3 and
C4 the number of terms to be retained in the series (2) in order to reach some
predetermined accuracy in the results depends on h and on the numerical values
of the parameters p0 , p1 , p2 or q0 , q1 , q2 . For given p–s or q–s this number
decreases with h.
Weights of the two–step bdf algorithm
We consider the initial value problem
y = f (x, y), x ∈ [a, b], y(a) = y0 ,

(6)

and its solution by a two-step bdf algorithm,
a0 y¯k + a1 y¯k+1 + y¯k+2 = hb2 f (xk+2 , y¯k+2 ), k = 0, 1, 2, . . . ,

(7)

on an equidistant partition with the stepsize h. y¯j is an approximation to y(a +
jh). The weights a0 , a1 and b2 will diﬀer from one interval to another. Their

446

L.G. Ixaru and B. Paternoster

construction on the current interval centered at X = xk+1 (and then xk =
X − h, xk+2 = X + h) is done as it follows.
The linear functional
L[y(x); X, h, a0 , a1 , b2 ] =: a0 y(X − h) + a1 y(X) + y(X + h) − hb2 y (X + h)
is associated to algorithm (7) and we require that this functional is identically
vanishing when y(x) = φ1 (x), φ2 (x), φ3 (x). We have
a0 φi (X − h) + a1 δi1 + φi (X + h) − b2 hφi (X + h) = 0, i = 1, 2, 3.

(8)

Here δij is the usual Kronecker symbol and it appears because, by the very
construction, the three functions satisfy φ1 (X) = 1 and φ2 (X) = φ3 (X) = 0.
The linear system (8) has the solution
D
a0
b2
a1

= h[−φ2 (X − h)φ3 (X + h) + φ3 (X − h)φ2 (X + h)],
= h[φ2 (X + h)φ3 (X + h) − φ3 (X + h)φ2 (X + h)]/D,
= [−φ2 (X − h)φ3 (X + h) + φ3 (X − h)φ2 (X + h)]/D,
= b2 hφ1 (X + h) − a0 φ1 (X − h) − φ1 (X + h).

When φ1 (x) = 1, φ2 (x) = x − X and φ3 (x) = (x − X)2 , as for C0, we get
a0 =

1
4
2
, a1 = − and b2 = ,
3
3
3

(9)

that is the classical weights.

3

Error Analysis

For the error analysis it is convenient to express L in terms of the moments. The
moment Lm is the expression of L when y(x) is the power function (x − X)m ,
i.e.
Lm =: L[(x − X)m ; X, h, a0 , a1 , b2 ].
In fact, the knowledge of the moments allow writing
∞

L[y(x); X, h, a0 , a1 , b2 ] =

1
Lm y (m) (X)
m!
m=0

(10)

for any function y(x) which admits a series expansion in power functions.
If y(x) is the solution of (6), the series (10) furnishes the local error of the
method. Omitting the details, it is possible to draw two conclusions:
1. If p0 = p1 = p2 , as for the classical algorithm, the ﬁrst nonvanishing moment
is L3 . The leading term of the error then reads
lte =

1
2
L3 y (3) (X) = − h3 y (3) (X),
3!
9

a well known result. The order of this version is therefore two.

Function Fitting Two–Step BDF Algorithms for ODEs

447

2. The order is still two also when p0 , p1 and/or p2 are diﬀerent from zero.
This is because the free term in L2 is absent i.e. L2 ∼ h3 .
p0 , p1 and p2 should be chosen in order to obtain an increased accuracy. To this
purpose we introduce the function
s(x) =:

y 3 (x)
,
y (x)

(11)

where y(x) is the exact solution of eq.(6). We have
y (3) (x) = −s(x)y (x), y (4) (x) = (s2 (x) − s (x))y (x),
y (5) (x) = (s3 (x) − 3s(x)s (x) + s (x))y (x), . . .
An analysis of L suggests searching for a determination of the p-s in terms of
s(x). We just require that the parabola α2 (x) = p0 + p1 ∆ + p2 ∆2 is interpolating
s(x) at the three knots X and X ± h to obtain
p0 = s0 , p1 =

1
1
(s1 − s−1 ), p2 = 2 (s1 − 2s0 + s−1 )
2h
2h

where sj = s(X + jh). With this determination, ﬁnally, L ∼ h6 .
To summarize, we have obtained the following result: The C1 version of the
two step bdf algorithm (7) is in general of the second order. However, if the
coeﬃcients p0 , p1 and p2 are ﬁxed by the parabolic interpolation of function s(x)
deﬁned by eq.(11), the order becomes ﬁve.
The above error analysis can be repeated for versions C2 and C3, as well.
The result remains the same, i.e. each of these is in general of the second order,
but if the p-s are determined by interpolating the functions
s(x) =:

y 3 (x)
,
y (x)

s(x) =:

y 3 (x)
,
y(x)

for C2, and

for C3, then these versions become of the ﬁfth order.
Seen from practical point of view each of these three versions exhibits its own
limitation. For instance, C1 version has to be avoided when the second derivative
of the solution of (6) has a zero inside the quoted interval. Likewise, the use of
optimal C2 (or C3) versions should be avoided on the intervals where the ﬁrst
derivative of the solution (or the solution itself) has a zero. For the (exponential
ﬁtting) C4–based algorithm, the interpolation procedure to obtain a ﬁfth order
algorithmis is necessarily replaced by that of solving the linear algebraic system
q2 y (X + jh) + q1 y (X + jh) + q0 y(X + jh) = −y (3) (X + jh), j = −1, 0, 1 (12)
for the unknowns q0 , q1 and q2 , which becomes increasingly ill-conditioned and
therefore the determination of the parameters is less and less accurate.

448

4

L.G. Ixaru and B. Paternoster

The Flexible Function Fitting Algorithm

In spite of the fact that each of these version has its own limitation, the very
existence of three function ﬁtting versions of the same ﬁfth order makes a choice
possible in terms of a safety criterion. The rule of choosing between various
versions in the ﬂexible ﬁtting algorithm is in the following.
Let us assume that we know the exact values at the points X − h, X and
X + h for the solution of the diﬀerential equation (6) and for its derivatives.
We introduce
s1 = −

1
(3)
(X + jh) 2
j=−1 y
,s
1
j=−1 y (X + jh)

s3 = −

=−

1
(3)
(X + jh)
j=−1 y
,
1
j=−1 y (X + jh)

1
(3)
(X + jh)
j=−1 y
,
1
j=−1 y(X + jh)

and evaluate the maximal deviation of the input data for each version,
m
m
m
m
∆sm = max[|sm − sm
−1 |, |s − s0 |, |s − s1 |], m = 1, 2, 3.
¯
¯ be that m such that ∆sm
is the
We compare ∆s1 , ∆s2 and ∆s3 and let m
smallest of the three. The version Cm
¯ is selected for application in that step. In
the case of systems of diﬀerential equations the selection of the optimal version
is operated on each component separately because only in this way the method
remains of the ﬁfth order.
In a real run the exact values of the solution and of its derivatives are obviously not known but we just rely on the numerical values calculated up to that
interval, that is on y¯0 , y¯1 , y¯2 , . . . , y¯k , y¯k+1 . On eﬀectively using the last three
∗
of them, an extrapolated value at the new point xk+2 = X + h, denoted yk+2
,
is generated by the four point Milne–Simpson formula

−¯
yk−1 +

27
3
27
∗
∗
(−¯
yk + y¯k+1 ) + yk+2
= h[ (fk−1 + f (xk+2 , yk+2
)) + (fk + fk+1 )],
11
11
11

which is suﬃciently accurate for this purpose; its error behaves as h7 . y¯k , y¯k+1
∗
and yk+2
are then accepted as suﬃciently reliable representations of the exact
values of the solution at the three mesh points of the current interval. The values
of the derivatives at the same points (these are needed for the interpolation) are
generated via the analytic expressions of f and of its total ﬁrst and second
derivative with respect to x.

5

A Numerical Illustration

We present one test case, whose exact solution is known. We compare three
algorithms: (i) The classical two-step bdf algorithm (C0); it is based on the three
solutions of eq.(1) with α0 (x) = α1 (x) = α2 (x) = 0 and it has the weights in
(9). (ii) The optimal exponential ﬁtting algorithm (CEF); this is based on the

Function Fitting Two–Step BDF Algorithms for ODEs

449

solutions of eq.(5) where the three parameters q0 , q1 and q2 are calculated by
solving the system (12) in each step. (iii) The optimal ﬂexible ﬁtting algorithm
(CFF); in each step this chooses between versions C1, C2 and C3 in terms of the
safety criterion explained before. We assume that y(a) and y(a + h) are given
for C0 while three starting values, y(a), y(a + h) and y(a + 2h) are available for
CEF and CFF. The third data is needed for the activation of the Milne–Simpson
extrapolation.
Let us consider the system of two equations
y1 = −2y1 + y2 + 2 sin(x),
y2 = y1 − 2[y2 + sin(x) − cos(x)], x ∈ [0, 2], y1 (0) = 2, y2 (0) = 1.

(13)

Its solution is
y1 (x) = exp(−x) + exp(−3x) + sin(x),
y2 (x) = exp(−x) − exp(−3x) + cos(x).

Table 1. Absolute errors ∆yi (x) = yi (x) − yicomput (x) at x = 1.5 and 2.0 from the
classical two–point bdf algorithm C0, its optimal exponential ﬁtting extension and its
optimal ﬂexible ﬁtting extension for the two components of system (13).

h
C0
0.0500
0.0250
0.0125
CEF
0.0500
0.0250
0.0125
CFF

∆y1

x = 1.5

x=2.0
∆y2

∆y1

∆y2

0.822(−03) −0.353(−03)
0.198(−03) −0.853(−04)
0.485(−04) −0.210(−04)

0.260(−03) −0.230(−03)
0.604(−04) −0.579(−04)
0.145(−04) −0.145(−04)

0.131(−07)
0.409(−09)
0.128(−10)

0.115(−07)
0.329(−09)
0.163(−06)

0.151(−07)
0.482(−09)
0.152(−10)

0.143(−07)
0.326(−09)
0.522(−06)

0.0500 −0.121(−07) −0.154(−07) −0.400(−08) −0.113(−07)
0.0250 −0.832(−09) −0.884(−09) −0.393(−09) −0.597(−09)
0.0125 −0.286(−10) −0.301(−10) −0.139(−10) −0.201(−10)

Each of the two components is a linear combination of four exponential functions, with the frequencies −1, −3 and ± i, respectively. For this reason, one
may be tempted to admit that the exponential ﬁtting version is the method of
choice. The reality is however diﬀerent. At each step, and for each of the two
components of the equation, the version CEF determines its optimal parameters
by ﬁrst solving the linear system (12) but the accuracy of this evaluation depends
on whether the system is well or badly conditioned which, at its turn, depends
of the magnitude of h. When h is still big the eﬀect is negligible but when h is

450

L.G. Ixaru and B. Paternoster

further decreased it becomes more and more important. In the case of system
(13) this eﬀect is negligible for both components of the solution when h = 0.05
or h = 0.025 but when h = 0.0125 it becomes important around x = 1.7 for the
second component. Note also that y2 (x) changes the sign in that region.
The consequencies are clearly seen in table 2. The errors from CEF are conforming the theoretical ﬁfth order when x = 1.5 but when x = 2 the errors at
h = 0.0125 are abnormally big and they will remain so at any bigger x. This
does not happen with CFF because this algorithm is ﬂexible, and also because
the parameters are calculated by interpolation. In the interval around x = 1.7
the version C3 is excluded for the second component but the two others are still
available. As a matter of fact, in that region, it activates the version C3 for the
ﬁrst component but C2 for the second.
The result is very encouraging but more investigations are needed for a complete understanding of the properties of the new versions and for improving the
quality of the present code, together with analysis of the stability properties of
the CFF algorithm.

References
1. L. Gr. Ixaru, Numerical Methods for Diﬀerential Equations and Applications, Reidel, Dordrecht-Boston-Lancaster, 1984.
2. L. Gr. Ixaru, The Numerov method and singular potentials, J. Comput. Phys. 72,
270–274, 1987.
3. L. Gr. Ixaru, Operations on oscillatory functions, Comput. Phys. Commun. 105,
1–19, 1997.
4. L. Gr. Ixaru and B. Paternoster, A Gauss quadrature rule for oscillatory integrands,
Comput. Phys. Commun. 133, 177–188, 2001.
5. L. Gr. Ixaru, M. Rizea, H. De Meyer and G. Vanden Berghe, Weights of the exponential ﬁtting multistep algorithms for ﬁrst order ODEs, J. Comput. Appl. Math.
132, 83–93, 2001.
6. L. Gr. Ixaru, G. Vanden Berghe and H. De Meyer, Frequency evaluation in exponential ﬁtting multistep algorithms for ODEs, J. Comput. Appl. Math. 140,
423–434, 2002.
7. T. E. Simos, A sixth order Bessel and Neumann ﬁtted method for the numerical
solution of the Schr¨
odinger equation, Molecular Simulation 21, 191–204, 1999.
8. T. E. Simos, An exponentially ﬁtted eight-order method for the numerical solution
of the Schr¨
odinger equation, J. Comput. Appl. Math. 108, 177–194, 1999.
9. T. E. Simos and A. D. Raptis, A fourth order Bessel ﬁtting method for the numerical solution of the Schr¨
odinger equation, J. Comput. Appl. Math. 43, 313–322,
1992.
10. T. E. Simos and P. S. Williams, Bessel and Neumann ﬁtted methods for the numerical solution of the radial Schr¨
odinger equation, Computers and Chemistry 21,
175–179, 1997.
11. G. Vanden Berghe, H. De Meyer, M. Van Daele and T. Van Hecke, Exponentiallyﬁtted explicit Runge-Kutta methods, Comput. Phys. Commun. 123, 7–15, 1997.

