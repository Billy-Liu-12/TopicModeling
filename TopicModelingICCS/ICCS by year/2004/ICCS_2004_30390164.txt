Eﬀective Use of Procedural Shaders in
Animated Scenes
Polina Kondratieva, Vlastimil Havran, and Hans-Peter Seidel
MPI Informatik, Stuhlsatzenhausweg 85, 66123 Saarbr¨
ucken, Germany.
{polina,havran,hpseidel}@mpi-sb.mpg.de

Abstract. Complex procedural shaders are commonly used to enrich
the appearance of high-quality computer animations. In traditional rendering architectures the shading computation is performed independently
for each animation frame which leads to signiﬁcant costs. In this paper
we propose an approach which eliminates redundant computation between subsequent frames by exploiting temporal coherence in shading.
The shading computation is decomposed into view-dependent and viewindependent parts and the results of the latter one are shared by a number of subsequent frames. This leads to a signiﬁcant improvement of the
computation performance. Also, the visual quality of resulting animations is much better due to the reduction of temporal aliasing in shading
patterns.

1

Introduction

Creation of photo-realistic images with low computational requirements is one
of the main goals of computer graphics. Procedural shaders can be used as an
eﬀective mean for rendering high-quality realistic images due to some distinct
advantages, such as simplicity of procedural shading for arbitrarily complex surfaces and the possibility to change the shaded surface with time, viewing angle
or distance [7].
The approach presented in this paper extends the research in Havran
et al. [3]. We show that a signiﬁcant part of shading computation can be reused
in subsequent frames. There are two diﬀerent techniques to prepare the shader
data for reusing. While the ﬁrst approach is based on the 3D-texture notion,
the second one is related to analytical splitting of the procedural shader into
the view-dependent and view-independent parts. The algorithm of reusing the
view-independent data for both techniques is similar.
A key aspect of most procedural shading is the use of a shading language
which allows a high-level description of the color and shading of each surface.
Shaders written in the RenderMan Shading Language can be used by any compliant renderer, no matter what rendering method it uses [8]. For this reason all
examples of shaders in this paper are similar to the RenderMan shaders.
The paper is organized as follows. Section 2 discusses the properties of three
rendering architectures. The algorithm of reusing the view-independent data is
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3039, pp. 164–172, 2004.
c Springer-Verlag Berlin Heidelberg 2004

Eﬀective Use of Procedural Shaders in Animated Scenes

165

presented in Sect. 3. Section 4 describes preprocessing techniques for the preparation of shading data for reusing. Examples of such a preparation are also
presented in this section. The achieved results are shown in Sect. 5. Finally, Sect.
6 concludes the paper and proposes some directions for future work.

2

Related Work

Here we discuss the advantage of Eﬃcient Spatio-Temporal Architecture for
Rendering Animation (ESTARA) [3] compared to the well-known rendering architectures using procedural shaders, such as REYES [2] and Maya renderer [5].
Rendered images have the property of similarity between the consecutive
frames known as temporal coherence, which can be used to accelerate the rendering. Both Maya and REYES architectures compute images of animation sequence frame by frame. On the other hand, ESTARA exploits the property of
temporal coherence by splitting the shading function into the view-independent
and view-dependent parts, whereas the ﬁrst one is computed only once for a
given sample point and the second one is recomputed for each frame. In this
way, ESTARA outperforms both REYES and Maya by considerable reducing
the computational cost of shading computation as well as the temporal aliasing
(ﬂickering). ESTARA can be used for pixel based renderers including bidirectional path tracing, ray tracing, etc. Here we extend the ideas in [3] for ray tracing
with procedural shaders.

3
3.1

Algorithm of Reusing the View-Independent Data for
Procedural Shaders
Notions of View-Dependent and View-Independent Shader
Parts

Before discussing the features of the algorithm of reusing the data, we give a
brief deﬁnition of view−dependent (VD) and view−independent (VI) data with
respect to procedural shaders. The symbolic notation used throughout the rest of
the paper and adopted from RenderMan Shading Language is shown in Table 1.
The computation of the color for each sample can be split into two parts:
VD and VI. The VI data do not change when the camera moves (see Fig. 1(a)).
A simple example of the VI data is the diff use surf ace color which can be
computed according to Lambertian law as follows:
diff useCol = Kd · Cs · cos( N, L) .

(1)

In contrast to the VI data, VD data change whenever the camera moves.
More precisely, the VD data depend on the reciprocal location of the surface
point (hit point) and camera (viewer) in 3D space. A simple example of the VI
data is the specular shading color of the surface. According to the well-known
Phong model, specular color can be computed as following:
specularCol = Ks · specular · cosn ( Rm , V) .

(2)

166

P. Kondratieva, V. Havran, and H.-P. Seidel

In the following chapters we show examples of shader decompositions into
the VD and VI data.
Table 1. Symbolic notation used in the document
Symbol
Ka, Kd, Ks
rough
Kt, Kr
T, R, Rm
Cs, Os
Ci, Oi
specular
N, Nf
L, V
P
du, dv
dPdu, dPdv

3.2

Description
coeﬃcients for the ambient, diﬀuse and specular color
roughness coeﬃcient
refraction and reﬂection coeﬃcients
transmitted, reﬂected and mirror-reﬂected ray directions
surface self color and opacity
incident ray color and opacity
specular color of the surface
geometric and face-forwarded normals
incoming light and opposite view directions
hit point position on the surface of an object
changes in surface parameters
derivatives of surface position along u, v directions.

Algorithm of Reusing the Shading Data

The problem of wasting time for unnecessary recomputations of unchanged data
is addressed by the algorithm of reusing the shading data described in detail
here. The main idea of the algorithm is to save the VI data into the cache and
then reuse it for subsequent frames.
The aliasing artifacts caused by poor sampling of procedural textures as well
as ordinary 2D-textures can be reduced by increasing the number of samples,
thus increasing rendering time. By reusing the VI data for shading in ESTARA
we can decrease the computational cost for one sample. In addition, since the
algorithm of reusing the VI data spreads the shading data into the time domain (Fig. 1(b)), similarly to [6], the temporal aliasing known as ﬂickering and
scintillation is highly reduced.
Let us describe the algorithm of reusing in more detail. For a sequence of
N frames (N camera positions) the VI component of the pixel color in a given
frame can be reused for subsequent frames. In this way, for the ﬁrst frame of a
sequence the ray with ID number unique for each hit point is shot and the color
of the hit point is computed. The VI data of the computed pixel color is saved
into the cache with the corresponding ray ID as a search key.
Afterwards the hit point is reprojected onto the image plane of subsequent
frames. Note, that due to the fact that the camera position can change within
the sequence of frames, the positions of the correspondent reprojected pixels on
the image plane for subsequent frames are diﬀerent. After the reprojection the
hit point is checked for occlusion. If the ray is not occluded, the VI data can be
used for shading computation.
For a range of frames the VI data are possibly combined with recomputed VD
data to get the pixel color. This reusing of the VI data for shading is performed
for all the pixels in the sequence of frames. Since the samples are obtained in a
low cost, the total time of computations decreases.
An example of hit point reprojection for subsequent camera positions is
shown in Fig. 1(b). For more details, see original paper [3]. Since any pixel

Eﬀective Use of Procedural Shaders in Animated Scenes

167

of an image in a sequence of frames can be accessed by the reprojection, all the
image data for a sequence of frames are saved in the main memory.

(a)

object A

(b)

shooted ray
projected ray

P

N
ID = 1005

V1
L

object B
screen

screen

P

/

ID = 1005

ID = 700

screen

V2
camera position i
compute color (1st ray)

P

camera position i+1
compute color (occluded ray)

camera position i+2
reuse color

Fig. 1. Illustrations for the algorithm of reusing the data: (a) Example of the incoming/outgoing vectors for a given hit point P, (b) Hit point reprojection for subsequent
camera positions followed by reusing or recomputation the shading data

3.3

Speedup Analysis

Let us now compare the timings for shading computation required for the traditional frame-by-frame approach and for the proposed algorithm of reusing the
VI data. Suppose the pixel color computation for each camera position in this
case takes Ts1 time. Since, without reusing, the color of each sample for each
camera position should be recomputed, the time T 1 required to compute the
pixel color for n camera positions is:
(3)
T 1 = Ts1 · n .
If the algorithm of reusing the data is involved, the situation changes. For
the ﬁrst camera position times Tvd and Tvi are required to compute the VD
and VI data correspondingly, Tcombine to combine these parts, and Tsave to save
the VI data into the cache. For the remaining n−1 camera positions times Tvd ,
Tcombine are needed as above, and Textract is required to extract (reuse) the VI
data from the cache. Thus, the time needed to compute the pixel color for the
ﬁrst (Ts2 ) and for the remaining n−1 (Ts3 ) camera positions can be calculated
as follows:
Ts2 = Tvd + Tvi + Tcombine + Tsave ,

Ts3 = Tvd + Textract + Tcombine .

The total time T 2 with reusing the VI data is then:
T 2 = Ts2 + Ts3 · (n − 1) .

(4)

The speedup of shading computation achieved by ESTARA with the algorithm of reusing the VI data can be evaluated from (3) and (4). It is clear
that Ts1 < Ts2 and Ts1 > Ts3 . Hence, Ts1 · (n − 1) > Ts3 · (n − 1). If
n > (Ts2 − Ts3 )/(Ts1 − Ts3 ) , then T 1 > T 2 . Therefore, the maximum theoretical speedup achieved by applying the algorithm of reusing the data for n
camera positions can be evaluated as follows:
lim speedup = n · Ts1 /(Ts2 + (n − 1) · Ts3 ) = Ts1 /Ts3 .

n→∞

(5)

168

P. Kondratieva, V. Havran, and H.-P. Seidel

Formula (5) shows that the computational cost of rendering can be reduced
by the algorithm of reusing the shading data. Note that the main point is to use a
fast data structure for saving the VI data, otherwise no speedup can be achieved.
For this purpose some kind of the ﬁxed-size cache with LRU replacement policy
[4] is used in ESTARA.

4

Preprocessing Techniques for Shading Data Reusing

We distinguish two diﬀerent procedural shader classes: representable as 3Dtextures and non-representable as 3D-textures.
4.1

Shaders Representable as 3D-Textures

The main feature of these shaders is that all the properties of the shader are
deﬁned by the complex color (Cs in formula (1)), which represents some pattern
on the surface and it is independent of both V and N.
Analysis of the VD and VI data described in Sect. 3.1 allows to deﬁne whether
a given shader is representable as a 3D-texture. So, the shader can be represented
as a 3D-texture if it has the following properties:
– its VD data contain only the computation of the glossy specular color,
– the computed complex diﬀuse color does not depend on V and can be used
together with the function diff use() in the same way as Cs color,
– it does not create any surface displacements (N perturbations).
Good examples of such shaders are CWoodT exture [11], CStoneT exture [12],
and CCobbleStoneT exture [10]. The pseudo-code of the function which computes
the complex diﬀuse color for the CCobblestoneT exture is shown in Fig. 2.
CobbleStone DiffuseColor(float Kd, jitter, sscale, ttscale, txtscale; color selfCol, varCol)
{
Scale P with txtscale, u with sscale, and v with ttscale
Compute Voronoi noise voronoi(ss, tt,jitter, f1, spos1, tpos1, f2, spos2, tpos2)
paintColor = selfCol,
Cgrout = selfCol · 0.5
paintColor ·= (cellnoise([ spos1-67,tpos1+55 ])+1.5)· varCol · 0.5
//Create cellular pattern with f2-f1.
blendval = smoothstep( 0.03, 0.07, f2-f1)
diffuseColor = Kd · (paintColor · blendval + Cgrout · (1− blendval))
}

Fig. 2. Example of procedural 3D-texture

If the shader is representable as a 3D-texture the complex diﬀuse color can
be saved into the cache as a simple Cs color and then reused for the next frames.
4.2

Shaders Non-representable as 3D-Textures

The shaders of this class have implicit VD and VI data closely interacting with
each other; the shading computation for them is decomposed into layers. There
is a great variety of non-representable as 3D-textures shaders: some of them have

Eﬀective Use of Procedural Shaders in Animated Scenes

169

RCSkin( float Kd, eta, thickness, angle, Xrough, Yrough, maxfreq, blemishfreq, blemishthresh,
blemishopac, oily, brightness, poresfreq, poresthresh, poresdepth; color sheen, Cs,Os)
{
//--- layer 0 - pores -----------------Spread the pores over the surface, compute displaced normal (NN )
//--- layer 1 - skin main color -------color skin = Cs, Oi = Os
//--- layer 2 - blemishes subsurface --PP = transform(object, P)· blemishfreq;
turb = 0;
for (f = 1; f < maxfreq; f *= 2)
turb += abs(snoise(PP· f)) / f;
blemishColor = spline(color1 ,...,colorn ,turbblemishtresh )
Compute Kr, Kt, R, T for the view ray
illuminance cycle(P, Nf , π/2)
{
if(cos( (L + V), Nf ) > 0)
glossy = Kr · sheen · Cl · cos( L, Nf ) · cos4 ( (L+V),L)
glossy += 2 · Kr · sheen · Cl · abs(cos( L, Nf ))
Compute Kr2 , Kt2 , R2 , T2 for L, and single scattering approximations s1 , s2 , s3
glossy += blemishColor · Cl · cos( L, Nf ) · Kt · Kt2 · (s1 +s2 +s3 )
}
Mix color glossy with color skin

}

//- layer 3 - anisotropic Ward model --Compute anisotropic directions anisDir(dPdu, Nf ,angle), XaDir, YaDir
illuminance cycle(P, Nf , π/2)
{
Compute Ward coefficient rho(XaDir, Nf , YaDir, L, V)
if(Light source is specular) Canis = (Cl · cos( L, Nf ) · rho)/(4 · Xrough · Yrough)
}
Diff = Kd · diffuse(Nf ))
color skin += (Canis · 0.1 · oily + Diff) · brightness
Save Diff, blemishColor, Os, NN , P, XaDir, YaDir into the cache

Fig. 3. An example of non-representable as 3D-texture 4-layer shader

only one layer, such as velvet [11], some others consist of many complicated layers
involving Fresnel function, Ward reﬂection model, and/or some other functions
for anisotropic reﬂection, such as RCSkin [11]. Despite of their complexity, even
these shaders can be usually split into VD and VI data.
At this point, let us consider an example of complicated shader - RCSkin. It
consists of four layers and the computation of the color for each layer is highly
time consuming. The pseudo-code of the function which calculates the pixel color
for this shader is presented in Fig. 3.
The RCSkin shader presented in Fig. 3 computes a number of speciﬁc VD
functions. For example, the Ward reﬂection model and the Fresnel function are
quite computationally demanding. Fortunately, after the careful analysis the
following components of the shader can be considered as the VI data:
–
–
–
–

At layer 0 the displaced normal NN for pores,
At layer 1 the skin color color skin and Oi,
At layer 2 the blemishColor computed by the spline function for 3D-vectors,
At layer 3 the anisotropic directions (XaDir, YaDir).

In the same way all the other non-representable as a 3D-texture shaders can
be split into the VD and VI data. The main point is that the time required to
compute the VI data should be greater than the time required to insert/extract
the data from the cache.

170

5

P. Kondratieva, V. Havran, and H.-P. Seidel

Results

We have veriﬁed the eﬃciency of the described algorithm of reusing the shading data embedded by ESTARA on three scenes applying diﬀerent shaders. A
computer with processor Intel(R) Xeon(TM) CPU 1.706MHz and 1024MB of
memory was used for rendering. All the shaders were taken from the [1], [9], or
RenderMan sites [10],[11], [12] and adapted for our renderer, as described above.
At the ﬁrst step, the speedup of the shading color computation for each shader
was evaluated for a simple scene avoiding the visibility test. The timing results
in seconds for all the shaders are shown in Table 2. In Table 2 column noreuse
presents the shading time results for the traditional frame-by-frame approach.
Column reuse shows the timing results for the algorithm of reusing the shading
data. Column speedup depicts the speedup (speedup = noreuse/reuse).
At the next step, the speedup evaluation was accomplished for two more
complex scenes: scene F ace, containing RCSkin and greenmarble shaders, and
scene Interior, containing all the shaders from Table 2 except RCSkin, performing the visibility test. Note, that speedup was achieved by the combined
reusing of the VI data and visibility information. The timing results in seconds
for both scenes are presented in Table 3.
Table 2. Timing and speedup results for shaders applied to the simple scene
Shader
blocks
carpet
cmarble
colormarble
cobblestone
greenmarble
spatter
stone
velvet
wood
RCSkin

50 camera positions
noreuse
reuse
speedup
25.47
8.02
3.18
27.35
9.84
2.78
77.89
18.24
4.27
73.36
18.29
4.01
26.99
11.83
2.28
50.97
17.44
2.92
21.57
12.33
1.75
15.68
13.13
1.19
12.27
12.44
0.99
25.44
15.27
1.67
97.12
46.98
2.07

100 camera positions
noreuse
reuse
speedup
52.00
15.96
3.26
55.14
18.92
2.91
154.76
34.93
4.43
148.43
34.93
4.25
62.25
27.20
2.29
97.91
33.06
2.96
47.55
27.17
1.75
32.91
25.99
1.27
24.45
23.84
1.03
51.34
29.85
1.72
185.75
78.05
2.38

Table 3. Timimg results for scenes Interior and F ace
Scene
F ace
Interior

Time
reuse
noreuse
2.24e+03
2.73e+03
1.25e+05
3.28e+05

speedup
1.22
2.62

The resulting images for the scene F ace with diﬀerent values of parameters
for RCSkin shader are presented in Fig. 4(a) and 4(b). The resulting images for
the scene Interior with procedural shaders are depicted in Fig. 4(c).

6

Conclusion and Future Work

In this paper we have described techniques, which signiﬁcantly reduce the computational cost of procedural shading in animation rendering, while improving

Eﬀective Use of Procedural Shaders in Animated Scenes
(a)

(b)

171

(c)

Fig. 4. Images rendered by ESTARA with reusing: (a), (b) scene F ace with diﬀerent
parameter settings for RCSkin shader; (c) scene Interior

the quality of resulting images in the context of ESTARA rendering architecture [3]. The speedup is achieved by splitting the shader into two parts: the
view-dependent (VD) and the view-independent (VI).
Applying the algorithm of reusing the shading data for ray tracing a moderately complex scene with procedural shaders, we received signiﬁcant speedup
up to a factor of 2.62. Since the VI data of the color are the same for the pixels
corresponding to the reprojection of the shaded point in the object space to the
image plane of subsequent frames, the temporal aliasing (ﬂickering) is reduced.
The main disadvantage of the proposed algorithm is the fact that all shaders should be split into the VD and VI data manually. Intuitively, this time
consuming and laborious process could be done by computer. We envision the
automation of the splitting process as the next step in the development of the
algorithm of reusing the shading data.
Acknowledgments. The authors would like to thank Karol Myszkowski for
helpful discussions and suggestions during the preparation of the paper.

References
1. Apodaca, A.A., and Gritz, L. Advanced RenderMan. Morgan Kaufmann, 1999
2. Cook, R.L., Carpenter, L., Catmull, E.: The Reyes Image Rendering Architecture.
ACM Computer Graphics SIGGRAPH’97 Proc. (1987) 95-102
3. Havran, V., Damez, C., Myszkowski, K., and Seidel, H.-P.: An Eﬃcient Spatiotemporal Architecture for Animation Rendering. Eurographics Symposium on Rendering (2003)
4. Knuth, D.E.: The Art of Computer Programming, Vol.3 (Sorting and Searching).
Addison-Wesley Series (1973).
5. Sung, K., Craighead, J., Wang, C., Bakshi, S., Pearce, A., and Woo, A.: Design and
implementation of the Maya Renderer. Paciﬁc Graphics’98 Proc. (1998) 150-159
6. Martin, W., Reinhard, E., Shirley, P., Parker, S. and Thompson, W.: Temporally
coherent interactive ray tracing. Journal of Graphics Tools 2 (2002) 41-48
7. Olano, M.: A Programmable Pipeline for Graphics Hardware. PhD dissertation,
University of North Carolina, Chapel Hill (1998)

172

P. Kondratieva, V. Havran, and H.-P. Seidel

8. Olano, M., Lastra, A.: A Shading Language on Graphics Hardware: The PixelFlow
Shading System. ACM Computer Graphics SIGGRAPH’98 Proc (1998) 159-168
9. Upstill, S.: The RenderMan Companion. A programmer’s Guide to realistic Computer Graphics. Addison-Wesley publishing company (1990)
10. http://www.cs.unc.edu/˜{}stewart/comp238/shade.html
11. http://www.renderman.org/RMR/Shaders/
12. http://www-2.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15462/arch/
sgi 65/prman/lib/shaders/stone.sl

