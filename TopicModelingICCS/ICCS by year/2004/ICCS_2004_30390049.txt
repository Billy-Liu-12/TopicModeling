Automatic Detection of Glaucomatous Changes
Using Adaptive Thresholding and Neural
Networks
Katarzyna St¸apor1 , Leslaw Pawlaczyk1 , Radim Chrastek2 , and
Georg Michelson3
1

Institute of Computer Science, Silesian University of Technology, Akademicka 16,
PL-44-100 Gliwice, Poland,
2
Chair for Pattern Recognition, Friedrich-Alexander-University
Erlangen-Nuremberg, Martenstrasse 3, D-91058 Erlangen, Germany,
3
Department of Ophthalmology, Friedrich-Alexander-University
Erlangen-Nuremberg Schwabachanlage 6, D-91054 Erlangen, Germany
delta@ivp.iinf.polsl.gliwice.pl

Abstract. In this paper the new method for automatic classiﬁcation of
fundus eye images into normal and glaucomatous ones is proposed. The
new, morphological features for quantitative cup evaluation are proposed
based on genetic algorithms. For computation of these features the original method for automatic segmentation of the cup contour is proposed.
The computed features are then used in classiﬁcation procedure which is
based on multilayer perceptron. The mean sensitivity is 90%, while the
mean speciﬁcity: 86%. The obtained results are encouraging.

1

Introduction

Glaucoma is a group of diseases characterized by the proceeding optic nerve
neuropathy which leads to the rising diminution in vision ﬁeld, ending with
blindness. The correct optic disk (i.e. the exit of the optic nerve from the eye
known as ”blind spot”) structure contains: neuroretinal rim of pink color and
centrally placed yellowish cup [6] (Fig. 2a). The cup is the area within the optic
disc where no nerve ﬁbers and blood vessels are present and in 3D image appears
as an excavation. The neuroretinal rim is the area between optic disc border and
cup border - see Fig. 2a. Glaucomatous changes in retina appearance embrace
various changes in neuroretinal rim and cup, as the result of nerve ﬁbers damages.
Optic disc structures evaluation is one of the most important examinations
in glaucoma progress monitoring and diagnosis. Searching for glaucoma damages
during routine examination is not an easy task and gives uncertain results even
with the experienced ophthalmologist [6]. The existing methods of qualitative
analysis are very subjective, while quantitative methods of optic disc morphology
evaluation (cup to disc ratio, neuroretinal rim area) do not result in full diagnosis.
The new methods of morphologic analysis based on scanning-laser-tomography
are expensive and accessible only in specialized ophthalmic centers.
M. Bubak et al. (Eds.): ICCS 2004, LNCS 3039, pp. 49–55, 2004.
c Springer-Verlag Berlin Heidelberg 2004

50

K. St¸apor et al.

In the existing approaches for supporting glaucoma diagnosing [4,7,8] the
automatic extraction of the cup region from fei was not the area of interest.
Also, automatic classiﬁcation of single fei acquired from fundus cameras into
normal and glaucomatous has received no attention.
That is why we have developed a more objective and cheaper method that
enables automatic classiﬁcation of digital fundus eye images (fei) into normal and
glaucomatous ones. The fei images were obtained by classical fundus-camera. We
plan to build the proposed methodology into classical fundus-camera software
to be used in routine examinations by an ophthalmologist.

2

Methods

The proposed method for automatic detection of glaucomatous changes in fundus
eye images is composed of the 3 main stages (shown in Fig. 1):
1. detection of the cup contour,
2. selection of the cup features using genetic algorithms,
3. classiﬁcation of fundus eye images using neural network classiﬁer
2.1

Automatic Detection of the Cup Contour

Digital fei are acquired from classical fundus camera in RGB additive color model
[5]. The color normalization step using histogram speciﬁcation [5] is performed
to decrease the variation in the color of fei from diﬀerent patients. A copy of the
acquired fei is converted into HSV color model [5]. On RGB image blood vessels
are detected automatically using a set of contour ﬁlters according to a method
described in [3].
Based on the detected vessels, the averaging of H,S,V components in HSV
image is performed to decrease the contrast. All pixels comprising the detected
vessels lying inside the user rectangle belong to the subregion named here
Reyecup vessels . First, the input image is converted from RGB to HSV color
model [5]. By overlying the image with detected vessels on the input, converted image all border pixels of the detected vessels are found (subregion
Reyecup vessels ). For each border pixel in Reyecup vessels its new color components
[Havg ,Savg ,Vavg ], being the average of the appropriate components of pixels lying in the 8-connected neighborhood outside of Reyecup vessels region are found.
After recalculation of all border pixels, they are deleted, new border pixels are
found and the process is repeated until size of Reyecup vessels is higher than 0.
This preprocessed HSV image is converted into L*a*b* color model [5]. For
further examinations only channel a* is used. Next, the a* component of L*a*b*
image is binarized by the proposed adaptive thresholding method which results
in white pixels of the cup (i.e. the object) and black pixels of the rest of the image
(i.e. the background). In the adaptive thresholding method a local threshold is
found by statistically examining the intensity values of a local neighborhood of

Automatic Detection of Glaucomatous Changes

51

each pixel. A window cantered at each pixel is constructed as its local neighborhood. The statistic used is a function:
T = Mmean − C,

(1)

where Mmean is a mean of gray level values in the window, C is a constans,
experimentally set.

Fig. 1. Stages of the eye cup segmentation method

Due to nerve ﬁbres damages during glaucoma progress, diﬀerent changes in
a shape of the neuroretinal rim (and of the cup) are observed. Proper shape
feature selection can reduce not only the cost of recognition by reducing the
number of features that need to be collected, but in some cases it can also provide
a better classiﬁcation accuracy due to ﬁnite sample size eﬀect In our approach,
29 geometric features are computed on the extracted cup region. These are: seven
Hu moment invariants [9], ﬁfteen compound invariant moments [9], two circular
coeﬃcients [9], area to perimeter coeﬃcient, Danielsson, Haralick, Blair-Bliss
and Feret coeﬃcients [9]. Genetic algorithms [1] are then used to select the most
signiﬁcant features characterizing the shape of cup region.
A given feature subset is represented as a binary string (a chromosome) of
length n, with a zero or one in position i denoting the absence or presence of
feature i in the set (n is the total number of available features). The initial population is generated in the following way: the number of 1’s for each chromosome
is generated randomly, then, the 1’s are randomly scattered in the chromosome.
A population of chromosomes is maintained. Each chromosome is evaluated to
determine its ”ﬁtness”, which determines how likely the chromosome is to survive
and breed into next generation. We proposed the following ﬁtness function:
F itness = 104 accuracy + 0.4zeros,

(2)

52

K. St¸apor et al.

a)

b)

c)

Fig. 2. a) The initial image with the optic disk and the cup in the central part;
b) channel a* of the input image; c) the contour of the extracted cup region overlaid
on the input image

where accuracy is the accuracy rate that the given subset of features achieves (i.e.
the performance of a classiﬁer on a given subset of features), zeros is the number
of zeros in the chromosome. Reproduction is based on a random choice according
to a fraction with repetitions method [1]. New chromosomes are created from
old chromosomes by the process of crossover and mutation [1].
The following 3 dimensional feature vector has been selected from a set of 29
features by genetic algorithm: (FI2, I3, RF), where
2
F I2 = (η20 + η02 )2 + 4η11
,

(3)

is Hu invariant moment, where: η20 , η02 , η11 are normalized central moments.
Normalized central moment of order (p+q) is deﬁned as [5]:
µpq =

mpq
p+q
,α =
+ 1,
(m00 )α
2

(4)

where: mpq is a spatial central moment of order p + q of an image f deﬁned as:
m

n

(i − I)p (j − J)q f (i, j),

mpq =

(5)

i=1 j=1

m10
,
m00
m01
J=
,
m00
I=

I3 = µ20 (µ21 µ03 − µ212 ) − µ11 (µ30 µ03 − µ21 µ12 ) + µ02 (µ30 µ12 − µ212 ),

(6)
(7)
(8)

is compound, invariant moment.
RF =

Lh
LV

(9)

Automatic Detection of Glaucomatous Changes

53

is Feret coeﬃcient, where:
Lh - maximal diameter in horizontal direction
LV - maximal diameter in vertical direction.
2.2

Classiﬁcation of Fundus Eye Images Using Neural Network
Classiﬁer

The method makes use of the 3-2-2 multilayer perceptron (MLP) [2]. The operation of MLP is speciﬁed by:
Vj1 = f (

wjk Vk0 ),

(10)

wjk Vk1 ),

(11)

k

Vj2 = f (
k

which speciﬁes how input pattern vector Vk0 is mapped into output pattern
vector Vk2 via the hidden pattern vector Vk1 in a manner parameterized by the
1
2
two layers of weights: wij
,wij
. The univariate function f is set to:
f (x) =

1
1 + e−x

(12)

The weights in the network are modiﬁed during training to optimize the match
between outputs and targets di using standard backpropagation rule [2]:
m−new
m−old
= wij
+ ηδim Vijm−1 ,
wij

where:

M −1
wiM
)[di − ViM ]
ij Vj

δiM = f (

(13)
(14)

j

delta-error for ith neuron in output layer M ,
δim−1 = f (

wim−1
Vjm−2 )
ij
j

m m
wji
δj

(15)

j

m = M, M − 1, . . . , 2 delta-error for ith neuron in hidden layer m. The trained network (classiﬁer) can be used to determine which class of pattern in the
training data each neuron in the network responds most strongly to. Unseen
data can then be classiﬁed according to the class label of the neuron with the
strongest activation for each pattern.

3

Results

The developed method has been applied into 100 fei of patients with glaucoma
and 100 fei of normal patients which where previously examined by conventional
methods by ophthalmologist. On the acquired from Canon CF-60Uvi funduscamera images, the cup contour is automatically detected. Next, for the detected

54

K. St¸apor et al.

cup the whole set of 29 geometric features is computed. The obtained set of
labeled feature vectors is divided into 4 parts: two training and two testing
sets. One pair composed of one training and one testing set is used by genetic
algorithms for suboptimal feature vector calculation, while the second pair of
sets for calculation of a performance of neural network classiﬁer.
The parameters of genetic algorithm used in all experiments are as follows:
the length of each chromosome is 29 (equal to the number of features), population size is 120. Genetic algorithm converged to the ﬁnal solution after 150
generations.
The parameters of a neural network classiﬁer are as follows: the structure is
set as 3-2-2 as described above, sigmoidal function is used as activation functions
in hidden and output layers. The learning rate η is equal to 1. Weights wij
are initialized to the small random values from (−1.5, 1.5) interval. Classiﬁer
performance is tested by k-fold cross validation method. During performance
evaluation, the constructed classiﬁer ran 5000 iterations to train and updated
the weights each time training data were presented. The following mean results
has been obtained: sensitivity 90% and speciﬁcity 86%.

4

Conclusions

As far as we know no automatic method for the segmentation and classiﬁcation
of fei acquired from fundus-cameras into normal and glaucomatous has been
reported yet. Our method proves that shape of the cup and its numerical characteristics correlate with progress of glaucoma. It also shows that by reducing
irrelevant information and using only selected features the classiﬁer performance
can be improved signiﬁcantly which is very important for application supporting
glaucoma diagnosing.
The obtained results are encouraging. It is expected that the new method,
after clinical tests would support glaucoma diagnosis based on digital fei obtained
from fundus-camera.

References
1. Arabas J.: Lectures on genetic algorithms. WNT, Warsaw (2001)
2. Bishop C.M.: Neural networks for pattern recognition. Clarendon Press, Oxford
(1995)
3. Chaudhuri S., et al.: Detection of Blood Vessels in Retinal Images Using TwoDimensional Matched Filter. IEEE Transactions on Medical Imaging, Vol 8, No.
3. (September 1989)
4. Goh K.G, et al: ADRIS An Automatic Diabetic Retinal Image Screening system.
K.J. Cios (Ed.): Medical Data Mining and Knowledge Discovery. Springer-Verlag,
New York (November 2000) 181-201
5. Gonzalez R.C., Woods R.E.: Digital image processing. Prentice-Hall (2002)
6. Kanski J. et al. Glaucoma: a color manual of diagnosis and treatment. ButterworthHeinemann (1996)

Automatic Detection of Glaucomatous Changes

55

7. Morris D.T., Donnison C.: Identifying the Neuroretinal Rim Boundary Using Dynamic Contours. Image and Vision Computing, Vol. 17. (1999) 169-174
8. Osareh A., et al.: Classiﬁcation and localisation of diabetic related eye disease. A.
Heyden et al. (Eds.): ECCV 2002, LNCS 2353 (2002) 502-516
9. Trier O., Jain A., Taxt T.: Feature extraction methods for character recognition a survey. Pattern Recognition, (1996) 641-662

