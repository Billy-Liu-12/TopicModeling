Procedia Computer Science
Volume 80, 2016, Pages 1507–1518
ICCS 2016. The International Conference on Computational
Science

WOWMON: A Machine Learning-based Proﬁler for
Self-adaptive Instrumentation of Scientiﬁc Workﬂows
Xuechen Zhang1 , Hasan Abbasi2 , Kevin Huck3 , and Allen D. Malony3
1

Washington State University Vancouver, Vancouver, Washington, U.S.A
xuechen.zhang@wsu.edu
2
Oak Ridge National Laboratory, Oak Ridge, Tennessee, U.S.A.
habbasi@ornl.gov
3
University of Oregon, Eugene, Oregon, U.S.A
khuck@cs.uoregon.edu, malony@cs.uoregon.edu

Abstract
Performance debugging using program proﬁling and tracing for scientiﬁc workﬂows can be
extremely diﬃcult for two reasons. 1) Existing performance tools lack the ability to automatically produce global performance data based on local information from coupled scientiﬁc
applications of workﬂows, particularly at runtime. 2) Proﬁling/tracing with static instrumentation may incur high overhead and signiﬁcantly slow down science-critical tasks. To gain more
insights on workﬂows we introduce a lightweight workﬂow monitoring infrastructure, WOWMON (WOrkﬂoW MONitor), which enables user’s access not only to cross-application performance data such as end-to-end latency and execution time of individual workﬂow components
at runtime, but also to customized performance events. To reduce proﬁling overhead, WOWMON uses adaptive selection of performance metrics based on machine learning algorithms
to guide proﬁlers collecting only metrics that have most impact on performance of workﬂows.
Through the study of real scientiﬁc workﬂows (e.g., LAMMPS) with the help of WOWMON,
we found that the performance of the workﬂows can be signiﬁcantly aﬀected by both software
and hardware factors, such as the policy of process mapping and in-situ buﬀer size. Moreover,
we experimentally show that WOWMON can reduce data movement for proﬁling by up to 54%
without missing the key metrics for performance debugging.
Keywords: TAU, Scientiﬁc workﬂows, Performance monitoring

1

Introduction

Data-intensive knowledge discovery requires scientiﬁc applications to run concurrently with
analytics and visualization codes as workﬂows. These coupled applications can be executed
in situ for timely output inspection and knowledge extraction. Performance debugging for
scientiﬁc workﬂows can be more diﬃcult than that for stand-alone applications using existing
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.474

1507

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

high-performance computing (HPC) performance tools [20, 2] for two reasons. First, they
lack the ability to produce global performance data based on local data from multiple coupled
applications at runtime. Without the global data, for example, it is diﬃcult to observe the total
amount of time that a scientiﬁc workﬂow used to process data produced by an application at a
particular execution step. We refer to this time as end-to-end latency of a workﬂow. Second,
proﬁling/tracing of multiple applications with static instrumentation can incur high storage
overhead and slow down the execution of mission-critical scientiﬁc tasks.
In this paper we describe a novel monitoring infrastructure called WOWMON to gain deeper
understanding of where and when performance bottleneck happen in scientiﬁc workﬂows. It
provides three unique features: 1) online feedback for timely workﬂow tuning and adaptation
by accessing in-memory performance data; 2) global monitoring which produces global performance data, speciﬁcally used for performance debugging of workﬂows; 3) self-adaptive proﬁling
which can guide proﬁlers collecting only the metrics that have most impact on performance of
workﬂows using machine learning algorithms. More speciﬁcally, we made the following contributions in this work:
• We designed simple interface for users to access in-memory performance data across multiple applications/components of workﬂows, and implemented a ﬂexible and lightweight
runtime system, supporting data sampling, multiple network topologies, metric selection
for customized coverage of performance metrics, and self-adaptive proﬁling.
• We implemented WOWMON based on TAU [20] and EVpath [4] libraries. With the help
of WOWMON our experiments using realistic scientiﬁc workﬂows (e.g., LAMMPS ) show
that the end-to-end latency of workﬂows can be aﬀected by the memory buﬀer size for
in-situ operations and the policy of mapping processes of applications to nodes.
• We demonstrated that WOWMON can evaluate performance metrics at runtime using
feature selection algorithms, and then use its output to further reduce the volume of performance data by 54% for the LAMMPS workﬂow, while still providing in-depth insights
for end-users.
The rest of this paper is organized as follows. Section 2 discusses the existing tools related
to performance research of scientiﬁc applications. Section 3 describes the design and implementation of WOWMON. Section 4 describes and analyzes experimental results. Finally, we
conclude the paper in Section 5.

2

Related Work

Most of the previous work focused on the performance measurement and monitoring of standalone applications. For example, TAU [20] has been very popular as an HPC toolkit for performance instrumentation, measurement, analysis, storage, and visualization. By leveraging
PAPI [2] and source instrumentation, it can access both hardware counters and application
performance data in standard ways. However, TAU’s performance data analysis is typically
performed after data has been written to disk-resident logs, or in a central location. This
restricts the scalability of online monitoring and analysis tasks.
An online monitoring infrastructure is needed to capture transient eﬀects of data-driven behaviors. Although many works have been proposed for this purpose, none of them was designed
for capturing performance of workﬂows. With respect to instrumentation, a salient feature of
1508

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

the performance measurement tool Paradyn [13] is ﬂexible selection of metric subsets for binary instrumentation at runtime, which might take seconds to ﬁnish. In contrast, WOWMON
creates initial instrumentation points based on a priori knowledge using the simple WOWMON
API. WOWMON’s runtime library supports online reconstruction of metric sets in networking
layers for reducing monitoring overhead. With respect to online data access, TAUg [10] was
designed to collect performance data of MPI processes for stand-alone applications. Roth et
al. [19] presented an online performance diagnosis system, focusing on optimization of problem
search strategies for ﬁnding bottlenecks of large-scale stand-alone applications. The Ganglia
distributed monitoring system [12] is widely used in both enterprise and HPC domains. However, it only targets on system metrics such as CPU idle time. WOWMON needs to collect
source-level data (e.g., function execution time) as well as track system-level events because
both are critical for the analysis of the workﬂow performance as shown in Section 4.
Other application-steering software may have built-in monitoring modules. An example is
Peridot [6], which allows programmers to guide analysis process with query and then interacts
with runtime systems. WOWMON can also provide feedback for optimization of the metric
sets. Moreover, it provides key services for performance diagnosis of a workﬂow not a standalone application. For the latter, performance steering has been well studied. Autopilot [18]
used classiﬁcation algorithms to produce the hints of making resource management decision
based on collected performance data. WOWMON can also leverage learning algorithms [9]
in order to evaluate importance of metrics. Eisenhauer et al. [3] proposed a steering system
working with multiple collaborated users. Falcon [7] supports online interaction with end users
of complex scientiﬁc simulations. Tapus et al. [21] proposed a steering approach, which takes
into account the performance characteristics of linked libraries of binaries.
In summary, WOWMON is the only system, which is designed for performance diagnosis
and steering of the scientiﬁc workﬂows composed of in-situ analytics.

3

The Design of WOWMON

We have three objectives in the design of WOWMON: 1) accessing in-memory data structures
for collecting online performance data; 2) tracking global performance data using the local data
collected from individual workﬂow components; 3) providing a ﬂexible and lightweight networking layer which can support self-adaptive proﬁling/tracing using machine learning algorithms.
In addition, WOWMON provides simple APIs for end users to create and track timers, specify
system and application events of interests, and customize communication patterns. We will
discuss them in detail in the following sections.

3.1

Architecture Overview

The WOWMON infrastructure includes three major components, user interface (APIs), a runtime library, and a workﬂow manager. Programmers need to instrument source code using the
APIs, as discussed in Section 3.2. At runtime, WOWMON creates relay networks connecting
the processes of applications and the workﬂow manager using a network topology speciﬁed in
the parameter (WOWMON TOPO COMM ) by users (star topology is set by default). Then
software and hardware events can be added to an initial metric set (M etricSetinit ), whose
members might be dynamically selected at runtime to control the size of the set, which correlates to monitoring overhead. Speciﬁcally, the software events can track program’s performance
such as function execution time, call depth, and memory heap size when entering and exiting
a function. And the hardware events are used to track hardware performance such as cache
1509

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

 



!

"









Zhang et al.





WOWMON Runtime



	


Data
Message




Control
Message



Figure 1: WOWMON architecture

misses, ﬂoating point operations, and so on. WOWMON reads the values of the metrics from
a in-memory data structure of a proﬁler, such as TAU [20]. The data structure tracks all the
current value of the metrics in M etricSetinit . For those not strongly correlated to the endto-end latency of workﬂows, as indicated by the outputs of machine learning algorithms, the
workﬂow manager can at runtime specify another set of metrics M etricSetinterest to replace
M etricSetinit . M etricSetinterest needs to be a subset of M etricSetinit . And only performance
data for the metrics in M etricSetinterest are transferred to the workﬂow manager. Because
the size of M etricSetinterest may be signiﬁcantly smaller than M etricSetinit , the monitoring
overhead of WOWMON can be reduced as shown in Section 4.4.
Function
WOWMON REGISTER VIEW()
WOWMON ADD EVENTS()
WOWMON GET GLOBAL DATA()
WOWMON DEREGISTER VIEW()
WOWMON INIT TIMER()
WOWMON TRACK TIMER()

Description
Establish connection to runtime
Track hardware/software events
Notify the networking layer to send data
Disconnect from the runtime
Create a user timer
Track a user timer

Table 1: A description of WOWMON APIs

3.2

User Interface

The user interface (APIs) of WOWMON is designed to be easy to use, and callable from C,
C++, and FORTRAN. The functions listed in Table 1 work synergistically with WOWMON
runtime to fulﬁll user’s needs on performance monitoring. The APIs include six functions.
WOWMON REGISTER VIEW() creates data buﬀers and connections to the runtime system.
With this function users can specify a network topology and name a communicator. WOWMON ADD EVENTS() adds events to M etricSetinit . For example, a software event can be
added to track memory heap size when entering a particular function having the signature string
1510

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

”void compute and send(bond record ptr) [bonds.c 398,1-469,1]” 1 . Function signatures can be
obtained using the existing proﬁling tools, such as TAU. WOWMON GET GLOBAL DATA()
is called to send performance data to the workﬂow manager. For data sampling users can
specify a subset of processes as the samples of proﬁling data using WOWMON PATTERN,
which should be in the range of 0 to nprocs, which is the total number of processes of an
application. When it is set to i, only data from the process of rank 0 to i − 1 are collected
and sent to the workﬂow manager. By default it is set to nprocs. This feature is very useful
for reducing communication overhead when workﬂows are executed at scale with thousands of
processes. Data collection can be disabled by setting WOWMON PATTERN to 0 when users
are not interested in the metrics from a particular component or the latency between directly
connected components. When a program is ﬁnalized, WOWMON DEREGISTER VIEW() is
needed to disconnect from runtime and clean up state buﬀers. WOWMON INIT TIMER() and
WOWMON TRACK TIMER() are called to create and track a user timer placed at a speciﬁc
location in source code.

3.3

The Runtime Library

In the design of WOWMON runtime, we optimize its proﬁling operations, buﬀer management,
and communication considering both portability and scalability. Three components, including
a proﬁler, a buﬀer manager, and a relay network, interact with the workﬂow manager to achieve
lightweight monitoring, as shown in Figure 1.
The proﬁler maintains in-memory data structures to keep tracking of the values of timers
and events instrumented by programmers. WOWMON uses the existing proﬁling software such
as TAU and PAPI for this purpose, although other tools can be supported easily because only
∼50 lines of code are proﬁler-dependent. When TAU is used as the proﬁler, WOWMON calls
two key functions TAU GET EVENT NAMES() and TAU GET FUNC VALS() [22] to read
the values of the metrics in M etricSetinterest and stores them in data buﬀers.
The buﬀer manager tracks M etricSetinterest and M etricSetinit for each application of a
workﬂow. Based on M etricSetinterest it reads in-memory proﬁles, creates buﬀers for data
messages, and then sends those messages to the workﬂow manager. As a receiver, it also updates
M etricSetinterest when control messages for adaptive proﬁling are received. The format of the
data messages is composed of both data ﬁelds, each corresponds to a metric in M etricSetinterest ,
and meta-data ﬁelds such as application ID, process ID, and communicator ID, which are then
used by the workﬂow manager to identify the messages from various running instances and
produce global performance data (e.g., end-to-end latency of workﬂows) based on proﬁled local
information.
The relay network is a thin communication layer between the runtime of applications
(sources) and workﬂow managers (sinks). The messages sent from the source to sink nodes may
be processed through multi-level relay nodes in order to remove a networking bottleneck caused
by a centralized workﬂow manager and improve the scalability of the network. EVpath [5] is
selected for relay network management for its proven performance on high-end machines and
support of multiple networking drivers (e.g., TCP/IP, Inﬁniband [14], and ENET [17] etc). If
WOWMON TOPO COMM is set to star, all the sources are directly connected to the workﬂow
manager. This topology should only be used for small scale runs. If WOWMON TOPO COMM
is set to tree, a network having a spanning tree topology is created for the applications having
more than 128 processes. In this scenario, only a limited number of relay nodes are directly
1 compute and send() is an expensive function in the Bonds code of the LAMMPS workﬂow. More details
of the workﬂow are presented in Section 4.1.

1511

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

WOWMON Runtime
MCoordinator
Data
e
Message

Control
Message




	

			
	

Figure 2: An example of a workﬂow manager using machine learning algorithms provided by
Weka to select correlated metrics.
connected to the workﬂow manager. The relay nodes periodically send the summarized performance data received in a period to the workﬂow manager for reduced overhead of data transfer
and a more balanced load distribution.

3.4

Self-adaptive Proﬁling

A workﬂow manager, named M Coordinator, is designed to help select metrics according to their
impact on end-to-end latency, rather than acting only as a dummy manager just collecting local
data. As shown in Figure 2, M Coordinator collects data from workﬂow components and then
converts them to software-compatible formats, such as attribute-relation ﬁle format (ARFF)
required by the Weka [8] software. In the next step, attributes selection algorithms are executed
to rank the metrics in M etricSetinit or M etricSetinterest . Speciﬁcally, we use an algorithm
called CfsSubsetEval in Weka to evaluate the worth of a subset of metrics by considering the
individual predictive ability of each metric along with the degree of redundancy between them.
Subsets of metrics that are highly correlated with the latency while having low inter-correlation
are preferred [9]. Breadth-ﬁrst search algorithm [11] is used for metric subsets creation during
the search. In the end, the metrics in the selected subset are sent back to WOWMON runtime
via a control channel. M Coordinator can trigger the metric selection procedure both oﬄine
and online. In addition, it needs to decide when to trigger the procedure to minimize its learning
overhead. A hybrid approach is used in the design of M Coordinator, whose metric selection
procedure can be triggered by both timers and special events, such as a moving average of the
end-to-end latency of workﬂows is 50% higher/lower than the one measured in the previous
steps.

4

Evaluation

In this section we study the impact of hardware and software factors on the performance
of realistic scientiﬁc workﬂows using WOWMON. In addition, we illustrate how its adaptive
proﬁling technique helps reduce the volume of performance data at runtime. For evaluation
we used an on-site cluster ACISS hosted at University of Oregon. The cluster includes 128 12core Intel Xeon CPU X5650 2.67 GHz nodes running RedHat Enterprise release 6.6. All nodes
are interconnected with a Voltaire Vantage 8500 10GigE network switch. The WOWMON
library and related tools were compiled with the latest release of TAU [22], EVpath [5], and
1512

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

ADIOS [1]. With respect to software conﬁgurations, QueueDepth for ADIOS is set to 20. We
run one LAMMPS process per core unless speciﬁed otherwise.

4.1

Driving Scientiﬁc Workﬂows

We instrumented LAMMPS (Large Scale Atomic/Molecular Massively Parallel Simulator) [15]
and its analytics Bonds and Csym, which are executed concurrently as the driving scientiﬁc
workﬂow in the experiments. LAMMPS has been widely used for material science study.
Bonds reads input from LAMMPS and performs all-nearest neighbor calculation to determine
which atoms are bonds together. Csym then uses the output of Bonds to further determine
whether there are deformation zones in the material. If they are detected, Csym continues
to calculate the conditions under which a crack occurred. Therefore, its execution time and
resource utilization may change over the whole period of simulation.
We manually select 12 metrics related to key functions of the LAMMPS workﬂow for tracing.
As shown in Table 2, the metrics, such as bonds read input and csym output results, are related
to I/Os for moving data from upstream applications to downstream analytics or to disks.
And the metrics such as bonds compute send and csym compute send are related to computing
kernels of Bonds and Csym, respectively. The other metrics are used to measure memory usage
of a function. For example, csym compute send mem measures the heap size of the function
csym compute send.

4.2

The End-to-end Latency of the LAMMPS Workﬂow

The end-to-end latency of the LAMMPS workﬂow determines the time spent on analyzing
physics of atoms using data generated by LAMMPS. We added 90 lines of code for source instrumentation of the metrics listed in Table 2. WOWMON can help capture transient behavior
of workﬂows. To demonstrate this we show a breakdown of the end-to-end latency after completion of each simulation step during the execution of the LAMMPS workﬂow. The number
of processes of LAMMPS, Bonds, and Csym are set to 128, 1, and 1, respectively.
From Figure 3, we observed that the end-to-end latency reached the maximum at the 42th
step. According to its execution time breakdown, we found that during the execution of the
workﬂow compute times of all the components did not change. In contrast, data transfer time
is increased by 110% on average for both LAMMPS and Csym. With a careful study of this
performance issues oﬄine, we found the reason is that the ADIOS library uses in-memory
queues to buﬀer output data of upstream applications for asynchronous execution. When the
buﬀers became full after the 42th step, queuing time was dominant in the data transfer time
as well as in the end-to-end latency.

4.3

Impact of a Workﬂow Mapping Policy

Given the same number of compute nodes, the policies of mapping processes of workﬂow components to nodes may signiﬁcantly impact the end-to-end latency of scientiﬁc workﬂows. Using
LAMMPS as an example, we demonstrate the performance diﬀerence between two mapping
policies given 11 compute nodes. More speciﬁcally, P olicyCB has Csym and Bonds placed on
a dedicated node, while LAMMPS is executed on the other 10 nodes. There is no resource
contention between LAMMPS and Csym or LAMMPS and Bonds. P olicyCL has Csym and
LAMMPS placed on the same nodes sharing memory and CPU resources. The above policies
are diﬀerent from the mapping policy used in the previous experiments in which processes use
dedicated cores. In the experiment, LAMMPS, Bonds and Csym are conﬁgured with 128, 1,
1513

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Metric name
bonds read input
bonds list output
bonds compute send

bonds read input mem
bonds compute send mem
csym read input
csym compute send
csym output results

csym read input mem
csym compute send mem
lammps start timer
csym stop timer

Zhang et al.

Description
Gives us a handle on throughput for reading data in
Bonds.
Gives us a handle on throughput for moving data out
of Bonds.
Monitors the main computation function in Bonds.
Most of its time is spent on building the adjacentformat output.
The memory usage for executing bonds read input()
The
memory
usage
for
executing
bonds compute send()
Gives us a handle on throughput for reading data in
Csym.
Monitors the main computation function in Csym.
Most of its time is spent on converting input data.
The corresponding function,
which follows
csym output results(), denotes the end of the
workﬂow and where we end the latency measurement.
The
memory
usage
for
executing
csym read input mem()
The
memory
usage
for
executing
csym compute send mem()
The timer is triggered when the generated data is
placed in buﬀers on LAMMPS end.
The timer is triggered when the last analytic ﬁnishes.

Table 2: The selected metrics for the LAMMPS workﬂow

Figure 3: An execution time breakdown. X-(Tran) and X-(Comp) denote data transfer time
and compute time of application X (Csym, Bonds, and LAMMPS), respectively.

and 1 processes, respectively. The end-to-end latency of each step with both P olicyCB and
P olicyCL are shown in Figure 4. The average end-to-end latencies are 35.6s and 40.0s for
1514

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

Figure 4: The end-to-end latency of the LAMMPS workﬂow with diﬀerent policies of mapping
processes of in-situ analytics to the compute nodes.

P olicyCB and P olicyCL , respectively. One observation is that from the 1st to 14th step the
end-to-end latency with P olicyCB is higher. When the buﬀers for storing data for in-situ analysis are full after the 20th step, P olicyCB has smaller latency than P olicyCL since LAMMPS
is more compute-intensive than Bonds. And extra interference between LAMMPS and Csym
with P olicyCL caused the higher latency.

4.4

Eﬀectiveness of Self-adaptive Proﬁling

In this section, we study the correlation between selected proﬁling metrics and the performance
of the LAMMPS workﬂow. In the experiment, the workﬂow is executed with 64 processes
for LAMMPS, 2 processes for Bonds, and 1 process for Csym. Using the performance data
collected from 1000 simulation steps as training data, the machine learning algorithm found
one best metric subset including bonds read input, csym read input, and csym compute send.
This result is consistent with our understanding that Csym is the bottleneck of the workﬂow
for lack of parallelism in its design. We further measured the execution times of the functions
corresponding to the selected metrics and found that they together account for about 46% of
the average end-to-end latency. Figure 5 shows the results. This explains why they can be
representative of the overall latency.
In addition, we evaluate the predictability of the models created based on either the selected
metrics or the original metric set using a regression tree algorithm [23]. In detail, we created two
machine learning models, M odel interest based on the three selected metrics and two timers,
and M odel init based on the metrics in M etricSet init as presented in Section 3.4. Both
models use the selected metrics to predict the end-to-end latency of the workﬂow. 80% and
20% of the training set are used for creating a model and model validation, respectively. The
validation results show that M odelinterest and M odelinit have relative absolute errors of 9.4%
and 13.6%, respectively. This means M etricSetinterest has better predictability than M odelinit
because the accuracy of M odel interest is improved for less noises from the low-impact metrics
in M etricSetinterest . Therefore, using M etricSetinterest for monitoring can reduce the total
amount of data transferred by 54% for the LAMMPS workﬂow without losing key metrics for
performance debugging.
1515

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

Figure 5: Execution times of the key functions of the LAMMPS workﬂow over 100 simulation
time steps.

Figure 6: Total execution time of the LAMMPS workﬂow. TAU: applications run with the
TAU proﬁler; WOWMON: applications run with WOWMON.

4.5

Overhead Analysis

There are three major sources of overhead in WOWMON. The ﬁrst is proﬁling overhead, which
has been well studied in many existing tools. WOWMON relies on these tools to provide
scalable proﬁling services on various machines [16]. The second overhead is networking latency.
We experimentally study the networking overhead of WOWMON compared to TAU, which
is the default proﬁler in WOWMON. In the experiment, LAMMPS workﬂow is executed on
ACISS with increased parallelism of LAMMPS from 32, 64, to 128 and one process for Bonds.
As shown in Figure 6, the execution time with WOWMON is on average 7% more than that
running with TAU alone. Its overhead grows sublinearly as the number of processes is increased.
Third, WOWMON causes the memory overhead for maintaining performance data buﬀer at
runtime. The size of the buﬀer is determined by the number of metrics in M etricSetinterest .
For the LAMMPS workﬂow its buﬀer size is less than 20 KB with 128 processes.
1516

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

5

Zhang et al.

Conclusion and Future Work

In the paper we present the design and implementation of WOWMON, a lightweight and powerful monitoring infrastructure, speciﬁcally designed for scientiﬁc workﬂows with in-situ analytics
targeting large-scale computing platforms. It enables the online observation of adaptive workﬂow behavior. Evaluation with real scientiﬁc workﬂows shows that workﬂow performance can
be aﬀected by both software and hardware factors, such as the policy of process mapping and
the size of memory buﬀer for in-situ processing. In addition, we show that WOWMON can
automatically rank the correlation of each metric relative to the end-to-end latency of workﬂows
using machine learning algorithms and reduce monitoring overhead with self-adaptive proﬁling/tracing. The overhead of WOWMON is 7% on average compared to the legacy proﬁling
tools, making it well suit for online performance monitoring and analysis.
Future work for WOWMON will focus on the study of the eﬀect of performance metrics
across diﬀerent runs with various input parameters to analytics (e.g., R 1 which determines
how close atoms are for Bonds). In addition, with the help of WOWMON, we need to further understand the changes of data-driven behaviors of scientiﬁc workﬂows in emerging HPC
platforms with deep memory hierarchies for caching in-situ output data.

6

Acknowledgements

We are grateful to the anonymous reviewers. We thank Jai Dayal and Matthew Wolf for
their support on the LAMMPS workﬂow instrumentation. We also thank Wyatt Spear for
many discussions during this work. This research was partially supported by DOE grant DESC0012381 funded by the Scientiﬁc Data Management, Analysis and Visualization (SDMAV)
program and WSU Seed Grant.

References
[1] Adaptable IO System (ADIOS).
https://www.olcf.ornl.gov/center-projects/adios/.
[2] S. Browne, J. Dongarra, N. Garner, G. Ho, and P. Mucci. A Portable Programming Interface
for Performance Evaluation on Modern Processors. International Journal of High Performance
Computing Applications, 14(3):189–204, 2000.
[3] Greg Eisenhauer and Karsten Schwan. An object-based infrastructure for program monitoring and
steering. In 2nd SIGMETRICS Symposium on Parallel and Distributed Tools (SPDT’98), pages
10–20, 1998.
[4] Greg Eisenhauer, Matthew Wolf, Hasan Abbasi, and Karsten Schwan. Event-based systems:
Opportunities and challenges at exascale. DEBS ’09, pages 2:1–2:10. ACM, 2009.
[5] EVpath Library.
http://svn.cc.gatech.edu/kaos/evpath/.
[6] Michael Gerndt, Andreas Schmidt, Martin Schulz, and R Wismuller. Performance analysis for
teraﬂop computers: a distributed automatic approach. In 10th Euromicro Workshop on Parallel,
Distributed and Network-based Processing, pages 23–30. IEEE, 2002.
[7] Weiming Gu, Greg Eisenhauer, Eileen Kraemer, Karsten Schwan, John Stasko, and Je rey Vetter.
Falcon: On-line monitoring and steering of large-scale parallel programs. In Proceedings of the 5th
Symposium of the Frontiers of Massively Parallel Computing, pages 422–429, 1995.
[8] Mark Hall, Eibe Frank, Geoﬀrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H.
Witten. The weka data mining software: An update. SIGKDD Explor. Newsl., 11(1):10–18, 2009.

1517

A Machine Learning-based Proﬁler for Self-adaptive Instrumentation

Zhang et al.

[9] Mark A. Hall. Correlation-based feature selection for machine learning. Technical report, 1999.
[10] Kevin A. Huck, Allen D. Malony Sameer Shende, and Alan Morris. TAUg: Runtime Global
Performance Data Access Using MPI. In EuroPVM/MPI 2006, 2006.
[11] Richard E. Korf. Depth-ﬁrst iterative-deepening. Artiﬁcial Intelligence, 27(1):97 – 109, 1985.
[12] Matthew L. Massie, Brent N. Chun, and David E. Culler. The ganglia distributed monitoring
system: Design, implementation and experience. Parallel Computing, 30:2004, 2003.
[13] Barton P. Miller, Jonathan M. Cargille, R. Bruce Irvin, Krishna Kunchithapadam Mark D.
Callaghan, Jeﬀrey K. Hollingsworth, Karen L. Karavanic, and Tia Newhall. The Paradyn Parallel
Performance Measurement Tools. Computer, 28:37–46, 1995.
[14] White Paper. Interconnect Analysis:10GigE and InﬁniBand in High Performance Computing.
HPC Advisory Council Network of Expertise.
[15] S. Plimpton, R. Pollock, and M. Stevens. Particle-Mesh Ewald and rRESPA for Parallel Molecular
Dynamics Simulations. In Proc of the Eighth SIAM Conference on Parallel Processing for Scientiﬁc
Computing, 2007.
[16] R.Bell, A.D. Malony, and S. Shende. A Portable, Extensible, and Scalable Tool for Parallel
Performance Proﬁle Analysis. In EUROPAR’ 03.
[17] Reliable UDP networking library.
http://enet.bespin.org/.
[18] Randy L. Ribler, Huseyin Simitci, and Daniel A. Reed. The autopilot performance-directed adaptive control system. In Future Generation Computer Systems, pages 175–187, 1997.
[19] Philip C. Roth and Barton P. Miller. On-line automated performance diagnosis on thousands of
processes. PPoPP ’06.
[20] S. Shende and A. D. Malony. TAU: The TAU Parallel Performance System. International Journal
of High Performance Computing Applications, pages 287–311, 2006.
[21] Cristian Tapus, I-Hsin Chung, and Jeﬀrey K. Hollingsworth. Active Harmony: Towards Automated Performance Tuning. In Supercomputing 2002, 2002.
[22] TAU Software.
https://www.cs.uoregon.edu/research/tau/downloads.php.
[23] Mengzhi Wang, Kinman Au, Anastassia Ailamaki, Anthony Brockwell, Christos Faloutsos, and
Gregory R. Ganger. Storage device performance prediction with cart models. pages 588–595, 2004.

1518

