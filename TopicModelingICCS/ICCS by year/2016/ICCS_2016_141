Procedia Computer Science
Volume 80, 2016, Pages 2256‚Äì2260
ICCS 2016. The International Conference on Computational
Science

Cost-beneÔ¨Åt analysis and exploration of
cost-energy-performance trade-oÔ¨Äs in scientiÔ¨Åc computing
infrastructures
Pablo Llopis1 , Gabriel G. CastaÀú
n¬¥e2 , and Jesus Carretero1
1
University Carlos III of Madrid
{pllopis,jcarrete}@arcos.inf.uc3m.es
2
Dublin City University
gabriel.gonzalezcastane@dcu.ie

Abstract
In this work, we demonstrate how a cost-beneÔ¨Åt analysis of diÔ¨Äerent scenarios reveals insights
into trade-oÔ¨Äs between cost, performance, and energy for speciÔ¨Åc scientiÔ¨Åc computational workloads. We leverage simulation to Ô¨Ånd a cluster conÔ¨Åguration that will oÔ¨Äer the lowest total cost
of ownership for a scientiÔ¨Åc cluster. We also analyze at what point in time a hardware upgrade
becomes beneÔ¨Åcial, taking into account performance/watt improvements and hardware devaluation. This knowledge enables a person responsible for planning, designing, and managing the
life cycle of a scientiÔ¨Åc computing infrastructure to Ô¨Ånd a cost-eÔ¨Äective solution tailored to their
speciÔ¨Åc applications and resource utilization patterns. We demonstrate that quite substantial
cost savings can be achieved by using this methodology.
Keywords: ScientiÔ¨Åc computing, total cost of ownership, infrastructure, energy eÔ¨Éciency, costeÔ¨Äectiveness, cost-beneÔ¨Åt, analysis

1

Introduction

Running computing facilities incur a lot of expenses which are not only due to the equipment
needed to run them. One of main contributing factors to expenditure is related to operating
costs. In fact, those related to power usage have long been expected to outgrow the annualized capital expenditure. These trends have been referred to as ‚ÄúThe economic breakdown of
Moore‚Äôs law‚Äù [3]. This is due to the fact that power per dollar has been growing in relation to
equipment cost per dollar. As this trend continues, the economics of information technology
are experiencing a rapid change.
The main goal of this work is to provide deeper insights into the economic aspects of a
scientiÔ¨Åc computing facility, revealing the architectural conÔ¨Ågurations that provide the most
cost-eÔ¨Äective and eÔ¨Écient solutions. Doing this results in a non-trivial task due to the existing
2256

Selection and peer-review under responsibility of the ScientiÔ¨Åc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.402

Cost-beneÔ¨Åt analysis of cost-energy-performance trade-oÔ¨Äs

Llopis, CastaÀú
n¬¥e, and Carretero

trade-oÔ¨Äs between cost, performance, and energy eÔ¨Éciency. We demonstrate how the TCO
(Total Cost of Ownership) of a computing facility can be minimized by selecting hardware
speciÔ¨Åcally tailored for a scientiÔ¨Åc computing problem. We achieve this goal by leveraging
simulation techniques and an economic model that includes capital and operational expenses.
The methodology followed in this work is application-independent, but we demonstrate its
eÔ¨Äectiveness focusing on a speciÔ¨Åc scientiÔ¨Åc application. We model a speciÔ¨Åc target application
on a trusted simulation platform, and validate its performance and energy prediction accuracy
using an existing physical cluster. We then simulate this application on a large number of
cluster conÔ¨Ågurations to obtain cost-performance trade-oÔ¨Äs which allow us to select the cluster
conÔ¨Åguration with the lowest TCO.
This paper is structured as follows. Section 2 discusses related work. In Section 3 we validate
the predictive capabilities of the simulations of our target application. In Section 4 we Ô¨Ånd the
cluster conÔ¨Åguration with the lowest TCO. Section 5 concludes.

2

Related Work

This work has similarities to several publication which aim to reduce cost of scientiÔ¨Åc computing
infrastructures. In [4], MapReduce applications are modeled after Hadoop and simulated using
the same simulation platform. In the work by A. Nunez et al. [6], MapReduce applications are
evaluated as well, where multiple cluster hardware conÔ¨Ågurations are simulated. Koomey et al.
have done extensive research on the true cost of data centers, and have published studies on
the impact and implications of diÔ¨Äerences between the growth of performance per server cost
and performance per watt [5]. In contrast to existing research, our work demonstrates that the
total cost of an infrastructure can be reduced by optimizing the trade-oÔ¨Äs between hardware
cost, energy consumption, and performance. It focuses on minimizing total cost of ownership
by taking into account not only capital expenditure costs, but also operating expenditure costs
directly related to power usage and energy consumption.

3

Overview of the simulation platform and application
model validation

We leverage an existing cluster and cloud simulation platform to predict the performance and
energy consumption. The iCanCloud simulation platform is oriented towards the simulation of
diÔ¨Äerent kinds of cluster and cloud computing systems and their underlying architectures and
has already been used to model cloud environments accurately [6]. This framework provides
very high detailed models for Ô¨Åle systems, disk drives, volume managers, block cache, block
schedulers, etc. The project was initiated in 2010 and is currently available as open source
software [1]. We leverage this framework to model NASA‚Äôs NAS Parallel Benchmark (NPB)
Block-Tridiagonal (BT) application and demonstrate that we are able to produce results that
exhibit a behavior comparable to that of the physical infrastructure.
The NAS Parallel Benchmarks were developed by NASA to evaluate parallel programming
models and machines, and have become widely used for the past two decades. In this paper,
we use the MPI implementation of the NPB-BT workload, which is derived from 3-dimensional
Computational Fluid Dynamics (CFD) code, and used in the aircraft industry, research centers,
and academia. It features the Alternating Direction Implicit algorithm [2], where time-varying
data dependencies play a big role. We developed a model based on the analytical model
provided by [7], using asynchronous send and receive operations, matching NASA‚Äôs Fortran
2257


















	







	

Llopis, CastaÀú
n¬¥e, and Carretero


	









Cost-beneÔ¨Åt analysis of cost-energy-performance trade-oÔ¨Äs










	



(a) Measured execution time versis simulated time.







	




(b) Measured consumed energy versus
simulated energy

Figure 1: Validation comparing measured and simulated total execution time andn energy
consumption for executions of NPB-BT using 9, 16, 36, and 64 processors.
implementation. We run this model on the simulator and compare predicted performance
and energy consumption to that of our physical infrastructure to validate the model on our
simulation platform.
The application is run on our physical infrastructure. Three identical nodes consist of four
Xeon E7-4807, 128GB of ECC RAM, and 10Gb Ethernet. NPB-BT is run with the following
parameters. A grid size of 162 √ó 162 √ó 162, 200 iterations, and a time-step of 0.0001. This
execution is repeated at least 5 times using 9, 16, 36, and 64 processes.
Figure 1 depicts simulated time and energy, compared to the actual total execution time
and measured energy consumption. The results of our validation show that our simulation and
application model produces accurate results, very similar to that of our physical infrastructure.
The critical aspect that is of concern is that, while diÔ¨Äerent hardware conÔ¨Ågurations might
produce diÔ¨Äerent absolute values, the diÔ¨Äerence between two executions in a physical environment will match that of two simulations with corresponding parameters. Consequently, the
simulation framework being used exhibits the same trends of physical executions.

4

Cost-eÔ¨Äective hardware conÔ¨Åguration

In this section, we perform a cost-beneÔ¨Åt analysis by exploring diÔ¨Äerent sets of cluster conÔ¨Ågurations in order to Ô¨Ånd the most cost-eÔ¨Äective solution for a scientiÔ¨Åc cluster when running
NPB-BT. The motivation behind this reasoning is that each component has a diÔ¨Äerent cost
and provides diÔ¨Äerent performance and power consumption trade-oÔ¨Äs. Moreover, depending on
the target application being run, some components will make a greater contribution to performance and energy usage than others. The goal of these experiments is to establish the most
cost-eÔ¨Äective cluster conÔ¨Åguration out of a set of possible components, and a target scientiÔ¨Åc
application. The criterion for establishing the cost of the scientiÔ¨Åc computing facility is the
total cost of ownership (TCO). We deÔ¨Åne the TCO using the following economic model.
T CO = CapEx + OpEx
Where CapEx stands for capital expenditure, in this case the infrastructure acquisition cost.
this includes CPU, memory, storage, and networking equipment.
OpEx stands for operational expenditure, meaning the cost of running the infrastructure.
We focus on power usage and consider that our facility has a typical PUE (Power Usage EÔ¨Äectiveness) of 2.
Next, the components listed in Table 1 are combined to generate node conÔ¨Ågurations of a
homogeneous cluster. Each of these conÔ¨Ågurations is used to evaluate run-time and energy when
2258




	



	


	


Cost-beneÔ¨Åt analysis of cost-energy-performance trade-oÔ¨Äs



















	
	



Llopis, CastaÀú
n¬¥e, and Carretero

E5-2695v3 1GbE
E5-2650Lv3 1GbE
E5-2650Lv2 1GbE
E5-2650L 1GbE
E5-2695v3 10GbE
E5-2650Lv3 10GbE
E5-2650Lv2 10GbE
E5-2650L 10GbE





Figure 2: Cost-performance trade-oÔ¨Äs for each Figure 3: CPU and network performance-TCO
trade-oÔ¨Äs.
of the 48 conÔ¨Ågurations.
running NPB-BT, producing a cost-execution time matrix. Note that by leveraging simulation
we are able to compute cost taking into account the energy consumption and performance
patterns speciÔ¨Åcally tailored to our application.
Category
Switch
Switch
Network card
Network card
Storage
Storage
Storage
Memory
CPU
CPU
CPU
CPU

Product name
Cisco WS-C4948-10GE-S Catalyst 4948-10GE 48 Port Switch
Cisco WS-C2960S-48TS-S 2960 48 Port Gigabit Switch
Supermicro AOC-CTG-i1S Single-Port 10GBE
1GbE Ethernet Card
Seagate 1TB ST1000NM0033
Seagate 3TB ST3000NM0053
Samsung 840 EVO 250GB SATA 3
Kingston 16GB 1600Mhz KVR16R11D4/16
Intel Xeon Processor E5-2650L
Intel Xeon Processor E5-2650L v2
Intel Xeon Processor E5-2650L v3
Intel Xeon Processor E5-2695 v3

Price (USD)
4122
1134
299.99
0 (builtin)
93.96
190
112.99
175.99
1107
1219
1329
2424

Table 1: Listing of components used to create system conÔ¨Ågurations by generating all possible
combinations. We assume 1GbE ports do not incur additional cost.
Moreover, for each selected component we consider two possible node conÔ¨Ågurations; one
with 2x 16GB RAM sticks, and one with 4x 16GB RAM sticks. We consider a scientiÔ¨Åc cluster
made up of 128 nodes and three networking switches. In total, we produced a matrix of 48 total
possible cluster conÔ¨Ågurations (4 CPUs, 2 memory sizes, 3 storage devices, and 2 networks).
These data are then used to feed the simulation models, jointly with our application model
and producing the matrix of results. The amount of work and problem size performed in each
simulation is Ô¨Åxed. For each simulation, we obtain total execution time and energetic cost.
Figure 2 depicts a scatter plot of the resulting 48 conÔ¨Ågurations, showing trade-oÔ¨Äs between
performance and TCO, considering a PUE of 2 and 10 years of operation. The results reveal
that for this scientiÔ¨Åc application, storage and memory do not play a big role. The application
seems to be CPU and network bound. Therefore, conÔ¨Ågurations with more RAM and better
storage are more expensive due to higher component cost without contributing to improved
performance. NPB-BT does a lot of neighbor communication, where 10GbE networking is
beneÔ¨Åcial. However, whether to invest in 10GbE networking equipment is not trivial due to
their elevated cost. In light of the results, it is clear that investing in 10GbE networking
equipment is a cost-eÔ¨Äective option for this application.
Figure 3 depicts a scatter plot that is a subset of all 48 conÔ¨Ågurations. This picture focuses on
CPU and networking for depicting trade-oÔ¨Äs between Performance and TCO, since it has been
established through the examination of results that these two components provide the greatest
impact on performance and TCO. Each color is a diÔ¨Äerent CPU, with rhombuses representing
1GbE cluster conÔ¨Ågurations, and triangles representing 10GbE cluster conÔ¨Ågurations. The
results show that in our particular case, the cluster conÔ¨Åguration that results in the lowest
2259

Cost-beneÔ¨Åt analysis of cost-energy-performance trade-oÔ¨Äs

Llopis, CastaÀú
n¬¥e, and Carretero

TCO is the one comprised of nodes with Xeon E5-2650L v2, 10GbE networking, Seagate 1TB
drives, and 2x Kingston 16GB 1600Mhz. As was already mentioned, the objective of this work is
not to present a speciÔ¨Åc conÔ¨Åguration for minimizing the TCO for NPB-BT, but to demonstrate
that we can leverage this methodology for matching the appropriate infrastructure components
to an arbitrary speciÔ¨Åc computational problem, providing potentially big cost savings. We note
that the greatest TCO doubles the smallest, leading to a total cost saving of over 330,000 USD.
Consequently, we conclude that our approach can yield substantial cost savings.

5

Conclusions

In this work, we have demonstrated a methodology that leverages simulation techniques for
performing a cost-beneÔ¨Åt analysis and Ô¨Ånding a cluster conÔ¨Åguration optimized for scientiÔ¨Åc
applications that minimizes the total cost of ownership. While we have focused on the BT
application of NAS Parallel Benchmarks, the same methodology could be applied to any application. The analysis we have performed gives us important insights into the trade-oÔ¨Äs between
total cost, performance, and energy, enabling important capital expenditure and operating expenditure cost savings. We have provided answers to the question of which cluster conÔ¨Åguration
produces the lowest TCO, taking into account a speciÔ¨Åc workload and infrastructure utilization
patterns. This work demonstrates how we can estimate the point in time when it becomes
economically beneÔ¨Åcial to perform cluster infrastructure upgrades.

Acknowledgements
This work has been partially supported by the EU under the COST Programme Action IC1305,
Network for Sustainable Ultrascale Computing (NESUS), by the grant TIN2013-41350-P, Scalable Data Management Techniques for High-End Computing Systems from the Spanish Ministry
of Economy and Competitiveness, and by the European Unions Seventh Framework Programme
under grant agreement 610711 (CACTOS).

References
[1] The iCanCloud Simulation Platform, 2015. http://www.icancloud.org/.
[2] R. M. Beam and R. F. Warming. An implicit Ô¨Ånite-diÔ¨Äerence algorithm for hyperbolic systems in
conservation-law form. Journal of Computational Physics, 22(1):87‚Äì110, 1976.
[3] K. G. Brill. The invisible crisis in the data center: The economic breakdown of moores law. white
paper, Uptime Institute, 2007.
[4] G. G. CastaÀú
n`e, A. N¬¥
unez, R. Filgueira, and J. Carretero. Dimensioning scientiÔ¨Åc computing systems
to improve performance of map-reduce based applications. Procedia Computer Science, 9:226‚Äì235,
2012.
[5] J. G. Koomey, C. Belady, M. Patterson, A. Santos, and K.-D. Lange. Implications of recent trends
in performance, costs, and energy use for servers. The Green Computing Book: Tackling Energy
EÔ¨Éciency at Large Scale, page 297, 2014.
[6] A. N¬¥
un
Àúez, C. Andr¬¥es, and M. G. Merayomg. Optimizing the trade-oÔ¨Äs between cost and performance
in scientiÔ¨Åc computing. Procedia Computer Science, 9:498‚Äì507, 2012.
[7] R. F. Van der Wijngaart, S. Sridharan, and V. W. Lee. Extending the bt nas parallel benchmark
to exascale computing. In High Performance Computing, Networking, Storage and Analysis (SC),
2012 International Conference for, pages 1‚Äì9. IEEE, 2012.

2260

