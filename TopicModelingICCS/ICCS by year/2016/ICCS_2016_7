Procedia Computer Science
Volume 80, 2016, Pages 2053–2061
ICCS 2016. The International Conference on Computational
Science

On the Performance, Scalability and Sensitivity Analysis of
a Large Air Pollution Model
Tzvetan Ostromsky1 , Vassil Alexandrov2,3 , Ivan Dimov1 , and Zahari Zlatev4
1

4

Institute of Information and Communication Technologies,
Bulgarian Academy of Sciences,
Acad. G. Bonchev, bl. 25A, 1113 Soﬁa, Bulgaria
ceco@parallel.bas.bg, ivdimov@bas.bg
2
ICREA – Barcelona Supercomputing Centre (BSC-CNS),
Carrer Jordi Girona 29, E-08034 Barcelona, Spain
vassil.alexandrov@bsc.es
3
Distinguished Visiting Professor in Computational Science,
Technologico de Monterrey (ITESM), Campus Monterrey, Mexico
National Centre for Environment and Energy, University of ˚
Arhus,
Frederiksborgvej 399 P.O. Box 358, DK-4000 Roskilde, Denmark
zz@dmu.dk

Abstract
Computationally eﬃcient sensitivity analysis of a large-scale air pollution model is an important issue we focus on in this paper. Sensitivity studies play an important role for reliability
analysis of the results of complex nonlinear models as those used in the air pollution modelling.
There is a number of uncertainties in the input data sets, as well as in some internal coeﬃcients, which determine the speed of the main chemical reactions in the chemical part of the
model. These uncertainties are subject to our quantitative sensitivity study. Monte Carlo and
quasi-Monte Carlo algorithms are used in this study.
A large number of numerical experiments with some special modiﬁcations of the model
must be carried out in order to collect the necessary input data for the particular sensitivity
study. For this purpose we created an eﬃcient high performance implementation SA-DEM,
based on the MPI version of the package UNI-DEM. A large number of numerical experiments
were carried out with SA-DEM on the IBM MareNostrum III at BSC - Barcelona, helped us
to identify a severe performance problem with an earlier version of the code and to resolve it
successfuly. The improved implementation appears to be quite eﬃcient for that challenging
computational problem, as our experiments show. Some numerical results with performance
and scalability analysis of these results are presented in the paper.
Keywords: air pollution model, DEM, MPI, parallel algorithm, scalability, performance, speed-up,
supercomputer, sensitivity analysis

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.525

2053

Performance, Scalability and SA of an Air Pollution Model

1

Ostromsky, Alexandrov, Dimov, Zlatev

Introduction to sensitivity analysis

In a popular deﬁnition (due to A. Saltelli [11]), sensitivity analysis (SA) is the study of how
uncertainty in the output of a model can be apportioned to diﬀerent sources of uncertainty in
the model input. The uncertainties in the model input can be due to various reasons: inaccurate
measurements or calculation, approximation, data compression, etc.. In order to measure the
speciﬁc contribution of the uncertainty in each input parameter, considered to be a potential
source, the sensitivity indices (SIs) have been introduced. Two kinds of sensitivity analysis have
been discussed in the literature: local and global. Here we focus on global SA, which takes into
account the whole domain of variation changes in the set of input parameters, and apportions
the output uncertainty to the uncertainty in the input data. In particular, we search for eﬃcient
numerical algorithms for computing the global sensitivity indices (SIs) for the Uniﬁed Danish
Eulerian Model (UNI-DEM) [16]. This large-scale model is described by a large system of
partial diﬀerential equations (the number of equations being equal to the number of chemical
species studied by the model). In dependence with the resolution of the discretization grid, the
size of the ﬁnal numerical problem can reach several millions of equations. This means that
enormous computational tasks arise in the treatment of such a large-scale air pollution model,
and great diﬃculties arise even when modern high-performance computers are used.
Therefore, it is highly desirable to simplify as much as possible the model. A careful sensitivity analysis is needed in order to decide where and how simpliﬁcations can be made. On
the other hand, air pollution modelers might ask the extent to which their results depend on
assumptions of initial conditions, boundary conditions, or chemical reaction rate constants.
This analysis can give valuable information about how precise the model output is and identify
which variables should be investigated more closely if the uncertainty is unacceptably high.
The goals may be to rank the importance of input variables, improve precision, screening, and
decision making.
Among quantitative methods, variance-based methods are the most often used [10]. The
main idea of these methods is to evaluate how the variance of an input or a group of inputs
contributes into the variance of an output variable. Variance-based methods deliver global,
quantitative and model-independent sensitivity measures. A general sensitivity concept, namely
the variance-based sensitivity analysis using a Monte Carlo technique, has been used in [6]. This
concept is sampling-based, that is why a Monte Carlo simulation is applied. The techniques
based on Monte-Carlo methods require a lot of simulations. The uncertain input parameters
are modeled by random variables and characterized by their probabilistic density functions.
The variance-based analysis focuses on the following questions: ”Which of the input variables
variances inﬂuences the model output variance at most?” and ”Which of the input variables has
to be known more accurately to reduce the output variance?”
The sensitivity analysis concept is used here to study the sesnsitivity of the output ozone
concentrations, calculated by the Danish Eulerian Model, with respect to some perturbations
in the intut data or uncertain parameters. More speciﬁcly, we introduced two kinds of perturbations: to the values of the input anthropogenic emissions and to some chemical reactions rate
coeﬃcients. This study can be used for increasing the reliability of the model, as well as for
identifying those parameters, which should be measured more precisely.
Let us consider a scalar function, representing some model output: u = f (x), where the input
parameters x = (x1 , x2 , . . . , xd ) ∈ U d ≡ [0, 1]d are assumed to be independent (non-correlated)
random variables with a known joint probability density function p(x) = p(x1 , . . . , xd ). In this
way the output u becomes also a random variable (as it is a function of the random vector x)
and let E be its mathematical expectation. Let D[E(u|xi )] be the variance of the conditional
2054

Performance, Scalability and SA of an Air Pollution Model

Ostromsky, Alexandrov, Dimov, Zlatev

expectation of u with respect to xi and Du - the total variance according to u. This indicator
is called ﬁrst-order sensitivity index by Sobol [12] or sometimes correlation ratio.
Total Sensitivity Index (TSI) [12] of an input parameter xi , i ∈ {1, . . . , d} is the sum of
the complete set of mutual sensitivity indices of any order (main eﬀect, two-way interactions
(second order), three-way interactions (third order), etc.):
= Si +
Sxtot
i

Sil1 +
l1 =i

Sil1 l2 + . . . + Sil1 ...ld−1 ,

(1)

l1 ,l2 =i,l1 <l2

where Sil1 ...lj−1 – j th order sensitivity index for the parameter xi (1 ≤ j ≤ d), j = 1 : Si
– the ”main eﬀect” of xi . According to the values of their total sensitivity indices, the input
parameters can be classiﬁed by the level of their importance. In most practical problems the
high dimensional terms are suﬃciently small and can be neglected, thus reducing signiﬁcantly
the number of summands in (1). In addition, a numerical approach for evaluating the small
sensitivity indices that combines reduction of the mean value and correlated sampling suggested
in [13] has been applied. Here we are not going into deeper details on the sensitvity analysis
matter, because the main purpose of this paper is to discuss the performance and scalability of
the numerical algorithms, used in this study. However, if the reader is particularly interested
in that topic, in [2, 4, 5] he can ﬁnd more detailed description, analysis and results of various
sensitivity analysis studies performed so far.

2

The Danish Eulerian Model – description, versions, parallelization

The Danish Eulerian Model (DEM) [15] is a large-scale air pollution model, used to calculate
the concentrations of various dangerous pollutants and other species over a large geographical
region (4800 × 4800 km), covering the whole of Europe, the Mediterranean and some parts of
Asia and Africa. It takes into account the main physical, chemical and photochemical processes
between the studied species, the emissions, the quickly changing meteorological conditions.
The Danish Eulerian Model is mathematicaly represented as a large system of partial diﬀerential equations (2), in which the unknown concentrations of a large number of chemical species
(pollutants and other chemically active components) take part. The main physical and chemical
processes (advection, diﬀusion, chemical reactions, emissions and deposition) are represented
as separate additive terms in the right-hand-side of this system.
∂cs
∂t

=

∂(ucs ) ∂(vcs ) ∂(wcs )
−
−
+
∂x
∂y
∂z
∂
∂cs
∂cs
∂
+
Kx
+
Ky
∂x
∂x
∂y
∂y

−

+

∂
∂z

+ Es + Qs (c1 , c2 , . . . cq ) − (k1s + k2s )cs ,

Kz

∂cs
∂z

+

(2)

s = 1, 2, . . . q .

Here it is a short description of the functions, participating in the above system:
• cs = cs (x, y, z, t) are the concentrations of the chemical species. All the functions described in the next items are also dependent on the space and time coordinates (x, y, z, t),
but for the sake of shortening the formulae they are usually not written explicitly.
• u, v, w – the components of the wind vector W (x, y, z, t) along the coordinate axes.
2055

Performance, Scalability and SA of an Air Pollution Model

Ostromsky, Alexandrov, Dimov, Zlatev

• Kx , Ky , Kz – diﬀusion coeﬃcients.
• Es – the emission functions.
• k1s , k2s – dry / wet deposition coeﬃcients.
• Qs (c1 , c2 , . . . cq ) – non-linear functions describing the chemical reactions between species
under consideration.

2.1

Numerical treatment of the model

The above large and rather complex system (2) is not suitable for direct numerical treatment.
For the purpose of numerical solution it is split into submodels, which represent the main
physical and chemical processes. The sequential splitting [7] is used in the production version
of the model, although other splitting methods have also been considered and tested in some
experimental versions [1].
Below the 3 basic submodels of DEM are given (obtained by using the most straightforward
sequential splitting scheme in accordance with the major physical and chemical processes).
[1]

[1]

∂cs
∂t

=

−

∂(ucs ) ∂(vcs )[1]
∂
−
+
∂x
∂y
∂x

[1]

Kx

∂cs
∂x

+

∂
∂y

[1]

Ky

∂cs
∂y

= A1 c[1]
s (t)

(3)

(horizontal advection and diﬀusion)
[2]

∂cs
∂t

=

[2]

[2]

[2]
[2]
Es + Qs (c1 , c2 , . . . c[2]
q ) − (k1s + k2s )cs = A2 cs (t)

(4)

(chemistry, emission and deposition)
[3]

∂cs
∂t

[3]

=

−

∂(wcs )
∂
+
∂z
∂z

[3]

Kz

∂cs
∂z

= A3 c[3]
s (t)

(5)

(vertical transport)

These submodels are solved numericaly in a cycle at each time step ti . The second and
[m]
third submodel at i-th time step use for initial values of cs (x, y, z, ti ) , m = 2, 3 the results
[m−1]
(x, y, z, ti ) of the previous submodel at the same time step, while the ﬁrst submodel uses
cs
[3]
for initial values the results cs (x, y, z, ti−1 ) of the third submodel at the previous time step
ti−1 .
Spatial and time discretization makes each of the above submodels a huge computational
task, challenging even for the most powerful supercomputers available nowadays. That is why
the parallelization has always been a key point in the computer implementation of DEM since
its very early stages. A coarse-grain parallelization strategy based on partitioning of the spatial
domain appears to be the most eﬃcient and well-balanced way on widest class of nowadays
parallel machines (with not too many processors), although some restrictions apply.
In the submodel for the vertical transport – Finite Elements, followed by θ-methods. We
should mention that it is possible to switch oﬀ the vertical transport submodel (optionally),
resulting in a simpliﬁed 2D version of the model with about 10 times less computational complexity, compared to the corresponding 3D version (the latter splits the atmosphere into 10
layers, in spite of the horizontal discretization step). The 2D version, although not so accurate,
is quite practical when the solution time is critical, and especially in case of insuﬃcient memory
of the computing system to execute the 3D version.
2056

Performance, Scalability and SA of an Air Pollution Model

2.2

Ostromsky, Alexandrov, Dimov, Zlatev

UNI-DEM package, features and parameters

The development and improvements of DEM throughout the years has lead to a variety of
diﬀerent versions with respect to the grid-size/resolution, vertical layering (2D or 3D model
respectively) and the number of species in the chemical scheme. The most prospective of them
have been united in the packege UNI-DEM. The available up-to-date versions, the selecting
parameters and their optional values are shown in Table 1.
Table 1: User-determined parameters for selecting an appropriate UNI-DEM version
Parameter Description
Supported optional values
NX = NY
NZ
NEQUAT

Grid size
(Grid step)
# layers (2D/3D)
# chemical species

96 × 96
(50 km)
1
35

288 × 288
(16.7 km)
10
56

480 × 480
(10 km)
168

A coarse-grain parallelization strategy based on partitioning of the spatial domain in strips or
blocks is currently used in UNI-DEM. For the purpose of this study, the strip-based distributed
memory parallelization of the model via MPI is used [3, 9]. It is based on partitioning of
the horizontal grid, which implies certain restrictions on the number of MPI tasks and requires
communication on each time step. Improving the data locality for more eﬃcient cache utilization
is achieved by using chunks to group properly the small tasks in the chemistry-deposition and
vertical exchange stages. Additional pre-processing and post-processing stages are needed for
scattering the input data and gathering the results, causing some overhead.

2.3

SA-DEM and its parallelization properties

A special parallel version (SA-DEM) of the UNI-DEM has been created to produce the necessary
data for our sensitivity analysis algorithm (see [2, 8] for more detail). It has been implemented
ﬁrst on the IBM Blue Gene/P platform at the Bulgarian Supercomputing Center.
SA-DEM is composed of the following three parts:
(i) A modiﬁcation of UNI-DEM with ability to modify certain parameters, subject to SA
study. By now we have been interested in some chemical rate constants as well as in
the input data for the anthropogenic emissions. A small number of input parameters is
reserved for this purpose.
(ii) A driver routine that automatically generates a set of tasks to produce the necessary
results for a particular SA study. It allows to perform in parallel a large number of runs
with common input data (reusing it), producing at once a whole set of values on a regular
mesh (used later for calculating the sensitivity indices).
(iii) An additional program for extracting the necessary mean monthly concentrations and
computing the normalised ratios to be analysed.
Signiﬁcant improvements of the ﬁrst version of SA-DEM were made by introducing two
additional levels of parallelism: top-level(MPI) and bottom-level(OpenMP). They allow us to
use eﬃciently the computational power of a typical state-of-the-art supercomputer cluster with
multicore nodes.
2057

Performance, Scalability and SA of an Air Pollution Model

Ostromsky, Alexandrov, Dimov, Zlatev

A new subroutine that splits the global communicator MPI COM WORLD and deﬁnes separate
communicators for each of the top-level parallel tasks is introduced in SA-DEM. The communicators are very useful on the lower level of parallelizm (where intensive communications are
performed on each time-step).

3

Numerical results from experiments with SA-DEM on
an IBM MareNostrum III supercomputer

In this section we present some scalability results (including execution times, speed-ups and
parallel eﬃciencies ), obtained from our experiments with SA-DEM on the largest supercomputer system in Spain - IBM MareNostrum III (managed by BSC - Barcelona). It consists of
3028 nodes IBM dx360 M4 (16 core) with 32 GB RAM per node. The total number of cores
is 48488 (Intel SandyBridge-EP E5-2670, 2600 MHz). It has total RAM more than 94 TB,
total disk storage about 1,9 PB and two interconnection networks (Inﬁniband / Gigabit Ethernet). The system has theoretical peak performance ∼ 1 PFLOPS. Table 2 contains results of
experiments on diﬀerent number of processors, showing the scalability of SA-DEM on the IBM
MareNostrum III machine at BSC.
Table 2: Time (T) in seconds and speed-up Sp of SA-DEM (ﬁnest grid) supercomputer IBM
MareNostrum III at BSC, Barcelona
Time and speed-up of SA-DEM (MPI only) on IBM MareNostrum III
(480 × 480 × 1) grid,
35 species,
CHUNKSIZE=16
#

#

CPU

nodes

10
40
80
160
320
640
960
1600

1
3
5
10
20
40
60
100

4

Advection
T [s]
Sp
83460
19448
9874
5250
2895
1522
1215
873

10
43
85
159
288
548
687
956

Chemistry
T [s]
Sp
77273
16946
9047
4562
2403
1269
822
502

10
46
85
169
322
609
940
1538

TOTAL
T [s]
Sp

E [%]

10
42
77
133
209
319
421
522

100 %
106 %
96 %
83 %
65 %
50 %
44 %
33 %

171707
40471
22261
12875
8233
5387
4075
3289

Improved data management parallel algorithm

In order to resolve the severe data transfer problem and to improve the total eﬃciency of the
SA-DEM, the following changes were made in the strategy for data transfer and management.
A small (ﬁxed) number of processors are used only for I/O procedures (global ﬁle transfer
and scatter/gather operations), as well as for exchange of data (via MPI) with the rest of the
processors. In particular, 11 processors are reserved for the 11 meteorological input data sets
and 5 - for the output data sets, (16 in total). The rest of the processors are executing the basic
algorithm without the above-mentioned (overhead-causing) operations. Recieving and sending
of (local) I/O data is done via MPI instead of reading/writing temporary ﬁles (normally, much
faster on most modern supercomputers). The number of opened ﬁles in a time is kept constant
2058

Performance, Scalability and SA of an Air Pollution Model

Ostromsky, Alexandrov, Dimov, Zlatev

(independent of the number of MPI processes). Part of the non-scalable overhead (producing
and using local temporary ﬁles) is fully avoided.
Table 3: Time (T) in seconds and speed-up Sp of SA-DEM (ﬁnest grid) with the improved data
management strategy on the Spanish supercomputer IBM MareNostrum III at BSC, Barcelona
Time and speed-up of SA-DEM (MPI only) on IBM MareNostrum III
(480 × 480 × 1) grid,
35 species,
CHUNKSIZE=16
#

#

CPU

nodes

10
56
96
176
336
656
976
1616

1
4
6
11
21
41
61
101

Advection
T [s]
Sp
83460
20117
10778
5219
2862
1491
1197
848

10
41
77
160
292
560
697
984

Chemistry
T [s]
Sp
77273
16695
9148
4409
2214
1162
772
479

10.00
46
84
175
349
665
1001
1614

TOTAL
T [s]
Sp

E [%]

10
44
79
153
257
441
601
778

100 %
79 %
83 %
87 %
77 %
67 %
62 %
48 %

169015
37983
21286
11080
6567
3833
2814
2173

Table 3 contains results of scalability experiments with the improved data management
version of SA-DEM (as described above) on the IBM MareNostrum III machine at Barcelona
are presented. As in 2, the times are for one year modelling period. The ﬁrst row of the table
(for 10 CPU) is taken from Table 2, as we cannot apply the new parallelization strategy on
16 CPU or less. Even on 2 - 3 times more CPUs, the new algorithm will not work eﬃciently,
as relatively large part of the CPUs will be used to deal with the communication and data
distribution overhead only (not so heavy when the number of parallel tasks is relatively small),
in contrast with the rest of the CPUs, which will be rather busy with the main computational
work. The eﬀect of this relatively poor load-balance can still be seen on the second row of the
table (where 40 out of 56 CPUs are engaged in executing the main computational work).
With increasing the total number of CPUs, however, this eﬀect disappears and we obtain
better results for the total speed-up and eﬃciency (in comparison with those for the basic
version, shown in Table 2 ). The tiny part of the processors, selected to deal with the I/O
transfer and scatter/gather operations, helps a lot to avoid the communication bottleneck and
to provide conditions for smooth and eﬃcient work for the rest (now – the vast majority) of
the CPUs executing in parallel the computational tasks. For the highest levels of parallelism
the new parallel algorithm appears to be much more eﬃcient.

5

Conclusions and plans for future work

From the results, obtained in our scalability experiments and shown above in this paper, the
following conclusions can be drawn:
(i) SA-DEM is an eﬃcient high performance tool, used to produce sensitivity analysis data
for the DEM. Its parallel implementations on the most powerful supercomputer in Spain, IBM
MareNostrum III, show very good scalability.
(ii) Chemistry, the most computationally expensive stage of DEM, has almost linear speedup in the whole range of experiments.
2059

Performance, Scalability and SA of an Air Pollution Model

Ostromsky, Alexandrov, Dimov, Zlatev

(iii) Advection stage scales pretty well in most of the experiments, with certain slow-down in
the highly parallel experiments (expected). It is caused by the signiﬁcant boundary overlapping
of the domain partitioning when approaching the inherent partitioning limitations.
(iv) With increasing the number of processors the time for I/O operations (non-scalable)
becomes strongly dominant. As a consequence, the total eﬃciency decreases with increasing
the CPU number (especially above certain high level of parallelizm in dependence with the grid
size).
(v) The above eﬀect has been signiﬁcantly reduced by improving the data management
strategy. It reduces the amount of I/O operations and executes part of them in parallel with
the computations on the other stages, a kind of pipelining between the I/O-intensive part
and the computationally-intensive stages of the model. The new data management strategy
improves the overall speed-up and eﬃciency of DEM and SA-DEM, as shown by experiments
on the IBM MareNostrum III supercomputer in BSC - Barcelona. These developments will
allow us to use widely the most detailed and, respectively, the most computationally expensive
ﬁnest-grid version in our future sensitivity studies of DEM.

Acknowledgments
This research is supported in parts by the Bulgarian NSF Grant Eﬃcient Parallel Algorithms
for Large Scale Computational Problems (DFNI # I 02/20). Barcelona Supercomputing Centre
(BSC) is kindly acknowledged too for granting us access and computer time for experiments on
their most powerful supercomputers.

References
´ Havasi, Z. Zlatev, Operator splitting and commutativity analysis in the
[1] I. Dimov, I. Farag´
o, A.
Danish Eulerian Model, Math. Comp. Sim. 67 (2004), pp. 217–233.
[2] I. Dimov, R. Georgieva, S. Ivanovska, Tz. Ostromsky, Z. Zlatev, Studying the Sensitivity of the
Pollutants Concentrations Caused by Variations of Chemical Rates, Journal of Computational and
Applied Mathematics Vol. 235, No. 2 (2010), pp. 391–402.
[3] I. Dimov, K. Georgiev, Tz. Ostromsky, Z. Zlatev, Computational challenges in the numerical
treatment of large air pollution models, Ecological Modelling 179, Elsevier (2004), pp. 187-203.
[4] I. Dimov, K. Georgiev, Tz. Ostromsky, Z. Zlatev, Sensitivity studies of pollutant concentrations
calculated by UNI-DEM with respect to input emissions, Central Europe Journal of Mathematics
Vol. 11, No 8 (2013), pp. 1531–1545.
[5] I. Dimov, R. Georgieva, Tz. Ostromsky, Monte Carlo Sensitivity Analysis of an Eulerian Largescale Air Pollution Model, Reliability Engineering and System Safety 107, Elsevier (2012), pp.
23–28.
[6] I. Dimov, Z. Zlatev, Testing the sensitivity of air pollution levels to variations of some chemical
rate constants, Notes on Numerical Fluid Mechanics 62 (1997) 167–175.
[7] G. I. Marchuk, Mathematical modeling for the problem of the environment, Studies in Mathematics
and Applications, No. 16, North-Holland, Amsterdam, (1985).
[8] Tz. Ostromsky, I. Dimov, R. Georgieva, Z. Zlatev, Sensitivity Analysis of a Large-scale Air Pollution Model: Numerical Aspects and a Highly Parallel Implementation, In: Large-Scale Scientiﬁc
Computations, LNCS-5910 (2010), Springer, pp. 197–205.
[9] Tz. Ostromsky, Z. Zlatev, Parallel Implementation of a Large-scale 3-D Air Pollution Model, Large
Scale Scientiﬁc Computing (S. Margenov, J. Wasniewski, P. Yalamov, Eds.), LNCS-2179, Springer
(2001), pp. 309–316.

2060

Performance, Scalability and SA of an Air Pollution Model

Ostromsky, Alexandrov, Dimov, Zlatev

[10] A. Saltelli, K. Chan, M. Scott, Sensitivity Analysis, Probability and Statistics series, John Wiley
& Sons (2000).
[11] A. Saltelli, S. Tarantola, F. Campolongo, M. Ratto, Sensitivity Analysis in Practice: A Guide to
Assessing Scientiﬁc Models, Halsted Press New York (2004).
[12] I.M. Sobol, Sensitivity estimates for nonlinear mathematical models, Mathematical Modeling and
Computational Experiment 1 (1993), pp. 407–414.
[13] I.M. Sobol, E. Myshetskaya, Monte Carlo Estimators for Small Sensitivity Indices, Monte Carlo
Methods and Applications 13 (5-6) (2007) pp. 455–465.
[14] WEB-site of the Danish Eulerian Model, available at:
http://www.dmu.dk/AtmosphericEnvironment/DEM
[15] Z. Zlatev, Computer treatment of large air pollution models, Kluwer, 1995.
[16] Z. Zlatev, I. Dimov, Computational and Numerical Challenges in Environmental Modelling, Elsevier, Amsterdam (2006).

2061

