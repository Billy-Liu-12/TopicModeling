Distributed Simulation of Amorphous Hydrogenated
Silicon Films: Numerical Experiments on a Linux Based
Computing Environment
Y.E. Gorbachev, M.A. Zatevakhin, V.V. Krzhizhanovskaya, A.A. Ignatiev,
V.Kh. Protopopov, N.V. Sokolova, and A.B. Witenberg
Institute for High Performance Computing and Data Bases
Fontanka 118, off. 55, St. Petersburg 198005, Russia
Gorbachev@hm.csa.ru
http://www.csa.ru/comphyga/PECVD

Abstract. Numerical scheme, grid generation and parallelization algorithm are
presented for numerical simulation of complex process of silicon-based films
growth in plasma enhanced chemical vapor deposition reactors. MPI-based
computing environment and advanced interactive software with graphic user
interface, real-time visualization system and Web access were recently
developed to provide distributed parallel multitask calculation and visualization
on Linux clusters. Analysis of system performance and cluster load balance
showed the bottlenecks of parallel implementation and the ways of algorithms
improvement.

Introduction
Numerical simulation of deposition process of amorphous hydrogenated silicon
(��Si:H) films, the widespread material in modern microelectronics, is an important
problem that has been solved over two recent decades. One of the most popular
technologies of silicon-based films production is plasma enhanced chemical vapor
deposition (PECVD), that has been studied for many years, so the knowledge about
physics and chemistry of this phenomenon is rather rich in details. Though dozens of
models were developed, describing the system with different levels of abstraction and
accuracy, even the most advanced models still can not take into account all the
numerous chemical kinetics, plasma physics and transport processes occur in
industrial PECVD reactors due to terrific amount of computational time needed for
thorough numerical simulation of the problem.
In that way, to find a balance between phenomenon knowledge and computational
resources available, not only new physical models are developed, but also new
rational numerical algorithms and computational environment are created, adjusted to
modern computing facilities.
The project described in this paper is aimed to the development of efficient general
purpose computer environment for large parameter space exploration of processes
under consideration and to creation of high-performance software for end users
working in chemical industry and for scientists studying PECVD processes.
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2073, pp. 483-491, 2001.
© Springer-Verlag Berlin Heidelberg 2001

484

Y.E. Gorbachev et al.

Although high performance is the vital factor for simulation of complex-shaped
essentially 3D plasma deposition reactors, especially if it should be a short-time
forecasting calculations for prediction and controlling of industrial processes, we
oriented not to the unique most powerful supercomputers, but to the widely used
Linux clusters, accumulated many virtues of parallel computers, and being the
cheapest facilities on the factor of FLOPS cost, that is quite important parameter for
scientific community. Nowadays, the maturity of clustering software, open sources
and easiness of clusters assembling make them more and more popular in highperformance computing.

Model Description
For numerical experiments with cluster computing environment recently developed,
2D approach was chosen for modeling of ��Si:H films deposition from radiofrequency discharge silane plasma. We used the most reliable and well-studied
method of computational fluid dynamics for simulation of the physical-chemical
processes occur in PECVD reactors, based upon full Navier-Stockes equations. Under
the conditions considered (characterized by low Mach and Reynolds numbers), for
unsteady laminar flow of viscous compressible chemically active N-component gas
mixture, these equations in conservation law 2D-form for a Cartesian coordinate
system can be written as [1]:

�
UdV � � ( F � G ) � dS � � HdV ,
�t V�
S
V

(1)

where t is time and U = ��, �ux , �uy , �e, �f1 ,..., �fN-1 � is a vector of conservative
variables (here � is density, ux, uy are velocity components, e is a total energy per mass
unit, fi is mass fraction of i-species), V is arbitrary gas volume and dS is outward
vector, normal to the element of surface S which encloses volume V. Flux vectors F
and G are associated with convective and viscous transfer correspondingly. Source
term H describes species production due to chemical reactions.
For calculation of the electron density, the hydrodynamic model of RF discharge
between two planar parallel electrodes was used [2]. The electron and ion continuity
equations were solved consistently with the Poisson equation for the electric field
distribution.
Boundary conditions taking into account slipping, sticking and deposition effects
for velocity, temperature and chemical components concentrations on the wall were
applied [3,4].
T

Numerical Scheme and Grid Generation
Physical processes factorization method [5] was used for solving equations.
According to this method the problem was split into inviscid and viscous "steps". At
the first one, implicit ENO-scheme [6] was used in combination with bidiagonal

Distributed Simulation of Amorphous Hydrogenated Silicon Films

485

algorithm [7] for implicit increment calculation, and for solving the "viscous" part, a
new implicit finite-deference scheme was developed on the basis of [8].
Since an ordinary PECVD reactor has a complex shape (for example, one of the
simplest reactors is shown on the figure 7), the multi-block grid generation algorithm
was used, when whole computational domain is divided into simple blocks, and then
in each block the regular grid is generated. The original method of mechanical
analogy with deformed body [9] was applied for generation of non-uniform grids in
non-rectangular blocks. The idea of this method is based upon solving equations of
elastic body deformation theory:
Let us consider the rectangular plate ABCD made of elastic material with
rectangular non-uniform grid plotted on it. Deformation of this plate, leading to the
desirable shape of the reactor block, will accordingly deform the grid lines, thus
creating the desired curvilinear grid. Figure 1 illustrates this approach. Grid points
coordinates in this case are calculated from the elliptic equations of the theory of
elasticity [9]. An example of multi-block grid for a complex geometry reactor is
shown at the figure 2.

Fig. 1. Plate deformation method for grid generation

Fig. 2. Example of multi-block grid

Parallelization
Working out the effective computing environment for parallel computing, different
levels of parallelization are considered. Because of the large number of parameters
which influence upon film deposition rate and properties (pressure, gas and substrate
temperatures, flow velocity, reactor volume and configuration, mixture composition
and numerous plasma characteristics), for thorough investigation of the system
behavior, many tasks with different initial conditions can be run in parallel on
different processors, providing thus exploration of a large parameter space. This way
of job-level parallelization is the most natural and efficient for many computational
fluid dynamic problems which require significant efforts for parallelization of
individual program algorithm and code. To utilize the advantages of this approach, a
task Manager environment was developed, looking after cluster processors idleness
and loading them with new jobs. When one of the processors finished its job, the
Manager initiates a process with new initial data set, running over the values of
parameters studied.

486

Y.E. Gorbachev et al.

However, this project is aimed to multipurpose multiscale simulation systems,
including 3D simulation and visualization of complex-shaped industrial reactors, that
implies terrifically heavy calculations, so parallelization on a task level is also needed.
The algorithm and its implementation will be described in the next section.
The last and the most difficult problem of parallelizing and load balancing is the
case when all the processors of computing cluster are already loaded with one or few
tasks, and a user with the same priority (tasks with the lower priority are simply queue
up) starts one or few more program(s). This problem recently arose when the
computational system was tested by remote users working with the server cluster
through the web-interface. The preliminary results of studying this problem are
described in the Results section.
Job-Level Parallelization Algorithm
The natural approach to solve unsteady computational fluid dynamic problem with
parallel computers is based on the following two obvious steps:
� Decomposition of computational domain into approximately equal sub-domains so
that their number is equal to number of processors.
� At each time iteration each processor calculates only own sub-domain and then
sends its results (decrements of variables) to the master processor (with rank 0).
The efficacy of this approach essentially depends on few factors:
� Simplicity of domain geometry, which permits to decompose whole domain into
approximately equal sub-domains;
� Spatial uniformity of physical parameters fields and equality of total amount of
operations to be done in every sub-domain;
� The ratio of data exchange time between two processes to calculation time for one
processor.
Typical domain of PECVD reactor is usually rather complex, so the trivial geometric
decomposition makes sub-domains unbalanced in number of grid points and total
calculations to be done. A specific decomposition algorithm was developed in order
to alleviate this imbalance. It is based upon multi-block regular grid with beam
distribution for parallelization.
According to this concept the whole calculation domain is divided into number of
primitive blocks which are mere boxes in 2D index space i and j. For example,
figure 3 shows a complex domain consisting of nine blocks. Each block is divided
into 4-face cells so that in the whole domain has two families of beams: beams in “i”
index direction and beams in “j” index direction. Each cell belongs to only one beam
of each family and each beam includes a sequence of cells with adjacent faces so that
one beam begins and finishes at the physical boundary (fig. 3).

Distributed Simulation of Amorphous Hydrogenated Silicon Films

Fig. 3. Nine block domain

487

Fig. 4. Beam grouping inside “i” list

This beams decomposition has one important advantage for parallelization. This
approach allows using uniform implicit scheme by applying sweep-type algorithms to
the single beam and then to distribute beams among the processors.
Thus, the parallel algorithm of calculation at one time iteration boils down to the
following steps:
� Formation of two lists of beams in two index directions (“i” list and “j” list) for the
given domain.
� Compilation of NP groups of beams inside each of two lists. (NP – number of
processors), so that each group has approximately equal number of cells.
From this point of view the best parallelization efficiency is achieved when the
number of cells in every index direction of each block is divisible by NP.
Otherwise beams are rearranged to meet the condition of approximate equality of
number of the cells per every block, but the load balance will not be ideal because
of some additional operations on the physical boundaries.
Figure 4 illustrates group distribution of beams for “i” list of our nine-blocks
domain from fig. 3 for four processors. One can see that in this case loading of all
processors is approximately equal. Similar grouping is made for “j” list.
� Based on this beam grouping, the work instructions are formed for each processor,
listing the beams to be calculated by every processor.
� In the beginning of each time iteration
master processor (with rank = 0) sends all
necessary information (conservative
variables at n-time level) to each slave
processor (with rank > 0) according to its
instructions. Each slave processor
receives the data and computes the beams
listed in its instructions.
� After performing its management duties,
master processor fulfills its own
calculation job and then waits for results
(decrements of conservative variables)
Fig. 5. Parallel algorithm

488

Y.E. Gorbachev et al.

from the slave processors. On receiving these results the Manager merges all data
arrays into one decrements filed and repeats the previous step.
Briefly this algorithm for 1 time iteration is illustrated on the figure 5.

Implementation
For implementation of numerical scheme and parallelization algorithm, MPI message
passing interface was used in combination with computational C++ core. To create a
high-end software, an advanced graphic user interface was designed. For its
realization we used C/C++ programming languages, widespread platform independent
GTK+ graphic library and free Glade programming system. The application
developed provides users with friendly intuitive interface that allows to control
computing process carried out on a server cluster, to visualize numerical results in
real-time (or postponed) mode, and to access chemical components data base or
results archive. All programs of the software package are platform independent, and
were compiled for OS Linux Red Hat 6.2.
To provide access to computational server for users studying PECVD process, the
interface of remote user was developed. One of the prevalent technologies used for
remote access to distributed computational resources is based upon Web browser as a
client application. For this interface, we created HTML pages, Java applets,
JavaScripts and CGI scripts. This system, like a local GUI, provides control over
calculations and graphical presentation of current physical parameters fields, that is
demonstrated on the figure 6.
We have tested the computing environment on two Linux clusters. One consists of
four two-processors nodes (each is Intel P-II 450 MHz with 512 Mb RAM) connected
with Myrinet network adapter, and the second is 32-processors cluster of Intel P-III
600 MHz with 512 Mb RAM and SCI network communication.
After in-deep analysis of existing API interfaces for MPI library to the Myrinet
communication environment, MPI-over-TCP was chosen, which allows to run many
programs on cluster nodes simultaneously.

Fig. 6. Remote user interface

Fig. 7. Simulation results: Si4H9 formation

Distributed Simulation of Amorphous Hydrogenated Silicon Films

489

Results and Discussion
A set of numerical experiments was carried out on a Linux-based computing
environment, to verify the computational physical-chemical model and to evaluate the
efficiency of parallelization algorithm. Reactor geometry, initial gas mixture and
plasma discharge parameters were chosen corresponding to the real experimental data
available [10]. Further details of the problem formulation can be found in [11].
Influence of different PECVD parameters on film growth and quality was studied,
using the job-level parallelization. Running in exclusive mode, this problem did not
cause imbalance of cluster processors load, thus a perfect efficiency was achieved
with implementation of the task manager controlling processors idleness.
Few distinctive computational results are presented on figures 7 and 8 for the
large-scale computational tasks. Here the influence of reactor geometry and pumping
path is shown. In the first case (fig. 7, 8a), gas mixture was pumped into the reactor
chamber through the inlets located outside discharge area, while in the second case
(fig. 8b) mixture flows through a pump tube connected to one of the electrodes.
Figure 7 shows the field of Si4H9 component (so called higher silane) concentration,
and figures 8a,b demonstrate silyl concentration, that is the main component,
contributing to the film growth.
���

���

��������� �
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
�

���
���
���

�
����
�
�
�

��
��

���

�
� ��
�
�
�
��

��������� ��
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���
������ ���

��

��
�

���

�� �

�

� �� ��

��

���

�

���

�

�����

��

Fig. 8. Simulation results: stream lines and silyl concentration field. a , b - different geometrical configuration of reactors

On the next stage of our work, parallelization efficiency on a task-level was
analyzed. Numerous tests showed that due to specificity of the problem, good results
of parallel algorithm implementation for an individual task is possible only for a
certain range of parameters, when communication overheads are minimal.
Figure 9 illustrates the typical performance result for ’unfavorable’ task. Here
speedup coefficient was calculated as the ratio of computing time with one processor
to computing time for the number processors used. Analysis of communication traffic
and workload balance showed, that freezing of speedup with number of processors is
caused by too large time of data exchange comparatively with calculation time at
every iteration.

490

Y.E. Gorbachev et al.

One possible way to improve this situation is
to replace consecutive exchange between
processors with more sophisticated algorithm
configured as a processor tree.
Some experiments with different Myrinet
communication environment drivers and versions
of MPI showed that it is possible to achieve
better performance (up to 30 %), but the tendency
of freezing speedup coefficient still remains,
especially for the middle-scale tasks, where
number of beams is not large enough and the fact
that their number is not divisible by total number
of processors plays a significant role in load
imbalance.

Fig. 9. Speed up coefficient

Besides, it is clear that the faster communications and the larger cash memory
would help to overcome the difficulties, but we believe that some advantages also can
be won by modification of the algorithms.
Working on the project, we discovered a new problem, when our simulation
environment on the cluster was open for remote testing and many parallelized
programs were submitted for execution on different number of processors. Serious
processors workload imbalance was revealed. Attempts of using standard free-ware
utilities, like queue,PBS,DQS, failed because algorithms used there do not suit the
specific features of the program. For example, queue looks for the least loaded
processor and sends a new process there. In the case of a large amount of data to be
sent and heavy network traffic, this operation makes the target processor workload
even less, and balance manager sends there one more task, collapsing whole
calculation process. Under these circumstances, development (or using already
produced) dynamic load balancing environment becomes the vital need on the way of
creating general purpose efficient software for scientific community.

Conclusion and Future Work
Model and numerical algorithm for simulation of amorphous hydrogenated silicon
films deposition were developed, MPI-based computing environment and advanced
interactive software with graphic user interface, real-time visualization system and
Web access were created, and large-scale parameter space investigations were
successfully carried out on two Linux clusters.
Task-level parallelization algorithm using multi-block regular grid with beam
distribution was applied for parallel implementation. It provided rather good
parallelization efficiency for this class of CFD problem. However, it turned out that
due to large communication overheads for most of the tasks considered, system
performance almost stops speeding up with increasing of processors number, after a
certain ’critical’ number. The modification of parallelization algorithm is planned in
order to eliminate possible bottlenecks, and some improvements will be made in

Distributed Simulation of Amorphous Hydrogenated Silicon Films

491

initial beams distribution among processors for better load balancing. Possible ways
of the communication environment modernization will be also investigated.
Considerable efforts should be made in development of dynamic load balancing
environment in order to create a multi-scale multi-user multi-purpose parallel server
software to provide an effective utilization of cluster computer power.

References
1.

Yu.V. Lapin, M.Kh. Strelets. Internal flows of gas mixtures. Moscow, Nauka, 1989 (in
Russian)
2. M.I. Zhilyaev, V.A. Schweigert, I.V. Schweigert. Simulation of RF silane discharge. Appl.
Mech. Tech. Phys. V. 35, N 1, 1994, pp. 13-21
3. M.N. Kogan. Dynamics of rarefied gas. Moscow, Nauka, 1967 (in Russian)
4. Yu.E. Gorbachev, M.A. Zatevakhin, I.D. Kaganovich. Simulation of the growth of
hydrogenated amorphous silicon films from an rf plasma. Tech. Phys. V. 41, N 12, 1996,
pp. 1247-1258
5. S.K. Godunov, V.S. Riabenkii. Difference schemes. Moscow, Nauka, 1973 (in Russian)
6. Yang J.Y., Hsu C.A. High-Resolution, Nonoscillatory Schemes for Unsteady
Compressible Flows. AIAA J., V. 30, N 6, 1992, pp. 1570-1575
7. F. Casier, H. Deconinck, Ch. Hirsch. A class of bidiagonal schemes for solving the Euler
Equations. AIAA J. V. 22, N 11, pp. 1556-1563
8. V.L. Varentsov, A.A. Ignatiev. Numerical investigations of internal supersonic jet targets
formation for storage rings. Nuclear Instruments and Methods in Physics Research A 413,
1998, pp. 447-456
9. A.A.Ignatiev. Regular grid generation with mechanical approach. Mathematical
Modelling, V. 12, N 2, 2000, pp. 101-105 (in Russian)
10. G.J. Nienhuis, W.J. Goedheer, E.A.G. Hamers, W.G.J.H.M. van Sark, and J. Bezemer,
A self-consistent fluid model for RF dischargdes in SiH4-H2 compared to experiments.
J. Appl. Phys. V.82, 1997, pp.2060-2071
11. Yu.E. Gorbachev, M.A. Zatevakhin, V.V. Krzhizhanovskaya, V.A. Schweigert. Special
Features of the Growth of Hydrogenated Amorphous Silicon in PECVD reactors. Tech.
Phys. V. 45 N 8, 2000, pp.1032-1041

