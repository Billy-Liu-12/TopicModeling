Noise-Induced Signal Enhancement in
Heterogeneous Neural Networks
Michael J. Barber and Babette K. Dellen
Institut für Theoretische Physik, Universität zu Köln, D-50937 Köln, Germany
mjb@thp.uni-koeln.de bd@thp.uni-koeln.de

Abstract. Neural networks can represent complex functions, but are
often constructed of very simple units. We investigate the limitations
imposed by such a simple unit, the McCulloch-Pitts neuron. We explore
the role of stochastic resonance in units of ﬁnite precision and show
how to construct neural networks that overcome the limitations of single
units.

1

Introduction

Neural networks are often constructed of very simple model neurons. Typically,
model neurons have a particular threshold or bias, and saturate to a ﬁxed value
for either strong or weak inputs, yielding a so-called sigmoidal activation or
“squashing” function. While individual units are simple, it is well known that
neural networks can represent complex functions. In this work, we will investigate
the degree to which the simple dynamics of an individual unit limit the inputs
that can be represented, and how these limitations can be overcome.
To do this, we consider the response of model neurons to a variety of signals.
The model neurons have limited precision, which we implement by including
noise in the systems. We consider noise that is intrinsic to the neurons, and thus
has identical statistics for each of the units in the neural networks.
Noise is usually viewed as limiting the sensitivity of a system, but nonlinear
systems can show an optimal response to weak or subthreshold signals when
a non-zero level of noise is added to the system. This phenomenon is called
stochastic resonance (SR) [2]. SR is seen in many systems, ranging from resonant
cavities to neural networks to the onset of ice ages [5]. For example, a noise-free,
subthreshold neuronal input can occasionally become suprathreshold when noise
is added, allowing some character of the input signal to be detected.
Collins et al.[1] showed, in a summing network of identical Fitzhugh-Nagumo
model neurons, that an emergent property of SR in multi-component systems is
that the enhancement of the response becomes independent of the exact value
of the noise variance. This allows networks of elements with ﬁnite precision to
take advantage of SR for diverse inputs. To build upon the ﬁndings of Collins
et al., we consider networks of simpler model neurons, but these are allowed to
have diﬀerent dynamics. In particular, we examine noisy McCulloch-Pitts (McP)
V.N. Alexandrov et al. (Eds.): ICCS 2001, LNCS 2074, pp. 996−999, 2001.
�
� Springer-Verlag Berlin Heidelberg 2001

Noise-Induced Signal Enhancement in Heterogeneous Neural Networks

997

neurons [3] with a distribution of thresholds. We construct heterogeneous networks that perform better than a homogeneous network with the same number
of noisy McP neurons and similar network architecture.

2

Results

To investigate the eﬀect of noise on signal transduction in networks of thresholding units, we constructed a network of noisy McCulloch-Pitts neurons. A McP
neuron is a simple thresholding unit, which can be expressed mathematically as
a step function. When the total input to a neuron (signal plus noise) exceeds
its threshold, the neuron activates, ﬁring an action potential or “spike.” The
presence of a non-zero level of noise can make the neuron more sensitive to weak
signals; for example, a subthreshold signal can occasionally be driven above the
neuronal threshold by the noise. The intrinsic neuronal noise is modeled in this
work as independent, identically distributed Gaussian white noise that is added
to the input signal. We use the standard deviation of the Gaussian as a measure
of the noise strength.
The network architecture is very simple: an input layer of N noisy McP
neurons is connected to a single linear output neuron. Each synaptic weight is of
identical strength, so the output neuron calculates the mean value of the input
neuron activation states. Each input unit is presented the same analog signal,
but with a diﬀerent realization of the √
intrinsic neuronal noise. The uncorrelated
noises increase only by a factor of N on average across the population of
neurons, while the coherent input signal is strengthened by a factor of N . This
yields an increased signal-to-noise ratio and a more sensitive neural network.
We reconstruct the input signal by convolving the output neuron response
with a linear ﬁlter [4]. The ﬁlter is generated to minimize a quadratic diﬀerence
between the reconstructed signal and the input signal; the resulting ﬁlter for
McP neurons is a low-pass ﬁlter. We quantitatively compare the reconstruction
with the original signal, and make use of the standard correlation coeﬃcient r 2
as a direct measure of the similarity between signal and reconstruction.
A single McP neuron shows a characteristic stochastic resonance proﬁle in
response to weak signals (generated here as a random walk with zero mean and
a typical variance of one) with diﬀerent noise intensities (Fig. 1a, green circles).
As the noise increases, there is an initially enhanced network response, which
then drops oﬀ as the noise further increases, overwhelming the signal. However,
networks of McP neurons, all of which have identical thresholds, have a broad
plateau of noise-enhanced responses (Fig. 1a, blue squares and red triangles), as
well as an overall enhanced response to a signal. This is similar to the ﬁndings
of Collins et al.[1].
The behavior seen in Fig. 1a appears to indicate that noise is a good thing
to have in neurons, but it was calculated under the assumption of weak signals.
To expand upon this assumption, we consider the ability of networks of McP
neurons to reconstruct signals of diﬀerent strength. In this instance, “strength”
can be understood as the diﬀerence between the mean value of the input signal

998
a

M.J. Barber and B.K. Dellen
N=1

1.0

b

Noise Free

1.0

Noise = 0.3

N = 10

0.5

0.0

r2

r2

N = 100

0

2

Noise

4

0.5

0.0
–2

0

2

Mean Value of Signal

Fig. 1. Stochastic resonance is seen in networks of McCulloch-Pitts neurons. (a) With
an increasing number N of neurons, the stochastic resonance peak broadens, losing the
strong dependence on a particular noise level. The network responses shown are the
average result for 50 zero-mean, random walk inputs; each signal is weak and normally
subthreshold, with the neuronal thresholds equal to one. (b) The presence of noise
widens the range over which signals are accurately detected and reconstructed. Here,
we show a network of 100 neurons with thresholds of zero.

and the value of the neuronal thresholds, so we vary the signal mean while
keeping the thresholds and the noise intensity ﬁxed. In this manner, we see that
the presence of noise broadens the range of signal strengths that the network can
detect (Fig. 1b). This is the mirror image of the weak-signal stochastic resonance
eﬀect: strong input signals may be supra-threshold at all times, so that the McP
neuron ﬁres at each sampling time, but the presence of noise can drive the total
signal below the threshold and improve the network sensitivity.
The network sensitivity increases as the number of input neurons increases
(Fig. 2a). For large numbers of neurons, adding more units widens the range
of signal detection, but does not signiﬁcantly improve the peak reconstruction
performance of the network.
The networks shown in Fig. 2a indicate that there is only a minimal widening of the range of signal detection for a large increase in the number of neurons. However, these networks were homogeneous, with each neuron having an
identical threshold. A natural extension is to consider heterogeneous systems,
where the thresholds are not uniform. We divide the neurons evenly into two
subpopulations of diﬀerent thresholds. The neurons in each subpopulation are
identical, and the subpopulations have identical noise intensities, diﬀering only
in the thresholds. Again applying the signal reconstruction procedure, we see
that the signal detection range can be more eﬃciently widened in this way than
with a single homogeneous population of neurons (Fig. 2b). The use of multiple
thresholds increases the range of signal detection without any signiﬁcant loss in
the quality of signal detection.

3

Conclusion

We have constructed a network of heterogeneous McP neurons that outperforms
similar networks of homogeneous McP neurons. The network architectures are

Noise-Induced Signal Enhancement in Heterogeneous Neural Networks
a

N=1

1.0

b

999

Homogeneous

1.0

N = 10

Heterogeneous

0.5

r2

r2

N = 100

0.0
–2

0

2

Mean Value of Signal

0.5

0.0
–2

0

2

Mean Value of Signal

Fig. 2. Comparison of homogeneous and heterogeneous networks. (a) The range of effective signal detection and reconstruction increases gradually as the number of neurons
increases. Every neuron in each of the networks shown here has an identical threshold,
equal to zero. (b) Segregating the neurons into two groups with diﬀerent thresholds
leads to a greater range of eﬀective signal detection and reconstruction than an increase in the number of neurons with uniform thresholds. The heterogeneous network
has 10 neurons with a threshold of −0.65 and 10 neurons with a threshold of +0.65.
The homogeneous network is identical to the 100 neuron network shown in (a).

identical, with the only diﬀerence being the distribution of neuronal thresholds.
The heterogeneous system is sensitive to a wider range of signals than the homogeneous systems. Such networks of heterogeneous units are easily implemented,
and could serve as simple models of many diverse natural and artiﬁcial systems.
A network of low-precision neurons (or other units) can take advantage of
stochastic resonance to accurately encode and transmit an input. The collective
properties of these systems can exceed the limitations of a single element. A
careful consideration of properties of the elements, such as their thresholds, may
yield even further improvements in the performance of the system.

Acknowledgements
We thank John Clark, Manfred Ristig, and Jürgen Hescheler for valuable discussion. This work was supported in part by Graduiertenkolleg Azentrische Kristalle
GK549 of the DFG.

References
[1] J.J. Collins, C.C. Chow, and T.T. Imhoﬀ. Stochastic resonance without tuning.
Nature, 376:236–238, July 1995.
[2] L. Gammaitoni, P. Hänggi, P. Jung, and F. Marchesoni. Stochastic resonance. Rev.
Mod. Phys., 70(1):223–87, January 1998.
[3] J. Hertz, A. Krogh, and R.G. Palmer. Introduction to the Theory of Neural Computation. Addison-Wesley Publishing Company, Reading, MA, 1991.
[4] F. Rieke, D. Warland, R.R. de Ruyter van Steveninck, and W. Bialek. Spikes:
Exploring the Neural Code. MIT Press, Cambridge, MA, 1997.
[5] K. Wiesenfeld and F. Moss. Stochastic resonance and the beneﬁts of noise: From
ice ages to crayﬁsh and SQUIDs. Nature, 373:33–36, January 1995.

