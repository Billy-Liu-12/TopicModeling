Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1278–1287

International Conference on Computational Science, ICCS 2011

PACC: A Path Associativity Congestion Control and Throughput
Model For Multi-path TCP
Yin Liua,1 , Baojin Wangb , Ke Xua , Zhen Maa
a Computer
b National

Science & Technology, University of Tsinghua, Beijing, China
Digital Switching System Engineering and Technological Reserach Center, China

Abstract
Multipath TCP protocol (MPTCP) is a complicated transport layer protocol that transfers data by multiple paths
simultaneously. It can improve end to end transmission throughput and increase network utilization. However, we
ﬁnd there are still deﬁciencies in the congestion control algorithm and throughput model of MPTCP, so we investigate
these deﬁciencies in this study. Firstly, we design a novel congestion control algorithm, Path Associativity Congestion
Control (PACC), which further enhances the throughput of MPTCP. PACC is based on fairness, the deﬁnition of
which is more reasonable. Secondly, we ﬁnd the adaptation problem of MPTCP that aﬀects its performance, and
propose a MPTCP throughput model, which can predict the throughput in real network environment. Finally, by
analyzing the main factors causing the adaptation problem based on the throughput model, we design a dynamic
reservation algorithm to improve the traﬃc distribution and eliminate that issue. Extensive ns-2 simulation study has
been performed to validate our design and algorithms.
Keywords: multi-path TCP, PACC, throughput model, adaptation problem, dynamic reservation algorithm

1. Introduction
Multipath TCP protocol (MPTCP) is a transport layer technology based on multi-homed, which transfers data
with multiple paths simultaneously in order to take full advantage of the idle resources in internet. It can improve end
to end transmission throughput and increase the utilization of network resources. With the development of network
technology, multi-homed devices is getting more and more popular, such as mobile phones. The multi-homed devices
can be attached to various networks. And with the networks expanding, the traditional TCP can’t utilize the bandwidth,
causing waste of network resources. MPTCP is proposed to support multi-homed and utilize remainder bandwidth. It
uses multiple paths to enhance the utilization of network resources, improve the speed of transmission, facilitate the
load balancing of network, and meanwhile enhance the robustness of the network.
In 1995, the original idea of MPTCP was proposed by Christian Huitema in an IETF draft [1]. Subsequently,
there are many studies on this protocol, such as mTCP[7]. Nevertheless, it didn’t cause widespread concern. Now,
because of Kelly’s research [8] that published in 2005, multi-path TCP protocol becomes a hot-spot of the network

Email address: liuyin08@mails.tsinghua.edu.cn (Yin Liu)
author

1 Corresponding

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.138

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

1279

research. Currently, it is standardized by the Multipath TCP working group of IETF, involving the main aspects
such as architectural design, detailed design, API, congestion control and security, as well as applications in wireless
networks and other scenes. Although these studies are comprehensive, the throughput model of MPTCP has not been
studied in depth. In addition, the deﬁnition of fairness, which is the basis of the congestion control algorithm, is not
entirely correct in our opinion. In this paper, we focus on the two problems.
Our study is composed of four aspects. First, we give a reasonable deﬁnition of the fairness for the scene where
MPTCP and TCP coexist. A new congestion control algorithm (Path Associativity Congestion Control, PACC) is
derived from the new deﬁnition. PACC improves the performance in the independent path scene compared to the
previous one. Second, we ﬁnd the adaptation problem which is the key issue of MPTCP inﬂuencing the performance
seriously. This issue is tend to occur in the scene where the performance of paths in MPTCP is diﬀerent signiﬁcantly.
By analyzing the protocol, we believe the adaptation problem is caused mainly by the ﬂow control mechanism, which
has not been studied yet. To solve this problem, we propose MPTCP throughput model on basis of PACC and ﬂow
control. It can accurately predict the performance of MPTCP in reality network. Third, with the support of the
throughput model, we design a dynamic reservation algorithm (DR) to solve the adaptation problem by improving
the traﬃc distribution mechanism. At last, the ns-2 simulation study has been performed to validate our design and
algorithms.
The main innovation of this paper involves three aspects:
• We present a novel congestion control algorithm, Path Associativity Congestion Control (PACC), based on a
new deﬁnition of fairness.
• We derive a novel throughput model for MPTCP based on PACC. It can accurately predict the performance of
MPTCP in real networks, and provide a theoretical model for throughput research.
• We propose a dynamic reservation algorithm (DR) by the analysis of MPTCP throughput model to solve the
adaptation problem that discovered in experiment.
The remainder of this paper is organized as follows. Section 2 describes the related work. Section 3 introduces
the congestion control problem and the adaptation problem. Section 4 and 5 present our innovation, including PACC,
the throughput model and the DR algorithm. Ns-2 simulation study is reported in Section 6. We conclude the paper
in Section 7.
2. Related Work
Currently, there are already a number of studies on the MPTCP design [5]-[12]. mTCP [7] is the ﬁrst multi-path
TCP protocol implemented in real environment, which increases the useable transmission bandwidth through multiple paths. However, it only designs independent congestion control algorithm in each sub-ﬂow, rather than overall
congestion control algorithm for MPTCP, and it doesn’t suit to large-scale deployment. In [8], Kelly and Thomas
Voice propose an end to end algorithm that integrated multi-path routing and rate control. An optimized allocation
of traﬃc algorithm is presented in [9], which uses route diversity and the minimized congestion feedback signal in
route to achieve stable state at the source node, but it depends on the control of the feedback signal, and the allocation
algorithm is very complex. In [10], Damon Wischik etc. focus on explaining how to achieve a simpliﬁed, ﬂexible and
powerful resource pool, which is one of the basic objectives of MPTCP, by combining congestion control and multipath routing. In [11], they mainly analyze some congestion control algorithm of that time, and ﬁnd the likeliness of
occurring ﬂap when adjusting the ﬂow of traﬃc by these algorithms from the angle of load balancing, propose method
to measure resource pool through the deﬁnition of resource capacity matrix. In [12], a novel distribution algorithm is
proposed, but it needs calculate the rtt for every packet to decide the transmit path, which is complex and diﬃcult to
deploy in Internet.
The MPTCP working group of IETF is established under the promotion of UCL University. Its main objective is
to standardize MPTCP. The working group come up with several drafts[14]- [16], mainly relating to protocol design,
routing, congestion control algorithm, API design and security. The MPTCP protocol studied in this paper is based on
the protocol raised by this working group. In [16], UCL proposed a fairness-based congestion control algorithm by
using an implicit approach to avoid the detection of bottleneck link and implement the support of fairness. However,
we think its deﬁnition of fairness is not quite sound, thus we come up with a new deﬁnition of fairness, and propose a
new congestion control algorithm.

1280

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287
A

A

Bottleneck1
༃

B

Bottleneck1

༃

B

Bottleneck2

༄

Bottleneck2
༅

༄

C

C

(a) Exclusive Bottleneck Scene

(b) Share Bottleneck Scene

Figure 1: MPTCP Fairness Deﬁnition Scenes

There are also plenty of studies on throughput model, such as [2]-[4]. A typical throughput model of TCP is
proposed in [2], which is established through an analysis of fast retransmission, timeout and the receive window size.
The NewReno throughput model is ﬁnished recently by Nadim Parvez [3], it optimizes the throughput model about
fast recovery algorithm, and describes the packet loss rate with two variables. However, there has been few research
about the MPTCP throughput, so we come up with a MPTCP throughput model based on [2].
3. Analysis of MPTCP Problems
Currently, the IETF MPTCP Working Group presents a preliminary design of MPTCP [14][15]. In this paper, we
study the simpliﬁed model of this design, in which MPTCP includes two parts, the sender and the receiver. At the
sender, there is a uniﬁed send window responsible for distributing data to sub-ﬂows with round-robin algorithm. This
simpliﬁed model assumes that there are unlimited packets to send. Similarly, at the receiver, there is a uniﬁed receive
window responsible for receiving and reordering the packets. Only the packets with correct sequence will be sent
to the upper layer. Meanwhile, each sub-ﬂow, which is created by MPTCP, has a congestion control window and a
receive window separately. The congestion control and ﬂow control in sub-ﬂow are the same as TCP.
Each packet in MPTCP has two sequence number. In MPTCP layer, it has a data sequence number to identify the
post of the packet in MPTCP data stream, while in the sub-ﬂow layer, it has the sub-ﬂow sequence number to mark
its location in sub-ﬂow stream. The two sequence numbers are mapping. When receiving the packet, each sub-ﬂow
receiver deals with it in the same way as TCP and stores it in the sub-ﬂow receive window. Only when the data
sequence is in the range of the MPTCP receive window, the packet can be transferred to the uniﬁed receive window.
In the MPTCP receive window, if the previous packets have correct sequence and with no gap, the MPTCP will send
these packets to the application layer and readjust the range of its receive window. In the ACK, the declared receive
window size is the rest space of the sub-ﬂow receive window. The ﬂow control mechanism of MPTCP is realized in
this way.
3.1. Fairness Problem in Congestion Control
Currently, in MPTCP design, the congestion control is divided into two parts. In each sub-ﬂow, the congestion
control is responsible for processing the link congestion, like TCP, while in MPTCP layer there is a uniﬁed congestion
control, responsible for adjusting the traﬃc throughput. In the IETF design, the congestion control in MPTCP layer
is based on fairness.
In the congestion control algorithm of UCL [16], the fairness is deﬁned as the MPTCP ﬂow’s aggregate bandwidth
which is the same bandwidth as a regular TCP ﬂow on the best path of MPTCP. In Fig. 1(a), node B uses MPTCP,
while A and C use TCP. Assume the capacity of both Bottleneck1 and Bottleneck2 is c. As discribed in the deﬁnition
of fairness in [16], the throughput of MPTCP at node B is 2c/3, same with A and C, which is fair. However, we think
fairness is only related to the bottleneck link. This means that MPTCP do no harm to TCP in bottleneck. So we think
the deﬁnition of fairness should be:
Deﬁnition 1 (fairness). In the bottleneck link, if there are two or more paths in the same MPTCP, the total bandwidth
occupied by MPTCP should be less than or equal to the TCP in bottleneck.

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

1281

The speciﬁc meaning of Def. 1 is shown in Fig. 1(b). Node B uses MPTCP. In Bottleneck1 , the two paths of
MPTCP should occupy the bandwidth of c/2, and same in Bottleneck2 . Thus the throughput of MPTCP is c, while
A and C each get c/2. In this scene, we think MPTCP is fair with TCP. We will propose a novel congestion control
algorithm for MPTCP base on the Def. 1 in this paper.
3.2. The Adaptation Problem
At present, the MPTCP code based on Linux has been preliminarily implemented by UCL. MPTCP is added to
the Linux network stack by modifying the kernel. We ﬁnd a problem when deploying the code in a real network
environment, that is when limiting the speed of two paths, the performance diﬀerence between the paths would reduce
the throughput of MPTCP seriously. For example, when we set the speed of both MPTCP paths at 50KB/s, the total
speed is 94KB/s. However, in the same environment, when we set one path at 50KB/s, the other at 25KB/s, the total
speed is 55KB/s. The fast link is aﬀected seriously. As a result, how to adapt the diversity is a serious problem. In
this paper, we deﬁne the problem as the adaptation problem in Def. 2. In later chapters, we will study it in depth.
Deﬁnition 2 (The adaptation problem). The overall throughput of MPTCP is decreased due to the performance
diﬀerence between paths, which makes MPTCP be not able to achieve the best performance.
4. PACC and Throughput Model
4.1. PACC
Congestion control is the core of MPTCP and the key point of whether MPTCP can be widespreadly deployed.
According to the deﬁnition of fairness given in Sec. 3.1, we derive a new congestion control algorithm(Path Associativity Congestion Control, PACC) in this section. It mainly considers the situation of multi-path interaction in MPTCP,
removes the eﬀect in UCL algorithm on non-interactive paths, so as to improve the MPTCP performance and ensure
fairness. In PACC, we ﬁrst deﬁne a factor in Def. 3.
Deﬁnition 3 (Path correlated coeﬃcient, α). α indicates the impact on congestion control when a path intersecting
with other path in MPTCP. The value of α is between (0,1], where 1 indicates the independent of this path. When α is
closer to 0, this path has greater correlation to other paths, and has stronger eﬀect on congestion control.
On the calculation of α, based on Def. 1 and the situation in Fig. 1(b), we set the throughput for link 1 and 2 of
MPTCP at node B as T 1 and T 2 when congestion occurs in Bottleneck1 , where T 1 > T 2 . We can conclude from Def. 1
that when 1 and 2 pass the same path, the overall performance of the two paths should have the same characteristics
as TCP. In PACC, take the larger throughput of the two paths as the throughput of TCP, so the following Eq. (1) should
be satisﬁed:
α1 ∗ T 1 + α2 ∗ T 2 = T 1
α1 and α2 indicate respectively correlation coeﬃcient of
of MPTCP can be concluded from (1), showed in Eq. (2).

1

and

2

(1)
in Bottleneck1 . The path correlation coeﬃcient

T1
T1 + T2

(2)

MAX cwndi ∗mssi
i
rtti
n cwndi ∗mssi
i=1
rtti

(3)

α=
Then, it can be changed to:
α=

The calculation of this coeﬃcient is similar to that of α in [16], but the author didn’t show the process of obtaining
the result, so this paper details the algorithm to get the coeﬃcient calculation.
Eq. (3) presents only the calculation of each path’s α when there are multiple paths in the same bottleneck link.
This congestion algorithm also considers the situation where one path shares diﬀerent bottlenecks with others. In

1282

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

this situation, the path correlation coeﬃcient can be calculated by Eq. (4), in which αi (i = 1, 2, , k) indicates the
correlation coeﬃcient obtained from the i-th bottleneck, and the total number of shared bottlenecks is k.
α = Πk1 αi

(4)

PACC mainly uses path correlation coeﬃcient to adjust each sub-ﬂow, to achieve the purpose of fairness. Similar
to [16], PACC only plays a role in the congestion avoidance phase, by controlling the growth of congestion window. In
the sub-ﬂow congestion control, when each sub-ﬂow i receives ACK, the increment of congestion window size should
satisﬁes formula (5). Where α is the path correlated coeﬃcient, bytes acked is the amount of data ACK conﬁrmed,
mssi is the maximum transmission size of pathi , cwndi is the congestion window size of pathi , and b indicates that
after b rounds the congestion window size is added by 1.
cwndincrement = α2 ∗

bytes acked ∗ mssi
b ∗ cwndi

(5)

Alg. 1 is the PACC algorithm designed in this section. This algorithm can accurately represent the interaction of
paths in MPTCP, and eﬀectively use the capacity of multiple links on the premise of ensuring fairness, so as to achieve
the goal of increasing throughput.
Algorithm 1: PACC
• Obtain the correlation coeﬃcient αi for Pathi .
i
for every Path.
• Obtain the cwndincrement
i
for Pathi .
• Increase the congestion window size by cwndincrement

A key point of PACC is the discovery mechanism of path intersection, which aﬀects the deployment of this
algorithm. We believe that solving this problem can be considered from two aspects. First, according to the design,
MPTCP should use source routing, so the path intersection can be easily recognized, and correlation coeﬃcient
between paths can be calculated. Second, even if it doesn’t use source routing, there are already many studies to
determine paths intersection. We think the research of [19] can be applied to PACC, in which the auditor determines
intersection by measuring the correlation of packet loss rate and RTT from diﬀerent paths when congestion occurred.
Therefore we believe PACC can be widely deployed.
4.2. MPTCP Throughput Model
To solve the adaptation problem, we conduct in-depth analysis and ﬁnd that the root of this issue lies in the ﬂow
control mechanisms. The MPTCP ﬂow control mechanism, like TCP, is that when the size of the receive window
is smaller than that of the congestion window, the speed of sending data will be aﬀected. When the size of receive
window is 0, the sender will even stop sending data.
MPTCP need to use multiple paths in transmission, so when performance diﬀerence exists between paths, the link
with low performance may cause the delay of the transmitted packets, which will result in the emergence of out of
order packets. So the receiver can’t transfer data in the cache to the upper layer because of waiting for those packets
with serial number ahead, which will decrease the receive window. At that time, due to lack of buﬀer space, the
speed of sending date through the high performance links will be reduced, or even stop. This results in the adaptation
problem.
To solve this problem, we propose a MPTCP throughput model. We analyze and model MPTCP using only two
paths in transmission at ﬁrst, and then extend to the case of multiple paths. The throughput model is derived from the
root cause of the adaptation problem and the consideration of key factors aﬀecting MPTCP performance. It predict
the MPTCP performance correctly. The two paths throughput model is as follows:
First consider the scenario shown in Fig. 1(a), where there are two exclusive paths in MPTCP, Path1 and Path2 .
Node B is the sender and the corresponding end is the receiver. Suppose the parameters of Path1 are: round trip time
RT T 1 , packet loss rate P1 , the sub-ﬂow receive window size W1 , throughput rate of this path B1 ; the parameters of
Path2 are: RT T 2 , P2 , W2 , and B2 . The MPTCP receive window size is W.

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

1283

Deﬁnition 4 (Flow Control Interaction Probability, FCIP). The probability of the interaction between any two paths due to the ﬂow control mechanism in MPTCP.
The goal of this model is to calculate the probability of two paths interaction in MPTCP transmission. According to
the previous analysis, the key factor aﬀecting the performance of MPTCP is the occurrence of ﬂow control interaction.
This key factor in this paper is deﬁned as ﬂow control interaction probability, as described in Def. 4. From the angle
of simplifying the problem, the FCIP is set as the occurrence probability of the transmission stops resulted from the
receive window size reducing to 0. Except the FCIP, there are other factors that will result in interaction of links, such
as bottleneck, which are not considered here.
To calculate the FCIP, this model analyzes the adaptation problem mainly from the perspective of out of order
packets. When the size of one path’s receive window is 0, there must be at least one data packet out of order, the time
it reaches the MPTCP receive window is at least later than W + Wi (i = 1 or 2) packets whose serial number come
after. Therefore, the calculation of FCIP is transformed to ﬁnd the probability that out of order packets occurs.
Without loss of generality, assume RT T 1 ≥ RT T 2 , so the probability that Path1 has impact on Path2 is calculated
as follow:
T1
Note m = RT
RT T 2 , assume Ai , A j as the transmitted packets number, Ai through Path1 , A j through Path2 , and
j > i + W + W2 . Note r satisfy the ﬂowing equation:
r ∗ (r − 1)
≥ W + W2
(6)
2
Wi is the size of sub-ﬂow congestion control window of Path2 when Path1 sending packet Ai . r is the number of
rounds that causes the receive window size to become 0 in Path2 . When W1 is 1, r reaches the maximum value.
Assume the arrival time of Ai is di , A j is d j , then the probability of ﬂow control interaction, Path1 to Path2 , is
deﬁned as follows:
r ∗ Wi +

∞

P(2, 1) = Prob(di > d j ) =

(1 −
k=1,km>r

r
) ∗ P(k−1)
1
km

(7)

From Eq. 7, it can be observed that P(2, 1) has the following properties: (i) Path2 will stop the transition when
r
k ∗ m > r, because of the aﬀect of Path1 . (ii) (1 − km
) indicates the proportion of the suspended time. (iii) P(k−1)
is the
1
probability of km > r. k = 1 presents the delay, k = 2 the retransmission, and k > 2 the timeout.
Similarly, we can get the FCIP of Path2 to Path1 , P(1, 2). And the throughput rate of each sub-ﬂow can be derived
from [2] as follows:
Bi = α ∗ T i

(8)

Where Bi is the throughput rate. αi is path correlated coeﬃcient of this sub-ﬂow. T i is the throughput rate from
[2] in this scene.
Therefore, the throughput rate of MPTCP in Fig.3 is deﬁned by Eq. 9
B = α1 ∗ B1 ∗ (1 − P(1, 2)) + α2 ∗ B2 ∗ (1 − P(2, 1))

(9)

Extending the two path throughput model, we can get the multiple paths throughput model as follows:
RT T 1 : RT T 2 : RT T 3 : . . . : RT T n = m1 : m2 : m3 : . . . : mn

(10)

P(k, g) is the probability of ﬂow control interaction, Pathg to Pathk , deﬁned by Eq. 11.
r ∗ Wi +
Note m =

mg
mk ,

then,

r ∗ (r − 1)
≥
2

W
n
1
j=1, j g m j
1
mk

(11)

1284

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

∞

P(k, g) =

(1 −
k=1,km>r

r
) ∗ P(k−1)
g
km

(12)

P(k,*) presents the probability of ﬂow control interaction from others to Pathk , and it is as follows:
n

P(k, i) ∗

P(k, ∗) =

j

i(1 − P(k, j))

(13)

i=1,i k

Therefore,
n

αi ∗ Bi ∗ (1 − P(i, ∗))

B=

(14)

i=1

In the Eq. 14, B is the total throughput rate. This MPTCP throughput model is base on PACC and TCP throughput
model [2], and veriﬁed in Sec. 6. It can predict the throughput in real network correctly.
5. Dynamic Reservation Algorithm
In the previous analysis of this paper, we know that the adaptation problem is a serious issue which limits the
deployment of MPTCP in real network. In the Internet, due to the restrictions of diﬀerent ISPs and the diverse
performance of the middle routers, there is a great performance diﬀerence between various paths, such as the GPRS
and WIFI in mobile phone. This may result in the adaptation problem frequently and aﬀect the MPTCP throughput
seriously. Consequently, it is required to improve the protocol to solve this issue, thus really achieve the MPTCP
objective to increase the end to end throughput through various paths.
With the analysis of the MPTCP throughput model, we ﬁnd there are two directions to improve the protocol.
One direction is to optimize the scheduling approach of the traﬃc distribution to avoid the adaptation problem. The
other is to study the path selection method. It chooses the paths with tolerant diversity to reduce the probability of
adaptation problems. The ﬁrst direction is studied in this paper. We develop a simple algorithm (Dynamic Reservation
Algorithm, DR), which can achieve the desired results veriﬁed by ns-2 simulation.
Algorithm 2: DR

1

Input: m individuals X = {X1 , X2 , , Xm }, Y = {Y1 , Y2 , , Ym }, k
Output: m updated individuals Y = {Y1 , Y2 , , Ym }
sort X to X = {Xm1 , Xm2 , , Xmm }, Y to Y = {Ym1 , Ym2 , , Ymm }
// B is the min size of packet.

2
3
4
5
6
7
8
9

j

Ym ← Zmin ∗

10

j

j

i
xm
j

xm

if Ym < Zm then
j
j
Ym ← Zm
end

11
12
13

end
end
break

14
15
16

end

17
18

F is the correlation coefficient of two paths

for i = 1; i ≤ m; i + + do
Zmi ← FreeS pace(i)
end
for i = 1; i ≤ m; i + + do
if Zmi > B then
Zmin ← Zmi
for j = i; j ≥ 1; j − − do
j
if Ym == 0 then

end

∗F

1285

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

Currently, the MPTCP design has not studied deeply into scheduling problem, but gives a simple scheduling
method, namely, round robin. With the throughput MPTCP model, this paper proposes DR algorithm to dynamically adjust data reserve space for MPTCP paths based on their performance. By analyzing the model, we ﬁnd the
diﬀerences of RTTs between paths have serious impact on overall throughput of MPTCP. Therefore, the improved
algorithm mainly focuses on adapting to diﬀerences of RTTs. As transmission is dynamic, each packet can not be
ﬁgured out precisely which path to transmit. Also we have to consider the diﬃculty of implementation, with not
aﬀecting the MPTCP deployment and easy to maintain, so we propose a simpliﬁed scheduling method, shown as
Alg. 2.
In Alg. 2, X indicates RTT; Y indicates the space reserved for each sub-ﬂow. When it is needed to allocate packets
for each sub-ﬂow, this algorithm will ﬁrst rank parameters of each sub-ﬂow based on their RTT, and calculate the
remaining space of their congestion window. Next, it selects out the path which presently need to add packets and
has the maximal RTT as the calculation standard. Finally, DR allocates reservation space for other paths in order
proportionally. Though simple DR is, it is veriﬁed that DR can signiﬁcantly improve the adaptation problem in
various complex environments.
6. Ns-2 Simulation
Separate Path: p = 0.005, WinMax = 20

Share Path: p = 0.005, WinMax = 20

1000

800
UCL(TCP)
PACC(TCP)
UCL(MPTCP)
PACC(MPTCP)

900

TCP
UCL(MPTCP)
PACC(MPTCP)

700
600

700

Throughput (Kbps)

Throughput (Kbps)

800

600
500
400
300

500
400
300
200

200
100

100
0
0

100

200

300

400

0
0

500

100

200

Time (s)

300

400

500

Time (s)

(a) Exclusive Bottleneck Scene

(b) Share Bottleneck Scene

Figure 2: MPTCP Congestion Control Comparison In Diﬀerent Scenes

In this section, we evaluate the foregoing conclusion by ns-2 simulation study. We ﬁrst consider the scene in
Fig 1 to evaluate the throughput rate with PACC and UCL [16]. Then we verify the adaptation problem of MPTCP.
Finally the MPTCP throughput model and dynamic reservation algorithm are evaluated. Note that we have performed
extensive simulations over various parameter settings and achieved similar results. Due to space limitations, only a
small part of the results are reported in this section.
rtt1 = 0.116s, rtt2 = 0.997s, p1 = p2 = 0.005, WinMax = 10
500

800

450

700

400
Throughput (Kbps)

Throughput (Kbps)

rtt1 = rtt2 = 0.116s, p1 = p2 = 0.005, WinMax = 10
900

600
500
400
300
200

0
0

100

200

300
Time (s)

(a) Same RTTs

400

300
250
200
150
mptcp
normal

100

mptcp
normal

100

350

50
500

0
0

100

200

300

400

500

Time (s)

(b) Diﬀerent RTTs
Figure 3: The Adaptation Problem Veriﬁcation

We consider the the comparative experiments of PACC and UCL congestion control algorithm ﬁrst. To study the
improvement of PACC, we compare the MPTCP throughput rate with TCP in the same network environment. We get

1286

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

the results from the two scene in Fig. 1, which are reported in Fig. 2. The legend ”PACC (MPTCP)” in the ﬁgures
stands for the diﬀerent throughput rate over time of MPTCP with PACC, and ”UCL (MPTCP)” presents diﬀerent
throughput rate of MPTCP with the congestion control algorithm in [16], while ”UCL (TCP)”, ”PACC (TCP)” and
”TCP”, the throughput rate of TCP in the same network environment as MPTCP, are listed for comparison.
The improvement of PACC is shown in Figs. 2(a) and 2(b). The total throughput of PACC is higher than that of
UCL, closer to TCP in the exclusive bottleneck in Fig. 2(a). In Fig. 2(b), when the two paths belonging to the same
MPTCP sharing the same bottleneck, the PACC throughput is similar to the UCL, close to a half of TCP. It is clear
that the PACC algorithm can get the fairness in share bottleneck scene and lead to a higher throughput rate than UCL.
Fig. 3 depicts the simulation results of the fast path throughput of MPTCP in comparison with TCP in diﬀerent
scenes, the same rtts and diﬀerent rtts. This simulation adopts the test scene in Fig. 1(a). To evaluate the adaptation
problem, we simplify the test by ignoring the competition for link resources with others and only setting the packet
loss rate on the link. There are two scenes. In one scene the packet loss rates are all 0.005 and the rtts are both 0.116s.
In the other scene the packet loss rates are same as in the ﬁrst scene, while one rtt is 0.116s and the other is 0.997s.
Fig. 3(a) shows the results of the ﬁrst scene, while Fig. 3(b) the second scene. It is obvious that the throughput of
the fast link in MPTCP is similar to TCP. However, with diﬀerent performance paths, the fast path is slowed down
seriously.
11

x 10

Throughput Model(Two Pathes)

4

5

x 10

Throughput Model(Three Pathes)

4

PACC(MPTCP)
PACC model(MPTCP)

9

Number of Packets Sent (pkts/s)

Number of Packets Sent (pkts/s)

10

8
7
6
5
4

4.5

PACC(MPTCP)
PACC model(MPTCP)

4

3.5

3

2.5

3
2
0

0.2

0.4

0.6
RTT (s)

0.8

1

2
0

1.2

0.2

(a) Two Paths

0.4

0.6
RTT (s)

0.8

1

1.2

(b) Three Paths
Figure 4: The Throughput Model Veriﬁcation

Next, we validate the throughput model with background traﬃc. Fig. 4(a) shows the results of ns-2 simulations
and our model in representative experiments with one path rtt set to 0.116s, and the rtt of the other path varies. The
comparison of three paths is represented in Fig. 4(b), which sets the rtt of two paths to a ﬁxed value and the left one
varies. In all the simulations, the packet loss rates are all equal to 0.005. The legend ”PACC (MPTCP)” stands for the
results of experiments, and ”PACC model (MPTCP)” is the results derived from the model. These results demonstrate
the accuracy and robustness of our throughput model. It can be applied to multiple paths of MPTCP.
rtt1 = 0.116s, rtt2 = 0.997s, p1 = p2 = 0.005, WinMax = 10
500

450

450

400

400

350

350

Throughput (Kbps)

Throughput (Kbps)

rtt1 = 0.116s, rtt2 = 0.997s, p1 = p2 = 0.005, WinMax = 10
500

300
250
200
150
100

original mptcp
modified mptcp(10)
modified mptcp(18)

50
0
0

100

200

300

400

500

Time (s)

300
250
200
150
original mptcp
modified mptcp(30)
modified mptcp(60)

100
50
0
0

100

200

300

400

500

Time (s)

(a) Dynamic Reservation Algorithm

(b) The Receive Window Size

Figure 5: The Adaptation Problem Solutions

Finally, the DR algorithm is simulated in the scene where the rtts is set as in Fig. 3. The original throughput rate
is very low, shown in Fig. 5(a) with legend ”original mptcp”. By changing the reserved space in DR, the throughput

Yin Liu et al. / Procedia Computer Science 4 (2011) 1278–1287

1287

rate changes. The legend ”modiﬁed mptcp (10)” represents the space reserved is 10 , and ”modiﬁed mptcp (18)”
represents the space is 18. It is very clear that when reserved space is 18, the throughput can reach the maximum,
close to TCP. Fig. 5(b) shows the inﬂuence of the various receive window sizes. The size of ”original mptcp” is 10,
and for the other two tests, the sizes are 30 and 60. It is also explicit that the throughput can reach the maximum with
size 60, close to TCP. Therefore, DR can solve the adaptation problem, same with the method of increasing receive
window size.
7. Conclusion and Future Work
In this paper, we ﬁrst design a new congestion control algorithm of MPTCP, the PACC, on the basis of our new
deﬁnition of fairness, to improve overall throughput of MPTCP while ensuring MPTCP’s bandwidth in bottleneck link.
Second, through analysis of congestion control and ﬂow control, we set up performance model to calculate precisely
the throughput of MPTCP in diﬀerent network scenarios. Third, we ﬁnd key issue that aﬀects actual performance of
MPTCP, the adaption problem. We also analyze key factors causing the adaptation problem, and design the improved
algorithm to solve this problem initially. At last, we verify the accuracy of our study by ns-2 simulation.
In the future, we are ready to deploy the code to mobile phones for further validation of the adaptability of PACC
algorithm and DR algorithm, and the accuracy of the throughput model. Moreover, we will start to study other ways
to solve the adaptation problem from aspects of path selection and control of path number.
8. Acknowledge
This research is mainly supported by the National High Technology Development Program of China(No. 2008AA01
and 2009AA01A334).
9. References:
[1] C. Huitema. Multi-homed TCP draft-huitema-multi-homed-0.txt. Internet-Draft, IETF, 1995
[2] J. Padhye, V. Firoiu, D. Towsley, J. Kurose. Modeling TCP Throughput: A Simple Model and its Empirical Validation. ACM SIGCOMM,
1998.
[3] N. Parvez, A. Mahanti, and C. Williamson. An analytic throughput model for TCP NewReno, In IEEE/ACM Trans. Networking, 2009.
[4] Z. Yi,Tarek Saadawi, Myung Lee. Analytic model of Stream Control Transmission Protocol, PMCCS, 2003.
[5] H. Hsieh and R. Sivakumar. pTCP: An end-to-end transport layer protocol for striped connections. In Proceedings of IEEE ICNP, 2002.
[6] K. Rojviboonchai and H. Aida. An evaluation of multi-path transmission control protocol (M/TCP) with robust acknowledgement schemes.
IEICE Trans. Communications, 2004.
[7] M. Zhang, J. Lai, A. Krishnamurthy, L. Peterson, and R. Wang. A transport layer approach for improving end-to-end performance and
robustness using redundant paths. In ATEC ’04: Proceedings of the annual conference on USENIX Annual Technical Conference, pages 8-8,
Berkeley, CA, USA, 2004.
[8] F. Kelly and T. Voice. Stability of end-to-end algorithms for joint routing and rate control. CCR, 35(2). 2005.
[9] H. Han, S. Shakkottai, C. V. Hollot, R. Srikant, and D. Towsley. Multi-Path TCP: A Joint Congestion Control and Routing Scheme to Exploit
Path Diversity on the Internet, IEEE/ACM Trans. on Networking, vol. 14, December 2006.
[10] Damon Wischik, Mark Handley, Marcelo Bagnulo Braun. The resource pooling principle. ACM SIGCOMM Computer Communication
Review. 2008.
[11] Damon Wischik, Mark Handley and Costin Raiciu. Control of Multipath TCP and Optimization of Multipath Routing in the Internet. Network
Control and Optimization. 2009.
[12] Y. Hasegawa, I. Yamaguchi, T. Hama, H. Shimonishi, T.Murase. Improved data distribution for multipath TCP communication, GLOBECOM,
2005
[13] T. Anjali, A. Fortin, G. Calinescu, S. Kapoor, N. Kirubanandan, S. Tongngam. Multipath Network Flows: Bounded Buﬀers and Jitter.
INFOCOM, 2010.
[14] A. Ford, C. Raiciu, M. Handley. TCP Extensions for Multipath Operation with Multiple Addresses draft-ietf-mptcp-multiaddressed-02.
Internet-Draft, IETF, 2010.
[15] A. Ford, Ed., C. Raiciu, M. Handley, S. Barre, Louvain, J. Iyengar. Architectural Guidelines for Multipath TCP Development draft-ietfmptcp-architecture-03. Internet-Draft, IETF, 2010.
[16] C. Raiciu, M. Handley, D. Wischik. Coupled Multipath-Aware Congestion Control draft-ietf-mptcp-congestion-00. Internet-Draft, IETF,
2010.
[17] Damon Wischik, Mark Handley and Costin Raiciu. Proc: Control of multipath TCP and optimization of multipath routing in the Internet.
NetCOOP, 2009.
[18] D. Wischik, M. Handley, and M. Bagnulo Braun. The Resource Pooling Principle, ACM SIGCOMM CCR, Oct. 2008.
[19] D. Rubenstein, J. Kurose, D. Towsley. Detecting shared congestion of ﬂows via end-to-end measurement. IEEE/ACM Trans. on Networking.
2002.

