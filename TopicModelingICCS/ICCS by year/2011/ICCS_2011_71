Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1072–1081

International Conference on Computational Science, ICCS 2010

Improved prediction of protein interaction from microarray data
using asymmetric correlation
Kojiro Yano1,∗
Faculty of Information Science and Technology, Osaka Institute of Technology, 1-79-1 Kitayama, Hirakata City, Osaka 573-0196 Japan

Abstract
Background:. Detection of correlated gene expression is a fundamental process in the characterization of gene functions using microarray data. Commonly used methods such as the Pearson correlation can detect only a fraction of
interactions between genes or their products. However, the performance of correlation analysis can be signiﬁcantly
improved either by providing additional biological information or by combining correlation with other techniques that
can extract various mathematical or statistical properties of gene expression from microarray data. In this article, I
will test the performance of three correlation methods-the Pearson correlation, the rank (Spearman) correlation, and
the Mutual Information approach-in detection of protein-protein interactions, and I will further examine the properties
of these techniques when they are used together. I will also develop a new correlation measure which can be used
with other measures to improve predictive power.
Results:. Using data from 5,896 microarray hybridizations, the three measures were obtained for 30,499 known
protein-interacting pairs in the Human Protein Reference Database (HPRD). Pearson correlation showed the best
sensitivity (0.305) but the three measures showed similar speciﬁcity (0.240 - 0.257). When the three measures were
compared, it was found that better speciﬁcity could be obtained at a high Pearson coeﬃcient combined with a low
Spearman coeﬃcient or Mutual Information. Using a toy model of two gene interactions, I found that such measure
combinations were most likely to exist at stronger curvature. I therefore introduced a new measure, termed asymmetric
correlation (AC), which directly quantiﬁes the degree of curvature in the expression levels of two genes as a degree of
asymmetry. I found that AC performed better than the other measures, particularly when high speciﬁcity was required.
Moreover, a combination of AC with other measures signiﬁcantly improved speciﬁcity and sensitivity, by up to 50%.
Conclusions:. A combination of correlation measures, particularly AC and Pearson correlation, can improve prediction of protein-protein interactions. Further studies are required to assess the biological signiﬁcance of asymmetry in
expression patterns of gene pairs.
Keywords: gene expression, microarray, correlation

∗

Email address: vzb10326@me.com (Kojiro Yano)
author

1 Corresponding

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.114

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081

1073

1. Introduction
In microarray data analysis, it is common to examine correlations among gene expression levels [1]. Correlated
expression of a group of genes implies that the genes are involved in the same biological process or form a protein
complex, and correlation measures have been used to predict disease markers [2] and protein-interaction partners [3].
For linear correlations, measures such as Euclidean distance or Pearson correlation (PC) have been used, whereas
more general correlations may be quantiﬁed by rank (Spearman) correlation (SC) [4], Mutual Information (MI) [5].
However, the reliability of these measures when used to infer gene interactions is not always satisfactory [6], and
new methods have been proposed to improve the functional annotation of genes from microarray data. Some of
these techniques seek to enhance the performance of measures by incorporating evolutionary information, such as
orthologous co-expression [7, 8], or by considering conditional correlations mediated by a third gene [9, 10, 11]. In
addition to correlation measures, statistically more sophisticated but computationally more intensive methods have
also been developed; these include Bayesian networks [12, 13, 14] and support vector machines [15, 16].
Gene interactions cover a wide variety of mechanisms, and diﬀerent methods of gene network inference are based
on various models of gene interaction. Therefore, a combination of such approaches can improve the performance of
network inference. For example, it has been shown that direct inference methods such as PC are suitable for detecting
stable protein complexes whereas conditional methods, including partial PC or the Graphical Gaussian model, are
better at deﬁning causal interactions [17]. This means that diﬀerent methods can be mutually complementary, when
used to expand detection of protein interactions. In this article, I examine the performance of three commonly used
measures - PC, SC, and MI - in predicting known human protein-protein interactions from microarray data, and assess
the possibility of achieving improved performance through data combination. Based on this analysis, I introduce a
new measure, termed asymmetric correlation (AC), and show that AC improves the performance of other measures.
2. Results and Discussion
2.1. Data source
The pre-processed meta-analysis data set E-TABM-185 from ArrayExpress [18] was used in all analyses. The
dataset contained measurements from 5,896 arrays of human cell and tissue samples, all of which were hybridized with
the Aﬀymetrix GeneChip Human Genome HG-U133 (22215 probes). In this dataset, raw data from the microarray
were re-normalized with gcrma from Bioconductor [19] and output data were all log2-transformed. Human protein
interaction data were from the Human Protein Reference Database (HPRD) [20], which has information on 30,499
interactions (excluding self-interactions). I also randomly selected 30,499 pairs of genes from the microarray dataset,
as a negative control.
2.2. Quantiﬁcation of correlated gene expression
PC and SC were calculated using corr function from MATLAB (Mathworks, Inc. Natick, MA) and MI was
estimated using information MATLAB function constructed by Moddemeijer [5]. More speciﬁcally, when I(X;Y)
is MI of variables X and Y, I(X; Y) = H(X) + H(Y) − H(X, Y), where H(X) are H(Y) are the entropies of variable
X and Y, respectively and H(X,Y) is the joint entropy of X and Y. To obtain H(X), the maximum and minimum
values of X, namely Xmax and Xmin were calculated and the range Xmin ≤ X ≤ Xmax were divided into ten equal
intervals (called bins) Bi = B1 , B2 ..., B10 . Next the number of elements Ci in bin Bi was calculated for all bins.
Finally H(X) was calculated as H(X) = − Pi (X)log(Pi (X)), where Pi (X)=Ci / Ci . H(Y) is obtained by the same
manipulation. To obtain H(X,Y), the number of elements Ci, j of a vector Zi, j =(Xi , Yi ) was calculated for 10-by-10
bins Bi, j with equal intervals in the ranges Xmin ≤ X ≤ Xmax and Ymin ≤ Y ≤ Ymax . Next H(X,Y) was calculated as
H(X, Y) = − Pi, j (X, Y)log(Pi, j (X, Y)), where Pi, j (X, Y)=Ci, j / Ci, j . Correlation measures for both protein-protein
interaction pairs and control pairs are shown as histograms in Figure 1. With all three measures, mean values were
higher using HPRD genes than control genes (HPRD; PC, 0.167; SC, 0.244; MI, 0.0981; Control: PC, 0.0139; SC,
0.1127; MI, 0.0558).

1074

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081



!

"










	











#

	








 !









!









"!"!



!!

"








	



#
















 !









!









"!"!

Figure 1: Distribution of correlation measures for the Human Protein Reference Database (HPRD) and control data. Pearson coeﬃcient, Spearman
coeﬃcient, and Mutual Information were calculated for 30,499 known interacting pairs from HPRD (top) and the same number of randomly
selected negative control pairs (bottom).

2.3. Sensitivity and speciﬁcity of protein interaction prediction by gene expression correlation
To compare the performance of the three measures, I calculated sensitivity and speciﬁcity in discovery of proteinprotein interactions. At various threshold levels above which correlations were considered to be signiﬁcant, speciﬁcity
(proportion of below-threshold pairs to the total in the control group) and sensitivity (proportion of above-threshold
pairs to the total in the protein-interaction group) were calculated, and are plotted in Figure 2. When the speciﬁcity was
0.9, the sensitivity was 0.305 with PC, 0.255 with MI, and 0.125 with SC. When the sensitivity was 0.9, the speciﬁcity
was 0.257 with PC, 0.244 with MI, and 0.240 with SC. Therefore, PC performed best when high speciﬁcity was
required, but there was no signiﬁcant diﬀerence in measure performance at high sensitivity.
2.4. Combined measures yield better speciﬁcity
To improve prediction performance, I compared the combined distributions of pairs of measures using the HPRD
pairs and controls. Figure 3 shows scatter plots for PC and SC, PC and MI, and SC and MI, for all pairs in the
protein-interacting group (blue) and the control group (red). It was found that at high PC (>0.5), protein-interacting
pairs became more predominant in the lower range of MI or SC. Such properties were not seen when the relationship
between SC and MI was examined; in all ranges of SC the protein-interacting group predominated over the control
group at higher levels of MI.
In what situation will SC or MI be reduced when PC is still high? I approach this question using a toy model. Let
us consider genes X and Y and assume that the expression level of gene Y (termed Ye ) is a function of the expression
level of gene X (termed Xe ), and that they system follows Michaelis-Menten kinetics, as shown below:
dYe /dt = V1 Xe /(Xe + K) − ke Ye
where V1 , K and ke are constants. At the steady state, the relationship between Ye and Xe is:
Ye = V1 Xe /ke /(Xe + K) = V2 Xe /(Xe + K)
where V2 = V1 /ke . Now the measured levels of Ye and Xe (termed Ym and Xm ) are expressed as
Ym = d1 Ye + D1 , Xm = d2 Xe + D2

1075

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081

1
0.9
0.8

Specificity

0.7
0.6
0.5
Pearson coefficient
Spearman coefficient
Mutual information

0.4
0.3
0.2
0.1
0
0

0.2

0.4
0.6
Sensitivity

0.8

1

Figure 2: Sensitivity and speciﬁcity for detection of protein-protein interactions, and in distinguishing such interactions from random pairs. Pearson
coeﬃcient (black), Spearman coeﬃcient (blue), and Mutual Information (red) were calculated for gene pairs from the protein-protein interaction
data in the Human Protein Reference Database (HPRD) and randomly selected negative control pairs. At diﬀerent threshold levels, the proportion
of HPRD pairs with above-threshold values, with respect to the total (sensitivity), and the proportion of control pairs with below-threshold values,
with respect to the total (speciﬁcity), were calculated.

Figure 3: Scatter plots of correlation measures for the Human Protein Reference Database (HPRD) and control data. Pearson coeﬃcient, Spearman
coeﬃcient, and Mutual Information for known interacting pairs from HPRD (blue) and randomly selected control pairs (red) were plotted against
each other. left, Pearson coeﬃcient against Spearman coeﬃcient; Middle, Pearson coeﬃcient against Mutual Information; Right, Spearman
coeﬃcient against Mutual Information.

1076

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081

where d1 and d2 are biological noise modelled as normally distributed noise with a mean = 1 and a standard deviation
= R1 . D1 and D2 are technical noise modelled as evenly distributed random variables ranging between 0 and R2
[21]. Note that the parameters for noise are arbitrarily chosen and are used solely for demonstration of potential
eﬀects on correlation measures. Now, I vary K, R1 , and R2 as follows: K = 10, 000, 1, 000 or 100, and [R1 , R2 ] =
[0.01, 10], [0.03, 30] or [0.09, 90]. Figure 4 shows the log2 transformed plot of Xm (10 < Xm < 1, 000) against Ym
and Table 1 shows PC, SC and MI outputs with diﬀerent combinations of K and [R1 , R2 ]. At low and moderate noise
levels ([R1 , R2 ] = [0.01, 10] and [0.03, 30], respectively), SC was relatively unaﬀected by the decrease in K (i.e. the
increase of non-linearity). At the high noise level ([R1 , R2 ] = [0.09, 90]), however, SC was strongly aﬀected by the
decrease in K, but PC was less aﬀected. At all noise levels, MI was highly sensitive to the value of K. These results
show that the elevated PC, and the low SC and MI, on analysis of the protein-interacting group, are more likely to
be evident at high levels of non-linearity and noise. As the level of noise will not be signiﬁcantly diﬀerent between
HPRD and control groups, nonlinearity will probably be higher when the protein-interacting pairs are considered.
K=10000, R1=0.01, R2=10

K=1000, R1=0.01, R2=10

12
10
Gene Y

K=100, R1=0.01, R2=10

14

14
13

12

12

8
10

11

6
8

10

4
2

6
2

4

6

8

10

12

2

K=10000, R1=0.03, R2=30

8

10

12

9

2

4

6

8

10

12

K=100, R1=0.03, R2=30

14

10
Gene Y

6

K=1000, R1=0.03, R2=30

12

14
13

12

12

8
10

11

6
8

4
2

6
2

4

6

8

10

12

10

2

K=10000, R1=0.09, R2=90

4

6

8

10

12

9

2

K=1000, R1=0.09, R2=90

12

4

6

8

10

12

K=100, R1=0.09, R2=90

14

10
Gene Y

4

14
13

12

8

12
10

6

11
8

4
2

4

6

8
Gene X

10

12

6

10

2

4

6
8
Gene X

10

12

9

2

4

6
8
Gene X

10

12

Figure 4: Measured expression levels of genes X and Y in the toy model at diﬀerent levels of nonlinearity and noise. The scatter plots show
log2-transfored measured expression levels of genes X and Y in the toy model. Nonlinearity (K) and noise levels (R1 and R2 ) were varied between
100 and 1000, 0.01 and 0.09, and 10 and 90, respectively, and their eﬀects on the distribution of the measured levels of X and Y are shown.

2.5. Deﬁning asymmetric correlation
In the toy model above, the increase in non-linearity seen as K decreased caused the plot to diverge from the
diagonal line and become more asymmetric. This has been noted not only when Michaelis-Menten kinetic is applied,
but also in a system where reaction activation involves cooperativity between activators [22, 23, 24]. I now attempt to

1077

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081

Table 1: Correlation measures for measured expression levels of genes X and Y in the toy model using diﬀerent combinations of parameters.

Parameters
K = 10000, [R1 , R2 ] = [0.01, 10]
K = 1000, [R1 , R1 ] = [0.01, 10]
K = 100, [R1 , R2 ] = [0.01, 10]
K = 10000, [R1 , R2 ] = [0.03, 30]
K = 1000, [R1 , R2 ] = [0.03, 30]
K = 100, [R1 , R2 ] = [0.03, 30]
K = 10000, [R1 , R2 ] = [0.09, 90]
K = 1000, [R1 , R2 ] = [0.09, 90]
K = 100, [R1 , R2 ] = [0.09, 90]

Pearson coeﬃcient
0.999
0.993
0.932
0.994
0.985
0.918
0.957
0.955
0.845

Spearman coeﬃcient
0.999
0.999
0.989
0.995
0.993
0.942
0.962
0.947
0.776

Mutual Information
1.33
1.17
0.768
1.31
1.19
0.793
0.960
0.907
0.564

deﬁne and quantify the asymmetry of expression of a pair of genes. When the expression levels of genes X and Y are
Xe and Ye , and their means are Xav and Yav , respectively, I deﬁne
Q=

|(Xe − Xav )(Ye − Yav )|

and
Q1 = Q for all (Xe ,Ye ) with Xe > Xav & Ye > Yav ,
Q2 = Q for all (Xe ,Ye ) with Xe < Xav & Ye > Yav ,
Q3 = Q for all (Xe ,Ye ) with Xe < Xav & Ye < Yav ,
Q4 = Q for all (Xe ,Ye ) with Xe > Xav & Ye < Yav ,
Xe and Ye are symmetric when all of Q1 , Q2 , Q3 and Q4 are equal, and asymmetric if they are not. Please note
that linear plots, such as Y=X are also considered to be asymmetric by this deﬁnition. Therefore nonlinear curves are
asymmetric but asymmetry alone does not guarantee nonlinearity.
Now let me give a simple example to explain this concept more clearly. Here is a microarray dataset Z which has
three samples Z1 , Z2 and Z3 , with expression levels of genes X and Y being (X1 ,Y1 ), (X2 ,Y2 ) and (X3 ,Y3 ), respectively,
and X1 =5,X2 =X3 =2, Y1 =Y2 =5, Y3 =2, Zav = (Xav , Yav )=(3,4) (Figure 5). Therefore, according to the deﬁnition above,
Q1 = |(X1 − Xav )(Y1 − Yav )|=2, which is the area of the rectangle deﬁned by Z1 and Zav . Similarly, Q2 = |(X2 − Xav )(Y2 −
Yav )|=1, Q3 = |(X3 − Xav )(Y3 − Yav )|=2 and Q4 = 0. Therefore Z is asymmetric.
When Qz is the smallest value of Q1 ...Q4 , Xe and Ye are termed asymmetric with respect to Qz . Alternatively,
it could be stated that Xe and Ye are asymmetric with respect to the upper right quadrant if Q1 is the smallest, with
respect to the upper left quadrant if Q2 is the smallest, with respect to the lower left quadrant if Q3 is the smallest, or
with respect to the lower right quadrant if Q4 is the smallest. Finally the asymmetric correlation coeﬃcient S z with
respect to Qz is deﬁned by S z = Qi /4 − Qz . In the example above, Z is asymmetric with respect to Q4 , or lower right
quadrant, and the asymmetric coeﬃcient S 4 = (Q1 +Q2 +Q3 + Q4 )/4 - Q4 = (|(X1 − Xav )(Y1 − Yav )|+|(X2 − Xav )(Y2 −
Yav )|+|(X3 − Xav )(Y3 − Yav )|)/4=(2+1+2)=1.25. On the other hand, if X2 =(X1 +X3 )/2 = 3.5 and Y2 =(Y1 +Y3 )/2=3.5, Z1 ,
Z2 and Z3 will form a straight line and S 4 = (|(5 − 3.5)(5 − 3.5)|+0+|(2 − 3.5)(2 − 3.5)|)/4=1.125, which is smaller than
when Z was asymmetric.
2.6. Inplementation of the asymmetric correlation coeﬃcient
A diﬃculty with asymmetric correlation is that it is highly sensitive to the distribution of Xe and Ye . In other words,
Xe and Ye will be asymmetric if their distribution is skewed, even when they are entirely independent. Therefore it
is important to eliminate the asymmetry which comes from the individual distribution of Xe and Ye . I employed the
following procedures to this end. First, an n ∗ n two-dimensional matrix M sx,y is calculated from a two-dimensional
histogram of a scatter plot for V(Xe , Ye ), where V is an expression level vector for genes X and Y. Next two 1 ∗ n
one-dimensional vectors VX and VY are calculated from one-dimensional histograms of Xe and Ye , respectively. In
the third step a matrix Mrx,y is derived by Mrx,y = VX ∗ VY /(total number of samples). This matrix represents the
expected distribution of combinations of Xe and Ye when Xe and Ye are independent. Finally, I normalize M sx,y by Mrx,y

1078

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081





	






	

	

	



Figure 5: An example for quantiﬁcation of asymmetric correlation. This is a scatter plot of the expression levels of genes X and Y (Xe and Ye ,
respectively) for microarray data Z with three samples, Z1 , Z2 and Z3 (open circles). Zav (ﬁlled circle) is the average of Z1 , Z2 and Z3 . The
asymmetric coeﬃcient Q is calculated from Q1 , Q2 , Q3 and Q4 and the area of the hatched rectangle in the ﬁgure represent Q1 , Q2 , and Q3 as
indicated. Q4 is zero in this example.

to obtain the normalized expression matrix Mnx,y = M sx,y ./(M sx,y + Mrx,y ), where ./ indicates element-wise division.
Now, the asymmetric coeﬃcient with respect to the lower right quadrant S 4 is obtained by 4i=1 S i /4 − S 4 =
n,n/2
n,n
x=1,y=1 (Mn x,y |(x − (n + 1)/2)(y − (n + 1)/2)|)/4 −
x=n/2,y=1 (Mn x,y (x − (n + 1)/2)((n + 1)/2 − y)).
2.7. Performance of asymmetric correlation
Figure 6 shows histograms of the asymmetric correlation coeﬃcient with respect to the lower right quadrant for
HPRD data and the control data used above. The mean values of the coeﬃcients are 1,599 for HPRD data and 1,002
for control data. When speciﬁcity and sensitivity were examined as for other correlation measures, the asymmetric
coeﬃcient performed better than did PC. When the speciﬁcity was 0.9, sensitivity was 0.347 (0.305 with PC), and
when the sensitivity was 0.9, speciﬁcity was 0.290 (0.257 with PC).
However, better performance could be obtained by combining the asymmetric coeﬃcient with other measures.
Figure 7 shows scatter plots for asymmetric coeﬃcients and PC, SC, and MI of all HPRD pairs (blue) and control
pairs (red). As can be seen in the top-right portion of all three scatter plots, the HPRD pairs were very speciﬁcally
detected when AC was high and the other measure (i.e. PC, SC or MI) was positive. As a result of this observation, I
introduced a measure which combines PC, SC or MI with AC:
RPC,AC = rP + A
RS C,AC = rS + A
R MI,AC = rM + A
where RPC,AC , RS C,AC and R MI,AC are combined measures for PC and AC, SC and AC, and MI and AC, respectively.
P, S, M and A in the equations are values of PC, SC, MI, and AC respectively and r is a constant. Figure 8 shows
speciﬁcity at 90% sensitivity and sensitivity at 90% speciﬁcity when r was varied between 0 and 5,000. With PC
and MI, speciﬁcity was relatively unaﬀected by r (maximum values = 0.293 and 0.290 for PC and MI, respectively).
However, the sensitivity increased signiﬁcantly as r increased and attained peaks (0.448 for PC and 0.389 for MI)
when r = 2,400 and 5,000, respectively. On the other hand, both speciﬁcity and sensitivity improved with SC when r
was increased to some extent, but all improvements were modest (peak speciﬁcity and sensitivity = 0.378 and 0.313,

1079

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081

!!












	

	

"

"

!























  







 #!!






  











 #!!

Figure 6: Distribution of asymmetric correlation for the Human Protein Reference Database (HPRD) and the control datasets. Asymmetric
correlation with respect to the lower-right quadrant (please see the main text for deﬁnition) was calculated for protein-interacting pairs from the
HPRD (top) and negative control pairs from the control (bottom) datasets.

respectively, at r = 1,000) and a further increase in r caused signiﬁcant deterioration in speciﬁcity. These results
demonstrate that a combination of asymmetric correlation with other measures could improve performance by as
much as 50%, depending on the measures chosen for combination.

Figure 7: Scatter plots of asymmetric and Pearsson coeﬃcients for the Human Protein Reference Database (HPRD) and control datasets. Asymmetric coeﬃcient and Pearson coeﬃcient (left), Spearman coeﬃcient (center) and Mutual Information (right) for known interacting pairs from
HPRD (blue) and randomely selected control pairs (red) were plotted against each other. Note the top right-hand corner of the scatter plots where
blue spots are predominant.

Why did AC perform better when it was combined with PC? Both PC and AC can show large magnitudes for
both linear and non-linear curves, but PC favors linear curves and AC favors non-linear curves. Therefore non-linear
curves can be captured better by selecting gene pairs with relatively high AC and low PC. In Figure 7, some proteininteracting pairs which did not overlap with the negative controls had high PC (¿0.8) and modest AC (2000 2500),
meaning they had linear relationships. However, there are also protein-interacting pairs which had high AC (¿3000)
with relatively low PC ( 0.4), corresponding to nonlinear asymmetric relationships, and they were found more frequently from protein-interacting pairs than the negative controls. Therefore the combination of PC and AC is more
robust than using PC or AC alone in detecting both linear and nonlinear relationships between protein-interacting
pairs.

1080

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081

0.45
Pearson
coefficient

Sensitivity at 90% specificity

Specificity/Sensitivity

0.4

Mutual information

Spearman coefficient

0.35
Spearman coefficient
0.3

Pearson coefficient
Mutual information

0.25

0

Specificity at 90% Sensitivity

1000

2000

3000

4000

5000

r

Figure 8: Sensitivity and speciﬁcity of a combined measure for detecting protein-protein interactions. The performances of a combined measure
R=r(Pearson coeﬃcient, Spearman coeﬃcient or Mutual Information)+(asymmetric coeﬃcient) are shown. The plot shows the proportion of
HPRD pairs with above-threshold values with respect to total pairs (sensitivity, shown in blue) at 90% speciﬁcity, and the proportion of control
pairs with below-threshold values with respect to total pairs (speciﬁcity, shown in red) at 90% sensitivity, respectively. Solid lines with no markers
indicate values obtained with a combination of the asymmetric coeﬃcient and the Pearson coeﬃcient, those with square markers indicate values
obtained with a combination of the asymmetric coeﬃcient and the Spearman coeﬃcient, and those with circles indicate values obtained with a
combination of the asymmetric coeﬃcient and Mutual Information.

3. Conclusions
A number of sophisticated mathematical and computational microarray analysis techniques have been developed
in recent years, but more work is needed to exploit the wealth of gene expression data in microarray and other
databases. I found that, by using a new asymmetric correlation measure, it was possible to extract new information
from passive microarray data (i.e. with no external perturbations) at a relatively low computational cost. However,
the proposed method is not intended to replace existing methods for gene network inference, because gene regulatory
mechanisms are so complex that no single analysis can ever extract all information from microarray data. Indeed, I
found that asymmetric correlation can enhance the performance of existing inference methods when the techniques
are used together. However, it should be noted that the method will not work when microarray data show little
nonlinearity, in which case the PC and MI measures will demonstrate linear relationships. Moreover, asymmetry
is just one of the many properties of nonlinearity and even the combination of AC and PC will not quantify the all
properties of nonlinearity. Although I do not fully explore the topic in this article, another important property of
asymmetric correlation is that it can produce directed graphs based on the direction of asymmetry. As asymmetry
is one of the fundamental properties of causal relationships [25, 26], it may be possible to extract information on
causality from asymmetric correlations. This should be examined systematically in future work, using both simulated
datasets and a large collection of experimental data on causal relationships between proteins.
Acknowledgements
K.Y. is the AstraZeneca Senior Research Fellow in Systems Biology, at Pembroke College, University of Cambridge, UK.
Reference
[1] A. D. Baxevanis, B. F. F. Ouellette. (Eds.), Bioinformatics : a practical guide to the analysis of genes and proteins, 3rd Edition, John Wiley &
Sons, Inc., 2005.
[2] A. Dupuy, R. M. Simon, Critical review of published microarray studies for cancer outcome and guidelines on statistical analysis and
reporting., J Natl Cancer Inst 99 (2) (2007) 147–157.

Kojiro Yano. / Procedia Computer Science 4 (2011) 1072–1081

1081

[3] R. Jansen, D. Greenbaum, M. Gerstein, Relating whole-genome expression data with protein-protein interactions., Genome Res 12 (1) (2002)
37–46.
[4] K. H. Zou, K. Tuncali, S. G. Silverman, Correlation and simple linear regression., Radiology 227 (3) (2003) 617–622.
[5] R. Moddemeijer, On estimation of entropy and mutual information of continuous distributions, Signal Processing 16 (3) (1989) 233–246.
[6] A. Almudevar, L. B. Klebanov, X. Qiu, P. Salzman, A. Y. Yakovlev, Utility of correlation measures in analysis of gene expression., NeuroRx
3 (3) (2006) 384–395.
[7] I. Tirosh, N. Barkai, Computational veriﬁcation of protein-protein interactions by orthologous co-expression., BMC Bioinformatics 6 (2005)
40.
[8] H. B. Fraser, A. E. Hirsh, D. P. Wall, M. B. Eisen, Coevolution of gene expression among interacting proteins., Proc Natl Acad Sci U S A
101 (24) (2004) 9033–9038.
[9] T.-T. Soong, K. Wrzeszczynski, B. Rost, Physical protein-protein interactions predicted from microarrays, Bioinformatics 24 (2008) 2608,
10.1093/bioinformatics/btn498.
[10] J. Zhang, Y. Ji, L. Zhang, Extracting three-way gene interactions from microarray data., Bioinformatics 23 (21) (2007) 2903–2909.
[11] W. Luo, K. D. Hankenson, P. J. Woolf, Learning transcriptional regulatory networks from high throughput gene expression data using
continuous three-way mutual information., BMC Bioinformatics 9 (2008) 467.
[12] D. Pe’er, A. Regev, G. Elidan, N. Friedman, Inferring subnetworks from perturbed expression proﬁles., Bioinformatics 17 Suppl 1 (2001)
S215–S224.
[13] A. Djebbari, J. Quackenbush, Seeded bayesian networks: Constructing genetic networks from microarray data, BMC Systems Biology 2
(2008) 57, 10.1186/1752-0509-2-57.
[14] A. V. Werhli, M. Grzegorczyk, D. Husmeier, Comparative evaluation of reverse engineering gene regulatory networks with relevance networks, graphical gaussian models and bayesian networks, Bioinformatics 22 (2006) 2523–2531, 10.1093/bioinformatics/btl391.
[15] C. Zhang, P. Li, A. Rajendran, Y. Deng, D. Chen, Parallelization of multicategory support vector machines (pmc-svm) for classifying microarray data., BMC Bioinformatics 7 Suppl 4 (2006) S15.
[16] S. Ramaswamy, P. Tamayo, R. Rifkin, S. Mukherjee, C. H. Yeang, M. Angelo, C. Ladd, M. Reich, E. Latulippe, J. P. Mesirov, T. Poggio,
W. Gerald, M. Loda, E. S. Lander, T. R. Golub, Multiclass cancer diagnosis using tumor gene expression signatures., Proc Natl Acad Sci U
S A 98 (26) (2001) 15149–15154.
[17] M. Zampieri, N. Soranzo, C. Altaﬁni, Discerning static and causal interactions in genome-wide reverse engineering problems., Bioinformatics
24 (13) (2008) 1510–1515.
[18] H. Parkinson, M. Kapushesky, N. Kolesnikov, G. Rustici, M. Shojatalab, N. Abeygunawardena, H. Berube, M. Dylag, I. Emam, A. Farne,
E. Holloway, M. Lukk, J. Malone, R. Mani, E. Pilicheva, T. F. Rayner, F. Rezwan, A. Sharma, E. Williams, X. Z. Bradley, T. Adamusiak,
M. Brandizi, T. Burdett, R. Coulson, M. Krestyaninova, P. Kurnosov, E. Maguire, S. G. Neogi, P. Rocca-Serra, S.-A. Sansone, N. Sklyar,
M. Zhao, U. Sarkans, A. Brazma, Arrayexpress update–from an archive of functional genomics experiments to the atlas of gene expression.,
Nucleic Acids Res 37 (Database issue) (2009) D868–D872.
[19] R. C. Gentleman, V. J. Carey, D. M. Bates, B. Bolstad, M. Dettling, S. Dudoit, B. Ellis, L. Gautier, Y. Ge, J. Gentry, K. Hornik, T. Hothorn,
W. Huber, S. Iacus, R. Irizarry, F. Leisch, C. Li, M. Maechler, A. J. Rossini, G. Sawitzki, C. Smith, G. Smyth, L. Tierney, J. Y. H. Yang,
J. Zhang, Bioconductor: open software development for computational biology and bioinformatics., Genome Biol 5 (10) (2004) R80.
[20] T. S. K. Prasad, R. Goel, K. Kandasamy, S. Keerthikumar, S. Kumar, S. Mathivanan, D. Telikicherla, R. Raju, B. Shafreen, A. Venugopal,
L. Balakrishnan, A. Marimuthu, S. Banerjee, D. S. Somanathan, A. Sebastian, S. Rani, S. Ray, C. J. H. Kishore, S. Kanth, M. Ahmed,
M. K. Kashyap, R. Mohmood, Y. L. Ramachandra, V. Krishna, B. A. Rahiman, S. Mohan, P. Ranganathan, S. Ramabadran, R. Chaerkady,
A. Pandey, Human protein reference database–2009 update., Nucleic Acids Res 37 (Database issue) (2009) D767–D772.
[21] O. G. Troyanskaya, M. E. Garber, P. O. Brown, D. Botstein, R. B. Altman, Nonparametric methods for identifying diﬀerentially expressed
genes in microarray data., Bioinformatics 18 (11) (2002) 1454–1461.
[22] A. Benecke, Genomic plasticity and information processing by transcription coregulators, Complexus 1 (2003) 65, 10.1159/000070463.
[23] H. Bolouri, E. H. Davidson, Modeling transcriptional regulatory networks, Bioessays 24 (2002) 1118–1129, 10.1002/bies.10189.
[24] R. A. Veitia, A sigmoidal transcriptional response: cooperativity, synergy and dosage eﬀects., Biol Rev Camb Philos Soc 78 (1) (2003)
149–170.
[25] D. Hausman, Causal Asymmetries, Cambridge: Cambridge University Press, 1998.
[26] B. Shipley, Cause and Correlation in Biology, Cambridge: Cambridge University Press, 2002.

