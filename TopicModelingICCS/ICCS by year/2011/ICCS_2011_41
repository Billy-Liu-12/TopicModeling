Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1403–1411

International Conference on Computational Science, ICCS 2011

A Monte Carlo Method for High-Dimensional Volume Estimation
and Application to Polytopes
Uwe Jaekel∗
Department of Mathematics and Technology, University of Applied Sciences Koblenz, 53424 Remagen, Germany

Abstract
A direct Monte Carlo method for volume estimation of star-shaped or convex domains is presented, and is generalized to a Markov Chain Monte Carlo method for high-dimensional problems. The direct approach itself, which is
closely related to a method proposed by Fok and Crevier, is already applicable to some moderately high-dimensional
problems. The combination with a Markov Chain Monte Carlo method and nested sampling or thermodynamic integration extends its scope considerably. Applications to the volume estimation for high-dimensional polytopes are
presented, and the method is tested using exact results for the ﬁrst 10 Birkhoﬀ polytopes.
Keywords: Volume estimation, Monte Carlo methods, Thermodynamic integration, Polytopes, Birkhoﬀ polytopes

1. Introduction
Estimating the volume of a high-dimensional domain is a diﬃcult problem with important applications in many
ﬁelds. The ﬁrst random polynomial time algorithm for approximating the volume of a convex body has been proposed
by Dyer, Frieze and Kannan [1] with a very high power of the dimension d, that could be reduced in later works.
Currently, the best available algorithm [2] is based on a multiphase Markov chain Monte Carlo approach that requires
O∗ (d4 ) calls of a membership oracle, where O∗ (d4 ) means O(d4 ) up to polynomial factors in log(d).
In this paper, an alternative Monte Carlo algorithm is constructed from a representation of the volume of a convex
or star shaped domain as an integral over the unit sphere. This allows to construct a direct Monte Carlo method that
already leads to good results for some interesting test problems with fewer than about 20 dimensions. For higherdimensional problems, however, the curse of dimensionality is reﬂected in the occurrence of very sharp peaks of the
integrand, such that it becomes necessary to combine this method with importance sampling techniques.
To overcome the limitations of the direct Monte Carlo approach, a generalization of this method to a Markov
Chain Monte Carlo (MCMC) approach is presented that is based on the interpretation of the integrand as a probability
distribution with an unknown normalization coeﬃcient. The Metropolis-Hastings method allows to sample preferably close to peaks of the integrand without knowledge of the normalization factor. In order to ﬁnd the latter, the
Metropolis-Hastings method is combined with a thermodynamic integration method. Thermodynamic integration is a
∗

Email address: jaekel@rheinahrcampus.de (Uwe Jaekel)

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.151

1404

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

method originating in statistical physics and can favorably be combined with parallel tempering approaches that allow
to overcome problems arising from the possibly highly multi-modal density over the unit sphere.
An important application of volume estimation, relevant e.g. in theoretical and systems biology ([4], [5], [6]) is
volume estimation for high-dimensional polytopes. The methods developed in this paper were tested with the ﬁrst 10
Birkhoﬀ polytopes, for which exact results are known ([7]-[9]). The Birkhoﬀ polytopes are sets of doubly stochastic
matrices occurring in a wide range of applications from combinatorial optimization to quantum information.
2. A direct Monte Carlo method for volume estimation
2.1. The general idea
A direct Monte Carlo method for volume estimation in high-dimensional spaces has been proposed by Fok and
Crevier [3], assuming that it is possible to ﬁnd for every direction e the point at which a straight line starting from
an interior point of the domain with direction e hits the boundary. In many important applications this can be done
eﬃciently, either in closed form or by iterative methods.
We derive a related, but not completely equivalent method using Gauss’ divergence theorem, assuming that Ω ⊂
Rd is a compact domain with piecewise smooth boundary. Let F be a vector ﬁeld with constant divergence divF = 1.
A natural – but not necessarily optimal – choice is F(x) = d1 x. Then the volume V of the domain can be computed
using the divergence theorem
V

=

Ω

dV =

divF dV =
K

∂Ω

divF · n dσ,

(1)

where ∂Ω is the boundary of the domain, n(x) is the outer normal vector at the point x of the boundary, dσ is the
(d − 1)-dimensional volume element on the boundary, and a · b denotes the scalar product of the two vectors a and b.
For the moment, we assume that K is star shaped around an interior point x0 located inside Ω. Then the volume can
be estimated as a Monte Carlo integral over F · n using the following algorithm:
1. Draw K vectors ek , k = 1 . . . K uniformly distributed from the unit sphere.
2. Starting from x0 , move along direction ek until the boundary is hit, i.e. compute the smallest parameter tk > 0
such that xk = x0 + tek lies on the boundary.
3. Compute the normal vector nk and the value Fk of the vector ﬁeld F at xk .
The volume element on the unit sphere is scaled by the projection to the boundary at xk by a factor of td−1 /nk · ek . The
surface hypervolume of the n-dimensional unit sphere is Ad = 2Γ(d/2)/πd/2 and we ﬁnd for the Monte Carlo estimator
2Γ(d/2)
Vˆ K =
Nπd/2

K
k=1

Fk · nk d−1
t
→V
ek · nk k

for K → ∞.

(2)

2.2. Choice of the vector ﬁeld and the Fok-Crevier estimator
For the choice F(x) = d1 x, the estimator becomes
Vˆ K

=

2Γ(d/2)
dKπd/2

K
k=1

xk · nk d−1
t .
ek · n k k

(3)

The origin of the co-ordinate system can be located anywhere. However, in order to minimize the variance and to
avoid roundoﬀ errors, the projection xk · nk should not change its sign, i.e. the origin should lie inside Ω. If the origin
is shifted to the point x0 , the search direction vector ek is parallel to the boundary vector xk = tk ek , such that the
estimator reduces to
Vˆ K

=

2Γ(d/2)
dKπd/2

K
k=1

tk ek · nk d−1 2Γ(d/2)
t
=
ek · n k k
dKπd/2

K

tkd .
k=1

(4)

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

1405

This is the estimator proposed by Fok and Crevier [3], which can therefore be regarded as a special case of the
estimator in Eq. (2). Note, however, that the estimator in Eq. (4) can be derived without assumptions on the smoothness
of the boundary ∂Ω.
It remains to be shown that there are reasonable choices for the vector ﬁeld F and the location of the reference
point x0 other than those leading to the estimator by Fok and Crevier. In order to see that, consider a thin rectangle I =
{(x, y)|0 ≤ x ≤ 1 ∧ 0 ≤ L} where L 1, and assume that the integral shall be computed using an importance sampling
method (such as the Markov Chain Monte Carlo method developed in section 3), in a variant where x0 = (0, 0), and the
integral is only over the intersection of the unit sphere with the ﬁrst quadrant.
√ For the choice leading to the Fok-Crevier
estimator, the MCMC method will sample values for t ranging from 1 to L2 + 1. If we choose F(x, y) = (0, y), the
value of F · n will only be non-zero on the upper boundary {(x, y)|0 ≤ x ≤ 1 ∧ y = L}. Therefore,
importance sampling
√
will avoid the right boundary completely, and sample only values for t ranging from L to L2 + 1, leading to a much
smaller variance of the estimator.
2.3. Generalizations
2.3.1. Membership oracles and convex domains
Many of the available methods for volume estimation only require the existence of a membership oracle, which for
the general case is a much less restrictive requirement than an algorithm that computes all intersections of a straight
line with the boundary of the inspected domain. However, for convex domains, starting from an interior point x0 , a
membership oracle can be used to ﬁnd the intersection points eﬃciently by line search methods. A membership oracle
is therefore not a less restrictive requirement for convex domains.
2.3.2. Integrations over domains that are not star shaped
For domains that are not convex or star shaped, the generalization is straightforward in principle, and analogous to
the construction in [3], provided there is an algorithm that yields all intersections of a straight line with the boundary
of the domain as well as the oriented normal vectors in these boundary points. This requirement is obviously fulﬁlled
for polytopes. However, the non-negativity of the integrand will be lost, which makes the application of the MCMC
generalization developed in section 3 more diﬃcult.
2.4. Application to convex polytopes
2.4.1. Polytopes without equality constraints
A convex polytope can be characterized as the solution set of multiple inequalities:
P = x ∈ Rd Ax≤b
where A is an r × d-matrix, b ∈ Rr , and the inequality is to be understood componentwise. In this case, the value t
where x = x0 + te hits the boundary is the minimal value t > 0 above which one of the constraints is violated. If a j is
the j-th row vector of A, and b j the j-th component of b, this value can be computed from
t( j) =

b j − a j · x0
,
aj · e

j = 1, . . . r

t = min t(1) , . . . , t(r) ∩ t( j) t( j) > 0 .
The normal vector of the surface that has been hit is the corresponding row vector of A.
2.5. Polytopes with equality constraints
Many polytopes useful in practical applications are deﬁned via mixed inequality and equality constraints:
P = x ∈ Rd A≤b ∧ Cx = d
where A is an s ×d-matrix, d ∈ R s . Interesting special cases are transportation or ﬂux polytopes that play an important
role, e.g. for biomedical applications in the description of metabolic networks [5], [4]. The algorithm can be adapted

1406

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

easily to this problem by the computation constructing an inner point of the polytope, and then restricting the search
directions to the null space of C.
Famous representatives of this class are the Birkhoﬀ polytopes which serve as test problems in this paper. The n-th
Birkhoﬀ polytope Bn is formed by the set of doubly stochastic n × n matrices, i.e. matrices with non-negative entries
where all row sums and all column sums are equal to 1. The Birkhoﬀ polytopes therefore form an (n−1)2 -dimensional
subspace of the space of n × n matrices. Bn has n2 facets and, as it can be characterized as the convex hull of the
n-dimensional permutation matrices, n! vertices. The Birkhoﬀ polytopes were selected as non-trivial reference cases
since exact results have been derived for the volumes of the ﬁrst 10 Birkhoﬀ polytopes [7],[8], [9] in the case of B10
by a long and massive computation on a workstation farm. The volume of B10 is
volB10 ≈ 8.8 · 10−46
relative to the 81-dimensional unit hypercube. The naive Monte Carlo approach by sampling from the unit hypercube
and counting points hitting the polytope is obviously hopeless in this case.
2.6. Application of the direct approach to high-dimensional polytopes
The direct algorithm can be implemented in a few lines of MATLAB code. There are only two implementation
details one should care about:
1. For this straightforward implementation, the reference point x0 obviously should not be located close to a vertex:
If the vertex is, for instance, the intersection of d orthogonal hyperplanes, the probability that a direction vector
sampled from a uniform distribution on the unit sphere does not point to one of the nearby facets converges to
2−d . With a probability of of 1−2−d , the distance t to the boundary will be tiny and give a negligible contribution
to the integral, as the integrand is proportional to td . If available, an estimation for the center of the polytope
is a good choice. Alternatively, since the expectation value does not depend on the location of x0 , it is possible
to let the reference point walk through the polytope. Good results can be achieved by keeping track of the
maximum value of the integrand on the sample, and moving the reference point to x0 + 12 tk ek whenever the
integrand exceeds a few percent of the maximum.
2. It should be controlled if the polytope is thin in one or more directions. This can be achieved by keeping track of
the covariance matrix C of the sampled boundary points. Small eigenvalues reveal “thin directions” in form of
the corresponding eigenvectors. These can be compensated by rescaling the coordinates using the eigenvectors
as a new basis.
The direct method described above was tested with standard simplices and Birkhoﬀ the polytopes B1 , . . . , B10 .
The volume of the d-dimensional standard simplex
⎧
⎫
d
⎪
⎪
⎪
⎪
⎨
⎬
d
Δd−1 = ⎪
0
≤
x
x
∈
R
≤
1∀i
=
1
.
.
.
d
∧
x
=
1
⎪
i
i
⎪
⎪
⎩
⎭
i=1

−33

is 1/d!. For d = 30, this is about 3.77 · 10 , so again the naive Monte Carlo approach counting hits from uniformly
distributed samples in the unit hypercube is not applicable.
In many applications, such as the estimation of the evidence of a model or the evidence against a hypothesis,
it is suﬃcient to estimate the order of magnitude of the results. If we regard the method (somewhat arbitrarily) as
applicable if it gives the correct order of magnitude, i.e. a logarithmic (log10 ) diﬀerence between the exact result and
the estimator less than 1/2 and a corresponding conﬁdence interval, within a computation time of about 1 hour on a
single core of a 2GHz PC, the algorithm seems to work up to d ≈ 35 . . . 45 for the simplex, with much better accuracy
of course for lower dimensions. The volume of a 10-dimensional standard simplex (volΔ9 ≈ 2.76 · 10−7 ), for instance,
can be computed with two correct decimal places within a few minutes. These results were consistent with the results
for the Birkhoﬀ polytope: The order of magnitude is correct for B6 (25 dimensions) after a few minutes, while
the algorithm needs hours for B7 (36 dimensions). These results can be improved of course by variance reduction
techniques. Nevertheless it is worthwhile to note that already this simple method gives good results for moderately
high dimensions, at least in applications that don’t require too many computations on varying domains. In general,
however, for more than 20 dimensions, one would certainly wish for lower variance estimators, which we shall focus
on in the following section.

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

1407

2.7. Importance sampling
For polytopes, the weight td of the integrand is obviously sharply peaked at the vertices. Therefore, importance
sampling methods can be tailored to the polytope that sample preferably around the vertices of the polytope. For the
Birkhoﬀ polytope this is particularly easy since its vertices are many, but known, and all have the same distance to
the matrix ai j = 1/n ∀1 ≤ i, j ≤ n. However, in order to generalize the method also for higher-dimensional domains
that are not bounded by hyperplanes (such as level sets of a convex function), we will focus on a Markov Chain Monte
Carlo variant.
3. A generalization based on Markov Chain Monte Carlo methods
If the domain does not have an almost circular shape, the values of the integrand, that contains a factor proportional
to td will ﬂuctuate over many orders of magnitude for high dimensions, and will be sharply peaked around its maxima.
If the vector ﬁeld is chosen such that F · x is non-negative, as it is the case e.g. in the Fok-Crevier estimator in Eq. (4),
we can interpret the integrand normalized to the volume
p(x) :=

1 F · n d−1
t
V e·n k

(5)

as a probability density. Expectations under this density can be estimated using Markov Chain Monte Carlo methods such as the Metropolis-Hastings algorithm in which the density has to be known only up to a constant factor.
The problem now is that the normalization constant is the volume that we wish to compute, and therefore remains
unknown. Several approaches to the problem of estimating normalization constants, such as nested sampling or bridging or annealing techniques, have been suggested in diﬀerent disciplines ([11], [12]). For the purpose of this paper,
we choose a method called thermodynamic integration due to its interpretation in statistical physics. The method is
equivalent to bridge sampling.
3.1. Thermodynamic integration
In order to express the volume as an expectation under the density in Eq. (5), we introduce a family of densities
pβ (x) :=

1
1
f (x)β =
exp (β ln f (x)) ,
Z(β)
Z(β)

(6)

where
Z(β) =

exp (β ln f (x(ω))) dω,

(7)

S d−1

where S d−1 is the d-dimensional unit sphere. In statistical physics, β is interpreted as an inverse temperature. Obviously, for β = 0, the integrand is 1, and Z(0) is the surface hypervolume of S d−1 , such that
Z(0)

=

Ad =

Z(1)

=

V

2Γ(d/2)
πd/2
(8)

On the other hand,
ln

Z(1)
Z(0)

1

=
0

1

=
0

d
ln Z(β) dβ
dβ
1
ln f (x(ω)) exp (β ln f (x)) dβ
Z(β) S d−1

1

=

S d−1

0

ln f (x(ω))pβ (x(ω)) dω dβ

1

=
0

E pβ ln f dβ

(9)

1408

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

where E pβ ln f is the expectation value of ln f under the density pβ . The integrand can be estimated using the
Metropolis-Hastings algorithm for any given value of β, such that the integral can be computed numerically. A simple
choice for the proposal distribution is a random walk step on the unit sphere, such that for any given β, a simple
algorithm for the evaluation of the integrand in a ﬁxed number K of steps starting with a search direction e0 with a
value f0 = f (x0 ) of the integrand is as follows:
1. fork = 1 . . . K
2.
Draw a direction vector e uniformly distributed on the unit sphere.
3.
Set e = (ek−1 + δξe ) where 0 < δ < 1 is a ﬁxed constant, and ξ ∈ U(0, 1) is a uniformly distributed random num
4.
Set e = e /||e ||.
5.
Set f to the value of f in direction e .
β
6.
Accept e as new search direction ek with probability min(1, f β / fk−1
),
otherwise let the search direction remain unchanged, i.e. ek = ek−1 .
7.
Set fk to the value of f in direction ek .
8. end for.
K
9. Let IˆK (β) = K1 k=1
fkβ .
As usual, one should perform a bigger number of Metropolis steps (2-6) before IˆK is sampled, in order to make sure
that the starting direction e0 is not too far away from a peak. The volume can then be estimated from
1

V = Z(1) = Ad exp
0

E pβ ln f dβ ,

and the MCMC estimator for V is
Vˆ KMCMC = Ad exp

(10)

1

IˆK (β) dβ

(11)

0

1

where the integral 0 IˆK (β) dβ is evaluated numerically.
For a general high-dimensional polytope, the distribution will be highly multimodal, and so sharply peaked that
transitions of the Markov chains from one peak to another are very unlikely. Therefore, if one wants to use the
simple algorithm above, it is necessary to restart the algorithm with diﬀerent random start directions e0 repeatedly,
and average over the resulting values of IˆK . A much better alternative is to evaluate the integral using path sampling
techniques that elegantly combine transitions between the peaks at lower values of β and exploration of the details of
f at β ≈ 1 ([11], [12]).
3.2. Parallel tempering
Parallel tempering [13] is a technique to keep Markov chains from getting caught in local modes. Not necessarily
related to thermodynamic integration, the idea is to run Markov chains at diﬀerent “inverse temperatures” β, with
densities deﬁned as in the previous section, and allow the exchange states between diﬀerent temperatures 0 = β1 <
β2 < . . . < β M = 1. The MCMC method described above is augmented by additional “replica exchange” steps that
accept a proposed swap of the state e( j) at inverse temperature β j and the state e(i) at another βi (usually i = j − 1) with
probability
min 1, exp (β j − βi ) H(e(i) ) − H(e( j) )
where H = ln f . This rule guarantees detailed balance and therefore under mild restrictions convergence of the
Markov chains at all temperatures. Markov chains that would otherwise be trapped for large values of β close to a
local maximum of the density f , are released by parallel tempering, since transitions between local modes are very
likely for suﬃciently small values of β. Often, one is interested only in the distribution for β = 1, but for the case of
thermodynamic integration, all copies at all temperatures are contributing to the evaluation of the integral.

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

1409

3.3. Numerical results
Table 1 shows the results for a straightforward MATLAB implementation of the parallel tempering MCMC method
described above, applied to the Birkhoﬀ polytopes B5 . . . B10 , on a single core of a 2.67 GHz workstation. 100 Copies
of a Markov chain at diﬀerent temperatures were used, equally spaced between 0 and 1. The integral in Eq. (11) was
estimated using the midpoint rule. Parameters of the method, such as δ in the proposal distribution or the length of
the chain were the same for all dimensions and not optimized. The Markov chains were restarted repeatedly, and the
length of the chains just made large enough to ensure convergence for B10 . 95% conﬁdence intervals for the volumes
were computed from the values between restarts. In all cases, the exact value was located inside the conﬁdence
interval, and a relative error of better than 5% was achieved, if we deﬁne this as ratio of the half length of the 95%
conﬁdence interval and the exact value. Fig. 1 visualizes the good agreement of exact and Monte Carlo values with
results varying over many orders of magnitude.
The estimation for B10 with an error of 5% in this implementation (not tuned for eﬃciency) took about 12 hours.
An exact result is of much higher value of course, but for comparison, it is interesting to note that [8] reports that the
total computation time needed to ﬁnd the exact value of volB10 on a workstation farm – scaled down to a single 1GHz
processor – was almost 17 years.
Fig. 2 shows how the computation time required to get a relative error of 5% depends on the number of dimensions.
A double logarithmic ﬁt indicates a that the computation time increases with a power law dν with an exponent ν ≈ 2.92.
This dependence has to be investigated for a larger class of polytopes and higher dimensions, but it provides some
evidence that the algorithm proposed can compete with the best available algorithm that requires O∗ (d4 ) oracle calls.
Table 1: MCMC volume estimation of the Birkhoﬀ polytopes.

Polytope
B5
B6
B7
B8
B9
B10

Dimensions
16
25
36
49
64
81

Exact value
1.40937 · 10−4
7.35257 · 10−9
5.63984 · 10−15
4.41855 · 10−23
2.59833 · 10−33
8.78201 · 10−46

MCMC value
1.404 · 10−4
7.357 · 10−9
5.669 · 10−15
4.463 · 10−23
2.611 · 10−33
8.860 · 10−46

95% conﬁdence interval
[1.398, 1.410] · 10−4
[7.304, 7.411] · 10−9
[5.604, 5.735] · 10−15
[4.392, 4.535] · 10−23
[2.549, 2.673] · 10−33
[8.490, 9.247] · 10−46

Computation time [sec]
31251
33679
35640
36822
42107
44649

4. Summary and conclusions
In this work, a direct Monte Carlo method for high-dimensional volume estimation based on the representation of
the volume as a surface integral over the unit sphere was developed as well as an MCMC variant. The direct method
is related to a method developed by Fok and Crevier, and already can give good results for interesting cases with a
moderate number dimensions. For high dimensions, d
10, the representation usually leads to a sharply peaked
and multimodal integrand that requires the usage of importance sampling techniques. Markov Chain Monte Carlo
methods for the computation of normalizing factors were used to derive an algorithm that also works in much higher
dimensions. The methods were tested successfully for up to 81 dimensions, for an estimation of the volume of the
Birkhoﬀ polytope B10 .
For the Birkhoﬀ polytopes investigated, the computation time shows a O(dν )-dependence on the number d of
dimensions, with a comparatively small value ν ≈ 3. Since the best available algorithm for volume computation [2]
has a running time of O∗ (d4 ), it is interesting to study the behaviour of the method for a larger class of polytopes and
higher dimensions. The method proposed can be further improved using more sophisticated path sampling techniques
([11], [12]) and adaptive MCMC methods ([14], [15]).
Acknowledgments
I thank Maik Kschischo, Claus Neidhardt and Matthias Beck for helpful discussions.

1410

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

0

10

MCMC result
analytical value
−10

10

−20

n

vol(B )

10

−30

10

−40

10

−50

10

5

6

7

8

9

10

n

Figure 1: Volumes of the Birkhoﬀ polytopes B5 . . . B10 .

6

10

MCMC runs
fit ∝ d2.92
power law ∝ d4

5

computation time [sec]

10

4

10

3

10

2

10

1

10
1
10

2

10
d

Figure 2: Dependence of the computation times required to achieve 5% accuracy using the MCMC method.

Uwe Jaekel et al. / Procedia Computer Science 4 (2011) 1403–1411

1411

References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]

M. Dyer et al., 1991. JACM (38)1.
L. Lov´asz and S. Vempala, 2006, J. Comput. Syst. Sci. (72) 392.
D.S.K. Fok and D. Crevier, 1989, J. Statist. Comput. Simul.(31) 223.
E. Almaas et al. , 2004, Global organization of metabolic ﬂuxes in the bacterium Escher- ichia coli. Nature. 427 (6977), 839?84.
S.J. Wiback et al, 2004, J. Theor. Biol. (228) 437.
M. Kschischo, 2010, Eur. Phys. J. Special Topics (187) 255.
M. Beck and D. Pixton, 2003, Discrete and Computational Geometry (30), 623.
M. Beck and D. Pixton, http://www.math.binghamton.edu/dennis/Papers/birkhoff.10.pdf.
M. Beck and D. Pixton, Volume of the Birkhoﬀ polytope for n =1, ..., 10,
http://www.math.binghamton.edu/dennis/Birkhoff/volumes.html.
R. E. Kass and A. E. Raftery, Journal of the American Statistical Association, Vol. 90, No. 430. (Jun., 1995), pp. 773-795.
A. Gelman and X.-L. Meng, 1998, Stat. Sci. (13), 163.
I. Murray, Advances in Markov chain Monte Carlo methods, PhD thesis, 2007, Gatsby computational neuroscience unit, University College
London, http://homepages.inf.ed.ac.uk/imurray2/pub/07thesis/murray_thesis_2007.pdf, and references therein.
D. Gamerman and H.F. Lopes, 2006, Markov chain Monte Carlo: stochastic simulation for Bayesian Inference, 2nd edn. Chapman & Hall,
London
C. Andrieu and J. Thoms, 2008, Stat. Comput. (18), 343.
H. Haario et al., 2006, Stat. Comput. (16), 339.

