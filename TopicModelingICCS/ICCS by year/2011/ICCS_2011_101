Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1422–1430

A Trust-Region Algorithm for Bi-Objective Stochastic
Optimization
Sujin Kima,1 , Jong-hyun Ryua,∗
a National

University of Singapore 1 Engineering Drive 2, 117576, Singapore

Abstract
We develop a new method for approximating the Pareto front of a bi-objective stochastic optimization problem in
which the expected objective functions are estimated by taking sample averaged outputs from expensive simulations.
At each iteration of the proposed algorithm, a trust region is identiﬁed and quadratic approximate functions for the
expected objective functions are built using the sample average values. To determine non-dominated solutions in the
trust region, a single-objective optimization problem is constructed based on the approximate objective functions.
After updating the set of non-dominated solutions, a new trust region around the most isolated point is determined
to explore areas that have not been visited. When the computational budget is limited, a large sample size at each
iteration leads to more accurate approximation of the expected objective functions, but the algorithm is not able to
run for enough iterations to generate a set of solutions that are close to the Pareto front. The proposed variable
sampling scheme adaptively updates the sample size with consideration for this trade-oﬀ between approximation and
optimization errors. The numerical results show that our proposed method is feasible, and the performance can be
signiﬁcantly improved with an appropriate sampling scheme.
Keywords: multi-objective optimization, stochastic programming, sample average approximation, trust-region
method,

1. Introduction
Multi-objective optimization problems arise in a wide range of areas such as economics and engineering. For
example, a product designer might want to simultaneously optimize several critical factors [1, 2, 3], or a ﬁnancial
portfolio manager looks for a position where both return and risk can be optimized [4]. Diﬀerent objectives often
conﬂict with each other, and a single decision cannot optimize all the objectives at the same time. Therefore, the notion
of optimality in single-objective optimization cannot be directly applied to multi-objective optimization problems,
and it is necessary to introduce a new concept of optimality in this framework. The optimal decision may be taken by
identifying the best trade-oﬀs among the multiple objectives, which is often the goal of multi-objective optimization.
More speciﬁcally, the best trade-oﬀ solutions can be described by the notion of Pareto optimality or Pareto eﬃciency,
which has been regarded as an important criterion of performance for multi-objective optimization in economics and
engineering systems.
∗ Research

fellow in the department of Industrial Systems & Engineering
Email addresses: isesk@nus.edu.sg (Sujin Kim), iserj@nus.edu.sg (Jong-hyun Ryu)
1 Assistant professor in the department of Industrial Systems & Engineering

1877–0509 © 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.153

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

1423

When the number of objectives is p, the multi-objective optimization problem can be formally expressed as follows:
min F(x) = ( f1 (x), f2 (x), ..., f p (x)),
x∈X

where X is a subset of Rq and F : X → R p is a vector valued function. In this paper, we assume that X is continuous.
Pareto optimality for the problem with the above form is deﬁned by the dominance relationship [5].
Deﬁnition 1. Let xu , xv ∈ X be two decision vectors. F(xu ) dominates F(xv ) (denoted by F(xu ) ≺ F(xv )) if and only
if fi (xu ) ≤ fi (xv ), for all i ∈ {1, 2, ..., p} and there exists l ∈ {1, 2, ..., p} such that fl (xu ) < fl (xv ).
Deﬁnition 2. A point x∗ ∈ X is said to be globally Pareto optimal if and only if there is no x ∈ X such that F(x) ≺
F(x∗ ). F(x∗ ) is called globally eﬃcient and the image of the set of globally eﬃcient points is called the Pareto front.
In the case where the Pareto front is disconnected, it is hard to develop a method that can guarantee the global
Pareto optimality for a general class of problems. In this work, we focus on searching for a Pareto front in a local
region instead.
Deﬁnition 3. A point x∗ ∈ X is said to be locally Pareto optimal if and only if there exists an open neighborhood of
x∗ , N(x∗ ), such that there is no x ∈ N(x∗ ) ∩ X satisfying F(x) ≺ F(x∗ ). F(x∗ ) is then called locally eﬃcient and the
image of the set of locally eﬃcient points is called the local Pareto front.
One of the most widely used approaches to solve multi-objective optimization problems in the above form is to
convert them into single-objective problems. The weighted sum method (WS) [3, 6] takes a convex combination of the
multiple objectives and minimizes it. By taking diﬀerent weight combinations, a desired number of optimal solutions
can be identiﬁed and used to approximate the Pareto front. However, the WS method has a serious limitation: it is
able to ﬁnd points only on the convex part of the Pareto front. Audet et al. [7] focuses particularly on a class of
bi-objective problems and applies a direct search method to a series of single-objective problems that are designed
to detect solutions on both convex and nonconvex parts of Pareto front. The algorithm generates a set of points
converging to the Pareto front, but the convergence rate may be slow when the dimension of the considered problem
is high. Ryu et al. [8] developed a trust-region method for the bi-objective black-box optimization problem. Their
numerical results show that the proposed algorithm performs well for both convex and nonconvex problems and
outperforms the method developed by Audet et al. [7] for a certain set of problems. For large-scale, complex problems,
an evolutionary algorithm combined with the weighted sum method can be considered [5, 9]. The algorithm is not
guaranteed to converge, and can be computationally expensive because a massive number of non-Pareto set points
should be evaluated while searching for Pareto optimal solutions.
In this paper, we consider black-box problems where the analytic forms of the objective functions fi , i = 1, . . . , p,
are not available, and the values can only be estimated by output responses from computationally expensive simulations. In addition, we assume that the estimated function values contain stochastic white noise. We are particularly
interested in unconstrained stochastic bi-objective problems with the following form:
minq F(x) = ( f1 (x), f2 (x)) := EF(x, ξ) = E f1 (x, ξ1 ), f2 (x, ξ2 ) .
x∈R

(1)

ξ1 and ξ2 are random vectors deﬁned on a probability space (Ω, F , P) with support Ξ1 and Ξ2 , respectively. The
sample objective functions fi (·, ·) : Rq × Ξi → R, i = 1, 2, are real valued functions, and their values are evaluated via
simulation. The value of the expected functions cannot be computed exactly, but can be estimated via sample averages.
We assume that the two objective functions f1 and f2 are in conﬂict with each other and have ﬁnite minimum values.
In general, multi-objective optimization is considered to be diﬃcult because the goal is to ﬁnd a set of solutions
that can accurately approximate the Pareto front, rather than search for a single solution. The stochastic noise in the
sample response adds another layer of complexity and challenge to the problem. A very limited work is found in the
literature in this area. Lee et al. [10] develop a ranking & selection procedure for a multi-objective problem with a
ﬁnite number of feasible designs.
To approximate the problem (1), we take the sample average approximation (SAA) approach. The basic idea of
SAA is to replace the expected value function by the sample average, and then solve the resulting problem using a
deterministic optimization algorithm [11]. The SAA problem to the problem (1) is deﬁned by

1424

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

⎧
⎛
⎪
⎜⎜ 1
⎪
⎨ˆ
minq ⎪
F(x) = fˆ1 (x), fˆ2 (x) = ⎜⎜⎜⎝
⎪
x∈R ⎩
N

N
r=1

1
f1 (x, ξ1r ),
N

N
r=1

⎞⎫
⎟⎟⎪
⎪
⎬
f2 (x, ξ2r )⎟⎟⎟⎠⎪
,
⎪
⎭

(2)

where N is the sample size and (ξ11 , ξ21 ), (ξ12 , ξ12 ), . . . , (ξ1N , ξ1N ) are N independent replications of (ξ1 , ξ2 ).
To identify non-dominated solutions, we modify the trust-region method for multi-objective deterministic optimization developed by Ryu et al. [8] and apply it to the SAA problem (2). At each iteration of the proposed
algorithm, a trust region is identiﬁed and quadratic approximate functions for the expected objective functions are
built using the sample average values at design points selected within a trust region. A single-objective optimization
problem is constructed based on the approximate objective functions to search for non-dominated solutions in the
trust region. After updating the set of non-dominated solutions, a new trust region around the most isolated point is
determined to explore the non-visited area.
The accuracy of solutions from the algorithm can be improved by controlling sampling and optimization errors.
The diﬀerence between the solutions obtained from SAA and the solutions to the true problems can be reduced by
taking a larger sample size at each iteration. On the other hand, as the number of iterations grows, the distance between
solutions from each iteration and the Pareto front decreases. Also, a bigger number of solutions over a wide region
can be evaluated, which allows the method to generate more widely spread and evenly distributed Pareto optimal
solutions. When the computational budget is limited, the sample size at each iteration should be carefully chosen with
consideration for this trade-oﬀ between sampling and optimization errors. We adopt the idea of the variable sampling
scheme [12, 13, 14] to adaptively update the sample size based on the result from the past iteration.
This paper is organized as follows. In section 2, we describe the proposed algorithm for solving bi-objective
optimization problems in detail. In Section 3, to show the feasibility of our proposed method, we conduct numerical
experiments with diﬀerent sampling schemes. Section 4 draws some concluding remarks.
2. Bi-objective Stochastic Optimization Algorithm
In this section, we consider the bi-objective stochastic optimization problem (1) and present an algorithm to
generate a set of Pareto optimal solutions. The algorithm iteratively applies a trust-region method [8, 15] to SAA
problems and ﬁnds a set of non-dominated points within a local region. At each iteration, the most isolated point is
selected among the points that have thus far been determined to be non-dominated. This point is then deﬁned as the
current iterate. A trust region centered at the current iterate is determined to maintain the uniformity of the optimal
solution set by exploring non-visited areas. Thus, the trust region iteratively moves according to the selected iterate.
Several design points in the trust region are chosen using a design of experiment technique, and the sample average
values at the design points as well as the iterate are computed. A quadratic regression model for each objective function
is constructed based on the sample average values at the design points [16], and a single-objective optimization
problem is built to search for non-dominated solutions within the trust region. To improve the eﬃciency of the
algorithm, the sample size at each iteration can be adaptively determined considering the present state of the algorithm
such as the number of iteration, the trust region radius and the variance of the sample response. We assume that the
objective functions f1 and f2 are Lipschitz continuous so that trust region method for single objective problems can
converge.
2.1. Iterate determination
We deﬁne

(k)
X(k) = {x(k)
j , j = 1, 2, . . . , J }

as a set of non-dominated points returned at the end of iteration (k − 1), where J (k) denotes the cardinality of X(k) . The
non-dominated point x(k)
j is associated with the following four parameters:
(k)
• n(k)
j : the sample size used to evaluate the value of sample average objectives at x j .
(k)
ˆ (k) ˆ (k)
ˆ(k)
• Fˆ (k)
j = f1 j , f2 j : the vector of sample average objectives evaluated at x j . For i = 1, 2, fi j =

1
n(k)
j

n(k)
j
r=1

f (x(k)
j , ξir

1425

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

(k)
(k)
• Δ(k)
j and ρ j : Suppose that x j is detected at some iteration l < k. If Δ is the radius of the trust-region used to
construct quadratic approximate models at the iteration l and ρ is the reduction ratio (see Equation (5)) computed
(k)
(k)
at x(k)
j , we set Δ j = Δ and ρ j = ρ.

While we would like to identify solutions close to the Pareto front, we also want to generate well-spread solutions
in order to approximate as much of the Pareto front as possible. To this end, we select the most isolated point xc(k) in
X(k) and search for new solutions around a region centered at the point. We introduce a quantity γ(k)
j that indicates the
degree of isolation of point xi(k) , based on the distance between the objective vectors at x(k)
j and its neighboring points.
When measuring the distance between two objective vectors, the sampling error should be taken into consideration.
We compute the conﬁdence interval of each objective value and consider the widest possible distance between the
(k)
(k)
ˆ(k)
two objective vectors. Let [C (k)
i j , C i j ] (i = 1, 2, j = 1, 2, . . . , J ) be the conﬁdence interval of fi j under normality
(k)
assumptions with a signiﬁcance level of 1 − α. The procedure to compute the isolation measure γ(k)
j , j = 1, 2, . . . , J

and to select the most isolated point xc(k) is as follows:
(k)
(k)
(k)
≤ fˆ12
≤ ... fˆ1J
1. Sort points in X(k) so that fˆ11
(k) .

2. Let δ > 0 be a user-deﬁned constant. We compute γ(k)
j using the below formula:

γ(k)
j

⎛
⎧
2
⎜⎜⎜
⎪
(k)
(k)
⎪
(k)
⎪
⎜
⎪
max
δ,
2
−
C
+ C 2 j − C (k)
C
⎜
⎪
1(
j+1)
⎝
⎪
1j
2( j+1)
⎪
⎪
⎪
⎪
⎛
⎪
⎪
2
⎪
⎜⎜⎜
⎪
(k)
(k)
(k)
(k)
⎪
⎪
⎜
⎪
⎪
⎨max ⎜⎝ δ, 2 C 1( j−1) − C 1 j + C 2( j−1) − C 2 j
=⎪
⎪
⎪
⎪
2
2
⎪
(k)
(k)
⎪
(k)
(k)
⎪
⎪
−
C
+
C
−
C
C
⎪
1(
j+1)
2
j
1j
2( j+1)
⎪
⎪
⎪
⎪
⎪
2
2
⎪
⎪
(k)
(k)
⎪
⎪
⎩+
+ C 2( j−1) − C (k)
C (k)
1( j−1) − C 1 j
2j

⎞
⎟⎟⎟ if j = 1
⎠
⎞
2⎟
⎟⎟⎟
⎟⎠ if j = J (k)
2⎟
⎟

otherwise.

(k)
(k)
(k)
∗
(k)
= max{γ(k)
3. Let γmax
j : j = 1, 2, . . . , J }, j = argmax{γ j : j = 1, 2, . . . , J }, and Δtol > 0 be the convergence
tolerance parameter of the trust-region method.
(k)
• If γmax
≥ δ, xc(k) = x(k)
j∗ ,
(k)
(k)
(k)
• else if Δ(k)
1 ≤ Δtol and Δ J (k) ≤ Δtol , xc = x j∗ ,

• else if Δ(k)
> Δtol , xc(k) = x1(k) ,
J (k)
• else xc(k) = x(k)
.
J (k)
(k)
If γmax
< δ, it follows that the solutions in X(k) are all close to each other. In this case, either x1(k) or x(k)
is
J (k)
(k)
selected so that the iterate xc moves toward the end part of the Pareto front. In this way, the algorithm can generate
well-spread solutions while searching for the minimizer of each objective as the iteration k grows.

2.2. Quadratic regression model
We construct quadratic models on a trust region centered at xc(k) to search for local solutions. Suppose that xc(k) =
(k)
(k)
(k)
(k)
x j for some j ∈ {1, 2, . . . , J (k) }. We set ρ(k)
c = ρ j and Δc = Δ j . The algorithm parameters η, τ, τinc and Δmax are
constants such that 0 ≤ η < 1, 0 < τ < 1 < τinc and Δmax > 0. Then, the trust region radius is determined by
⎧ (k)
(k)
(k)
⎪
⎪
⎨ Δc , min{τinc Δc , Δmax } if ρc ≥ η
(k)
Δ ∈⎪
(3)
⎪
⎩{τΔ(k)
otherwise.
c }
xc(k)

η is a parameter to test if the considered solution is acceptable or not. If the reduction ratio ρ(k)
c is greater than η,
is acceptable and we either keep the same trust region or expand it. τinc is the maximum ratio to increase the trust

1426

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

region radius and Δmax > 0 is the upper bound of it. If a solution is not acceptable, we reduce the trust region radius
by factor of τ. The trust-region is deﬁned as a closed ball centered at xc(k) with radius Δ(k) :
B(k) = {x ∈ Rq | x − xc(k) ≤ Δ(k) }.
Now, we apply the quadratic least-squares regression to single objectives and build local approximate models on
the trust region. Let N (k) be the sample size chosen according to one of the sampling schemes discussed in subsection
2.3. We sample points in B(k) by using a central composite design [16] and evaluate the sample average objectives at
the design point as well as the center point with the sample size N (k) . Then corresponding local quadratic models are
deﬁned by
1
fˆ1 (xc(k) + s) ≈ q1 (xc(k) + s) = c1 + sT gˆ1 + sT Hˆ1 s,
2
1
T
(k)
(k)
fˆ2 (xc + s) ≈ q2 (xc + s) = c2 + s gˆ2 + sT Hˆ2 s,
2
where xc(k) + s ∈ B(k) , c1 and c2 are scalar, and gˆi and Hˆ i are the estimates of the gradient gi and the Hessian Hi of the
quadratic model qi at xc(k) (i = 1, 2).
In order to ﬁnd the best trade-oﬀ solution between two conﬂicting objectives, we use the following form of singleobjective product formulation suggested by Audet et al. [7]:
2

f3 (x) = −

{(ri − fi (x))+ }2 ,

(4)

i=1

where ri = fi (xc(k) ), i = 1, 2. The strong advantage of this formulation over the WS method is that any solution to the
problem of minimizing f3 is Pareto optimal for the original bi-objective problem, and hence solutions on both convex
and nonconvex parts of the Pareto front can be detected. We also estimate f3 using quadratic approximation:
1
fˆ3 (xc(k) + s) ≈ q3 (xc(k) + s) = c3 + sT gˆ3 + sT Hˆ3 s.
2
2.3. Sample size for each iteration
In the standard SAA method, the sample N (k) is set to be constant. However, instead of ﬁxing a sample from the
beginning and then iteratively searching for the solutions of the resulting deterministic problem (2), we may use an
increasing sequence of sample sizes in order to improve the ﬁnite-time performance of the algorithm. At iteration k,
we can either reuse N (k−1) samples from the previous iteration and draw N (k) − N (k−1) new samples, or we can generate
a new sample that is independent of all the samples generated previously. This idea of the variable sampling scheme
has been studied in the context of single-objective stochastic optimization problems and shown to perform better than
the standard SAA method. [13, 14].
The sample size N (k) is crucial to the performance of the algorithm. The diﬀerence between the solutions obtained
from SAA and the solutions to the true problems can be reduced by taking a larger sample size at each iteration. If
N (k) is too small, the resulting SAA problem would be inaccurate and may lead to a bad movement of the algorithm.
However, when the radius Δ(k) is still large and the solutions have not been near the Pareto front, we may not need a
highly accurate approximate problem to determine solutions in the current trust region, and hence signiﬁcant computational savings can be achieved by using a small size. As the number of iterations grows, the distance between the
solutions from each iteration and the Pareto front decreases, and a larger number of solutions over a wide region can
be evaluated, which allows the method to generate more accurate and widely spread Pareto optimal solutions. Kim
and Zhang [14] show that the size of the local search region is an essential factor in the determination of the sample
2
size. Adapting their result, we set N (k) = O ln(k)/Δ(k) .
2.4. Algorithm description
I. Initialization: Choose the initial point x(0) , the initial trust-region radius Δ0 , and the value of parameters Δmax , Δtol ,
δ η, τ, and τinc . Determine the number of design points d according to the considered central composite design.
Evaluate fˆ1 (x(0) ) and fˆ2 (x(0) ) using the initial sample size N (0) . Set Δ(0) = Δ0 , and ρ(0) = 1.

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

1427

II. Algorithm: For each iteration k = 1, 2, . . . ,
Step 1 (next iterate selection) From the previous iteration, the set of non-dominated points X(k) is returned.
Select xc(k) in X(k) according to the procedure described in subsection 2.1.
Step 2 (trust-region radius update) Update Δ(k) and B(k) using formula (3).
Step 3 (sampling and regression models) Update N (k) and generate samples. Using the central composite
(k)
+ 1, J (k) + 2, . . . , J (k) + d. Construct quadratic
design, select d number of design points x(k)
j , j = J
regression models q(k)
i , i = 1, 2, 3 as described in subsection 2.2.
Step 4 (solving three single-objective problems) Solve each single objective problem and let
(k)
x(k)
= arg min{q(k)
i (x) : x ∈ B }, i = 1, 2, 3.
J (k) +d+i

Step 5 (update the value of ρ) Evaluate fˆi (x(k)
), i = 1, 2, 3, and the reduction ratio
J (k) +d+i
ρ(k)
i

=

)
fˆi (xc(k) ) − fˆi (x(k)
J (k) +d+i
qi (xc(k) ) − qi (x(k)
)
J (k) +d+i

.

(5)

Step 6 (update non-dominated solution set) Set
n(k)
j

=

N (k) , j = J (k) + 1, . . . , J (k) + d + 3,

Δ(k)
j

=

ρ(k)
j

=

Δ(k) , j = J (k) + 1, . . . , J (k) + d + 3,
⎧
⎪
⎪
if j = J (k) + 1, . . . , J (k) + d
⎨1
⎪
⎪
⎩ρ(k) if j = J (k) + d + 1, . . . , J (k) + d + 3.
i

(k)
ˆ
Compare the vector values F(x),
x ∈ {x(k)
j , j = 1, 2, . . . , Ji+d+3 } and determine the set of non-dominated
points X(k+1) . Go to Step 1.

3. Numerical experiments
In this section, we test the proposed algorithm with several sampling schemes. The test problem is taken from
[17], which is an unconstrained deterministic bi-objective problem with a convex Pareto front. After adding noise to
the decision variable x, our problem is formulated as follows:
Minimize:

f1 (x(1) , x(2) , ξ) = (x(1) ξ1 − 2)2 + (x(2) ξ2 − 1)2
f2 (x(1) , x(2) , ξ) = (x(1) ξ1 )2 + (x(2) ξ2 − 6)2 ,

where ξ = [ξ1 , ξ2 ] ∼ [N(1, 0.1), N(1, 0.1)], and ξ1 and ξ2 are independent. We use common random numbers to
generate samples from the distribution of ξ. The starting point is x(0) = [5, 5] and the initial parameters are set by
Δ(0) = 0.8, Δtol = 0.001, α = 0.98, Z (0) = 5, η = 0.5, τ = 0.7, τinc = 1, and δ = 0.001. The Pareto front is
approximated by evaluating 401 × 701 uniformly-spaced points on [−2, 2] × [0, 7] without the noise term ξ. We ﬁnd
a set of solutions H of around 2, 500 non-dominated solutions that are uniformly-spaced.
To evaluate our method, we use the generational distance (GD) criterion [18]. Suppose that the solution set is
H = {x1 , . . . , xe }. Then, the GD is computed by
⎧
⎪
⎪
⎨
F(x j ) − F(x∗j )
⎪
⎪ min
∗
j=1 ⎩ x j ∈H
e

GD =

e

⎫2
⎪
⎪
⎬
⎪
⎪
⎭

.

1428

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

0.5
Nk=10

0.45

Nk=20
Nk=ln(k)/(50*2k )

0.4
0.35

GD

0.3
0.25
0.2
0.15
0.1
0.05
0

0

0.5

1
1.5
Number of function evaluations

2
4

x 10

Figure 1: Comparison of diﬀerent sample allocation rules

This is a measure of the average distance between the objective value at the obtained solution and the true Pareto front.
Hence, smaller GD is preferable. Note that GD= 0 indicates that all the generated solutions are placed on the Pareto
front.
To determine the sample size at each iteration, three sampling schemes are applied: N (k) = 10, N (k) = 20, and
2
N (k) = ln (k)/(θ ∗ Δ(k) ) with θ = 50. The ﬁrst two schemes allocate a constant sample size to all iterations, and
the third one considers the iteration number and the trust-region radius to determine the size. Figure 1 compares the
2
values of GD as the number of function evaluations goes up to 20,000. The algorithm with N (k) = ln (k)/(θ ∗ Δ(k) )
yields better values of GD at any number of function evaluations. In the early iterations, it takes a smaller sample
size but a bigger number of iterations than the constant sampling schemes, which allows it to evaluate the objectives
at more points with lower accuracy. In the later iterations, it makes a greater eﬀort to reduce the sample variance and
2
ﬁnd more accurate solutions. In Figure 2, we compare N (k) = 10 and N (k) = ln (k)/(θ ∗ Δ(k) ) on the objective value
space with around 5000 and 20,000 function evaluations. The small dot represents all the visited points, and the large
2
dots are the non-dominated points generated. The solid line is the true Pareto front. Using N (k) = ln (k)/(50Δ(k) )
(Figure 2(c)), almost all the generated points are near the Pareto front with around 5000 function evaluations. With
N (k) = 10, however, there are several points signiﬁcantly away from the Pareto front as seen in Figure 2(a).
4. Conclusion
We developed an iterative algorithm for bi-objective stochastic optimization problems based on the trust region
method and investigated diﬀerent sampling schemes. The algorithm does not require any strong modeling assumptions, and has great potential to work well in various real-world settings. The numerical results show that the our proposed method is feasible, and the performance can be signiﬁcantly improved with an appropriate sampling scheme.
To improve the ﬁnite time performance of the algorithm, the sampling rule should be carefully determined with consideration for the trade-oﬀ between sampling and optimization errors. Currently, we are analyzing these two errors for

1429

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

40

40

35

35

-5030 evaluations

30

-GD: 0.556802

25
f2

f2

15

10

10

5

5

5

10

15
Evals

20
25
f1
Non-Dom

30

35

-GD: 0.0547146

20

15

0

-50 solutions

25

20

0

-20070 evaluations

30

-14 solutions

0

40

0

15

20
25
f1
Non-Dom

30

35

40

P.F.

(b) Result of Nk = 10 with 2 × 104 evaluations

40

40

35

35

-5075 evaluations

30

-GD: 0.0570399
f2

15

10

10

5

5

10

15
Evals

20
25
f1
Non-Dom

30

35

-GD: 0.0277917

20

15

5

-53 solutions

25

20

0

-20072 evaluations

30

-37 solutions

25

0

10
Evals

(a) Result of Nk = 10 with 5 × 103 evaluations

f2

5

P.F.

40

0

0

5

10

P.F.

(c) Result of Nk = ln (k)/(50 ∗ Δ2k ) with 5 × 103 evaluations

15
Evals

20
25
f1
Non-Dom

30

35

40

P.F.

(d) Result of Nk = ln (k)/(50 ∗ Δ2k ) with 2 × 104 evaluations

Figure 2: Performance comparisons of diﬀerent sample allocation rules

a certain class of problems and developing a sampling scheme that may work robustly for those problems. To generate
well-spread solutions over the Pareto front, identifying an appropriate center point of the trust region is crucial. In this
regard, developing a good isolation measure is one of the key factors to enhance the performance of the algorithm.
We are considering a way to directly construct the conﬁdence interval of the distance between two objective vectors
rather than use the conﬁdence interval of each objective. Thus, the correlation between objectives can be incorporated
to reduce the variance of the estimated distance.
5. Acknowledgments
This research was supported by NUS Research Grant R-266-000-049-133.
[1] B. Wilson, D. Cappelleri, T. Simpson, M. Frecker, Eﬃcient pareto frontier exploration using surrogate approximations, Optimization and
Engineering 2 (2001) 31–50.
[2] R. Tappeta, J. Renaud, J. Rodr´ıguez, An interactive multiobjective optimization design strategy for decision based multidisciplinary design,
Engineering Optimization 34 (5) (2002) 523–544.
[3] S. Shan, G. G. Wang, An eﬃcient pareto set identiﬁcation approach for multiobjective optimization on black-box functions, Journal of
Mechanical Design 127 (5) (2005) 866–874.
[4] H. Markowitz, Portfolio selection: eﬃcient diversiﬁcation of investments, Blackwell, Malden, Massachusetts, 1991.

1430

Sujin Kim et al. / Procedia Computer Science 4 (2011) 1422–1430

[5] R. G. Ajith Abraham, L C. Jain, Evolutionary multiobjective optimization: theoretical advances and applications, Springer-Verlag, London,
2005.
[6] J. L. Cohon, Multiobjective Programming and Planning, Academic Press, New York, 1978.
[7] C. Audet, G. Savard, W. Zghal, Multiobjective optimization through a series of single-objective formulations, SIAM Journal on Optimization
19 (2008) 188–210.
[8] J. Ryu, S. Kim, H. Wan, Pareto front approximation with adaptive weighted sum method in multiobjective simulation optimization, in: M. D.
Rossetti, R. R. Hill, B. Johansson, A. Dunkin, R. G. Ingalls (Eds.), Proceedings of the 2009 Winter Simulation Conference, Austin, TX.,
2009, pp. 623–633.
[9] K. Deb, Multi-objective genetic algorithms: Problem diﬃculties and construction of test problems, Evolutionary Computation 7 (1999)
205–230.
[10] L. H. Lee, E. P. Chew, S. Teng, D. Goldsman, Finding the non-dominated pareto set for multi-objective simulation models, IIE Transactions
42 (9) (2010) 656–674.
[11] A. Shapiro, Monte carlo sampling methods, in: A. Ruszczynski, A. Shapiro (Eds.), Stochastic Programming, Vol. 10 of Handbooks in
Operations Research and Management Science, Elsevier, 2003, pp. 353 – 425.
[12] T. HomemDeMello, Variable-sample methods for stochastic optimization, ACM Trans. Model. Comput. Simul. 13 (2003) 108–133.
[13] G. Deng, M. C. Ferris, Variable-number sample-path optimization, Mathematical Programming 117 (2009) 81–109.
[14] S. Kim, D. Zhang, Convergence properties of direct search methods for stochastic optimization, in: B. Johansson, S. Jain, J. Montoya-Torres,
J. Hugan, E. Y¨ucesan (Eds.), Proceedings of the 2010 Winter Simulation Conference, Baltimore, MD, 2010, pp. 1003–1011.
[15] A. Conn, K. Scheinberg, L. Vicente, Introduction to derivative-free optimization, MPS-SIAM series on optimization, Society for Industrial
and Applied Mathematics/Mathematical Programming Society, 2009.
[16] R. Myers, D. Montgomery, C. Anderson-Cook, Response surface methodology: process and product optimization using designed experiments, Wiley series in probability and statistics, Wiley, 2009.
[17] B. Wilson, D. Cappelleri, T. Simpson, M. Frecker, Eﬃcient pareto frontier exploration using surrogate approximations, Optimization and
Engineering 2 (2001) 31–50.
[18] D. V. Veldhuizen, G. Lamont, Multiobjective evolutionary algorithm research: A history and analysis, Tech. Rep. TR-98-03, Department of
Electrical and Computer Engineering, Graduate School of Engineering, Air Force Institute of Technology, Writhe-Patterson AFB, OH (1998).

