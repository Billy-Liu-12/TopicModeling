Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 1004‚Äì1013

International Conference on Computational Science, ICCS 2011
Lattice Boltzmann Simulation Code Optimization Based on Constant-time
Circular Array Shifting
G. Dethiera,‚àó, P. A. de MarneÔ¨Äea , P. Marchotb
a Department

of Electrical Engineering & Computer Science of University of Li`ege
of Chemical Engineering of University of Li`ege

b Department

Abstract
Lattice Boltzmann (LB) methods are a class of Computational Fluid Dynamics (CFD) methods for Ô¨Çuid Ô¨Çow simulation. LB simulation codes have high requirements regarding memory and computational power: they may involve
the update of several millions of Ô¨Çoating point values thousands of times and therefore require several gigabytes of
available memory and run for several days. Optimized implementations of LB methods minimize these requirements.
An existing method based on a particular data layout and an associated implementation implying a constant time
array shifting allows to reduce the execution time of LB simulations and almost minimize memory usage when compared to a naive implementation.
In this paper, we show that this method can be further improved, both in memory usage and performances by
slightly modifying the data layout and by using blocking in order to enhance data locality.
Keywords: Lattice Boltzmann, Optimization, Data Locality, Circular arrays

1. Introduction
Lattice Boltzmann (LB) methods [1, 2] are a class of Computational Fluid Dynamics (CFD) methods for Ô¨Çuid
Ô¨Çow simulation. Unlike many CFD methods solving motion equations at some points in space, LB methods use an
alternative approach: Ô¨Çuid is described by Ô¨Åctitious particles moving on a regular grid. These particles collide with
each other or against solid obstacles at the cells of the mesh. Flow parameters are then computed in function of the
state of these particles.
LB methods are particularly interesting for simulating Ô¨Çuid Ô¨Çows in complex boundaries like porous media. However, LB simulation codes have high requirements regarding memory and computational power: they may involve
the update of several millions of Ô¨Çoating point values thousands of times and therefore require several gigabytes of
available memory and run for several days. Optimized implementations of LB methods minimize these needs.
LB simulation codes imply the regular access to values in large multi-dimensional arrays stored in main memory
and the update of these values. An obvious way to optimize a LB simulation code is to ensure data locality, in
particular by choosing an optimal way to organize data in memory [3, 4, 5, 6].
‚àó Corresponding

author
Email address: G.Dethier@ulg.ac.be (G. Dethier)

1877‚Äì0509 ¬© 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka doi:10.1016/j.procs.2011.04.106

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

















1005



	
		
	

























Figure 1: A site (center of the cube) of a D3Q19 lattice and its neighborhood. The numbers are identiÔ¨Åers of the neighborhood vectors (i is the
identiÔ¨Åer of vector ni ).

Murphy [7] proposes an interesting data layout and an associated implementation that allows to reduce the execution time of LB simulations. However, Murphy‚Äôs method is not adapted to programming languages that do not
support pointer arithmetic. Also, it can be enhanced in order to further reduce execution time. Finally, it implies a
small memory overhead that can be avoided. In this paper, we solve all these drawbacks.
All the algorithms described in the following are written using the guarded commands language deÔ¨Åned by Dijkstra [8].
Section 2 shortly describes LB methods and a naive implementation. In Section 3.1, the data locality principle is
presented and the representation of multi-dimensional arrays is discussed. Section 3 describes the method proposed
by Murphy and a Ô¨Årst improvement. Section 4 describes how Murphy‚Äôs method can be further enhanced by ensuring
better data locality. Execution times obtained using the naive implementation of Section 2, Murphy‚Äôs method and our
optimized implementation are compared in Section 5. Finally, Section 6 concludes this paper.
2. Lattice Boltzmann Methods
In LB methods [1, 2], the spatial domain (R3 ) is discretized into a regular grid called lattice. Each node of the
lattice is called a site and is associated to a point in space. If the point associated to a site is part of a solid, the site is
an obstacle. Time is also regularly discretized. Finally, the set of possible velocities for a particle (R3 ) is reduced to
a set of q velocity vectors vi ‚àà R3 with i = 0, 1, . . . , q ‚àí 1. These vectors are deÔ¨Åned such as a particle at point p in
space at time t and moving according to a velocity vi is at point p + vi at time t + Œît where Œît is the time sampling
period.
A site has a position x in the lattice with x ‚àà Z3 . A function s : Z3 ‚Üí {true, f alse} is used to deÔ¨Åne the nature of
a site: if s(x) is true then the site at position x is an obstacle. Otherwise, the site is not an obstacle.
A set of q neighborhood vectors ni with i = 0, 1, . . . , q ‚àí 1 and ni ‚àà Z3 is deÔ¨Åned such as x + ni is the position
of another site of the lattice. ni has the same direction as vi and is deÔ¨Åned such as a particle at the point associated to
position x at discrete time t and moving according to velocity vi is at the point associated to position x + ni at discrete
time t + 1.
The neighborhood of a site at position x is the set of q sites at positions x + ni with i = 0, 1, . . . , q ‚àí 1. The
neighborhood of the site may contain the site itself if one of the neighborhood vectors is equal to the zero vector
(noted 0).
Lattices used in the context of LB methods are generally classiÔ¨Åed using the notation DdQq where d is the number
of dimensions and q the number of velocity vectors. Note that for all lattices used in LB methods, for any velocity vi ,
v j exists such as vi + v j = 0. Similarly, for any neighborhood vector ni , n j exists such as ni + n j = 0.
Figure 1 shows a site of a D3Q19 lattice and its neighbors. On the Ô¨Ågure, only 18 neighborhood vectors are
represented. The last neighborhood vector being zero vector: the site is also a neighbor of itself.
LB methods are based on the following equation:
fi (x + ni , t + 1) = fi (x, t) + Œ©i

i = 0, 1, . . . , q ‚àí 1

(1)

where x is the position of a site, ni a neighborhood vector and t discrete time. fi : Z3 √ó Z ‚Üí R is called the particle
distribution function.

1006

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

fi (x, t) is a real value from the interval [0..1], called density, that can be interpreted as the probability of having
particles at position x moving along velocity vector vi at time t. A velocity vector equal to zero vector therefore allows
to represent particles at rest.
The term Œ©i is called collision operator. It describes the interaction of particles located at a point at a given time.
A common method to compute Œ©i is the BGK model [9].
The collision operator is only applied on sites that are not obstacles. A widely used method called bounceback [10] is applied otherwise. The main idea of the bounce-back is that a particle following a given direction and
that collides with an obstacle ‚Äúbounces‚Äù in the opposite direction. A more formal deÔ¨Ånition is given below.
The computation of the densities at time t + 1 in function of densities at time t generally involves two main phases:
propagation (also called streaming) and collision. Propagation is the operation of ‚Äúmoving‚Äù fi (x, t) values to x‚Äôs
neighbors x + ni with i = 0, 1, . . . , q ‚àí 1. Collision is the computation of the new particle distribution functions values
fi (x, t + 1) given the interaction of particles (and, therefore, based on propagated values). These two operations can
be highlighted by decomposing Equation 1 into two equations, Ô¨Årst representing propagation and second representing
collision:
(2)
fÀÜi (x + ni , t) = fi (x, t)
ÀÜ
fi (x, t + 1) = fi (x, t) + Œ©i
(3)
In case s(x) is true, bounce-back is applied and following equation is used instead of Equation 3:
fi (x, t + 1) = fÀÜj (x, t)

(4)

where i and j are such as ni = ‚àín j .
Note that most collision operators (BGK included) are local i.e. computed for each site in function of the densities
associated to the site: Œ©i (x, t) = gi (ÀÜf(x, t)) where gi : Rq ‚Üí R is a function that depends on the operator type.
A Ô¨Çuid simulated with numerical methods must be deÔ¨Åned on a bounded spatial domain. Boundary conditions (periodic, pressure or velocity conditions) are therefore used to describe the Ô¨Çuid dynamics on its boundaries composed
of the lattice borders.
A general deÔ¨Ånition for the border of a lattice is the set of sites that lack at least one neighbor: let x be the position
of one of these sites, it exists a neighborhood vector ni such as x + ni is not the position of a site of the lattice (the
position is out of the lattice).
A 3D Ô¨Ånite lattice (D3Qq family) is a cube or a cuboid. The components of position x = (x, y, z) have ranges
deÔ¨Åned in the following way: 0 ‚â§ x < xS ize, 0 ‚â§ y < yS ize and 0 ‚â§ z < zS ize where xS ize, yS ize and zS ize are the
size of each dimension. The size of a 3D lattice is deÔ¨Åned by the vector (xS ize, yS ize, zS ize) and the number of sites
of the lattice is given by xS ize √ó yS ize √ó zS ize.
A 4D array f of real values can therefore be used to represent the particle distribution functions of a lattice. In the
same way, the solid function s can be represented by a 3D array of booleans.
These arrays can be declared as follows:
f :
s :

array[0..xSize-1, 0..ySize-1, 0..zSize-1, 0..18] of real;
array[0..xSize-1, 0..ySize-1, 0..zSize-1] of boolean;

where xSize, ySize, zSize are the components of the size of the lattice (in number of sites).
Below is a typical LB simulation code, timeSteps is the number of time steps of the simulation:
"Fill s";
"Initialize f";
t := 0;
do t < timeSteps ‚Üí
"Propagate values";
"Apply boundary conditions";
"Apply collision";
t := t + 1
od

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

1007

A naive implementation of "Propagate values", directly based on Equation 2, requires an additional array
fHat declared in the same way as f and representing fÀÜ. "Apply collision" uses the values from fHat and stores
them back to array f (Equation 4 if the site is an obstacle or Equation 3 if it is not).
However, technics exist [3, 4, 5, 7] that avoid the use of the fHat array and therefore almost divide memory usage
by two. In particular, Murphy [7] suggests a method where densities are displaced in f in an order depending on
the associated velocity vector and preventing the destruction of information. "Apply collision" can then directly
modify the values of f.
For example, the in-place propagation of the densities associated to velocity vector n8 = (‚àí1, 1, 0) is described by
following algorithm:
x, y, z := 1, ySize - 2, 0;
do x < xSize ‚Üí
f[x-1, y+1, z, 8] := f[x, y, z, 8];
if z < zSize - 1 ‚Üí z := z + 1
z = zSize - 1 ‚Üí
z := 0;
if y > 0 ‚Üí y := y - 1
y = 0 ‚Üí
y := ySize - 2; x := x + 1
Ô¨Å
Ô¨Å
od

where densities associated to velocity n8 are displaced using a scan that has a direction (1, ‚àí1, 0) opposed to n8 .
In general, the propagation of all densities associated to each velocity i is a translation following vector ni and
using a scan that has direction ‚àíni . The propagation step for a D3Q19 lattice is therefore composed of 18 translations
(translation following rest vector n0 has no eÔ¨Äect).
3. Optimizing Propagation Step
Unlike other optimization technics [3, 4, 5], Murphy‚Äôs method [7] does not merge collision and propagation step.
It implies a propagation optimized data layout which is, in general, an approach that gives good results [6].
3.1. Data Locality and Representation of Multi-dimensional Arrays
Memory has a hierarchical organization [11]: data used as operands of an instruction are loaded into the registers
from cache memory. If data are not available in cache memory, a cache miss occurs and the program‚Äôs execution is
interrupted until data are transferred from slow main memory to fast cache memory. When a cache miss occurs, a
portion of main memory is copied into cache memory.
Typical code optimization includes the minimization of the number of cache misses by using an optimal data
organisation in memory and an optimal data access ‚Äúscheduling‚Äù. The data locality principle (data brought into cache
are used at least once before being Ô¨Çushed out of it) is then ensured.
LB simulations are memory intensive applications, ensuring the data locality principle is therefore essential and
addressed by most optimized LB simulation algorithms [3, 4, 5].
In order to use the optimization proposed by Murphy [7], a multi-dimensional array needs to be represented
by a 1D array (as done internally in languages supporting directly multi-dimensional arrays). Figure 3 shows the
representation of array A from Figure 2 in a 1D array. Consecutive lines are then contiguous in memory which
potentially ensures a better data locality when array is scanned line by line.
In general, for a dD array of size (s1 , s2 , . . . , sd ), a 1D array of size di=1 si is needed. An index function Œ¥ : Nd ‚Üí N
that, from the position (i1 , i2 , . . . , id ) (with 0 ‚â§ i j < si for i = 1, 2, . . . , d) of an element of the dD array, gives the
position in the 1D array must also be deÔ¨Åned. In the example given in Figure 3, Œ¥(i1 , i2 ) = i1 √ó 3 + i2 with 0 ‚â§ i1 , i2 < 3.

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

1008


	








  



	



  



        

  

Figure 2: 2D array A of 3 √ó 3 integers represented using arrays of arrays.




















Figure 3: 2D array of 3 √ó 3 integers represented using a 1D array.



	
				





 













		





	





Figure 4: Array shift with base pointer move.

Figure 5: 2D array shift using oÔ¨Äset vector (1, 1).

Let v f be the 1D representation of a D3Q19 lattice of size (xS ize, yS ize, zS ize). The size of v f (in number of
Ô¨Çoating point values) is given by xS ize √ó yS ize √ó zS ize √ó 19. To have the same data organization as used in simple
implementation of Section 2, the following index function must be used:
Œ¥(x, y, z, q) = x √ó (yS ize √ó zS ize √ó 19) + y √ó (zS ize √ó 19) + z √ó 19 + q
With this representation, in order to ensure data locality, lattice elements should be accessed in the following way:
x, y, z, q := 0, 0, 0, 0;
do x < xSize ‚Üí
"Access vf[delta(x, y, z, q)]";
if q < 18 ‚Üí q := q + 1
q = 18 ‚Üí
q := 0;
if z < zSize - 1 ‚Üí z := z + 1
z = zSize - 1 ‚Üí
z := 0;
if y < ySize - 1 ‚Üí y := y + 1
y = ySize - 1 ‚Üí
y := 0; x := x + 1
Ô¨Å
Ô¨Å
Ô¨Å
od

Note that the implementation of in-place propagation described in Section 2 does not necessarily ensure data
locality.
3.2. Array Shift
Murphy‚Äôs method [7] is based on the constant time shift of elements of an array. The shift operation is implemented
by moving the base pointer (pointer to the Ô¨Årst element of the array) of the array to the ‚Äúright‚Äù (base pointer is
increased) or to the ‚Äúleft‚Äù (base pointer is decreased).
For example, Figure 4 illustrates the shift of an array containing Ô¨Åve elements two positions to the right. The base
pointer of the array is moved two positions to the left. As shown in the Ô¨Ågure, an element at position i in the array
before shift has position i + 2 after shift.
With a shift of n positions to the right, n elements are undeÔ¨Åned at the beginning of the array. With a shift of n
positions to the left, n elements are undeÔ¨Åned at the end of the array.

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

















	
























	



Figure 6: Shift of the vector representation of a (3 √ó 3) array.



































1009









	

	


 	

Figure 7: Two left shifts and a pointer and data reset.

The shift of the elements of an array is deÔ¨Åned by an integer called the oÔ¨Äset: with an oÔ¨Äset equal to n, after the
shift, the element at position i is at position i + n if it is in the array boundaries. If n is positive, elements are shifted
to the right. If n is negative, elements are shifted to the left.
The shift of the elements of a dD array is deÔ¨Åned by a vector called oÔ¨Äset vector: with an oÔ¨Äset vector v an
element at position p has position p + v after the shift if it is in the array boundaries. Figure 5 illustrates the shift of
the elements of a 2D array of size (3, 3) with an oÔ¨Äset vector (1, 1).
If a dD array is represented using a 1D array, the shift of its elements using vector v is obtained by shifting the 1D
array using oÔ¨Äset Œ¥(v). Figure 6 illustrates the shift of the elements of the 1D array backing the 2D array of Figure 5
with oÔ¨Äset Œ¥(1, 1) = 1 √ó 3 + 1 = 4. In the Ô¨Ågure, the element with label ‚Äú3‚Äù has been marked as undeÔ¨Åned. Its value
is, in fact, known but does not make sense in the context of the multi-dimensional array shift.
Note that in order to use the base array pointer move method to shift elements of an array without potentially
overwriting required data in memory, enough memory needs to be reserved to the left and/or to the right of the array.
3.3. Propagation Based on Array Shifting
In-place propagation presented in Section 2 can be implemented using multi-dimensional array shifting if lattice
values are reorganized: the values associated to each velocity should be grouped in separate 3D arrays, each represented by a 1D array. Instead of a 4D array, a D3Q19 lattice is then represented by 19 1D arrays. The index function
Œ¥(x, y, z) for these arrays is given by:
Œ¥(x, y, z) = x √ó (yS ize √ó zS ize) + y √ó (zS ize) + z
As stated previously, propagation is the application of a translation vector to all values associated to each velocity.
Propagation can therefore be implemented by shifting each of the 19 arrays of new representation by a Ô¨Åxed oÔ¨Äset.
The oÔ¨Äset di to apply to the array associated to velocity i is given by Œ¥(ni ) where ni is the neighborhood vector
associated to velocity i.
Memory must be reserved around the array in order to move the array base pointer without overwriting other used
data. In its implementation, Murphy allocates a supplementary space of |di | √ó k values. This way, k shifts can occur
before no more space is available to continue to shift array base pointers. At this point, array elements are copied back
to their initial positions and the base pointer is reset. k new shifts can then occur again. Figure 7 shows an array of
Ô¨Åve elements with 2 additional positions reserved at its left. Two right shifts with an oÔ¨Äset of 1 can then be performed
before pointer and data are reset.
3.4. Circular Array Shifting
To avoid the memory overhead and pointer and data reset operation of Murphy‚Äôs method, we use a circular array:
the base pointer never moves but an oÔ¨Äset pointing to the actual Ô¨Årst position of the circular array can be moved (see
Figure 8).
A circular array represented using a simple array can be declared as follows:
var
v : array[0..N-1] of "type";
off : integer

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

1010

























Figure 8: Circular array and one position right shift.

where v contains the data of the circular array, N is the size of the circular array and off the index of the Ô¨Årst element
of the array. The element at position i in the circular array is at position (o f f + i) mod N in v. To apply an oÔ¨Äset a to
the elements of v, the following command is executed: off := (off - a) mod N.
In an implementation of propagation using circular array shift, a D3Q19 lattice can be represented as follows:
var
f : array[0..18, 0..M-1] of real;
offs : array[0..18] of integer

where f is a 2D array of real values: each line f[i,.] corresponds to the 1D representation of a 3D array containing
the densities associated to velocity i with 0 ‚â§ i < 19; offs is an array of integers that contains the current oÔ¨Äset
associated to each line of f.
Propagation based on circular array shifts is more eÔ¨Écient than Murphy‚Äôs method because there is no substantial
memory overhead and no ‚Äúpointer and data reset‚Äù operations are needed. However, the cost of accessing elements of
the array is increased because of the additional modulus. This cost is discussed in next section.
4. Adapting Collision to New Data Organization
The new data organization dramatically improves the eÔ¨Éciency of propagation operation, however, due to data
locality problems and a more complex element access, slows down collision step.
Let xyzSize be the size of each line f[i, .]. The 19 densities f[i, (k + offs[i]) mod xyzSize] with
0 ‚â§ i < 19 are associated to the same site. Accessing these 19 densities subsequently as it is currently done in collision
step does probably not ensure data locality as these values are ‚Äúfar‚Äù regarding their memory address. The number of
cache misses is therefore not minimized. However, accessing subsequently b densities f[i, (k + offs[i]) mod
xyzSize] with i Ô¨Åxed and k ‚àà [a..a + b[ ensures a better data locality as these densities are contiguous in memory.
To reduce the number of cache misses and complex element accesses, the values associated to a part of lattice
sites can be copied into a small 2D array, called block, that Ô¨Åts entirely in cache memory. A block has B lines and
19 columns: B is the maximum number of sites the block can contain and each line contains the densities of a site.
The operation of copying densities from lattice to a block, called lattice-block copy, must be written in a way that
minimizes the number of cache misses. Collision can then be applied on block‚Äôs sites and the lattice updated with
block‚Äôs data (block-lattice copy). As for lattice-block copy, block-lattice copy must be implemented in a way that
minimizes the number of cache misses.
A block can be declared as follows:
type
Block =
size
data
xPos
yPos
zPos
end

record
: integer;
: array[B,
: array[B]
: array[B]
: array[B]

0..18] of real;
of integer;
of integer;
of integer

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

1011

where B is the maximum size of the block, size its actual size, data the array containing densities and xPos, yPos
and zPos arrays containing respectively the x, y and z components of the extracted sites‚Äô positions in the lattice.
The collision step ("Apply collision", see Section 2) can be rewritten in order to access lattice‚Äôs sites block by
block and therefore ensuring better data locality in the context of the lattice representation introduced in Section 3.4.
Next algorithm describes the rewritten collision step using block access:
var
block : Block;
k : integer
begin
k := 0;
do k < xyzSize ‚Üí
latticeBlockCopy(k, block);
"Apply collision on copied block";
blockLatticeCopy(k, block);
k := k + block.size
od
end

"Apply collision on copied block" simply consists in applying collision operator or bounce-back to each site
of the block.
As suggested above, latticeBlockCopy and blockLatticeCopy procedures copy densities from lattice to
block and vice-versa by accessing subsequent densities velocity per velocity. In addition, the use of the modulus to
compute the position of a density in each line f[i,.] array is minimized in order to reduce the access overhead
caused by circular array representation. This is done by computing the position from of the Ô¨Årst density to copy and
the position to such as (to ‚àí1) is the position of the the last density to copy from a line f[i,.] into a block. As f[i,
.] represents a circular array, to may be lower than from. In this case, the densities to copy are in two areas: f[i,
from..xyzSize-1] and f[i, 0..to-1]. Otherwise, the densities to copy are in one area: f[i, from..to-1].
The procedure latticeBlockCopy is described below. The parameter start is the position of the Ô¨Årst density to
copy from each circular array and bl is the destination block. A precondition on start is that 0 ‚â§ start < xyzSize
i.e. start must point a value of a line of f.
procedure latticeBlockCopy(start : integer;
var bl : Block);
begin
bl.size := min(xyzSize - start, B);
if bl.size = 0 ‚Üí skip
bl.size > 0 ‚Üí
q := 0;
do q < 19 ‚Üí
from := (offs[q] + start) mod
xyzSize;
to := (offs[q] + start + bl.size)
mod xyzSize;
"Copy of densities from lattice
to block";
q := q + 1
od;
"Set positions in bl"
Ô¨Å
end

** Copy of densities from lattice to block **
if from ‚â§ to ‚Üí
pos, i := q, from;
do i < to ‚Üí
bl.data[pos] := f[q, i];
i, pos := i + 1, pos + 19
od
from > to ‚Üí
pos, i := q, from;
do i < xyzSize ‚Üí
bl.data[pos] := f[q, i];
i, pos := i + 1, pos + 19
od;
i := 0;
do i < to ‚Üí
bl.data[pos] := f[q, i];
i, pos := i + 1, pos + 19
od
Ô¨Å

Finally, the positions of the sites in the block are computed ("Set positions in bl"). The use of the modulus
is avoided as much as possible. The position of the Ô¨Årst site of the block is computed in function of start and the
positions of next sites are set accordingly. The algorithm below describes this operation:

1012

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013















	


	




 

	

Figure 9: Comparison of execution time for a complete simulation when using diÔ¨Äerent algorithms.

yzSize := ySize * zSize;
x := (start div yzSize);
y := (start mod yzSize) div zSize;
z := start mod zSize;
site := 0;
do site < bl.size ‚Üí
xPos[site], yPos[site], zPos[site] := x, y, z;
site := site + 1;
if z < zSize - 1 ‚Üí z := z + 1
z = zSize - 1 ‚Üí
z := 0;
if y < ySize - 1 ‚Üí y := y + 1
y = ySize - 1 ‚Üí
y := 0; x := x + 1
Ô¨Å
Ô¨Å
od

The principle behind block-lattice copy is similar to lattice-block copy.
Note that "Apply boundary conditions" should also be adapted to circular array-based lattice representation
by following above principles (maximizing data locality and avoiding as much as possible the use of the modulus to
compute the position of a density).
5. Comparison of Simple and Optimized Algorithms
In order to evaluate our optimization method, we applied it to an existing implementation that is part of a tool
that aims to be highly portable and is therefore written in Java. This explains the relatively poor performance of the
implementation when compared to optimized native codes. However, we should be able to observe the execution time
reduction implied by our optimization method.
Figure 9 shows the execution times for one time step of a complete simulation (propagation, boundary conditions
and collision) on a (64, 64, 64) D3Q19 lattice. These execution times have been measured on a computer equipped
with an Intel R CoreTM 2 2.13Ghz CPU with 2 MBytes of cache memory. The labels of the Ô¨Ågure‚Äôs legend have the
following meaning:
‚Ä¢ simple: Simple lattice representation described at the end of Section 2 with in-place propagation;
‚Ä¢ murphyŒ±: Murphy‚Äôs optimization with data and pointer reset operations required every Œ± simulation iterations;
‚Ä¢ oÔ¨Ä: Circular array representation, shift based propagation, no block access;

G. Dethier et al. / Procedia Computer Science 4 (2011) 1004‚Äì1013

1013

‚Ä¢ oÔ¨ÄBlockŒ≤: Circular array representation, shift based propagation, block access (maximum block size B = Œ≤);
The use of circular arrays in order to avoid data and pointer reset operations increases simulation code eÔ¨Éciency
when compared to Murphy‚Äôs method. Also, ‚Äúmurphy10‚Äù implementation is 1.6 times faster than ‚Äúsimple‚Äù implementation which is what Murphy observed with its Fortran implementation [7]. Finally, block access further improves
eÔ¨Éciency and ‚ÄúoÔ¨ÄBlock20‚Äù implementation is more than 2.5 times faster than ‚Äúsimple‚Äù implementation.
Furthermore, we observe that the Java implementation used to produce above results is able to handle more than
2 million sites per second (‚ÄúoÔ¨ÄBlock20‚Äù implementation). This is ‚Äúonly‚Äù 2 times slower than native optimized implementations on almost similar equipments (AMD R OpteronTM 2Ghz and Intel R XeonTM 3.2Ghz) [12]. We therefore
expect to reach at least similar results if applying our optimization technic to a native implementation.
6. Conclusion
LB methods require large amounts of memory and computational power. In order to minimize these requirements,
an optimized implementation is required. LB methods are memory intensive applications; a proper representation of
these arrays and ensuring data locality are therefore essential.
Murphy [7] provides an interesting data layout and an implementation (see Section 3) that minimizes propagation
step execution time. In particular, his method is based on constant time array shifting that can be used to implement
the propagation step. This constant time array shifting method implies the displacement of the array base pointer and
therefore requires additional memory reserved before or after the array. In addition, data need to be regularly copied
back to their original position (pointer and data reset operation).
In Section 3.4, we propose to use a constant time circular array shifting. With this method, there is no more need to
reserve memory before or after the array and pointer and data reset operations can be avoided. However, our method
implies a more complex access to the elements of the array and, in the same way Murphy‚Äôs method does, does not
ensure data locality for collision step.
To handle this issue, we introduced block access in Section 4: blocks containing the state of several sites are
copied from lattice in a way that minimizes cache misses, collision is then applied on block‚Äôs sites and block‚Äôs data
are copied back into the lattice, again by ensuring best data locality. This process is repeated until all sites have been
collided.
Finally, we observed in Section 5 that our enhanced optimization applied to an existing Java implementation of LB
simulations is more than 2.5 faster than the simple implementation with a (64, 64, 64) D3Q19 lattice on a computer
with an Intel R CoreTM 2 2.13Ghz CPU with 2 MBytes of cache memory allowing to handle more than 2 million sites
per second.
In future work, we plan to use our method to optimize a native implementation of LB simulation code and compare
it to other ‚Äústate of the art‚Äù optimization technics.
7. References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]

S. Chen, G. D. Doolen, Lattice Boltzmann method for Ô¨Çuid Ô¨Çows, Annual Review of Fluid Mechanics 30 (1998) 329‚Äì364.
S. Succi, The Lattice Boltzmann Equation for Fluid Dynamics and Beyond, Oxford University Press, 2001.
J. Latt, How to implement your DdQq dynamics with only q variables per node (instead of 2q), Tech. rep., Tufts University (June 2007).
K. Mattila, J. Hyv¬®aluoma, T. Rossi, M. Aspn¬®as, J. Westerholm, An eÔ¨Écient swap algorithm for the lattice Boltzmann method, Computer
Physics Communications 176 (3) (2007) 200‚Äì210.
T. Pohl, M. Kowarschik, J. Wilke, K. Iglberger, U. R¬®ude, Optimization and proÔ¨Åling of the cache performance of parallel lattice Boltzmann
codes, Parallel Processing Letter 13 (4) (2003) 549‚Äì560.
G. Wellein, T. Zeiser, G. Hager, S. Donath, On the single processor performance of simple lattice boltzmann kernels, Computers & Fluids
35 (8-9) (2006) 910‚Äì919.
S. Murphy, Performance of Lattice Boltzmann kernels, Master‚Äôs thesis, University of Edinburgh, this document is available at
http://www2.epcc.ed.ac.uk/msc/dissertations/dissertations-0405/0762240-9j-dissertation1.1.pdf (2005).
E. Dijkstra, Guarded commands, nondeterminacy and formal derivation of programs, Communications of the ACM 18 (1975) 453‚Äì457.
P. L. Bhatnagar, E. P. Gross, M. Krook, A model for collision processes in gases. I. Small amplitude processes in charged and neutral
one-component systems, Physical Review 94 (1954) 511‚Äì525.
S. Wolfram, Cellular automaton Ô¨Çuids 1: Basic theory, Journal of Statistical Physics 45 (3-4) (1986) 471‚Äì526.
S. Goedecker, A. Hoisie, Performance Optimization of Numerically Intensive Codes, SIAM, 2001.
K. Mattila, J. Hyv¬®aluoma, J. Timonen, T. Rossi, Comparison of implementations of the lattice-Boltzmann method, Computers and Mathematics with Applications 55 (2008) 1514‚Äì1524.

