Using Padding to Optimize Locality
in Scientiﬁc Applications
E. Herruzo1 , O. Plata2 , and E.L. Zapata2
1

2

Dept. Electronics, University of C´
ordoba, Spain
eze@uco.es
Dept. Computer Architecture, University of M´
alaga, Spain
oscar@ac.uma.es, ezapata@ac.uma.es

Abstract. Program locality exploitation is a key issue to reduce the execution time of scientiﬁc applications, so as many techniques have been
designed for locality optimization. This paper presents new compiler algorithms based on array padding that optimize program locality either
locally (at loop level) or globally (the whole program). We ﬁrst introduce a formal cache model that is used to analyze how all cache levels
are ﬁlled up when arrays inside nested loops are referenced. We further
study the relation between the model parameters and the data memory
layout of the arrays, and deﬁne how to pad those arrays in order to optimize cache occupation at all levels. Experimental evaluation on some
numerical benchmarks shows the beneﬁts of our approach.

1

Introduction

For the last decades locality exploitation has been one of the main goals for improving the performance of scientiﬁc applications, giving rise to a wide range of
software optimizations. Nowadays two locality-related trends can be observed:
applications process larger and larger data sets, and the processor-memory gap
problem is more and more signiﬁcant. The memory latency problem has been
attacked from two diﬀerent fronts. On the one hand, by means of hardware
solutions, like lockup-free caches, multithreading, prefetching, out-of-order execution, data and instruction speculation and so on. On the other hand, by means
of compiler techniques for code and/or data transformations [1].
Array padding is a well-known data layout optimization technique that optimizes locality by reducing conﬂict misses. Although a global technique (aﬀects
the whole program), its use can be localized to the nested loop (or few loops)
where most of the execution time is spent (a frequent case in scientiﬁc applications). This paper presents a simple model of the cache that captures essential
information of its behaviour during the execution of a loop nest. This model
is used as a framework to deﬁne how to pad the arrays in the loop in order to
optimize cache occupation. Our method establishes a relationship among a small
set of cache parameters, how the array elements are referenced and how they are
stored in memory in order to obtain the optimal padding that optimizes cache
occupation. The proposed method is subsequently extended to optimize cache
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 863–872, 2008.
c Springer-Verlag Berlin Heidelberg 2008

864

E. Herruzo, O. Plata, and E.L. Zapata

locality for the whole program (global code optimization) and as well as for the
complete cache hierarchy.
The rest of the paper is organized as follows. First, the cache model developed
to design our padding methods is introduced. In the next section, our intra-array
padding approach is developed for three scenarios: a single loop nest optimization, all loops in the program (global optimization) and all levels in the cache
hierarchy. After that, the proposed techniques are experimentally evaluated for
a wide set of numerical bechmarks. Finally, some related work is discussed.

2

Modelling the Cache Behaviour

A minimal set of characteristic parameters will be deﬁned with the aim of optimizing cache occupation by using array padding. We consider a L−way setassociative cache, of size C × L × W , where C is the number of cache sets, L is
the number of blocks per set, and W is the block size in words. We also consider
that the array access patterns come from referencing a M −dimensional array,
X, within a N −depth nested loop. Expressions in the array dimensions are of
the form fk ∗ Ik , k = 1, . . . , M , where I = (I1 , I2 , . . . , IN ) is the iteration vector
of the loop, but any general aﬃne expression is perfectly valid. Without loss
of generality, we assume that N = M . To simplify the explanation, we restrict
the cache model to a single array X inside a perfectly nested loop. However
this model can be extended to several arrays appearing in the same loop and to
not-perfectly nested loops.
When the multidimensional array X is allocated in memory, it is linearized
and laid out in some order. So, considering for instance a column-major order, the
oﬀset (in words) from the beginning of the array of the element of X referenced in
the iteration I = (I1 , I2 , . . . , IM ) of the nested loop is given by ArrOf f (X, I ) =
k−1
M−1
f1 ∗ I1 + . . . + fk ∗ Ik ∗ i=1 Di + . . . + fM ∗ IM ∗ i=1 Di , where Di is the
size of the i−dimension of X. The stride of array X on loop index Ik is deﬁned
as the distance in memory (in words) of array entries referenced by consecutive
l
iterations of the loop k, that is, Stride(X, Ik ) = fk ∗ Ikl+1 ∗ k−1
i=1 Di − fk ∗ Ik ∗
k−1
l
i=1 Di , where Ik represents the l−th iteration of the loop k.
Let us consider now the cache. The execution of consecutive iterations of
the loop k generates array references separated in memory a word distance
equals to Stride(X, Ik ). We will deﬁne now two new cache-related strides.
The above array references are contained in cache blocks (of size W words
each). The distance (in blocks) between these cache blocks is deﬁned as the
cache block stride, that is, BlockStride(X, Ik ) = block(X, Ikl+1 ) − block(X, Ikl ) =
M emAddr(X, Ikl+1 )/W − M emAddr(X, Ikl )/W . Note that although Stride()
is constant BlockStride() may not be constant, depending on the relative oﬀset
of the memory references in their corresponding blocks. On the other hand, the
distance (in cache sets) of the above blocks once they are placed into cache is
deﬁned as the cache set stride, that is, SetStride(X, Ik ) = (block(X, Ikl+1 ) −
block(X, Ikl )) mod C, or SetStride(X, Ik ) = BlockStride(X, Ik ) mod C. We are
assuming BlockStride is a positive integer, in order to simplify the expressions

Using Padding to Optimize Locality in Scientiﬁc Applications

865

(otherwise, we have to take absolute values and consider negative loop steps).
With this deﬁnition, if we take as a reference the ﬁrst iteration of the loop k
(iteration Lw), we can use the following expression to calculate the set where is
located the block referenced in the l−th iteration of the loop,
Set(X, Ikl ) = (Set(X, IkLw ) + l ∗ SetStride(X, Ik )) mod C.

(1)

This expression assumes that SetStride() is constant for all iterations of the loop
k, which is true if BlockStride() is also constant for that loop. This condition is
fulﬁlled if all array references have the same block oﬀset, that is, if Stride(X, Ik )
is a multiple of W . Our method to optimize cache occupation considers that this
is the case. Otherwise, we can always reach this condition by incrementing the
k dimension of X by the amount Stride(X, Ik ) mod W .

3

Optimizing Cache Occupation by Array Padding

We propose a new approach to determine how to pad arrays in order to optimize
cache occupation, and consequently reduce miss rates. Padding techniques modify the portion of memory reserved for storing array data by including empty
memory zones [1]. We focus our analysis on intra-array padding, where the empty
memory zones are included among the array dimensions that is, arrays are redimensioned by increasing the size in some of its dimensions.
3.1

Single Loop Nest

Consider ﬁrst the case of a single loop nest and a single-level cache hierarchy. In
our analysis we are specially interested in those arrays with a stride greater than
the cache block size (W ) in the innermost loop of the nest. The cache occupation
for these arrays may suﬀer from block replacements by self-interference, and some
cache blocks may remain unoccupied. This happens when SetStride(X, Ik ) >
1. This situation is very common in scientiﬁc applications, but the interesting
problem occurs when the number of sets involved in the replacements is small.
These cases shows an ineﬃcient use of the cache space. Our goal is to change,
in these cases, the array memory layout through padding to maximize the cache
occupation, and consequently reduce the miss rate (due to self-replacements).
Next lemma explains how to determine the dimension increments (intra-array
padding) needed to maximize cache occupation.
Lemma. Given a loop k in the nest and the array X, the occupation of the
cache is maximized if SetStride(X, Ik ) and C are mutually prime, that is,
GCD(SetStride(X, Ik ), C) = 1 (GCD condition).
Proof. We will prove that if SetStride(X, Ik ) is relatively prime to C then the
ﬁrst C iterations of the loop k touch diﬀerent cache sets. In that case, if the
loop k is longer than C then all cache sets are occupied by references to array X in that loop. If it is shorter, the number of touched cache sets is maximum

866

E. Herruzo, O. Plata, and E.L. Zapata

Select all Xi arrays with stride greater than W
on the innermost loop (IM )
for (each Xi array) do
if (SetStride(Xi , IM ) is even) then
N ewStride(Xi , IM ) = Stride(Xi , IM ) + W
endif
endfor
Fig. 1. Intra-array padding algorithm for a single loop nest and a single cache

(as many as the length of the loop). So, let us consider two of the ﬁrst C iterations of the loop k, say p and q. Note that 0 ≤ p, q < C. Let us assume that
references to X in those two iterations are located to the same cache set, that
is, Set(X, Ikp ) = Set(X, Ikq ). In that case, from Eq. (1), we have, (Set(X, IkLw ) +
p ∗ SetStride(X, Ik )) mod C = (Set(X, IkLw ) + q ∗ SetStride(X, Ik )) mod C,
or, eliminating the module operation, Set(X, IkLw ) + p ∗ SetStride(X, Ik ) =
Set(X, IkLw ) + q ∗ SetStride(X, Ik ) + C ∗ r, where r is an integer number.
A bit of simpliﬁcation gives, (p − q) ∗ SetStride(X, Ik ) = C ∗ r. Given that
SetStride(X, Ik ) and C are mutually prime, p − q must be divisible by C, as r is
an integer number. But | p − q | is lower than C, so we came to a contradiction.
Thus, references to X in both iterations must touch diﬀerent cache sets. And
this must be true for any pair of such iterations.
Q.E.D.
In the case that SetStride(X, Ik ) and C are not mutually prime then the lemma
does not hold. However, if β is the greatest common factor between both values,
then SetStride (X, Ik ) = SetStride(X, Ik )/β and C = C/β are mutually prime.
So, the lemma holds for these new reduced values. That means that the ﬁrst C
iterations of loop k touch diﬀerent cache sets. The rest of them may cause set
replacements. In addition, as SetStride(X, Ik ) is assumed constant, the cache
sets touched by these ﬁrst iterations are β sets apart. So, only the fraction C/β
cache sets are assured to be occupied.
The GCD condition can be used to deﬁne a simple algorithm (see Fig. 1) to
compute the needed padding of an array in a nested loop for achieving maximum
cache occupation. The key idea is touching the maximum number of cache sets
when executing the iterations in the innermost loop. That permits to increase
the cache set reuse by iterations of the next outer loop. In order to touch all
the cache sets, we need to modify SetStride() to make it relatively prime to C.
As C is a power of two, an increment of SetStride() by one is enough. This is
obtained by increasing BlockStride() by also one, or by increasing Stride() of
the array by W (remember that BlockStride() is assumed constant).
3.2

Multiple Loop Nests (Global Code Optimization)

In scientiﬁc codes it is very frequent that the same few arrays, usually referenced
in the body of loop nests, are re-used during the whole program execution. To
maximize the cache occupation for these array we may pad them satisfying the

Using Padding to Optimize Locality in Scientiﬁc Applications

867

for (each X array in the program) do
i = 1, P (0) = 0
for (each loop nest in the program) do
if (SetStride(X, IM ) is odd) then P (0) = 1
else P (i) = SetStride(X, IM )/2, i = i + 1
endfor
n = i, even = 0, odd = 0
if (P (0) == 0) then ΔSetStride = 1
else for (i = 1 to n) do
if (P (i) is even) then even = even + 1
else odd = odd + 1
endfor
if (odd > even) then ΔSetStride = 4
else ΔSetStride = 2
N ewStride(Xi , IM ) = Stride(Xi , IM ) + W ∗ ΔSetStride
endfor
Fig. 2. Intra-array padding procedure for the whole program

GCD condition for all loop nests in the program that include such arrays. We
have to bear in mind that we consider the arrays which are referenced over a
non-contiguous dimension in the innermost loop of a nest. Then, for a speciﬁc
array under consideration, we take all SetStride()’s corresponding to all nested
loops, and calculate the stride increment (from now on, ΔStride) needed to
satisfy the GCD condition for every SetStride().
A new problem arises when for some loop nests SetStride() is even and for
other loop nests SetStride() is odd. As ΔStride must be the same for all loop
nests, we need to calculate it so that it satisﬁes the GCD condition for all of
them or, at least, it minimizes GCD(SetStride(), C), in order to maximize the
number of the used cache sets.
In what follows we assume that the number of iterations of the diﬀerent nested
loops are similar. We also assume that the number of the odd and even values
of SetStride()’s are similar. This is the worst case because we need to obtain a
solution for the even values of SetStride()’s. In our approach, with a mixture of
odd and even values for SetStride()’s, an even ΔStride will be calculated, in order to not turning odd values into even ones. To minimize the number of the non
touched cache sets, this even increment should minimize GCD(SetStride(), C).
In addition, it is convenient that the increment being the smallest possible, in
order to minimize the number of (empty) pad locations. Based on this idea, we
have deﬁned the algorithm shown in Fig. 2, that determines the array stride increment needed to maximize the occupation of the cache for the whole program.
In the procedure a vector P is computed containing the values SetStride()/2
for all even values of SetStride()’s. The ﬁrst value of P shows if there are odd
values of SetStride()’s or not. With the even values, the minimum even increment in stride to minimize GCD(SetStride(), C) is computed for the whole
program.

868

E. Herruzo, O. Plata, and E.L. Zapata
Select a X array inside a nested loop
Sort cache levels in decreasing order of their block size
for (each cache level take Wi in the sorted order) do
Apply single-level procedure(Stride(X, IM ), Ci , Wi )
Stride(X, IM ) = N ewStride(X, IM )
endfor
Fig. 3. Intra-array padding procedure for the complete cache hierarchy

3.3

Complete Cache Hierarchy

In the cache hierarchy the blocks may be the same size for all levels. In this case,
the stride increment is the same for all cache levels, so we can apply the same
algorithms described above. Otherwise, if block sizes are diﬀerent over the cache
hierarchy, we need to obtain a stride increment appropriate for each cache level.
The algorithm in Fig. 1 calculates the stride increment for a speciﬁc cache
level. To pad the array for other cache level, we need to carry out the same
algorithm changing SetStride() and the cache block size (W ). The method to
accomplish this process starts with the cache level with the largest block size,
continuing with the rest of levels in decreasing order of block size. As an example,
consider a two-level cache hierarchy with diﬀerent block sizes, W 1 and W 2,
where W 1 < W 2 (both are power of two). For this system, if Stride()/W 2 is
integer, then all the quotients, Stride()/W 1, (Stride() + W 2)/W 2), (Stride() +
W 1)/W 1) and (Stride() + W 2 + W 1)/W 1) are all also integer. However, the
quotient (Stride() + W 2 + W 1)/W 2) is non-integer. Despite this, its integer part
satisﬁes the GCD condition. Based on these results, a simple algorithm has been
developed to extend our padding approach to a cache hierarchy (see Fig. 3).

4

Experimental Evaluation

We ﬁrst tested the basic padding method (single loop nest and one level cache)
for a synthetic single loop nest example on a real machine, and for a small set
of kernel benchmarks on a cache simulator. Second, we tested the full padding
method (whole program optimization on a complete cache hierarchy) for a selection of benchmarks on a real machine. When using a real machine, diﬀerent
optimization levels where tested, obtaining similar results. In this paper we show
those results for two optimization levels on two diﬀerent processors.
4.1

Basic Padding Method

In this section we present the evaluation of the basic padding method for a simple
test code, a double nested loop of 1000 × 1000 iterations (i, j), where the loop
body is X(i, j) = 3, being X a 1600 × 1600 single-precision ﬂoating-point array
(4-byte words). The experiments were conducted in a MIPS R10K-processor
system running in exclusive mode. This system has a 2-way set associative 32KByte L1 data cache with a 32-Byte cache block (C = 512, L = 2, W = 8),

Using Padding to Optimize Locality in Scientiﬁc Applications

869

Table 1. L1 (left) and L2 (right) data cache misses for diﬀerent array paddings
Arr. Dim. SetStride GCD Exec.Time L1 Misses Arr. Dim. SetStride GCD Exec.Time L2 Misses
1600
200
8
0.212
1,001,000
1600
50
2
0.212
23,100
1608
201
1
0.171
312,000
1632
51
1
0.214
19,500
1616
202
2
0.214
1,001,000
1664
52
4
0.219
27,640
1624
203
1
0.169
310,000
1696
53
1
0.217
20,400
1632
204
4
0.214
1,001,000
1728
54
2
0.214
24,700
1640
205
1
0.168
312,000
1760
55
1
0.212
18,600
1648
206
2
0.216
1,001,000
2048
64
64
0.548
698,500
1664
208
16
0.217
1,001,000
2176
68
4
0.217
22,200

Table 2. Cache miss ratio for a 16 KB cache using a simulator
C=1024
Benchmark Array Dim. GCD L=1
test code
400
4
1
test code
404
1
1.196
test code
408
2
0.282
test code
412
1
9.310
liver
240
4
1
liver
244
1
3.874
liver
248
2
0.869
liver
252
1
1.705
mxm
200
2
1
mxm
204
1
0.858
mxm
208
4
2.502
mxm
220
1
7.826

Cache Miss Ratio
C=512 C=256 C=128 C=64
L=2
L=4
L=8 L=16
1
1
1
1
1.442 2.732 13.333 13.333
0.105 0.873 4.230 4.230
3.307 3.142 3.142 12.571
1
1
1
1
3.874 1.193 13.741 14.200
0.869 3.354 4.531 4.531
1.705 13.741 13.741 14.200
1
1
1
1
0.256 0.131 0.226 0.645
1.031 0.432 0.140 0.145
1.351 0.658 0.138 1.001

C=32
L=32
1
61.710
4.645
12.342
1
14.200
4.531
14.200
1
1.072
0.093
1.208

and a 2-way set associative 4-MByte L2 data cache with a 128-Byte cache block
(C = 16384, L = 2, W = 32). The results correspond to codes compiled with
the MIPSpro Fortran 90 (v. 7.30) compiler using the ”O0” optimization option.
Considering the test code, we have Stride(X, i) = 1 and Stride(X, j) = 1600.
For the L1 cache level we have, BlockStride(X, j) = 1600/8 = 200 (constant),
SetStride(X, j) = 200 mod 512 = 200, and GCD(200, 512) = 8. This result
means that between two touched cache sets there are 7 other sets which are never
used. With an increment by one of SetStride(X, j), we have GCD(201, 512) = 1
and N ewStride(X, j) = 1600 + 8 = 1608. Table 1 (left) shows the experimental
results (execution time and L1 data cache misses) for diﬀerent values of the
second dimension of the array X. Besides, the table shows the SetStride(X, j)
for each case and the values of GCD(SetStride(X, j), C). Note that the best
results are obtained when the GCD condition holds, as expected.
For the L2 cache level, we have now BlockStride(X, j) = 1600/32 = 50
(constant), SetStride(X, j) = 50 mod 16384 = 50, and GCD(50, 16384) = 2.
So, only half of the L2 cache is used. Table 1 (right) shows the experimental
results for the L2 cache and diﬀerent values for the array second dimension.
The table shows three cases fulﬁlling the GCD condition. For these cases the
minimum miss rate is obtained, as expected.
A diﬀerent scenario corresponds to the evaluation of our basic padding method
using a cache simulator, in order to test easily diﬀerent cache conﬁgurations.
The obtained results are shown in table 2, for three diﬀerent benchmarks: test

870

E. Herruzo, O. Plata, and E.L. Zapata

code (test code described above), liver (livermore kernel [3]), and mxm (matrix
multiplication of square matrices). The ﬁrst row in table 2 for each benchmark
corresponds to the original dimension size of the array. The rest of rows include
diﬀerent padded dimension sizes. The smallest one (that is, the second row)
corresponds to the increment given by our padding technique. For each cache
conﬁguration we measured the cache miss rate using our simulator. The results
are given in the table as Cache Miss Ratio, that is obtained by dividing the cache
miss rate for the original dimension size by the cache miss rate for the padded
dimension size. This way, a value larger than 1 means that the miss rate was
decreased after applying padding. In case of mxm, padding is not eﬀective due
to the small size of the data structures.
4.2

Full Padding Method

A diﬀerent experimental setup was implemented testing a number of bechmarks
from diﬀerent suites (SPEC95 & 2000, perfectB and NAS) on a Intel Pentium-4
platform. The computer system has a 8-way set associative 16-KByte L1 data
cache with a 64-Byte block size, and a 8-way set associative 1-MByte L2 data
cache with a 64-Byte block size. The results shown here correspond to codes
compiled with the Intel Fortran Compiler v. 9.0, using in this case the ”O3” optimization level and ”-align none” option (in order to not interfere with padding).
In addition, the code was executed in exclusive mode (hard real-time mode in
the linux scheduler). Table 3 (top) shows the performance results applying our
padding method for the complete cache hierarchy. Note that there are a signiﬁcant performance improvement by padding the arrays.
In order to optimize the whole code, we ﬁrst have to ﬁnd all the nested loops
where array references in a non contiguous dimension exist in the innermost
loop. Next, we proceed by selecting one of these arrays. From this point on,
SetStride()’s are calculated for every level of the cache hierarchy. For each one,
the corresponding values of GCD(SetStride(), C) are also calculated, and from
then, the stride increments. If the stride values are the same for all the loops, we
only have to carry out the sum of the stride increments obtained for each level
of the cache memory. Otherwise, we have to apply the corresponding padding
algorithm. Table 3 (bottom) show the improvement obtained by applying our
padding method to several benchmarks on the Pentium-4 machine.

5

Related Work

There is a great amount of work in the literature related to the design of compiler
techniques for program locality exploitation. In [6] authors present an iterative
method that uses ILP (Integer Linear Programming) to compute optimal solutions of memory layout transformations. Other works [7,8] also develop heuristic
solutions to data layout and loop transformations, based on data reuse vectors.
Works based on Cache Miss Equations (CMEs) [5] are similar to our own
proposal in some aspects but with diﬀerent results. They analyze the cache

Using Padding to Optimize Locality in Scientiﬁc Applications

871

Table 3. Improvement for a single loop nest (top) and the whole code (bottom) for
the complete cache hierarchy in Pentium 4
Subroutine

Original
array dim.

Padded
% Exec. time % L1 num. misses % L2 num. misses
array dim. improvement
improvement
improvement

PerfectB
Bench.
adm
hyd
50,50,50
56,52,50
arc2d
scaldt
500,500,4
544,500,4
dyfesm
mnlbyx
500,500,3
544,500,3
ﬂo52
collc
200,200,200 200,205,200
mg3d
march
100,100
100,112
spec77
horiz2
500,500
544,500
trfd
trfa
500,500
544,500
NAS
Bench.
appsp
spentax3
660,33,33
660,35,34
appbt
l2norm
50,50,50,50 56,52,56,50
ﬀtpde
transx
1024,1024
1064,1024
SPEC CFP
Bench.
tomcatv
cal.res.
513,513
540,520
applu
rhs
20,50,50,100 20,50,70,100
swim
calc3z
1335,1335
1352,1336
hydro2d
v.th.p
1200,800
1224,800
mgrid
norm2u3 320,200,200 344,201,200
turb3d
wcal
33,64,64
34,68,64
wave
RADFG 100,100,100 116,140,100
tﬀt2
transc
500,30,500 500,30,501

swim
mgrid
appsp
ﬀtpde

16.2
11.3
7.1
5.4
3.2
16.8
18.3

15.1
15.7
1.2
5.5
0.7
15.5
3.8

0
13.6
44.4
5.7
8.6
34.2
0

0
0
120.0

6.3
0.2
-1.7

2.0
0
90.0

588.2
5.7
6.8
433.2
4.2
8.3
5.4
6.5

211.5
4.7
1.6
907.4
19.5
-0.1
5.5
11.7

103.8
2.9
3.6
173.3
18.4
11.7
5.7
0

% Exec. time % L1 num. misses % L2 num. misses
improvement
improvement
improvement
1.1
3.2
-0.2
3.4
2.5
1.3
4.8
2.8
3.7
1.2
3.9
10.4

occupation through references to arrays in loops and deﬁne the algorithms to
generate the CMEs and some optimizations, as padding. In [11] authors also use
CMEs to propose a cost model that combined with a genetic algorithm carries
out padding (and tiling) for a multi-level cache memory system.
The work in [2] is mainly focused on spatial locality optimization. The method
provides a parameterized cost function based on polytopes and Ehrhart polynomials from the iteration space of a loop nest. We also use the polyhedron
deﬁned by the iteration space of a loop nest, but with a diﬀerent objective. Our
goal is to determine the cache occupation generated by this polyhedron. In [9]
authors present a similar approach to ours for array padding. Their technique
is iterative until no self-interference is caused. Our method, however, is a direct calculation, more accurate and with lower algorithmic complexity. Other
work [10] computes the conﬂict distance of array references by directly linearizing the uniformly-generated references. In [12] authors analyze iterative stencil
loops and use array padding to remove conﬂict misses after tiling the loops.
Finally, the work in [4] shares with our approach a similar treatment of the
cache and the program code. However, we also take into account how array

872

E. Herruzo, O. Plata, and E.L. Zapata

data is stored in memory, and we introduce the new notions of cache block and
set strides and work with them to develop the padding algorithms. These facts,
to some extent, complete their work, justifying some of the results they obtain.

6

Conclusions

We presented a parameter-based cache model that is used as a framework to
determine how to pad arrays in order to optimize program locality. In fact, the
model permits to maximize cache occupation when arrays are reference within
loop nests. This model is used to develop array padding algorithms in diﬀerent
scenarios: single loop nest and multiple loops, single and multiple cache levels.
We showed that simple padding techniques are very useful to obtain respectable
performance improvements for a variety of scientiﬁc codes.

References
1. Bacon, D.F., Graham, S.L., Sharp, O.J.: Compiler Transformations for HighPerformance Computing. ACM Computing Surveys 26(4), 345–420 (1994)
2. Clauss, P., Meister, B.: Automatic Memory Layout Transformation to Optimize Spatial Locality in Parameterized Loop Nests. ACM Computer Architecture
News 28(1), 11–19 (2000)
3. Coleman, S., Mckinley, K.S.: Tile Size Selection Using Cache Organization and
Data Layout. In: ACM Conf. on PLDI. La Jolla (CA), pp. 279–290 (1995)
4. Ferrante, J., Sarkar, V., Thrash, W.: On Estimating and Enhancing Cache Eﬀectivenes. Work. on Languages and Compilers for Parallel Computers (1991)
5. Ghosh, S., Martonosi, M., Malik, S.: Cache Miss Equations: A Compiler Framework
for Analyzing and Tunning Memory Behaviour. ACM TOPLAS 21(4), 703–746
(1999)
6. Kandemir, M., Banerjee, P., Choudhary, A., Ramanujam, J., Ayguade, E.: An
Integer Linear Programming Approach for Optimizing Cache Locality. In: ACM
Int’l. Conf. on Supercomputing Rhodes, pp. 500–509 (1999)
7. Kandemir, M., Choudhary, A., Ramanujam, J., Banerjee, P.: Improving Locality Using Loop and Data Transformations in an Integrated Framework. In:
ACM/IEEE Int’l. Symp. on Microarchitecture. Dallas (TX), pp. 285–297 (1998)
8. O’Boyle, M., Knijnenburg, P.: Integrating Loop and Data Transformations for
Global Optimizations. In: IEEE Int’l. Conf. on Parallel Architectures and Compilation Techniques., Paris, pp. 12–19 (1998)
9. Panda, P., Nakamura, H., Dutt, N., Nicolau, A.: A Data Alignment Technique
for Improving Cache Performance. In: Int’l. Conf. on Computer Design: VLSI in
Computers and Processors., Austin (TX), pp. 587–592 (1997)
10. Rivera, G., Tseng, C.W.: Data Transformations for Eliminating Conﬂict Misses.
In: ACM Conf. on PLDI, Montreal, pp. 38–49 (1998)
11. Vera, X., Abella, J., Llosa, J., Gonz´
alez, A.: An Accurate Cost Model for Guiding
Data Locality Transformations. ACM TOPLAS 27(5), 946–987 (2005)
12. Li, Z., Song, Y.: Automatic Tiling of Iterative Stencil Loops. ACM TOPLAS 26(6),
975–1028 (2004)

