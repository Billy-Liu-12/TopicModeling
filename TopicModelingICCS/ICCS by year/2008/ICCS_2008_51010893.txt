Extending the Four Russian Algorithm to
Compute the Edit Script in Linear Space
Vamsi Kundeti and Sanguthevar Rajasekaran
Department of Computer Science and Engineering
University of Connecticut
Storrs, CT 06269, USA
{vamsik,rajasek}@engr.uconn.edu

Abstract. Computing the edit distance between two strings is one of the
most fundamental problems in computer science. The standard dynamic
programming based algorithm computes the edit distance and edit script
in O(n2 ) time and space. Often the edit script is of more importance than
the value of the edit distance. The Four Russian Algorithm [1] computes
the edit distance in O(n2 / log n) time but does not address how to compute edit script within that runtime. Hirschberg [2] gave an algorithm to
compute edit script in linear space but the runtime remained O(n2 ). In
this paper we present algorithms that compute both the edit script and
n2
) time using O(n) space.
edit distance in O( log
n
Keywords: edit distance, edit script, linear space, four russian algorithm, hirschberg’s algorithm.

1

Introduction

The edit distance between strings S1 = [a1 , a2 , a3 . . . an ] and S2 = [b1 , b2 , b3 . . . bn ]
is deﬁned as the minimal cost of transforming S1 into S2 using the three operations Insert, Delete, and Change(C) (see e.g., [3]). The ﬁrst application(global
alignment) of the edit distance algorithm for protein sequences was studied by
Needleman [4]. Later algorithms for several variations (such as local alignment,
aﬃne gap costs, etc.) of the problem were developed (for example) in [5], [6],
and [7]. The ﬁrst major improvement in the asymptotic runtime for computing the value of the edit distance was achieved in [1]. This algorithm is widely
known as the Four Russian Algorithm and it improves the running time by a
factor of O(log n) (with a run time of O(n2 / log n)) to compute just the value
of the edit distance. It does not address the problem of computing the actual
edit script, which is of wider interest rather than just the value. Hirschberg [2]
has given an algorithm that computes the actual script in O(n2 ) time and O(n)
space. The space saving idea from [2] was applied to biological problems in [8]
and [9]. However the asymptotic complexity of the core algorithm in each of
these remained O(n2 ). Also, parallel algorithms for the edit distance problem
and its application to sequence alignment of biological sequences were studied
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 893–902, 2008.
c Springer-Verlag Berlin Heidelberg 2008

894

V. Kundeti and S. Rajasekaran

extensively (for example) in [10] and [11]. In paper [12] linear space parallel algorithms for the sequence alignment problem were given, however they assume
that O(n2 ) is the optimal asymptotic complexity of the sequential algorithm.
Please refer to [13] for an excellent survey on all these algorithms. A special case
is one where each of these operations is of unit cost. Edit Script is the actual
sequence of operations that converts S1 into S2 . In particular, the edit script
is a sequence Escript = {X1 , X2 , X3 . . . Xn }, Xi ∈ I, D, C. Standard dynamic
programming based algorithms solve both the distance version and the script
version in O(n2 ) time and O(n2 ) space. The main result of this paper is an algorithm for computing the edit distance and edit script in O

n2
log n

time and

O(n) space.
The rest of the paper is organized as follows. In Sec. 2 we provide a summary
of the four Russian algorithm [1]. In Sec. 3 we discuss the O(n2 ) time algorithm
that consumes O(n) space and ﬁnally in Sec. 4 we show how to compute the edit
n2
distance and script using O( log
n ) time and O(n) space.

2

Four Russian Algorithm

In this section we summarize the Four Russian Algorithm. Let D be the dynamic
programming table that is ﬁlled during the edit distance algorithm. The standard
edit distance algorithm ﬁlls this table D row by row after initialization of the
ﬁrst row and the ﬁrst column. Without loss of generality, throughout this paper
we assume that all the edit operations cost unit time each.
The basic idea behind the Four Russian Algorithm is to partition the dynamic
programming table D into small blocks each of width and height equal to t where
t is a parameter to be ﬁxed in the analysis. Each such block is called a t-block. The
dynamic programming table is divided into t-blocks such that any two adjacent
t-blocks overlap by either a row or column of width (or height) equal to t. See
Fig. 1 for more details on how the dynamic programming table D is partitioned.
After this partitioning is done The Four Russian algorithm ﬁlls up the table D
block by block. Algorithm 1 has more details.
A quick qualitative analysis of the algorithm is as follows. After the partition2
ing of the dynamic programming table D into t-blocks we have nt2 blocks and if
2
processing of each of the block takes O(t) time then the running time is O( nt ).
In the case of standard dynamic programming, entries are ﬁlled one at a time
(rather than one block at a time). Each entry can be ﬁlled in O(1) time and
2
hence the total run time is O(n2 ). In the Four Russian algorithm, there are nt2
blocks. In order to be able to ﬁll each block in O(t) time, some preprocessing is
done. Theorem 1 is the basis of the preprocessing.
Theorem 1. If D is the edit distance table then |D[i, j] − D[i + 1, j]| ≤ 1, and
|D[i, j] − D[i, j + 1]| ≤ 1∀(0 ≤ i, j ≤ n).
Proof. Note that D[i, j] is deﬁned as the minimum cost of converting S1 [1 : i]
into S2 [1 : j]. Every element of the table D[i, j] is ﬁlled based on the values from

Computing edit script in O(n2 / log n) Time and O(n) Space

895

D[i − 1, j − 1],D[i − 1, j] or D[i, j − 1]. D[i, j] ≥ D[i − 1, j − 1](characters at
S1 [i] and S2 [j] may be same or diﬀerent), D[i, j] ≤ D[i, j − 1] + 1 (cost of insert
is unity),D[i, j − 1] ≤ D[i − 1, j − 1] + 1(same inequality as the previous one
rewritten for element D[i, j − 1]). The following inequalities can be derived from
the previous inequalities.
−D[i, j] ≤ −D[i − 1, j − 1]
D[i, j − 1] ≤ D[i − 1, j − 1] + 1
−D[i, j] + D[i, j − 1] ≤ 1
D[i, j − 1] − D[i, j] ≤ 1
D[i, j] ≤ D[i, j − 1] + 1 {Started with this}
−1 ≥ D[i, j − 1] − D[i, j]
|D[i, j − 1] − D[i, j]| ≤ 1
Along the same lines we can also prove that |D[i − 1, j] − D[i, j]| ≤ 1 and
D[i − 1, j − 1] ≤ D[i, j].
Theorem 1 essentially states that the value of the edit distance in the dynamic
programming table D will either increase by 1 or decrease by 1 or remain the
same compared to the previous element in any row or a column of D. Theorem 1
helps us in encoding any row or column of D with a vector of 0, 1, −. For example
a row in the edit distance table D[i, ∗] = [k, k + 1, k, k, k − 1, k − 2, k − 1] can
be encoded with a vector vi = [0, 1, −1, 0, −1, −1, 1]. To characterize any row or
column we just need the vector vi and k corresponding to that particular row or
column. For example, if D[i, ∗] = [1, 2, 3, 4, . . . , n], then k = 1 for this row and
vi = [0, 1, 1, 1, 1, 1, 1, . . . , 1]. For the computation of the edit distance table D
the leftmost column and the topmost row must be ﬁlled (or initialized) before
the start of the algorithm. Similarly in this algorithm we need the topmost row
(A) and leftmost column (B) to compute the edit distance within the t-block see
Fig. 1. Also see Algorithm 2. It is essential that we compute the edit distance
within any t-block in constant time.
In the Four Russian algorithm the computation of each t-block depends on the
variables A, B, K, C, E (see Fig. 1). The variable A represents the top row of the
t-block and B represents the the left column of the t-block. C and E represent the
corresponding substrings in the strings S1 and S2 . K is the intersection of A and
B. If the value of the variable K is k then from Theorem 1 we can represent A and
B as vectors of {0,1,-1} rather than with exact values along the row and column.
As an example, consider the ﬁrst t-block which is the intersection of the ﬁrst t
rows and the ﬁrst t columns of D. For this t-block the variables {A, B, K, C, E}
have the following values: K = D[0, 0], A = D[0, ∗] = [0, 1, 1, 1, . . . , 1], B =
D[∗, 0] = [0, 1, 1, 1, . . . , 1], C = S2 [0, 1, . . . , t], and E = S1 [0, 1, . . . , t]. For any
t-block we have to compute {A , B , K } as a function of {A, K, B, C, E} in
O(1) time. In this example plugging in {A, B, K, C, E} for the ﬁrst t-block gives
K = D[t, t], A = [D[0, t], . . . , D[t, t]],B = [D[t, 0], . . . , D[t, t]]. To accomplish
the task of computing the edit distance in a t-block in O(1) time, we precompute

896

V. Kundeti and S. Rajasekaran

S1

E

S2
{A’,B’,K’} = F(A,B,C,K,E)

K
B
A

C

t−block

A’ overlapping row

B’
overlapping column

K’

filled pattern indicates initialized values of the dynamic
programming table

Fig. 1. Using preprocessed lookup table {A , B , K } = F (A, B, C, K, E)

all the possible inputs in terms of variables {A, B, 0, C, E}. We don’t have to
consider all possible values of K since if K1 is the value of K we get with
input variables {A, B, 0, C, E} then the value of K for inputs {A, B, K, C, E}
would be K1 + K. Thus this encoding(and some preprocessing) helps us in the
computation of the edit distance of the t-block in O(1) time. The algorithm is
divided into two parts pre-processing step and actual computation.

Algorithm 1. Four Russian Algorithm, t is a parameter to be ﬁxed.
INPUT : Strings S1 and S2 , Σ, t
OUTPUT: Optimal Edit distance
/*Pre-processing step*/
F = PreProcess(Σ, t) ;
for i = 0;i < n;i+ = t do
for j = 0;j < n;j+ = t do
{A , B , D } = LookU pF (i, j, t) ;
[D[i + t, j] . . . D[i + t, j + t] = A ;
[D[i, j + t] . . . D[i + t, j + t] = B ;
end
end

2.1

Pre Processing Step

As we can see from the previous description, at any stage of the Algorithm 1
we need to do a lookup for the edit distance of any t-block and as a result
get the row and column for the adjacent t-blocks. From Theorem 1 its evident

Computing edit script in O(n2 / log n) Time and O(n) Space

897

Algorithm 2. LookUp routine used by Algorithm 1.
INPUT : i,j,t
OUTPUT: A , B , D
A = [D[i, j] . . . D[i, j + t]];
B = [D[i, j] . . . D[i + t, j]];
C = [S2 [j] . . . S2 [j + t]];
E = [S1 [j] . . . S1 [j + t]];
K = D[i, j];
/*Encode A,B*/
for k = 1;k < t;k + + do
A[k] = A[k] − A[k − 1];
B[k] = B[k] − B[k − 1];
end
/*Although K is not used in building lookup table F we maintain the
consistency with Fig. 1 */
return {A , B , D } = F (A, B, C, K, E) ;

that any input {A, B, K, C, E} (see Fig. 1) to the t-block can be transformed
into vectors of {−1, 0, 1}. In the preprocessing stage we try out all possible
inputs to the t-block and compute the corresponding output row and column
({A , B , K } (see Fig. 1). More formally, the row (A ) and column(B ) that
need to be for any t-block can be repesented as a function F (lookup table) with
inputs {A, B, K, C, E}, such that {A , B , K } = F (A, B, K, C, E). This function
can be precomputed since we have only limited possibilities. For any given t, we
can have 3t vectors corresponding to A and B.
For a given alphabet of size Σ we have Σ t possible inputs corresponding to C
and E. K will not have any eﬀect since we just have to add K to A [t] or B [t]
at the end to compute K . The time to preprocess is thus O((3Σ)2t t2 ) and the
space for the lookup table F would be O((3Σ)2t t). Since t2 ≤ (3Σ)t , if we pick
log n
t = 3 log(3Σ)
, the preprocessing time as well as the space for the lookup table
will be O(n). Here we make use of the fact that the word length of the computer
is Θ(log n). This in particular means that a vector of length t can be thought of
as one word.
2.2

Computation Step

Once the preprocessing is completed in O(n) time, the main computation step
proceedes scanning the t-blocks row by row and ﬁlling up the dynamic programming table(D). Algorithm 1 calls Algorithm 2 in the inner most for loop.
Algorithm 2 takes O(t) time to endcode the actual values in D and calls the
function F which takes O(1) time and returns the row (A ) and column (B )
which are used as input for other t-blocks. The runtime of the entire algorithm is
2
O( nt nt t) = O( nt ). Since t = Θ(log n) the run time of the Four Russian Algorithm
2
n
is O( log
n ).

898

3

V. Kundeti and S. Rajasekaran

Hirschberg’s Algorithm to Compute the Edit Script

In this section we brieﬂy describe Hirschberg’s [2] algorithm that computes the
edit script in O(n2 ) time using O(n) space. The key idea behind this algorithm
is an appropriate formulation of the dynamic programming paradigm. We make
some deﬁnitions before giving details on the algorithm.
– Let S1 and S2 be strings with |S1 | = m and |S2 | = n. A substring from index
i to j in a string S is denoted as S[i . . . j].
– If S is a string then S r denotes the reverse of the string.
– Let D(i, j) stand for the optimal edit distance between S1 [1 . . . i] and
S2 [1 . . . j].
– Let Dr (i, j) be the optimal edit distance between S1r [1 . . . i] and S2r [1 . . . j].
Lemma 1. D(m, n) = min0≤k≤m {D[ n2 , k] + Dr [ n2 , m − k]}.
The Lemma 1 essentially says that ﬁnding the optimal value of the edit distance
between strings S1 and S2 can be done as follows: Split S1 into two parts (p11
and p12 ) and S2 into two parts (p21 and p22 ); Find the edit distance (e1 ) between
p11 and p21 ; Find the edit distance (e2 ) between p12 and p22 ; Finally add both
the distances to get the ﬁnal edit distance (e1 + e2 ); Since we are looking for the
minimum edit distance we have to ﬁnd a breaking point (k) that minimizes the
value of (e1 + e2 ).
We would not miss this minimum even if we break one of the strings deterministically and ﬁnd the corresponding breaking point in the other string. As a
result of this we keep the place where we break in one of the strings ﬁxed. (Say
we always break one of the strings in the middle). Then we ﬁnd a breaking point
in the other string that will give us minimum value of (e1 + e2 ).
The k in Lemma 1 can be found in O(mn) time and O(m) space for the following reasons. To ﬁnd the k at any stage we need two rows(D[ n2 , ∗] and Dr [ n2 , ∗])
from forward and reverse dynamic programming tables. Since the values in any
row of the dynamic programming table just depend on the previous row, we just
have to keep track of the previous row while computing the table D and Dr .
Once we ﬁnd k we can also determine the path from the previous row ( n2 − 1) to
row ( n2 ) in both the dynamic programming tables D and Dr (see Fig. 2). Once
we ﬁnd these subpaths we can continue to do the same for the two subproblems (see Fig. 2) and continue recursively. The run time of the algorithm can be
computed by the following reccurence relation.
T (n, m) = T ( n2 , k) + T ( n2 , m − k) + mn
mn
T ( n2 , k) + T ( n2 , m − k) = mn
2 + 4 + . . . = O(mn)
In each stage we use only O(m) space and hence the space complexity is linear.

Computing edit script in O(n2 / log n) Time and O(n) Space

899

S1
S2

m−k
D
sub−problem
n/2 −1

k

(k at which D[n/2,k]+
Dr [n/2,m−k] is min)

n/2
n/2 −1

subpaths

Dr
sub−problem

S r2
S r1
Fig. 2. Illustration of Hirschberg’s recursive algorithm

4

Our Algorithm

Our algorithm combines the frameworks of the Four Russian algorithm and
n2
that of Hirschberg’s Algorithm. Our algorithms ﬁnds the edit script in O log
n
time using linear space. We extend the Four Russian algorithm to accommodate
Lemma 1 and to compute the edit script in O(n) space.
At the top-level of our algorithm we use a dynamic programming formulation
similar to that of Hirschberg. Our algorithm is recursive and in each stage of the
algorithm we compute k and also ﬁnd the sub-path as follows.
n
n
D(m, n) = min0≤k≤m {D( , k) + Dr ( , m − k)}
2
2
The key question here is how to use the Four Russian framework in the computation of D( n2 , k) and Dr ( n2 , m − k) for any k in time better than O(n2 )? .
Hirschberg’s algorithm needs the rows D( n2 , ∗) and Dr ( n2 , ∗) at any stage of the
recursion. In Hirschberg’s algorithm at recursive stage (R(m, n)), D( n2 , k) and
Dr ( n2 , m − k) are computed in O(mn) time. We cannot use the same approach
since the run time will be Ω(n2 ). We have to ﬁnd a way to compute the rows
n2
D( nn , ∗) and Dr ( n2 , ∗) with a run time of O( log
n ).
The top-level outline of our algorithm is illustrated by the pseudo-code in
TopLevel (see Algorithm 3). The algorithm starts with input strings S1 and S2
of length m and n, respectively. At this level the algorithm applies Lemma 1 and
ﬁnds k. Since the algorithm requires D( n2 , ∗) and Dr ( n2 , ∗) at this level it calls the
algorithm FourCompute to compute the rows D( n2 , ∗), D( n2 − 1, ∗), Dr ( n2 , ∗) and

900

V. Kundeti and S. Rajasekaran

Dr ( n2 − 1, ∗). Note the fact that although for ﬁnding k we require rows D( n2 , ∗)
and Dr ( n2 , ∗), to compute the actual edit script we require rows D( n2 − 1, ∗)
and Dr ( n2 − 1, ∗). Also note that these are passed to algorithm FindEditScript to
report the edit script around index k.
Once the algorithm ﬁnds the appropriate k for which the edit distance would
be minimum at this stage, it divides the problem into two sub problems (see
Fig. 2) (S1 [1 . . . k1 − 1], S2 [1 . . . n2 − 1]) and (S1 [m − k2 + 1 . . . m], S2 [ n2 + 1 . . . n].
Observe that k1 and k2 are returned by FindEditScript. FindEditScript is trying
to ﬁnd if the sub-path passes through the row n2 (at the corresponding level
of recursion) and updates k so that we can create sub-problems (please see
arcs (sub-paths) in Fig. 2). Once the sub-problems are properly updated the
algorithm solves each of these problems recursively.
We now describe algorithm FourCompute which ﬁnds the rows D( n2 , ∗) and
r n
D ( 2 , ∗) (that are required at each recursive stage of TopLevel (Algorithm 3))
in time O( nm
t ) where t is the size of blocks used in the Four Russian Algorithm.
We do exactly the same pre-processing done by the Four Russian Algorithm and
create the lookup table F . FourCompute is called for both forward (S1 ,S2 ) and
reverse strings (S1r ,S2r ). The lookup table F (A, B, K, C, E) has been created for
all the strings from Σ of length t. We can use the same lookup table F for all
the calls to FourCompute. A very important fact to remember is that in the Four
Russian algorithm whenever a lookup call is made to F the outputs {A , B }
are always aligned at the rows which are multiples of t, i.e., at any stage of the
Four Russian algorithm we only require the values of the rows D(i, ∗) such that
i mod t = 0. In our case we cannot directly use the Four Russian Algorithm in
algorithm FourCompute because the lengths of the strings which are passed to
FourCompute from each recursive level of TopLevel is not necessarily a multiple
of t. Suppose that in some stage of the FourCompute algorithm a row i is not
a multiple of t. We apply the Four Russian Algorithm and compute till row
D( ti , ∗), ﬁnd the values in the row D( ti − t, ∗) and apply lookups for rows
i
i
i
t − t, t − t + 1, . . ., and t − t + i mod t. Basically we need to slide the
i
t-block from the row t − t to ti − t + i mod t.
Thus we can compute any row that is not a multiple of t in an extra i mod t∗ m
t
time (where m is the length of the string represented across the columns). We
can also use the standard edit distance computation in rows ti , ti + 1, . . .
i
t + i mod t which also takes the same amount of extra time. Also consider the
space used while we compute the required rows in the FourCompute algorithm.
We used only O(m + n) space to store arrays D [0, ∗] and D [∗, 0] and reused
them. So the space complexity of algorithm FourCompute is linear. The run time
is O(( nt )( mt )(t)) to compute a row D(n, ∗) or Dr (n, ∗). We arrive at the following
Lemma.
Lemma 2. Algorithm FourCompute Computes rows Dr ( n2 , ∗), D( n2 , ∗) required
by Algorithm TopLevel at any stage in O( mn
t ) time and O(m + n) space.

Computing edit script in O(n2 / log n) Time and O(n) Space

901

The run time of the complete algorithm is as follows. Here c is a constant.
T (n, m) = T ( n2 , k) + T ( n2 , m − k) + c mn
2t .
mn
mn
+
+
·
·
·
)
=
O(
T (n, m) = c( mn
2t
4t
t ).
Since t = Θ(log n) the run time is O(n2 / log n).
Algorithm 3. TopLevel which calls FourCompute at each recursive level.
Input: Strings S1 ,S2 ,|S1 | = m,|S2 | = n
Output: Edit Distance and Edit Script
D( n2 , ∗) = FourCompute( n2 , m, S1 , S2 , D(∗, 0), D(0, ∗));
Dr ( n2 , ∗) = FourCompute( n2 , m, S1r , S2r , Dr (∗, 0), Dr (0, ∗));
/*Find the k which gives min Edit Distance at this level*/
M inimum = (m + n) ;
for i = 0 to n do
if (D( n2 , i) + Dr ( n2 , m − i)) < M inimum then
k=i;
M inimum = D( n2 , i) + Dr ( n2 , m − i) ;
end
end
/*Compute The EditScripts at this level */
k1 = FindEditScript(D( n2 , ∗), D( n2 − 1, ∗), k, F orward) ;
k2 = FindEditScript(Dr ( n2 , ∗), Dr ( n2 − 1, ∗), k, Backward) ;
/*Make a recursive call If necessary*/ ;
TopLevel(S1 [1 . . . k1 − 1],S2 [1 . . . n2 − 1]) ;
TopLevel(S1 [m − k2 + 1 . . . m],S2 [ n2 + 1 . . . n]) ;
4.1

Space Complexity

The space complexity is the maximum space required at any stage of the algorithm. We have two major stages where we need to analyze the space complexity
as follows. The ﬁrst during the execution of the entire algorithm and the second
during preprocessing and storing the lookup table.
4.2

Space during the Execution

The space for algorithm TopLevel is clearly linear since we need to store just
4 rows at any stage: Rows D( n2 , ∗), D( n2 − 1, ∗), Dr ( n2 , ∗) and Dr ( n2 − 1, ∗).
From Lemma 2 the space required for FourCompute is also linear. So the space
complexity of the algorithm during execution is linear.
4.3

Space for Storing Lookup Table F

We also need to consider the space for storing the lookup table F . The space
required to store the lookup table F is also linear for an appropriate value of t
n2
(as has been shown in Sec. 2.1). The runtime of the algorithm is O log
n .

902

5

V. Kundeti and S. Rajasekaran

Conclusion

In this paper we have shown that we can compute both the edit distance and
n2
edit script in time O( log
n ) using O(n) space.
Acknowledgments. This research has been supported in part by the NSF
Grant ITR-0326155 and a UTC endowment.

References
1. Arlazarov, V.L., Dinic, E.A., Kronrod, M.A., Faradzev, I.A.: On economic construction of the transitive closure of a directed graph. Dokl. Akad. Nauk SSSR 194,
487–488 (1970)
2. Hirschberg, D.S.: Linear space algorithm for computing maximal common subsequences. Communications of the ACM 18(6), 341–343 (1975)
3. Horowitz, E., Sahni, S., Rajasekaran, S.: Computer Algorithms. Silicon Press
(2008)
4. Needleman, S.B., Wunsch, C.D.: A general method applicable to the search for
similarities in the amino acid sequence of two proteins. Journal of Molecular Biology 48(3), 443–453 (1970)
5. Smith, T.F., Waterman, M.S.: Identiﬁcation of common molecular subsequences.
Journal of Molecular Biology 147(1), 195–197 (1981)
6. Gotoh, O.: Alignment of three biological sequences with an eﬃcient traceback
procedure. Journal of Theoretical Biology 121(3), 327–337 (1986)
7. Huang, X., Hardison, R.C., Miller, W.: A space-eﬃcient algorithm for local similarities. Computer Applications in the Biosciences 6(4), 373–381 (1990)
8. Gotoh, O.: Pattern matching of biological sequences with limited storage. Computer Applications in the Biosciences 3(1), 17–20 (1987)
9. Myers, E.W., Miller, W.: Optimal alignments in linear space. Computer Applications in the Biosciences 4(1), 11–17 (1988)
10. Edmiston, E., Wagner, R.A.: Parallelization of the dynamic programming algorithm for comparison of sequences, pp. 78–80 (1987)
11. Ranka, S., Sahni, S.: String editing on an simd hypercube multicomputer. Journal
of Parallel and Distributed Computing 9(4), 411–418 (1990)
12. Rajko, S., Aluru, S.: Space and time optimal parallel sequence alignments. IEEE
Transactions on Parallel and Distributed Systems 15(12), 1070–1081 (2004)
13. Gusﬁeld, D.: Algorithms of Strings Trees and Sequences. Cambridge (1997)

