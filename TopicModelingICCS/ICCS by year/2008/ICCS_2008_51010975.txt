Linearized Initialization of the Newton Krylov
Algorithm for Nonlinear Elliptic Problems
Sanjay Kumar Khattri
Stord/Haugesund University College,
Bjørnsonsgt. 45 Haugesund 5528, Norway
sanjay.khattri@hsh.no

Abstract. It is known that the Newton Krylov algorithm may not always converge if the initial assumption or initialization is far from the
exact solution. We present a technique for initializing Newton Krylov
solver for nonlinear elliptic problems. In this technique, initial guess is
generated by solving linearised equation corresponding to the nonlinear
equation. Here, nonlinear part is replaced by the equivalent linear part.
Eﬀectiveness of the technique is presented through numerical examples.

1

Introduction

The past ﬁfty to sixty years have seen generous improvement in solving linear
systems. Krylov subspace methods are the result of the tremendous eﬀort by
the researchers during the last century. It is one among the ten best algorithms
of the 20th century. There exists optimal linear solvers [16]. But, still there is
no optimal nonlinear solver, or the one that we know of. Our research is in the
ﬁeld of optimal solution of nonlinear equations generated by the discretization of
the nonlinear elliptic equations [15], [14], [13], [12]. Let us consider the following
nonlinear elliptic partial diﬀerential equation [15]
div(−K grad p) + f (p) = s(x, y)
D

p(x, y) = p
ˆ
g(x, y) = (−K ∇p) · n

in Ω

(1)

on ∂ΩD
on ∂ΩN

(2)
(3)

Here, Ω is a polyhedral domain in Rd , the source function s(x, y) is assumed to be
in L2 (Ω), and the medium property K is uniformly positive. In the equations (2)
and (3), ∂ΩD and ∂ΩN represent Dirichlet and Neumann part of the boundary,
respectively. f (p) represents nonlinear part of the equation. p is the unknown
function. The equations (1), (2) and (3) models a wide variety of processes
with practical applications. For example, pattern formation in biology, viscous
ﬂuid ﬂow phenomena, chemical reactions, biomolecule electrostatics and crystal
growth [9], [5], [6], [7], [8], [10].
There are various methods for discretizing the equations (1), (2) and (3).
To mention a few: Finite Volume, Finite Element and Finite Diﬀerence methods
[12]. These methods convert nonlinear partial diﬀerential equations into a system
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 975–982, 2008.
c Springer-Verlag Berlin Heidelberg 2008

976

S.K. Khattri

of algebraic equations. We are using the Newton Krylov algorithm for solving
the discrete nonlinear system of equations formed by the Finite Volume method
[15]. Since, initial guess or initialization is very important for the convergence of
the Newton’s algorithm. Thus, for starting the Newton Krylov algorithm, we are
solving the corresponding linearised equation, and use this solution as the initial
guess for the Newton Krylov algorithm. The corresponding linearized equations
to the nonlinear equaion (1) is div(−K grad p)+ f (p) = s. Here, f (p) is the linear
representation of the nonlinear part f (p).

2

Newton Krylov Algorithm

For formulating Newton algorithm, equation (1) is discretized in the residual
form [15]
div(−K grad p) + f (p) − s = 0.
Let the discretization of the nonlinear partial diﬀerential equations result in a
system of nonlinear algebraic equations A(p) = 0. Each cell in the mesh produces
a nonlinear algebraic equation [15], [12]. Thus, discretization of the equations (1),
(2) and (3) on a mesh with n cells result in n nonlinear equations, and let these
equations are given as
⎛
⎞
A1 (p)
⎜ A2 (p) ⎟
⎜
⎟
(4)
A(p) = ⎜ . ⎟ .
⎝ .. ⎠
An (p)
We are interested in ﬁnding the vector p which makes the operator A vanish.
The Taylors expansion of nonlinear operator A(p) around some initial guess
p0 is
A(p) = A(p0 ) + J(p0 ) Δp + hot,
(5)
where hot stands for higher order terms. That is, terms involving higher than
the ﬁrst power of Δp. Here, diﬀerence vector Δp = p − p0 . The Jacobian J is
a n × n linear system evaluated at the p0 . The Jacobian J in the equation (5)
is given as follows
⎞
⎛
∂A1
∂A1 ∂A1
···
⎜ ∂p1 ∂p2
∂pn ⎟
⎜ ∂A ∂A
∂A2 ⎟
2
2
⎟
⎜
···
⎟
⎜
∂Ai
⎜
∂p
∂p
∂p
1
2
n ⎟
=⎜
J=
⎟
.
.
.
∂pj
⎜ ..
.. . . . .. ⎟
⎟
⎜
⎝ ∂An ∂An
∂An ⎠
···
∂p1 ∂p2
∂pn
Since, we are interested in the zeroth of the non-linear vector function A(p).
Thus, setting the equation (5) equals to zero and neglecting higher order terms
will result in the following well known Newton Iteration Method

Linearized Initialization of the Newton Krylov Algorithm

J(pk ) Δpk = −A(pk ),
pk+1 = pk + Δpk+1 ,

k = 0, . . . , n.

977

(6)

The linear system (6) is solved by the Conjugate Gradient algorithm [16]. The
pseudo code is presented in the Algorithm 1. The presented algorithm have been
implemented in the C++ language. Three stopping criteria are used in the Algorithm 1. The ﬁrst criterion is the number of iterations. Second and third criteria
are based on the residual vector, A(p) and diﬀerence vector Δpk . If the method
is convergent, L2 norm of the diﬀerence vector, Δp, and the residual vector,
A(p), converge to zero [see 11]. We are reporting convergence of both of these
vectors. For better understanding the error reducing property of the method,
we report variation of A(pk ) L2 / A(p0 ) L2 and Δ(pk ) L2 / Δ(p0 ) L2 with
iterations (k).
Algorithm 1. Newton Krylov algorithm.
1
2
3
4
5
6
7
8
9

Mesh the domain;
Form the non-linear system, A(p);
Find initial guess p0 ;
Set the counter k = 0 ;
while k ≤ maxiter or Δpk L2 ≤ tol or A(pk ) L2 ≤ tol do
Solve the discrete system J(pk )Δpk = −A(pk );
pk+1 = pk + Δpk ;
k ++ ;
end

Our research work is focus on the initialization step of the above algorithm.
Initialization (step three of the Algorithm 1) is a very important part of the
Newton Krylov algorithm.

3
3.1

Numerical Work
Example 1

Without loss of generality let us assume that K is unity, and the boundary is of
Dirichlet type. Let f (p) be γ exp(p). Thus, the equations (1), (2) and (3) are
written as
−∇2 p + γ exp(p) = f
p(x, y) = p

D

in Ω,

(7)

on ∂ΩD .

(8)

Here, γ is a scalar. Let γ be 100. For computing the true error and convergence
behavior of the methods, let us further assume that the exact solution of the
equations (7) and (8) is the following bubble function

978

S.K. Khattri

0.07
0.06
0.05
0.04
0.03
0.02
0.01
0
1
0.8
0.6
0.4
0.2
0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Fig. 1. Surface plot of the exact solution of example 3.1

p = x (x − 1) y (y − 1).
Let our domain be a unit square. Thus, Ω = [0, 1] × [0, 1].
Figure 1 displays the surface plot of the exact solution. We are discretizing
equations (7) and (8) on a 40 × 40 mesh by the method of Finite Volumes [11],
[12], [13], [15]. Discretization results in a nonlinear algebraic vector (4) with 1600
nonlinear equations.
For making initial guess, we are using two approaches. In the ﬁrst tradtional
approach, we make a random initialization. The second approach is based on the
linearization of the nonlinear part. Let us now form a linear approximation to
the nonlinear part through Taylor series expansion. The Taylor series expansion
of the nonlinear part (exponential funciton) is given as
∞

ep =
i=0

pi
,
i

=1+p+

p3
p2
+
+ ···.
2
3

From the above expansion, the linear approximation of ep is (1 + p). For forming
a corresponding linearized equation to the nonlinear equation (7), we replace, ep
by (1 + p). Thus, for ﬁnding an initial guess for the Newton algorithm, we are
solving the following corresponding linearised equation
−∇2 p + γ (1 + p) = f.
The Newton iteration for both of these initial guesses are reported in the
Fig. 2(a). Figure 2(a) presents the convergence of the residual vector, while
Fig. 2(b) presents the convergence of the diﬀerence vector for ﬁrst eight

Linearized Initialization of the Newton Krylov Algorithm

979

0

10

Random Initialization
Linearized Initialization
−2

10

−4

||A(pk)||L2/||A(p0)||L2

10

−6

10

−8

10

−10

10

−12

10

0

1

2

3

4
Iterations [ k ]

(a) Newton iteration vs A(pk )

L2

5

6

7

8

for two diﬀerent initialization.

0

10

Random Initialization
Linearized Initialization
−2

10

−4

||Δpk||L2/||Δp0||L2

10

−6

10

−8

10

−10

10

−12

10

0

1

2

3

4
Iterations [ k ]

(b) Newton Iteration vs Δ(pk )

L2

5

6

7

8

for diﬀerent initialization.

Fig. 2. Example 3.1

iterations. We are solving the Jacobian system by the ILU preconditioned Conjugate Gradient with a tolerance of 1 × 10−10 .
It is clear from the Figs. 2(a) and 2(b) that solving the corresponding linearized equation for the initial guess can make a big diﬀerence. With random
initialization, the residual after ﬁve iterations is about 1/100 of the initial residual. While with linearized initialization, the residual after ﬁve iteration is about
1/1012 of the initial residual. It is interesting to note in the Fig. 2(b), with random
initialization the Newton Krylov algortithm is not converging in the L2 norm
of the diﬀerence vector. On the other hand, with a linearized initialization the
Newton Krylov algorithm is still reducing the error in diﬀerence vector by 1/1012
of the initial error.

980

S.K. Khattri

3.2

Example 2

Let us solve the following equations
−∇2 p + ξ sinh(exp(p)) = f
p(x, y) = p

in Ω,
D

(9)

on ∂ΩD .

(10)

Here, ξ is a scalar. We choose ξ to be 10. Let the exact solution be given as
p = cosx + y cos3 x − y + cosx − y sinhx + 3 y
+ 5 e−(x

2

+y 2 )/8

Let our domain be a unit square. Thus, Ω = [0, 1] × [0, 1].
Figure 3 portrays the surface plot of the exact solution. For forming a corresponding linearized equation. The Taylor series expansion of sinh(exp(p)) around
p = 0 is given as
sinhep =

1
1
e+
2
2e

1
1
e−
+
2
2e
+

p

5e
1
1 2
ep + −
+
2
12e
12

p3 + . . . .

The above series expansion is found through the Maple by using the command “taylor(sinh(exp(p)), p = 0, 5)”. From the above expansion, the linear
approximation of sinhep is
1
1
e−
2
2e

1
1
e+
2
2e

+

p.

7
6.5
6
5.5
5
4.5
4
3.5
3
2.5
1
0.8
0.6
0.4
0.2
0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

Fig. 3. Surface plot of the exact solution of example 3.2

0.8

0.9

1

Linearized Initialization of the Newton Krylov Algorithm

981

For forming a corresponding linearized equation to the nonlinear equation (9),
we replace, sinhep by (1/2 e − 1/2 e) + (1/2 e + 1/2 e) p. Thus, for ﬁnding an initial
guess for the Newton algorithm, we are solving the following linearised equation
−∇2 p + ξ

4

1
1
e−
+
2
2e

1
1
e+
2
2e

p = f.

Conclusions

Robust initialization of the Newton Krylov algorithm is very crucial for the
convergence. Initialization plays very important role in the convergence of the
Newton Krylov algorithm. We presented a technique for forming the initial guess.
Numerical work shows that initializing the Newton Krylov algorithm through the
solution of the corresponding linearized equation is computationally eﬃcient.

Bibliography
[1] Khattri, S.K.: Newton-Krylov Algorithm with Adaptive Error Correction For the
Poisson-Boltzmann Equation. MATCH Commun. Math. Comput. Chem. 1, 197–
208 (2006)
[2] Khattri, S.K., Hellevang, H., Fladmark, G.E., Kvamme, B.: Simulation of longterm fate of CO2 in the sand of Utsira. Journal of Porous Media (to be published)
[3] Khattri, S.K.: Grid generation and adaptation by functionals. Computational and
Applied Mathematics 26, 1–15 (2007)
[4] Khattri, S.K.: Numerical Tools for Multicomponent, Multiphase, Reactive Processes: Flow of CO2 in Porous Media. PhD Thesis, The University of Bergen
(2006)
[5] Host, M., Kozack, R.E., Saied, F., Subramaniam, S.: Treatment of Electrostatic
Eﬀects in Proteins: Multigrid-based Newton Iterative Method for Solution of the
Full Nonlinear Poisson-Boltzmann Equation. Proteins: Structure, Function, and
Genetics 18, 231–245 (1994)
[6] Holst, M., Kozack, R., Saied, F., Subramaniam, S.: Protein electrostatics: Rapid
multigrid-based Newton algorithm for solution of the full nonlinear PoissonBoltzmann equation. J. of Bio. Struct. & Dyn. 11, 1437–1445 (1994)
[7] Holst, M., Kozack, R., Saied, F., Subramaniam, S.: Multigrid-based Newton iterative method for solving the full Nonlinear Poisson-Boltzmann equation. Biophys.
J 66, A130–A130 (1994)
[8] Holst, M.: A robust and eﬃcient numerical method for nonlinear protein modeling equations. Technical Report CRPC-94-9, Applied Mathematics and CRPC,
California Institute of Technology (1994)
[9] Holst, M., Saied, F.: Multigrid solution of the Poisson-Boltzmann equation. J.
Comput. Chem. 14, 105–113 (1993)
[10] M. Holst: MCLite: An Adaptive Multilevel Finite Element MATLAB Package
for Scalar Nonlinear Elliptic Equations in the Plane. UCSD Technical report and
guide to the MCLite software package. Available on line at,
http://scicomp.ucsd.edu/∼ mholst/pubs/publications.html
[11] Khattri, S.: Convergence of an Adaptive Newton Algorithm. Int. Journal of Math.
Analysis 1, 279–284 (2007)

982

S.K. Khattri

[12] Khattri, S., Aavatsmark, I.: Numerical convergence on adaptive grids for control volume methods. The Journal of Numerical Methods for Partial Diﬀerential
Equations 9999 (2007)
[13] Khattri, S.: Analyzing Finite Volume for Single Phase Flow in Porous Media.
Journal of Porous Media 10, 109–123 (2007)
[14] Khattri, S., Fladmark, G.: Which Meshes Are Better Conditioned: Adaptive, Uniform, Locally Reﬁned or Locally Adjusted? In: Alexandrov, V.N., van Albada,
G.D., Sloot, P.M.A., Dongarra, J. (eds.) ICCS 2006. LNCS, vol. 3992, pp. 102–
105. Springer, Heidelberg (2006)
[15] S. Khattri, Nonlinear elliptic problems with the method of ﬁnite volumes. Diﬀerential Equations and Nonlinear Mechanics. Article ID 31797 (2006)
[16] van der Vorst, H.A.: Iterative Krylov Methods for Large Linear Systems. Cambridge monographs on applied and computational mathematics. Cambridge University Press, New York (2003)

