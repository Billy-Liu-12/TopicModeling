Reutilization of Partial LU Factorizations for
Self-adaptive hp Finite Element Method Solver
Maciej Paszynski and Robert Schaefer
Department of Computer Science
AGH University of Science and Technology,
Al. Mickiewicza 30, 30-059 Krak´
ow, Poland
paszynsk,schaefer@agh.edu.pl
http://home.agh.edu.pl/~paszynsk

Abstract. The paper presents theoretical analysis of the extension of
the new direct solver dedicated for the fully automatic hp adaptive Finite Element Method. The self-adaptive hp-FEM generates in a fully
automatic mode (without any user interaction) a sequence of meshes delivering exponential convergence of the numerical error with respect to
the mesh size. The consecutive meshes are obtained by performing h, p
or hp reﬁnements. The proposed solver constructs an initial elimination
tree based on the nested dissection algorithm executed over the initial
mesh. The constructed elimination tree is updated each time the mesh
is reﬁned, by adding the elimination sub-tree related to the executed
reﬁnement. We propose a new strategy for reutilization of partial LU
factorizations computed by the direct solver on the previous mesh, when
solving a consecutive mesh from the sequence. We show that the number
of LU factorizations that must be recomputed is linearly proportional to
the number of singularities in the problem.

1

Motivation and the Basic Idea of Solution

The paper presents theoretical analysis of the extension of the sequential and
parallel solvers [1], [2] dedicated for the self-adaptive hp Finite Element Method
[3], [4], [5]. The self-adaptive hp-FEM generates a sequence of approximation
spaces delivering exponential convergence of the numerical error of the resulting
approximation of the variational problem under consideration. The exponential
convergence of the error is obtained with respect to the dimension of the approximation space. The self-adaptive hp-FEM starts from an initial approximation
space, constructed by utilizing a given uniform initial ﬁnite element mesh. The
ﬁrst order polynomial basis function (”pyramids”) are related to vertices of the
mesh, and the higher order polynomial basis functions are related to ﬁnite element edges and interiors [3]. The consecutive spaces from the produced sequence
are obtained by performing so-called h or p reﬁnements. The h reﬁnement consists in breaking selected ﬁnite element into new son-elements, and adding new
basis functions related to just created elements. The p reﬁnement consists in
adding higher order basis function associated with selected element edges or interiors. The reﬁnements performed to improve the quality of the approximation
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 965–974, 2008.
c Springer-Verlag Berlin Heidelberg 2008

966

M. Paszynski and R. Schaefer

Fig. 1. Updating of the elimination tree when the mesh is h reﬁned

space are selected by utilizing knowledge driven algorithm [6] based on the graph
grammar formalism.
An eﬃcient solver must be utilized to compute coeﬃcients of the projection
of the considered weak (variational) problem solution onto the current approximation space. The coeﬃcients are called degrees of freedom (d.o.f.). These coefﬁcients, denoted by uihp , are computed by solving the system of equations
dim

uihp b (ei , ej ) = l (ej )

∀j = 1, ..., dim ,

(1)

i=1

where dim denotes the dimension of the approximation space (number of the
basis functions), {ek }dim
k=1 denote the basis functions and b (ei , ej ) and l (ej ) are
matrix and right-hand-side vector entries obtained by computing some integrals
resulting from the considered problem.
Here we present a short description of direct solvers utilized by FEM. The
frontal solver browses ﬁnite elements in the order prescribed by the user, aggregates d.o.f. to the so-called frontal matrix. Based on the elements connectivity
information it recognizes fully assembled degrees of freedom and eliminates them
from the frontal matrix [7]. This is done to keep the size of the frontal matrix as
small as possible. The key for eﬃcient work of the frontal solver is the optimal
ordering of ﬁnite elements. The multi-frontal solver constructs the d.o.f. connectivity tree based on analysis of the geometry of computational domain [7]. The
frontal elimination pattern is utilized on every tree branch. Finite elements are
joined into pairs and d.o.f. are assembled into frontal matrix associated with the
branch. The process is repeated until the root of the assembly tree is reached.
Finally, the common dense problem is solved and partial backward substitutions are recursively executed on the assembly tree. The sub-structuring method
solver is a parallel solver working over a computational domain partitioned into
multiple sub-domains [8]. First, the sub-domains internal d.o.f. are eliminated
with respect to the interface d.o.f. Second, the interface problem is solved. Finally, the internal problems are solved by executing backward substitution on
each sub-domain. This can be done by performing frontal decomposition on each
sub-domain, and then solving the interface problem by a sequential frontal solver
(this method is called the multiple fronts solver [9]). The better method is to

Reutilization of Partial LU Factorizations

967

Fig. 2. Elimination tree for simple two ﬁnite elements mesh. Fully aggregated degrees of
freedom for element interiors are eliminated in parallel, the resulting Schur complement
contributions are added, and common interface problem is ﬁnally solved. The process is
followed by performing recursive backward substitutions (not presented in the picture).

solve the interface problem also by a parallel solver (this is called the direct
sub-structuring method solver ). The parallel implementation of the multi-frontal
solver is called the sparse direct method solver. The MUlti frontal Massively
Parallel Solver (MUMPS) [10] is an example of such a solver.
A new eﬃcient sequential and parallel solver for self-adaptive hp-FEM has
been designed [1], [2], utilizing elimination tree constructed base on the history
of mesh reﬁnements. The elimination tree for the initial mesh is created by
utilizing nested dissection algorithm. The exemplary two ﬁnite elements mesh
with its elimination tree is presented on the ﬁrst panel in Fig. 1. Each time
decision about mesh reﬁnement is made, the elimination tree is dynamically
expanded by adding sub-tree related to the performed reﬁnements. The example
of two h reﬁnements performed on the initial mesh with resulting expanding of
the elimination tree is presented in Fig. 1. Thus, we can distinguish two levels
on the elimination tree. The ﬁrst level is related to the initial mesh elements,
and the second level is related to reﬁnements performed over the initial mesh.
The following observation is the key idea of the designed solver [1], [6]. The
integral b (ei , ej ) is non-zero only if intersection of supports of ei and ej is not
empty. The support of a vertex basis function spreads over ﬁnite elements having
the vertex, the support of an element edge basis function spreads over two ﬁnite
elements adjacent to the edge, and ﬁnally the support of an element interior basis
function spreads only over the element. Thus, the integral b (ei , ej ) is zero if basis
functions are related to distanced elements. The solver constructs ﬁrst partially
aggregated sub-matrices related to single ﬁnite elements, then it eliminates these
entries that have already been fully assembled, and then it recursively merges
resulting sub-matrices and eliminates fully assembled entries until it reaches the
top of the elimination tree. Finally, it executes recursive backward substitutions,
from the root of the tree down to the leaves. The exemplary execution of the
solver on the two elements initial mesh from Fig. 1 is presented in Fig. 2.
The resulting LU factorizations computed at every node of the elimination
tree can be stored at tree nodes for further reutilization. Each time the mesh

968

M. Paszynski and R. Schaefer

Fig. 3. The problem is solved over the ﬁrst mesh. All LU factorizations (black and grey)
are computed. Then, the mesh is reﬁned, and the problem is solved again. Grey LU
factorizations are reutilized from the previous mesh, but all brown LU factorizations
must be recomputed. Black LU factorizations from previous mesh are deleted.

is reﬁned, the LU factorizations from the unreﬁned parts of the mesh can be
reutilized. There is a need to recompute LU factorization over the reﬁned elements, as well as on the whole path from any reﬁned leaf up to the root of the
elimination tree. The example of the reutilization of partial LU factorizations
after performing two local reﬁnements is presented in Fig. 3.

2

Theoretical Analysis of the Solver Eﬃciency

We start this section with the sketch of the recursive solver algorithm, with
reutilizations of LU factorizations.
matrix function recursive solver(tree node)
if (tree node has no son nodes) then
eliminate leaf element stiffness matrix internal nodes;
store Schur complement sub-matrix at tree node;
return (Schur complement sub-matrix);
else if (tree node has son nodes) then
do (for each tree node son)
if (sub-tree has been refined) then
son matrix = recursive solver(tree node son);
else
get the Schur complement sub-matrix from tree node son;
endif
merge son matrix into new matrix;
enddo
decide which unknowns of new matrix can be eliminated;
perform partial forward elimination on new matrix;
store Schur complement sub-matrix at tree node;
return (Schur complement sub-matrix);
endif

Reutilization of Partial LU Factorizations

969

Computational Complexity of the Sequential, Recursive Solver Without Reutilization of LU Factorizations. Let us estimate ﬁrst the number of
operations performed by a sequential recursive solver during forward elimination
over a square shape 2D ﬁnite element mesh with N = 2n × 2n ﬁnite elements.
The order of approximation in the interior of the element is assumed to be
equal to (p1 , p2 ). The orders of approximation on element edges are assumed
to be equal to the corresponding orders in the interior. From this assumption
it follows that there are 2 faces with orders p1 and 2 faces with orders p2 . The
total number of d.o.f. in such an element is nrdof = (p1 + 1) (p2 + 1) = O (p1 p2 ).
To estimate the eﬃciency of the sequential solver, we assume that p1 = p2 =
p, e.g. by taking p = max{p1 , p2 }. Thus, the total number of d.o.f. satisﬁes
2
nrdof = (p + 1) = O(p2 ), while the number of interior d.o.f. can be evaluated
as interior nrdof = (p − 1)2 = O(p2 ), and the number of interface d.o.f. satisﬁes
interf ace nrdof = 4p2 = O(p2 ).
The recursive solver eliminates d.o.f. related to elements interiors. The computational complexity of this step is 22n × O(p6 ) since there are 22n such ﬁnite
elements and the internal d.o.f. elimination cost is O(p6 ) on every element.
Then, the solver joints elements into pairs, and eliminates d.o.f. related to
common edges. The computational complexity of this operation is 22n−1 × ((2 +
4 + 1) × p)2 × (2 + 4) × p since there are 22n−1 such pairs of elements, and there
are 7 total edges within a pair, and only one edge is eliminated.
In the next step elements are joint into sets of four, and d.o.f. related to
two common edges are eliminated. The computational complexity of this step is
22n−2 × ((4 × 2 + 2) × p)2 × (4 × 2) × p since there are 22n−2 such sets of elements,
and there are 10 edges in every set, and only 2 edges are eliminated.

Fig. 4. Two tested meshes with uniform p = 4 and p = 5

The process is repeated until we reach the root of the elimination tree. The
total computational complexity of this process is
22n × p6 + 22n−1 × (2 + 4 + 1)2 p2 × (2 + 4) × p +
22n−2k−1 2 × 2k+1 + 2 × 2k + 2k

2

p2 2 × 2k+1 + 2 × 2k p+

22n−2k 2 × 2k + 2 × 2k + 2k

2

p2 2 × 2 k + 2 × 2 k p

k=1,...,n

.

970

M. Paszynski and R. Schaefer

Fig. 5. The execution time of the parallel solver over the second tested mesh

This can be estimated by utilizing the sum of the geometrical series as
⎞
⎛
22n+k+5 p3 ⎠

T1 = O 22n p6 + O 22n−1 p3 + O ⎝
k=1,...,n
2n 6

=O 2 p + 2

2n−1

+2

3n+6

−2

2n+4

p

3

2n 6

= O(2 p + 23n p3 + 22n p3 ) . (2)

Computational Complexity of the Sequential Solver With Reutilization of LU Factorizations. In this section we perform the same analysis of the
computational complexity like in the previous section, but this time we assume
that the problem over the computational mesh has been already solved, and
only one element has been h reﬁned in the direction of a mesh corner singularity. In this case, there is a need to compute all LU factorizations related to the
elimination sub-tree associated with broken corner element. It is also necessary
to recompute all LU factorizations on the single path from the reﬁned element
(represented by a leaf in the original elimination tree) up to the root of the tree.
The computational complexity over the broken element is
4 × p6 + 2 × (2 + 4 + 1)2 p2 × (2 + 4) × p + (4 ∗ 2 + 2)2 p2 × (4 ∗ 2) × p , (3)
since there are 4 element interiors, two single common edges and 1 twofold edge.
The computational complexity of the recomputation of the whole path from the
reﬁned leaf up to the elimination tree root can be estimated by utilizing equation
(2) with the correction that there is only one set of elements on every level of
the tree, and without the leaf element computations, already estimated in (3).
(2 + 4 + 1)2 p2 × (2 + 4) × p +
2 × 2k+1 + 2 × 2k + 2k

2

p2 2 × 2k+1 + 2 × 2k p+

2 × 2k + 2 × 2k + 2k

2

p2 2 × 2 k + 2 × 2 k p

k=1,...,n

.

(4)

Reutilization of Partial LU Factorizations

971

Table 1. Execution time at diﬀerent elimination tree nodes on two tested meshes
First mesh
Tree level Nodes number min time [s] max time [s]
1
1
0.115
2
2
0.854
0.883
3
4
0.864
2.406
4
8
0.828
2.542
5
16
0.904
2.750
6
32
0.049
0.230
< 10−2
7
64
< 10−2
< 10−3
8-14
128-9216
< 10−3

Second mesh
min time [s] max time [s]
0.212
1.631
1.674
1.617
4.625
1.675
4.535
1.621
4.686
1.606
4.763
< 10−2
0.110
< 10−3
< 10−3

The total computational complexity of the solver reutilizing LU factorization is
equal to the sum of (3) and (4), that is
⎞
⎛
23k+6 p3 ⎠

T11 = O p6 + O p3 + O ⎝
k=1,...,n
6

=O p + 1+2

3n+6

−2

6

p

3

= O(p6 + 23n p3 ) .

(5)

In the case of multiple reﬁned leaves, the pessimistic estimation is that each
leaf will generate a separate path to be totally recomputed. Thus, the total
computational complexity with r reﬁned leafs (resulting from r4 singularities) is
T1r = O rp6 + r + r23n+6 − r26 p3 = O(rp6 + r23n p3 ) .

(6)

We conclude this section with the comparison of the execution times of the
sequential solver with reutilization of LU factorization with respect to the sequential solver without the reutilization
T1
=O
T1r

22n
r

=O

N
r

.

The solver with reutilization of partial LU factorizations is O

(7)
N
r

times faster.

Complexity of the Parallel Solver Without Reutilization of LU Factorizations. The parallel version of the solver exchanges the partially aggregated
matrices between the same level nodes [1]. Leaves of the elimination tree are assigned to diﬀerent processors. When traveling up the elimination tree, the local
Schur complements are sent from the second children node to the ﬁrst one (to
the ﬁrst processor in every set). To estimate the computational complexity of the
parallel recursive solve, we assume that the number of processors is P = 22m .
Each processor is responsible for its part of the mesh, with 22n−2m ﬁnite
elements. Thus, each processor performs
O(22(n−m) p6 + 23(n−m) p3 )

(8)

972

M. Paszynski and R. Schaefer

operations on its part of the mesh. After this step, all computations over the
elimination tree are performed fully in parallel:
2 × 2k+1 + 2 × 2k + 2k

2

p2 2 × 2k+1 + 2 × 2k p+

k=m+1,...,n

2 × 2k + 2 × 2k + 2k
= O(p3

22k ) = O(p3
k=m+1,n

2

p2 2 × 2 k + 2 × 2 k p

22(m+k) ) = O(22(n−m) p3 ) .

(9)

k=1,n−m

The communication complexity involves 2(n − m + 1) parallel point to point
communications where sub-matrices related to local Schur complements are exchanged between pairs of tree nodes. The communication complexity is then
2 × (2k × p)2 = O(p2
k=m+1,n

2(m+k) ) = O(22(n−m) p2 )

(10)

k=1,n−m

since the size of every sub-matrix is 2k × p. The total complexity of the parallel
solver without reutilization of the LU factorizations is then
TP = (22(n−m) p6 + 23(n−m) p3 + 22(n−m) p3 ) × tcomp + 22(n−m) p2 × tcomm (11)
with P = 22m the number of processor, and p the order of approximation.
Complexity of the Parallel Solver With Reutilization of LU Factorizations. In the case of the parallelization of the reutilization, the maximum
number of processors that can be utilized is equal to r, the number of elements
reﬁned within the actual mesh. Each reﬁnement requires the recomputation of
the whole path from the reﬁned leaf up to the tree root, which is a purely sequential. If the number of processors P = 22m is larger or equal to the number of
executed reﬁnements 22m ≥ r, then the total computational complexity can be
roughly estimated as parallel execution of r paths from a leaf to the root of the
tree, which is equal to (5). The communication complexity remains unchanged,
since there is still a need to exchange the LU factorization, even if they are taken
from local tree nodes. Thus the communication complexity is equal to (10). The
total complexity of the parallel solver with reutilization of LU factorizations is
TPr = (p6 + 23n p3 ) × tcomp + 22(n−m) p2 × tcomm .

(12)

This is the “best parallel time” that can be obtain by the parallel solver with
reutilization of partial LU factorizations, under the assumption that we have
enough available processors (P = 22m ≥ r). In other words, it is not possible
to utilize more processors then number of reﬁned elements r. We can compare
the execution time of the parallel solver with reutilization to the parallel solver
without the reutilization (as usually under the assumption that we have enough
processors P = 22m ≥ r).
TP
= O 22(n−m) = O
TPr

N
22m

The parallel solver with reutilization is O
solver without the reutilization.

=O
N
r

N
P

≤O

N
r

.

(13)

times faster than the parallel

Reutilization of Partial LU Factorizations

3

973

Test Results

We conclude the presentation with two numerical experiments, presented in Fig.
4. The goal of these experiments is to illustrate the limitation of the scalability of
the solver by the sequential part of the algorithm - the longest path from the root
of the elimination tree down to the deepest leaf. For more numerical experiments
executed for much larger problems, with more detailed discussion on the performance of the solver, as well as for the detailed comparison with the MUMPS
solver, we refer to [1]. Both numerical experiments have been performed for the
3D Direct Current (DC) borehole resistivity measurement simulations [11]. The
3D problem has been reduced to 2D by utilizing the Fourier series expansions
in the non-orthogonal system of coordinates. We refer to [11] for the detailed
problem formulation. The ﬁrst mesh contains 9216 ﬁnite elements with polynomial order of approximation p = 4, and 148, 257 d.o.f. The second mesh contains
9216 ﬁnite elements with polynomial order of approximation p = 5, and 231, 401
d.o.f. Both meshes have been obtained by performing two global hp reﬁnements
from the initial mesh with 32 × 18 = 576 ﬁnite elements with polynomial order
of approximation p = 2 or p = 3, respectively. There are necessary 10 nested
dissection cross-sections of the initial mesh, since 32 × 18 ≤ 25 × 25 . Thus, the
depth of the initial elimination tree is 10. Each global hp reﬁnement consists
in breaking each ﬁnite element into 4 son elements and increasing polynomial
order of approximation by 1. Thus, each global hp reﬁnement adds 2 levels to
the elimination tree, so the total number of levels in the elimination tree is 14.
Table 1 contains the total number of nodes at given elimination tree level, as
well as the minimum and maximum Schur complement computation times for
nodes located at given level of the elimination tree. The time of computing the
entire path of partial LU factorization from a tree leaf up to the elimination
tree root varies from 4 sec. to 9 sec. on the ﬁrst mesh and from about 10 sec.
up to 17 sec. on the second mesh. The execution time of the sequential solver
with reutilization of LU factorizations over r times reﬁned mesh will be within
(4 × r, 9 × r) sec. over the ﬁrst and (10 × r, 17 × r) sec. over the second mesh.
The execution time of the parallel solver with reutilization of LU factorizations
over r times reﬁned mesh will be within (4, 9) sec. over the ﬁrst and (10, 17) sec.
over the second mesh, if there are more processors than reﬁned elements. We
present also in Fig. 5 the execution time of the parallel solver over the ﬁrst mesh
with N = 231, 401 unknowns, for increasing number of processors. We observe
that the parallel solver execution time is limited by the maximum time required
to solve the entire path, which is about 9 second in this case.

4

Conclusions

We proposed a new algorithm for the sequential and parallel solver, that allows for signiﬁcant reduction of the solver execution time over a sequence of
meshes generated by the self-adaptive hp-FEM. The solver reutilized partial LU
factorizations computed in previous iterations over unreﬁned parts of the mesh.

974

M. Paszynski and R. Schaefer

Every local h reﬁnements requires a sequential recomputation of all LU factorization on a path from the reﬁned leaf up to the root of the elimination tree. The
maximum number of processors that can be utilized by the parallel solver with
reutilization is equal to the number of reﬁned elements. Both, the sequential
and parallel solver with reutilization is O Nr faster than the solver without the
reutilization, where N is number of elements and r is number of reﬁnements.
Acknowledgments. We acknowledge the support of Polish MNiSW grant no.
3TO8B05529 and Foundation for Polish Science under Homming Programme.

References
1. Paszy´
nski, M., Pardo, D., Torres-Verdin, C., Demkowicz, L., Calo, V.: Multi-Level
Direct Sub-structuring Multi-frontal Parallel Direct Solver for hp Finite Element
Method. ICES Report 07-33 (2007)
2. Paszy´
nski, M., Pardo, D., Torres-Verdin, C., Matuszyk, P.: Eﬃcient Sequential and
Parallel Solvers for hp FEM. In: APCOM-EPMSC 2007, Kioto, Japan (2007)
3. Demkowicz, L.: Computing with hp-Adaptive Finite Elements, vol. I. Chapman &
Hall/Crc Applied Mathematics & Nonlinear Science, New York (2006)
4. Demkowicz, L., Pardo, D., Paszy´
nski, M., Rachowicz, W., Zduneka, A.: Computing
with hp-Adaptive Finite Elements, vol. II. Chapman & Hall/Crc Applied Mathematics & Nonlinear Science, New York (2007)
5. Paszy´
nski, M., Kurtz, J., Demkowicz, L.: Parallel Fully Automatic hp-Adaptive
2D Finite Element Package. Computer Methods in Applied Mechanics and Engineering 195(7-8), 711–741 (2007)
6. Paszy´
nski, M.: Parallelization Strategy for Self-Adaptive PDE Solvers. Fundamenta
Informaticae (submitted, 2007)
7. Duﬀ, I.S., Reid, J.K.: The Multifrontal Solution of Indeﬁnite Sparse Symmetric
Linear Systems. ACM Trans. on Math. Soft. 9, 302–325 (1983)
8. Giraud, L., Marocco, A., Rioual, J.-C.: Iterative Versus Direct Parallel Substructuring Methods in Semiconductor Device Modelling. Numerical Linear Algebra
with Applications 12(1), 33–55 (2005)
9. Scott, J.A.: Parallel Frontal Solvers for Large Sparse Linear Systems. ACM Trans.
on Math. Soft. 29(4), 395–417 (2003)
10. Milti-frontal Massively Parallel Sparse Direct Solver (MUMPS),
http://graal.ens-lyon.fr/MUMPS/
11. Pardo, D., Calo, V.M., Torres-Verdin, C., Nam, M.J.: Fourier Series Expansion in a
Non-Orthogonal System of Coordinates for Simulation of 3D Borehole Resistivity
Measurements; Part I: DC. ICES Report 07-20 (2007)

