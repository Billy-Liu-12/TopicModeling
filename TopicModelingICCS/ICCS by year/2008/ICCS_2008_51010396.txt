Reducing False Alarm Rate in Anomaly
Detection with Layered Filtering
Rafal Pokrywka1,2
1

Institute of Computer Science
AGH University of Science and Technology
al. Mickiewicza 30, 30-059 Krak´
ow, Poland
pokrywka@agh.edu.pl
2
IBM SWG Laboratory
ul. Armii Krajowej 18, 30-150 Krak´
ow, Poland

Abstract. There is a general class of methods of detecting anomalies
in a computer system which are based on heuristics or artiﬁcial intelligence techniques. These methods are to distinguish between normal and
anomalous system behaviour. The main weakness of these methods is
a false alarm rate which is usually measured by counting false-positives
on a sample set representing normal behaviour. In this measurement a
base rate of anomalous behaviour in a live environment is not taken into
account and that leads to a base-rate fallacy. This problem can greatly
aﬀect a real number of false alarms which can be signiﬁcantly greater
then expected value. Usually little can be done to further improve classiﬁcation algorithms. In this paper a diﬀerent approach to reducing real
false alarm rate based on layered ﬁltering is presented and discussed.
The solution explores potential in a properly structured system of several anomaly detectors.

1

Introduction

Work presented here is a part of research on Intrusion Detection System (IDS)
which is based on anomaly detection. This kind of security systems are usually
placed in key nodes of network infrastructure and are often used to complement
signature based detection systems. The system detects anomalies by comparing
normal behaviour, stored in some way as a proﬁle, and current behaviour of
supervised processes. This approach allows to detect an attack without a priori
knowledge of attack’s technique in opposite to signature-based detectors which
are basically blind to novel attack patterns.
Anomaly detectors sometimes fail to correctly classify current event. From all
misclassiﬁcation types the false-positive error, also referred as false alarm which
is when normal behaviour is marked as anomalous, is the most signiﬁcant. This
article focuses on a very important aspect of my research – proper handling
of this kind of errors. The goal is to have an eﬀective system yet with very
This paper is NOT related to any of my job responsibilities as an employee of IBM.
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 396–404, 2008.
c Springer-Verlag Berlin Heidelberg 2008

Reducing False Alarm Rate in Anomaly Detection with Layered Filtering

397

low real false alarm rate – even close to 0. The problem is that real life system
usually works ﬁne most of the time and only sometimes abnormal event happens
– simply the frequency of anomalies is fairly low. The false alarm rate of anomaly
detectors is usually measured by taking the ratio between a number of alarms
ﬁred on a sample set of normal events and the size of this set – the base rate is
not taken into account in this measurement. The result is that real false alarm
rate achieved during monitoring of real systems can be signiﬁcantly larger then
expected – even large enough to make anomaly detector basically useless. This
phenomenon is known as base-rate fallacy and directly stems out from Bayes
theorem. It also frequently skips the attention of researchers. It is a hard task
to further improve current anomaly detection algorithms, which have already
achieved quite low false alarm rates, but even large improvement may not be
enough. The real improvement can be achieved by combining several anomaly
detectors with diﬀerent properties and performance into layers which gradually
ﬁlters out abnormal events.
In this article the term ”event” is used to describe smallest set of information from the system that can be classiﬁed. The term ”behaviour” relates to a
sequence of events.

2

Anomaly Detectors Overview

Anomaly detection algorithms are used to distinguish if a current event is normal
or not. To simplify discussion at this moment it can be assumed that information
about type of anomaly, like for example error condition or buﬀer overﬂow, can
be neglected. In this case detector can be seen as binary classiﬁer as there are
only two possible classes of events – normal event or anomaly.
There are four possible outcomes from a detector with respect to the actual
class of an event:
– true positive (TP) – when current event is anomalous and detector prediction
is correct (signalisation of anomaly)
– false positive (FP) – when current event is normal but detector prediction
is incorrect (signalisation of anomaly)
– true negative (TN) – when current event is normal and detector prediction
is correct (no signalisation of anomaly)
– false negative (FN) – when current event is anomalous but detector prediction is incorrect (no signalisation of anomaly)
The false positive is also known in statistics as type I error and this is the
situation when a false alarm is ﬁred. False negative is know as type II error and
it describes the situation when real anomaly is missed by the detector. True
positive is when a detector correctly signals anomaly and true negative when it
correctly indicates normal event.
Anomaly detectors in scientiﬁc publications are usually characterized by the
following operational characteristics:

398

R. Pokrywka

– detection rate (DR) – which is exactly the same as true positive rate and
P
can be calculated using the following equation: DR = T PT+F
N
– false alarm rate (FAR) – which is the same as false positive rate and is
P
calculated using: F AR = F PF+T
N
A good graphical presentation of these two characteristics (DR and FAR) is
provided by ROC curve. It allows to conveniently compare diﬀerent detection
algorithms or choose the best set of algorithm parameters. A great survey of a
couple of the most popular detection techniques can be found in [3].

3

The Base-Rate Fallacy

The diﬃculty in improving eﬀectiveness of anomaly detectors due to base-rate
fallacy phenomenon has been ﬁrst pointed out by Stefan Axelsson in [2]. The
fallacy stems out directly from Bayes theorem which relates prior and posterior
probability of an event and is given by the following formula:
P (A|B) =

P (A) ∗ P (B|A)
.
P (B)

(1)

P (B) can be expressed, using the law of total probability for n mutually exclusive
outcomes of A, in the following way:
n

P (Ai ) ∗ P (B|Ai ) .

P (B) =

(2)

i=1

Finally after combination of (1) and (2) the most popular Bayes theorem form
can be derived:
P (A) ∗ P (B|A)
.
(3)
P (A|B) = n
i=1 P (Ai ∗ P (B|Ai )
Following Axellsson let’s assume that I means an anomalous event in a system,
¬I that it is a normal event (no anomaly), A that there is an alarm signalisation
from a detector and ¬A that there is no alarm ﬁred. The false alarm rate can
be expressed by the probability P (A|¬I) and detection rate by P (A|I). True
negative and false negative rates can be obtained, respectively, in the following
way: P (¬A|¬I) = 1 − P (A|¬I) and P (¬A|I) = 1 − P (A|I). Equation (3) can
now be rewritten as:
P (I|A) =

P (I) ∗ P (A|I)
.
P (I) ∗ P (A|I) + P (¬I) ∗ P (A|¬I)

(4)

The goal in anomaly detection is to maximise P (I|A), which is called by Axellson a Bayesian Detection Rate (BDR), and P (¬I|¬A), which is the probability
that lack of alarm really means lack of anomaly and in this paper will be called
Bayesian True Negative Rate (BTNR). In a real life environment the frequency
of anomalies is fairly low. Based on [2] the assumptions has been made that

Reducing False Alarm Rate in Anomaly Detection with Layered Filtering

399

the average is 2 ∗ 10 anomalous events per day and 106 events overall per day.
This allows to calculate the following probabilities: P (I) = 2∗10−5 and P (¬I) =
1−P (I) = 0.99998. Another assumptions has been made about characteristics of
hypothetical anomaly detector: DT = P (A|I) = 1 and F AR = P (A|¬I) = 10−5 .
In fact such values would be a really great achievement – they are simply not
realistic and are only to show how signiﬁcant base-rate fallacy is. Taking all these
values the calculated BDR is 0.66667. It means that the probability a ﬁred alarm
is not a false alarm is only 0.66667. This value in practice can not be tolerated – it
makes anomaly detector useless for an administrator. Under the same base rate
(¬I)∗P (¬A|¬I)
assumptions the probability BT N R = P (¬I|¬A) = P (¬I)∗PP(¬A|¬I)+P
(I)∗P (¬A|I)
is dominated by the base rate of normal events and is always close to 1 which
means that anomaly rarely escapes detection.
Axelsson argues that it is crucial to keep false alarm rate as low as possible
even if the algorithm complexity and resource consumption is very high. This
of course makes the detection very slow and there is a risk that intrusion is not
detected on time. The potential damages and losses may have already been done.
Also further improvement of F AR of current detection algorithms may not be a
feasible task – there is to much eﬀort for little gains. Layered Filtering may be
an answer for these diﬃculties.

4

Layered Filtering

Layered ﬁltering is well known in air or water pollution elimination. It consist
of at least two ﬁlters in a sequence and each ﬁlter is responsible for elimination
of diﬀerent pollution type. The air, for example, ﬂows through all ﬁlters and
every ﬁlter is responsible for eliminating diﬀerent chemical pollution or dust. As
a result a clean air is supposed to be achieved.
Returning back to the computer science ﬁeld there is a method of combining
binary classiﬁers to get a multiple classiﬁer. This classiﬁer uses more then one
specialised binary classiﬁer for each class and combines theirs outcomes – see for
example [4].
The idea behind layered ﬁltering takes something from both analogies: computer science and non-computer science. It gradually ﬁlters out normal system
events as air ﬁlters do with pollution. It is also similar to multiple classiﬁer
but with the exception that there are still only two classes of an event and the
specialisation considers only the method of how a check is performed.
At the end Layered Filtering follows the rule of thumb that the whole exceeds
the sum of its parts.
Let’s consider a sequence of layered anomaly detectors Ld1 , ..., Ldn where
n is the number of layers. Each detector has one input stream and two output
streams: a− stream for anomalous and n− stream for normal events. A detector
Ldi passes to Ldi+1 only those events which are classiﬁed as anomalous. Among
them there could be a lot of false positives but this is not important at this point.
A Detector can perform any processing or transformations of events, under the
condition that a − stream of Ldi is compatible with input stream of Ldi+1 . The

400

R. Pokrywka

All System
events

Ld_1

Abnormal
Events
+ False
alarms

Ld_2

Ld_3

Final Output

Filtered out
normal events

Fig. 1. Layered ﬁltering schema

ﬁrst and last detectors are distinguished in a sense that Ld1 must accept event
types of system under supervision and Ldn outputs information about anomalies
to security oﬃcer. Figure 1 presents a schema for an anomaly detector based on
layered ﬁltering.
Let introduce the following symbols:
–
–
–
–
–
–

DTi – i-th layer detection rate
F ARi – i-th layer false alarm rate
P (I)i – i-th layer base rate of anomalous events
P (¬I)i – i-th layer base rate of normal events
BDRi – i-th layer bayesian detection rate
BT N Ri – i-th layer bayesian true negatives rate

Because of its operational characteristics the detector Ldi+1 operates on a set
of events with signiﬁcantly changed base rates of anomalies and non-anomalies
– this is the most important part as it reduces the base-rate fallacy inﬂuence
on a real false alarm rate. The base rates probabilities for the next layer are
expressed in the following way:
P (I)i+1 = BDRi .
P (¬I)i+1 = 1 − BDRi .

(5)
(6)

It is now possible to write equations for BDRi+1 and BT N Ri+1 as functions of,
respectively BDRi and BT N Ri :
BDRi ∗ DRi+1
.
BDRi ∗ DRi+1 + (1 − BDRi ) ∗ F ARi+1
(1 − BDRi ) ∗ (1 − F ARi+1 )
.
=
(1 − BDRi ) ∗ (1 − F ARi+1 ) + BDRi ∗ (1 − DRi+1 )

BDRi+1 =
BT N Ri+1

(7)
(8)

In this method requirements for operational characteristics for Ldi can be
relaxed signiﬁcantly in terms of false alarm rate. However still it is best to
have detection rate as high as possible. Additional advantage is that eﬃciency,

Reducing False Alarm Rate in Anomaly Detection with Layered Filtering

401

in terms of system resources usage, should be improved because avoiding false
alarms is one of the most complicated task for anomaly detector. What is more
quantity of events that reaches further layers is greatly reduced and it makes it
possible to use there more sophisticated algorithms without the risk of signiﬁcant
increase in the overall computational complexity.

5

Results and Example IDS

In this section results for two example layered ﬁlters are shown. In both cases
the initial frequencies of normal and abnormal events are taken from previous
section. These frequencies seen by next layers are calculated using (5) and (6).
BDR and BT N R values are calculated using (7) and (8).
Table 1. Results for the ﬁrst layered ﬁlter
Ld1

Ld2

Ld3

P (I)i 0.00002 0.66667 0.99994
P (¬I)i 0.99998 0.33333 0.00005
1.0
0.98
0.98
DRi
F ARi 0.00001 0.0001 0.00001
BDRi 0.66667 0.99994 0.99999
1
0.96153 0.00254
BT N Ri

BDR
BTNR
1

Rate Value

0.8

0.6

0.4

0.2

0
1

2
Layer Number

Fig. 2. BT N R and BDR changes for each layer of the ﬁrst ﬁlter

3

402

R. Pokrywka
Table 2. Results for the second layered ﬁlter
Ld1

Ld2

Ld3

P (I)i 0.00002 0.000391 0.27135
P (¬I)i 0.99998 0.99960 0.72864
0.98
0.95
0.98
DRi
0.05
0.001
0.0001
F ARi
BDRi 0.000391 0.271353 0.999726
BT N Ri 0.999999 0.999980 0.99260

BDR
BTNR
1

Rate Value

0.8

0.6

0.4

0.2

0
1

2
Layer Number

3

Fig. 3. BT N R and BDR changes for each layer of the second ﬁlter

First ﬁlter consists of three layers. Characteristics of each layer detector were
based on assumptions from [2] and are rather unrealistic. Table 1 shows the
calculated probabilities of normal and abnormal events, operational characteristics, BDR and BT N R values for each layer. It can be noticed that BDR for the
ﬁrst ﬁlter increases signiﬁcantly for the second layer and also BT N R value falls
dramatically for the third layer. In order the anomaly detector to be eﬀective
these both values must be maximised. As this is natural that increase of one of
these values causes decrease of the second one the right balance must be found
of layers quantity and detector characteristics. Figure 2 shows the plot of how
the BDR and BT N R values changes for each layer.

Reducing False Alarm Rate in Anomaly Detection with Layered Filtering

403

For the Second ﬁlter there have been a more realistic assumptions made, for
the false alarm rates and detection rates of each layer, based on evaluations from
[3]. This ﬁlter also consists of three layers. In this case the increase of BDR is
a bit slower and also BT N R stays on acceptable levels for all layers. Table 2
shows the calculated values. Figure 3 presents the relation of the layer number
and BDR (BT N R) values.
A form of real implementation of layered ﬁlter can be found in [1]. The system
presented there is not directly referenced as layered ﬁlter but it consists of one
layer based on Variable Order Markov Chain and the second one based on neural
networks and multiagent systems. False alarm rate achieved there is actually 0
but the tests have been performed on a limited number of data sets and there
have been a help from additional mechanism for suppressing false alarms called
”anergic agents”.

6

Conclusions and Further Work

This article shows that layered ﬁltering approach for anomaly detection has
a potential in reducing false alarm rate. Furthermore it can help in reducing
computational complexity because of relaxed requirements especially for the
ﬁrst layer. However each layer detector must be carefully chosen in terms of
performance and eﬀectiveness. Also the balance between BDR and BT N R must
be monitored as for certain number of layers BT N R starts to fall very quickly.
At the end it would be a mistake to use a detector based on the same methods
in more then one layer as probably no additional classiﬁcation decisions would
be made.
The method presented here focuses on reducing false alarm rate but similar
approach can be taken in reducing false negative rate by taking the second output
from previous layer and connecting to it some sort of specialised detector which
can verify if any anomaly has skipped detection and eventually redirect it to the
next layer. It is also possible to build a two dimensional network of detectors for
more sophisticated system for reducing both values.
Additional important remark can be done about constructing network security system based on signatures and anomaly detectors. Placing signature based
detector on the ﬁrst line of defence changes the base rates in the wrong way
and makes anomaly detector useless. First line in detector stack must be held
by system based on anomaly detection with proper characteristics minimising
false negative rate. Second line may consists of signature based system or another anomaly detector. The work presented here may be an important input to
the process of building network security from more then one intrusion detection
system.
It is very interesting how operational characteristics change with number of
layers. Further work includes implementation of IDS which is based on layered
ﬁltering and performing tests on real life environments. Also further research is
needed on other methods of increasing intrusion detection systems eﬀectiveness
in terms of false negative and false positive rates.

404

R. Pokrywka

References
1. Cetnarowicz, K., Rojek, G., Pokrywka, R.: Intelligent Agents as Cells of Immunological Memory. In: Alexandrov, V.N., van Albada, G.D., Sloot, P.M.A., Dongarra,
J. (eds.) ICCS 2006. LNCS, vol. 3993, pp. 855–862. Springer, Heidelberg (2006)
2. Axelsson, S.: The Base-Rate Fallacy and the Diﬃculty of Intrusion Detection. ACM
Trans. Inf. Syst. Secur. 3, 186–205 (2000)
3. Warrender, C., Forrest, S., Perlmutter, B.: Detecting Intrusions Using System Calls:
Alternative Data Models. In: IEEE Symposium on Security and Privacy, pp. 133–
145 (1999)
4. Klautau, A., Jevtic, N., Orlitsky, A.: Combined Binary Classiﬁers with Applications
to Speech Recognition. In: International Conference on Spoken Language Processing
2002, pp. 2469–2472 (2002)

