Analysis and Comparison of Reordering for Two
Factorization Methods (LU and WZ) for Sparse
Matrices
Beata Bylina and Jaroslaw Bylina
Department of Computer Science
Institute of Mathematics
Marie Curie-Sklodowska University
Pl. M. Curie-Sklodowskiej 1, 20-031 Lublin, Poland
beatas@hektor.umcs.lublin.pl,
jmbylina@hektor.umcs.lublin.pl

Abstract. The authors of the article make analysis and comparison of
reordering for two factorizations of the sparse matrices – the traditional
factorization into the matrices L and U as well as the factorization into
matrices W and Z. The article compares these two factorizations regarding: the produced quantity of non-zero elements alias their susceptibility
to a ﬁll-in; the algorithms reorganizing matrix (for LU it will be the
algorithm AMD but for WZ it will be a modiﬁcation of the Markowitz
algorithm); as well as the time of the algorithms. The paper also describes the results of a numerical experiment carried for diﬀerent sparse
matrices from Davis Collection.

1

Introduction

It is a very important issue for the numerical linear algebra to solve diﬀerent
linear systems of equations both when the matrix of coeﬃcients is a dense one
(that is including few non-zero elements) or when the matrix is sparse. In this
paper we deal with a question of solving linear systems with a sparse matrix of
coeﬃcients by a factorization of the matrix.
Solving sparse systems demands applying direct or iterative methods. Both
kinds of methods have their own merits and ﬂaws. However, in this paper we
only handle the direct methods based on Gaussian elimination.
As far as the direct methods are concerned, they demand applying the coeﬃcient matrix factorization into factors of two matrices, e.g. into LU, WZ or QR
as well as into three factors, e.g. into LDLT .
We will assume that A is a square (n×n), nonsingular and sparse matrix of not
any particular structure. Usually during a factorization of a sparse matrix, matrices which come into existence have far more non-zero elements comparing to the
primary matrix. During the matrix A factorization into a product, one has to do
with this ﬁll-in problem – consisting in generating additional non-zero elements
(except the ones which were non-zero in the matrix A). The ﬁll-in causes a substantial increase in memory requirements and (what comes with that) a worsening
M. Bubak et al. (Eds.): ICCS 2008, Part I, LNCS 5101, pp. 983–992, 2008.
c Springer-Verlag Berlin Heidelberg 2008

984

B. Bylina and J. Bylina

of a solver performance. Some problems connected to the ﬁll-in are: a reduction of
the very ﬁll-in (by some reordering or approximation) and forecasts of positions
of non-zeros (for more eﬃcient storing of the matrices’ elements).
The ﬁll-in is the reason for applying algorithms and data structures to reduce it
and act in due time. A sparse factorization usually consists of two parts. The ﬁrst
part is a reorganization of the matrix and its analysis where a symbolic factorization
is done, pointing in anticipation of the places where non-zero elements appear. The
second part is a usual numerical sparse matrix factorization into factors.
We can ﬁnd some examples of this approach – as MUMPS [2] and SuperLU
[13]. In [3] we can ﬁnd analysis and comparison of two solvers mentioned above.
In this paper we focus on the ﬁrst part of the algorithm – that is the reordering.
Reducing of non-zero elements quantity demands applying diﬀerent permutations of rows and columns (known as reordering). The number of all possible
permutations is n! (for an n × n matrix) and ﬁnding, which of them is the best
one, belongs to the class of NP-complete problems.
For structured matrices (like symmetric ones) we can use the Minimum Degree
Algorithm [16] or the Nested Dissection [15].
Of course, we do not always know the structure of the matrix so there are
heuristic algorithms which reorganize the matrix. Some of them include the
Markowitz scheme [14] and the Markowitz scheme with threshold pivoting (for
stability) [10]. In papers [4] and [5] some other modiﬁcations of the Markowitz
scheme are considered.
The article considers reordering for the LU and WZ factorizations [9,10,16,18]
for a sparse square (n × n) matrix of not any particular structure.
The article describes and examines a matrix transformation leading to a reduction of non-zero elements in the output matrices L, U by applying the AMD
(Approximate Minimum Degree) algorithm [1] as well as in the output matrices
W, Z by applying the modiﬁed Markowitz algorithm (for the WZ factorization)
given by the authors. The aim of the paper is to compare the algorithms in
their eﬀectiveness of the ﬁll-in reduction. The performance time of the modiﬁed
Markowitz algorithm is also considered.
The reasons for choosing AMD is its popularity, accessibility and wide
application.
The rest of the paper is organized as follows. Section 2 presents the WZ
factorization. Section 3 presents the modiﬁcations of the Markowitz scheme for
the WZ factorization which ensures the growth of the matrices W and Z sparsity
and also a factorization stability. Section 4 describes an environment used to
numerical experiments conducted for plenty of matrices from Davis Collection
and we also present the results of the examination. We will make an analysis,
how many non-zero elements we will ﬁnd in the matrices L + U and W + Z, and
also how the AMD algorithm and the modiﬁed Markowitz algorithm inﬂuence
the number of non-zero elements as well as the time of algorithms performance.
In this article we mark the well-known numerical algorithm of the LU factorization simply by LU. The numerical algorithm LU with reordering [1] we mark
by AMD – in the same way as it is marked in the literature.

Analysis and Comparison of Reordering for Two Factorization Methods

2

985

WZ Factorization

The WZ factorization was proposed by Evans and Hatzopoulos [12] as the factorization compatible to SIMD computers. SIMD according to Flynn classiﬁcation means a Single Instruction stream and a Multiple Data stream, so the
SIMD architecture is characterized by multiplexing of processing units. The papers [6,7,11,17] develop and examine the modiﬁcations of the WZ factorization
method and consider its parallel implementations.
Let A be a nonsingular matrix. The WZ factorization causes a division of the
matrix A into W and Z factors (so that A = WZ) assuming forms which can
be described like follows: (for an even n):
⎤
⎡
1
0
⎢ w21 1
0 w2n ⎥
⎥
⎢
⎢ ··· ··· ···
··· ··· ··· ⎥
⎥
⎢
⎢ ··· ··· ··· ···
··· ··· ··· ··· ⎥
⎥
⎢
⎢ ··· ··· ··· ··· 1 0 ··· ··· ··· ··· ⎥
⎥
(1)
W=⎢
⎢ ··· ··· ··· ··· 0 1 ··· ··· ··· ··· ⎥,
⎥
⎢
⎢ ··· ··· ··· ···
··· ··· ··· ··· ⎥
⎥
⎢
⎢ ··· ··· ···
··· ··· ··· ⎥
⎥
⎢
⎣ wn−1,1 0
1 wn−1,n ⎦
0
1
⎡
⎤
z11 · · · · · · · · · · · · · · · · · · · · · · · · z1,n
⎢
⎥
z22 · · · · · · · · · · · · · · · · · · z2,n
⎢
⎥
⎢
⎥
··· ··· ··· ··· ··· ···
⎢
⎥
⎢
⎥
··· ··· ··· ···
⎢
⎥
⎢
⎥
zpp zpq
⎥,
Z=⎢
(2)
⎢
⎥
zqp zqq
⎢
⎥
⎢
⎥
··· ··· ··· ···
⎢
⎥
⎢
⎥
··· ··· ··· ··· ··· ···
⎢
⎥
⎣
⎦
zn−1,2 · · · · · · · · · · · · · · · · · · zn−1,n
zn1 · · · · · · · · · · · · · · · · · · · · · · · · zn,n
where
m = (n − 1)/2 ,

p = (n + 1)/2 ,

An example for an odd n (n = 5):
⎡
⎤
1 0 0 0 0
⎢ w21 1 0 0 w25 ⎥
⎢
⎥
⎥
W=⎢
⎢ w31 w32 1 w34 w35 ⎥ ,
⎣ w41 0 0 1 w45 ⎦
0 0 0 0 1

⎡

z11
⎢ 0
⎢
Z=⎢
⎢ 0
⎣ 0
z51

q = (n + 1)/2 .

(3)

⎤
z15
0 ⎥
⎥
0 ⎥
⎥.
0 ⎦
z55

(4)

z12
z22
0
z42
z52

z13
z23
z33
z43
z53

z14
z24
0
z44
z54

See also Fig. 1 and Fig. 2.
The numerical algorithm of the WZ factorization in this article is marked
simply by WZ.

986

B. Bylina and J. Bylina

Fig. 1. The form of the output matrices in the WZ factorization (left: W; right: Z)

Fig. 2. The kth step of the WZ factorization (actually, of the transformation of the
matrix A into Z); here k2 = n − k + 1

3

Modiﬁcation of Markowitz Scheme for WZ
Factorization

The original Markowitz scheme was ﬁrst presented in [14]. It consists in a special
way of the pivoting – not regarding to the value of pivot element but to the
quantity of non-zero elements in rows and columns left to process. The row
having the fewest non-zeros is chosen to be swapped with the current row and
similarly columns are swapped. Thus, the number of newly generated non-zeros

Analysis and Comparison of Reordering for Two Factorization Methods

987

(that is the amount of the ﬁll-in) can be reduced signiﬁcantly. Unfortunately,
such an algorithm can lead to a zero pivot and hence make the factorization fail.
There are modiﬁcations of the Markowitz scheme which ensure success of the
factorization (as in [4,5,10]).
Here we show a modiﬁed Markowitz scheme version for the WZ factorization.
Let A(k) be the matrix obtained from the kth step of the WZ factorization with
(k)
the size (n − 2k + 2) × (n − 2k + 2) (as in Fig. 2), let ri be the number of
(k)
non-zero values in the ith row of the matrix A . We choose
i1 = arg

min

(k)

i∈{k,...,k2 }

ri

(5)

and
i2 = arg

(k)

min

i∈{k,...,k2 }\{i1 }

ri .

(6)

Then we swap the kth row with the i1 st row and the k2 nd row with the i2 nd
row. (We consider only rows, because in the WZ factorization there would be
much more comparisons if we considered also columns because of two pivot rows
[instead of only one in LU] and two pivot columns [instead of only one in LU]).
Of course, such swapping can lead to the situation where the determinant
(k) (k)

(k)

(k)

d = akk ak2 k2 − ak2 k akk2

(7)

(which is the pivot by which we divide in the WZ factorization) will be zero –
then the continuation of the factorization will not be possible. That is why we
must additionally choose i1 and i2 in the way the determinant d will not equal
zero (what is not shown in the above paragraph).
It means that in the modiﬁed Markowitz scheme (as in the original one) during
each turn of completely external loop there is a need to make many comparisons
to choose two rows including the smallest number of non-zero elements.
The algorithm, which consists of the WZ factorization with our modiﬁcation
of the Markowitz algorithm, we mark as MWZ.

4

Numerical Experiment

Here we try to compare the performance of some algorithms and study the
reordering inﬂuence on the number of non-zero elements.
The algorithms’ implementation was done using C language. Data structures
to store the matrices A, W, Z, L, U were two-dimensional arrays located in
RAM. The numerical experiment was done using a Pentium IV 2.80 GHz computer with 1 GB RAM. The algorithms were tested in a GNU/Linux environment and the compilation was done using the compiler gcc with an optimization
option -O3. Tests were done for matrices from Davis Collection [8].
The tests were done for a set of 40 sparse matrices from diﬀerent applications. We have not managed to do the WZ factorization for 11 matrices – they
were singular. For 14 matrices we needed the WZ factorization with the modiﬁed

988

B. Bylina and J. Bylina
Table 1. Test matrices chosen from Davis Collection
#
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

matrix name
lfat5 e
bcsstko1
nos4
olm100
rdb2001
orsirr 1
comsol
rdb2048
ex29
rdb3200
rdb5000
uym5940
raefsky5
fp
pd

matrix size
14
48
100
100
2001
1030
1500
2048
2870
3200
5000
5940
6316
7548
8081

number of non-zeros
30
224
347
396
1120
6858
97645
12032
23754
18880
2960
85842
167178
884222
13036

is it symmetric?
no
yes
yes
no
no
no
no
no
no
no
no
no
no
no
no

Table 2. The comparison of non-zero elements quantity for the algorithms LU, WZ,
MWZ, AMD
#
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

LU
44
272
447
639
7674
145528
1176657
258298
217840
505914
990394
2991163
212829
39967153
23526

WZ
44
272
447
639
7368
207125
1101656
254516
131951
274908
980888
2673569
226487
53861147
23818

MWZ
44
272
447
545
4730
86392
934350
114862
120198
216135
409015
1045803
227613
20092097
23088

AMD
52
930
1164
494
3730
50374
213582
82234
127970
150256
82234
656730
226632
2875348
20599

Markowitz scheme (as a kind of pivoting) what enabled the numerical WZ factorization (with no pivoting such factorizations were impossible). Table 1 includes
the set of the matrices where the WZ and MWZ algorithms were successfully
applied.
Table 2 includes information how many non-zero elements (nz) were created
while doing the algorithms WZ, LU, AMD and MWZ. By using data from Davis
Collection [8] we placed the number of elements for the matrices created by the
algorithm AMD; the results for LU, WZ and MWZ are from the authors’ tests.

Analysis and Comparison of Reordering for Two Factorization Methods

989

Table 3. The comparison of the performance times for the algorithms LU, WZ, MWZ
(times given in seconds)
#
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

LU
0.01
0.01
0.01
0.01
0.01
2.58
7.73
19.14
51.96
71.19
246.53
411.44
506.38
901.20
1135.50

WZ
0.02
0.03
0.05
0.06
0.10
1.44
4.30
10.41
28.95
37.53
143.66
237.18
286.07
503.96
591.44

MWZ
0.04
0.07
0.09
0.13
0.20
1.63
7.07
10.59
29.67
38.19
146.96
248.03
280.85
854.40
599.64

Table 3 presents time during which the algorithms WZ, LU and MWZ were
being done.
The quantities of non-zero elements and the performance times for chosen four
matrices are also presented in Fig. 3 and Fig. 4. (They are scaled for every matrix
to show the relative changes of the number of non-zeros and the performance
time.)
By comparing the algorithms LU and WZ we can notice that the number of
non-zero elements generated by these two factorizations is approximately similar.
It is possible to ﬁnd matrices for which the WZ factorization generates fewer nonzero elements than the LU factorization, for example the matrix ex29. But we
can ﬁnd the matrices for which the LU factorization generates fewer non-zero
elements, e.g. the matrix fp. For the tested matrices the algorithm WZ generates
on the average 2% fewer non-zero elements than the algorithm LU.
Applying the Markowitz scheme before the further WZ factorization caused a
considerable decline of created non-zero elements number. Applying the
Markowitz algorithm for the WZ factorization causes an increase of non-zero
elements number for the only one matrix among all the tested matrices. For the
rest ones, MWZ causes a decrease of non-zero elements number of average 25%
comparing to the WZ algorithm.
Applying the AMD algorithm for the tested matrices considerably reduced the
quantity of non-zero elements of average 36%. We managed to ﬁnd such matrices
for which the WZ factorization as well as the MWZ factorization produce fewer
non-zero elements than the AMD algorithm, e.g. the matrix ex29.

990

B. Bylina and J. Bylina

Fig. 3. Relative numbers of non-zeros in the four algorithms for four sample matrices

Fig. 4. Relative performance times of the three algorithms for four sample matrices

In the Markowitz scheme comparing to the algorithm which does not use any
permutation, time for the tested matrices grows 17% on the average.. It is worth
noticing that the time for LU is 50% longer than for WZ.

5

Conclusions

In this paper we have presented a detailed analysis and comparison of two reordering schemes. The ﬁrst, called AMD, is used for the LU factorization; the
second – MWZ – proposed by the authors, is used for the WZ factorization. The
algorithms’ functioning was presented with some sparse matrices taken from
concrete engineering applications.
Our analysis is based on experiments with the use of a usual PC. The analysis addresses two aspects of the eﬃciency of the factorization: the role of the
reordering step and the time needed for the factorization. We can summarize

Analysis and Comparison of Reordering for Two Factorization Methods

991

our observations as follows: there exist matrices for which MWZ (proposed by
the authors) is worth using instead of AMD.
Moreover, it appeared that the time of the WZ algorithm was on the average
50% shorter comparing to the LU algorithm. It results from the fact that loops
in the WZ factorization are two times shorter what enables better use of modern
processors architecture: threading (possibility to use parallel calculations) and
the organization of the processor access to the memory (particularly an optimal
use of the multilevel cache memory).
Our future works would research problems of the inﬂuence of reordering on
the results’ numerical accuracy. The other future issue is to name properties of
the matrices for which using MWZ is better then using AMD.
Acknowledgments. This work was partially supported within the project
Metody i modele dla kontroli zatloczenia i oceny efektywno´sci mechanizm´
ow
jako´sci uslug w Internecie nastepnej generacji (N517 025 31/2997).
This work was also partially supported by Marie Curie-Sklodowska University
in Lublin within the project R´
ownolegle algorytmy generacji i rozwiazywania
mechanizm´
ow kontroli przecia˙zenia w protokole TCP modelowanych przy u˙zyciu
la´
ncuch´
ow Markowa.

References
1. Amestoy, P., Davis, T.A., Duﬀ, I.S.: Algorithm 837: AMD, An approximate minimum degree ordering algorithm. ACM Trans. Math. Soft. 23, 1129–1139 (1997)
2. Amestoy, P.R., Duﬀ, I.S., L’Excellent, J.-I., Koster, J.: A full asynchronous
multifrontal solver using distributed dynamic scheduling. SIAM J. Matr. Anal.
Apl. 23(1), 15–41 (2001)
3. Amestoy, P.R., Duﬀ, I.S., L’Excellent, J.-I., Li, X.S.: Analysis and Comparison
of Two General Sparse Solvers for Distributed Memory Computers. ACM Trans.
Math. Soft. 27(4), 388–421 (2001)
4. Amestoy, P., Li, X.S., Ng, E.G.: Diagonal Markowitz Scheme with Local Symmetrization. Report LBNL-53854 (2003); SIAM. J. Matr. Anal. Appl. 29, 228
(2007)
5. Amestoy, P., Pralet, S.: Unsymmetric Ordering Using a Constrained Markowitz
Scheme. SIAM J. Matr. Anal. Appl.; Report LBNL-56861 (submitted, 2005)
6. Bylina, B., Bylina, J.: The Vectorized and Parallelized Solving of Markovian Models
for Optical Networks. In: Bubak, M., van Albada, G.D., Sloot, P.M.A., Dongarra,
J. (eds.) ICCS 2004. LNCS, vol. 3037, pp. 578–581. Springer, Heidelberg (2004)
7. Chandra Sekhara Rao, S.: Existence and uniqueness of WZ factorization. Parall.
Comp. 23, 1129–1139 (1997)
8. Davis, T.: University of Florida Sparse Matrix Collection. NA Digest 92(42) (1994),
NA Digest 96(28) (1996), and NA Digest 97(23) (1997),
http://www.cise.ufl.edu/research/sparse/matrices
9. Duﬀ, I.S.: Combining direct and iterative methods for the solution of large systems
in diﬀerent application areas. Technical Report RAL-TR-2004-033 (2004)
10. Duﬀ, I.S., Erisman, A.M., Reid, J.: Direct Methods for Sparse Matrices. Oxford
University Press, New York (1986)

992

B. Bylina and J. Bylina

11. Evans, D.J., Barulli, M.: BSP linear solver for dense matrices. Parall. Comp. 24,
777–795 (1998)
12. Evans, D.J., Hatzopoulos, M.: The parallel solution of linear system. Int. J. Comp.
Math. 7, 227–238 (1979)
13. Li, X.S., Demmel, J.W.: A scalable sparse direct solver using static pivoting. In:
Proceedings of the Ninth SIAM Conference on Parallel Processing for Scientiﬁc
Computing (1999)
14. Markowitz, H.M.: The elimination form of the inverse and its application to linear
programming. Management Science 3, 255–269 (1957)
15. Reid, J., Duﬀ, I.S., Erisman, A.M.: On George’s nested dissection method. SIAM
J. Numer. Anal. 13, 686 (1976)
16. Tinney, W.F., Walker, J.W.: Direct solution of sparse network equations by optimally ordered triangular factorization. Proc. IEEE 55, 1801–1809 (1967)
17. Yalamov, P., Evans, D.J.: The WZ matrix factorization method. Parall. Comp. 21,
1111–1120 (1995)
18. Zlatev, Z.: On some pivotal strategies in Gaussian elimination by sparse technique.
SIAM J. Numer. Anal. 17, 18–30 (1980)

