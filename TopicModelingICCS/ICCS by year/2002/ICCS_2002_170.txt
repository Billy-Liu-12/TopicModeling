Distributed Computing Using Internet
Surjeet Singh

Hardeep Singh

K.S.Kahlon

surjit_gndu@yahoo.com
hardeep_gndu@rediffmail.com
k_kahlon@yahoo.com
Departement Of Computer Science & Engineering, Guru Nanak Dev University,
Amritsar, Panjab, India
PHONE: 0183-258531, 0183-258802-09 EXTN 3228
FAX:0183-258820

Abstract
Parallel and distributed computing on a cluster of workstations is being increasingly applied to a variety
of large size computational problems. A common technique for improving performance of many
distributed and parallel applications is to overlap communication with computation. Existing techniques
for remote method invocation cause the execution of the requesting object to be suspended until the
method has completed. This delay is incurred regardless of when or if the invoking object requires the
return value. Object replication is a well-known technique to improve the performance of parallel
object-based applications. In this paper We describe a programming model that allows the programmer
to define groups of objects that can be replicated and updated as a whole, using totally-ordered
broadcast to send update methods to all machines containing a copy. Experiment results of system
performance with a set of different parallel applications has been presented.

1.0 Introduction

Java [3,9] is an interpreted object-oriented language that supports distribution and distributed
communication. Remote objects and Remote Method Invocation (RMI) [9] allow Java objects to perform
distributed computation and communicate with each other. Remote objects are maintained through remote
references, which take the form of a stub class. This stub class is responsible for protocol management and
the actual communication required within the client/server model. Java provides additional distributed
object services independent of RMI, such as the Messaging service, which provides asynchronous
communication capabilities but is not compatible with Java RMI. The Java Remote Method Invocation
system is a three-tier communications protocol. Remote objects are defined through a remote interface,
which can be exported to remote clients to abstractly define communications. A stub which defines how the
communications protocol is to be used, in Java's case the RMI wire protocol, is generated statically from
the implementation of the remote interface. A preprocessor, RMIC, is used to perform the stub generation
after the completion of the interface and the server implementation. Objects are passed between the client
and server by marshaling the object into a serialised byte stream. This serialisation process can be
performed dynamically using Java's reflective capabilities, or it can be tuned by the implementor for
optimal results. Communication between the client and remote server appears to be completely abstract.
The client obtains a reference to the remote object through a remote registry lookup. It can then perform
method invocations on the remote object as it would on a local object, since the stub or proxy that is
returned appears to be exactly the same as the server implementation in its method signatures. Java
implementations to date have suffered from performance problems due to their interpreted nature and
unoptimised serialisation mechanism [12,4]. Potential solutions, such as native compilation and Just-InTime (JIT) compilation have been discussed in [6]. These methods do provide performance improvements
but do not tackle the fundamental performance problems and latency issues of Java RMI [7, 13].

2.0 Related work

Object replication is a well-known technique to improve the performance of parallel object-based
applications [1]. Although several different forms of object replication have been proposed for Java [2, 5, 8,
11, 14], no scheme exists yet that transparently and efficiently supports replicated objects in Java and that
integrates cleanly with Java’s primary point-to-point communication mechanism, Remote Method
Invocation (RMI) [10]. Some systems temporarily cache objects rather than trying to keep multiple copies
of an object consistent [2, 5, 8, 14]. Some proposals have a programming model that is quite different from
the object invocation model of RMI [11]. Also, performance results are often lacking or disappointing. The
probable reason for these problems is the inherent difficulty in implementing object replication. In
particular, it is hard to find a good programming abstraction that is easy to use, integrates well with RMI,
and can be implemented efficiently. In this paper we introduce a new approach for object replication in

Java that is designed to resemble a Remote Method Invocation. Our model does not allow arbitrarily
complex object graphs to be replicated, but deliberately imposes restrictions to obtain a clear programming
model and high performance.

3.0 The Model

The primary goal of our object replication mechanism is to provide a programming model as close as
possible to RMI. With RMI, parallel applications strictly follow Java’s object-oriented model in which
client objects invoke methods on server objects in a location-transparent way. Each remote object is
physically located at one machine. Although the RMI model hides object remoteness from the programmer,
the actual object location has a strong impact on application performance. From the client’s point of view,
object replication is conceptually equivalent to the RMI model. The difference is in the implementation:
objects may be physically replicated on multiple processors. The advantage of replication is that read-only
methods (i.e., methods that do not modify the object’s data) can be performed locally, without any
communication. The disadvantage is that write methods become more complex and have to keep the state
of object replicas consistent. For objects that have a high read-write ratio, replication will reduce
communication overhead. Data replication can be implemented in different ways, influencing both
performance and the programming model. Many systems that use replication apply an invalidation scheme
where the replicas are removed (invalidated) after a write method. Orca language [1], however, show that
for object-based languages an update protocol often is more efficient, especially if it is implemented with
function shipping. With this strategy, a write method on a replicated object is sent to all machines that
contain a copy. Then the method is applied to all copies. For object-based systems, this strategy is often
more efficient than invalidation schemes. Especially if the object is large (e.g., a big hash table),
invalidating it is unattractive, as each machine must then retrieve a new copy of the entire object on the
next access. With function shipping, only the method and its parameters are sent, usually resulting in much
smaller data transfers than with invalidation schemes or data shipping schemes, which send or broadcast
entire objects. To update all replicas in a consistent way, methods are sent using totally-ordered group
communication [1], so all updates are executed in the same order on all machines. Remote method
invocation (RMI) can be seen as a simple form of function shipping to a single, remote object. This is why
we call our approach replicated method invocation. As with RMI, the arguments to methods of a replicated
object have call-by-value rather than call-by-reference semantics. The same holds for return values.
Because methods are executed once per replica, return values as well as possibly raised exceptions will be
discarded on all nodes except the one on which the method was invoked. A difficult problem with object
replication is that a method invoked on a given object can also access many other objects, by following the
references in the first object. A write method can thus access and update an arbitrarily complex graph of
objects. Synchronizing multiple concur-rent write methods on different (but possibly overlapping) object
graphs is difficult and expensive. Also, if the function-shipping update strategy is applied naively to graphs
of objects, broadcast communication would be needed for each object in the graph, resulting in a high
communication overhead. A simple solution for Java would be to replicate only objects without references
to other objects, but this would be far too restrictive for many applications. For example, it would then be
impossible to replicate data structures like linked lists, since these are built out of objects (unlike in Orca,
where the entire list would typically be a single object). Our solution to this problem is to take an
intermediate approach and replicate only closed groups of objects, which we call clouds. A cloud is a
programmer-defined collection of objects with a single entry point, that will be replicated and updated as a
whole. Hence, a write method on a cloud is implemented using a single broadcast message, independent of
the number of objects in the cloud. The entry point of a cloud is called its root, and it is the only object that
can be accessed by objects outside the cloud. In addition, a cloud can have other objects reachable from the
root, called the node objects; these node objects, however, cannot be referenced directly from outside the
cloud. As a consequence, only methods of the root object can be directly invoked in order to manipulate
(read or modify) the cloud. All other method invocations inside the cloud can only be the indirect result of
an invocation on the root object. This model is general enough to express all common data structures like
lists, graphs, hash tables, and so on.

4.0 Implementation

The advantage of object replication compared to RMI is that methods which only read objects can be
performed locally, without any communication. Only write operations cause communication across the set
of replicas. The compiler checks if there are any operations in the method that assign values to class
variables, or if there are calls to other methods that can be attributed as write methods. If so, the method is

classified as a write method, otherwise it is considered to be a read method. Also, if a method may execute
a notify or notifyAll operation, it is a write operation. The implemented analysis is conservative by always
classifying methods that contain assignments as write methods, even if the assignments may only be
executed conditionally. Furthermore, methods of classes other than for root or node objects are assumed to
be free of side effects and can thus safely be ignored in the read/write analysis. Due to Java’s support for
polymorphism and dynamic binding, the method to be invoked depends, in general, on the runtime type of
the object. Since a read-only method of one class may be overridden by a write method in a subclass (or
vice versa), it may not be known until runtime whether a given invocation reads or writes an object. Still, it
is important to execute each method in the correct mode (read or write). If a read-only method would be
executed as if it were a write method, it would be broadcast, resulting in much overhead. Even worse, if a
write method would accidentally be executed as if it were a read-only method, erroneous program behavior
would occur. Due to this problem, the final check to distinguish between read and write operations is
performed at run time. Wrappers are generated for all methods of root and node objects in which the
current execution mode (read or write) is checked before actually invoking the object’s method. If the
current invocation is executed in read mode, and the actual method requires write mode, the current
invocation is aborted and restarted in write mode. This may, for example, happen during the execution of a
method of the root object when another method of a node object is to be called. This restart can be
performed safely, because so far only read operations have been executed, and the object state has not
changed yet.
4.1 Cloud management
Whenever a new root object is created, a new cloud is implicitly created along with it. On the invoking
process, the root object is created, and a unique identifier is assigned to it. In turn, the new cloud is
broadcast to all nodes of the parallel application, using Panda’s totally ordered broadcast mechanism. This
ensures that clouds are always created on all nodes before any write operation attempts to modify them.
Although the replicated clouds are immediately established on all nodes, the application itself views them
as being replicated on demand. Only the process on which the cloud was created gets a reference to the new
cloud. The application code then has to distribute the reference to other nodes using RMI. A possible
optimization of this scheme would be to replicate a cloud only on those nodes that actually have a reference
to it. This could avoid some overhead of processing write updates on objects that are not used on some of
the nodes. As a drawback, elaborate group management would have to be implemented.
4.2 Wait and notify
The execution model for write methods also has to correctly handle synchronization for wait,
notify,andnotifyAll primitives. Whenever a broadcast message for invoking a write method is received, the
method will not immediately be executed. Instead, each object cloud has a queue for incoming broadcast
messages, and a thread waiting for messages to appear in the queue. Whenever a message appears, the
thread takes it out of the queue and invokes the respective method. All write methods are therefore
executed by a single thread, one at a time, in the order they were received in. This model ensures that all
nodes execute all write methods in the same order. This single-threaded scheme cannot be used for
executing write methods that may block while calling wait. In this case, no other write methods will be able
to run, including the one intended to wake up the blocked method. A simple-minded solution would be to
create one thread for each incoming broadcast message. A new thread is created whenever the original
thread blocks. Although this happens in the same order on each node it still has to be guaranteed that
blocked threads also wake up in exactly the same order on all nodes, otherwise the total execution order for
write methods would still be violated. Unfortunately, Java’s wait/notify mechanism does not guarantee any
order in which waiting threads will wake up. Here, the execution of notifyAll on a root or node object
causes waiting threads to be put back into the execution queue in exactly the global order in which they
were invoked. The current thread servicing the queue will then detect that the head of the queue contains a
blocked thread, wake this thread up, and terminate itself. The woken up thread will then continue to run and
wake up the next thread when it terminates. The last thread will not terminate, but continue servicing new
calls from the queue. This way, all machines will wake up the threads in the same order and keep the copies
of the object clouds consistent.

5.0 Experiment results

We evaluated the model with three applications the experimentation platform consist of 1GHz Pentium III
nodes each with 128MB memory and connected through a 100MBPS Ethernet network. We implemented
three version of the algorithm for each application using a remote object, optimized remote object and
replicated object. The first application is Traveling Salesperson Problem (TSP) which computes the

Speedup

shortest path for a salesperson to visit all cities in a given set exactly once, starting in one specific city. We
use a branch-and-bound algorithm, which prunes a large part of the search space by ignoring partial routes
that are already longer than the current best solution. The program is parallelized by distributing the search
space over the different nodes. Because the algorithm performs pruning, however, the amount of
computation needed for each sub-space is not known in advance. The program therefore uses a centralized
job queue to balance the load. Each job contains an initial path of a fixed number of cities; a node that
executes the job computes the lengths of all possible continuations, pruning paths that are longer than the
current best solution. The results are shown in figure 1
50
40
30
20
10
0

Remote object

0

10 20 30 40 50 60 70

Optimised
Remote object
Replicated
object

Processors

Figure 1

Speedup

The second application is All-pairs Shortest Paths (ASP) program finds the shortest path between any pair
of nodes in a graph, using a parallel version of Floyd’s algorithm. The program uses a distance matrix that
is divided row-wise among the available processors. At the beginning of iteration k, all processors need the
value of the kth row of the matrix. The processor containing this row must make it available to the other
processors by storing it in a remote object or broadcasting it. The results are shown in figure 2
70
60
50
40
30
20
10
0

Remote
Object
Optimised
Remote
Object
0

10 20 30 40 50 60 70

Replicated
Object

Processors

Figure2
The third application Linear equation solver (LEQ) is an iterative solver for linear systems of the form Ax
= b. Eachiteration refines a candidate solution vector x i into a better solution xi +1. This is repeated until
the difference between xi. +1 and xi becomes smaller than a specified bound. The program is parallelized by
partitioning a matrix containing the equation coefficients over the processors. In each iteration, each
processor produces a part of the vector xi +1, but needs all of vector xi as its input. Therefore, all processors
exchange their partial solution vectors at the end of each iteration. This is similar to a gather-to-all
collective operation as defined in the MPI standard [15]. Besides exchanging their vectors, the processor
must also decide if another iteration is necessary. To do this, each processor calculates the difference
between their fragment of xi +1 and xi . A reduce-to-all collective operation [15] is used to process these
differences and decide if the program should stop. The results are shown in figure 3.

Speedup

70
60
50
40
30
20
10
0

Remote
Object
Optimised
Remote
Object
0 10 20 30 40 50 60 70

Replicated
Object

Processors

Figure 3

6.0 Conclusions

We have shown that our approach provides efficient object replication for Java with a programming model
close to standard RMI. Object clouds allow complex data structures to be replicated without sacrificing
runtime performance. We evaluated our system with application kernels and showed that object replication
model allows implementation of straight-forward, shared-object applications, while yielding performance
close to manually optimized versions based on individual RMI calls. The run-time system establishes and
updates object clouds on all nodes of a parallel application. It also coordinates the execution of method
invocations to enforce replica consistency. We added support for Java’s polymorphism as well as for the
synchronization mechanism based on wait and notify, which may cause replicated method invocations to
block in the middle of their execution. Our goal was to keep the programming model as close as possible to
RMI. To achieve this, objects are declared to become replicated by implementing one of two new special
interfaces.

References

1. H. Bal, R. Bhoedjang, R. Hofman, C. Jacobs, K. Langendoen, T. R¨ uhl, and F. Kaashoek. Performance
Evaluation of the Orca Shared Object System. ACM Transactions on Computer Systems, 16(1):1–
40,1998.
2. D. Hagimont and D. Louvegnies. Javanaise: Distributed Shared Objects for Internet Cooperative
Applications. In Proc. Middleware’98, The Lake District, England, Sept. 1998.
3. D. Flanagan. Java in a Nutshell. O'Reilly & Associates, Inc., 1996. ISBN 1-56592-183-6.
4. S. Hirano, Y. Yasu, and H. Igarashi. Performance Evaluation of Popular Distributed Object Technologies
for Java. In Proc. ACM 1998 Workshop on Java for High-performance network computing, February
1998.
5. V. Krishnaswamy, D. Walther, S. Bhola, E. Bommaiah, G. Riley, B. Topol, and M. Ahamad. Effi-cient
Implementations of Java RMI. In 4th USENIX Conference on Object-Oriented Technologies and
Systems (COOTS’98), Santa Fe, NM, 1998.
6. A. Krall and R. Gra . CACAO - A 64 bit JavaVM Just-in-Time Compiler. Concurrency: Practice and
Experience, November 1997. Available from http://www.complang.tuwien.ac.at/andi/.
7. Christian Nester, Michael Philippsen, and Bernard Haumacher. A More E_cient RMI for Java. In Proc.
of ACM 1999 Java Grande Conference, pages 152{157, June 1999.
8. M. W. Macbeth, K. A. McGuigan, and P. J. Hatcher. Executing Java Threads in Parallel in a
Distributed-Memory Environment. In Proc. CASCON’98, pages 40–54, Missisauga, ON, 1998. Published by IBM Canada and the National Research Council of Canada.
9. Sun Microsystems, Inc. Java Remote Method Invocation Speci_cation. Available from
http://www.sun.com/, October 1998.
10. J. Waldo. Remote procedure calls and Java Remote Method Invocation. IEEE Concurrency, 6(3):5–
7,July–September 1998.
11. B. Topol, M. Ahamad, and J. T. Stasko. Robust State Sharing for Wide Area Distributed Applications.

In 18th International Conference on Distributed Computing Systems (ICDCS’98), pages 554–561,
Amsterdam, The Netherlands, May 1998.
12. Java Grande Forum. Available at http://www.javagrande.org/
13. Matt Welsh. Ninja RMI : A Free Java RMI. Available from http://www.cs.berkeley.edu/~mdw/
proj/ninja/ninjarmi.html, 1999.
14. R. Veldema, R. A. F. Bhoedjang, and H. Bal. Distributed Shared Memory Management for Java. In
Proc. sixth annual conference of the Advanced School for Computing and Imaging (ASCI 2000), pages
256–264, Lommel, Belgium, June 2000.
15. B. Carpenter, V. Getov, G. Judd, T. Skjellum, and G. Fox. MPI for Java: Position Document and Draft
API Specification. Technical Report JGF-TR-03, Java Grande Forum, November 1998.

