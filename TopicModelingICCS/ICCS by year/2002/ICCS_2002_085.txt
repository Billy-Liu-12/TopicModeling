Using PDES to Simulate Individual-Oriented Models in
Ecology: A Case Study
1

Remo Suppi, Pere Munt, and Emilio Luque
Dept. of Computer Science, University Autonoma of Barcelona,
08193, Bellaterra, Spain
Remo.Suppi@uab.es Pere.Munt@campus.uab.es Emilio.Luque@uab.es

Abstract. The present work outlines the results of the Parallel Discrete Event
Simulation (PDES) utilization for solving an individual based model: Fish
Schools. This type of model cannot be solved through analytical methods, thus
simulation techniques are necessary. The greater problem presented by this type
of model is the high computing capacity necessary for solving middle-high size
problems (hundreds to thousands of individuals). PDES is presented as a useful
and low cost tool for individual-oriented models simulation, since it allows a
scalable and efficient solution in accordance with the problem to be simulated.

1. Introduction
One of the main drawbacks to the use in ecology of individual-oriented models is
the necessary computing capacity for their simulation. This type of model chooses the
individual as basic element of the system. The ecosystem is described by dynamic
and static individuals properties. The behaviour of an individual can differ from the
behaviour of other individuals of the same or other species. This type of model cannot
be solved in analytical form and it is therefore necessary to use simulation techniques
in obtaining the ecosystem’s dynamical behaviour. For complex systems (thousands
of individuals), it is necessary to use advanced simulation techniques and paralleldistributed computing systems to give an efficient response to this type of problems.
PDES (parallel and distributed event simulation) is a useful tool (and indispensable in
some instances) for providing response to complex problems within an acceptable
time. There are two main objectives to PDES: to reduce the simulation execution
time, and to increase the potential dimension of the problem to be simulated. This
paper demonstrates the use of PDES in solving a type of individual-oriented model:
Fish Schools. The next section is a summary of the individual-orient model characteristics. Section 3 shows the implementation of the model on a distributed simulator.
Section 4 presents the experimental framework and sections 5 and 6 the conclusions
and references, respectively.

1

This work has been supported by the CICYT under contract TIC98-0433

2. Individual-oriented models
There are considerable references to individual-oriented models (IoM) in the literature [3,7,6]. The model definition is based on recognizing each individual as an
autonomous agent that acts according to a set of biological rules.
One of the most representative applications of IoM is used to describe the movement of given species (schools, flocks, herds, etc) [5,6]. The IoM utilization allows us
to determine the movement of a species group by using the movement of each member. The Fish Schools is an IoM application for the movement of fish species.
[8,6,10]. From the observation, was discovered that fish can describe very complex
figures in their movement, but that these figures are governed by three basic postulates from the point of view of the individual:
• To avoid collisions
• Speed coupling
• To obtain a position in the centre of the group.
These rules express both the individual’s need for survival and its instinct for protection (the need to escape from predators). Each fish in the model is represented as a
point in a three-dimensional space with an associated speed. And each fish changes
position and speed simultaneously after a certain period ∆t. The actions that the
model describes for each fish are:
1- Each fish chooses up to X neighbour fish (X=4 seems sufficient for most
schools), which will be those nearest and with direct vision.
2- Each fish reacts in accordance with the direction and distance of each
neighbour. Three influence radios and three possible reactions are established. The final reaction will be the average of the reactions experimented
on each neighbour.
a.
If the neighbour is found within the smaller radio, the fish will
carry out an “opposed to address” movement -repulsion action- (to
avoid collisions).
b.
If the neighbour is within a second influence radio, the fish will
adopt the same direction as the neighbour.
c.
If the neighbour is within a third radio, the fish will move towards
it.
3- Each fish calculates its new position according to the new direction.
This generates a very simple model, but one that allows very complex behaviour to
be described (an implementation with applets in 2D can be found in [4]). As a counterpart, very high computing power is necessary, since the complexity algorithm is of
2
O(N ), where N is the number of fish (each fish attempts to find the neighbour fish by
inspecting all other fish in the school).
Each fish Fi is defined by its position p i and velocity v i , and chooses its potential
neighbours by watching concentric zones of incremental radio until finding X fish. To
calculate the distance between two fish, the Euclidean distance is used:

Dist ( p a , pb ) = ( p ax − pbx ) 2 + ( p ay − pby ) 2 + ( p az − pbz ) 2

(1)

The potential neighbours are chosen by using the algorithm of front priority. This
algorithm calculates all the angles formed by v i and p i − p j (being the collision
angle between pi and pj); the X neighbours with the smallest angle are chosen. Figure
1 shows the neighbour selection of p1 using the front priority algorithm. p2 is the
neighbour selected, since the angle v1-v21 (v2, (p2-p1)) is less than v1-v31 (v3, (p3-p1)).

Fig. 1. Neighbour selection
Each Fi, once they have selected the X neighbours, must then determine the reaction
(rotation of the vi) to each Fj. βij will be the Fi reaction with respect to Fj expressed in
spherical coordinates. Each fish Fj can be found within one of three possible areas of
influence with respect to Fi (A: near, B: middle, C: far):
− If Dist(Fj, Fi)≤A, Fi has a repulsion reaction with respect to Fj and βij=(1,π, π)
− If A<Dist(Fj, Fi)≤B, Fi adopts a parallel position with respect to Fj and βij= (1,θj,ϕj)
− If B<Dist(Fj, Fi)≤C, Fi is guided toward Fj and βij =(1, θi-θj,ϕi-ϕj)
Finally, reaction β is obtained (mean value for all βij) and vi is rotated according to
β. Object-Oriented methodology and UML techniques [1] were used for the model
implementation and the analysis phase, respectively. [5]

3. PDES simulation
As model of the parallel discrete event simulation (PDES), a set of logical processes (LP) managing a distributed event lists was considered. These processes interact
exclusively by exchanging time-stamped messages. The PDES mechanisms can be
divided in two categories: conservative and optimistic. Conservative approaches use
synchronization to avoid causality errors. In these algorithms, the events are processed when it is certain that the execution order is correct. On the other hand, in optimistic algorithms, each LP processes the events as soon as they are available and this
execution, in some instances, can mean causality errors. Nevertheless, the algorithm
has detection mechanisms to avoid these errors and to recover the causality [11,9].

The fish school simulator was built on the base of a PDES simulation kernel developed at the UAB (written in C++). This kernel is designed to be executed in Unix
stations and PVM. The union of the simulation kernel and the model classes is accomplished through the inheritance of the kernel classes and virtual functions implementation. This simulation kernel uses an STL library for data structure management.
[9,2]. Based on the UAB kernel, two simulator versions were developed: sequential
and distributed. The distributed version will be used to make performance analysis
using different simulation PDES algorithms. The sequential version will allow
speedup and performance analysis to be undertaken with respect to the distributed
version.

3.1 Model distribution
One of the most important problems than a model of these characteristics outlines
is the individual’s distribution within distributed architecture computing elements.
Lorek [8] outlines a distribution of a Fish School simulator for real time visualization.
The distribution is accomplished by assigning a static partition of the fish group to
simulate in each processor, but each processor has the information on the fish assigned in other processors.
Our solution is based on the problem division in a set of logical processes (LP),
which will be executed in the different processors. For each LP, an initial partition of
the problem (number of fish) is assigned and this quantity will change dynamically
during the simulation. The LPs have a physical zone of the problem (cubes in fig. 2)
to simulate (Spatially Explicit Simulation) and the fish movement will imply migrations between the LPs.

Fig. 2. Model distribution
The present model implements two types of messages between LPs: neighbour petition within a given zone and migration. To reduce the information quantity that the
LPs should share, a point-to-point petition was designed (under demand): only the
neighbours of a specific zone are requested. If the LP simulated area is a cube, only
the neighbours that share a cube side will be requested (see fig. 2).

4. Experimental Studies
The experimental framework was developed on a cluster of machines executing
Linux SuSE 6.4 and interconnected by Fast Ethernet. The tools used for the development were: Pvm 3.4.3, Xpvm 1.1.5, Gcc 2.95 and Ddd 3.2 (Date Display Debugger).
Figure 3 a,b,c shows three types of animation frames obtained from the simulator
traces.

Fig. 3.a 3-D Fish Visualization

Fig. 3.b, c. Visualization of trajectory & density of fish
(10 frame animations)

Figure 3.a shows a distribution of 300 fish. The point and colours indicate their position and depth (with respect to the colour scale), respectively, and the arrows indicate their direction and speed. Figure 3.b shows a path graph for 300 fish during a
100-frame simulation, and figure 3.c shows fish density in a given zone (red=high
density, green=low density).
The first step in the development process was the design and development of the
sequential simulator version. This version was analysed with different territory sizes
(up to 800:100:100), number of individuals (100,200,400,800,1600), constant velocity and constant neighbours number (5 and 4 respectively) and constant influence
radios (R1=5, R2=20, R3=30) to verify the model and to validate the simulator. As
reference measure, we chose a sample of the real complexity and frame generation
time (new position and speed for each individual) for colonies of 100 to 1600 fish
(figure 4). Figure 4 shows that the real complexity of the algorithm is always below
2
2
N , but is superior to N (the algorithm IoM requires N in the worst case). This graph
shows that animations in real time in the sequential simulator have a complex treatment, since with groups of 200 individuals, 1 second per frame is needed.

Seconds per frame

25

23,132

20
15
7,573

10
5

0,292

0,974

2,513

0
100

200

400

800

1600

Number of Fish

Fig. 4. Seconds per frame in the sequential simulator
After the sequential version, the following step was the development of distributed
versions. The first objective was to build the simulator under an optimistic algorithm
(Time Warp) and to solve the load balance between the LPs, in order to avoid synchronizations. The results under this simulation method are acceptable, but do not
have a homogeneous behaviour for different fish colonies (as was expected). Under
the Time Warp algorithm (optimistic), the model shows acceptable behaviour for
small quantities of fish (<100 individual) on large territories (800x100x100) where
migration events are few and therefore the need for synchronization is minimal. With
a more realistic evaluation of fish quantities (>100 individual), the simulation model
was unable to advance due to the great quantity of external events produced both by
migration and neighbour request. The main problem with the Time Warp algorithm is
the rollback chains [11]. In an IoM of these characteristics, rollback chains are produced easily in the migration and neighbours petition actions. The problem is due to
the fact that the fish do not have a regular movement and often come and go on the
same point (see figure 3.b). This behaviour generates a very high quantity of migra-

tions on the LPs shared cube face. Such activity means that synchronization between
the two LPs is very difficult.
The second step was the utilization of conservative distributed simulation algorithms to control the synchronization events. Our objective was to avoid the ‘out of
order’ events processing to remove the synchronization events. Each LPj will have to
execute the following steps (in each iteration):
1. To generate the iteration results Tj,i (state + migrations).
2. To wait until all the LPk k≠j sharing information with LPj finish their iteration Tk,i.
3. To process the external events.
4. To generate the iteration Tj,i+1
The worse case is when an LP does not know with which LP shares information.
In this case, a global waiting time will be necessary and therefore the global simulation time progression (GVT) will be conditioned by the speed of the slowest LP. This
situation does not exist when the experiments are accomplished on homogeneous
machines and similar computing charges. Figure 5 shows the time per frame for a
conservative distributed simulation on 1,2,4,6,8 processors. The simulation characteristics are: territory=800:100:100; individual=100,200,400,800,1600; speed=5;
neighbour number=4; influence radio= 5:20:30.
8
7

Seconds/Frame

6
5
4
3
2
1
0
100

1 Processor

200

400
Number of Fish

2 Processors

800

4 Processors

1600

8 Processors

Fig. 5. Conservative fish school simulation
From figures 5 and 6, the following conclusions can be extracted:
− The model scales well: as a rule, an increase in processor number facilitates a reduction in frame time to values below 1 second.
− The frame generation time cannot be reduced without the limit increasing processor number. Figure 6 shows that the tendency line for 1600 fish is asymptotically
to 0,15s (decreasing this time would require acting on the communications model).
For visualizations in real time, approximately 4 fps for 400 fish and 4 processors
are obtained.

− The model to be simulated must be analysed carefully, there are situations in
which adding processors does not bring about benefits. This case is present in the
current model (fig. 4): it is not necessary to use 8 processors to simulate below 800
individuals (the cube generates a high communication granularity for these cases).
− The results obtained are excellent, but results above the linearity require explanation.

Seconds/Frame

25

100
200

20

400
800
1600

15

T endency (1600)

10

5

0
1 Processor

2 Processors

4 Processors

8 Processors

Fig. 6. Improvement & tendency line for the simulation of 1600 individuals
Figure 7 shows speedup with respect to the sequential version and for different fish
colonies. This figure confirms that at least 100 fish per processor are required in order
to obtain acceptable speedups. A comment with respect to this profit is necessary.
Parallel programs use linear speedup as maximum profit, but figure 7 shows that the
profit obtained is superior in given points. This singularity is explained by the model
2
complexity calculation. The IoM Fish Schools has complexity O(N ) [8], since the
data structure that sustains the individuals does not have the implicit location
(neighbours are found searching in N fish positions). The partition generation (section
3.1) adds this information implicitly: each process must accomplish the neighbour’s
searches in the current partition and, eventually, in the shared cube faces. In this way,
2
2
2
the complexity for two processes is O(2*(N/2) ), and 2*(N/2) is less than N . In this
sense, two comments are required:
a) The model distribution generate a considerable additional advantage that
must be taken into account in the PDES speedup calculation.
2
b) The model series was not implemented with complexity O(k*(N/k) ), because the same model proposed by Lorek & Sonnenschein was used [8]. In
the Lorek model, the local territory notion does not exist. Each processor has
global information of the whole territory and seeks neighbours in N fish positions, only obtaining good speedups with low and unrealistic granularity
(speedup=16 with 10 fish per processor).

15
13

Speedup

11
9
7
5
3
1
1 Processor
100 Fish

2 Processors
200 Fish

4 Processors

400 Fish

800 Fish

8 Processors
1600 Fish

Fig. 7. Speedup

5. Conclusions
The ecological systems simulation is a field that requires considerable computing
power for realistic models, and parallelism is a very useful tool in solving this type of
problem. The present study shows very good results for IoM models and efficient
solutions for such problems by using PDES. The operative prototypes were built
using a PDES kernel developed at the UAB and are executed on a low-cost distributed architecture based on Linux.
The IoM Fish Schools model was developed using conservative and optimistic
PDES algorithms. The results are better in the first type of protocols, due to the model
characteristics. The main conclusions that can be extracted are:
− Model scalability is possible and acceptable. The division of the problem to be
simulated into partitions (cubes) increases the speedup with respect to the existing
parallel versions [8].
− Performance is good with respect to large data animations, but there is a limit essentially imposed both by the communications model and the architecture. A reduction in this time would mean changing the communications model (for example
using MPI) and modifying the network communications technology (Gigabit
Ethernet).
Future work is guided towards:
− The need to include within the study an increase in individual and processor numbers in order to verify model scalability.
− Simulation methods will have to include optimistic protocols such as the STW [11]
that allows improvement in results by controlling the rollback chains.

− The IoM model must be improved, including biological characteristics to make it
more realistic. This would involve, for example: speed coupling, behaviour patterns, inertial behaviours, dead angles, etc.
− The visualization of the simulation results must be improved in order to allow
totally integrated animations with the simulation, by using (for example) OpenGL.

6. References
1. Booch, G., Rumbaugh. J., Jacobson, I. The unified modelling language: User’s guide. Adisson-Wesley. (1999)
2. Cores, F. Switch Time Warp: Un método para el control del optimismo en el protocolo de
simulacion distribuïda Time Warp. MsC Thesis (in Spanish). Universitat Autònoma de Barcelona. Spain. (2000)
3. Deelman, E., Coraco, T., Boleslaw, K. Parallel discrete event simulation of lime disease.
Pacific Biocomputing Conference. (1996). 191-202.
4. ECOTOOLS: High level tools for modelling and simulation of individual-oriented ecological models. http://www.offis.uni-oldenburg.de/projekte/ecotools (1999)
5. Fishwick, P., Sanderson, J.G., Wolf, W. A multimodeling basis for across-trophic-level
ecosystem modelling. Trans. SCS. Vol. 15. No. 2. (1998) 76-89.
6. Huth, A., Wissel, C. The simulation of movement of fish schools. Journal of Theoretical
Biology 156. (1992) 365-385.
7. Kreft, J. Booth, G, Wimpenny, W. BacSim, a simulator for individual-based modelling of
bacterial colony growth. Microbiology 144. (1998) 3275-3287.
8. Lorek, H, Sonnenschein, M. Using parallel computers to simulate individual oriented models: a case study. European Simulation Multiconference (ESM). (1995) 526-531.
9. Munt, P. Simulació distribuïda en PVM: Implementació dels algorismes TimeWarp i Switch
Time Warp. Graduate Thesis (in Catalan). Universitat Autònoma de Barcelona. Spain.
(1999)
10. Proctor, G., Winter, C. Information flocking, data visualisation in Virtual Worlds using
emergent behaviours. Proc. Int. Conf. of Virtual Worlds Vol. 1434. Springer-Verlag.
(1998) 168-176.
11. Suppi, R., Cores, F, Luque, E.. Improving optimistic PDES in PVM environments. Lecture
Notes in Computer Science. Springer-Verlag 1908. (2000). 304-312.

