Improvement of Digital Terrain Model Interpolation
Using SFS Techniques with Single Satellite Imagery
1

Mohammad A. Rajabi , J. A. Rod Blais

1

Dept. of Geomatics Eng., The University of Calgary, 2500, University Dr., NW,
Calgary, Alberta, Canada, T2N 1N4
{marajabi, blais}@ucalgary.ca

Abstract. The technique of stereo measurement is mainly applied to extract
Digital Terrain Model (DTM) height data from stereo images in
photogrammetry and remote sensing. Tremendous amounts of local and global
DTM data with different specifications are now available. However, there are
numerous geoscience and engineering applications which need denser DTM
grid data than what exists. Advanced space technology has provided much
single (if not stereo) high-resolution satellite imageries almost worldwide. In
cases where only monocular images are available, reconstruction of the object
surfaces becomes more difficult. Shape from Shading (SFS) is one of the
methods to derive the geometric information of the objects from the analysis of
the monocular images. This paper discusses the idea of using SFS methods with
single high resolution satellite imagery to densify regular grids of heights.
Three different methodologies are explained and implemented with both
simulated and real data. Very encouraging results are obtained and briefly
discussed.

1.

Introduction

Digital Terrain Models (DTMs) are simply regular grids of elevation measurements
over the land surface. They are used for the analysis of topographical features in GISs
and numerous engineering computations. Rajabi and Blais [1] briefly reviewed and
referenced a number of sources for DTM and their applications in engineering as well
as science.
Stereo measurements from a pair of aerial photographs or satellite images have
mainly been used as the primary method of producing DTMs. Information from
double or multiple images in overlap areas ensures reliable and stable models for
geometric and radiometric processing. Specially recently, with the rapid improvement
in remote sensing technology, automated analysis of stereo satellite data has been
used to derive DTM data ([2], [3], and [4]).
Today, especially with the greater need for the scientific management of the
limited natural resources, there are numerous geoscience and engineering applications
which need denser DTM data than available. But due to some reasons such as cloud
coverage, technical and/or political limitations, stereo satellite imagery is not

available everywhere. Obviously, collecting additional height data in the field is a
remedy, but if not impossible, is either expensive or time consuming or both. While
interpolation techniques are fast and cheap, they have their own inherent difficulties
and problems, especially in terms of accuracy of interpolation in rough terrain.
On the other hand, the availability of single satellite imagery for nearly all of the
Earth is taken for granted nowadays. But unfortunately, reconstruction of objects from
monocular images is very difficult, and in some cases, not possible at all. Inverse
rendering or the procedure of recovering three-dimensional surfaces of unknown
objects from two-dimensional images is an important task in computer vision
research. Shape from Shading (SFS) [5] [6], [7] is one of the techniques used for
inverse rendering which converts the reflectance characteristics in images to shape
information.
This paper discusses the application of shape from shading techniques to improve
the quality of the interpolated DTM grid data with single satellite imagery of better
resolution than the DTM data. The idea is highly motivated by the wide availability of
satellite remotely sensed imagery such as Landsat TM and SPOT HRV imagery.
Section 2 briefly reviews the general SFS problem and the methods implemented in
this paper. Section 3 discusses some implementation details of the methods explained
in section 2 in more depth. Section 4 provides numerical examples to support the
methodology. Last but not least, section 5 ends the paper with some remarks and
conclusion.

2.

Shape from Shading

SFS is one of the methods which transforms single or stereo 2D images to a 3D scene.
Basically, it recovers the surface shape from gradual variations of shading in the
image. The recovered shape can be expressed either in terrain height z(x,y) or surface
→

normal N or surface gradient (p,q)= (∂z / ∂x, ∂z / ∂y ) .
Studying of the image formation process is the key step to solve the SFS problem.
A Lambertian model is the simplest one in which it is assumed that the gray level at
each pixel depends only on light source direction and surface normal. Assuming that
the surface is illuminated by a distant point source, we have the following equation
for the image intensity:
→ →

R ( x, y ) = ρ N ⋅ L = ρ

where

ρ

pl1 + ql 2 + l 3
p2 + q2 +1
→

→

is the surface albedo,

(1)

N is the normal to the surface and L = (l1 , l 2 , l 3 ) is
→

the light source direction. Even with known ρ and L , the SFS problem will still be a
challenging subject, as this is one nonlinear equation with two unknowns for each
pixel in the image. Therefore, SFS is intrinsically an underdetermined problem and in
order to get a unique solution, if there is any at all, we need to have some constraints.

Based on the conceptual differences in the algorithms, there are three different
strategies to solve the SFS problem [1]: 1. Minimization (regularization) approaches
2. Propagation approaches, and 3. Local approaches. A more detailed survey of SFS
methods can be found in [8]. The following subsections briefly review the
minimization approach, which is widely used in to solve the SFS problem and the
other variants of the minimization approach which are used here to enhance the
solution.
2.1

Minimization Approach

Based on one of the earliest minimization methods, the SFS problem is formulated as
a function of surface gradients, while brightness and smoothness constraints are added
to ensure that a unique solution exists [10]. The brightness constraint ensures that the
reconstructed shape produces the same brightness as the input image. The smoothness
constraint in terms of second order surface gradients helps in reconstruction of a
smooth surface.
Brooks and Horn [13] defined the error functional:

{

(

I = ∫∫ ( E ( x, y ) − N ⋅ L) 2 + λ N x

2

+ Ny

2

)+ µ ( N

2

where E(x,y) is the gray level in the image, and the constants λ ,

}

− 1) dxdy

(2)

N x and N y are the

partial derivatives of the surface normal with respect to x and y directions respectively
and µ are Lagrangian multipliers. As it can be seen the functional has three terms: 1)
The brightness error which encourages data closeness of the measured images
intensity and the reflectance function, 2) The regularizing term which imposes the
smoothness on the recovered surface normals, and 3) The normalization constraint on
the recovered normals.
The functional is minimized by applying variational calculus and solving the Euler
equation: The resulting fixed-point iterative scheme for updating the estimated normal
at the coordinate of (i,j) and epoch k+1, using the previously available estimate from
epoch k is:

N

k +1
i, j

 ~k ε 2
1
 N i , j +
=
Ei , j − N ik, j ⋅ L
2
4λ
1 + µ i , j (ε / 4λ ) 

(


L 


)

(3)

where
~

N ik, j =

(

)

1 k
N i +1, j + N ik−1, j + N ik, j +1 + N ik, j −1 .
4

(4)

There are two comments about this update equation. First, it seems that one has to
solve for the Lagrangian multiplier
seen

µ i, j on a pixel-by-pixel basis. However, as it is

µ i, j enters the update equation as a multiplying factor which doesn’t change the

direction of the update normal, therefore we can replace that factor by a normalization
step. The second comment is about the geometry of the update equation. As it is seen,
the update equation is composed of two components. The first one comes from the
smoothness constraint while the second one is a response to the physics of image
irradiance equation.
The main disadvantage of the Brook and Horn method or any other similar
minimization approach is the tendency of over smoothing the solution which results
in the loss of fine detail. Selecting a conservative value for the Lagrangian multiplier
is a very challenging issue in this method. However, in an attempt to overcome this
problem, Horn [11] starts the solution with a large value for the Lagrangian multiplier
and reduces the influence of smoothness constraint in each iteration as the final
solution is approached.
2.2

Modified Minimization Approaches

As it was mentioned in the previous section, the update equation is composed of two
components, smoothness part and the data closeness part. As the first attempt to solve
the over smoothing problem of the general minimization approach, a spatially
controlled regularization parameter λ(i, j) instead of a fixed λ is suggested to be
used to adaptively control the smoothness over the image space [9]. In each iteration,
the space varying regularization parameter at location (i,j) can be determined by the
following function:

λ new = (1 − e

−

c(i, j )
VT

) λ min + ( e

−

c (i, j )
VT

(5)

) λ old (i , j )

where c(i,j) is the control signal, V T is a time-constant that regulates the rate of
exponential decrease and λ min is a preselected minimum value that λ(i, j) may have.
The control signal is defined as c(i,j)=abs(I(i,j)-R(i,j)), where abs() denotes the
absolute value and the function λ new is an exponential decreasing function with the
following properties:

lim

c ( i , j )→0

new

=

old

(i, j)

and

lim

c ( i , j ) →∞

new

=

min

(6)

so that the regularization parameter is only allowed to decrease with the iterations.
Another method to solve the over smoothing problem is to use a robust error kernel in
conjunction with curvature consistency instead of using a quadratic smoothness. The
robust regularizer constraint function can be defined as [14]:

(

ρσ ( N x ) + ρσ N y

)

where ρ σ (η) is a robust kernel defined on the residual

(7)

η and with width parameter

σ . Among different robust kernels, it is proved that the sigmodial-derivative M-

estimator, a continuous version of Hurber’s estimator, has the best properties for
handling surface discontinuities [14] and is defined by:

ρ σ (η) =

σ
 πη 
log cosh .
π
 σ 

(8)

Applying the calculus of variations to the constraint function using the above
mentioned kernel results in the corresponding update equation [14]. Here σ , the
width parameter of robust kernel, is computed based on the variance of the shape
index. Based on Koenderink and Van Doorn [12] the shape index is another method
of representing curvature information. It is a continuous measure which encodes the
same curvature class information as the mean and Gauss curvature, but in an angular
representation. In terms of surface normals, the shape index is defined as [12]:


2
φ = arctan 

π



(N x )1 + (N y )2

2
((N x )1 − (N y )2 ) + 4(N x )2 (N y )1 

(9)

where (…) 1 and (…) 2 denote the x and y components of the parenthesized vector,
respectively. The variance dependence of the kernel is controlled using the
exponential function:
1
 
(φ l − φ c ) 2  2 
 1

σ = σ 0 exp −  ∑
∆φ d2  
 N



(10)

σ 0 is the reference kernel width which we set to one, φ c is the shape index
associated with the central normal of the neighborhood, N i , j , φ l is one of the
where

neighboring shape index values and

∆φ d is the difference in the shape index between

the center values of adjacent curvature classes which is equal to 1/8 [12].
The other modification that can be done on the minimization approach is on the data
closeness part of the update equation. We know that the set of surface normals at a
point which satisfy the image irradiance equation define a cone about the light source
direction. In other words, the individual surface normals can only assume directions
that fall on this cone. At each iteration the updated normal is free to move away from
the cone under the action of the local smoothness. However, we can subsequently
map it back onto the closest normal residing on the cone. This has not only numerical
stability advantage but also all normal vectors in the intermediate states are all
solutions of image irradiance equation. In other words, the update equation for the
surface normals can be written as:

N

k +1
i, j

~
k
i, j

= ΘN

(91)

~

where

N ik, j is the surface normal that minimizes the smoothness constraint while

Θ is the rotation matrix which maps the updated normal to the closest normal lying
on the cone of ambiguity. The axis of rotation is found by taking the cross-product of
the intermediate update with the light source direction:

 ~
 k
N i, j ⋅ L
−1 
θ = − cos  ~
 N ik, j L



3.




−1
 + cos E




(102)

Implementation Details

The main goal of this investigation is to improve the accuracy of the interpolated
DTM grid data by applying SFS techniques with the corresponding single satellite
imagery, while the original DTM data are used as boundary constraints in the SFS
problem.
The basic assumption here is that the satellite imagery has one dyadic order better
resolution than the original DTM data. We also assume that 1) the surface is
Lambertian (which is questionable in reality), 2) the surface albedo is known (by
applying classification techniques to multispectral satellite imageries), 3) the surface
is illuminated by a distant point source (sun), and finally 4) the position of the light
source is known.
Our approach deals with a patch at a time (see Fig. 2) with forty nine points.
Sixteen grid points have known heights (dark circles) and the other thirty three are
points with the interpolated heights (unmarked grid points). Our main interest is to
improve the accuracy of the interpolation for the five innermost unknown points. The
idea of using a patch at a time for parallel processing techniques appears highly
attractive for extensive applications
The method essentially consists of
three stages: 1) preprocessing, 2)
processing, and 3) postprocessing.
The preprocessing stage itself has two
steps. In the first step, using
interpolation (bilinear) techniques, the
heights of the unknown points in the
patch are estimated. When dealing
with the real height data, if there is a
gap in height measurements due to
Fig. 1. A patch: Circles are the grid points
any reason (such as existing of rivers
with known heights and the unmarked ones
or lakes), the whole patch is left
are the points with the interpolated heights.
untouched.

In the second step, using the known grid points, the relative orientation of the inner
most square in the patch with respect to the light source is estimated. If this relative
orientation implies that the patch is in the shadow, then there would be no useful
shading information to improve the accuracy of the interpolated heights. Therefore, in
this case the interpolated heights are considered the final height values.
Otherwise, the processing stage for each patch consists of three steps. In the first
step, the smoothed surface normals (based on one of the three methods explained in
Section (2) are computed. Then in the second step these surface normals are mapped
onto the corresponding ambiguity cone. Finally in the third step, the surface normals
are passed to an overdetermined (74 equations and 33 unknowns) linear adjustment
process to solve for the heights. This is simply done by approximating p and q with
finite differences in terms of heights. The control goes back to the first step of this
stage unless the average difference between the calculated and original image gray
values of all the pixels in the patch is less than a predetermined threshold.
The last stage, postprocessing, consists of taking arithmetic means of two solutions
for the unknown heights located on the boundary of the innermost square in each
patches coming from the neighboring patches, except for the outsides of the
peripheral patches.

4.

Numerical Examples

The methodologies described in Sections 2 and 3 have been tested using a number of
numerical examples. One synthetic object with its synthetic imagery and one real
DTM data and its corresponding satellite imagery were used in these experiments.
With the synthetic object the orientation of the light source was considered as a
variable to investigate the effects of relative positions of the object and the light
source on the solution.
The synthetic object under investigation is a 1024 by 1024 pixel convex
hemisphere with a radius of 250 units, sampled at each 0.5 unit. The corresponding
DTM (one dyadic order less than the object, i.e., 512 by 512 pixels) was extracted out
from the object. Meanwhile, the corresponding image of the object was created using
Lambertian reflectance model with a much (5 times) denser version of the object. The
resulting image was passed through a smoothing filter to get an image with the same
density as the original object under study.
The differences between the original object, the Interpolated Grid Solution (IGS)
and the SFS solutions were analyzed. Table 1 summarizes these results. SFS1, SFS2,
and SFS3 in the table correspond to the three different SFS solutions mentioned in
Section 2 respectively. The total number of the patches in this experiment is 215296.
The statistics shown in this table are computed with those pixels which our SFS
method was able to update their height values. The other patches are either those for
which there is no shading information or the SFS techniques failed to find a solution.
In Table 1 nothing is mentioned about the azimuth of the light source. The symmetry
of the synthetic object under investigation makes the process independent of the light
source azimuth. As it can be seen from this table, SFS techniques have improved the
standard deviation of the differences by an average rate of 43.1%.

Table 1. The convex hemishpere

Object –IGS

Object –SFS1

Object-SFS2

Object –SFS3

Elev.
Mean

Std

Mean

Std

Mean

Std

Mean

Std

30

-0.04

0.32

-0.05

0.19

-0.04

0.18

-0.04

0.18

45

-0.01

0.29

-0.03

0.17

-0.02

0.17

-0.03

0.16

60

0.02

0.32

0.03

0.18

0.03

0.17

0.02

0.17

Patches
not
updated

-

32294

17223

10764

The second test object is a real terrain data set from southern Alberta (Watertoon),
Canada with 25 metre spacing in UTM coordinate system. The original measured
DTM data consists of 100 metre spacing grid in addition to the feature points. These
measurements were used to interpolate the 25-metre grids. A 1024 by 1024 grid with
more than 1300 metre height difference which was extracted out from the four
quadrants of NTS 82H04 DTM data file.
The corresponding satellite imagery is a 3 channel SPOT data file with 20 m
resolution which was originally georeferenced to an extended UTM coordinate
system. By extracting the coordinates of the distinguished terrain features from the
corresponding 1/20000 topographic map sheets, the SPOT imagery was
georeferenced to the same coordinate system as the DTM data are. For this purpose
23 points with good distribution in the area under investigation were used. A second
order polynomial was used for the purpose of georeferencing. The RMS of
georeferencing in x and y direction were 2.96 m and 1.40 m respectively.
Using PCI software, a principal component transformation was applied and the first
channel with 88.52% energy was selected for these experiments. Finally, the satellite
imagery pixel size was changed from 20 m to 25 m using bilinear interpolation
method.
To test the efficiency of the SFS methods with the real data set, we tried to
reconstruct the 25 m DTM from 50 m DTM and 25 m SPOT imagery. Similar to the
simulated data the total number of the patches in this experiment is 215296. The
statistics shown in this table are computed with those pixels which our SFS method
was able to update their height values. The other patches are either those for which
there is no shading information or the SFS techniques failed to find a solution.
Moreover, there is no update in height values for those patches which contain natural
features such as rivers or lakes where there is no measured height data. Table 2
summarizes the results of our experiment with this data set. As it can be seen from
this table, the rate improvement in standard deviation can be reached up to 48%.

Table 2. The real terrain data set.

Object –IGS

Object –SFS1

Object-SFS2

Object –SFS3

Mean
(m)

Std
(m)

Mean
(m)

Std
(m)

Mean
(m)

Std
(m)

Mean
(m)

Std
(m)

0.03

14.95

-0.04

10.17

0.03

8.82

0.04

7.77

5.

-

32%

41%

48%

Improvement
of Std

-

25835

2066

15716

Patches not
updated

Remarks and Conclusions

SFS is intrinsically an underdetermined problem and in order to get a unique solution
one has to implement some kind of constraint(s). Horn’s method uses a single
Lagrangian multiplier in the formulation of the constraint in the SFS problem.
Selecting a conservative value for the Lagrangian multiplier is a very challenging
issue in this method. Moreover, Horn’s method and other similar approaches have the
tendency of over smoothing the solution which results in the loss of fine detail.
Obviously, selecting different Lagrangian multipliers for each pixel or cluster of
pixels based on the roughness of the surface under study is the remedy for this
problem.
On the other hand, it seems that using the idea of mapping the computed smoothed
normals at each iteration back onto the ambiguity cone as data closeness constraint
works very well. This has not only numerical stability advantage but also all normal
vectors in the intermediate states are all solutions of image irradiance equation.
Numerical examples show very encouraging results. The fact that the synthetic
object is a much smoother surface than the real data set convinces us that the SFS
methods should have given us better results than the real data set which is not the
case. The only reason by which this can be explained is the way the synthetic image
was constructed. It shows that our method of constructing the synthetic image does
not resemble the real life case.
Satellite imagery used in this experiment has a very good quality without any
with cloud or snow cover or any other major problem. However, to prove the
efficiency of the above mentioned SFS methods, one should test them with different
satellite imageries with different quality, resolution, sun position, spectral bands and
last but not least different types of terrain.
Fine tuning different variable parameters in the SFS methods, applying
classification techniques for having a more realistic value for the albedo, and using
more sophisticated reflectance model are obviously things that should be taken into
consideration in the future research and development.

6.
1.

2.
3.

4.
5.

6.
7.
8.

9.

10.
11.
12.
13.
14.

References
Rajabi, M. A., Blais, J. A. R.: Improvement of Digital Terrain Model
Interpolation Using SFS Techniques with Single Satellite Imagery. Lecture Notes
in Computer Science, Vol. ????. Springer-Verlag. Berlin Heidelberg New York
(2001) ?????
Gugan, D. J., Dowman, I. J.: Topographic Mapping from Spot Imagery.
Photgrammetric Engineering and Remote Sensing 54(10) (1988):1409-1414
Simard, R., Rochon, G., Leclerc, A.: Mapping with SPOT Imagery and
Integrated Data Sets. Invited paper presented at the 16th congress of the
International Society for Photogrammetry and Remote Sensing held July 1988 in
Kyoto, Japan
Tam, A. P.: Terrain Information Extraction from Digital SPOT Satellite Imagery.
Dept. of Geomatics Eng., The University of Calgary (1990)
Horn, B. K. P.: Shape from Shading: A method for Obtaining the Shape of a
Smooth Opaque from One View. PhD Thesis, Massachusetts Ins. of Technology
(1970)
Horn, B. K. P.: Height and gradient from shading. Int. J. Comput. Vision, 37-5
(1990)
Zhang, R., Tsai, P. S., Cryer, J. E., Shah, M.: Analysis of Shape from Shading
Techniques. Proc. Computer Vision Pttern Recognition (1994): 377-384
Zhang, R., Tsai, P.-S., Cryer, J. E., Shah, M.: Shape from Shading: A Survey.
IEEE Transcation on Pattern Analysis and Machine Intelligence, Vol. 21, No. 8,
August (1999): 690-706
Gultekin, A., Gokmen, M.: Adaptive Shape From Shading. ISCIS XI The
Eleventh International Symposium on Computer and Information Sciences
(1996): 83-92
Ikeuchi, K., Horn, B. K. P.: Numerical Shape from Shading and Occluding
Boundaries. Artificial Intelligence, Vol. 17, Nos. 1-3 (1981): 141-184
Horn, B.K.P.: Height and Gradient from Shading. Int. J. Comput. Vision , Vol. 5,
No. 1, (1990): 37-75
Koenderink, J. J., van Doorn, A.: Surface Shape and Curvature Scales. Image and
Vision Computing, Vol. 10, No. 8, October (1992): 557-565
Brooks, M. J., Horn, B. K. P.: Shape and Source from Shading. International
Joint Conference on Artifical Intelligence, (1985): 932-936
Worthington, P. L., Hancock, E. R.: Needle Map Recovery Using Robust
Regularizers. Image and Vision Computing, Vol. 17, (1999): 545-557

