ODEs and Redefining the Concept of Elementary
Functions
Alexander Gofen
The Smith-Kettlewell Eye Research Institute, 2318 Fillmore St., San Francisco, CA 94102,
USA
galex@ski.org , www.ski.org/gofen

Abstract. The modern concept of elementary functions and the Taylor method
are deeply connected. The article summarizes the remarkable (although not
widely known) facts about the modern Taylor method, Ordinary Differential
Equations (ODEs) and the modern notion of elementary functions - the property
that actually takes place for all ODEs used in applications. Beside the typical
usage of the Taylor method for integrating initial value problems, two new
applications of the Taylor method are considered: integrating until the given
end value, and integrating the boundary value problem.

In the bright memory of the late Prof. Michael L. Lidov

1 Introduction
According to the tradition since the 19th century, elementary functions were defined
just by a convention as a certain limited list of well studied functions, a desirable final
format to express the solutions of different problems. They were polynomials and
rational functions (of several variables), plus the exponential, logarithmic,
trigonometric and the inverse trigonometric functions (of one variable), plus all finite
superpositions of them (The Mathematical Encyclopedia).
Liouville adhered to a slightly different definition: he considered elementary also
algebraic functions, integrals, exponential of integrals, solutions of linear differential
equations with constant coefficients, and all functions which can be obtained by
repeated iteration of these functions.
In any case, it was just a sort of a rather artificial convention. Probably it was Ramon
Moore [1], who first suggested another approach to define the elementary functions
based not on an arbitrary convention, but on a quite fundamental property, that the
elementary functions are solutions of ODEs with the rational right hand parts.
Although his goal was mostly to improve and optimize the algorithm of the classical
Taylor method such a way, that the modern Taylor method would require no more
than O(N2) operations, the new approach appeared to have also a profound
mathematical meaning and connections. Established was a fundamental dividing line
between non-elementary functions and the elementary ones. The latter characterize
the types of ODEs for which the modern Taylor method is applicable, and they also

provide a constructive way how (almost) any (!) non-liner source system of ODEs
may be transformed to quite remarkable forms – even as simple as square
polynomials (Table 2 below).
First of all, the modern Taylor method was intended as a powerful numeric method to
integrate the initial value problems with the ultimate accuracy. The software
implementing it was known since the 80s, and the recent such version of an integrated
environment for PCs (The Taylor Center) is described in these proceedings [6,7].
This paper considers also a couple of less typical tasks for the Taylor method:
integration until the given end value of the dependent variable, and the boundary
value problem.

2 Elementary Functions and ODEs
This section summarizes the fundamental facts about the modern elementary
functions – the basis of the modern Taylor method.
Definition 1: a (vector-) function f = {fk(x1, …, xm)}, (k=1,…,n), is called elementary
with respect to x1 if there exists a system of N≥n ODEs

∂fk/∂x1 = Rk1(f1,…,fN), k = 1,…, N

(1)

with the rational right hand parts Rk1, for which f is a solution (f is defined by this
system as a function of x1). We say that the (vector-) function f is elementary if it is
elementary by all its variables x1, …, xm, thus there exist m different systems of ODEs
(l=1,…m) defining f as a (vector-) function of each of its arguments xl . All those
rational right hand parts Rk1 may be organized into a matrix, called the matrix of
elementarity of the (vector-) function f .
It was proved [2], that if we consider a similar Definition 1' (a version of the
Definition 1), with the polynomial right hand parts Pk1 rather than the rational Rk1,
both definition are equivalent.
In order to demonstrate elementarity of a (vector-) function, it may appear necessary
to consider it as a component of a larger vector-function. For example, f(x,y,z) =
y
y
cos(x)e ζ(z) is elementary together with g(x,y,z) = sin(x)e ζ(z) by x, (fx' = -g; gx' = f),
it is elementary “itself” by y (fy' = f), and it is probably not elementary by z (Zeta
function of Riemann). Thus, the matrix of elementarity by x, y for function f (as a
component of the vector-function {f,g} ) is this:
-g
 f

f 
0 

The function w=tan(t) is elementary together with u=cos(t) and v=sin(t), and the
matrix of elementarity is
2
T
(-v u 1/u ) .

Table 1. Theorems and facts about the elementary functions

1 Polynomial and rational functions
2 All traditionally elementary functions, as well as those
by Liouville
3 Superposition of elementary vector-functions
4 Inverse to an elementary vector-function
5 Implicit functions xk of an equation F(x1,x2,…xn)=0 with
an elementary function F
6 Algebraic functions
7 Derivative of an elementary function
8 Indefinite integral with respect to a certain variable
(say t) of an elementary function f(t,x)
9 Vector-function uk(t,x) which is a solution of ODEs
uk'=fk(u1,…un, x) with an elementary vector-function {fk}
10 lim fn(t) with all functions fn(t) elementary
11

∞

Σantn converging to f(t). Coefficients an are arbitrary

Elementary
Elementary
Elementary
Elementary
Elementary
Elementary
Elementary
Elementary by t, but
not necessarily by x
Elementary by t, but
not necessarily by x
Not necessarily
elementary
Not necessarily
elementary

n=0

12

∞

Σantn converging to f(t). Coefficients an are obtained

Elementary

n=0

via the special recurrent formulas for differentiating the
canonical equations
13 A solution x(t) of a finite difference equation
Not necessarily
elementary
F(x(t), x(t+h))=0 with an elementary non-linear
function F
14 Euler’s Gamma function defined as Γ(x+1) = xΓ(x)
Non-elementary

An algebraic function x=X(y,z), defined by an implicit equations P(x,y,z)=0, where P
is a polynomial of arbitrary high degree, is elementary by y and z:
Xy' = -Py' (X,y,z)/Px’(X,y,z); Xz' = -Pz' (X,y,z)/Px' (X,y,z).

This demonstrates existence of elementary functions of more than one variable,
which are not rational (a case not covered by the definition of Moore [1]). Also, each
of these ODEs gives an example, when the solution X(y,z) is elementary both by its
parameter and the differential variable, which is not always the case, but rather an
exception.
The fundamental properties of elementary functions are summarized in the Table 1.
This modern definition of elementarity includes all functions, which traditionally
belong to that notion, plus all solutions of ODEs with the rational right hand parts, all
their possible superpositions and inverse (vector-) functions. Well, then, do nonelementary functions exist at all according to the modern definition? It is not so easy
to point out even one. All types of functions in the Table 1 mentioned as “not
necessarily elementary” are rather the “good candidates”. Meanwhile the nonelementarity is known for sure only for the Euler’s Gamma function Γ(x) (due to the
theorem of Hödel, stating that Γ(x) cannot be a solution of any polynomial ODE).
Table 2. The remarkable transformations possible for all ODEs with the right hand parts being
elementary vector-function (practically any system of ODEs used in applications)

A standard system of ODEs whose right hand parts are an elementary vector-function
(practically any system of ODEs used in applications) can be reduced to…
A system of ODEs whose right hand parts are the rational functions [2]. It can be
further reduced to…
A system of ODEs whose right hand parts are the
A canonical system, a
mixture of the algebraic
polynomial functions [2]. It can be further reduced to…
and differential equations A system of ODEs whose right hand parts are the
of certain simple types,
polynomials of a degree ≤ 2 (see [4]). It can be further
used to compute
reduced to…
efficiently the N-order
derivatives with no more A system of ODEs whose right A system of ODEs
hand parts are the polynomials whose right hand parts
than O(N2) operations.
of a degree 2 with coefficients are the polynomials
with square terms only
-1, 0 or 1 only (see [5]).
(see [4]).

Is there any sense in defining so large concept of the elementary functions, that
practically all functions used in applications belong to this class? The great reason is
that for all ODEs with the elementary right hand parts there exists a unified,
constructive and efficient way of transforming them to the rational and several other
remarkable forms, including the canonical, which makes possible the efficient
modern Taylor method. These transformations are summarized in the Table 2.
Each transformation (from the upper to lower cells in this Table) results in certain
increase of the number of the equations. But the transformation required for the
modern Taylor method

Any Elementary ODEs → Rational ODEs → Canonic System
adds just as little, as is necessary to define the non-rational elementary functions [2].
On the contrary, transforming to the polynomial formats of a degree ≤ 2 may multiply
the number of equations essentially [4, 5]. The fact itself, that it is possible seems
remarkable in any case.
Even with the notion of elementarity that large, it does impose certain applicability
limits for the Taylor method. For example, we must be aware, that the solutions of
ODEs as functions of the parameters mostly are not elementary, thus we cannot apply
the Taylor method to further integrate them by these parameters. Similarly, double
and triple integrals by the parameters also cannot be computed with the Taylor
method directly.

3 Modern Taylor Method Basics
First, we assume a convention. In Modern Taylor Method, the concept of n-th
derivative means the so called normalized derivative, which by definition is
[n]

u

(n)

=u

/n!

so that the Taylor expansion looks like this:
u(t) =

Σ u[k](t - t0)k ;

(further on, the conventional notation u
normalized derivatives).

(k)

is used, although we always mean the

What distinguishes the modern Taylor method from its classical counterpart is the
special technique of computing derivatives. Let us consider a standard initial value
problem for a system of ODEs with any analytical right hand parts
uk'=fk(u1,…, um),

uk|t=a= ak,

k=1,…m

(2)

With no additional assumptions about the right hand parts (2), to perform N-order
differentiation, we have nothing simpler than the formula of Faa di-Bruno [2] for
N-order derivatives of a superposition of functions – quite a complex formula with the
exponential growth, completely impractical.
Even for a more specific right hand parts, for example like x'= uvwy, the Leibnitz
formula for several factors is needed

(uvwy)

(N)

=

ΣΣΣ u(i)v(j)w (k)y (N-i-j-k)

4

That requires as many as O(N ) operations in this specific case. What is the key issue
for the modern Taylor method is a possibility to reduce whichever complex (but
elementary!) right hand parts to a sequence of simple canonical equations [2,3], or to
a sequence of formulas over two operands, for which computing N-order derivatives
2
never requires more than O(N ) operations. Such formulas are for example, the
Leibnitz formula for N-th derivative of a product of two functions:
N

(uv)

(N)

=

(3)

Σ u(i)v(N-i)

i=0
2

The similar by complexity O(N ) formulas exist for quotient, power function,
exponent and logarithm, for example
N-1

if R=u/v, then R

(N)

=( u

(N)

-

Σ R(i)u(N-i) )/v

;

i=0
N-1
a

if R=u , then R

(N)

=

( Σ(a(1-i/N) - i/N)R(i)u(N-i) )/u,

(a is a constant).

i=0

For the linear equations like au, u+v the corresponding formulas are trivial and
require O(n) operations only.
Note: the canonic equations or the sequence of formulas must be computed in the
given order only (not a good case for parallel computing), but the polynomial forms
of a degree ≤ 2 may be used instead of the canonical equations, and unlike the latter,
they may be computed in any order concurrently.
Thus, the modern Taylor method allows obtaining the numeric values of N-order
derivatives in any given point for the system (2) and then summing the Taylor
expansion. As soon as the source system (2) is reduced to the rational right hand parts
(possibly allowing also the power, exponent and logarithm), an algorithm, similar to
parsing an arithmetic expression, automatically performs further reducing to certain
internal structures (like the implicit canonic system), and computes the Taylor
expansion. That way the Taylor method integrates the initial value problems, applying
finite steps not approaching zero and still maintaining any required high accuracy up
to the ultimate – the all available digits of the given binary representation [6, 7].
Practically, it is reasonable to select the order N of the Taylor method according to the
Moore’s “rule of thumb” [1-3] – a value between 20 and 30. The heuristic radius of
convergence may be obtained from the series of the derivatives [6, 7].

4 Reaching the Given End Value
The initial value problem is a “native” one for the Taylor method, but it may be
needed for an application to integrate until the moment, when the given end value of
the dependent variable is reached: that would allow determining a period of the
solution (if it exists). Specifically, we are going to integrate say u1(t) until it reaches
certain value b1. To do that, there are two approaches in the frame of the Taylor
method: (1) It’s always possible and easy to write the systems of ODEs for the inverse
function T(u1) and to integrate it by now independent variable u1 until b1 ; (2) To apply
the standard technique of numeric analysis of polynomials to determine whether there
is a root of u1(t) = P1(t) = b1 in the current domain of the Taylor expansion for u1(t).
4.1 Integrating the Inverse Function
Given the source system (2), the ODEs for the function T(u1) inverse to u1(t) are

∂uk/∂u1 = fk(u1,…, um)/ f1(u1,…, um),

k=1,…m

(4)

∂T/∂u1 =1/ f1(u1,…, um)
True, when switching to system (4) with the independent variable u1, we must be
ready to hit into singularities while integrating from a current point to the end value
b1. We may have to edge into the complex plane temporarily to circumvent the
singularities, and to take into the consideration different Riemann planes. Or we can
just switch back to the system (2) and integrate it by t while near the singularity, and
then to return back to integration by u1 again.
4.2 Analyzing the Polynomial
At each step of integration by t, we may obtain a polynomial expansion P1(t),
representing the solution u1(t) with the ultimate accuracy in a certain finite domain.
Thus, without sacrificing any accuracy, we can explore the equation P1(t) = b1 in the
domain applying the well developed technique for the polynomials. That would allow
either to conclude that there are no solutions (and to perform the next step of
integration by t), or to obtain the solution t1 delivering the end condition u1(t1) = b1 .

5 Boundary Value Problems
Lets us consider a boundary value problem
uk'=fk(u1,…, um),

k=1,…m;
u1|t=0= x,

uk|t=0= ak,
u1|t=1= b1

k=2,…m

(5)

with the unknown component x of the initial value. Given the incomplete initial
condition u1=x at t=0, the unknown solution uk(t,x) in general case is not elementary
by x, therefore there is no hope to find a system for the inverse function X(t,u1) and to
follow the approach 4.1. Instead, to obtain the N-order Taylor expansion of the
solution u by x at the end point t=1, we can adjust the approach 4.2. That will require
n
n
N-times expanding the source system (5), adding ODEs defining all ∂ uk/∂x as
functions of t. (Practically, the order N of the Taylor method is usually 20-30).
Here is how it is done.
uk'=fk(u1,…, um),

u1|t=0= x, uk|t=0= ak, k=2,…m, (the source ODEs).

Then, we may add:

∂uk'/∂x = ∂fk/∂x,

∂u1/∂x|t=0 =1, ∂uk/∂x|t=0 =0, k=2,…m;

∂2uk'/∂x2 = ∂2fk/∂x2,

∂2uk/∂x2|t=0 =0, k=1,…m;

. . . . . . . . . .
∂Νuk'/∂xΝ = ∂Νfk/∂xΝ,

∂Νuk/∂xΝ|t=0 =0, k=1,…m;

(6)

Now, if we start with an arbitrary parameter x, after integrating this system from t=0
until t=1, we will obtain the sequence in this point

∂u1/∂x, ∂2u1/∂x2 , . . . . , ∂Nu1/∂xN
which makes available the Taylor expansion by x of u1(t,x) at t=1 (as though u1(t,x)
were elementary by x and we had the correspondent system of ODEs):
u1(t, x+∆x) = u1(t,x) + (∂u1/∂x)∆x + (∂2u1/∂x2)∆x2 + . . . + (∂Nu1/∂xN)∆xN
(the derivatives are normalized). Now, similarly to that we do with respect to t, we
can estimate the domain of convergence by x of this Taylor expansion, and then
analyze if there is a root of the following polynomial of ∆x
u1(t,x) + (∂u1/∂x)∆x + (∂2u1/∂x2)∆x2 + . . . + (∂ u1/∂x )∆x = b1 .
n

n

n

Here we are in the position similar to that in the section 4.2 above (except that it took
much more efforts to obtain this expansion). If there is no solution in the domain, we
increment x+∆x and repeat this whole step.
A question may arise how we would obtain all these right hand parts ∂Νfk/∂xΝ of those
additional Nm equations (6). Surprising as it is, we should not care at all: the right
hand parts of the source equations (5) do not depend explicitly on x: instead, the
parameter x occurs in the initial values. Therefore, the same algorithm (the same
postfix sequence and the instructions encoding it) [6-8], performing the automatic
differentiation by t, would do that also by x, writing the corresponding results into the

array (with one dimension more). It would perform it in the embedded loops: external
loop by t-differentiation, the internal – by x-differentiation. (This algorithm will be
added to the existing version of the Taylor Center computer program [6-8] in the
future).
Thus, the automatic differentiation by the parameter x appeared to be also possible –
even without the assumption about the elementarity by x of the solution. If this
elementarity really took place and we knew the ODEs defining u1(t,x) with respect to
x, we would be able to integrate them by x just once in the end point t=1. Otherwise,
we have to do that at each t-step (integrating N times larger system). In other words,
n
n
n
n
2
in order to have available both ∂ uk/∂t and ∂ uk/∂x , n=1,2,…, N, we compute N
derivatives of the source system (5) at each step (vs. just N derivatives for the initial
value problem by t).
Note: the same approach remains valid also for integrating the source system
depending on two and more parameters as soon as the parameters are in the initial
values (rather than in the right hand parts). For example, for two parameters x, y,
2
(plus t) the number of computed derivatives would be 2N , i.e. it grows linearly with
number of the parameters (unlike the number of the mixed partial derivatives).
Another concern indeed is that the x-convergence radius at the end point t=1 may be
extremely small (depending on the instability of the problem) so that a lot of
x-integration steps would be needed in order to reach the given value b1.

6 Conclusions
The modern concept of elementary functions reveals the deep connections between
seemingly unrelated issues such as the elementarity vs. :
2

(1) Existence of formulas for obtaining N-order derivatives with efficiency O(N );
(2) Reducing of any arbitrary non-liner ODEs to surprisingly simple forms.
It also shows fundamental differences in:
(3) The nature of the dependency on t of the solutions of ODEs vs. the dependency on
the parameters;
(4) The nature of the solutions of non-linear finite difference equations vs. those of
ODEs.
The automatic differentiation by parameters of the solution of ODEs could be just as
simple as switching to another system of ODEs with no increase in the per-step
computation, if the dependency on the parameters of the solution were also
elementary and the corresponding systems were known. Even with no elementarity by
the parameters, the automatic differentiation by them is still possible, providing they

are placed in the initial conditions. Then the volume of computation at each step
grows proportionally with the number of parameters.
The modern Taylor method is an efficient integrator with unique features especially
important when the ultimate accuracy is the main goal. Typically used for the initial
value problems, it may be adjusted also for the boundary value problems or
integration until the given end value of the unknown function. The suggested features
are to be added in the future to the software package for PCs [6-8], which introduces
an integrating environment for exploring and graphing solutions of ODEs
implemented with the all features of the Graphical User Interface.
Acknowledgement: I am very thankful to Dr. Dmitriy Sonechkin, who first pointed me
out and provided the references to the remarkable transformations [4, 5] for ODEs,
when I enjoyed working together with him in the Hydrometeorological Center
(Moscow, Russia) in 80s.

References
1. Moore, R. E.: Interval Analysis. Prenitce-Hall, Englewood Cliffs, N.Y. (1966).
2. Gofen, A. M.: Fast Taylor-Series Expansion and the Solution of the Cauchy Problem.
U.S.S.R. Comput. Maths. Math. Phys. Vol. 22, No. 5, pp. 74-88 (1982)
3. Gofen, A. M.: Taylor Method of Integrating Ordinary Differential Equations: the Problem of
Steps and Singularities. Cosmic Research, Vol. 30, No. 6, pp. 581-593 (1992)
4. Charnyi, V. I.: Two Methods of integrating the equations of motion. Cosmic Research,
Vol. 8, No. 5 (1970)
5. Kerner, E. H.: Universal Formats for Nonlinear Differential Systems. J. Math. Phys. Vol. 22,
No. 7 (1981)
6. Gofen, A. M.: Recursive Journey to Three Bodies. Delphi Informant Magazine. Vol. 7,
No. 11 (2001)
7. Gofen, A. M.: The Taylor Center for PCs: Graphing and Integrating ODEs with the Ultimate
Accuracy. These Proceedings (2002)
8. Gofen, A. M.: The Taylor Center Demo for PCs.
http://www.ski.org/rehab/mackeben/gofen/TaylorMethod.htm

