Available online at www.sciencedirect.com

Procedia Computer Science 9 (2012) 196 ‚Äì 205

International Conference on Computational Science, ICCS 2012

Evaluation of the Stretch S6 Hybrid ReconÔ¨Ågurable Embedded
CPU Architecture for Power-EÔ¨Écient ScientiÔ¨Åc Computing
Thang Viet Huynha , Manfred M¬®uckeb , Wilfried N. Ganstererb
a Graz

University of Technology, Signal Processing and Speech Communication Lab (SPSC)
of Vienna, Research Group Theory and Applications of Algorithms (TAA)

b University

Abstract
Embedded CPUs typically use much less power than desktop or server CPUs but provide limited or no support for
Ô¨Çoating-point arithmetic. Hybrid reconÔ¨Ågurable CPUs combine Ô¨Åxed and reconÔ¨Ågurable computing fabrics to balance
better execution performance and power consumption. We show how a Stretch S6 hybrid reconÔ¨Ågurable CPU (S6)
can be extended to natively support double precision Ô¨Çoating-point arithmetic. For lower precision number formats,
multiple parallel arithmetic units can be implemented. We evaluate if the superlinear performance improvement of
Ô¨Çoating-point multiplication on reconÔ¨Ågurable fabrics can be exploited in the framework of a hybrid reconÔ¨Ågurable
CPU. We provide an in-depth investigation of data paths to and from the S6 reconÔ¨Ågurable fabric and present peak
and sustained throughput as a function of wide registers used and total operand size. We demonstrate the eÔ¨Äect of the
given interface when using a Ô¨Çoating-point fused multiply-accumulate (FMA) SIMD unit to accelerate the LINPACK
benchmark. We identify a mismatch between the size of the S6‚Äôs reconÔ¨Ågurable fabric and the available interface
bandwidth as the major bottleneck limiting performance which makes it a poor choice for scientiÔ¨Åc workloads relying
on native support for Ô¨Çoating-point arithmetic.
Keywords: ScientiÔ¨Åc Computing, Floating-Point Arithmetic, Power-Aware Computing, LINPACK, ReconÔ¨Ågurable
Hardware, Computer Architecture

1. Introduction
Power consumption has become a major concern in scientiÔ¨Åc computing [1, 2], leading to signiÔ¨Åcant interest in
use of power-eÔ¨Écient CPU architectures as typically found in embedded and mobile computing platforms. Embedded
and mobile computing platforms, on the other hand, face a steep increase of complexity in their native application
set (like speech recognition or augmented reality on mobile phones) approaching the requirements typically found in
scientiÔ¨Åc applications. One typical key requirement of scientiÔ¨Åc applications is support for eÔ¨Écient single- or double
precision Ô¨Çoating-point arithmetic. At the intersection of these two trends, we Ô¨Ånd highly capable yet power-eÔ¨Écient
embedded CPU architectures. Several projects rely on such specialised architectures to build power-eÔ¨Écient large
scale computing infrastructure [1].
Email addresses: thang.huynhviet@tugraz.at (Thang Viet Huynh), Manfred.Muecke@univie.ac.at (Manfred M¬®ucke),
Wilfried.Gansterer@univie.ac.at (Wilfried N. Gansterer)

1877-0509 ¬© 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
doi:10.1016/j.procs.2012.04.021

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

197

Fixed computer architectures need to compromise on many architectural details to appeal to a large audience.
We are interested in exploring the suitability of hybrid reconÔ¨Ågurable CPUs for use as power eÔ¨Écient computing
platforms for scientiÔ¨Åc workloads. Hybrid reconÔ¨Ågurable CPUs allow for selective customisation of the data-path
through extension instructions. In contrast to fully reconÔ¨Ågurable devices like FPGAs, relying for most parts on a
proven static CPU architecture signiÔ¨Åcantly reduces development eÔ¨Äort. Hybrid reconÔ¨Ågurable CPUs thereby allow
for signiÔ¨Åcantly improving a given application‚Äôs performance with low development overhead. The more complex the
custom instruction, i.e. the higher the equivalent number of instructions from the original instruction set, the higher is
typically the achievable performance gain.
Designers of hybrid reconÔ¨Ågurable CPUs are faced with the question of how to combine best the respective
strengths of Ô¨Åxed instruction-set architectures and reconÔ¨Ågurable logic.While the peak performance of hybrid reconÔ¨Ågurable CPUs (subject to application requirements and suitable conÔ¨Åguration) is mostly deÔ¨Åned by the size of the
reconÔ¨Ågurable fabric, the achievable sustained performance relies heavily on the (static) interface between reconÔ¨Ågurable fabric and Ô¨Åxed CPU.
Over the last decade, short-vector single-instruction multiple-data (SIMD) units have been integrated into mainstream CPUs [3, 4, 5]. This trend extends to Ô¨Çoating-point units. As a result, most mainstream CPUs can issue
either a single double precision operation or two single precision operations.Given identical issue rates, the Ô¨Çoatingpoint peak performance doubles if single precision data types are used instead of double precision data types. This
has led to a renewed interest in algorithms relying partly on lower precision number formats to achieve a result
in some higher-precision number format [6]. Algorithms using a limited set of Ô¨Çoating-point number formats are
called mixed-precision algorithms [7]. While static FPUs typically provide a linear improvement in parallelism with
decreasing precision, FPGAs provide quadratic improvement in parallelism with decreasing precision for selected
operations [8, 9]. Implementation of complex numerical algorithms in reconÔ¨Ågurable logic requiring speciÔ¨Åcation in
a hardware description language (HDL) appears both laborious and error-prone. Hybrid reconÔ¨Ågurable CPUs provide
a means for eÔ¨Écient coding using a reliable software stack while potentially delivering a superlinear performance gain
for lower precision arithmetic operations.
This paper aims at verifying the assumption of superlinear performance gain for lower precision arithmetic operations on the Stretch S6 hybrid reconÔ¨Ågurable CPU [10]. This is achieved by investigating in detail the interface
between reconÔ¨Ågurable fabric and Ô¨Åxed CPU considering typical requirements of extension instructions using singleand double precision operands. The S6 was chosen, because it is one of the few commercially available hybrid
reconÔ¨Ågurable CPUs.
LINPACK is a well known benchmark to characterise Ô¨Çoating-point performance of computers and widely used
both in academia and industry [11]. LINPACK does not require the use of speciÔ¨Åc number formats but demands the
solution to achieve a given accuracy. We will demonstrate the eÔ¨Äect of diÔ¨Äerent interface limitations on minimum
issue rate and sustained performance using the LINPACK benchmark when using either double- or single precision
number formats. Based on this characterisation, the performance of mixed-precision solvers can be modeled.
To the best of our knowledge, this work is the Ô¨Årst one considering diÔ¨Äerent Ô¨Çoating-point number formats in
the context of reconÔ¨Ågurable hybrid CPUs. We speciÔ¨Åcally show how the S6‚Äôs interface deÔ¨Ånes achievable performance of double precision extension instructions and how increased peak performance for single precision extension
instructions can not be exploited due to interface restrictions.
The remaining of this paper is organised as follow. We Ô¨Årst summarise related work in Section 2 and present the
Stretch reconÔ¨Ågurable hybrid CPU architecture in Section 3. We then describe our implementation of double precision
and short-vector SIMD single precision fused multiply-accumulate (FMA) operations as extension instructions on the
S6‚Äôs instruction-set extension fabric in Section 4. Section 5 presents and discusses performance of LINPACK on
the S6 when accelerated using diÔ¨Äerent extension instructions. Section 6 investigates in detail the S6‚Äôs interface
between Ô¨Åxed Xtensa CPU core and reconÔ¨Ågurable fabric. The Ô¨Åndings are used to explain the observed LINPACK
performance as well as discussing architectural limitations and possible future improvements. Finally, Section 7 gives
our conclusion and sketches future work.
2. Related Work
Several hybrid reconÔ¨Ågurable CPU architectures exist, among them MOLEN [12], GARP [13] and Stretch [10].
An overview can be found in [14, 15]. Most publications presenting a reconÔ¨Ågurable CPU include some design space

198

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

	"#$#	"





















 


 !	


 !	















	
	

	
	





%&'(		
	









	





  


  

















	
















	








	




)	)	*'

 





	



 








 

Figure 1: a) Stretch S6 Architecture; b) the DFMA and c) multiple parallel SFMA extension instructions implemented on the ISEF

exploration for applications originating from multimedia benchmarks (a favorite usage scenario for reconÔ¨Ågurable
CPUs). We believe Ô¨Çoating-point applications are underrepresented in design space exploration for hybrid reconÔ¨Ågurable CPUs, potentially leading to suboptimal interface design.
Jin et al. [16] added an IEEE-754 compliant single precision FPU to the eMIPS (extensible MIPS) microprocessor (the eMIPS exists as a soft-core design and was synthesized on a Xilinx FPGA). A single precision (SP) fused
operation that integrates 25 basic operations was implemented and evaluated by executing single precision LINPACK.
Huynh et al. [17] demonstrated implementation of a double precision Ô¨Çoating-point FMA operation within the
reconÔ¨Ågurable fabric of the commercially available Stretch S6 hybrid reconÔ¨Ågurable CPU.
Ramkumar et al. [18] pointed out the problematic mismatch of increasing number of operands consumed by
reconÔ¨Ågurable fabrics and limited register Ô¨Åle bandwidth on typical RISC platforms.
Iterative reÔ¨Ånement strategies in Ô¨Çoating-point arithmetic were Ô¨Årst analyzed by Moler [19]. Recently, mixed
precision iterative reÔ¨Ånement received new attention due to the availability of short-vector SIMD units in mainstream
CPUs [6]. We are currently investigating arbitrary-precision iterative reÔ¨Ånement and its performance on reconÔ¨Ågurable
devices [9].
3. Stretch S6 Hybrid ReconÔ¨Ågurable CPU
The Stretch S6 [10] is a hybrid reconÔ¨Ågurable embedded CPU which combines a Ô¨Åxed Tensilica Xtensa LX
instruction set architecture with a dynamically (i.e. at run time) reconÔ¨Ågurable Stretch extension unit. In the following
we describe the S6‚Äôs architecture and summarise typical application development on the S6 hybrid reconÔ¨Ågurable
CPU.
3.1. Architecture
Figure 1a) gives an overview of the Stretch S6 architecture. The 32-bit Xtensa LX core (blue) can run at a clock
frequency of up to 300 MHz and the programmable Instruction Set Extension Fabric (ISEF, yellow) can run at clock
frequencies identical, 1/2 or 1/3 of the Xtensa clock frequency. The Xtensa core is equipped with an IEEE-754 single
precision Ô¨Çoating-point unit. Double precision arithmetic has to be emulated in software. The typically used emulation
relies on the gcc soft Ô¨Çoat routines (contained in libgcc and normally used by gcc when generation of Ô¨Çoating-point
instructions is disabled).
ISEF. The ISEF is an array of reconÔ¨Ågurable computational resources, memories, registers and respective interconnect, which can be used to implement user-deÔ¨Åned extension instructions. Between the Xtensa core and the ISEF,
data is transferred via 128-bit Wide Registers (WR), using a maximum of three registers for input and two registers
for output. The ISEF supports full pipelining of extension instructions with up to 27 pipeline stages. The ISEF‚Äôs
computational resources comprise 4096 arithmetic units (AUs) for bitwise addition/subtraction and logic operations
and 8192 multiply units (MUs) for bitwise multiply and shift operations. The ISEF features 64kB of embedded RAM
(IRAM) which can be accessed from the Xtensa core via fast direct memory access (DMA).

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

199

There are four fundamental sources of potential performance gains when oÔ¨Ñoading computations to the ISEF [20]:
(i) Instruction specialization: As extension instructions serve only a single application, they can be much more speciÔ¨Åc
than general-purpose instructions; (ii) Spatial parallelism: The ISEF allows for implementation of parallel data paths,
limited only by the number of available ISEF resources and the width of input- and output registers; (iii) Temporal
parallelism: Up to 27 pipelining stages; (iv) Embedded memory: The ISEF features multiple embedded memories
providing massive bandwidth at very low latency to access look-up tables or to keep temporary data.
Byte-Streaming. The Stretch S6 provides byte-streaming load-store instructions, which allow for transferring of 1 to
16 bytes between WRs and memory while implicitly updating the memory address with an increment or decrement.
The S6 CPU provides three independent load-streams (RAM to WR) and one store-stream (WR to RAM). After
initialisation, streaming loads and stores take just one cycle to execute, as long as the data resides in data-cache or
dual-port dataram.
3.2. Application Development
Application development for the Stretch CPU typically starts with a new or existing C or C++ program running
on a sequential CPU platform [10, 20]. The code is proÔ¨Åled and analysed to identify the code segments, typically
inner loops, which consume most of the execution time. These identiÔ¨Åed code segments will then be replaced by
user-deÔ¨Åned extension instructions, implemented in the ISEF, and invoked from the main program as C intrinsics.
The Stretch C Compiler (SCC), which is based on gcc, maps ordinary C code into a series of instructions to run on the
Xtensa processor, and synthesises Stretch C code obtainig a bitstream for ISEF conÔ¨Åguration. Once the user-deÔ¨Åned
extension instructions have been deÔ¨Åned in Stretch C, the extension instructions are compiled by SCC. A header
Ô¨Åle deÔ¨Åning the intrinsics associated with the extension instructions is created and included in all ordinary C Ô¨Åles in
which the extension instructions are used. Stretch C is ANSI C with a few enhancements and limitations [20]. The
enhancements include data types of parameterizable bit width and operators for packing and unpacking bits within
longer words. The wide registers (WRs) build the interface between ISEF and Xtensa, holding the input to extension
instructions as well as the computed result. The Stretch S6 ISA provides a variety of load/store instructions to transfer
data between memory, Xtensa and WRs.
4. Floating-Point FMA Extension Instructions on S6
The Xtensa core is equipped with one IEEE single precision Ô¨Çoating-point unit. Our aim is ‚Äì using the S6‚Äôs
reconÔ¨Ågurable fabric ‚Äì to natively support arithmetic operations any desired Ô¨Çoating-point number format up to double
precision. To maximise throughput, we want to reuse remaining logic resources for additional parallel units. In the
following, we describe the implementation of an extension instruction performing IEEE-754 compliant (with the
support of round-to-nearest and the exception of denormalised numbers) Ô¨Çoating-point fused multiply-accumulate
(FMA). FMA combines a Ô¨Çoating-point multiplication followed by a Ô¨Çoating-point addition. As one rounding step
can be omitted, FMA provides more accurate results and higher performance compared to a sequence of Ô¨Çoating-point
multiplication and addition [21].
Floating-Point Arithmetic. Floating-point arithmetic is the standard approach for approximating real number arithmetic in modern computers [22]. Compared to Ô¨Åxed-point numbers, Ô¨Çoating-point numbers cover a larger dynamic
range using less bits at the cost of non-uniform resolution. Floating-point numbers have a Ô¨Åxed relative error while
Ô¨Åxed-point numbers have a Ô¨Åxed absolute error. The advantages of Ô¨Çoating-point arithmetic come at the cost of
more complex hardware implementation. The IEEE-754 standard [23] speciÔ¨Åes number formats and operations for
Ô¨Çoating-point arithmetic on digital computer systems. Many algorithms to implement Ô¨Çoating-point addition and multiplication on digital logic have been presented [24, 22]. In this work, we follow textbook implementations in [22].
Floating-Point Fused Multiply-Accumulate (FMA). The fused multiply-accumulate (FMA) operation performs Z =
X1 ¬∑ X2 + X3 with a single rounding as an indivisible operation, thereby providing a more accurate result compared
to multiplication, rounding, addition and rounding. An FMA can therefore potentially increase both the accuracy and
performance of many computations involving the accumulation of products including dot product, matrix multiplication or Newton‚Äôs iteration for function approximation.

200

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

Table 1: Resources required to implement DFMA, SFMA and SFMAx extension instructions on S6 ISEF.

Arithmetic/Logic Units (AUs)
Multiplication Units (MUs)
ISEF Stages
Routing
fmax [MHz]
Peak performance @ fISEF =300 MHz [MFlop/s]
Peak performance @ fISEF =100 MHz [MFlop/s]
Peak performance @ fISEF =40 MHz [MFlop/s]

Available
4096
8192
27
300

DFMA
54%
39%
10
routable
100
600
200
80

SFMA
21%
8%
6
routable
100
600
200
80

SFMA2
42%
16%
7
routable
100
1200
400
160

SFMA3
62%
24%
17
not routable
100
1800
600
240

SFMA4
84%
32%
n/a
not routable
n/a
2400
800
320

DFMA Extension Instruction. Figure 1b) depicts how the DFMA extension instruction‚Äôs inputs and output are aligned in
the wide registers. The DFMA extension instruction accepts three input operands from three 128-bit wide registers, and
places the corresponding computed result Z = X1 ¬∑ X2 + X3 in one 128-bit wide register. Since the double precision
number format is 64 bits wide, only half of each wide register is used. Table 1 reports the DFMA ISEF resource usage
(AUs, MUs, pipeline stages, routable) as reported by SCC. It gives the maximum achieved clock frequency fmax as
well as the theoretical DFMA peak performance of 600, 200 and 80 MFlop/s if executed at 300, 100 and 40 MHz,
respectively (assuming a throughput of one DFMA or two basic Ô¨Çoating-point operations per clock cycle).
SFMA Extension Instruction. To demonstrate the eÔ¨Äects of lower precision operators, a single precision FMA operator
was implemented. The lower resource usage allows for implementation of multiple parallel single precision Ô¨Çoatingpoint FMA operators (SFMA) in the ISEF. Figure 1c) depicts how the SFMAx extension instruction inputs and output
are aligned in the wide registers. Table 1 reports the ISEF resource usage (AUs, MUs, pipeline stages, routable) when
one, two, three or four SFMA operators are implemented in parallel. The ISEF‚Äôs computational resources would be
suÔ¨Écient to implement up to four parallel SFMA operators. The ISEF routing resources, however, are exhausted with
the implementation of two SFMAs, making actual implementation of three or four parallel units impossible.
Choice of fXtensa and fIS EF . The DFMA and SFMA extension instructions were speciÔ¨Åed Using Stretch C and compiled
using SCC. Obviously, the goal is to achieve an ISEF implementation at the S6‚Äôs maximum clock frequency of
300 MHz. The compiler, however, could not meet a target frequency of 300 MHz. Given the limited ISEF resources,
the FMA‚Äôs most critical path can be implemented at clock frequencies equal or less than 100 MHz for both the Xtensa
core and the ISEF, only. At 100 MHz, SCC was able to synthesize the DFMA and SFMAx extension instructions.
However, setting the clock frequency of the S6 PCIe board to 100 MHz is currently not possible. The next lower
available clock frequency is 40 MHz.
5. Linpack Performance Evaluation
In the following, we will characterise the LINPACK benchmark, detail the benchmark‚Äôs mapping onto the S6
hybrid reconÔ¨Ågurable CPU and report performance measurements for diÔ¨Äerent implementation variants. We close
with a discussion of the reported results.
LINPACK. The LINPACK benchmark [11] measures how fast a computer solves a dense N √ó N system of linear
equations Ax = b. The implementation used in this work is based on a C code available on netlib1 relying on BLAS
Level-1 routines [11]. While there exist more eÔ¨Écient LINPACK implementations, our aim in this work is not to
maximise LINPACK performance, but to demonstrate relative LINPACK performance among various CPUs and at
diÔ¨Äerent precision levels when exploiting short-vector SIMD extension instructions. LINPACK uses the BLAS routine
DGEFA to perform the LU decomposition of the squared matrix A with partial pivoting and DGESL to solve the given
1 http://www.netlib.org/benchmark/linpackc.new

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

201

system of linear equations by forward and back substitution. Most of the execution time of LINPACK is spent in
DGEFA, of which the largest part is spent in the DAXPY routine. DAXPY performs y = Œ± ¬∑ x + y, i.e. it multiplies a vector
x with a scalar Œ± and accumulates the result in vector y.
Experiment Setup. The following experiments were set up, reÔ¨Çecting implementation choices available on the Stretch
S6 hybrid reconÔ¨Ågurable CPU. For each implementation, the Ô¨Çoating-point operators in DAXPY were replaced by
function calls to the respective extension instruction.
1.
2.
3.
4.
5.

LDX {DP LINPACK, software-emulated via Xtensa ALU}: Software-emulated DP arithmetic via Xtensa ALU.
LD1 {DP LINPACK, Xtensa+ISEF (DFMA)}: DAXPY uses extension instruction DFMA.
LSX {SP LINPACK, Xtensa FPU}: DAXPY uses the Xtensa SP FPU (no ISEF used).
LS1 {SP LINPACK, Xtensa+ISEF (1SFMA)}: DAXPY uses extension instruction SFMA.
LS2 {SP LINPACK, Xtensa+ISEF (2SFMA)}: DAXPY uses extension instruction 2SFMA.

Mainstream CPUs. In order to compare performance of the Stretch S6 hybrid reconÔ¨Ågurable CPU to desktop CPUs,
we repeat the measurements on two desktop CPUs from AMD (AMD Opteron 2439, 2.8 GHz, 105 W) and Intel (Intel
Core i7 970, 3.2 GHz, 130 W). On desktop CPUs, the LINPACK code was compiled using gcc version 4.3.2 under
Debian 4.3.2-1.1 with optimization Ô¨Çag -O3.
LINPACK Code. For the double precision experiment, we replace the original sequence of DP Ô¨Çoating-point multiplication and addition in DAXPY by a single DFMA extension instruction. For the single precision experiments, we use
either the S6‚Äôs SP FPU or the SFMA and 2SFMA extension instruction, respectively. The data transfer is implemented
using simple load store (external memory read/write and byte-streaming channels (internal memory to ISEF).
The code was compiled using the Stretch C compiler (SCC) version 2010.01 (built on 5 Feb 2010). Used SCC
Ô¨Çags were -stretch-effort10 and -O3. Both, Xtensa and ISEF were forced to run at a clock frequency of 40 MHz
(i.e. fXtensa = fIS EF = 40 MHz)
5.1. Measurements
For every experiment, we measure the total execution time in cycles. The estimated number of Ô¨Çoating-point
operations at system size N is (2/3N 3 + 2N 2 ) [11]. The LINPACK performance in Ô¨Çoating-point operations per second (Flop/s) is calculated by dividing the number of estimated Ô¨Çoating-point operations by the respective LINPACK
execution time.
Table 2 reports the performance of DP and SP LINPACK benchmarks achieved on Stretch S6 and on desktop CPUs
for systems of size N=500. The performance of DP LINPACK using software-emulated Ô¨Çoating-point arithmetic via
Xtensa ALU is about 0.5 MFlop/s. By providing native DP Ô¨Çoating-point arithmetic through the DFMA extension
instruction, the performance achieved by DP LINPACK on S6 is 12.6 MFlop/s, This corresponds to a speed-up of
about 25 times compared to DP software-emulated LINPACK. The desktop CPUs operating at much higher clock
frequencies signiÔ¨Åcantly outperform the Stretch S6 hybrid CPU in raw performance (MFlop/s). Accepting a lower
accuracy by using SP arithmetic, the SP LINPACK implementation using the native SP Xtensa FPU achieves a sustained performance of 7.0 MFlop/s at 40MHz. Using an extension instruction implementing one and two SP FMAs in
parallel at 40 MHz, achievable LINPACK performance becomes 10.1 MFlop/s and 13.6 MFlop/s, respectively. This is
about 1.5 and 2 times more eÔ¨Écient than SP LINPACK using the native SP Xtensa FPU at the same clock frequency.
Columns three and four in Table 2 present the performance eÔ¨Éciency and the power eÔ¨Éciency of all LINPACK
implementations on S6 CPU. The best performance eÔ¨Éciency is 16% with DFMA for DP Linpack, and 13% with
SFMA for SP Linpack. The maximum power consumption of the PCIe expansion card holding four Stretch S6 CPU
is 25W. We can currently not measure the actual power consumption and therefore assume a worst-case scenario of
25W/4=6.25W per S6 CPU. Dividing sustained performance by power consumption gives a worst-case estimate of
power eÔ¨Éciency at N=500 of 2.0 MFlop/W and 2.2 MFlop/W for DP and SP LINPACK implementations on S6 CPU,
respectively.

202

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

Table 2: LINPACK Performance eÔ¨Éciency and Power eÔ¨Éciency at N=500.
Sustained performance
Peak performance
Performance
[MFlop/s]
[MFlop/s]
eÔ¨Éciency
DP emulated via S6 ALU
40 MHz
0.5
80
1%
DP DFMA ISEF
40 MHz
12.6
80
16%
7.0
80
9%
SP on S6 FPU
40 MHz
SP 1SFMA ISEF
40 MHz
10.1
80
13%
13.6
160
8%
SP 2SFMAs ISEF
40 MHz
DP AMD Opteron 2439
2800 MHz
1570
1560
DP Intel Core i7
3200 MHz

Table 3: LINPACK Execution times and CPEI (N=500, #Flops = 83833333)
Exec. cycles [√ó106 ]
Flops per Ext.Instr.
DP emulated via S6 ALU
40 MHz
6312
2
DP DFMA ISEF
40 MHz
267
2
483
2
SP on S6 FPU
40 MHz
SP 1SFMA ISEF
40 MHz
332
2
247
4
SP 2SFMAs ISEF
40 MHz

Power eÔ¨Éciency
[MFlop/W]
0.1
2.0
1.1
1.6
2.2
14.9
12.0

CPEI
150.6
6.4
11.5
7.9
11.8

Performance Measure Cycles per Extension Instruction (CPEI). In analogy to the cycles per instruction (CPI) measure used in CPU design [25], we will characterise the performance of extension instructions quoting the cycles per
extension instruction (CPEI). It is equivalent to the extension instruction issue rate. The CPEI for some program or
code section is calculated as the ratio of the executed Xtensa clock cycles nXtensa and the executed extension instructions nIS EF
To compare the eÔ¨Éciency of Linpack against the best possible performance achievable on the Stretch S6, we calculate the corresponding CPEI for each implementation. Our Linpack implementation performs n500 = 83833333 Flops
at a system size of N=500. Given the equivalent number of Ô¨Çoating-point operations per extension instruction (FPEI),
we can calculate the CPEI as #cycles ¬∑ FPEI/n500 .
Inspecting Table 3 shows that the CPEI using DFMA is 6.4. Using a single SFMA results in a CPEI of 7.9 while
using two SFMAs gives a CPEI of 11.8. For SP Linpack on Xtensa FPU (no ISEF), we observe that the Xtensa FPU
performs a single precision fused multiply-accumulate instruction within the routine SAXPY, with respective assembly
code madd.s, thereby resulting in a FPEI of 2 and leading to a CPI (cycle per instruction) of 11.5.
Residual report. In accordance with [11], we report the respective residuals of solutions solved by all LINPACK
benchmarks performed in Table 4; N is the system size, is the relative machine precision. The matrix A is a random
matrix generated by the LINPACK code. For reference, we report the condition number Œ∫ of A using the 2-norm:
Œ∫(A) = ||A||2 ||A‚àí1 ||2 . Note that LINPACK implementations using the SFMA and DFMA extension instructions on the S6
ISEF provide more accurate results compared to implementations without fused operations due to the lower number
of rounding operations.
5.2. Discussion
The S6‚Äôs reconÔ¨Ågurable fabric is able to provide support for complex Ô¨Çoating-point operators like fused multiply
accumulate (FMA). For double precision LINPACK, this leads to a speed-up of 25 compared software-emulated
double precision arithmetic. For single precision LINPACK, the fused operation outperforms the implementation

Table 4: Residuals of Linpack solution (N=500)
rN
r1
Œ∫(A)
||Ax ‚àí b||‚àû
SP on S6 Xtensa FPU
4.6e+2
1.42e-03
0.04
0.04
SP SFMA on S6 ISEF
4.6e+2
1.28e-03
0.03
0.03
DP emulated on S6
4.6e+2
3.58e-12
0.05
0.05
DP DFMA on S6 ISEF
4.6e+2
2.87e-12
0.04
0.04
DP on AMD
4.6e+2
3.58e-12
0.05
0.05
DP on Intel
4.6e+2
3.58e-12
0.05
0.05

r‚àû
17.34
16.39
23.56
18.90
23.56
23.56

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

WRs In
1
0
1
2
3

Table 5: S6 Minimum Cycles per Extension Instruction
Instructions required
WRs out
0
1 ext. instruction + 1 WR load
1
1 ext. instruction + 1 WR store
1
1 ext. instruction + 1 WR load + 1 WR store
1 ext. instruction + 2 WR loads + 1 WR store
1
1
1 ext. instruction + 3 WR loads + 1 WR store

203

CPEImin
1
1
2
3
4

relying on the Xtensa FPU. A SIMD unit providing two SFMA operators in parallel improves performance by about
35%. The desktop CPUs running at clock frequencies of 2.8 and 3.2 GHz outperform the S6 by about two orders of
magnitude with respect to throughput. Energy eÔ¨Éciency is about one order of magnitude better on desktop CPU. The
two most evident reasons for the S6‚Äôs poor performance are the artiÔ¨Åcially low clock frequency (40 MHz due to a
setting issue) and the S6‚Äôs low extension instruction issue rate.
6. S6 ISEF Interface Performance Characterisation
Section 4 outlined the FMA implementation and made naive assumptions about achievable peak throughput. LINPACK performance Ô¨Ågures reported in Section 5 showed that sustained performance achieved by the benchmark are
signiÔ¨Åcantly lower. This section details the interface between ISEF and S6 on-chip memories. We derive theoretical peak throughput from architectural features and present respective measurements. Detailed understanding of the
ISEF‚Äôs interface allows for a better explanation of the observed LINPACK performance as well as a detailed documentation of inherent performance degradation due to S6 architectural limitations.
Bandwidth Requirements. A key feature of reconÔ¨Ågurable fabrics is the fact that some arithmetic operation‚Äôs complexity increases superlinear with the precision [8, 22, 26]. When reusing freed resources for additional parallel units,
reducing precision can therefore lead to superlinear parallelism with decreasing precision. Superlinear parallelism,
however, leads to increased total required bandwidth (i.e. if a double precision unit can be replaced by four single
precision units, each accepting two operands, the total required bandwidth doubles from 1*64 bit to 4*32=128 bit,
assuming an issue rate of 1/unit*cycle). Exploitation of the increased parallelism is subject to availability of this
bandwidth. We are therefore interested in understanding all eÔ¨Äects (both architectural and compiler-induced) that
inÔ¨Çuence the achievable data transfer bandwidth to and from the ISEF.
ISEF Interface. The S6‚Äôs execution unit connects on-chip memory (D-Cache and DataRAM) and ISEF via 128bit wide buses. Wide registers (WRs) act as interface for data transfer to and from the ISEF. We are interested in
understanding the implications of (i) the number of input WRs used and (ii) the size of operands used (i.e. bits used
in each WR) on achievable throughput of custom SIMD extension instructions using the streaming interface on S6
CPU. In the following, we derive minimum CPEI (CPEImin ) for diÔ¨Äerent extension instruction conÔ¨Ågurations from
architectural features and perform experiments to obtain the respective average CPEI (CPEI).
S6 Minimum CPEI CPEImin . The on-chip memory system and the wide register (WR) Ô¨Åle are linked with a single
128-bit wide data bus, allowing for a load or a store of at most one 128-bit WR every clock cycle. The Stretch S6
Ô¨Åxed CPU design is an Xtensa LX dual-issue core whose execution unit is able to issue two instructions every clock
cycle. As a consequence of the dual-issue architecture, an extension instruction and a WR load or a WR store can
be issued simultaneously. Therefore, if an extension instruction consumes (or writes) only a single WR, the absolute
minimum issue rate is 1. Every additional WR load or store operation increases the CPEI by one.
The CPEImin for all selected S6 extension instruction conÔ¨Ågurations is reported in Table 5. In summary, an S6
extension instruction reading and writing into two diÔ¨Äerent wide registers can be issued every two Xtensa clock cycles,
in case all data is accessible in local memory. Every additionally used register increases the CPEImin by one clock
cycle.

204

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

Table 6: Minimum and average CPEI for on-chip memory access via byte-streaming channels.
CPEImin
32 bits ops.
64 bits ops.
96 bits ops.
128 bits ops.
1 input WR, 1 output WR
2
3.04
3.09
3.13
3.18
2 input WRs, 1 output WR
3
3.07
3.17
3.22
3.29
3 input WRs, 1 output WR
4
4.05
4.09
4.14
4.18

6.1. Experiments
A small test program measures the average CPEImin achievable as a function of the number of input wide registers
and operand size. Byte-streaming channels are used for eÔ¨Écient data transfer to and from the ISEF (cf. Section 3). For
ease of understanding and presentation, two simple extension instructions DNEGx and SNEGx were implemented using
Stretch C, performing negation for double precision and single precision Ô¨Çoating-point operands, respectively. For
each extension instruction, there exist variants reading data from the lower part of one (DNEG1, SNEG1), two (DNEG2,
SNEG2) or three (DNEG3, SNEG3) wide registers. The result of the operation is always a single Ô¨Çoating-point number.
The extension instruction is executed in a loop reading data from on- or oÔ¨Ä-chip memory. For all experiments, the
Xtensa core runs at 300 MHz, and the Xtensa core and ISEF were forced to run at the same clock frequency by using
SCC Ô¨Çag -stretch-issue-rate 1, i.e. fISEF = fXtensa = 300 MHz.
6.1.1. On-chip memory access
For on-chip memory access, byte-streaming channels are used. For each extension instruction (i.e. using 1, 2 or
3 input WRs), the input operand size is varied between 32, 64, 96 and 128 bit. The resulting sustained CPEIs of the
SIMD extension instructions using byte-streaming channels when the data reside in on-chip memories are reported in
Table 6. The measured CPEIs when data is in D-Cache and in DataRAM are almost equal. Therefore only the smaller
measured CPEI is chosen and reported.
6.2. Discussion
For data transfer between on-chip memory and wide registers via byte-streaming channels, the CPEImin is expected
to depend on the number of WRs used, but not on the size of the operands within a WR. This is conÔ¨Årmed by our
measurements. For conÔ¨Ågurations using two and three input WRs, the measured CPEI almost matches the CPEImin .
For conÔ¨Ågurations using one input WR, the measured CPEI exceeds the expected CPEImin by one clock cycle.
7. Conclusion
Hybrid reconÔ¨Ågurable CPUs are prime candidates for power-eÔ¨Écient acceleration of demanding signal processing
applications. Our goal was to investigate the extent to which this applies to the domain of scientiÔ¨Åc computing,
especially Ô¨Çoating-point arithmetic.
Benchmarking LINPACK using a Ô¨Çoating-point FMA extension instruction showed the functional viability of
using the S6 for scientiÔ¨Åc workloads, but achieved disappointing performance Ô¨Ågures. The low Ô¨Ågures were due to
(i) a low clock frequency of 40 MHz compared to achievable 100 MHz for the extension instruction (ii) a maximum
clock rate of 300 MHz for the Xtensa core and (iii) a low issue rate of extension instructions (cf. Table 3). This work
explored architectural limitations leading to the low issue rate.
ReconÔ¨Ågurable fabrics can provide superlinear parallelism when implementing short-vector SIMD units for selected arithmetic operations in reduced precision. This genuine advantage of reconÔ¨Ågurable logic can only be exploited in reconÔ¨Ågurable hybrid CPUs if the interface between reconÔ¨Ågurable logic and Ô¨Åxed CPU can provide the
necessary bandwidth for data transfer. In this work we have explored the data bandwidth of the interface between
reconÔ¨Ågurable fabric and Ô¨Åxed CPU of the Stretch S6 hybrid reconÔ¨Ågurable CPU.
We derived minimum cycles per extension instruction between 1 and 4, depending on the number of WRs used.
The streaming channels work as expected, decoupling extension instruction issue rate from the amount of bits consumed by each WR. Except for one case (single input WR), our CPEI measurements conÔ¨Årm the expected minimum
cycle values. Both, minimum and measured CPEI increase with the number of WR‚Äôs used.
The Stretch S6 features a large and versatile reconÔ¨Ågurable fabric with impressive I/O (3x128 bit in, 2x128 bit
out). The surrounding infrastructure does not match these capabilities, however, limiting the overall data transfer to

Thang Viet Huynh et al. / Procedia Computer Science 9 (2012) 196 ‚Äì 205

205

128 bit per clock cycle. Fast Ô¨Çoating-point arithmetic relies on eÔ¨Écient transfer of large operands. Given the S6 CPU
design, multiple arithmetic units ‚Äì although implementable in the ISEF ‚Äì can not be fed with the respective data,
resulting in frequent stalls and ineÔ¨Écient program execution. Therefore, the Stretch S6 seems unsuitable for scientiÔ¨Åc
workloads due to the limited bandwidth between ISEF and on-chip memories.
Outlook. The dominant issue identiÔ¨Åed in this work is the mismatch between ISEF resources and WR/Xtensa bandwidth. We will investigate if other hybrid reconÔ¨Ågurable CPUs provide a better match of resources. The Stretch S7
features improved ISEF routing resources. We plan to evaluate if our presented SIMD design scales better (i.e. more
parallel units can actually be implemented) on the S7.
Acknowledgments. This research was partially supported by the Austrian Science Fund (FWF) through project S10608
(NFN SISE) and by the Austrian Academic Exchange Service (OeAD).
References
[1] M. Wehner, L. Oliker, J. Shalf, Low-power supercomputers, in: IEEE Spectrum, October 2009.
[2] M. Mohiyuddin, M. Murphy, L. Oliker, J. Shalf, J. Wawrzynek, S. Williams, A design methodology for domain-optimized power-eÔ¨Écient
supercomputing, in: SC ‚Äô09: Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis, New York,
NY, USA, 2009, pp. 1‚Äì12. doi:10.1145/1654059.1654072.
[3] S. Oberman, G. Favor, F. Weber, AMD 3DNow! technology: architecture and implementations, IEEE Micro 19 (2) (1999) 37‚Äì48.
doi:10.1109/40.755466.
[4] Intel SSE4 Programming Reference.
[5] K. DiefendorÔ¨Ä, P. K. Dubey, R. Hochsprung, H. Scale, AltiVec extension to PowerPC accelerates media processing, IEEE Micro 20 (2)
(2000) 85‚Äì95. doi:10.1109/40.848475.
[6] J. Langou, J. Langou, P. Luszczek, J. Kurzak, A. Buttari, J. Dongarra, Exploiting the performance of 32 bit Ô¨Çoating point arithmetic in
obtaining 64 bit accuracy (revisiting iterative reÔ¨Ånement for linear systems), in: SC ‚Äô06: Proceedings of the 2006 ACM/IEEE conference on
Supercomputing, ACM, New York, NY, USA, 2006. doi:10.1145/1188455.1188573.
[7] A. Buttari, J. Dongarra, J. Langou, J. Langou, P. Luszczek, J. Kurzak, Mixed precision iterative reÔ¨Ånement techniques for the solution of
dense linear systems, Int. J. High Perform. Comput. Appl. 21 (4) (2007) 457‚Äì466. doi:10.1177/1094342007084026.
[8] B. Parhami, Computer arithmetic: algorithms and hardware designs, Oxford University Press, Oxford, UK, 2000.
[9] W. N. Gansterer, M. M¬®ucke, K. Prikopa, Arbitrary precision iterative reÔ¨Ånement.
[10] R. E. Gonzalez, A software-conÔ¨Ågurable processor architecture, IEEE Micro 26 (5) (2006) 42‚Äì51. doi:10.1109/MM.2006.85.
[11] J. J. Dongarra, P. Luszczek, A. Petitet, The LINPACK benchmark: past, present and future, Concurrency and Computation: Practice and
Experience 15 (9) (2003) 803‚Äì820. doi:10.1002/cpe.728.
[12] S. Vassiliadis, S. Wong, G. Gaydadjiev, K. Bertels, G. Kuzmanov, E. M. Panainte, The MOLEN polymorphic processor, IEEE Transactions
on Computers 53 (11) (2004) 1363‚Äì1375. doi:10.1109/TC.2004.104.
[13] T. J. Callahan, J. R. Hauser, J. Wawrzynek, The Garp architecture and C compiler, Computer 33 (4) (2000) 62‚Äì69. doi:10.1109/2.839323.
[14] H. P. Huynh, T. Mitra, Runtime adaptive extensible embedded processors ‚Äì a survey, in: Proceedings of the 9th International Workshop
on Embedded Computer Systems: Architectures, Modeling, and Simulation, SAMOS ‚Äô09, Springer-Verlag, Berlin, Heidelberg, 2009, pp.
215‚Äì225. doi:10.1007/978-3-642-03138-0 23.
[15] M. Sima, S. Vassiliadis, S. Cotofana, J. T. J. Eijndhoven, K. Vissers, Field-Programmable custom computing machines - a taxonomy -, in:
M. Glesner, P. Zipf, M. Renovell (Eds.), Proceedings of the 12th International Conference on Field Programmable Logic, FPL 2002, Vol.
2438 of Lecture Notes in Computer Science, Springer, Berlin, Heidelberg, 2002, pp. 79‚Äì88. doi:10.1007/3-540-46117-5 10.
[16] Z. Jin, R. N. Pittman, A. Forin, ReconÔ¨Ågurable Custom Ô¨Çoating-point instructions, in: Microsoft Research Technical Report, MSR-TR-2009157, 2009.
[17] T. V. Huynh, M. M¬®ucke, W. N. Gansterer, Native double-precision LINPACK implementation on a hybrid reconÔ¨Ågurable CPU, in: 18th
ReconÔ¨Ågurable Architectures Workshop (RAW 2011), IEEE, 2011, pp. 298‚Äì301.
[18] R. Jayaseelan, H. Liu, T. Mitra, Exploiting forwarding to improve data bandwidth of instruction-set extensions, in: Proceedings of the 43rd
annual Design Automation Conference, DAC ‚Äô06, ACM, New York, NY, USA, 2006, pp. 43‚Äì48. doi:10.1145/1146909.1146924.
[19] C. B. Moler, Iterative reÔ¨Ånement in Ô¨Çoating point, J. ACM 14 (2) (1967) 316‚Äì321. doi:10.1145/321386.321394.
[20] Stretch Inc., Stretch SCP Programmer‚Äôs Reference - Version 1.0, Stretch INC, 2007.
[21] S. Boldo, J. M. Muller, Some functions computable with a Fused-Mac, in: 17th IEEE Symposium on Computer Arithmetic (ARITH‚Äô05),
IEEE, Washington, DC, USA, 2005, pp. 52‚Äì58. doi:10.1109/ARITH.2005.39.
[22] J.-M. Muller, N. Brisebarre, F. de Dinechin, C.-P. Jeannerod, V. Lef`evre, G. Melquiond, N. Revol, D. Stehl¬¥e, S. Torres, Handbook of FloatingPoint Arithmetic, Birkh¬®auser Boston, 2010.
[23] IEEE standard for Ô¨Çoating-point arithmetic, IEEE Std 754-2008 (2008) 1 ‚Äì58doi:10.1109/IEEESTD.2008.4610935.
[24] J. Hennessy, D. Patterson, Computer Architecture - A Quantitative Approach - Appendix I: Computer Arithmetic by David Goldberg, 4th
Edition, Morgan Kaufmann, 2007.
[25] J. L. Hennessy, D. A. Patterson, Computer Architecture: A Quantitative Approach, 4th Edition, 4th Edition, Morgan Kaufmann, 2006.
[26] M. M¬®ucke, B. Lesser, W. N. Gansterer, Peak performance model for a custom precision Ô¨Çoating-point dot product on FPGAs, in: D. Hutchison
(Ed.), Euro-Par 2010 Parallel Processing Workshops, Workshop on Unconventional High-Performance Computing (UCHPC 2010), Vol. 6586
of Lecture Notes in Computer Science, Springer, Berlin, Heidelberg, 2010, pp. 399‚Äì406. doi:10.1007/978-3-642-21878-1 49.

