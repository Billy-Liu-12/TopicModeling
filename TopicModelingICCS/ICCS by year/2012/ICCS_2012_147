Available online at www.sciencedirect.com

Procedia Computer Science 9 (2012) 1334 – 1337

International Conference on Computational Science, ICCS 2012

Initial pattern library algorithm for human action recognition
H.S. Lia, B.H. Xub *
a

School of Information and Communication, Guilin University of Electronic Technology,Guilin,China
b
School of information science and technology, Beijing Normal University,Beijing,China

Abstract
Human action recognition is currently one of the most active research topics in society management, including human moving
detection, human moving classification, human moving tracking, and activity recognition and description. In this paper, we have
proposed a new classifying and sorting initial pattern library algorithm for human action recognition. First, we classify the
training vector set to two subsets by vector variance. Secondly, sort the subsets to put the similar pattern vectors together. Last,
select some number of pattern vectors from the sorted subsets to form the initial pattern library. This new initial pattern library is
tested by self-organizing maps (SOM) algorithm. Experimental results in image recognition show that this new initial pattern
library algorithm is better than the common random sampling initial pattern library.

Keywords: Human action recognition; Self-organizing maps; Initial pattern libary; Image recognition

1. Introduction
Human action recognition is currently one of the most active research topics in society management and physical
education, including human moving detection, human moving classification, human moving tracking, and activity
recognition and description [1].
The self-organizing map (SOM) is an unsupervised machine learning algorithm [2], and is widely applied in
pattern recognition [3, 4] and human action analysis [5, 12]. As it can reveal the complex nonlinear relationship of
high dimensional data and figure it in low dimensional space, SOM algorithm has been paid lots of attention.
In human action analysis and recognition, the initial pattern library plays an important part which reflects the start
of training. The random algorithm is the simplest initial pattern library algorithm while it has several disadvantages,
such as limited adaptability to the source, poor learning efficiency and convergence performance. Splitting
algorithm is another common initial pattern library algorithm which is more efficient than random algorithm, but it
is more complex and needs a great deal of computation.
In order to improve the performance of the pattern library, a new classifying and sorting initial pattern library
algorithm is proposed in this paper. First, we classify the training vector set to two subsets based on vector variance.
Secondly, sort the subsets to put the similar pattern vectors together. Last, select some number of pattern vectors

E-mail address: hongsongli@yahoo.cn (H.S. Li).

1877-0509 © 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
doi:10.1016/j.procs.2012.04.146

H.S. Li and B.H. Xu / Procedia Computer Science 9 (2012) 1334 – 1337

1335

from the sorted subsets to form the initial pattern library.
2. SOM Algorithm
Step-1: Given a neural network of size N , M and a training vector set {X (t ), t = 0,1, , L − 1} , where N
is the size of pattern library, M is the size of each pattern vector and L is the number of training vectors. Initialize
the neighborhood

{NEj (0), j = 0,1, , N −1} and the initial pattern library {Wj (0) j = 0,1, , N −1}.

Step-2: Input a new training vector X (t ) .
Step-3: Compute the distortion

d j (t )

between

X (t ) and each pattern vector W j (t ) . Select the minimum

distortion pattern vector W * (t ) given by
j

d j* (t ) = min d j (t )
0≤ j ≤ N −1

Step-4: Modify

W j * (t )

and its neighboring pattern vectors by

Wj (t + 1) =

Wj (t) + α(t)[X(t) − Wj (t)]
Wj (t)

j ∈ j * , NEj* (t)
else

Where, NE * (t ) is Euclidean distance neighborhood around the minimum distortion pattern vector which is
j
decreased with t given by
− t / T1
0
1
j*

NE ( t ) = A + A e

Where, A0 A1 are constants determining the neighborhood range. T1 is a constant, determining the decreasing rate.
The learning rate α (t ) ( 0 ≤ α (t ) ≤ 1 ) determines the modification value of pattern vector. Theoretically, if
α (t ) is small enough, the average error function of the system will reach the minimum after a long time training. In
practice, learning rate is usually determined by

α (t ) = A2e−t
Where,
rate.

2

/ T2

A2 is a constant determining the maximum of learning rate, and T2 is a constant determining the decreasing

Step-5: Go to Step-2.
3. Initial Pattern Library Algorithm
3.1. Random Algorithm
Random algorithm can be classified to random data setting and random sampling. In random data setting
algorithm, the initial pattern vector are set to random data. Because the initial pattern library is independent with the
training set, and some invalid pattern vector often exist in the pattern library after training, thus random data setting
algorithm is not usually used.
In random sampling algorithm, the initial pattern vectors are selected randomly from the training set. For example,
if the training set is denoted by {X (t ), t = 0,1, , L − 1} , the initial pattern library can be obtained by selecting
vectors X (0), X ( p ), , X (( N − 1) p ) , where p = L / N . This algorithm has two advantages: it doesn’t need any

1336

H.S. Li and B.H. Xu / Procedia Computer Science 9 (2012) 1334 – 1337

calculation; there will be no invalid pattern vectors in the pattern library. However, sometimes many similar vectors
or unrepresentative vectors are selected, and the pattern library performance will degrade.
3.2. Splitting Algorithm
The splitting algorithm [9] proposed by Linde, Buzo and Gray can be implemented as follows:
Step-1: Compute the centroid (represented by W( 0) ) of all training vectors, split W(0) to two close vector
W1( 0) = W ( 0) + e and W2( 0 ) = W ( 0 ) − e , where e is a fix perturbation vector.
Step-2: Use {W1( 0 ) , W2( 0 ) } as the initial pattern library, design the pattern library with two pattern vectors by LBG
algorithm. The resulting pattern library is represented by {W1(1) , W2(1) } .
Step-3: Split {W1(1) , W2(1) } to four pattern vectors as Step-1.
Step-4: Design the pattern library with four pattern vectors as Step-2, and the resulting pattern vectors are split to
eight pattern vectors. Repeat this procedure until N initial pattern vectors are created.
The defect of splitting algorithm is too complex, and it is not suitable for SOM algorithm.
3.3. Classifying and Sorting Algorithm
As variance reflects the frequency feature of the image block (i.e. pattern vector), and different frequencies have
different impacts on human vision, we consider dividing the vectors in the training set into two categories by
variance. Then training is performed on each category respectively which can save a lot of training time and make
the training more pertinent. Last, pattern libraries are combined to one pattern library after training. The classifying
and sorting algorithm is described as follows:
Step-1: Compute the variance of each vector in the training set, then classify the vectors to low-frequency or highfrequency by a variance threshold, the results are represented by {X L ( t )} , {X H ( t )} .
Step-2: Sort {X L ( t )} and {X H ( t )} as follows (taking {X L ( t )} as example):
Set X L (0) to be the first initial pattern vector W0 , calculate the distance between W0 and the rest vectors in
{X L ( t )} , take the vector with the shortest distance ( i.e. the nearest one to W0 ) to be the second initial pattern vector

W1 , then take the vector W2 from the residual vectors who is the nearest to W1 to be the third initial pattern vector.
~
Repeat this procedure to the end. Finally, we get a sorted low-frequency initial pattern library represented by {X L ( t )} .
~
~
Step-3: Select pattern vectors with an interval from {X L ( t )} and {X H ( t )} to get the low-frequency and highfrequency initial pattern libraries.

In our experiments, the sizes of low-frequency and high-frequency pattern library are 410 and 1638. Then the
size of the whole pattern library is 2048.

4. Experimental Results
We have simulated three initial pattern library design algorithms using three standard testing images (‘Lena’,
‘Pepper’ and ‘Fishing boat’). The size of image block is M = 8 × 8 . Distortion measure is calculated
by d j (t ) = X (t ) − W (t ) 2 .
The reconstructed image quality is measured by the PSNR, PSNR = 10 log 10 ( 255 2 / MSE ) , and MSE is the mean
square error between original image and reconstructed image.

1337

H.S. Li and B.H. Xu / Procedia Computer Science 9 (2012) 1334 – 1337

The experimental results are shown in Table 1for PSNR of the reconstruction images. We can see that SOM
algorithm is better than LBG algorithm. Our classifying and sorting algorithm is better than random sampling
algorithm, and the average PSNR improvement is about 1.5 dB.
Table1. PSNR of reconstructed images
Training algorithm

Initial pattern algorithm

Lena (dB)

Pepper (dB)

Boat (dB)

Average (dB)

LBG

Random Sampling

30.05

30.49

28.06

29.39

Splitting

30.98

31.97

29.20

30.56

Random Sampling

30.73

31.51

29.88

30.71

Classifying and Sorting

32.36

32.97

31.53

32.55

SOM

References
1. S. Sempena, N.U Maulidevi. P.R. Aryan, Human action recognition using dynamic time warping. 2011 International Conference on
Electrical Engineering and Informatics (ICEEI), 2011, pp. 1-5.
2. T. Kohonen, An introduction to neural computing, Neural Networks, Jan. 1988, pp.3.
3. L.R. Ezequied, Invariant pattern identification by self-organizing network, Pattern Recognition Letters, 22(2001), pp. 983.
4. V.V. Gafiychuk, B.Y. Datsko, Analysis of data clusters obtained by self-organizing methods, Physical Statistical Mechanics and its
Applications, 341(2004), pp. 547.
5. J.K. Aggarwal, Human activity recognition - a grand challenge Signals, Circuits and Systems, International Symposium, 2(2007), pp. 1-5.
6. W. Huang,, Human action recognition based on Self Organizing Maps, 2010 IEEE International Conference on Acoustics Speech and
Signal Processing (ICASSP2010), pp. 2130-2133.
7. L.Szerdiova, D. Simsik, Z. Dolna, Standing long jump and study of movement dynamics using human motion analysis, 2010 IEEE 8th
International Symposium on Applied Machine Intelligence and Informatics (SAMI2010), pp. 263 – 266.
8. H. Liu, S. Lin, Y.D. Zhang, K. Tao, Automatic video-based analysis of athlete action, 14th International Conference on Image Analysis
and Processing(ICIAP 200) , pp. 205 – 210, 2007.
9. K.F. Sim, K. Sundaraj, Human motion tracking on broadcast golf swing video using optical flow and template matching, 2010 International
Conference on Computer Applications and Industrial Electronics (ICCAIE2010), pp.169-173.
10. G.Y. Zhu, Q.M. Huang, Human behavior analysis for highlight ranking in broadcast racket sports video,

IEEE Transactions on

Multimedia,vol. 9 , 6( 2007) , pp. 1167 – 1182.
11. P.U. Maheswari, M. Rajaram, A novel approach for mining association rules on sports data using principal component analysis: for
cricket match perspective, 2009 IEEE International Conference on Advance Computing(IACC 2009), pp.1047-1080.
12. J.H. Ma, P.C.Yuen, W.W. Zou; J.H. Lai, Supervised neighborhood topology learning for human action recognition , 2009 IEEE 12th
International Conference on Computer Vision (ICCV2009), pp. 476-481.

