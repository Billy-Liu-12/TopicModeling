Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 1126 – 1135

2013 International Conference on Computational Science

An ontology-based approach to performance monitoring of
MUSCLE-bound multi-scale applications
Wlodzimierz Funikaa,b, Michal Janczykowskia, Konrad Jopeka, Maciej Grzegorczyka
a

AGH University of Science and Technology, Faculty of Computer Science, Electronics and Telecommunication, Department of Computer
Science , al. A.Mickiewicza 30, 30-059 Krakow, Poland
b
AGH University of Science and Technology, ACC Cyfronet AGH, ul. Nawojki 11 30, 30-950
and
e-mail: funika@agh.edu.pl

Abstract
In this paper we present an evolved and extended approach to the monitoring of data flow and resources' usage in multiscale applications built with the MUSCLE environment. Most multi-scale platforms provide the ability of running complex
computations, but do not sufficiently support monitoring features if any. Combining the monitored multi-scale application
with components that support gathering low-level monitoring data into high abstraction level performance information and
visualizing it at runtime is the main objective of our approach. Performance monitoring data should be presented to allow
the user to easily observe and interpret computation progress. Data access and processing based on ontologies enables easy
reconfiguration of monitored resources and application parameters. Moreover, ontologies facilitate automatic reasoning on
performance flaws.

© 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
and peer
review under
responsibility
of of
thethe
organizers
of of
thethe
2013
International
Conference
onon
Computational
Selection and/or
peer-review
under
responsibility
organizers
2013
International
Conference
Computational
Science
Keywords: multi-scale application; monitoring; performance analysis; visualization; ontology; MUSCLE; Nagios; SemMon; MessagePack

1. Introduction
Multi-scale applications play a significant role in many disciplines of science which require high
computational power. Many simulations in life sciences, chemistry, physics are realized on top of multi-scale
vide
frameworks which provide highdedicated functions for inter-process communication, parallel execution and other low-level issues. One of
them is the MUSCLE framework [1] which implements message-passing paradigm.
The authors and users of multi-scale applications need dedicated monitoring tools designed and
implemented with an eye on the requirements of this type of systems. What is worth to point out, such
experiments need to be monitored at various abstraction levels - the programmers and users need information
about CPU or memory usage as well as high-level details about the running application. Another issue is the
amount of collected monitoring data - modern computational systems are able to generate huge amounts of data

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.278

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

what makes it impossible to analyze by human. It is also a challenge for the monitoring systems to provide a
well-organized GUI and aggregated information from logs which can lead the programmers to conclusions on
information should be performed automatically. To fulfill all these requirements we worked out an approach
and implemented it in a new monitoring system which is a combination of low-level tools, such as System
Watcher - a dedicated monitoring solution for the MUSCLE framework and a high-level monitoring tool called
SemMon [2].
The approach we are going to present evolved: we resigned the idea of the primitive MUSCLE's and
Nagios' stubs [3]. Instead, some extra work has been done. New components such as Universal Monitoring
Proxy, System Watcher, Time Server and MUstub have been implemented and integrated into our system. In
fact, the impact of those changes was very deep they resulted in reorganizations in the architecture, data flow
and main system's activities.
The paper is organized as follows: a brief overview of related work is presented in Section 2. Section 3
gives an outline of the research goals. The section that follows presents an overview of the proposed solution.
The implementation details of the system are depicted in Section 5. The new tool's performance issues were
discussed in Section 6. Further on, we present a case study followed by Conclusions and ideas for future work.
2. Related work
Providing monitoring functionality for modern and complex applications, e.g. simulations, is addressed in
many computational platforms. Monitoring facilities offer different functionalities and abstraction levels of
monitoring data. Those more versatile ones usually deliver low-level monitoring data, whereas monitoring data
of high abstraction, more suited to particular environments, is provided by specific tools, whose adaptation to a
different monitored system is laborious if possible. Below we present some monitoring tools which are already
exploited or can be prospective for multi-scale simulations.
The most interesting tool is VAMPIR [4], a monitoring tool for parallel applications. It features advanced
performance visualization, one of its notable displays being the well-established space-time diagram. There is a
number of other interesting performance measurement and visualization tools also, such as the TAU tools suite
[5], which allows for a vast number of insights into applications built with different programming paradigms.
Another tool, G-PM [6] enables user-defined metrics that can be described on-line for interactive grid
applications, being supported by the OCM-G monitoring system.
A number of tools can provide low-level monitoring data, some of them being able to support
management actions: Nagios, Autopilot, Zabbix and GRM. Nagios [7] is a fast, lightweight system which
allows extending its functionality by plug-ins. Autopilot [8] is a complex monitoring tool which can influence a
monitored system - it can take actions based on sensors and actuators installed in the monitored application.
Zabbix [9] is similar to Autopilot, it restarts services if needed, alerts the administrator using emailing, SMS, or
other ways of communication. GRM [10] is a low-level monitoring tool with rich functionalities, but cannot be
used as a fully stand-alone tool. The analysis of the above systems made us to consider Nagios for providing
low-level data.
Whereas the mentioned tools provide a large scope of functions, adapting them to a new type of
system/application is not a trivial task that most often implies building auxiliary components and modifications
paradigm at all.
Recent interest in introducing semantics into building software resulted in the emergence of ontologybased approaches to the monitoring process as well. By introducing semantics into the monitoring process, the
the object that is monitored, which in turn reduces the time spent to manually
search for issues. Having a semantic description and taxonomy of the monitored elements and their contexts,

1127

1128

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

throughout the whole monitoring analysis process. One of the
existing systems that exploit ontology for monitoring purposes is SemMon which will be described below in
more details. There is also a similar tool called SAMM [11], which follows the idea of SemMon and combines
management activities with monitoring while featuring greater autonomy and managing a monitored process
via system mechanisms. Another example of the ontology-based performance-related approach is PerfOnto
[12] which exploits OWL ontology to describe so called experiment-related and resource-related concepts. The
experiment-related concept describes experiments and their associated performance data on applications. The
system enables to search data in an ontological fashion, e.g. to find a code region executed on a particular node
with a metric exceeding a threshold value, thus giving a hint to the site scheduler to migrate a job to another
node. Whereas PerfOnto gives a rich description of performance data, does not provide any automation for
using it.
3. Research goals
The Multi-Scale Coupling Library (MUSCLE) framework implements message-passing paradigm to
perform calculations in grid environments. MUSCLE contains multiple agents, called kernels, which are
responsible for separate parts of an experiment and need to communicate with each other by passing the results
of calculations. Owing to the message-passing paradigm, kernels can be in different states - computing, waiting
for data, or sending data.
The main objective of our system is to enable collecting monitoring data from various levels of
experiment's execution while all the collected information are going to be analyzed and visualized at runtime.
The information gathered will be related to the current state of MUSCLE kernels, the amount of data
transferred between them, and the resources usage by the application on each host, which is obtained using
other components independent from MUSLE Nagios which is responsible for monitoring low-level data on

or designer to easily interpret computation progress in order to facilitate improving the experiment's code. A
hierarchy of object classes and relationships between them are needed to present the collected information at
different levels of abstraction; this is realized by specifying a semantic description of the application elements.
Since MUSCLE is intended to perform computations in grid environments
synchronized using a well-established mechanism, like NTP 1, which enables to order monitoring data in a
stream of events in the monitored system, even if information is coming in a different order.
Furthermore, assuming that the system is running in a heterogeneous environment it should be able to
collect resources' data from various operating systems and transparently transfer information through network
to performance analysis. Moreover, gathering the data on the MUSCLE system should induce as low overhead

4. Overview of proposed solution
Now we are coming to a description of our concept and components used in this solution the reused
ones and those implemented specifically for the architecture of the system under discussion. We will explain
how these components work together, the way they are used and possibilities arising from their existence - not
necessarily only in our system.

1

Network Time Protocol (NTP) is a networking protocol for clock synchronization between computer systems over packet-switched,
variable-latency data networks.

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

4.1. Concept
The main component used in our system is the one that is a subject to monitoring
the MUSLE
framework. This environment provides a software framework for building and implementing simulations
consistent with the principles of finite cellular automata theory. Communication is performed using the actorbased concurrency model, which features asynchronous sending and synchronous receiving of the messages.
The implementation performs communication with JADE 2. The simulation involves splitting work between
communicating individual agents (kernels). MUSCLE supports distribution of the kernels onto multiple nodes
allowing scaling simulations, low-level calculations are performed within one machine and only higher-level
data is transferred between machines.
Another subsystem used in our research is SemMon an agent-based tool for monitoring which uses
external semantic description of monitored resources. It provides a model for collecting information along with
algorithms which can adapt measurements to the current analysis goal. A strong side of this tool is the ability to
easily change the ontological description just before starting the tool. The tool provides a semantic-based
integration layer for so called physical or low level monitoring systems. These systems may be oriented to a
concrete technology and are required to provide monitoring data about the application, thus the SemMon can
be used to monitor various technologies and applications in the same way, e.g. ProActive-based applications3
or those running in the cloud. The user can focus on its main task: to find performance issues within limited
period of time, based on the system guidance while being able to add their own measurements when needed.
The tool is assumed to be extendible with sensors and metrics strongly related to the structure of the monitored
application.
Nagios is a mature, low-level monitoring system. Due to its nature it is easy to locate potential problems
at the very early stage.
Combining these systems does not fully fulfill the goal that we have set. The main idea was to create a
monitoring system that would exploit ontologies. Some additional components turned out to be necessary to
implement a specific monitoring component for processes, a time server, and a component that will easily
manage data packages. Our conclusions related to the scope of actions to be taken follow below.
4.2. System components
In order to achieve the objectives of our research, we decided to use - besides the MUSCLE environment two tools: the Nagios monitoring system and SemMon - a system that aggregates/filters and visualizes the
collected data. There was also a need in additional components: to support process-level monitoring - System
Watcher (SW), a server to share universal UTC time - Time Server, a stub for the MUSCLE system MUstub
and, finally, a universal component of traffic management, Universal Monitoring Proxy (UMP). The previously
mentioned components are newly implemented as we gave up the idea of primitive MUSLE's and Nagios'
stubs. They caused major changes to the architecture that will be described later.
To enable implementation of the UMP component it was necessary to create a special communication
protocol which allows for traffic optimization and reduction of the size of transmitted packets. Time Server is
responsible for updating the time on local machines by synchronizing it via NTP. It provides the universal UTC
time for the components which are sending the monitoring data to SemMon. System Watcher is a component
that enables process-level monitoring which is not available with Nagios.

2
The ProActive platform is compliant with the Grid Component Model (GCM) to support HPC workflows and application parallelization
using the active objects paradigm (http:// http://proactive.activeeon.com/index.php).
3
Java Agent DEvelopment Framework (JADE Framework) is a software Framework fully implemented in Java language which simplifies
the implementation of multi-agent systems through a middle-ware that complies with the FIPA specifications and through a set of graphical
tools that supports the debugging and deployment phases.

1129

1130

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

MUstub as a proxy for MUSLE is assumed to administrate, sort and compress the monitored data. The
final component to describe is UMP. It enables the management of packages in real time, allows for
(re)configuration of monitoring at any moment. It handles receiving packages from monitoring tools, sending
them to visualizing tools, wrapping packages with a special header prior to sending them.
4.3.
The system's architecture is presented in Fig. 1.

Fig. 1. System's architecture

The architecture has changed compared with its original version since we implemented and integrated the
above mentioned new components earlier. Therefore we are giving a full description of the current system's
structure.
Time Server is connected via BSD sockets with the components that aggregate and send data to the
SemMon tool: MUSCLE, Nagios and System Watcher. Subsystem MUstub replaces the monitored system in a
number of duties, so that monitoring information is more objective and less distorted. The collected, sorted,
categorized and compressed data is sent from these tools to Universal Monitoring Proxy. UMP is a component
that manages the packages at system's runtime. This component does not analyze packages, it is only a
mediator which segregates them thus more important data - with a higher priority arrives at the visualizing
tool earlier when there are a lot of packages in queue to send. The architecture takes into account the distributed
nature of the MUSCLE platform. In this case, further instances of each component except for the SemMon tool
are required.
4.4. Ontological description of monitored objects
The SemMon system follows the idea of ontological description for every object it monitors. An
ontological description is an external file which is loaded into the system. Due to the lack of support for multiscale frameworks it was necessary to create entities with special meaning. Their naming follows that
established in the MUSCLE framework: Kernel and Experiment. Every Kernel has one capability: its state.

ke
from another kernel for a long period of time. Such modifications can speed up the execution of experiment.
on system means a set of kernels and it has a capability to monitor

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

so the research under discussion could only extend the existing description without any complicated
the usage of CPU, memory and separately -

es consume CPU time.

capabilities are shown in Fig. 2b.

Fig. 2.

resource and capabilities

4.5. Motivation for dedicated protocol
One of the main assumptions in the design of our system was to provide that adding components should
be as easy as possible. For this purpose, a communication protocol has been developed which is used in
communication between the components of the system we built. This protocol is defined by the rules of the
data exchange and message syntax. To provide a universal mechanism, reliability and a satisfactory rate of
transmission, we decided to use TCP sockets, thus there is no need to focus on the low-level flow control
issues, such as retransmission, acknowledgment of receipt, calculating of the checksum for the header and data
segments, reordering and removing duplicated segments.
The syntax of sending the message was designed with the purpose of simplicity and syntax brevity. For
binary compressing we exploit the MessagePack library [13] that provides powerful opportunities, e.g.,
effective data compression and fast serialization/deserialization.
5. Implementation details
The protocol designed for monitoring purposes is based on BSD sockets between each two components.
The information sent are Strings serialized by the MessagePack library, which provides both high performance
and effective compression of data.
5.1. Issue of transferred data volume
The size of data sent between computing kernels inside the MUSCLE platform is one of the most

programmer. There are not any features in Java to effortless calculate the size of an object, like operator
Java has a reflection mechanism 4 , which allows observing
powerful, but slow. Moreover, the size needs to be calculated depending on primitive type sizes, which can be

4

Reflection is the ability of a computer program to examine and modify the structure and behaviour of an object at runtime.

1131

1132

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

slightly different in various JVM implementations. As we assume to attain maximum performance, we
disregard the use of the reflection mechanism in a runtime monitoring system.
There is an instrumentation interface available in Java since version 1.5. It enables picking the object size,
but similarly to the reflection mechanism, the returned value is dependent on JVM implementation. MUSCLE
can be lunched under different JVMs or hosts, thus the data size need to be equal on each host.
In MUSCLE there is an own serialization mechanism for packing the wrapped data into binary format. It
is a very interesting method, because the real size of the sent data is obtained, which suits more to the complete
data volume.
The most reasonable way to tackle the issue of data size seems to be the use of the serialization
mechanism on unwrapped data and counting the number of created bytes. Both sizes, unwrapped and wrapped
data serialized, are gathered and visualized in SemMon. Unfortunately, all these methods have impact on
it is up
ng purposes.
5.2.
Among other purposes, the SemMon system is exploited to visualize resources' usage. Originally,
SemMon offered two types of charts: time-lined curves and histogram. However, it did not provide other types
of charts, especially useful in visualizing the flow of data in a network. So, we needed to create a specialized
matrix chart (which is presented in Fig. 3).

Fig. 3. Communication matrix chart

The matrix chart is basically a matrix n x n, where n means the number of kernels. On the
kernels. The example above presents data exchange between two kernels simple experiment in which the writer sends about 3250 bytes to the reader. There is no connection in the
-line and show the progress of experiment in real-time.
6. Issues of performance evaluation
Many important issues in the monitoring system are those related to performance. Below we present two
aspects, on which we have focused most attention.

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

6.1. Impact on the MUSCLE platform
We have conducted tests to compare the performance in different situations and settings. Since MUSCLE
follows the message passing paradigm it is quite difficult to measure the execution's time of some functions
so we decided to create a simple experiment and measure the whole execution time. There were no
computations in the experiment, only sending and receiving the messages. The prepared case contains
messages of various types, e.g. arrays of both primitive and complex types, collections, etc.
Sending the collected data to SemMon,
Loggin
Computing the size of unwrapped sent data.
The execution time of the experiment run without the monitoring system is assumed as a reference time.
When the monitoring system was used without logging and checking the real data size, the entire execution
time grew by 4.87%. It is possible to run the monitoring system without sending data to SemMon, only
the performance cost is similar, i.e., 5,36%. Using both options may extend the
application execution by 9.92%.
The full monitoring system needs to serialize unwrapped data to check its real size. It adds about 5-6% to
A drop of performance by ca 5%, 4.87% for SemMon or 5,36% for logging, is quite acceptable in
s MUSCLE work much longer, therefore
it is up to the users whether they want to obtain the real size of data transferred and which type of monitoring
data acquisition, extended (SemMon) or logging, should be used.
6.2.

evaluation

case of a distributed
system architecture the most important factor affecting the performance is network traffic and there is no clear
way to predict it exactly.
When our system is not distributed - it is only on the local machine we received very satisfactory results
in terms of performance. The delay resulting from the usage of additional components seems to be negligible in
comparison with the benefits obtained. With the current system's architecture adding new components should
not cause any problems. The system has been designed to allow future developers to easily maintain and
develop additional components.
The average time of package transition from the source location (MUSCLE) to destination (SemMon) is
2.74 [ms].
The package transfer time depends on its size, but due to applying dedicated rules to the communication
protocol in our system, we obtained a constant medium package size. This allows to better predict the system's
behavior and to adapt it for the current needs.
An interesting idea would be to collect a few packages and send them at the same time. Owing to it we
would get fewer connection try attempts. However, it should be noted that packages will not be as up-to-date at
the point of delivery as without the collecting idea. The user should decide what is more important for them at
the moment - whether more up-to-date packages and lower performance or better performance and not so upto-date packages, which sometimes can be a reasonable choice.
7. Case Study
The functionality of our system was tested in an example experiment. The test environment was
configured as follows: on the first machine we started SemMon, other components on the second one.

1133

1134

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

The second host runs an experiment and Universal Monitoring Proxy. SemMon has its own host. The
simulation was performed on the local network based on 100 Mbps ethernet. Due to the fact that the test
experiment generates a lot of messages rather than computational load this case study concentrates on a
network flow analysis.
The test example experiment simulates a heat flow in a two-dimensional object using five MUSCLE
kernels. The object is divided into five equal parts: every part has its own kernel for heat calculations.
The SemMon provides InterKernelCommunicationCapability which can be visualized with
matrix chart and time-lined chart. As mentioned above the communication matrix presents a data flow between
kernels in the experiment. The results of the experiment visualization indicate that the kernels formed a twodirectional broken ring. The first kernel communicates with the second, the second with the third and so on, but
the last kernel does not send data to first one. The volume of data sent between kernels is about 11 MB. The
above matrix diagram can be useful to trace data flow in the experiment as well as to visualize the internal
topology of inter-kernel connections.
The MUSCLE Kernel activity state is also monitored. In the MUSCLE framework the kernel may be in
one of three different states: working - kernel performs calculations, waiting - kernel waits for a data from
another kernel, sending - kernel sends data to another kernel.
, on
The Kernel activity is shown on the timelevel 1 - waiting and on level 2 - sending. The kernel's activity chart is presented in Figure 4. The main
middle_0
middle_0
computation kernel and it processes the data received from other kernels.

Fig. 4. Kernels' activity chart

8. Conclusion and future work
In this paper we described a new ontology-based approach to building monitoring tool for multi-scale
applications based on the MUSCLE framework. The initial concepts had been revised during implementation
and some of functionalities were implemented in a different way than that assumed originally. The most
noticeable change is developing a more distributed and flexible architecture of the system. The system has been
designed to facilitate the maintenance and further development. The proposed tools can be used both as a

Wlodzimierz Funika et al. / Procedia Computer Science 18 (2013) 1126 – 1135

complete system and independent monitoring data collectors due to the universal communication protocol
based on the MessagePack library.
Another change relates to the low-level monitoring mechanism. The dedicated tool called System
Watcher was implemented from scratch. As opposed to Nagios, System Watcher may also perform per-process
monitoring that is essential especially when monitoring computational kernels.
During the implementation process we had to overcome several problems. The most important one was
the communication overhead. Java RMI is too slow to send monitoring data in real-time hence a low-level
protocol has been designed and implemented. The original MUSCLE framework had no monitoring
mechanisms. Some needed data had to be retrieved from MUSCLE internals and exported to the proxy object
which sent it to the rest of the system.
The concept of the external ontological description of monitored metrics used in SemMon enables the
user to easily change the focus of monitoring and makes monitoring activities more flexible; it is possible to
aggregate and filter monitoring data according to the scope of current performance analysis goals,
independently of the underlying execution platform that is helpful in multi-scale applications.
Further work should concentrate on extending the capabilities of low-level monitoring and on providing
support for another multi-scale framework. An interesting idea would be to collect more than one package and
send them at the same time. Another good point for further research is to test automatic reasoning mechanisms
in the SemMon system during the execution of experiment.
Acknowledgements
Our thanks go to Dr. Katarzyna Rycerz for valuable discussions about MUSCLE. We thank prof. Jacek
Kitowski for a number of essential comments. The research is supported by AGH grant no. 11.11.230.015.
References
[1] MUSCLE Project, web site: http://www.irmb.bau.tu-bs.de/muscle/ .
, D. Semantic-Oriented Performance Monitoring of Distributed Applications. In: Computing
[2] Funika, W. , Godowski, P., Pegiel, P.,
and Informatics 31(2): 427-446 (2012)
[3] Funika, W., Janczykowski, M., Dudek, M., Kuboszek, A., Jopek, K., Grzegorczyk, M. Performance Monitoring and Analysis System
for MUSCLE-based Applications in PL-Grid. In: Proc. IEEE 7th Int. Conf. on E-Science, e-Science 2011 Workshops, Stockholm,
Sweden, December 5-8, 2011, IEEE Computer Society 2011, ISBN 978-1-4673-0026-1, p. 112-119.
[4] Vampir web site: http://vampir.eu .
[5] Malony, A. D., Shende, S., and Bell, R. On-line Performance Observation of Large-Scale Parallel Application. In: Proc. Parco 2003
Symposium, Elsevier B.V., Sept. 2003.
[6] Wismueller, R., et al. Support for User-Defined Metrics in the Online Performance Analysis Tool G-PM. In: M. D. Dikaiakos (eds.),
Grid Computing. Second European AcrossGrid Conference, AxGrids 2004, LNCS, no. 3166, Springer, 2004, p. 159-168.
[7] Nagios web site: http://nagios.com .
[8] Ribler R. L., Vetter, J.S., Simitci, H. , Reed, D.A. Autopilot: Adaptive Control of Distributed Applications, Department of Computer
Science University of Illinois, 2005.
[9] Zabbix Project, web site: http://zabbix.com .
[10] Balaton, Z., Kacsuk, P., Podhorszki, N. Application Monitoring in the GRID with GRM and PROVE. In: Proc. ICCS 2001, Part I.
LNCS 2073 Springer 2001, p. 253-262.
[11] Funika, W., Kupisz, M., Koperek, P. Towards autonomic semantic-based management of distributed applications. In: Computer
Science Annual of AGH-UST, vol. 11, 2010, p. 51-63, AGH Press, Krakow, 2010; ISSN 1508-2806
[12] Truong, H.-L., Dustdar, S., Fahringer, T. Performance Metrics and Ontologies for Grid Workows. In: Future Generation Comp. Syst.,
Vol. 23, 2007, No. 6, p. 760 772.
[13] MessagePack Project, web site: http://msgpack.org/

1135

