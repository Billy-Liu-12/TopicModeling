Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 1794 – 1803

International Conference on Computational Science, ICCS 2013

Sensitivity analysis for mixed-language numerical models
Jean Utkea,∗, Bradley T. Reardenb , Robert A. Lefebvreb
b Oak

a Argonne National Laboratory, MCS, 9700 S. Cass Ave., Argonne, IL 60439, USA
Ridge National Laboratory, P.O. Box 2008, M.S. 6170, Oak Ridge, TN 37831-6170, USA

Abstract
The separation of concerns in the development of numerical models not only leads to a separation into components but, based
on their purpose, these components may also be written in diﬀerent programming languages. The sensitivity analysis of a
numerical model provides quantitative information about the dependencies of the model outputs with respect to its inputs.
An analysis of mixed-language models using derivatives computed with algorithmic (or automatic) diﬀerentiation needs to
comprehensively handle all the involved components and the respective interfaces in a mixed-language environment. We
describe the issues arising in the context of the sensitivity analysis, present a solution implemented with the algorithmic
diﬀerentiation tool Rapsodia for C++ and Fortran, and discuss its practical use in a large-scale engineering application.
Keywords:
sensitivity analysis; mixed-programming languages; algorithmic diﬀerentiation

1. Introduction
The use of numerical models has been an essential ingredient in science and engineering for many years. As
the numerical models have improved, one can not only observe the simulation of real-world processes but also
consider the question of the sensitivity of the model behavior with respect to certain changes in the model’s input.
This sensitivity analysis may be done by sampling. While sampling is simple to orchestrate, it has however, the
disadvantage of being computationally expensive for high-dimensional input spaces and highly nonlinear models.
Alternatively one may compute derivatives to obtain more complete information about the model behavior. If such
derivatives are approximated by ﬁnite-diﬀerence schemes, they are subject to the tradeoﬀ between approximation
and truncation errors for the perturbation, which is aggravated for higher-order derivatives. If the derivatives are
computed with algorithmic diﬀerentiation (AD) [1], also known as automatic diﬀerentiation, then one can attain
the derivatives with machine precision provided the underlying program implementation of the numerical model
is amenable to the application of an AD tool.
One major stumbling block in that respect has been the typical assumption that a given numerical model be
implemented in a single programming language supported by a given AD tool. Even when AD tools are built to
address more than one programming language, it does not follow that they can handle a mixed-language model;
see Sec. 2 for details.
∗ Corresponding

author. Tel.: +1-630-252-4552 .
E-mail address: utke@mcs.anl.gov .

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.348

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

1795

Typically, numerical models will encompass not just purely numerical components, such as components for
linear algebra or nonlinear solvers. They will also have to read input data, process output data, or handle conﬁguration information. One can argue that the array syntax available and extended since the Fortran90 standard lends
itself to a concise programming style for numerical components and potentially enables compiler optimizations
for (dense) linear algebra not easily attainable in other programming languages. On the other hand, handling data
I/O that requires, for example, some parsing of text ﬁles or access to network streams has much better support in
other languages. As models are increasingly developed in components, it has become much more common to select the language best suited for the task at hand in order to attain the speed and accuracy needed for the numerical
components and the ease of maintenance, reusability, and portability needed for the non-numerical components.
The ensuing problem of correctly interfacing these mixed-language components has been addressed in various
ways. At the highest level, interface descriptions and interface code generators such as CORBA (general purpose)
[2] or BABEL (scientiﬁc computing) [3] oﬀer the most ﬂexibility. At the lowest level, one may be interested only
in two languages and either use simple interfaces or create a specialized interface layer.
The low-level, simple-interfaces approach has a long-established practice between Fortran and C for libraries
such as the Basic Linear Algebra Subroutines (BLAS) [4]. In the context of diﬀerentiation with AD it is often recommended that one manually diﬀerentiate (if possible) the ﬁxed, high-level mathematical mapping implemented
by each library call and hand code the derivative at the high level (e.g., linear solver calls). Unlike such numerical
libraries the typical model component implementation is assumed to be subject to changes as the model evolves;
that is, there is no ﬁxed mapping. Furthermore, the eﬀort to implement the derivative for the mapping will typically be at least of the same order of magnitude as the eﬀort for the component implementation itself. Even if
the non-numerical components do not involve any numerical computation, the usual tasks such as I/O still require
maintaining the association between the original model data and the derivatives computed for them. If one does
not want to engage in the time-consuming task of manually maintaining this association, one has to make the
mixed-language components subject to the AD approach.
1.1. Algorithmic Diﬀerentiation
The method of algorithmic diﬀerentiation assumes the numerical model is a function
y = f(x) : IRn → IRm

.

The execution of the program implies the execution of a sequence of intrinsics sin, e x , and so forth and arithmetic
operators to which the chain rule can be applied. For each such elemental operation r = φ(a, b, . . .) with result r
and arguments a, b, . . .1 we can write the total derivative as
r˙ =

∂φ
∂φ ˙
a˙ +
b + ...
∂a
∂b

.

Thus, applying the above rule to each elemental operation in the sequence gives a method to compute
y˙ = J˙x

with the Jacobian

J=

∂fi
, i = 1 . . . m, j = 1 . . . n
∂x j

without explicitly forming the Jacobian. This method applies the chain rule in the computation order of the values
in the program and is known as forward-mode AD. The opposite order of applying the chain rule to the elemental
operations, known as reverse-mode AD, yields projections x¯ = JT y¯ . In particular, for applications in which
m
n, the reverse mode is advantageous because its computational cost does not depend on n. For problems in
state estimation with very large n the reverse mode is indispensable.
On the other hand, the implementation of reverse-mode AD tools is nontrivial; and as this paper discusses a
foray into mixed-language AD, we will limit the scope to forward mode, leaving the extension to reverse mode
the subject of future work. For many practical applications the ratio between n and m still is feasible for the
forward mode. Certain application characteristics such as sparsity in the Jacobian permit compression techniques
1 In

practice most φ are uni- or bivariate.

1796

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

that allow the use of the forward mode in order to compute the entire Jacobian even when n is large [5, 6]. In these
cases one will compute a compressed Jacobian JS with d directions in the domain given as the columns of the
seed matrix S. Depending on the available memory, the derivatives in all d directions may be propagated forward
in vector mode, or one may propagate a subset of the directions at a time [7].
For highly nonlinear problems with moderate n, one may want to expand the sensitivity analysis to include
higher-order derivatives. A possible approach for higher-order derivative tensors is the forward propagation of
Taylor polynomials up to order o in d directions with coeﬃcients aij , j = 1 . . . o, i = 1 . . . d around the common
point a0 ≡ ai0 . The Taylor polynomial is a Taylor series truncated at order o:
φ(ao + h) = φ(a0 ) + φ (a0 ) · h +

φ (a0 ) 2
φ(d) (a0 ) o
· h + ... +
·h
2!
o!

.

Again, the propagation of coeﬃcients is done on the level of the elementary operations. For each r = φ(a, b, . . .)
we compute the result’s Taylor coeﬃcients rij based on the Taylor coeﬃcients of the arguments aij , bij , . . .. For
instance, for the addition r = a + b we simply add the coeﬃcients of the same order:
rij = aij + bij

.

For the multiplication r = a · b it is the convolution
j

rij =

ail · bij−l

.

l=0

Slightly more complicated formulas arise for sin and cos; we denote v˜ j = jv j :
k

s = sin(u) : s˜k =

k

u˜ j ck− j

and

c = cos(u) : c˜ k =

j=1

−˜u j sk− j

.

j=1

A comprehensive approach for all the standard φ occurring in C++ and Fortran is given in [1].
To compute higher-order derivative tensors from the Taylor coeﬃcients, we follow the method in [8]. It
uses an interpolation scheme to recover the distinct elements of all derivative tensors up to order o from forward
propagation of Taylor coeﬃcients in
n+o−1
d=
o
directions that are equal to the multi-indices t ∈ IN0n for which o ≡ |t| =

n
i=1

ti .

Distinctions among the AD implementation approaches relate to the way the set of Taylor coeﬃcients aij is
associated with the original program variable a (data augmentation) and how the logic for the coeﬃcient propagation is added to the original program (logic augmentation). The basic options for the former are association
by address and association by name. Association by address packs the original data and the Taylor coeﬃcients
into a new type, and all diﬀerentiated program variables have their type changed to that new type. Association by
name creates new variables for the augmenting data by adding some adornment to the original variable name and
thereby relates them to each other. For the logic augmentation one uses source code transformation or operator
overloading. The latter is the method of choice for our paper and implies association by address for the data
augmentation.
1.2. Language Interoperability for Numerical Models
A large body of numerical models and libraries has been implemented in Fortran77 and C. We do not want
to argue the relative advantages of these two languages over each other, C++, the more recent Fortran standards,
or other languages. In the following we will use F77 for the Fortran 77 standard and Fortran for all the more
recent standard editions starting with Fortran90. The currently established AD tools address the demands of the
AD users, and the overwhelming majority continues to use Fortran, C, and C++. The portion of pure Fortran77

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

1797

source code is shrinking, and there is only a small fraction of AD uses with C99/C11 code. Support for AD of
GPU accelerator languages such as CUDA and OpenCL is not yet readily available. Therefore, we feel justiﬁed
in restricting our discussion to F77, C, Fortran, and C++. To achieve interoperability, we are looking at the
ability to call routines from the respective other language and pass data. For C++ and Fortran source code using
modules, the symbol names in the object ﬁles resulting from compiling the source code are typically mangled in
a language and compiler implementation-speciﬁc fashion. Furthermore, the addition of virtual function tables,
array descriptors, and the like introduces more sources for incompatibilities that prevent simple direct calls and
data passing. Superﬁcially, for F77 and C the call interoperability is relatively easily achieved because, other
than capitalization (Fortran symbols are case insensitive) and optional trailing underscores, most compilers have
a one-to-one relation between the symbol names in object ﬁles resulting from compiling source code in the two
languages. The passing of data relies on assumptions about the compatibility of integer and ﬂoating-point types;
structured types are not supported in F77 anyway, and one may decide to pass only one-dimensional arrays because
already for two-dimensional arrays one will have to be aware of column major vs row major ordering, respectively.
On the C++ side one can force C-style linkage with the extern "C" qualiﬁer and make sure to pass only
nonstructured data as arguments to F77. On the Fortran side, with the extensions described in Fortran90 and the
subsequent standards, the C interoperability issues were eventually addressed in the standard by the deﬁnitions
provided in the iso_c_binding module, the bind attribute, and by the formal description of the interoperability
restrictions. This description addresses case sensitivity and optional adornments with underscores and permits
interoperability between simple structured types. As one would expect, it does not address the problem of passing
data with array descriptors or virtual function tables.
Because of the data augmentation needed for AD (see Sec. 1.1) the options regarding structured types and
arrays are of particular interest. The Taylor polynomial coeﬃcients aij , j = 1 . . . o, i = 1 . . . d around a common
point a0 ≡ ai0 can be coded as a structured type in C and the respective derived type in Fortran. The restrictions
given in the Fortran standard together with the ordering requirements in the C standard ensure alignment and
would make possible the passing by pointer of the Taylor coeﬃcient data structure between C++ and Fortran. The
question remains whether in a given application context, such a passing without copying is appropriate if the data
(other than the Taylor coeﬃcients) that need to be exchanged between the two sides do not abide by the restrictions
required for this direct exchange and instead an explicit copy is performed by an interface layer. Even if the copy
is not performed explicitly, it may be performed implicitly on the Fortran side, for example, when passing an
noncontiguous array slice to a routine with C binding forces the compiler to create a temporary contiguous copy.
2. Mixed-Language Algorithmic Diﬀerentiation
In Sec. 1.1 we introduced the basic AD principles but concentrated on those relevant for the approach to be
shown in Sec. 3. Here we brieﬂy discuss the issues arising with the main implementation choices in the context
of a mixed-language model.
Source Transformation. The main beneﬁt of the source transformation approach is the ability to attain a high-level
view of the model computation through source code analysis and use that view to optimize the derivative computation, for example, by avoiding logic and data augmentation for sections of the program that provably always have
zero derivative values (known as activity analysis). In the context of source transformation this is mostly a static
analysis; dynamic analysis approaches have so far remained experimental. A precise analysis can signiﬁcantly
reduce the computational eﬀort, for example, for coupled models with one-way dependencies. For the underlying
data dependency analysis to be precise, it needs to be performed on all involved components; and recursive calls
imply that it be implemented as an iteration over the call graph (whole program analysis). Even though there are
multilanguage compiler front-ends such as Rose [9], they typically provide the high-level syntactic representation
for source code in one language at a time and currently do not allow for mixed-language source code representations needed to do the whole program analysis in our usage scenario.2 In an environment of mixed-language
model components a source code analysis will therefore handle only components of one given language at a time
2 Interprocedural compiler optimization begins at a lower-level representation from which high-level source transformations are not feasible.

1798

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

while the components written in the other languages remain opaque. In order to be conservatively correct, the
analysis will assume all possible dependencies for the data passed in the interface to the opaque components. In
cases where library calls take the role of opaque components it is common practice to provide stubs, in order to
allow a more precise analysis. Examples are given for Tapenade for Fortran/C [10] and OpenAD/ADIC [11, 12].
Unlike for libraries we assume that model components may frequently change and therefore the correct updates
to the stubs become a nontrivial maintenance eﬀort. We also point out that the implementation of source transformation AD represents a signiﬁcant technical eﬀort and the developers of AD tools add support for the various
language features on demand. Because of the implied technical complexity (e.g., templates in C++) there is to
date little support for languages other than Fortran and C.
Operator Overloading. The operator overloading approach does not imply any automatic source code analysis
and merely requires the support of operator overloading as a language feature given, for example, in Python,
C++, or Fortran. Therefore, this excludes F77 and C if the users insist on remaining within the syntax of those
languages. By its nature, the operator overloading approach requires the association by address, and in turn that
means the structured types used to hold the derivative data together with the original program data must either
have a compatible representation in the mixed languages or one has to manually convert them in the interface
layer. Given some level of interoperability a conversion should always be possible, but it implies a computational
overhead for the conversion itself as well as an overhead in memory for the duplication of the data. It also
opens the door to data inconsistencies between the copies; consider as an example copied global data. Of course,
these concerns are not speciﬁc to the AD context, but the need for the data augmentation may force the issue.
That aside, one will treat each component in the fashion typical for operator overloading; that is, the type of all
the diﬀerentiable variables is changed to the type that triggers the overloaded functionality, and one manually
addresses the issues arising for formatted I/O and type casting. Typical examples of overloading-based AD tools
include Adol-C [13] and AD01/02 [14]. A Fortran companion tool to Adol-C, called Adol-F [15], has not been
updated since the late 1990s. Among the currently maintained operator-overloading-based AD tools Rapsodia
[16] is aimed at more than one language, but its original design goals did not include interoperability.
Data Augmentation. The aspects of the diﬀerent data augmentation approaches have been explored in [17]. An
association by name is the only option for F77 sources and implies source transformation. Combining it with an association by address approach in C++ (given the lack of robust source transformation AD tools for nontrivial C++)
increases the complexity of the manual conversion signiﬁcantly. Therefore one has to conclude that currently a
combination of Fortran (including F77) and C may be possible but for C++ only an operator-overloading-based
approach with Fortran is practically viable.
3. Mixed-Language Diﬀerentiation with Rapsodia
Rapsodia [16] is based on operator overloading for the forward propagation of univariate Taylor polynomials
as introduced in Sec. 1.1. Most other operator overloading AD tools have overloaded operators that are handcoded and operate on Taylor coeﬃcient arrays with variable length in loops with variable bounds to accommodate
the derivative orders and numbers of directions needed by the application. In contrast, Rapsodia generates on
demand a library of overloaded operators for a speciﬁc number of directions and a speciﬁc order. The library can
be generated as Fortran and as C++ code (the code generator itself is written in Python); see Fig. 1. To trigger the
overloaded operators, one changes the type of the ﬂoating-point variables. Following one of the established usage

struct RAfloatS {
float v;
float d1_1;
.... };
RAfloatS operator *(const RAfloatS& a,
const RAfloatS& b);
...

o,d
C++

Rapsodia
generator

Fortran

type RArealS
real(kind=RAsKind)::v
real(kind=RAsKind)::d1_1
...
interface operator(*)
module procedure multRArealSRArealS
...

Fig. 1. Rapsodia-generated code snippets.

1799

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

patterns for operator overloading tools, one can, for example, transparently switch the types via the preprocessor
as shown in Fig. 2, and in this simple case no other changes are needed. The generated code exhibits (partially)

1
2
3
4
5
6
7

#ifdef USE_AD
#define FFLOATTYPE
#define CFLOATTYPE
#else
#define FFLOATTYPE
#define CFLOATTYPE
#endif

1
2
3
4
5
6
7
8
9

type(RArealD)
RAfloatD
double precision
double

#include "types.h"
#ifdef USE_AD
#include "RAinclude.ipp"
#endif
struct ContextFoo{
CFLOATTYPE x;
CFLOATTYPE y;
void foo();
};

1
2
3
4
5
6

#include <cmath>
#include "Cpp/foo.hpp"
void ContextFoo::foo() {
y=sqrt(x);
}

types.h

foo.cpp

foo.hpp

Fig. 2. Switch types via preprocessor.

ﬂat data structures, partially unrolled loops over the directions, and fully unrolled loops over the derivative order;
see Fig. 3. This implies few array dereferences in the generated code, which in turn provides more freedom for
compiler optimization, yielding better performance than conventional overloaded operators even with ﬁxed loop
bounds. Timing comparisons show the resulting advantage. While it has remained diﬃcult to directly attribute the
improved performance, one plausible reason is that the generated code enables better register allocation. Because
many operators and intrinsics are common to Fortran and C++, the underlying code generator shares the logic
for the creation of the Taylor coeﬃcient propagation statements. Likewise, because the data structure is ﬂat, its
Fortran (as derived types) and C++ (as structs) representations are similar. Consequently, one will ﬁnd in the
body of the overloaded * operator similar code; see Fig. 3. In that ﬁgure, the r.v component corresponds to r0
1
2
3
4
5
6
7

r.v = a.v * b.v;
r.d1_1 = a.v * b.d1_1
r.d1_2 = a.v * b.d1_2
r.d1_3 = a.v * b.d1_3
r.d2_1 = a.v * b.d2_1
r.d2_2 = a.v * b.d2_2
r.d2_3 = a.v * b.d2_3

+
+
+
+
+
+

1
2
3
4
5
6
7

r%v=a%v * b%v
r%d1_1=a%v * b%d1_1
r%d1_2=a%v * b%d1_2
r%d1_3=a%v * b%d1_3
r%d2_1=a%v * b%d2_1
r%d2_2=a%v * b%d2_2
r%d2_3=a%v * b%d2_3

a%d1_1
a%d1_1
a%d1_1
a%d2_1
a%d2_1
a%d2_1

+
+
+
+
+
+

a.d1_1
a.d1_1
a.d1_1
a.d2_1
a.d2_1
a.d2_1

*
*
*
*
*
*

*
*
*
*
*
*

b.v;
b.d1_1
b.d1_2
b.v;
b.d2_1
b.d2_2

b%v
b%d1_1
b%d1_2
b%v
b%d2_1
b%d2_2

+ a.d1_2 * b.v;
+ a.d1_2 * b.d1_1 + a.d1_3 * b.v;
+ a.d2_2 * b.v;
+ a.d2_2 * b.d2_1 + a.d2_3 * b.v;

+ a%d1_2 * b%v
+ a%d1_2 * b%d1_1 + a%d1_3 * b%v
+ a%d2_2 * b%v
+ a%d2_2 * b%d2_1 + a%d2_3 * b%v

Fig. 3. Generated body of the * operator in C++ and Fortran for d = 2, o = 3.

and likewise r.d2_1 to r12 , and so on, in the notation of Sec. 1.1. The operator declarations/deﬁnitions cover all
possible combinations of arguments with diﬀerent precisions; there are precision-speciﬁc derived types/classes.
In order to permit the maximal freedom for the compiler optimization (e.g., the aforementioned register allocation), the default mode omits attributes such as sequence that force a particular ordering of the Fortran derived
type members. For C++ class members (unlike C struct members) there is no implied memory layout based on
the declaration order providing room for compiler optimizations. Even though it is not obvious whether an order
deviating from the declaration order could provide a performance advantage in either C++ or Fortran, one cannot
simply assume that no reordering will happen. Such a reordering would render the structured types incompatible,
and one could not simply pass them by pointer between C++ and Fortran even when all members have interoperable data types. On the other hand, if the interface between Fortran and C++ makes explicit copies of the data
anyway, then the structured types would be copied explicitly member by member as well, and a diﬀerent ordering
does not pose a problem. This is the case for the application discussed in Sec. 4. We implemented two diﬀerent
interoperability modes discussed in the following two sections.

1800

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

3.1. Interfacing with Explicit Copies
As outlined above, the copying does not require any restrictions with respect to the type deﬁnitions. To
illustrate the approach we assume a C++ main calling a Fortran routine bar, which in turn calls a C++ routine foo
via an interface layer (see Fig. 4); but direct passing of the data is prevented by context data structures on the C++
and Fortran sides that are not interoperable (contextMain vs. contextBar vs. contextFoo). Thus, copying takes
place in the interface layer. For convenient copying, the following features were added to the default-generated
Rapsodia code.
• Methods to copy the structured types to and from 1d arrays, e.g., in C++
void RAfloatS::toArray(float arr[RAfloatS::arrSz])
and
void RAfloatS::fromArray(float arr[RAfloatS::arrSz])

and Fortran with generic names RAtoArray and RAfromArray and speciﬁc implementations, e.g.
subroutine fromArrayRArealS(active,arr)

• Constants arrSz for the size of the arrays to hold the members of the structured types; depends on o and d
• Linker settings for certain Fortran/C++ compiler combinations based on whether there is a C++ main routine or a Fortran program.
C++

Fortran

main

Interface
barI

contextBar

C

contextMain

barIC
bar

contextFoo

fooI
fooIC

C

foo

1
2
3
4
5
6
7
8

#include "Cpp/foo.hpp"
extern "C" void fooIC(double *x, double *y);
void fooIC(double *x, double *y) {
ContextFoo cf;
cf.x=*x; cf.y=*y;
cf.foo();
*x=cf.x; *y=cf.y;
}

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

module mFooI
use mContextBar
use, intrinsic :: iso_c_binding
contains
subroutine fooI(c)
interface
subroutine fooIC(x,y) bind(C,name="fooIC")
use, intrinsic :: iso_c_binding
real(c_double) :: x,y
end subroutine
end interface
type(ContextBar) :: c
real(c_double) :: x,y
x=c%u; y=c%w
call fooIC(x,y)
c%u=x; c%w=y
end subroutine
end module

Fig. 4. Schematic and example code for C++/Fortran calls with copying; across the language boundary called routines have C linkage.

The application of Rapsodia then amounts to changing the interface code as shown in Fig. 5. The code outside the
interface is treated as shown in Fig. 2. Clearly, one would expect such a copying interface to be generated, and the
interface generator adapted to handle the changes shown in Fig. 5.
3.2. Interoperable Types
If copying is not imposed by the application context, we generate modiﬁed libraries that ensure interoperable
structured types RAfloatD, RArealD, and so on. Doing so requires modiﬁcations to the code generator that eﬀect
the following changes.
• For the Fortran structured types, add the bind(C) attribute to the type speciﬁcation in order to prevent
reordering of the data members, and reference the iso_c_binding intrinsic module to set the kind parameter
to the appropriate c_float, c_double constants for all ﬂoating-point variables in the generated library.
• Drop the overloaded Fortran type for complex variables, since Rapsodia currently does not support complex
variables on the C++ side.
• For the C++ structured types, extract all the nonstatic data members into a separate C struct from which
the C++ structured type inherits; doing so prevents reorderings because even though they are permitted in
C++, they are not permitted in C.

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

1
2
3
4
5
6
7
8

#include "Cpp/foo.hpp"
extern "C" void fooIC(double[RAfloatD::arrSz],
double[RAfloatD::arrSz]);
void fooIC(double x[RAfloatD::arrSz], double y
[RAfloatD::arrSz]) {
ContextFoo cf;
cf.x.fromArray(x); cf.y.fromArray(y);
cf.foo();
cf.x.toArray(x); cf.y.toArray(y);
}

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

1801

module mFooI
use mContextBar
use, intrinsic :: iso_c_binding
contains
subroutine fooI(c)
interface
subroutine fooIC(x,y) bind(C,name="fooIC")
use, intrinsic :: iso_c_binding
#include "RAinclude.i90"
real(c_double):: x(arrSz),y(arrSz)
end subroutine
end interface
type(ContextBar) :: c
real(c_double):: x(arrSz),y(arrSz)
call RAtoArray(c%u,x); call RAtoArray(c%w,y)
call fooIC(x,y)
call RAfromArray(c%u,x); call RAfromArray(c%w,y)
end subroutine
end module

Fig. 5. Code from Fig. 4 changed for Rapsodia use; the references to the Rapsodia library are highlighted.

These changes are triggered by passing the --interoperable ﬂag to the generator. Referring to the example
from the previous section, if instead of the noninteroperable contexts one passed the x and y variables directly by
pointer, one could eliminate the interface layer altogether if one declares C linkage for bar and foo. Depending
on the overall design this may not be appropriate, however, and therefore one may still retain a minimal interface
layer for intermediate callees with C linkage that then can become subject to the same style of type switching
(types.h is included everywhere) that is used for the code outside the interface; see Fig. 6
fooI declaration in Fortran:

C++ Fortran
main

C
barI
bar

foo

fooI

C

barI prototype in C++:
1
2
3
4

#ifdef USE_AD
#include "RAinclude.ipp"
#endif
extern "C" void barI(CFLOATTYPE *x, CFLOATTYPE *y);

barI deﬁnition in Fortran:
1
2
3
4
5
6
7
8
9

subroutine barI(x,y) bind (c, name="barI")
#ifdef USE_AD
#include "RAinclude.i90"
#endif
use, intrinsic :: iso_c_binding
FFLOATTYPE :: x,y
external bar
call bar(x,y)
end subroutine

1
2
3
4
5
6
7
8
9
10
11

module foo
interface
subroutine fooI(x,y) bind(C,name="fooI")
use, intrinsic :: iso_c_binding
#ifdef USE_AD
#include "RAinclude.i90"
#endif
FFLOATTYPE :: x,y
end subroutine fooI
end interface
end module foo

foo prototype in C++:
1
2
3
4

#ifdef USE_AD
#include "RAinclude.ipp"
#endif
void foo(const CFLOATTYPE &x, CFLOATTYPE &y);

fooI deﬁnition in C++:
1
2
3
4
5

#include "Cpp/foo.h"
extern "C" void fooI(CFLOATTYPE *x, CFLOATTYPE *y);
void fooI(CFLOATTYPE *x, CFLOATTYPE *y) {
foo(*x,*y);
}

Fig. 6. Schematic and example code for C++/Fortran calls with ISO interoperable types.

4. Practical Use within SCALE
The SCALE code system [18] developed at Oak Ridge National Laboratory (ORNL) provides a comprehensive, veriﬁed and validated, user-friendly tool set for criticality safety, reactor physics, radiation shielding,

1802

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

and sensitivity and uncertainty analysis. For more than 30 years, regulators, licensees, and research institutions
around the world have used SCALE for nuclear safety analysis and design. The Tools for Sensitivity and Uncertainty Analysis Methodology Implementation (TSUNAMI) computational sequences within the SCALE system
utilize ﬁrst-order perturbation theory to predict the response of a system to changes in the nuclear data, which
have associated uncertainties [19]. First, the neutron cross-section data that provide the probability of neutron
interactions with matter are processed to provide problem-dependent constants based on the physical conditions
of the system under consideration, taking into account materials, geometry, and temperature. This processing
accounts for the behavior of energy-dependent resonances within the neutron cross-section data and is known
as resonance self-shielding. A unique capability of the TSUNAMI sequences is the calculation of the so-called
implicit sensitivities of the problem-dependent resonance self-shielded neutron cross-section data due to parameters input to the resonance self-shielding calculation [20]. After the problem-dependent cross-section data are
prepared, adjoint-based perturbation theory is applied within three-dimensional neutron transport calculations to
obtain the explicit sensitivity of the desired response functions (e.g., neutron multiplication within a ﬁssile system)
to the resonance self-shielded nuclear data. The implicit and explicit components then are combined to form the
complete sensitivity of the system response to the nuclear data.
The current production version of SCALE generates the implicit sensitivity data through the use of the ORNL
GRESS90 AD package, which applies source transformation to Fortran77 and a limited set of Fortran90 [21]. As
the current production version of SCALE performs calculations by sequentially calling executable codes written
in Fortran and passing data between the executable modules with ﬁle I/O, GRESS90 includes a code coupling
capability to pass derivatives between modules, also through ﬁle I/O. In a typical production calculation, implicit
sensitivities are generated for ∼105 dependent variables with respect to ∼102 independent variables. When applying a reference solution path available in a previous version of SCALE, and subsequently removed for the
current release, one stage of the calculation generated ∼106 intermediate dependent values, along with derivative
information with respect to each independent variable, that were passed through ﬁle I/O from one code to the next.
The memory and runtime requirements for this reference solution were prohibitive for routine use.
Expanding the Fortran coverage of GRESS90 to keep pace with the SCALE development proved diﬃcult.
An interim eﬀort to apply OpenAD led to the successful diﬀerentiation of some components but was eventually eclipsed by the introduction of C++ into the SCALE development environment. Modernization of SCALE,
speciﬁcally where combining functionality into a uniﬁed code base eliminates the internal ﬁle I/O operations, is
implemented by using Fortran and C++ compute kernels within a modular C++ framework. Data are stored in
C++ objects and passed between Fortran and C++ by using the ISO c bindings standard. The motivation for C++
is its ease of use and maintenance as well as its ability to easily couple to user interfaces, input/output processors,
and third party components. It is desirable to apply AD to this modern SCALE framework in order to generate
the implicit sensitivity coeﬃcients.
These circumstances prompted the investigation into the mixed-language AD options and the new parts of
Rapsodia described in this paper. Based on our past experience with the diﬀerentiation of SCALE, the design of
the (generated) Fortran/C++ interfaces for the SCALE components, and the growing role of C++ in the SCALE
development, a new, comprehensive solution clearly was needed. Our new approach with Rapsodia ﬁts the bill,
and a proof of concept has shown its viability. The full application of the new approach to SCALE is subject to
future work.
5. Summary and Outlook
We discussed the problems arising in the context of sensitivity analysis by algorithmic diﬀerentiation when the
numerical model consists of components written in mixed languages, speciﬁcally C++ and Fortran. Among the
possible implementation options we show that only an operator overloading approach currently provides comprehensive AD capabilities for both languages and ensures interoperability of the diﬀerentiated model components.
We introduce modiﬁcations to the AD tool Rapsodia and demonstrate how to achieve derivative computation for
mixed-language components in practice. Using the SCALE code system as a large, practical example, we motivate
the need for this approach.
To our knowledge the modiﬁed Rapsodia tool as described here is the ﬁrst AD tool to support algorithmic
diﬀerentiation comprehensively across languages. The mixed-language environment is becoming ever more com-

Jean Utke et al. / Procedia Computer Science 18 (2013) 1794 – 1803

1803

mon. At the same time already within Rapsodia it is apparent that the diﬀerences in the language features impact
the AD implementation. For example, the Taylor coeﬃcient propagation can be done in parallel on multicore
system but in an asynchronous fashion currently only in C++, not in Fortran [22]. Thus, the more sophisticated
capabilities of Rapsodia can currently not be applied consistently across languages. Rather, the noted lack of
a reverse-mode capability in Rapsodia had previously already been a top development priority. The need for
interoperability will have a signiﬁcant impact on the reverse-mode implementation.
Acknowledgments. Utke was supported by the U.S. Department of Energy, under contract DE-AC02-06CH11357.
References
[1] A. Griewank, A. Walther, Evaluating Derivatives: Principles and Techniques of Algorithmic Diﬀerentiation, 2nd Edition, no. 105 in
Other Titles in Applied Mathematics, SIAM, Philadelphia, PA, 2008.
URL http://www.ec-securehost.com/SIAM/OT105.html
[2] Object Management Group / Common Object Request Broker Architecture (CORBA), http://www.corba.org/.
[3] BABEL: High-Performance Language Interoperability, https://computation.llnl.gov/casc/components/.
[4] Basic Linear Algebra Subprograms (BLAS), http://www.netlib.org/blas/.
[5] B. M. Averick, J. J. Mor´e, C. H. Bischof, A. Carle, A. Griewank, Computing large sparse Jacobian matrices using automatic diﬀerentiation, SIAM J. Sci. Comput. 15 (2) (1994) 285–294. doi:10.1137/0915020.
URL http://link.aip.org/link/?SCE/15/285/1
[6] S. Hossain, T. Steihaug, Reducing the number of AD passes for computing a sparse Jacobian matrix, in: G. Corliss, C. Faure,
A. Griewank, L. Hasco¨et, U. Naumann (Eds.), Automatic Diﬀerentiation of Algorithms: From Simulation to Optimization, Computer
and Information Science, Springer, New York, NY, 2002, Ch. 31, pp. 263–270.
[7] C. Bischof, L. Green, K. Haigler, T. Knauﬀ, Parallel calculation of sensitivity derivatives for aircraft design using automatic diﬀerentiation, in: Proceedings of the 5th AIAA/NASA/USAF/ISSMO Symposium on Multidisciplinary Analysis and Optimization, m AIAA
94-4261, American Institute of Aeronautics and Astronautics, 1994, pp. 73–84.
[8] A. Griewank, J. Utke, A. Walther, Evaluating higher derivative tensors by forward propagation of univariate Taylor series, Mathematics
of Computation 69 (2000) 1117–1130.
[9] ROSE compiler infrastructure, http://www.rosecompiler.org/.
[10] L. Hasco¨et, V. Pascual, The Tapenade Automatic Diﬀerentiation tool: principles, model, and speciﬁcation, To appear, ACM Transactions
on Mathematical Software.
[11] J. Utke, U. Naumann, M. Fagan, N. Tallent, M. Strout, P. Heimbach, C. Hill, C. Wunsch, OpenAD/F: A modular, opensource tool for automatic diﬀerentiation of Fortran codes, ACM Transactions on Mathematical Software 34 (4) (2008) 18:1–18:36.
doi:10.1145/1377596.1377598.
[12] S. H. K. Narayanan, B. Norris, B. Winnicka, Adic2: Development of a component source transformation system for diﬀerentiating c and
c++, Procedia Computer Science 1 (1) (2010) 1845 – 1853, iCCS 2010. doi:DOI: 10.1016/j.procs.2010.04.206.
URL http://www.sciencedirect.com/science/article/pii/S1877050910002073
[13] A. Griewank, D. Juedes, J. Utke, Algorithm 755: ADOL-C: A package for the automatic diﬀerentiation of algorithms written in C/C++,
ACM Transactions on Mathematical Software 22 (2) (1996) 131–167.
URL http://doi.acm.org/10.1145/229473.229474
[14] J. D. Pryce, J. K. Reid, ADO1, a Fortran 90 code for automatic diﬀerentiation, Tech. Rep. RAL-TR-1998-057, Rutherford Appleton
Laboratory, Chilton, Didcot, Oxfordshire, OX11 OQX, England (1998).
URL ftp://ftp.numerical.rl.ac.uk/pub/reports/prRAL98057.pdf
[15] D. Shiriaev, ADOL–F automatic diﬀerentiation of Fortran codes, in: M. Berz, C. H. Bischof, G. F. Corliss, A. Griewank (Eds.), Computational Diﬀerentiation: Techniques, Applications, and Tools, SIAM, Philadelphia, PA, 1996, pp. 375–384.
[16] I. Charpentier, J. Utke, Fast higher-order derivative tensors with Rapsodia, Optimization Methods & Software 24 (1) (2009) 1–14.
doi:10.1080/10556780802413769.
[17] M. Fagan, L. Hasco¨et, J. Utke, Data representation alternatives in semantically augmented numerical models, in: Proceedings of the
Sixth IEEE International Workshop on Source Code Analysis and Manipulation (SCAM 2006), IEEE Computer Society, Los Alamitos,
CA, USA, 2006, pp. 85–94. doi:10.1109/SCAM.2006.11.
[18] SCALE: A Comprehensive Modeling and Simulation Suite for Nuclear Safety Analysis and Design, ORNL/TM-2005/39, Version 6.1,
Oak Ridge National Laboratory, Oak Ridge, Tennessee (June 2011). available from Radiation Safety Information Computational Center
at Oak Ridge National Laboratory as CCC-785.
[19] B. T. Rearden, M. L. Williams, M. A. Jessee, D. E. Mueller, D. A. Wiarda, Sensitivity and uncertainty analysis capabilities and data in
SCALE, Nucl. Technol. 174 (2) (2011) 236–288.
[20] M. L. Williams, B. L. Broadhead, C. V. Parks, Eigenvalue sensitivity theory for resonance-shielded cross sections, Nucl. Sci. Eng. 138 (2)
(2001) 177–191.
[21] B. T. Rearden, J. E. Horwedel, Automatic diﬀerentiation with code coupling and applications to SCALE modules, in: Proceedings
of Mathematics and Computations and Supercomputing in Nuclear Applications,Monterey, CA, American Nuclear Society, Curran
Associates, Inc., April 15-19, 2007, pp. 974–983.
[22] D. Buntinas, A. J. Malozemoﬀ, J. Utke, Multithreaded derivative computation with generated libraries, Journal of Computational Science
1 (2) (2010) 89 – 97. doi:DOI: 10.1016/j.jocs.2010.03.009.
URL http://www.sciencedirect.com/science/article/B9HC1-4YT6DGV-4/2/f9e999964ccb5b925f9a2a4d60917ce7

