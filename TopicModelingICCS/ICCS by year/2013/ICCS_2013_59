Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 1302 – 1311

International Conference on Computational Science, ICCS 2013

A mathematical method for online autotuning of power and
energy consumption with corrected temperature eﬀects
Reiji Sudaa , Luo Chenga , Takahiro Katagirib
a Graduate

School of Information Science and Technology, the University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan
b Information Technology Center, the University of Tokyo, 2-11-16 Yayoi, Bunkyo-ku, Tokyo 113-8658, Japan

Abstract
This paper discusses a method of online autotuning of power or energy consumption. A problem of online power modeling is
the strong positive inﬂuence of the temperature on the power consumption. Without proper treatment of the temperature, an
autotuning mechanism will misunderstand a variant measured at a low temperature to be power-eﬃcient. This paper proposes
a model of the relation between power and temperature, a Bayesian inference formula to estimate the power consumption with
estimates of estimation errors, and an experimental design (i.e. algorithm of choosing variants) for online autotuning. The
proposed methods are evaluated by simulation, and applied to online power and energy optimizations.
Keywords: Autotuning; Power; Energy; Temperature; Cost Modeling; Experimental Design

1. Introduction
Power consumption is one of the most signiﬁcant issues of designing computer systems because of several
reasons. First, the clock frequency of computers no longer scales with the feature size of semiconductor devices,
and now is bounded by the power consumption. Second, the total performance of a big computer system is
limited by the power supply and the cooling facilities. Third, high power consumption could be problematic in the
electricity cost and the CO2 emission. Fourth, a higher temperature raises the hardware error rate, and possibly
reduces the durability. Fifth, speciﬁcally in Japan after the big earthquake on March 11, 2011, regional electricity
usage is sometimes limited, and we had to control the usage of electricity.
Thus there are many reasons to seek a control of the power consumption of computers. Till now, the power and
the temperature of computers are controlled mostly by hardware and low-level software. However, in the future,
power control and optimization by software are expected to be utilized in a higher degree. Currently the most
eﬀective software switches of power consumption are DVFS (Dynamic Voltage and Frequency Scaling) and ACPI
(Advanced Conﬁguration and Power Interface). Fine grain power control such as power gating is not yet controllable from high-level software. Other power control mechanisms, such as power control of accelerating processor
(such as GPU) and network links, will be utilized more in the future. In that prospect, we are investigating methods
of power control by software.
There are several existing research results on software control of power consumption [1, 2, 3]. In this paper,
we develop a method of autotuning for power control. The problem here is the inﬂuence of the temperature on
E-mail address: reiji@is.s.u-tokyo.ac.jp.

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.297

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

1303

the power consumption, that is, a higher power is consumed when the temperature is higher. It is known that this
is because a higher leak current at a higher temperature.Our measurements will be shown in Figures 3 and 4 in
section 4.
The temperature eﬀect brings a problem in autotuning of power and energy. We have tried to autotune power
with our previous method [4], but it failed to choose optimal tuning parameter. We found that our algorithm
misunderstood a tuning parameter run at a low temperature to be power-eﬃcient. Thus we have to develop a new
autotuning algorithm of power optimization.
To avoid such a misoptimization, we introduce an explicit treatment of the temperature in the performance
model using Bayesian formulation. The present work has some novelty in the autotuning research community.
First, as far as authors’ knowledge, this work is the ﬁrst of explicit treatment of the temperature for eﬃcient
experimental design of autotuning of power and energy consumptions. Second, this is the ﬁrst work of online
autotuning (deﬁned in the next section) for power optimization. Third, it provides mathematic treatments of the
nuisance parameters, while they were treated heuristically in the autotuning literature. Remember that a nuisance
parameter is a parameter that inﬂuences the observations, and without proper treatment, statistical methods will
fail. Fourth, this is the ﬁrst work of an application of the one-step approximation, our own experimental design
algorithm for autotuning[4], to a problem with a nuisance parameter.
2. Autotuning Concepts
In this section, we brieﬂy review concepts and terms of autotuning we use in this paper. We mostly follow the
description in [5].
Autotuning is a software technology to optimize performance by controlling tuning parameters in the software.
The performance to be optimized is deﬁned with costs, which can be execution time, computation error, power
consumption, energy consumption, etc. Tuning parameters correspond to values of tunable variables and/or variants of software implementations, and are expected to inﬂuence only on the performance, not on the functionality.
In this paper, each value of tuning parameter is called candidate. Various kinds of eﬀective tunable variables and
implementation variants for performance tuning are known, as discussed in [5]. In this paper, we consider mathematical formulation for autotuning, and do not discuss speciﬁc kinds of variants eﬀective for power control. We
assume that a tuning parameter is given and the power consumption can be measured. The software is executed
with various values of the tuning parameter with measuring the power consumption, and the tuning parameter
should be controlled so to minimize the power consumption or the energy consumption.
There are two kinds of software executions for autotuning. One is practice, that is a practical usage of the
software with measurements of costs. The other is trial, an execution only for cost measurements, where the
computed results are discarded. Online autotuning is autotuning only with practices. Oﬄine autotuning is autotuning only with trials before any practice, and a single parameter value is chosen for all practical executions. It is
known that online autotuning corresponds to multi-armed bandit problem, and oﬄine autotuning corresponds to
sequential sampling problem [6]. One of the claims of this paper is that online autotuning is a better formulation
for power optimization than oﬄine autotuning.
3. Proposed method
This section explains our method. Our aim is to design an autotuning algorithm that chooses power-eﬃcient
candidates. It should be eﬃcient in the sense that it can choose good candidate without requiring a large number
of experiments. Also it should work with much missing values, lacking a way of controlling temperature.
The assumptions in section 3.1 and Bayesian inference in section 3.2 are presented in our previous work [7].
The contribution of this paper is on the experimental design in section 3.3 and the evaluations in section 4.
3.1. Assumptions
First, our assumptions are presented.
A single tuning parameter i is given, and it can take one of the values from a ﬁnite set of candidates {1, 2, . . . , M}.
The processor temperature can be measured at any time, and discretized into a ﬁnite set of possible values
{t1 , t2 , . . . , tN }.

1304

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

Let μi j be the average power consumption at an execution with parameter i and temperature t j . In this paper, i
is always used to identify the tuning parameter, and j is used for the index of the temperature. Let (i, j) represent
a situation of choosing candidate i at temperature t j . We assume that the measurement error is normal, and
independent from the parameter i and the temperature t j . Let σ2 be the variance, common for all (i, j). Formally
it is expressed as:
yi jk = μi j +

i jk ,

∼ N(0, σ2 ),

where yi jk is the power consumption of kth execution with (i, j), i jk is a perturbation from true mean μi j , and
N(μ, σ2 ) stands for a normal distribution with mean μ and variance σ2 . To keep brevity of presentation, we
assume that σ2 is known.
The temperature has a positive impact on the power consumption. We assume a simple linear model
μi j ≈ ai + bt j ,

(1)

where ai and b are unknown constants. The base power consumption with diﬀerent tuning parameter i is expressed
with ai , and the eﬀect b of the temperature t j on the power consumption μi j is assumed independent from the tuning
parameter i. To be more speciﬁc, we assume a Bayesian prior distribution for the average power μi j as
μi j = ai + bt j + δi j ,

δi j ∼ N(0, τ2 ).

(2)

Here δi j represents the deviation of the real power consumption μi j from the simple model ai + bt j . The parameter
τ2 signiﬁes how precise the model is. We assume that τ2 is known, again for brevity.
It is important to choose a simple but eﬀective model to attain a good autotuning. If a model has many unknowns, then it requires many experiments to estimate the unknowns. The proposed model (1) is minimal to
represent the behavior of the power consumptions with diﬀerent tuning parameter and the eﬀects of the temperature. Note that the model (2) allows the true mean power μi j to deviate from the model (1), and thus diﬀerent
candidates can be power-optimal at diﬀerent temperatures.
Further we assume Bayesian priors for the unknown parameters ai and b. Such a scheme is known as hierarchical Bayes approach[8]. Our models for ai and b are
ai ∼ N(a0 , τ2a ),

b ∼ N(0, τ2b ),

where mean a0 is unknown and variances τ2a and τ2b are assumed to be known. The model ai ∼ N(a0 , τ2a ) means
that, the average of ai s is a0 and the variance is τ2a . It is probable that such an average and a variance exist. The
other model b ∼ N(0, τ2b ) means that the magnitude of the constant b will not be much bigger than τb . In our
previous experiments, we observed that the measurement errors are sometimes too big and the estimation of b
could be very far from the true trend. The proposed model can limit the estimate of b in a certain range, without
explicitly saying the value. If we have some prior information of an approximate value of b, then we could set a
prior mean for b. At last, we assume a non-informative prior for a0 , that is, we have no speciﬁc assumption on a0 .
3.2. Bayesian Inference
From the assumptions described in the previous subsection, we can derive a posterior distribution of μi j from
the measured power yi jk . The derivation is given in [7], and omitted in this paper. The result is as follows:
ˆ S),
μ ∼ N(μ,
where μ is a vector containing μi j . The estimate of μ is μˆ with variance-covariance matrix S. Here μˆ is deﬁned as
μˆ = S−1 Σ¯y.
Σ is deﬁned as
Σ = diag(σ−2 n),
where n is a vector containing ni j s, which are the numbers of measurements with (i, j). S is given as
ˆ a K,
S = Σ + τ−2 I MN − (ˆτ2b τ−4 )T T − K T

(3)

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

1305

where I MN is an identity matrix with size MN (here M is the number of the candidates, and N is the number of
discretized temperature values), and τˆ 2b is a constant determined by
1
1
Mt t
= 2+ 2
2
τ
τˆ b τb
with t = (t1 , t2 , . . . , tN ) . T is a row vector of length MN deﬁned as
T = t ⊗ 1M ,
where 1 M is a vector with M 1s, and ⊗ represents a Kronecker product. K is an M × MN matrix with
K = τ−2 J − τˆ 2b τ−4 N t¯1 M T,
ˆ a is an M × M matrix deﬁned as
where J = 1N ⊗ I M and t¯ = N −1 1N t. T
⎞
⎛ −1
τˆ 2b N 2 t¯2 ⎟⎟⎟
⎜⎜⎜ M
1
N
−1
ˆ
⎟⎠ 1 M 1 M .
⎜
Ta = 2 + 2 I M − ⎝ 2 +
τa τ
τa
τ4
3.3. Experimental Design
In this section, we propose a method of online autotuning for power optimization. The following method
determines which candidate should be chosen at each execution. This problem is known as experimental design.
The ﬁrst execution is done with a random candidate. This is the initial experimental design for our model.
We need only one execution for initial experimental design, because we assume the variances are known. If the
variances are unknown (which is more probable), then we need more executions for initial experimental design to
get an initial guesses of the variances.
At the second and later executions, the tuning parameter is set as follows. Before each execution, the processor
temperature is measured. Then the Bayesian inference presented in 3.2 is computed, and μˆ and S are obtained.
We pick up the parts of μˆ and S−1 corresponding to the measured temperature t j , and make estimates as
μi j ∼ N(μˆ i j , τˆ 2i j )
where τˆ 2i j is a diagonal element of S−1 corresponding to (i, j). Then we apply the one-step approximation formula,
our own algorithm of experimental design presented in [4] and in 16.3.4 in [5], to determine the candidate at the
next execution.
To use one-step approximation, we need the number of remaining executions. In this work, it is the number of
remaining executions at the current temperature. But the problem is that we do not know the temperature at future
executions. So we compute the empirical distribution of the temperature in the past executions, and estimate what
percentages of the remaining executions are done at the current temperature. In this paper, we assume that the
number of total executions is known a priori. If it is unknown, then the number of past executions is used as an
approximate of the number of future executions. We will not report the results of unknown execution times, but
were not much diﬀerent from those of known execution times, presented below.
In this paper, we introduce a reduction of the computational cost of the Bayesian inference formula, as follows.
S is deﬁned in eq. (3), where the last three terms of the right hand side is independent of the experimental data.
Let Sk be the matrix S at the kth execution. Then we have
Sk+1 = Sk + ei j σ−2 ei j ,
where ei j is a vector with a single 1 as (i, j)th element and 0s for all the other elements. Then by using ShermanMorrison-Woodbury formula, we have
−1
S−1
k+1 = Sk −

−1
σ−2 S−1
k ei j ei j Sk

1 + σ−2 ei j S−1
k ei j

.

The above equation provides an algorithm to update S−1 in O((MN)2 ) time, while making S and taking its inverse
takes O((MN)3 ) time. When we observe an unseen temperature, we increase N by one, compute new S, and take
its inverse in O((MN)3 ) time.

1306

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

4. Experiments
In this section, the proposed method is evaluated in experiments. First, the proposed method is evaluated using
simulation, that is, using artiﬁcial data generated by random numbers. There, our method is evaluated in two ways
using simulation. First, the Bayesian inference is evaluated in its capability of power prediction. Second, the
online experimental design algorithm is evaluated in its performance of power optimization. After that, we apply
our method to a power and an energy optimization of real software on a real machine.
4.1. Simulation method
We use the term simulation for numerical experiments with artiﬁcial data generated by using random numbers.
In this subsection, we describe how those data are generated.
For the ﬁrst evaluation, we set the following parameters:
M = 5,
N = 7,
σ2 = 102 ,

a = (170, 173, 177, 180, 200),
t = (32, 33, 34, 35, 36, 37, 38),
τ2 = 102 ,

(4)
(5)

τ2a = V AR(a),

τ2b = 102 ,

b=

τ2b

(6)

They are artiﬁcial values, though chosen to mimic some real situation. The true mean power μi j is generated as
μi j = ai + b(t j − 170) + δi j ,

δi j ∼ N(0, τ2 ).

(7)

Table 1 shows an example set of μi j values thus generated. Candidate 0 has the minimum base power a0 = 170,
but other choices can be more power eﬃcient than 0 in some temperatures.
Table 1. An example set of generated power values for simulation.
Temperature
32
33
Candidate 0 (a0 = 170)
176.1
169.4
Candidate 1 (a1 = 173)
178.6
176.5
194.5
205.7
Candidate 2 (a2 = 177)
Candidate 3 (a3 = 180)
182.7
198.0
212.3
198.4
Candidate 4 (a4 = 220)

Minimum power for each temperature is shown in bold faces.
34
35
36
37
186.4
211.5
235.7
215.0
189.4
203.1
215.2
208.7
198.6
196.6
226.2
217.6
183.2
196.2
227.0
220.9
215.4
230.2
234.1
236.0

38
225.4
250.4
237.3
242.6
262.3

The processor temperature changes depending on several factors, such as the executed computations, the
fan speeds, the room temperature, and so forth. We build an artiﬁcial model of the processor temperature that
mimics the behavior of the processor temperature that we have observed in experiments. We do not claim that
the following model quantitatively approximates the behavior of processor temperature. We approximate the
following observations in our model: (1) After an idle state, the processor temperature is relatively low. (2) When
we start executions, the temperature raises quickly. (3) In repeated executions, the temperature may still increase
slowly. (4) When we repeat a computation with high power consumption, the processor temperature stays at a
high value. (5) The measured temperature perturbs a little (one or two degrees) in a stable repeat of computations.
Our model mimics the above behavior of the temperature as follows. First, we deﬁne a vector of target
temperatures s as:
s = (35.0, 35.3, 35.7, 36, 38).
Those target temperatures mean that, if the i is repeated inﬁnitely many times, then the average temperature will
be si . The values of si is computed by
si = 0.1(ai − 170) + 35.
When the temperature before an execution with candidate i is t j , then the temperature after the execution t x is
generated as
t x = round(αt j + (1 − α)si + u),
where round(x) represents a rounding to an integer nearest to x, and u is a uniform random number from the range
[−1, 1]. We always start at the lowest temperature 32. An example of simulated temperature history is shown in
Fig. 2 (right), which is discussed later.

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

1307

4.2. Evaluation of the proposed Bayesian inference
In this subsection, we evaluate the Bayesian inference presented in section 3.2.

270

270

True Mean

230

210

Estimate

210

190

190

170

170

150

150
(candidate, temperature)

Observed Average

(1,32)
(2,32)
(3,32)
(4,32)
(5,32)
(1,33)
(2,33)
(3,33)
(4,33)
(5,33)
(1,34)
(2,34)
(3,34)
(4,34)
(5,34)
(1,35)
(2,35)
(3,35)
(4,35)
(5,35)
(1,36)
(2,36)
(3,36)
(4,36)
(5,36)
(1,37)
(2,37)
(3,37)
(4,37)
(5,37)
(1,38)
(2,38)
(3,38)
(4,38)
(5,38)

Estimate

(1,32)
(2,32)
(3,32)
(4,32)
(5,32)
(1,33)
(2,33)
(3,33)
(4,33)
(5,33)
(1,34)
(2,34)
(3,34)
(4,34)
(5,34)
(1,35)
(2,35)
(3,35)
(4,35)
(5,35)
(1,36)
(2,36)
(3,36)
(4,36)
(5,36)
(1,37)
(2,37)
(3,37)
(4,37)
(5,37)
(1,38)
(2,38)
(3,38)
(4,38)
(5,38)

power

230

True Mean
250

Observed Average

power

250

(candidate, temperature)

Fig. 1. (left) power estimation by Bayesian inference after 1 observation; (right) power estimation by Bayesian inference after 4 observations.

The left ﬁgure of Fig. 1 shows the Bayesian inference after a single observation. The initial temperature
was 32, and the candidate was randomly chosen as 3. It gives the power about 174, while the true mean of the
combination (3, 32) is about 194. In Fig. 1, the x axis corresponds to all combinations (i, j), and the y axis gives the
power (mean, observed, or estimated). The blue dots show the true mean power μi j , and the red crosses show the
observed average power y¯ i j , and the green bars show the estimated power μˆ i j ± τˆ i j . From just a single observation,
our model can ﬁnd no tendency, so the estimated power μˆ i j are same for all (i, j) (green bars in Fig. 1 (left)).
But the uncertainties (green error bars) are diﬀerent, and a lower uncertainty is estimated for observed candidate
(i = 3) and observed temperature (t j = 32).
The right ﬁgure of Fig. 2 shows the inference after 4 observations. The temperature is changed in the way
described in section 4.1, and the tuning parameter is set in the way described in section 3.3. Here, no candidate
has been chosen twice yet. Still our model predicts some trends of the power depending on the candidate and on
the temperature. The prior distributions described in section 3.1 enables such estimation, while no sign (positive
or negative) is suggested in the prior distribution.
Next, we restarted a simulation of 100 executions with μi j s given in Table 1. After 100 observations, the
Bayesian inference results as shown in the left ﬁgure of Fig. 2. In this simulation, the combinations (4, 35) and
(2, 36) were observed many times, and the error bars for those combinations are short. The temperature 32 was
observed only once, and the temperature 37 has never been observed. Still our model gives power predictions for
those temperatures. From those ﬁgures, our method seems to estimate the power consumptions without measuring
the power in some combinations (i, j).
4.3. Evaluation of the proposed experimental design
In this subsection, the proposed experimental design is evaluated via simulation. First, as a qualitative evaluation, we will check whether it does approximately minimize the power or not. Second, as a quantitative evaluation,
we will compare our method with other methods in terms of a statistical quantity called regret.
As is just explained, the left ﬁgure of Fig. 2 shows the Bayesian inference after 100 executions with the tuning
parameter set by our experimental design. The right ﬁgure of Fig. 2 plots the history of the temperature and the
tuning parameter for each execution. The temperature quickly went up after the start of the executions, and stayed
from 35 to 37. As shown in Table 1, the candidate that gives the lowest power at temperature 35 is 4, and it is 2
for temperature 35 and 36. Our experimental design chose those power-optimal parameters for most executions
after the 43rd execution.
Next, we compare our proposal with some other methods quantitatively. The methods of experimental design
to be compared are the following four.

1308

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

38

6

270
True Mean
250

36

Candidate

210
190
170

4

34
3

Temperature

Estimate

230
power

5

Observed Average

32

2

Candidate (left axis)

(1,32)
(2,32)
(3,32)
(4,32)
(5,32)
(1,33)
(2,33)
(3,33)
(4,33)
(5,33)
(1,34)
(2,34)
(3,34)
(4,34)
(5,34)
(1,35)
(2,35)
(3,35)
(4,35)
(5,35)
(1,36)
(2,36)
(3,36)
(4,36)
(5,36)
(1,37)
(2,37)
(3,37)
(4,37)
(5,37)
(1,38)
(2,38)
(3,38)
(4,38)
(5,38)

150
(candidate, temperature)

Temperature (right axis)

1
1

11

21

31

41
51
61
execution

71

81

30

91

Fig. 2. (left) power estimation by Bayesian inference; (right) history of temperature and parameter selection.

1. Method 0 (Random). This method chooses a random candidate. This method is used only to see the eﬀects
of autotuning.
2. Method 1 (Minimum). In this method, the power is measured for each pair (i, j) of candidate i and temperature t j . Let t j be the current temperature. If there is some value i that has never been observed for the
temperature t j , then one of such values is chosen. If all the values are observed for the temperature t j , then
the value that gives the minimum average power at that temperature is chosen. Thus this method does not
use any modeling, and does not consider the measurement perturbation.
3. Method 2 (No-temp). In this method, our own method of one-step approximation is used without considering the inﬂuence of the temperature on the power.
4. Method 3 (Proposed). The method presented in section 3.
The methods are evaluated in the total cost deﬁned as follows. The number of the total executions is 100. Let
yzk be the observed power of the kth execution with Method z, and let Yz be the sum of yzk s:
100

Yz =

yzk ,
k=1

which roughly corresponds to the average power consumption of Method z. Next we deﬁne the ideal power
consumption as follows. Let μ¯ j the minimum true mean power at temperature t j :
μ¯ j = min{μi j }.
j

Let Nz j be the number of executions at temperature t j among the 100 executions produced by Method z (thus we
have j Nz j = 100). Then the “ideal” total power consumption Y¯ z is deﬁned as
Y¯ z =

Nz j μ¯ j .
j

Note that Y¯ z depends on the history of the temperature, and the temperature depends on the choice of the candidates, and thus Y¯ z depends on Method z. Then we can deﬁne the regret Rz as
Rz = Yz − Y¯ z ,
which gives how much overheads were enforced by the Method z compared with the ideal power consumption.
Note that comparison of regret is more appropriate than comparison of average power. The average depends on
the temperature, so it could be high however an algorithm chooses good candidates. The above regret is deﬁned
so to reduce the eﬀects of the temperature in the evaluation of the algorithms.

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

Table 2. Parameter sets for evaluations. Parameters not shown are set as Eqs. (4), (5) and (6).
a
Parameter 1
(170, 173, 177, 180, 220)
Parameter 2
(170, 178, 183, 190, 200)
Parameter 3
(170, 170, 170, 170, 170)

σ2
100.0
100.0
1.0

1309

τ2a
419.5
131.2
10.0

We generated 10,000 sets of μi j s following Eq. (7), run simulations, and computed the regret Rz for each set.
The average R¯ and the variance V of the 10,000 regrets are computed, and are shown in the form R¯ ± V/104 ,
which gives a conﬁdence interval of the regret Rz .
First we run simulation with the set of parameters given in Eqs. (4), (5) and (6), which is referred as Parameter
1. We deﬁned other two sets of parameters, Parameter 2 and Parameter 3, as shown in Table 2. In Parameter 1,
the powers of the ﬁrst four candidates are close to each other, and there are some possibilities that the candidate
0 is not the optimal in power. In Parameter 2, the powers of the last four candidates are fairly far from candidate
0, so candidate 0 may well be the optimal in all temperature. For Parameter 2, Method 2 behaves better than
Parameter 1, because the optimal candidate is consistent for all temperatures. In Parameter 3, the base powers
of the all candidates are the same, and thus the optimal tuning parameter are diﬀerent for diﬀerent temperatures.
Also a lower value of σ2 is chosen, thus the mean power can be estimated well without repetitive observations.
Thus Parameter 3 is designed so that Method 1 behaves well.
Table 3. Regrets produced by the experimental design methods.
Method 0 (Random)
Method 1 (Minimum)
Parameter 1
2028.9 ± 3.7
646.8 ± 1.7
Parameter 2
1766.6 ± 3.9
529.2 ± 1.8
Parameter 3
1161.8 ± 3.0
239.9 ± 0.6

Method 2 (No-temp)
721.3 ± 4.2
584.4 ± 4.3
684.7 ± 3.4

Method 3 (Proposed)
352.6 ± 1.8
321.6 ± 1.7
213.6 ± 0.6

The evaluated regrets are shown in Table 3. In all parameter sets, Method 3 (Proposed) gives the smallest
regret. As is expected, Method 2 (No-temp) behaves relatively well for Parameter 2, and Method 1 (Minimum)
behaves well for Parameter 3. Method 1 and Method 2 are much better than Method 0 (Random), thus they are
not ineﬀective as experimental designs. But they did not outperform Method 3.
We noticed that Method 2 gives relatively large variances of regrets than Method 1 and Method 3. This is
because Method 2 does not consider the eﬀects of the temperature on the power, so it often chooses bad tuning
parameter. That brings higher power consumption, and the variance becomes larger.
4.4. Application to power and energy optimizations
Last, we apply our method to online power and energy optimizations. The target computation is a multiplication of two 800 × 800 matrices, and it is unrolled by ABCLibScript [9], which is a directive-based programming
tool for autotuning. In our experiments, it is used for generating 10 codes with diﬀerent unroll factors. The power
is measured by the method described in our previous work [10]. The machine is equipped with Intel Celeron
DualCore E3400, 2 GB DDR2 RAM and Tesla C2075 GPU, and Ubuntu 11.04 is installed. The computation is
done on the CPU, and the GPU is used to synchronize power measurement tools and the CPU as described in
[10]. The GPU consumes about 155W (in its idle state), which is more than half of the machine power. The CPU
has two cores, and we regard the average of the temperatures of the two cores as the processor temperature. The
number of executions was 100.
The left ﬁgure of Fig. 3 shows the history of the temperature and the chosen candidates. The temperature
started at a low value, and rose to values around 44. The chosen candidates are almost random. This is because
the 10 routines gave almost the same powers. The right ﬁgure of Fig. 3 shows the Bayesian power model after
100 executions. First note that the eﬀects of the temperature on the power are clear. However, we could not ﬁnd
signiﬁcant diﬀerence of the powers with diﬀerent candidates. Unfortunately, the optimizing eﬀects of our method
have not been observed, however, our method was able to successfully avoid mispredictions caused by the eﬀects
of the temperature on the power. We omit the results of the power consumptions, but were similar to that shown
in Fig. 5 (right).

1310

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

9

45

290

8

43

5
4

42

3
2

Estimated power

Candidate

6

Temperature

44

7

280

270

41

1

40
61

71

81

260

91

Execution

(0,44.5)

51

(0,44.0)

41

(0,43.5)

31

(0,43.0)

21

(0,42.5)

11

(0,42.0)

1

(0,41.5)

0

Fig. 3. (left) history of temperature and candidates in online power optimization; (right) power model after 100 executions.

9

46

290

8

44

5
4

43

3
2

Estimated power

Candidate

6

Temperature

45

7

280

270

42

1
71

81

91

260
(0,45.0)

Execution

61

(0,44.5)

51

(0,44.0)

41

(0,43.5)

31

(0,42.5)

21

(0,42.0)

11

(0,41.5)

1

(0,41.0)

41

0

Fig. 4. (left) history of temperature and candidates in online energy optimization; (right) power model after 100 executions.

Next, we modify our algorithm for the energy (the product of the power consumption and the elapsed time) as
the objective function in the experimental design. The left ﬁgure of Fig. 4 plots the histories of the temperature
and the candidates. In this run, the tuning parameter converged to 1. The estimated power model is shown in the
right ﬁgure of Fig. 4. As the values from 3 to 9 are observed only once, the uncertainties of the powers of those
candidates are very high. Still it was enough for our method to choose value 1 because of its short execution time.
The left ﬁgure of Fig. 5 shows the estimated execution time: the error bars are shown, but too small to recognize.
The right ﬁgure of Fig. 5 plots the histories of the power and the energy consumptions. It seems that our method
successfully optimize the energy consumption online.
Last, we make a remark on our choice of online autotuning rather than oﬄine autotuning. Before this work,
we have built Bayesian estimations of the base power ai s by using a similar technique as that discussed in section
3.2, and deﬁned an experimental design for oﬄine power autotuning. But the estimates of ai s did not converge.
We analyzed the reason as follows. Some values of low temperature are observed only a few times, and thus some
values of true mean power μi j s cannot be estimated in high precision. Then we cannot determine the base power
ai s and the power-temperature coeﬃcient b in high precision. Without determining good estimates for μi j s (or ai s),
we cannot ﬁx which candidate is best for each temperature (or in average). On the contrary, in online autotuning,
the power estimate μˆ i j converges for frequently observed temperature t j , and we can build power model as much
as the observed values of the temperature. Thus, at least in our work, only online autotuning can be proved to
optimize the power.

1311

Reiji Suda et al. / Procedia Computer Science 18 (2013) 1302 – 1311

Energy (right axis)

280

4.5

4.0

3.5

1300

Power (left axis)

1200

275

1100

270

1000
900

265

Candidate

9

8

7

6

5

4

3

2

1

0

3.0

Energy

285

Power

Estimated time

5.0

1

11

21

31

41

51

61

71

81

91

Execution

Fig. 5. (left) Bayesian time model after 100 executions; (right) history of power and energy in online energy optimization.

5. Conclusion
In this paper, we have discussed a method of online autotuning for power and energy optimization. Our method
consists of a model of relation between temperature and power, a Bayesian inference formula, and an experimental
design algorithm. We have evaluated our method in simulation and experiments. The proposed online autotuning
method can provide power optimization.
We have several topics of future work. First, we have assumed that the variances are known a priori, but
practically the variances must be estimated online. Second, the computational costs and memory costs of the
proposed method could be reduced by introducing approximations. Third, we are planning to implement our
method in our software tools of autotuning.
Acknowledgements
We appreciate the reviewers for their valuable comments.
This work is partially supported by JST CREST Project “ULP-HPC: Ultra Low-Power, High-Performance
Computing via Modeling and Optimization of Next Generation HPC Technologies”.
References
[1] L. Benini, A survey of design technique for system-level dynamic power management, IEEE Trans VLSI 8 (2000) 299–316.
[2] Y. Wang, K. Ma, X. Wang, Temperature-constrained power control for chip multiprocessors with online model estimation, in: Proc.
ISCA 2009, ACM, 2009, pp. 314–324.
[3] C. Isci, A. Buyuktosunoglu, C.-Y. Cher, P. Bose, M. Martonosi, An analysis of eﬃcient multi-core global power management policies:
Maximizing performance for a given power budget, in: Proc. MICRO-39, 2006, pp. 347–358.
[4] R. Suda, A bayesian method for online code selection: Toward eﬃcient and robust methods of automatic tuning, in: Proc. Second
International Workshop on Automatic Performance Tuning (iWAPT2007), 2007, pp. 23–31.
[5] K. Naono, K. Teranishi, J. Cavazos, R. Suda, Software Automatic Tuning: From Concepts to the State-of-the-Art Results, Springer,
2010.
[6] R. Cailori, R. C. Dalang, Sequential Stochastic Optimization, John Wiley and Sons, Inc., 1996.
[7] R. Suda, Automatic tuning: Software performance improvements via mathematical methods, in: RIMS Kokyuroku, Kyoto University,
to appear.
[8] B. P. Carlin, T. A. Louis, Bayes and Empirical Bayes Methods for Data Analysis, Chapman and Hall, 2000.
[9] T. Katagiri, K. Kise, H. Honda, T. Yuba, Abclibscript: A directive to support speciﬁcation of an auto-tuning facility for numerical
software, Parallel Computing 32 (2006) 92–112.
[10] C. Luo, K. Rocki, R. Suda, A precise measurement tool for power dissipation of cuda kernels, in: IPSJ SIG Technical Reports, Vol.
2012-HPC-133, 2012.

