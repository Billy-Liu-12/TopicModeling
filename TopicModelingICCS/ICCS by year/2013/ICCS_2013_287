Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 2028 – 2035

2013 International Conference on Computational Science

DDDAMS-based Crowd Control via UAVs and UGVs
Zhenrui Wanga, Mingyang Lia, Amirreza M. Khaleghia, Dong Xua, Alfonso Lobosa,
Christopher Vob, Jyh-Ming Lienb, Jian Liua, Young-Jun Sona, *
a

Systems and Industrial Engineering, The University of Arizona, Tucson, AZ 85721-0020, USA
b
Computer Science, George Mason University, Fairfax, VA 22030, USA

Abstract
Unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) collaboratively play central roles in intelligence
gathering and control in urban/border surveillance and crowd control. In this paper, we first propose a comprehensive
planning and control framework based on dynamic-data-driven, adaptive multi-scale simulation (DDDAMS). We then
discuss proposed algorithms enabling DDDAMS capability based on several methods such as 1) Bayesian-based
information aggregation/disaggregation, 2) dynamic information updating based on observation/simulation, 3) temporal and
spatial data fusion for enhanced performance, 4) multi-resolution strategy in temporal tracking frequency, and 5) cached
intelligent observers. Finally, preliminary results based on the proposed framework, algorithms, and testbeds are discussed.
© 2013
2013The
TheAuthors.
Authors. Published
Published by
by Elsevier
Elsevier B.V.
B.V. Open access under CC BY-NC-ND license.
©
Selection
peerpeer-review
review under
responsibility
of the
of the
International
Conference
on Computational
Selectionand
and/or
under
responsibility
of organizers
the organizers
of2013
the 2013
International
Conference
on Computational
Science
Science
Keywords: Crowd control; UAV; UGV; multi-scale; agent-based simulation

1. Introduction
Unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) collaboratively play central roles
in information gathering and control in border/urban surveillance and crowd control. Scalable, robust, and
effective monitoring, tracking, and control of crowd is challenging as the considered systems are highly
complex, dynamic, and uncertain, involving human behaviors, numerous autonomous hardware and software
technologies, and environmental conditions. The goal of our long-term research is to investigate algorithmic
approaches to create scalable, robust, multi-scale, and effective urban surveillance and crowd control strategies
using UAVs and UGVs. Scalability will provide group control over behavior-rich group with hundreds to
thousands of group members. Robustness will allow the controller agents (UAVs and UGVs) to generate

* Corresponding author. Tel.: +1-520-626-9530; fax: +1-520-621-6555.
E-mail address: son@sie.arizona.edu.

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.372

Zhenrui Wang et al. / Procedia Computer Science 18 (2013) 2028 – 2035

2029

control strategy even when the behaviors of the controlled group are not well modeled due to many sources of
inevitable uncertainty. In order to achieve our objective, we have proposed a comprehensive planning and
control framework based on dynamic-data-driven, adaptive multi-scale simulation (DDDAMS), where dynamic
data is incorporated into simulation, simulation steers the measurement process for data update and system
control, and an appropriate level of simulation fidelity is selected based on the time constraints for evaluating
alternative control policies using simulation. In our research, the DDDAMS framework that was developed by
the authors for the case of extended manufacturing enterprise [1] has been leveraged to address scalable, robust,
multi-scale, and effective surveillance and crowd control via UAVs and UGVs.
The particular goal of this paper is three-fold. First, the proposed DDDAMS-based planning and control
framework is discussed. Second, we discuss proposed algorithms enabling DDDAMS capability, where they
are based on several methods such as 1) Bayesian-based information aggregation/disaggregation among UAVs
and UGVs, 2) dynamic information updating based on observation/simulation, 3) temporal and spatial data
fusion for enhanced performance, 4) multi-resolution strategy in temporal tracking frequency, and 5) cached
intelligent observers. Third, we discuss testbeds involving real UAVs and other virtual components.
2. Proposed DDDAMS-based Planning and Control Framework
2.1. Scenario: Surveillance and Crowd Control
In the surveillance of a crowd, UGVs and UAVs collaborate in a complementary manner to achieve
detecting, tracking and control of individuals in the crowd [2]. Specifically, UAVs offer the searching
capability in a wider area and a global view of the crowd. However, the accuracy of the information on target
localization is restricted by various factors, such as the speed and altitude limits, on-board sensor resolution,
and environmental disturbances. UGVs, on
accurate sensing capability. However, their observation range is often smaller than that of UAVs and may be
obstructed by nearby obstacles. Fig 1 illustrates such information insufficiency if either UGVs or UAVs are
deployed alone. UGVs can observe dynamic movements of individual agents in a sub-crowd within their
observation range, with high resolution. UAVs can provide global but less accurate information on the overall
dynamic movement of the crowd. By integrating the information from both UGVs and UAVs up to time t, the
dynamics of the crowd region at future time horizon, e.g., time t+1, can be better estimated.

Fig. 1. Complementary role of the UGVs and UAVs

2.2. Overview of DDDAMS-based Planning and Control Framework
Fig 2 depicts the proposed DDDAMS-based planning and control framework, in which decision planner,
controller and real system are integrated for surveillance and crowd control via UAVs and UGVs. Switching
between planning and control occurs on a temporal basis or event basis. While planning is performed for equal
intervals under the temporal mechanism, planning under the event-based mechanism is triggered when a

2030

Zhenrui Wang et al. / Procedia Computer Science 18 (2013) 2028 – 2035

deviation between planned and observed system performances exceeds a threshold value. The system
performance criteria include generic measurement of effectiveness (MOE) for UAV/UGV mission tasks, where
the common ones are the probability of object detection and the duration percentage of successful tracking.

Fig. 2: DDDAMS-based planning and control framework

During the planning stage, a decision planner, which has been implemented in an agent-based simulation
environment, will devise a set of best UAV/UGV control strategies for the evolution of real system. Various
algorithms (e.g. UAV/UGV searching, detection, tracking, path planning) are implemented in the agent-based
simulation, which helps evaluate alternative control strategies against different scenarios. For instance,
UAV/UGV path planning algorithm involves selecting one from deterministic, probabilistic, and mixed
strategies (to list a few). Under a similar problem setting, the results may vary according to different choices of
strategy [3,4]. In addition, as different algorithms (e.g. tracking, path planning) are integrated in the same
simulation environment, strategy interactions and trade-offs should be considered for achieving the best system
level performance in favor of individual algorithm performance. Next, each potential strategy combination is
initialized as an instance for simulation-based evaluation. At the final step, statistical analyses (e.g. confidence
interval, hypothesis testing) are performed for selecting the best control strategies due to the variations
inherently in the simulation outputs. In this work, the agent-based simulation models have been implemented in
Repast Simphony® (see Fig 3(a)), and the statistical tool used is R®.
At the control side, an integrated controller consisting of four individual components (i.e. decision maker,
executor, monitor, and performance analyzer) has been developed. The decision maker 1) utilizes the best
control strategies to generate real-time commands (e.g. velocity, waypoints) for UAV/UGV operations, and 2)
to invoke the decision planner when the actual system performance deviates substantially from the predicted
system performance. The executor is directly linked with decision maker for receiving commands and sending
them into the real system. The communication between real hardware and executor is performed using opensource micro air vehicle communication protocol called MAVLink. The monitor updates the entire system
status based on feedback information (e.g. video, sensory data) from the real system, and then forwards it to the
performance analyzer. An open source, cross-platform software package called QGroundControl®, has been

Zhenrui Wang et al. / Procedia Computer Science 18 (2013) 2028 – 2035

2031

employed in this work, which has implemented the functionality of executor and monitor (see Fig 3(b)).
Finally, the performance analyzer 1) processes the picture, video stream, and sensory data transformation and
linking the transformed data with the performance criteria and 2) compares the actual and predicted system
performance and calls for the decision maker if necessary. Currently, the software implementation for the
performance analyzer consists of different algorithms (e.g. motion detection algorithm, motion tracking
algorithm) in OpenCV® (Open Source Computer Vision). Fig 3(c) depicts the quad copter that has been
developed at University of Arizona and George Mason University, which includes 5000 mAh battery, GPS,
telemetry, and can handle an additional payload of 1200g for at least 25 minutes. The real UAVs with virtual
components in the simulation constitute testbeds that can be used to evaluate the proposed control framework.

Fig. 3. (a) Snapshot of agent-based simulation; (b) Snapshot of QGroundControl® with waypoints; (c) UAVs available at UA and GM

3. Proposed Algorithms Enabling DDDAMS Capability
3.1. Crowd Motion Modeling
M, for individual agents in a crowd at time t, where
In this research, we adopt the state vector xi(t), i=1,
M is the total number of individual agents in the crowd, as depicted in Fig 1. The state vector contains state
information of an individual agent, including its preference state, such as moving speed and direction, and
geographic state, such as locations. Thus the preference state vectors are used as elements to model the
complex spatial/temporal problem. The state vector of a crowd at time t can be represented as a stack-up of all
(xM(t))T]T. The preference and geographic states of an
the M state vectors, i.e., x(t) = [(x1(t))T] (x2(t))T
individual agent at time t+1 are mainly affected by three types of factors: 1) the preference of crowd
individuals, including itself, at time t; 2) the environmental factors that affect crowd preferences; and 3) the
impacts of the controlling units, such as UAVs and UGVs. These complex relationships can be modeled by:

x(t 1)

A(t ) x(t ) Bf (t ) f (t ) Bu (t ) u(t ) w(t ) , t

(1)

where N is the total number of time steps; A(t) represents the moving dynamics of crowd agents; Bf(t)
s; Bu(t) represents the impacts of
represents the impacts of the environmental factors, f (t ) ,
; w(t) represents the un-modeled errors. The state vectors of
controlling activities, u(t )
individual agents may not be directly observable due to the resolution or range deficiency of sensors. Therefore,
a measurement model is often considered to represent the observation as a linear combination of true state
vector and observation noise, such as the one used in Kalman filter [5].
3.2. Crowd Motion Detection
Local motions necessary for the camera to maximize its visibility of the human crowd are considered. It is
noted that the camera motion is to locally adjust the camera locations/directions to achieve the best

2032

Zhenrui Wang et al. / Procedia Computer Science 18 (2013) 2028 – 2035

observations of the crowd. In most of the existing methods available in the literature, it is assumed that that
maintaining the visibility of a single reference point (e.g., the center of mass) will provide the visibility to the
entire target. However, it usually is not the case in the real world.

Fig 4. (a) A virtual city with 161 building; (b) Snapshots of CIOg camera following 30 targets in the city environment in (a)

Among widely known methods, the Intelligent Observer (IO) [6] camera provides a high success rate, but is
extremely inefficient. The Visibility-Aware Roadmap (VAR) [7] camera provides fast online tracking strategy
through the use of pre-computed visibility information, but it performs worse than IO in terms of visibility. To
address this issue, we propose two camera planning methods called Cached Intelligent Observers (CIO): CIOg
and CIOc [8]. These new methods provide comparable performance to both IO and VAR while reducing the
offline computation and maintaining efficiency in determining camera motions online. The main idea is to
incrementally build and cache the visibility information in the vicinity of the targets and the camera. These new
methods can be viewed as an improved IO camera that reduces the visibility computation complexity to almost
constant. The CIOg method begins by creating a two dimensional grid. For each grid point, CIOg caches a
certain amount of information about not only itself (such as its distance from the nearest obstacle), but also
about other grid points in the network (such as its visibility to other points). Like its predecessor, IO [6], at each
time step, CIOg uses prediction and evaluation of camera and target positions to try and find an ideal location
for the camera to maintain visibility of the as much of the flock as possible for the next time step. In CIOc, a
slightly different approach is taken to storing visibility information in the space. First, using disc-like partitions,
a graph is computed as well as a visibility graph among overlapping partitions of the workspace. As with CIOg,
these data structures are used with successive cycles of prediction and evaluation of future target and camera
positions to make decisions about where to move next. Fig. 4(b) shows an example of CIOg successfully
following 30 targets in the city environment shown in Fig. 4(a).
3.3. Crowd Motion Tracking and Controlling
Based on the observation of crowd motion, the crowd tracking algorithm can be developed. Different from
the camera planning algorithm, the objective of crowd tracking and controlling is to plan the moving paths of
UAVs and UGVs to follow and affect the crowd motion. This is achieved by predicting the location of
individual agents at next time step, based on the current observation achieved by CIOs. Various tracking
algorithms have been proposed in the literature, such as Kalman filter [5] and its extension [9], grid-based
tracking [10,11], and particle filter [12]. This paper adopts the Kalman filter for tracking of individual agents,
since Kalman filter has been proved to be optimal for linear dynamic systems with Gaussian noises, which is
often mathematically formulated with the state space model similar to Eq. (1).
Information collected from both UAVs and UGVs should be utilized together to capture the dynamic
characteristic of the overall crowd. The high resolution observations on sub-crowd or individuals collected by
direct observations of the overall crowd dynamics.
UGVs should be aggregated to be combined with
Denote the parameter set t { (t ), f (t ), u (t ), (t )} , which includes model parameters governing the crowd

Zhenrui Wang et al. / Procedia Computer Science 18 (2013) 2028 – 2035

2033

dynamics, where A(t ), Bf (t ), Bu (t ) are coefficient matrices for the state space model in Eq. (1), and (t ) refers
to the crowd region parameters. Let tA be the estimate based on direct observations, denoted as A , by the
UAVs with low resolution observations, its accuracy can be improved by combing the aggregated information
( i ), i 1,..., M , where i is the observation of the ith individual agent from UGVs.
from the UGVs, i.e. tG
G
is the estimate of t from aggregated information of the UGVs and ( ) is a link function for
t
aggregation. To compensate the information insufficiency of UAVs, tA and tG are combined to achieve a
better parameter estimation for the crowd dynamics as t wt tA (1 wt ) tG , where wt is a weighted scalar in
balancing the information. To improve the dynamic modeling of the individuals and/or subinformation can be disaggregated to lower-level of UGVs in compensating their disadvantages of limited
observation range. Let t ,i { i (t ), f ,i (t ), u,i (t )} denote the parameters in characterizing dynamics of the ith
individual agent, its estimation accuracy can be improved by disaggregating information from the UAVs, i.e.
A
G
( A ) , where ( )
t ,i
t ,i ,
A
G
as t ,i wt ,i t ,i (1 wt ,i ) t ,i .
Based on the predicted locations of individual agents in the crowd, UGVs need to determine the locations of
UGVs at the next time step. Since the objective of UGVs is to control the crowd, the optimal location at the
next time step for UGVs is the one that maximizes a given performance indicator. In this paper, coverage
probability is considered as the performance indicator, which can be calculated as the mean probability of
individual agents being controlled by UGVs. A higher probability indicates better control of the crowd.
4. Preliminary Results
To demonstrate the performance of the proposed approach, a simulation study is conducted. The study
considers the tracking and control of a crowd with M=10 individual agents in a certain area. One UAV and
three UGVs cooperatively achieve the detection, tracking and control of the crowd. Fig 5(a) gives an
illustration of the scenario, where the dots represent ten individual agents. The shaded region shows that these
ten agents form a small crowd and the arrow indicates that these ten agents move together to the right. The red
and green circles surrounding a UGV indicate its detection range (subject to sensor device capability and
environmental factors) and controllable range (subject to control device capability and environmental factors),
respectively. Two parameters, detection radius Rd and control radius Rc, Rd > Rc, are defined accordingly. The
detection radius is used to calculate a detection probability. The control radius, as well as the triangle region
formed by connecting the three UGVs, is used to calculate a coverage probability.
xi (t 1)

10 dt 0

xi (t )

ex ,i (t )

yi (t 1)

010 dt

yi (t )

ey ,i (t )

vx ,i (t 1)

0 01

vx ,i (t )

evx ,i (t )

v y ,i (t )

evy ,i (t )

v y ,i (t 1)

xi (t )
and

xi (t )

10 0

yi (t )

x ,i

yi (t )

010

vx ,i (t )

(t )

y ,i (t )

(2)

v y ,i (t )

In the simulation study, the initial locations of the individual agents are randomly generated from a bivariate
normal distribution with mean (0,0) and diagonal variance matrix being 0.01, with proper unit. The dynamics
of the individual agents are specified through the assumed state space model, shown in Eq. (2), where
vx ,i (t ) 0.15 and v y ,i (t ) 0 , i
M. The noises of locations and speed along x-axis and y-axis follow
normal distribution with mean 0 and variance 0.01. Individual agents move to the right with location and speed
impacted by additive Gaussian noise. To simplify this study, the environmental factors and control factors are
not considered.

2034

Zhenrui Wang et al. / Procedia Computer Science 18 (2013) 2028 – 2035

Due to the measurement accuracy of the sensors onboard the UGV, the observation model in Eq. (2) is used
to link the true state of the individual agents, and the observations [ xi (t ), yi (t )] show that the detected area are
formed with true state plus the additive Gaussian noise with mean 0 and variance 0.052.

UGV2

UAV

UGV1

UAV

UGV1

UGV3
Time t

UGV2

UGV3
Time t+1

Figure 5. (a) Illustration of simulated scenario; (b) Coverage probability of exemplary simulation run

As aforementioned, the individual agents may not be detected all the time. The UGVs detect them with a
probability, which is a function of distance and parameter Rd. In the study, this probability is specified as
is the cumulative distribution function of
Pr(detection)=2(1- (d / Rd ) ), where d denotes the distance,
standard normal distribution and detection radius Rd, Rd = 1.5, is used to quantify the detection capability.
Larger Rd indicates that when a distance between the UGV and individual agent is fixed, the UGV has a higher
detection probability.
tracking and controlling individual agents, the study assumes that
information disaggregation from UAV can improve the detection and control capability of UGVs. Specifically,
the det
as that without. The increased detection and control radius will improve tracking and control performance.
The predicted individual locations from Kalman filter are sent to UGVs so that path planning can be
performed. The study considers a simplified planning scenario where each UGV can either stop (i.e. staying in
the center of the three by three grids) or move to one of the eight neighboring grids. The combination of
candidate locations from all the three UGVs constitutes the search space for the optimal plan. Such a
combination of locations will be assigned to the UGVs at the next time step. The coverage probability is
defined as a function of UGV locations, predicted locations of individual agents, and a parameter Rc specifying
the control capability of UGV. As shown in Fig 5(a), for individual agents beyond the triangle formed by
UGVs, their probability of being controlled by a UGV in a distance d is given as Pr(control)=2(1- (d / Rc ) ),
with Rc=1.2. When the individual agent is within the triangle, the control probability is tripled. The overall
coverage probability of the whole crowd is the mean coverage probability of individual agents.
The simulation experiment is conducted 100 replications to compare the performance in two scenarios, one
n each replication, the simulation runs for 30 time steps, and the
mean coverage probability at each time step is calculated. In the simulation run, the coverage probability at
each time step is calculated and visualized, as shown in Fig 5(b). The horizontal axis represents the time and
has 30 points in total for the whole simulation run. The vertical axis shows the coverage probability for two
scenarios. The two curves in the figure begin to diverge at about 7 th time units. This divergence represents the
case that UGVs gradually lose control of the crowd due to limited detection and control capability.
The collected mean coverage probabilities PC from 100 replications under the two settings are compared via
hypothesis testing. Table 1 summarizes the mean of PC and sample standard deviation in 100 replications. A

Zhenrui Wang et al. / Procedia Computer Science 18 (2013) 2028 – 2035

test on the equal-variance is firstly conducted and it rejects the equal-variance hypothesis. Then, hypothesis test
on mean PC with unequal variance assumption indicates the significant performance improvement in crowd
control when UGVs receive disaggregated information from UAV.
Table 1. Summary of 100 replications

Without UAV
With UAV

Sample mean of PC
0.6126
0.9099

Sample standard deviation of PC
0.1606
0.0337

5. Conclusions and Future Research
A DDDAMS-based planning and control framework has been proposed for crowd control via UAVs and
UGVs. Models and algorithms have been also proposed for crowd motion detection, tracking, and control. The
simulation study has demonstrated the benefits of the proposed algorithms (e.g. information disaggregation) on
the performance improvement of crowd surveillance. It is noted that M, the number of individual agents may
significantly affect the performance of crowd tracking and control. One limitation of the current work is that it
assumes UAVs provide enhancement in detecting each individual agent in the crowd. There can be scenarios
that UAV may not be able to observe on individual scales. Instead, UAV observes only the dense region of a
crowd. Information aggregation/disaggregation under this scenario will be considered as a future work.
Acknowledgements
This work was supported by the Air Force Office of Scientific Research under FA9550-12-1-0238.
References
[1] Celik, N., S. Lee, K. Vasudevan, and Y. Son (2010). "DDDAS-based Multi-fidelity Simulation Framework for Supply Chain Systems."
IIE Transactions on Operations Engineering 42(5): 325-341.
[2] . Grocholsky, B., et al., Cooperative air and ground surveillance. Robotics & Automation Magazine, IEEE, 2006. 13(3): p. 16-25.
[3] De Filippis, L. and G. Guglieri, Path Planning strategies for UAVs in 3D environments. Journal of Intelligent & Robotic Systems 65.1
(2012): 247-264.
[4] Evsen et al. On path planning strategies for networked unmanned aerial vehicles. Computer Communications Workshops (INFOCOM
WKSHPS), 2011 IEEE Conference on 10 Apr. 2011: 212-216.
[5] . Welch, G. and G. Bishop, An introduction to the Kalman filter. 1995.
[6] C. Becker, H. González-Ba\ nos, J.Experimental Robotics IV, 1997, pp. 153 160.
[7] T. Oskam, R. W. Sumner, N. Thuerey, and M.
Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, 2009, pp. 55 65.
[8] C. Vo, S. McKay, N. Garg, and J.[9]. Pavlovic, V., J.M. Rehg, and J. MacCormick, Learning switching linear models of human motion. Advances in Neural Information
Processing Systems, 2001: p. 981-987.
[10].Arulampalam, M.S., et al., A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking. Signal Processing, IEEE
Transactions on, 2002. 50(2): p. 174-188.
[11].Silbert, M., T. Mazzuchi, and S. Sarkani. Comparison of a grid-based filter to a Kalman filter for the state estimation of a maneuvering
target. in Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series. 2011.
[12].Ristic, B., S. Arulampalam, and N. Gordon, Beyond the Kalman filter: Particle filters for tracking applications. 2004: Artech House
Publishers.

2035

