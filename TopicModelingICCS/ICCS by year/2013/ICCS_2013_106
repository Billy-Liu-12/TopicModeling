Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 2203 – 2212

2013 International Conference on Computational Science

Deadline-driven Resource Management within Urgent
Computing Cyberinfrastructure
Sergey V. Kovalchuka,*, Pavel A. Smirnova, Sergey V. Maryina,
Timofey N. Tchurova, Vladislav A. Karbovskiya
a

National Research University of Information Technologies, Mechanics and Optics, Birzhevaya line, 4, 199034, Saint-Petersburg, Russia

Abstract
One of the most important issues of urgent computing is the appropriate management of resources and tasks to meet the
requirements of this concept. This article presents a model-based approach to a deadline-driven resource control taking into
account the main requirements of urgent computing. The structure of stochastic multi-componential performance model for
estimation and optimization of the task processing time is defined. The set of impact factors of the performance process
including virtual resource management and services reliability is identified and modeled. The implementation of proposed
approaches within urgent computing mode of CLAVIRE platform is described and illustrated with experiments.
© 2013
2013 The
The Authors.
Authors. Published
Published by
by Elsevier
Elsevier B.V.
B.V. Open access under CC BY-NC-ND license.
©
Selection and
peerpeer-review
review under
responsibility
of the
organizers
of the
International
Conference
on Computational
and/or
under
responsibility
of the
organizers
of 2013
the 2013
International
Conference
on Computational
Science
Keywords: urgent computing; high-performance computing; resource management; performance modelling; cyberinfrastructure.

1. Introduction
One of the main ideas behind the concept of urgent computing (UC) [1] is providing the user with a priority
access to the resources which are needed to solve the task with required quality. This means that highperformance computational resources (software and hardware) involved into simulation process should be
provisioned and managed in the way that the computation process will be finished within a defined time-limit.
Today there are a lot of approaches to organize flexible computational cyberinfrastructure: so grid and cloud
computing [2] concepts exploit the ideas of providing required computational resources to the user on demand.
Concerning all the variety of infrastructure architectural concepts, the resource management process can have
different goals and priorities: e.g. cluster computing requires high scalability for parallel high-performance

* Corresponding author. Tel.: +7-962-687-0460; fax: +7-812-232-23-07.
E-mail address: sergey.v.kovalchuk@gmail.com.

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.391

2204

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

tasks (e.g. [3]), grid computing is focused on searching and interacting of appropriated, quality and reliable
services presented by virtual organizations within distributed environment [4], cloud computing works with
abstract resources which should be implemented (allocated or selected) to satisfy the service level agreement,
customer requirements and risk level [5]. The UC tasks have individual features which require specific
approaches in resource management and tasks scheduling. First of all, the UC tasks usually have firmly
specified deadline. Today there are projects devoted to the deadline-driven resource scheduling which usually
consider a model of unified tasks (see e.g. [6, 7]) or tasks with predefined execution time (e.g. [8]). However,
UC tasks processing should be considered as a multidisciplinary complex issue which requires integration of
diversity of simulation, data and control services. Moreover, a set of organizational, technological and
methodological issues defined by the nature of UC should be taken into account. Thus, a more complex model
system should be developed to support the cyberinfrastructure management within the UC concept.
This paper presents a model-based approach for estimation and optimization of the performance of UC tasks
within complex cyberinfrastructure. The main goal of the approaches’ development is to form a basis for
deadline-based resource management taking into account (a) heterogeneity of available resources (including
virtual resources); (b) diversity of incoming tasks; (c) priority management and queuing of tasks.
2. Backgrounds
UC concept is considered as a process which is tightly coupled with (a) high-performance simulation, which
provides the results to the user for managing particular extreme situation; (b) decision making process, which
should be performed before some particular deadline using simulation results, observations and other
information sources. Concerning the UC tasks nature, several basic technical requirements to the resource
management procedure implementation within cyberinfrastructure platform can be identified. Taking into
account heterogeneity of possible resource and variety of tasks traditional UC requirements [1, 9] can be
interpreted and extended as follows:
1) Deadline-based tasks management. The UC tasks are usually characterized by a firm deadline for
decision making. Thus the simulation process should also be scheduled within the defined time limits. For
making this possible the cyberinfrastructure should have an ability to predict the time which is required for
simulation and optimize it by selecting appropriate resources and tune execution parameters to gain the best
performance. This approach requires time estimation models to be implemented within the cyberinfrastructure
scheduler. These models should take into account all the procedures being performed during the simulation to
estimate the whole process from posting input data to getting the results of simulation.
2) Priority management. Resources should be accessed according to the priority granted to the user and to
the particular task. As a rule UC requests have the highest possible priority. Thus, UC task became the next-torun task in the queue or they even might cause the executing tasks to be stopped or suspended. But the situation
deteriorates if several tasks are to be run in a framework of one extreme situation processing. Then, within a
condition of limited available resources, UC tasks form a prioritized queue. Moreover, if we consider a
situation of simulation-driven decision support, there can be tasks with different origin and therefore with
different priority: tasks initially generated by the emergence of extreme event, tasks posted within interactive
simulation by experts and decision makers, tasks initiated by incoming events and information update during
the decision making. All these tasks should be processed according to theirs urgency levels.
3) Reliability control. One of the most important quality characteristics of provided services is reliability.
Within a framework of UC the reliability of used resources gain additional importance as simulation fails
become much more critical especially within the limited time. Thus, reliability of available resources should be
monitored continuously and the services’ selection should be performed according to the results of monitoring.
These requirements can be implemented on a basis of workflow management system for distributed
computing environment [10]. We choose CLAVIRE cloud computing platform [11] which allows integrating

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

2205

heterogeneous hardware and software providing access to abstract services with high-level support using
domain-specific knowledge. One of the available modes of the platform is urgent computing mode which
provides high-priority access to available services. To prove the developed approaches the CLAVIRE platform,
its scheduling, execution and resource management services were used as experimental facilities and
implementation basis for proposed solutions. Fig. 1 shows the architecture of execution subsystem of
CLAVIRE platform. The subsystem processes incoming tasks by scheduling with model-based performance
estimation and optimization and following execution using available resources of various architectures. To
perform appropriate scheduling the scheduler uses set of heuristics (several of them developed especially for
UC mode), information on currently available resource state and estimation service. For more detailed
description of CLAVIRE platform see [11].
CLAVIRE/
Estimator
Tuning
Modeling

CLAVIRE/
Provenance
CLAVIRE/
PackageBase

Description

Modeling
Logging

Execution

CLAVIRE/
Executor
Parameterization

Incoming
tasks

CLAVIRE/
Scheduler

Execution

Monitoring

CLAVIRE/ResourceBase

Desktops
Desktops
Software
Desktops
Desktops
Desktops

Clusters
Clusters
Clusters

Grids
Grids
Grids

Clouds
Clouds
Clouds

Available on

Fig. 1. Tasks execution within CLAVIRE platform

3. Performance Modeling
Estimation of task processing time is fundamental issue for resource management. We propose dynamic
model-based approach for estimation of the processing time and its optimization by tuning the parameters of
calling services. This section presents the structure of this model, procedures of its identification and usage.
3.1. Model Structure
Single task processing can be considered as a computational service calling procedure. The following formal
model of task processing time can be defined:
T ( S , Ξ ) = TR ( S ) + TQ ( S ) + TD ( S , Ξ ) + TE ( S , Ξ ) + TO ,

(1)

where S is a particular service being used, which is characterized by a set of parameters Ξ S ; Ξ = Ξ D ∪ Ξ E is
a set of task parameters which include data parameters Ξ D – a set of domain-specific input parameters (files,
values etc.) and execution parameters Ξ E – a set of technological parameters which define service execution
mode (e.g. number of parallel threads being used); TR is resource preparation time (may take significant time
in case the resource is presented by virtual machine needed to be launched); TQ is queuing time (as it was
mentioned, although UC process generally has the highest priority, there may be several tasks ordered to a
single resource); TD is input and output data transfer time; TE is service execution time; TO is a system
overhead time including time for analyzing the task structure, selecting the resource, scheduling, monitoring
task state, synchronization etc.

2206

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

Some of the mentioned time components can be considered as random variables with particular distribution
as the variation between tasks has little or even no influence on the result time. In particular, the value of TR is
a characteristic of a particular service being used, regardless of what particular task is to be executed at the
moment. Thus, this value can be considered as a probabilistic distribution associated with the service. It can be
characterized by its mean TRm and standard deviation TRσ . Furthermore, the value TO usually can be
considered as a random variable which characterizes the infrastructure with little dependency of the task being
executed. Therefore, it also can be considered as a random variable, characterized by its mean TOm and standard
deviation TOσ . Mentioned characteristics can be obtained by analyzing the history of cyberinfrastructure usage.
The value TQ should be estimated dynamically according to the set of tasks in the queue. E.g. in case the
queue is fixed for particular service, this time can be roughly calculated according to the following equation:
TQ ( S ) =

∑ T ( S , Ξi ) ,

(2)

i

where Ξi is the parameters of preceding tasks in the queue for the service S .
The value of data transfer time can be calculated as follows:
TD ( S , Ξ ) =

fin ( Ξ D )
Bin ( S )

+

f out ( Ξ D )
Bout ( S )

,

(3)

where Bin and Bout is input and output bandwidth of the service networking channel respectively; fin and
f out are the functions which calculate the size of input and output data defined by task parameters Ξ D . These
functions are defined by the particular service and data formats used by it. In fact while the function in most
cases is deterministic, bandwidth values are stochastic (its distribution can be estimated by analyzing
cyberinfrastructure history). Thus, the time of data transfer also can be considered as a stochastic value. So the
estimation of this value can be described as its mean TDm and standard deviation TDσ .
The execution time can be estimated by predefined function, which is also defined by a particular service:
TE ( S , Ξ ) = f E ( Ξ D , Ξ E , Ξ S ) ,

(4)

The particular form of this function is defined by service’s algorithm structure: computational complexity,
parallel structure and technology etc. This function also may be considered as a stochastic value. The simplest
way of its description in a form of random value is using the function (4) as a mean value TEm = TE ( S , Ξ ) and
definition of a function similar to (4) for standard deviation TEσ or relative standard deviation TEσ TEm .
Another way is identification TEσ or both of these values (in case of non-deterministic algorithm) by analyzing
execution history of cyberinfrastructure.
Finally, having characteristics of all parts of equation (1) for each task the processing time can be estimated
using the stochastic characteristics as follows:
T m = TRm + TQm + TDm + TEm + TOm ,
T σ = (TRσ )2 + (TQσ )2 + (TDσ )2 + (TEσ )2 + (TOσ )2 .

(5)

Thus, using this estimation one can define not only mean estimation of the processing time but also a
confidence interval for it. As a result, a more reliable estimation for UC tasks can be acquired.

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

2207

3.2. Models Identification and Usage
There are different ways to define the form of functions within models (3-4). Within iPSE concept [12] these
functions are considered as a part of expert knowledge. They are defined explicitly within a knowledge base.
Considering these functions several important procedures can be defined to support effective usage of the
proposed models structure.
1) Identification of the functions coefficients. This procedure can be performed only once (during the
storing of the function in the knowledge base). Nevertheless, the procedure can be repeated to refine the
coefficients according to real experiments (a) once – after a series of experiments was performed, (b)
periodically – to check correctness of defined models.
2) Identification of the service parameters. This procedure identifies characteristics Ξ S of the service being
used. One of the simplest ways to do that is minimization of the model error function constructed according to
the history analysis. E.g., using less squares the optimization task for equation (4) can be defined as follows:

∑ ( f E ( Ξ Di , ΞEi , ΞS ) − Ti )

2

⎯ ⎯ ⎯→ min ,

i

ΞS

(6)

where Ti is time of solving tasks stored in the history records of the cyberinfrastructure; Ξ Di and Ξ Ei is data
and execution parameters of corresponding tasks respectively. Usually there is a set of services available within
cyberinfrastructure. For precise estimation of the processing time, a set of experimental runs should be
performed on each of these services (or at least on one service from each services group with similar
performance characteristics). These runs can be done intentionally or the regular users’ activity can be analyzed
within a background process.
3) Execution parameters tuning. Proposed model structure can be used not only for time estimation, but
also for automatic tuning of default execution parameters to gain the best performance. So execution
parameters Ξ E can be identified according to the following statement:
f E ( Ξ D , Ξ E , Ξ S ) ⎯ ⎯ ⎯→ min .
ΞE

(7)

E.g. by using this approach the optimal number of parallel threads can be identified according to the model
(as there are cases where the maximum available number of running thread isn’t optimal [13]). This approach
allows optimizing running parameters automatically during resource analysis. Using the proposed approach the
execution parameters for each service can be tuned individually.
3.3. CLAVIRE implementation
Within the CLAVIRE environment (see fig. 1) the proposed model system has been implemented in
Estimator service, which is operating in two modes: regular mode and UC mode. UC mode allows defining
high-priority tasks and time limits for these tasks. Within the platform, the services are considered as the
software packages which can be run on the available resources. Thus, models (3-4) are defined as a part of
software packages description using domain-specific language EasyPackage available via PackageBase service.
Important procedure for processing time estimation is the identification of service parameters. CLAVIRE
implements the run history (available via Provenance service) analysis procedure which estimate service
parameters by solving (6) problem using Levenberg-Marquardt algorithm. Updated estimated parameters are
stored in parameter storage (within Estimator service) with association to the analyzed software service. Fig. 2a
shows service coefficient identification process for BSM software, which is used to forecast the sea level

2208

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

within given time span for St.Petersburg’s flood prevention solution [14]: the model estimation with default
and updated service parameters are shown. This software was described with a simple linear time model:
T = ( a ⋅FT + b ) ⋅Perf ,

(8)

where FT is the length of level forecast (in hours); Perf is the service coefficient which depend inversely on
the performance of the resource. After 12 runs of the service the value of the Perf parameter was updated to
satisfy the measurements of real runs. CLAVIRE estimates the confidence interval (see fig. 2a) according to the
relative error of the model estimation by the following equation:
f ( Ξ , Ξ , Ξ ) − Ti
Erel = E Di Ei S
.
f E ( Ξ Di , Ξ Ei , Ξ S )
a)

(9)
b)

Fig. 2. Processing time components (a) execution time estimation; (b) overhead time estimation.

Components of the processing time (e.g. TR and TO ) within the CLAVIRE platform are estimated using the
history of successful runs (available via Provenance service as well). As the characteristics of services and the
platform itself change over the time, the analysis procedure should use some filtering technique to adopt the
estimated value. The simplest way is to use the moving sample window to analyze the defined range of running
history. To improve this approach, weighted moving sample could be used. E.g. fig. 2b shows the estimation
process for system’s overhead value with exponential weighted moving average. Average value and confidence
interval are shown. System process of the CLAVIRE periodically runs the test tasks with stub services (with
average execution time – 0.07 s) available for each resource. Performing with low priority these tasks don’t
block regular tasks. The overhead time characteristics can be estimated after analysis of these runs. One of the
most important things shown on the fig. 2b is the adaptation process, which take place after the update of the
platform’s version which take place in a time period around test run #488 (a newer version has significant
updates within scheduling and resource management algorithms). Plans of CLAVIRE development include the
research on the filtering algorithm which is better as an adaptive technique.
4. Experiments
Considering the processing of the urgent computing tasks within a real complex cyberinfrastructure,
management issues of resource management should be taken into account beside of the time-based task

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

scheduling. This section presents a series of experiments which show some of the features having strong
influence on the resource management process.
4.1. Priority resource access
Priority resource access is one of the most important requirements of UC tasks processing. Access priority
should be considered taking into account the following criteria:
1) Organization issues. UC concept requires a special rights regulation to be developed for tasks according
to its priority, hazard level and necessity of preventing. This regulation should define (a) persons and
organizations able to post UC tasks in case of manual control; (b) well-defined rules of extreme events and
alerts identification in case of automatic control of UC.
2) Resources policies. In case of hardware resources being used, the services available within
cyberinfrastructure should have agreement to provide the platform a high-priority access to their task
management system (post high priority tasks or even stop executing tasks).
3) Multilevel priority queuing. As it was mentioned before UC process can include tasks with different
origin and thus different priority for processing.
Fig. 3 shows the experimental runs within cyberinfrastructure managed by the CLAVIRE platform using a
model-based approach described in section 3. Experiment includes two series of runs for BSM software [14]:
one is running in regular mode, another – in urgent computing mode. The plot shows the main difference
between regular and UC (next-to-run) tasks: as prioritized tasks mostly skip the queue, it causes significant
decline in processing time. Yet it requires a little more of overhead time to manage the extended priority policy.
As it can be seen most of the processing time components vary from time to time. As a result the probability
distributions of total processing time (shown at the left side of the plot) have significantly wide range even for
UC mode. Moreover complex UC problems (which include many tasks with different priority, decision making
process and diversity of available resources) state an issue of managing deadline-driven task processing. This
issue requires a complex model system for estimation of processing time in accordance with its nature.

Fig. 3. Urgent computing priority access within CLAVIRE platform

4.2. Virtual resources management
As it was mentioned before, using virtual resources (which can be stored in suspended state while there is no
need to compute) is one of the powerful ways to organize the infrastructure for UC. However, there are several
specific features of this approach:

2209

2210

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

1) Resource preparation time. Depending on the peculiarity of virtual resources and the mode of its launch
this time may take several minutes. Thus, estimation of this time should be taken into account.
2) Virtual resource management. Virtual resources pool can be managed easily than a pool of hardware
resources. One of the simplest ways of computation power variation is running the required quantity of virtual
resources. In this case it is required to identify the number of resources required for solving particular task.
To analyze these features the experimental cyberinfrastructure was developed. It contains a pool of virtual
resources which can be run dynamically and a scheduling platform. To load the experimental infrastructure a
series of tasks was pushed to the system with a predefined period. The experiment has been performed using
BSM software service mentioned earlier on the experimental pool of virtual machines managed by the
CLAVIRE platform. Measured time characteristics were as follow: average scheduling (including system’s
overhead) time was 4 s, average execution time – 140 s, virtual resource preparation time – 50 s. The density of
generated tasks arriving was 2 tasks/min = 1/30 tasks/s. Under these condition it is obvious that the sufficient
number of available resources should be 5 (140·1/30 = 4.66). Even in case of late running of the virtual
resources, after several iterations the tasks from queue will be processed with no delay.
Nevertheless, the situation became worse in case we consider random behavior of different blocks within the
proposed model. E.g. fig. 4a shows a waiting time of incoming tasks for the system containing 1 resource at the
start time and 4 resources starting after resource preparation. A series of 200 experiments of sequential runs
with execution time distributed normally (parameters m = 140 s, σ = 30 s) was performed to form the sample
for statistic analysis. The fig. 4a shows mean value and quartiles (25%, 50%, 75%) of waiting time for each run
in the sequence. For comparison the waiting time for the same system with deterministic execution time is
shown. As it can be seen the deterministic system with 5 resources available is completely enough for
processing of arriving tasks as all the tasks after number #24 have the lowest possible waiting time which is
defined only by the scheduler. Though, the case with random execution time shows that the mean waiting time
and 75% quartile are growing. This means that the number of virtual resources isn’t enough for processing of
the arriving tasks under the defined conditions. Fig. 4b shows the same experiment but with 5 additional
resources available after resource preparation time (6 resources in total). As it can be seen this configuration of
the resources is more suitable for the described conditions as waiting time is rapidly decreasing after virtual
resources become available.
b)
a)

Fig. 4. Waiting time for random execution time (a) with 1 static and 4 additional resources, (b) with 1 static and 5 additional resources.

The proposed model of periodically incoming tasks can be considered like an artificial simplification of
existing process of task arriving. I.e. usually within UC mode tasks arrive within a groups, defined by running a
particular composite application. Nevertheless this approach allows to estimate the quantity of virtual resources
to be used to decreasing the average waiting time.

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

4.3. Reliability assessment
Reliability of available services can be assessed by analyzing fails emerged within a run history (available
via Provenance service within CLAVIRE). This approach can be implemented by monitoring regular activity
of services or by periodically running the test tasks (active monitoring). The reliability of service within this
context is considered as an ability to keep continuously the values of all the functional and qualitative
parameters within the required limits. The interaction scheme consists of the following components: 1 – client
(client computer); 2 – network from the user to the platform; 3 – cyberinfrastructure management platform; 4 –
network from platform to the computational resource; 5 – computational resource hardware; 6 – computational
resource operating system; 7 – software package. The components 3-7 can be associated with the service
components of the model (1). Thus, to make any performance estimations on the service the appropriate
components should be reliable. Provenance data can be used to define which element of the system has failed,
by analyzing the returned errors. To quantify reliability of the service the product of the reliability probability
of its elements (which is defined by the selected history sample) can be used.
b)
a)

Fig. 5. Service reliability dynamic assessment (a) simple moving average (b) exponential weighted moving average

CLAVIRE platform uses the active monitoring approach: the reliability of available service is checked by
periodical run of test tasks. Fig. 5 shows the reliability functions for an experimental series of runs at the
moment where there are five sequential fails were artificially induced: three fails of network at runs #10, #12,
#15, and two fails of service software at runs #20, #21. The other elements are not shown on the plot, because
its work was completed without failures throughout the runs. The reliability level for the components was
assessed using simple moving average (SMA – fig. 5a) or weighted moving average (EWMA – fig. 5b). If the
reason of failure was eliminated, e.g. a system administrator fixed the error of package configuration, the
statistic could be reset manually (e.g. the reset within the experiment was done after run #22). The critical level
for the total score was defined at 0.8. So, during the test runs from #15 to #22 for SMA and from #12 to #22 for
EWMA (preferable variant) the service was considered as unreliable.
5. Discussion and Conclusion
Cloud computing approach [2] exploits the idea of on-demand resources (infrastructure, software, platforms)
available as a service. Concerning any object being provided as a service one of the most important things is
guaranteeing the particular level of quality of a service (QoS) which can be proved and supported by the

2211

2212

Sergey V. Kovalchuk et al. / Procedia Computer Science 18 (2013) 2203 – 2212

model-based concepts and algorithms [15]. As the most important quality characteristic of the UC is the ability
to satisfy a predefined deadline, the most important models for supporting QoS are comprehensive models for
time estimation. Contemporary level of model-based resource management approaches (e.g. [6, 7]) should be
developed and extended to cover the whole process of problem solving considering the nature of distributed
simulation process within heterogeneous environment and a set of significant factors influenced on the
performance. Among other important issues the development of workflow-aware methods for resource
management (see e.g. [8]) which also could be extended within model-based approach can be outlined.
This work presents the model-based approach which was developed to support deadline-driven resource
management within cloud computing environment. This approach incorporates multi-componential structure of
distributed simulation time, functional dependencies of selected components (e.g. simulation time and data
transfer rime), virtual resources control, tasks’ queuing and priority management. The basic task processing
model considers the stochastic nature of most processes which allows to identify confidence intervals and to
simulate more complex queuing processes. The proposed approaches and models were implemented within
CLAVIRE environment and tested in a series of experiments which showed their effectiveness.
Acknowledgements
This work was supported by project “Urgent Distributed Computing for Time-Critical Emergency
Decision Support” performed under Decree 220 of Government of the Russian Federation.
References
[1] "Urgent Computing: Exploring Supercomputing’s New Role", CTWatch Quarterly, vol. 4, n. 1, 60 p.
[2] I. Foster, Y. Zhao, I. Raicu, S. Lu, "Cloud Computing and Grid Computing 360-Degree Compared", eprint arXiv:0901.0131, 2008.
[3] E. Frachtenberg, F. Petrini, J. Fernandez, S. Pakin "STORM: Scalable Resource Management for Large-Scale Parallel Computers",
IEEE Transactions on Computers, vol. 55, n. 12, 2006, pp. 1572-1587.
[4] K. Krauter, R. Buyya, M. Maheswaran "A Taxonomy and Survey of Grid Resource Management Systems for Distributed Computing",
Software - Practices and Experience, n. 32, 2002, pp. 135–164.
[5] R. Buyya, S.K. Garg, R.N. Calheiros "SLA-oriented resource provisioning for cloud computing: Challenges, architecture, and
solutions", Proceedings of the 2011 International Conference on Cloud and Service Computing, 2011, pp. 1-10.
[6] C. Vecchiola, R.N. Calheiros, D. Karunamoorthy, R. Buyya "Deadline-driven provisioning of resources for scientific applications in
hybrid clouds with Aneka", Future Generation Computer Systems, n. 28, 2012, pp. 58-65.
[7] N.D. Trebon “Enabling Urgent Computing within the Existing Distributed Computing Infrastructure”, Ph.D. Dissertation, University of
Chicago, August 2011, 117 p.
[8] M. Malawski, G. Juve, E. Deelman, J. Nabrzyski "Cost- and Deadline-Constrained Provisioning for Scientific Workflow Ensembles in
IaaS Clouds" SC '12 Proceedings of the International Conference on High Performance Computing, Networking, Storage and
Analysis, Article No. 22, 2012, 11 p.
[9] P. Beckman, I. Beschastnikh, S. Nadella, N. Trebon "Building an Infrastructure for Urgent Computing", Advances in Parallel
Computing, Vol. 16: High Performance Computing and Grids in Action, 2008, pp. 75-95.
[10] J. Yu, R. Buyya "A Taxonomy of Workflow Management Systems for Grid Computing", Journal of Grid Computing, 2005, vol. 3, n.
3-4, pp. 171-200.
[11] K.V. Knyazkov, S.V. Kovalchuk, T.N. Tchurov, S.V. Maryin, A.V. Boukhanovsky "CLAVIRE: e-Science Infrastructure for Datadriven Computing", Journal of Computational Science, vol. 3, n 6, 2012, pp. 504-510.
[12] A.V. Boukhanovsky, S.V. Kovalchuk, S.V. Maryin "Intelligent Software Platform for Complex System Computer Simulation:
Conception, Architecture and Implementation", Izvestiya VUZov. Priborostroenie, n. 10, 2009, pp. 5-24 (in Russian).
[13] S. Kovalchuk, A. Larchenko, A. Boukhanovsky "Knowledge-Based Resource Management for Distributed Problem Solving",
Knowledge Engineering and Management, Advances in Intelligent and Soft Computing, vol. 123, 2012, pp. 121-128.
[14] S.V. Ivanov, S.S. Kosukhin, A.V. Kaluzhnaya, A.V. Boukhanovsky "Simulation-based collaborative decision support for surge floods
prevention in St. Petersburg", Journal of Computational Science, vol. 3, n. 6, 2012, pp. 450-455.
[15] R. Ranjan, R. Buyya, S. Nepal "Model-driven provisioning of application services in hybrid computing environments", Future
Generation Computer Systems (in press).

