Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 1145 – 1154

International Conference on Computational Science, ICCS 2013

Calibration in Finance: Very Fast Greeks through Algorithmic
Diﬀerentiation and Implicit Function
Marc Henrarda
a Quantitative

Research – OpenGamma, 185 Park street, London SE1 9BL, United Kingdom

Abstract
Adjoint Algorithmic Diﬀerentiation is an eﬃcient way to obtain price derivatives with respect to the data inputs. We describe
how the process eﬃciency can be further improved when a model calibration is performed. Using the implicit function theorem,
diﬀerentiating the numerical process used in calibration is not required. The resulting implementation is more eﬃcient than
automatic diﬀerentiation. The eﬃciency is described for root-ﬁnding and least square calibration.
Keywords: Financial model calibration, algorithmic diﬀerentiation, implicit function theorem, root ﬁnding, least square,
eﬃcient derivatives computation.

1. Introduction
In quantitative ﬁnance, computing the present value of ﬁnancial instruments is only part of the game; most
of the (computer) time is spent in calculating the derivatives of the present value with respect to the diﬀerent
ﬁnancial inputs, the so-called greeks. The number of inputs is often between 10 and 100 and the eﬃciency of the
implementation has a real impact in practice.
For the computation of present value derivatives, one eﬃcient technique is Algorithmic Diﬀerentiation (AD)
and in particular its Adjoint mode (AAD). The method is eﬃcient in two senses: it is fast and provides results with
machine-precision accuracy.
The adjoint method was popularised in ﬁnance by [1]. Since then, the technique has been applied in diﬀerent
contexts in ﬁnance, in particular for the Libor Market Model in [2] and [3], Monte Carlo-based calibration in [4],
correlation risk in credit models in [5], Monte Carlo credit risk in [6] and in general Monte Carlo implementation
in [7]. We also refer to [8] and the references therein for the general technique and its use in ﬁnance.
In theory, applying the adjoint method to compute a single price (P) and all its derivatives (D) should lead to
a relative time cost [9, Section 4.6]
Cost(P + D) ≤ ωA Cost(P)
with ωA ∈ [3, 4]. This relative cost can be compared to the ﬁnite diﬀerence (also called divided diﬀerence or
bump and recompute) method, another popular technique for derivative computation. With the ﬁnite diﬀerence
technique, the relative cost depends on the number of derivatives and is
Cost(P + D)
∗ Corresponding

(number of derivatives + 1)Cost(P).

author. Tel.: +44-20-3416-3360 ; email: marc@opengamma.com.

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.280

1146

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

Another popular approach is to code the derivatives functions directly from formulas. Depending on the way
this is implemented, the computational cost is between the two mentioned above but often with a more complex
implementation. The underlying mathematics are similar to AD but the implementation is diﬀerent. Even for
simple ﬁnancial instruments, the number of derivatives can be large. For a simple vanilla 10-year swap in EUR,
the number of derivatives is 41 in a standard multi-curves framework. The advantage of the AAD in term of
computational cost is obvious.
In practice, for simple functions, it is in general possible to do better than the theoretical upper bound. For
example the Black function option price and its derivatives (w.r.t. the forward, the volatility and the strike) can be
computed with a ratio of 1.11 , i.e. the three derivatives can be computed by increasing the computation time by
only 10%. Part of the saving comes from using domain speciﬁc knowledge. In the Black formula, the derivative
of the price with respect to the exercise boundary is zero as the boundary is the optimal one. This type of simpliﬁcation is not infrequent in ﬁnance; it appears in European swaption pricing in the Hull-White model, Bermudan
swaption pricing and in many other places. The domain speciﬁc knowledge required to achieve those optimisations are not accessible to automatic diﬀerentiation tools. The same can be said about the main result of this
article, combining AD with implicit function theorem requires an understanding of the underlying problem which
is very diﬃcult to use in an automatic diﬀerentiation approach.
In practice, the AD method is of greater interest when considering complex processes. One frequent part of
such a process for exotic option pricing in ﬁnance is model calibration. The process is as follows:
• the price of an exotic instrument is related to a speciﬁc basket of vanilla instruments;
• the price of these vanilla instruments is computed in a given base model;
• a complex model is selected and its parameters are calibrated to ﬁt the vanilla option prices from the base
model. This step is usually done through a generic numerical process (root ﬁnding or least square); and
• the exotic instrument is then priced with the calibrated complex model.
We suppose that the pricing algorithms and their derivatives are implemented. We want to diﬀerentiate the
exotic price with respect to the base model parameters. In the bump and recompute approach, this corresponds to
computing the risks with model recalibration. As the calibration can represent a major part of the total computation
time of the procedure, an alternative method is highly desirable. The subject of this note is the calibration process
part. It is intended to be complementary to the literature mentioned above. This note extends results from [10].
In general, the calibration process is not explicit, it is done through a numerical root ﬁnding or least square
approach. We have only one set of parameters of the calibrated model; the set corresponding to a speciﬁc set of
curves and base model parameters. There is no explicit algorithm that provides the calibrated model parameters
as function of the base model parameters, or its the adjoint algorithmic diﬀerentiation. What is demonstrated in
this note is that the derivative of the calibration process is not required; indeed the calculation can be performed
more eﬃciently without it when the structure of the problem is used.
To show this, the implicit function theorem is used to analyse equations of the form
f (x, y) = 0.
Theorem 1 (Implicit Function Theorem). Let f : Rn+m → Rm be continuously diﬀerentiable. If (x0 , y0 ) is such
that
f (x0 , y0 ) = 0
and if Dy f (x0 , y0 ) is invertible, then, in a neighbourhood X × Y of (x0 , y0 ), there is a (implicit) function g such that
f (x, g(x)) = 0 for x ∈ X, {(x, g(x)) : x ∈ X} = {(x, y) ∈ X × Y : f (x, y) = 0}, g is diﬀerentiable in x0 and
D x g(x0 ) = − Dy f (x0 , y0 )

−1

D x f (x0 , y0 ).

1 All ﬁgures related to actual implementations have been computed with the OpenGamma OG-Analytics library. The OpenGamma analytic
library is open source and available at http://developers.opengamma.com. The computations have been done on a Mac Pro 3.2 GHz
Quad-core. The test code is available from the author.

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

1147

In general, the numerical resolution of the equation f (x, y) = 0 requires several evaluations of f (and often
of its derivative). This is the case for iterative Newton-like methods. According to AAD, the derivatives of f are
computed in a time not greater than the time to perform four evaluation of f (in dimension 1). The derivatives of
f can be computed faster than calibrating the value y0 . The derivatives of the implicit function can be obtained in
a time which is less than the pricing time (subject to the price being computed already).
An independent related approach, using an Automatic Diﬀerentiation tool (ADOL-C), is proposed in [11].
The model used in there is the Hull-White one factor model in a single-curves framework. The problem analysed
is the calibration to European swaptions and pricing of Bermudan swaptions; they do not analyse the sensitivities.
The problem speciﬁc solution we propose here would not be achieved by an automatic tool approach.
The idea of combining AAD and the implicit function theorem has been present in AD for some time (see
for example [12]). In addition to calculating the derivative through equation solving, the referenced paper also
analyses error estimates for the function computed. Similar ideas are used in other applied mathematics ﬁelds.
In particular, [13] used it in engineering design; their formula for objective function derivatives is similar to the
derivatives of the exotic instrument price with respect to the curves in the base model presented in Section 3. To
our knowledge, the approach has not yet been used in the ﬁnancial calibration context. The combination of least
square calibration with implicit function for algorithmic diﬀerentiation appears also to be new.
We describe the improved eﬃciency of the derivatives calculation below. In the examples we show that the
eﬃciency described in theory can be obtained in practice. A present value with calibration and its 40 to 70
derivatives are obtained in a time which is below twice the pricing time (well below the theoretical upper bound).
In the least square case, the ratio is bearly above 1. The computation of the derivatives is almost free.
2. Adjoint method and implicit function theorem
The method is ﬁrst presented using a simple example, allowing simpliﬁed notation. Suppose we have a a
function f : R pa → R pz
z = f (a).
Within the algorithm to compute f , there is an equation to solve. The algorithm is decomposed into
b
c
z

= g1 (a)
s. t. g2 (b, c) = 0
=

g3 (c)

with g1 : R pa → R pb , g2 : R pb × R pc → R pc and g3 : R pc → R pz . The second part of the algorithm is a
multi-dimensional root-ﬁnding problem that need to be solved.
We assumed that all functions are diﬀerentiable. The derivative of f : R pa → R pz at a is denoted D f (a) or
Da f (a) if we want to emphasise the variable with respect to which the derivative is taken. The elements of R p are
represented by column vectors. The derivative D f (a) is represented by a pz × pa matrix (pz rows, pa columns).
Suppose that the AD versions of the functions gi (1 ≤ i ≤ 3) are available but the AD version for the solver
is not, i.e. the derivatives of the function that computes c from b are yet unknown. The implicit function theorem
ensures (under certain conditions) that the process that produces c as function of b is actually diﬀerentiable and
links its derivative to those of g2 . Deﬁning g4 as the implicit (and unknown) function associating c to b, i.e.
g4 (b) = c, the derivative of g4 is given by
Db g4 (b) = − (Dc g2 (b, c))−1 Db g2 (b, c).
Solving the equation is usually much more time-consuming than simply computing one value of g2 . In the
implicit function approach, there is no need to solve the equation again and there is no requirement to have the
AD version of the solver, only the derivatives of the function g2 are required. The AD method used in this way
will give better results than the standard (or automatic) approach as there is no need to solve the equation for g2
again. An automatic approach does not know the structure of the problem and cannot take advantage of it.

1148

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

The standard notation in AAD is to denote the derivative of the ﬁnal value z with respect to an intermediate
value x by x¯. The literature uses diﬀerent notations with regards to the transposition of x¯; here we use
x¯ = (D x z(x))T ,
i.e. the bar variables are column vectors if z is of dimension one, or matrices of size p x × pz otherwise. In our
instrument price examples, the dimension of z is one. The adjoint version of the algorithm can be written as
z¯ = I (with I the pz × pz identity)
c¯ = (Dc g3 (c))T z¯
b¯

= (Db g4 (b))T c¯ = − (Dc g2 (b, c))−1 Db g2 (b, c)

a¯

¯
= (Da g1 (a))T b.

T

c¯

Before describing the general technique, we describe the technique on an overly simpliﬁed example to show
the method ﬂow. Suppose we have the Black (log-normal) implied volatility for a given strike K and want to price
an option at a diﬀerent strike K using a Bachelier (normal) smile. We want to compute the derivative of the ﬁnal
price with respect to the original implied volatility. The Black price at strike K is denoted Black(σL , K) with σL
the log-normal volatility. The Bachelier price is denoted Bachelier(σN , K) with σN the normal volatility. The
initial Black implied volatility is σ0L . The algorithm is summarised by the following table:
a
b
c
z

a¯ = DσL Black(σ0L , K)b¯
= σ0L
L
b¯ = −(DσN Bachelier(σ0N , K))−1 c¯
= PV(Black, K)
g1 (a) = Black(σ0 , K)
N
N
= σ0
g2 (b, c) = b − Bachelier(σ0 , K) c¯ = DσN Bachelier(σ0N , K )¯z
g3 = Bachelier(σ0N , K )
z¯ = 1.
= PV(Bachelier, K )

The algorithm should be read going down the second column (present value) and going up the last column (vega).
The total derivative is the one expected from doing the computation on paper, the total derivative is a product of
the intermediary steps derivatives.
3. Perfect Calibration Technique
The method is applied with the interest rate model calibration case in mind. If the yield curve C is replaced by
any other asset class data, like FX rates, equity prices or credit curves, the results are still valid.
Let PVVanilla
Base be the prices of the vanilla ﬁnancial instruments used for calibration in the base model, i.e. the
function g1 in the previous section. The data required for the pricing are the yield curves (denoted C) and market
volatility parameters (e.g. SABR parameters or Black volatilities) for the base model (denoted Θ). The exotic
model can price the same vanilla options with the same curves but using diﬀerent parameters (denoted Φ and
equivalent to c in the previous section). The pricing function for the vanilla options in the calibrated complex
model is denoted PVVanilla
Calibrated . The calibration equation to solve is
g2 (C0 , Θ0 , Φ0 ) = 0.

(1)

Vanilla
g2 (C, Θ, Φ) = PVVanilla
Base (C, Θ) − PVCalibrated (C, Φ).

(2)

For perfect calibration, the function is simply

Equation (1) will be multi-dimensional when there are several calibrating instruments. There are as many calibration instruments as parameters to be calibrated. We also suppose that the derivative DΦ g2 (C0 , Θ0 , Φ0 ) is invertible.
In practice, some models may have more free parameters than calibrating instruments. In this case the model
parameters are constrained in such a way that there are the same number of degrees of freedom as the number of
instruments. The second example in the next section calibrates a two-factor LMM. We calibrate the parameters by
adding the constraint that for each yearly period, the parameters are multiples of a initially-given structure. For a

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

1149

10 year coverage the model has 40 parameters and the number of degrees of freedom is 10, one for each calibrating
instrument. The parameters Φ used here are those degrees of freedom, not the original model parameters.
With the calibration procedure, we obtain model parameters from the original parameters Θ0 and the curves
C0 : Φ = Φ(C0 , Θ0 ) (equivalent to g4 in the previous section). The parameters are obtained through the equation
solving procedure; there is no explicit solution or even explicit code that produces those parameters directly.
The exotic option is priced from the calibrated model through the pricing PVExotic
Calibrated (C, Φ) (equivalent to z in
the previous section). With the implicit function above we can deﬁne
Exotic
PVExotic
Base (C, Θ) = PVCalibrated (C, Φ(C, Θ))

We are interested in the derivative of the exotic option with respect to the curves and the base model parameters
Exotic
Exotic
Θ. With the AD versions of PVExotic
Calibrated , we can compute the derivatives DC PVCalibrated and DΦ PVCalibrated . The
quantities we would like to compute are
Exotic
DC PVExotic
Base and DΘ PVBase .

Through composition we have
Exotic
Exotic
DC PVExotic
Base (C 0 , Θ0 ) = DC PVCalibrated (C 0 , Φ(C 0 , Θ0 )) + DΦ PVCalibrated (C 0 , Φ(C 0 , Θ0 ))DC Φ(C 0 , Θ0 ),

and
Exotic
DΘ PVExotic
Base (C 0 , Θ0 ) = DΦ PVCalibrated (C 0 , Φ(C 0 , Θ0 ))DΘ Φ(C 0 , Θ0 ).

Where DC Φ and DΘ Φ are yet unknown. Using the implicit function theorem, the function Φ is diﬀerentiable
and its derivatives can be computed from the derivatives of f :
DΘ Φ(C0 , Θ0 ) = − (DΦ g2 (C0 , Θ0 , Φ(C0 , Θ0 )))−1 DΘ g2 (C0 , Θ0 , Φ(C0 , Θ0 ))
and

DC Φ(C0 , Θ0 ) = − (DΦ g2 (C0 , Θ0 , Φ(C0 , Θ0 )))−1 DC g2 (C0 , Θ0 , Φ(C0 , Θ0 )).

In the perfect calibration case
DΘ Φ(C0 , Θ0 ) = DΦ PVVanilla
Calibrated (C 0 , Φ(C 0 , Θ0 ))

−1

DΘ PVVanilla
Base (C 0 , Θ0 )

and
DC Φ(C0 , Θ0 )

=

DΦ PVVanilla
Calibrated (C 0 , Φ(C 0 , Θ0 ))

−1

Vanilla
DC PVVanilla
Base (C 0 , Θ0 ) − DC PVCalibrated (C 0 , Φ(C 0 , Θ0 )) .

4. Perfect Calibration Examples
In line with the above technique, we would like to price and compute the sensitivities of exotic swaptions
in a physical delivery SABR framework. For all the required pricing algorithms the AAD versions have been
implemented.
4.1. Cash swaptions in the Hull-White model
In the ﬁrst example we chose the simplest case, with only one calibrating instrument and one parameter, to
illustrate the approach. Our exotic instrument is a cash-settled swaption and our vanilla basket is composed of
a unique physical delivery swaption. The curve framework is the standard multi-curves framework as described
in [14] with deterministic spread. The base model is a SABR model on the swap rate. The model parameters Θ
are the SABR parameters α, ρ and ν (β is set to 0.50). The formula used for swaption in the SABR framework
is the one from [15]. The calibrated model is a Hull-White one factor (extended Vasicek) model with constant
volatility. The parameter of the Hull-White model to calibrate is the constant volatility. The pricing algorithm in

1150

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

the Hull-White model for the physical delivery swaption is described in [16], and the pricing algorithm used for
the cash-settled swaption is the eﬃcient approximation described in [17]. The pricing algorithms are fast and the
calibration is an important part of the comptation time.
For this example, we use a 1Y×9Y swaption on an annual vs 6m Euribor swap. There are three SABR
sensitivities (α, ρ, and ν) and 38 rate sensitivities (19 on each curve). The performance results are provided in
Table 1. The computation of the three SABR derivatives add less than 30% to the pricing computation time in this
approach; a non-symmetrical ﬁnite diﬀerence computation would add 300%.
Table 1. Performance for diﬀerent approaches to derivatives computations: cash settled swaption in Hull-White one factor model.
Risk type
Approach
Price time
Risks time
SABR
Finite diﬀerence
1.00
3×1.00
SABR
AAD and implicit function
1.00
0.28
Curve
Finite diﬀerence
1.00
38×1.00
Curve
AAD and implicit function
1.00
0.56
Curve and SABR
Finite diﬀerence
1.00
41×1.00
Curve and SABR
AAD and implicit function
1.00
0.83

Total
4.00
1.28
39.00
1.56
42.00
1.83

Times relative to the pricing time. The pricing time is 0.45 second for 1000 swaptions.

The same comparison was performed for the interest rate sensitivities. The ﬁnite diﬀerence requires 39 price
time (3900%). The proposed approach adds only 0.55 price time (55%). In total, the proposed algorithm is around
23 times faster than a ﬁnite diﬀerence approach and is numerically more stable. Note also that the total ratio 1.83
is well below the theoretical upper bound ωA ∈ [3, 4].
To partly compare with the results of [11], we also report ﬁgures for a Hull-White one factor model with
piecewise constant volatility. The set-up of the above article is diﬀerent but the underlying model is similar. The
computation time for the ﬁnite diﬀerence and adjoint evaluations of the Jacobian with respect to the piecewise
constant volatility for a 30Y and 100Y swap (annual volatility dates) is provided. The Jacobian is the derivative of
all European swaption prices with respect to all volatilities in the model. The 30Y Jacobian computation requires
0.110 seconds (s) by ﬁnite diﬀerence and less than 0.015 s by algorithmic diﬀerentiation. This is approximately
14% of the runtime and lower but of the same order of magnitude that the result of [11] (20%). The corresponding
ﬁgures for the 100Y case are 20.2 s and 0.42 s (2%).
4.2. Amortised swaptions in LMM
In this example, the exotic instrument is an amortised European swaption (i.e. a swaption with decreasing
notional), and the vanilla basket is composed of vanilla European swaptions with same expiry and increasing
maturities. The amortised swaption has a 10Y maturity and yearly amortisation. The calibrating instruments are
ten vanilla swaptions with yearly maturities between 1Y and 10Y and same strike as the amortised swaption.
The base model is a SABR model on each vanilla swaption. The pricing in the SABR framework is done as
in the previous example. The complex model is a two-factor LMM with displaced diﬀusion and Libor period of
six months. The pricing method for swaptions in LMM is the eﬃcient approximation described in [18].
The calibration is performed as follows: for each yearly period the weights of the diﬀerent parameters (four
in each year) are ﬁxed. The calibration is done by multiplying those weights by a common factor. The parameter
Φ in the previous section are the multiplicative factors (10 in total), even if in practice the derivatives with all the
model parameters (40 in total) are computed as an intermediary step.
The results for the SABR and curve sensitivities are reported in Table 2. There are 30 SABR sensitivities (α,
ρ, ν for 10 vanilla swaptions). In the described approach, the 30 sensitivities add less than 20% to the computation
time with respect to the calibration and price computation.
There are 42 curve sensitivities (two curves, semi-annual payments over 10 years). The computation of the 42
sensitivities takes less than 75% of the price time. In total, the AAD approach takes 2.5% of the time required by
ﬁnite diﬀerence. Note that computing the curve and SABR sensitivities take approximately the same amount of
time as computing the curve sensitivities as most of the computation are common. The total ration of 1.75 is well
below the theoretical upper bound of ωA ∈ [3, 4].
Similar results for amortised swaptions of diﬀerent maturities and with diﬀerent numbers of calibrating instruments are reported in Figure 1. The ratios between the price and sensitivities time and the price time are

1151

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

Table 2. Performance for diﬀerent approaches to derivatives computations: amortised swaption in the LMM.
Risk type
Approach
Price time
SABR
Finite diﬀerence
1.00
SABR
AAD and implicit function
1.00
Curve
Finite diﬀerence
1.00
Curve
AAD and implicit function
1.00
Curve and SABR
Finite diﬀerence
1.00
Curve and SABR
AAD and implicit function
1.00

Risks time
30×1.00
0.18
42×1.00
0.74
72×1.00
0.75

Total
31.00
1.18
43.00
1.74
73.00
1.75

Times relative to the pricing time. The pricing time is 0.425 second for 250 swaptions.

reported for the ﬁnite diﬀerence and Adjoint Algorithmic Diﬀerentiation using the implicit function method described in the previous section. The implicit function AAD method ratios are almost independent of the number
of sensitivities. In all cases but the 30Y swaptions (where 212 sensitivities are calculated), the ratios are below
two.
100

4

AAD Price+Vega
AAD Price+Delta
AAD Price+Vega+Delta
FD Price+Vega
FD Price+Delta
FD Price+Vega+Delta

AAD Price+Vega
AAD Price+Delta
AAD Price+Vega+Delta

3.5

80

3
2.5
Ratio

Ratio

60
40

2

1.5
1

20

0.5
0

0

5

10

15
Tenor

20

25

30

0

0

5

10

(a) Full picture

15
Tenor

20

25

30

(b) AAD picture

Fig. 1. Computation time ratios (price and sensitivities time to price time) for the ﬁnite diﬀerence and AAD methods. The vega represents the
derivatives with respect to the SABR parameters; the delta represents the derivatives with respect to the interest rate curves. The AAD method
uses the implicit function theorem approach. Figures for annually amortised swaptions in a two-factor LMM calibrated to vanilla swaptions
in SABR.

5. Least Square Calibration technique
In this section we develop techniques similar to the one developed in Section 3 but for the case where the
calibration is not a root-ﬁnding calibration but a least square calibration.
Here we consider the case were the parameters Φ are obtained through a (weighted) least square process.
Suppose that there are n calibrated parameters in Φ and m ≥ n instruments for the calibration process. The
weights associated to each instrument are (wi )i=1,...,m . The calibration parameters are deﬁned as
Φ0

=

arg minΦ∈Rn h(C0 , Θ0 , Φ)

=

arg minΦ

2

Vanilla
wi PVVanilla
Base (i, C 0 , Θ0 ) − PVCalibrated (i, C 0 , Φ) .
i=1,...,m

At the minimum Φ0 , the derivatives with respect to Φ are 0:
g2 (C0 , Θ0 , Φ0 ) = DΦ h(C0 , Θ0 , Φ0 ) = 0.

(3)

1152

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

The minimum satisﬁes Equation (1) with the function g2 deﬁned above. Like previously, we suppose that
DΦ g2 (C0 , Θ0 , Φ0 ) is invertible. This last equation is a n unknown and n equation system. We use the following convention for derivatives: DX y is a vector (matrix) with one column for each element in X and as many rows
as the dimension of y. In particular DΦ h is a row vector (n element). The above derivatives can be computed
explicitly as
DΦ h(C, Θ, Φ) = −2

Vanilla
Vanilla
wi PVVanilla
Base (i, C, Θ) − PVCalibrated (i, C, Φ) DΦ PVCalibrated (i, C, Φ).
i=1,...,m

With the calibration procedure, we obtain calibrated model parameters from the original model parameters
and the curves: Φ0 = Φ(C0 , Θ0 ). The parameters are obtained through the optimization procedure; there is no
explicit solution or even explicit code that produces those parameters directly.
The implicit function theorem states that there exists a function Φ(C, Θ) such that
g2 (C, Θ, Φ(C, Θ)) = 0
for (C, Θ) close to (C0 , Θ0 ) and there are no other solution. We still need to prove that the function Φ(C, Θ) gives
a minimum of the original problem (3) and not only a point with 0 derivatives (like a saddle point).
Let m0 denote the minimum value of (3) at Φ0 i.e. m0 = h(C0 , Θ0 , Φ0 ). As Φ0 is a minimum with DΦ g2 (C0 , Θ0 , Φ0 )
invertible, there exists a > 0 and a sphere around Φ0 such that h(C0 , Θ0 , Φ) > m0 + 3 for Φ on the sphere. As g2
is continuous, for (C, Θ) close enough to (C0 , Φ0 ), h(C, Θ, Φ) > m0 +2 for Φ on the sphere and h(C, Θ, Φ(C, Θ)) <
m0 + for (C, Θ) close to (C0 , Φ0 ). This proves that h has a minimum in the interior of the disk, thus the minimum
has zero derivatives. From the result of the theorem, Φ(C, Θ) is the only zero. This proves that the implicit function
Φ(C, Θ) is not only a zero of the derivative but also a minimum of the least square problem.
The exotic option is priced from the calibrated model through the pricing PVExotic
Calibrated (C, Φ). With the implicit
function above we can deﬁne
Exotic
PVExotic
Base (C, Θ) = PVCalibrated (C, Φ(C, Θ))
We are interested in the derivative of the exotic option with respect to the curves and the base model parameters
Exotic
Exotic
Θ. With the AD versions of PVExotic
Calibrated , we can compute the derivatives DC PVCalibrated and DΦ PVCalibrated . The
quantities of interest are
Exotic
DC PVExotic
Base and DΘ PVBase .
Through composition we have
Exotic
Exotic
DC PVExotic
Base (C 0 , Θ0 ) = DC PVCalibrated (C 0 , Φ(C 0 , Θ0 )) + DΦ PVCalibrated (C 0 , Φ(C 0 , Θ0 ))DC Φ(C 0 , Θ0 ),

and
Exotic
DΘ PVExotic
Base (C 0 , Θ0 ) = DΦ PVCalibrated (C 0 , Φ(C 0 , Θ0 ))DΘ Φ(C 0 , Θ0 ).

Where DC Φ and DΘ Φ are yet unknown. Using the implicit function theorem, the function Φ is diﬀerentiable
and its derivatives can be computed from the derivative of g2 :
DΘ Φ(C0 , Θ0 ) = − (DΦ g2 (C0 , Θ0 , Φ(C0 , Θ0 )))−1 DΘ g2 (C0 , Θ0 , Φ(C0 , Θ0 ))
and

DC Φ(C0 , Θ0 ) = − (DΦ g2 (C0 , Θ0 , Φ(C0 , Θ0 )))−1 DC g2 (C0 , Θ0 , Φ(C0 , Θ0 )).
We need to describe DX f .
DΘ f (C, Θ, Φ) = DΘ DΦ h(C, Θ, Φ) = −2

Vanilla
wi DTΦ PVVanilla
Calibrated (i, C, Φ)DΘ PVBase (i, C, Θ).
i=1,...,n

DC f (C, Θ, Φ)
=

−2

Vanilla
Vanilla
wi DTΦ PVVanilla
Calibrated (i, C, Φ) DC PVBase (i, C, Θ) − DC PVCalibrated (i, C, Φ)
i=1,...,n
Vanilla
Vanilla
wi PVVanilla
Base (i, C, Θ) − PVCalibrated (i, C, Φ) DC DΦ PVCalibrated (i, C, Φ)

−2
i=1,...,n

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

1153

DΦ f (C, Θ, Φ)
=

DΦ DΦ h(C, Θ, Φ) = 2

T
Vanilla
wi DΦ PVVanilla
Calibrated (i, C, Φ)DΦ PVCalibrated (i, C, Φ)
i=1,...,n

−2

wi PVVanilla
Base (i, C, Θ)

2
Vanilla
− PVVanilla
Calibrated (i, C, Φ) DΦ PVCalibrated (i, C, Φ).

i=1,...,n

The annoying parts are the second order parts. Usually the ﬁrst order derivatives are implemented in AD
frameworks but not the second order one. Fortunately in the above formula, the second order derivatives are
Vanilla
multiplied by PVVanilla
Base (i, C, Θ) − PVCalibrated (i, C, Φ) which is small when the calibrated model can match the base
prices well enough. Based on that, we can use the following approximations:
DC f (C, Θ, Φ)

−2

Vanilla
Vanilla
wi DTΦ PVVanilla
Calibrated (i, C, Φ) DC PVBase (i, C, Θ) − DC PVCalibrated (i, C, Φ) .
i=1,...,n

DΦ f (C, Θ, Φ)

Vanilla
wi DTΦ PVVanilla
Calibrated (i, C, Φ)DΦ PVCalibrated (i, C, Φ)

2
i=1,...,n

This is very similar to the approximation done in computing Hessian as described in [19, Section 14.4].
6. Least Square Examples
In this section we analyse an example similar to the second one of the previous example section. The model is
a Libor Market Model with displaced diﬀusion. We calibrate two parameters for each maturity: the volatility and
the displacement parameters. The volatility parameter guide the general level of the smile while the displacement
parameter command the skew of the smile. We calibrate the two parameters by a least square approach on the
price of swaptions with several strikes. In the tests we use between 2 and 6 strikes.
The calibration is done for each yearly block on a multiplicative factor to given weights to obtain volatilities
and on a shared displacement. The more diﬃcult the calibration is, the better the results of AD with implicit
function will be on a relative basis. The algorithmic diﬀerentiation with implicit theorem method is using the
already computed calibration in the sensitivity.
The reference example has a tenor of ﬁve years and there are ﬁve annual calibrations. The calibration on each
tenor is done on three strikes (-100, 0, +100) bps from ATM. In the ﬁnite diﬀerence approach, the ratio is roughly
3 (SABR) + 4 (semi-annual payments with 2 curve) for each years. For a ﬁve years tenor, the ﬁnite diﬀerence
ratio is around 36. The ratio obtained in practice in this example through AD with implicit function is 1.40.
We run the same test with several tenors, between 2 years and 30 years. The calibration is similarly annual on
three swaptions for each calibration date. In a ﬁnite diﬀerence the ratios would increase roughly linearly with the
tenor. Figure 2 reports the results. As in the previous examples, the metric to analyse the eﬃciency is the ratio
between price and derivatives time and price time. The derivatives are the SABR and curve sensitivities.
The linear increase of the ratios with the tenors is obvious for the ﬁnite diﬀerence method. The AD with
implicit function method achieves a relatively constant ratio which is barely above 1 and well below 1.5. This
is well below the theoretical upper bound of ωA ∈ [3, 4]. In the case of the 20-year swaption, the gain between
the ﬁnite diﬀerence and optimised AD with implicit function is around 100. In practice this is reducing the
computation time from 1 hour 40 minutes to 1 minute.
7. Conclusion
With the adjoint mode of algorithmic diﬀerentiation techniques, one can, in general, obtain all the derivatives
of the output with respect to the inputs at the computation cost of less than a ﬁxed constant (between three and
four in theory) times the cost of one price.

1154

Marc Henrard / Procedia Computer Science 18 (2013) 1145 – 1154

4AAD Price+Vega+Delta

AAD Price+Vega+Delta
FD Price+Vega+Delta

140

3.5
120

3
2.5
Ratio

Ratio

100
80
60

2

1.5

40

1

20

0.5

0

0

5

10

15
Tenor

(a) Full picture

20

25

30

0

0

5

10

15
Tenor

20

25

30

(b) AAD picture

Fig. 2. Computation time ratios (price and sensitivities time to price time) for the ﬁnite diﬀerence and AAD methods. The vega represents the
derivatives with respect to the SABR parameters; the delta represents the derivatives with respect to the curves. The AAD method uses the
implicit function approach. Figures for annually amortised swaptions in a LMM calibrated yearly to three vanilla swaptions in SABR.

This note focuses on a eﬃcient implementation in quantitative ﬁnance when a model calibration is part of the
pricing process. The calibration process is generally done through a numerical procedure requiring the calibrating function to be computed numerous times. Using the implicit function theorem, we are able to compute the
derivatives of the total process without requiring the derivative of the calibrating process itself.
By bypassing the calibration algorithm derivatives, a substantial performance gain is achieved. The gain is
possible only using the domain speciﬁc knowledge of the pricing process; it can not be achieved using automatic
diﬀerentiation. The gain is larger when the calibration process is an important part of the full pricing process. In
all the examples presented the cost ratio obtained in practice is below 2.0. In the most complex case, the cost ratio
obtain is practice is very close to 1.
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]

[18]
[19]

M. Giles, P. Glasserman, Smoking adjoints: fast Monte Carlo greeks., Risk 19 (2006) 88–92.
N. Denson, M. Joshi, Fast and accurate Greeks for the Libor Market Model., Journal of Computational Finance. 14 (4) (2009) 115–140.
N. Denson, M. Joshi, Flaming logs., Wilmott Journal 1 (2009) 5–6.
C. Kaebe, J. Maruhn, E. Sachs, Adjoint based Monte Carlo calibration of ﬁnancial market models., Finance and Stochastics 13 (3) (2009)
351–379.
L. Capriotti, M. Giles, Fast correlation Greeks by adjoint algorithmic diﬀerentiation., Risk 23 (3) (2010) 79–83.
L. Capriotti, J. Lee, M. Peacock, Real time counterparty credit risk management in Monte Carlo, Risk (2011) 86–90.
L. Capriotti, M. Giles, Algorithmic diﬀerentiation: Adjoint greeks made easy, Working Paper Series 1801522, SSRN (2011).
L. Capriotti, Fast Greeks by algorithmic diﬀerentiation, The Journal of Computational Finance 14 (3) (2011) 3–35.
A. Griewank, A. Walther, Evaluating derivatives: principles and techniques of algorithmic diﬀerentiation., 2nd Edition, SIAM, 2008.
M. Henrard, Adjoint algorithmic diﬀerentiation: Calibration and implicit function theorem., Journal of Computational Finance to appear.
S. Schlenkirch, Eﬃcient calibration of the hull-white model, Optimal Control Applications and Methods 33 (3) (2012) 352–362.
B. Christianson, Reverse accumulation and implicit functions, Optimisation Methods and Software 9 (4) (1998) 307–322.
M. B. Giles, N. A. Pierce, An introduction to adjoint approach to design., Flow, Turbulence and Combustion 65 (2000) 393–415.
M. Henrard, The irony in the derivatives discounting - Part II: the crisis, Wilmott Journal 2 (6) (2010) 301–316.
P. Hagan, D. Kumar, A. Lesniewski, D. Woodward, Managing smile risk, Wilmott Magazine Sep (2002) 84–108.
M. Henrard, Explicit bond option and swaption formula in Heath-Jarrow-Morton one-factor model, International Journal of Theoretical
and Applied Finance 6 (1) (2003) 57–72.
M. Henrard, Cash-settled swaptions: How wrong are we?, Working paper series 1703846, SSRN, available at SSRN:
http://ssrn.com/abstract=1703846 (2010).
URL http://ssrn.com/abstract=1703846
M. Henrard, Swaptions in Libor Market Model with local volatility, Wilmott Journal 2 (3) (2010) 135–154.
W. H. Press, B. P. Flannery, S. A. Teukolsky, W. T. Vetterling, Numerical Recipes in C: The Art of Scientiﬁc Computing, Cambridge
University Press, 1988.

