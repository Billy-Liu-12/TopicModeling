Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 1179 – 1188

2013 International Conference on Computational Science

Precision difference management using a common sub-vector to
extend the extended VSM method
David Werner, Christophe Cruz*
LE2I Laboratory, UMR CNRS 6306, BP 47870, 21078 Dijon Cedex, France

Abstract
Contractors, commercial and business decision-makers need economical information to drive their decisions. The
production and distribution of a press review about French regional economic actors represents a prospecting tool on
partners and competitors for the businessman. Our goal is to propose a customized review for each user, thus reducing the
overload of useless information. Some systems for recommending news items already exist. The usefulness of external
knowledge to improve the process has already been explained in information retrieval.
ncludes the domain knowledge used during the recommendation process. Our recommender system architecture is standard,
ed
on this domain knowledge. Articles and Profiles are semantically defined in the Knowledge base via concepts, instances
and relations. This paper deals with the relevance measure, a critical sub-task in recommendation systems and relationships
between relevance and similarity concepts. The Vector Space Model is a well-known model used for relevance ranking.
The problematic exposed here is the utilization of the standard VSM method with our indexing method.
©
The Authors.
Authors. Published
© 2013
2013 The
Published by
by Elsevier
Elsevier B.V.
B.V. Open access under CC BY-NC-ND license.
Selection
and/or
peer-review
under
responsibility
of the
organizers
of 2013
the 2013
International
Conference
on Computational
Selection and
peer
review under
responsibility
of the
organizers
of the
International
Conference
on Computational
Science
Science
Keywords: recommender system; news; domain ontology; ontologies; knowledge base; indexing; recommendation; vector space model

1. Introduction
The decision-making process in the economic field requires the centralization and intake of a large amount
of information. The aim is to keep abreast with current market trends. Thus, contractors, business men and
sales persons need to continuously be aware of the market conditions. This means to be up-to-date regarding
ongoing information and projects undergoing development. With the help of economic monitoring, prospects

* Corresponding author. E-mail address: {david.werner , christophe.cruz}@u-bourgogne.fr

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.284

1180

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

can be easily identified, so as to establish new contracts. Our tool is specialized in the production and distribution of press reviews about French regional economic actors.
The reviews sent are the same for each user, but personalized according to a geo-graphic area. All articles
useless information, we are moving towards a customized review for each user. Therefore, an opinion survey
on magazine readers that covers a broad array of subjects, including news services, was undertaken. Criteria for
a relevant customization of the review were identified as a result of this survey as well as expert domain
knowledge. These criteria are economic themes (i.e. main economic events), economic sectors, major transverse projects, temporal and localization data about each element underlined. Therefore, the complete production process of the review was redesigned to produce and to automatically distribute a customized review for
each user. Another drawback in the existing process is the produced information storage. News articles are
stored as PDF file reviews (i.e. the same format that is sent to customers, natural language), but this unstructured format is hard to handle and reuse.
The aim of the architecture is to manage all news produced, and provide the most relevant article for each
customer, using our domain knowledge. The overload of news information is a particular case of information
overload, which is a well-known problem, studied by Information Retrieval and Recommender Systems research fields. News recommender systems already exist [14] [9] [13] [21] SCENE [12] NewsJunkie [8] Athena
[10] GroupLens [18] News Dude [3] et YourNews [4]. Some of these systems use domain knowledge to improve the recommendation task [10] [14].
To achieve this goal, a content-based recommender system is being developed. A recommender system is
necessary for the item ranking. And content-base is required to analyze the content of each article to structure
and preserve information content. The results of the analysis enable to link the domain knowledge to the articles. Because, the domain knowledge can be reused to improve the recommendation task [10] [14].
This paper is organized as follows: Section 2 presents a brief review of related work. In section 3, we outline
the proposed solution of a recommender system. Section 4 presents the similarity measure task, and our implementation of VMS. Section 5 is the conclusion and future work.
2. Related work
Our work is related to several works in News recommender systems, SCENE [12] NewsJunkie [8] Athena
[10] News Dude [3] et YourNews [4]. The survey of K. Nagewara Rao [15] proposed a general comparison of
the main ad-vantages and drawbacks of each kind of Recommender System (e.g. content based or collaborative
filtering). The advantages of content-based recommender systems for news recommendation are also explained
in [13] to improve the Google news platform. The main drawback of collaborative filtering systems is the recommendation of new items. Novelty is very important in the particular case of news; each new article must be
quickly recommended. Waiting for enough users to have read it before recommending is a big waste of time.
Furthermore, we need to be able to recommend for very particular user profiles, as some customer needs are
unique.
There are many systems that work without Knowledge [13] [3] [18]. The advantages of using exterior
knowledge for enhancing the recommendation were exposed by Ijntema [10]. He uses the name semantic-based
recommender system to distinguish standard content-based systems from the systems using external knowledge
(e.g. domain ontologies or lexical knowledge as WordNet [7]). Lexical knowledge is used by [9] and domain
knowledge by [14]. Athena uses both [10]. Ontologies used by these systems already exist or are created and
maintained by hand. Unlike previous systems, the Knowledge base containing domain Knowledge is used as an
index for articles and profiles, as it is explained in section 3. To compare profiles and articles, classic VSM is
not directly usable, so we have adapted it, as presented in section 4.

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

3. Implementation
Our system is an ontology drive content based recommender system. An ontology schema is created and
populated with the help of company experts, in order to model the domain knowledge in a knowledge base. In a
classic content-based recommender system, we distinguish two main tasks. The first is indexing. The task is to
s, and item content. The Knowledge base will be populated during
this task. The quality of content analysis is important for the knowledge base population and for indexing, so
our system is semi-supervised by an expert. The second task is comparison. This task is the comparison with
item representation so as to measure the degree of relevance for each profile. Items are ranked with the help of
the similarity measure, after being provided to the user. These subjects are developed as follows.
3.1. The Knowledge base
The knowledge base K used for this system is composed of several ontologies [23]. An Upper level ontology is used to manage information shared by all application areas (in the case of an extension of the system to
new fields of application). High level concepts like location, geospatial information, temporality, events,
agents, etc. Domain ontology is used to manage domain-specific knowledge. Concepts of this ontology are
mainly specialization of concepts from the upper level. Other ontologies are used to manage articles, profiles,
and lexical resources used by a gazetteer. The lexical resource ontology is based on the ontology PROTON
used on the KIM platform [17]. In this paper the knowledge base model defined by Ehrig et al. [6] and based
on the Karlsruhe Ontology Model is used [20].
Definition 1 Ontology:

are disjoint sets of concepts, data types, relations and attributes,
are hierWherein
are function that provide the signature for each
archy of classes, data types, relations and attributes, and
attribute and
relation.
Definition 2 Knowledge Base:

Wherein
data values.

are disjoint sets of concepts, data types, relation attributes, instances and
is the classes instantiation function
.
is the data type instantiation function
. is the relation instantiation function
. is the attribute instantiation function
.

3.2. Indexing
To archive the recommendation of articles to customers, the system needs are a representation of the content
of each article, and representation of the needs of each customer. The index used in our system is the same for
articles and profiles. The knowledge base used has an index. Articles and profiles are represented by instances
in our knowledge base. Some relations in the system ontologies are used to model of article content, and users
interests.

1181

1182

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

Article indexing
The ambition is to create a machine understandable representation of the content of each article, so as to
compare with profiles. The unstructured information contained in articles is analyzed. Two kinds of information can be distinguished: explicit pieces of information (e.g. places, persons, organizations and so on) and
implicit pieces of information (e.g. the theme of each article). In the system, the theme is one criterion, corresponding to the main event related by the article. Company experts have predefined a hierarchical list of themes
wherein each article must be classified. The tasks of information extraction, annotation, indexing are done with
the help of the GATE platform [5]. A web interface was developed. It enables the writers to create articles.
Results of the analysis are presented in it. They can be validated/corrected by the writer.
Analysis
Some post processes are applied into articles, such as tokenizers, sentence splitters, POS taggers, gazetteers
(which use the knowledge base lexical resources as a dictionary) before JAPE patterns matching engine. In the
first prototype, we used handmade lexico-semantic patterns. The aim is to extract important entities (explicit
ts of analysis are hand-checked, corrected and validated. Implicit pieces of information are specifically handmade.
Population
For each article analyzed, an instance of the concept article is created in the knowledge base, so as to represent the article. Automatic analysis, correction done by hand and specifications of not automatically funded
criteria are used to characterize the content of each article. Relations are created in the knowledge base between
(result of the analysis). Instances of criteria and relations with the
instances of articles permit to index the article and create a semantic representation understandable by the machine.
Profiles indexing
In the company, sellers are in charge of understanding the needs of each customer. Several phone calls are
necessary so as to acquire future customers. During the phone call the seller proposes a free trial period. This
helps to create a first handmade profile for each customer by an expert, and avoids the problem of a cold start,
common to all content-based recommender systems.
The profile indexing process is the same as the articles. A profile instance is created in the knowledge base.
Relations are created between the profile instance and criteria instances. A web interface was developed to
enable sellers to define / change the user profile. The choices are reflected in the Knowledge base that permits
to index the profile, and create a semantic representation understandable by the machine.
3.3. Recommendation
The recommendation task is mainly based on the comparison between the profile and available items. The
knowledge base is used by the system like an index, and profiles and articles are presented by a set of instances
and relations. For each article validated by writers, the full content is inserted in the database and a representation of the article is created in the knowledge base. An instance of the concept article and an instance of each
the article with its criteria. For each profile made by the sellers, the representation is created in the knowledge base. An instance of the concept profile is created, and each isInterestedI relation between the profile instance and its criteria are instanced. We present the comparison method
used in the following section.

1183

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

4. Comparison
The comparison task enables to evaluate the relevance of an article for a profile, via some similarity
measures between them. Classical methods directly used the similarity as a measure of relevance. The profile
can be seen like the ideal item, so, more an item is similar to the ideal item (profile) more it is relevant to the
user interests.
is a function to measure the degree of similarity between
Definition 3 similarity:
and . The similarity function can satisfy some properties:
Positiveness
Reflexivity
. But this axom is open for debate in the
The last one is the symmetry,
community.
To extricate ourselves from the debate on symmetric or unsymmetric property of similarity, we chose to remain the classical analogy with the distance and so, to define the similarity with the symmetry axiom. Also we
used well-known algorithms for the comparison of vectors (e.i. Cosine similarity, Jaccard similarity and Euclidean distance) and these algorithms are symmetric. However our final measure, the relevant measure, is an
unsymmetric function. In our context, we need an asymmetric function for the relevance, because we consider
that comparing profiles and articles is not the same as comparing two articles.
4.1. VSM
An approach based on the vector space model [19] was used in the prototype. Articles and profiles are represented by vectors on a space wherein each dimension is a potential instance of criteria. Several methods can be
used to compare vectors; the most common is the cosine similarity.
(1)
An article can be defined like a vector of instances of Entities and criteria. For the recommendation task in
the prototype only instances of criteria are used.

Wherein, an article is represented by a vector

composed by a set of instances

Instances are instances of concepts belonging to the set of concepts
contains all instances of all concepts in the set .

The set

is a subset of the set of all instances of the Knowledge Base

A profile can be defined as a vector of instances of criteria.

.

defined by indexing criteria. The set

.

1184

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

Where, a profile is represented by a vector

composed of a set of instances

.

In our implementation, one vector for each criterion is used. This enables to weigh or use different similarity
measures (e.g. cosine, jacquard, Euclidian) for each criterion. For example, location, theme and sectors are
much more important than project and organization and so highly weighed.
(2)

.
rion.

Is the similarity between profile
And

and article
and
the coefficient for a specific criterion
. One or more concepts are defined for each crite-

Methods from the information retrieval fields can be used to enhance the recommendation. One of the first
systems using external knowledge to improve the understanding of user needs is [22]. The Voorhees approach
used WordNet [7] to provide a query expansion. We can translate this kind of method to recommender systems,
[14] uses this method
without naming it. Ijntema [10] also uses it, but unlike Middleton, he uses more powerful ontology relations
(not just is_a) to expand the user profile. In our system, the profile expansion takes the form of adding instancshows an interest for company Co and in the knowledge base a symmetric relation
profile. Our version of the Expanded VSM is developed in the following section.
4.2. Expanded vectors
The 4.1 section presents an implementation of the similarity measure between two instances, by the creation
of vectors of related instances. It was explained by Voorhees [22] in the VSM that all dimensions are orthogonal and so, all elements of each vector are considered as independent. That is not really the case for the lexical
mic
relations defined in WorldNet are used to add related lexical to the vector. In our case, relations between individuals exist, because we used a Knowledge base to manage the domain knowledge, and our criteria are hierarchically defined in it.
method, it seems logical to exMeronomic relations exist between instances of Location.
pand the profile (the query for Voorhees) with all sub instances enclosed by the most general instance. For
example, if the profile is interested in Bourgogne (Region, biggest Administrative division), it seems logical to
within the Bourgogne region, and Dijon, Beaune, Chenove, Auxerre, which are cities within these departments. But, in the real case with this method, it is necessary to add four departments and its 2047 cities to the
vector. The similarity between a profile interested in Bourgogne and an article about Dijon will be very low
with this method.
So our method is to expand profile and articles, not only the profile and limiting the size of vector, instances
added are including instances, not included (by meronomic relations). So our method is analogue to graphbased methods which search the common ancestor.

1185

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

With this method the first drawback is solved, but the second still is not. Our Relevant function is symmetric
and equivalent to the Similarity function. The precision of an article must not have the same consequences for
the Relevance as the precision of a profile. This problem is the subject of the following section.
5. Relevance
The previous section looked at how to take into account the relations between instances in the VSM. In this
section in contrast with the section 4 the relevance is no longer defined as an equivalent of the similarity. This
section is about the managing of the difference of precision between profiles and articles and its influence in
the relevance e.g. if an article is about Dijon and a Profile is interested in Bourgogne, the relevance must be
higher than the case of an article about Bourgogne and Profile is interested in Dijon, because of the loss of
precision (Dijon is a city located in Bourgogne). To solve this problem we used an intermediate vector for each
criterion, a sub vector composed of common instances of the article and profile vectors for the criteria.
is a function to measure the degree of relevance of
Definition 4 Relevance:
an article relative to a profile . The similarity function can satisfy some properties:
Positiveness
Reflexivity
The relevance is a concept from information science largely used in the fields of information retrieval and
recommender systems. In our case the Relevance is not binary; an article can more or less meets the information need of the user.
generals concepts enclosed more specifics ones. In the
Definition 5 Precision: In the concepts
hierarchy of instances it is the same. Instances from the top of the hierarchy are less specific than instances
from the bottom.
If the Article is about an instance form the bottom and the Profile is interested in top instance (of the same
branch), the relevant must be higher than if the Article is about a top instance and the Profile is inserted in an
instance from the bottom of the hierarchy because there is a loss of precision if the profile is more specific than
the article, so the article is less relevant.

is the sub set of common elements of the set of instances related to the profile

The vector

and the article

.

is composed by elements of the set
(3)

It is possible to weigh differently the precision of the profile and the precision of the article with this methand
, because we consider that the difference of preciod. In our implementation we used
is also possible to use different values according to the criterion.

1186

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

(4)
The final Relevance
(4) value is the sum of the Relevance measure for each criterion
eventually weighted. This measure is used for the ranking of articles proposed to the user according to his profile.

a

p

a

p

Exemple
E
l A.1
A1

Exemple
E
l A.2
A2

p

a

a

p
Exemple
E
l B
B.1
1

Exemple
l B.2

Fig. 1. Exemples of profiles and articles for a sigle criterion.

With this method the Relevance value for the case A.2 (Fig. 1.) is higher than the case A.1, because in the
case A.2, and have more common ancestors than in the case A.2. Moreover, the cases B.1 and B.2 figure
the problem of precision. With our asymmetric method the value of similarity between and in the case B.1
is higher than in the case B.2 because the user needs are specific and the article information (about this criterion) very general relative to the user needs. So the article is less relevant for the user. The following section
presents the conclusion and future work.
6. Conclusion and future work
In this paper we have presented the adaptation of a standard VSM recommender system to our specific
method of indexing (e.g. articles and profiles are semantically defined in the knowledge base via relations with
the domain knowledge already defined in it). We first presented the context, our goal, and the existing approaches, then we explained the architecture in detail. Finally we explained the specific task of comparison that
we adapted to our case.
As future work, we are planning to improve our system in two different ways. Firstly, we want to improve
the information extraction task to extract Events. Articles are mainly event-based. The rationale of each article
is to relating events. An event is gene
This kind of information is really valuable, so it is very important to store it in a formalized way. Moreover,
each customer is interested in some kind of event or some kind of role for some kind of organization during an
event. For a good understanding of the content of each article and thus a valid indexing, the extraction of the
events they contain is an important task. Today, the extraction process mainly focuses on Named Entities and

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

Relations between NE. More recently, the research community on knowledge extraction focus on Event extraction [11] [2] [21] [16]. Secondly, we want to improve the recommendation with a graph-based semantic similarity measure between profiles and articles. The idea is that our ontology is already structured information, so
to restructure it to a vector space model for the comparison task must be useless. Moreover, for some criterion
we have different levels of specificity that are difficult to manage in Vector Space. Some approaches to compare instances already exist [1] [6]. We want to adapt the Albertoni and De Martino framework to our system
with another vision of the semantic content in relation instances.
Acknowledgements
These This project if founded by the company Actualis SARL and the financing CIFRE research grant from
the French agency ANRT.

References
[1] Albertoni, R., De Martino, M.: Semantic Similarity of Ontology Instances Tailored on the Application Context. On the Move to
Meaningful Internet Systems 2006: CoopIS, DOA, GADA, and ODBASE, Vol. 4275, Lecture Notes in Computer Science, 2006, pp.
1020 1038.
[2] Aone, C., Ramos-Santacruz, M.: REES: A Large-Scale Relation and Event Extractio System. In: 6th Applied Natural Language
Processing Con-ference (ANLP 2000). pp. 76-83. Association for Computational Linguistics (2000)
[3] Billsus, D., Pazzani, M.J.: A Personal News Agent that Talks, Learns and Explains. In: The Third Annual Conference on Autonomous
Agents, ACM (1999) 268 275
[4] Ahn, J., Brusilovsky, P., Grady, J., He, D., Syn, S.Y.: Open User Profiles for Adaptive News Systems: Help or Harm? In: 16th
international conference on World Wide Web, ACM (2007) 11 20
[5] Cunningham, H.: GATE, a General Architecture for Text Engineering. Computers and the Humanities 36 (2002) 223 254
[6] Ehrig, M., Haase, P., Stojanovic, N., and Hefke, M.: Similarity for Ontologies - A Comprehensive Framework. ECIS 2005.
Regensburg, Germany (2005)
[7] Fellbaum, C., ed.: WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA (1998)
[8] Gabrilovich, E., Dumais, S., Horvitz E.: Newsjunkie: providing personalized newsfeeds via analysis of information novelty. In WWW
2004, pages 482 490.
[9] Getahun, F., Tekli, J., Richard, C., Viviani, M., Yetongnon, K.: Relating RSS News/Items. In: 9th International Conference on Web
Engineering, Springer (2009) 442 452
[10] IJntema, W., Goossen, F., Frasincar, F., Hogenboom, F.: Ontology-Based News Recommendation. In: International Workshop on
Business intelligence and the Web (BEWEB 2010), EDBT/ICDT Workshops. pp. 16:1{16:6. ACM, New York, USA (2010)
[11] Li, F., Sheng, H., Zhang, D.: Event Pattern Discovery from the Stock Market Bulletin. In: 5th International Conference on Discovery
Science (DS 2002). Lecture Notes in Computer Science, vol. 2534, pp. 35-49. Springer-Verlag Berlin Heidelberg (2002)
[12] Li, L., Wang, D., Li, T., Knox, D., Padmanabhan, B.: SCENE: A scalable two-stage personalized news recommendation system. In
Proc. the 34th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Beijing, China,
Jul. 25-29, 2011, pp.124-134.
[13] Liu, J., Dolan, P., Pedersen, E.R.: Personalized news recommendation based on click behavior. In Proceedings of the 15th
International Conference on Intelligent User Interfaces, pages 31 40. ACM, 2010.
[14] Middleton, S.E., Shadbolt, N.R., Roure, D.C.D.: Ontological User Profiling in Recommender Systems. ACM Transactions on
Information Systems 22(1) (2004) 54 88
[15] Nageswara Rao, K., Talwar, V.G.: Application Domain and Functional Classification of Recommender Systems A Survey, Journal
of Library & Information Technology, Vol. 28, No. 3: 17-35, 2008.
[16] Piskorski, J., Tanev, H., Wennerberg, P.O.: Extracting Violent Events From On-Line News for Ontology Population. In: 10th
International Conference on Business Information Systems (BIS 2007). Lecture Notes in Computer Science, vol. 4439, pp. 287-300.
Springer-Verlag Berlin Heidelberg (2007)
[17] Popov B., Kiryakov A., Kirilov A., Manov D., Ognyanoff D., Goranov M.: KIM Semantic Annotation Platform 2003

1187

1188

David Werner and Christophe Cruz / Procedia Computer Science 18 (2013) 1179 – 1188

[18] Resnick, P., Iacovou, N., Suchak, M., Bergstrom, P., Riedl, J.: GroupLens: An open architecture for collaborative filtering of netnews.
In Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work, Chapel Hill, North Carolina, United States.
ACM Press, New York, 1994. pp. 175-186.
[19] Salton, G.: The SMART retrieval system : Experiments in automatic document processing. Prentice Hall, 1970.
[20] Stumme, G., Ehrig, M., Handschuh, S., Hotho, A., Maedche, A., Motik, B., Oberle, D., Schmitz, C., Staab, S., Stojanovic, L.,
Stojanovic, N., Studer, R., Sure, Y., Volz, R., Zacharias, V.: The Karlsruhe view on ontologies. Technical report, University of
Karlsruhe, Institute AIFB (2003)
[21] Tanev, H., Piskorski, J., Atkinson, M.: Real-Time News Event Extraction for Global Crisis Monitoring. In: 13th International
Conference on Natural Language and Information Systems: Applications of Natural Language to Information Systems (NLDB 2008).
Lecture Notes in Computer Science, vol. 5039, pp. 207-218. Springer-Verlag Berlin Heidelberg (2008)
[22] Voorhees, E., Query Expansion using Lexical-Semantic Relations. 1994
[23] Werner, D., Cruz, C., Nicolle, C.: Ontology-based Recommender system of economic articles; In Proceedings of the 2012 Webist
Conference, Porto.

