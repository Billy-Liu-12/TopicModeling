Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 179 – 188

International Conference on Computational Science, ICCS 2013

Predictive and distributed routing balancing, an application-aware
approach
Carlos N´un˜ ez Castillo*a , Diego Lugonesb , Daniel Francoa , Emilio Luquea , Martin
Collierb
a Computer

Architecture and Operating Systems Department, Universitat Aut`onoma de Barcelona, Bellaterra, Spain
b School of Electronic Engineering, Dublin City University, Glasnevin, Dublin 9, Ireland

Abstract
The interconnection design in computing clusters and data centers is expected to change signiﬁcantly in the near future to
sustain the increasing communication demand at controlled capitalization and operational cost. In particular, a shift from typical and expensive full-bisection bandwidth interconnects (which safely cover the worst communication cases) to application
oriented designs (which may provide cost-eﬃcient data movement at larger system scales) is devised in academic research
and industry initiatives. Having information of communication dynamics of applications (e.g. repetitiveness, computing and
communication phases, traﬃc pattern and bandwidth, etc. ) allows for eﬃciently managing and provisioning of network resources at reduced cost. This paper presents an Application-Aware Predictive and Distributed Routing Balancing technique
(PR-DRB), a new method that controls network ineﬃciencies based on communication patterns of applications and speculative
routing, PR-DRB monitors increments in the communication latency and, then, dynamically re-distributes the network traﬃc
over multiple paths (path expansion) to deal with load unbalances. Additionally, PR-DRB stores the number of paths used to
balance the traﬃc (solution) and links it to the application’s pattern that caused the unbalance (problem). This information
allows PR-DRB to respond to similar situations in repetitive patterns, quickly converging to a stable solution.
Evaluation results show latency and completion time reductions of up to 37% for experiments conducted on 64 nodes executing
the NAS benchmarks and the Lammps application.
Keywords: Interconnection networks; high performance computing; predictive routing; hpc clusters; parallel scientiﬁc
applications; application-aware routing

1. Introduction
In the early days of High Performance Computing (HPC) systems, interconnection network high latency and
low bandwidth bottleneck signiﬁcantly aﬀected applications execution. Advances in current interconnection technologies such as InﬁniBand (IBA) [1] and 10 gigabit Ethernet allowed high data transmission rate and low trip
latency, fulﬁlling with HPC requirements. Moreover, current switches in HPC are provided with capabilities to
evaluate and adapt communication load according to network condition. HPC communications are characterized
by bursty traﬃc behavior, as opposite to a randomly constant packet injection [2]. Bursty traﬃc can produce
Hot-Spot situations, where some network resources are quite congested while others remains idle. If congestion
∗ Corresponding

author. Tel.: +34 93 581 1990 ; fax: +34 93 581 2478 .
E-mail address: cnunez@caos.uab.es.

1877-0509 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.181

180

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

is not eﬃciently controlled, message latency is increased and system performance is severely degraded. One solution to this problem is the use of adaptive routing algorithms. Robustness is important in this kind of algorithms.
For example, an algorithm should make proper decisions, despite monitoring information is not always accurate.
This issue raises a trade oﬀ: if good decisions are needed, more information is required, but more information
means more overhead. Therefore, the amount of information needed and the overhead required to process this
information must be balanced.
Consequently, an eﬃcient routing algorithm has to extract the smartest behavior from the information it has,
and must provide a fast response time. In this sense, it could be interesting that the routing algorithm could
learn form past situations to react faster and smarter. Communication patterns in parallel applications tend to
be repetitive in time [3]. This repetitiveness could be useful as a routing module input in order to decide about
future network conditions based on previously analyzed information. A speculative approach could be used to
dynamically adapt to traﬃc conditions, where decision about how to deal with actual congestion is based on past
situations.
In this paper we present the Application-Aware Predictive and Distributed Routing Balancing (PR-DRB), a
new adaptive routing policy that uses several alternative paths simultaneously, in order to increase the available
eﬀective bandwidth between src-dst pairs for packet delivery under repetitive communication patterns. PR-DRB
is based in the work presented in [4] and [5] but enhanced with new capabilities of current switches in order to
prevent network congestion. It is based on dynamic patterns recognition of parallel scientiﬁc applications. In this
sense, future decisions are based on information saved from communication patterns.
PR-DRB is enhanced with a predictive routing module. PR-DRB adapts itself by opening or closing alternative
paths when congestion is detected. This process is performed until the network becomes stable again, which
could be a time-consuming task. The main contributions of this work is the capability to learn from a real parallel
application communication patterns, in order to save the best solution, and use it when similar congestion is
detected again. This approach allows fast reaction to persistent and repetitive congestion patterns.
The paper is organized as follows. Section 2 presents the background and justiﬁcation of this work. In section
3 a description of our PR-DRB methodology is given. Section 4 shows the systematic analysis technique used.
Section 5 shows the evaluation with real applications. Finally, conclusions are given in section 6.
2. Background and Justiﬁcation
2.1. Parallel Application Phases - Repetitiveness
Studies of parallel applications in HPC reveal they have repetitive behavior, based on computing and communication phases [3]. Programs in general tend to be written in a modular fashion, and have a very strong periodic
behavior [16]. An example is given on Fig. 1, where the repetitive behavior of the NAMD [17] application is
shown. Here, some communications take longer than others (green bars). This imbalance in the communications
causes that some processes become idle (red bars). These ineﬃciencies are repeated in each application phase.
Fig. 2 shows an extract from one communication pattern of MG. Here if communications between nodes 0-1 and
0-3 could be reduced, then also the time for the MPI Wait state will decrease. This will allow the next primitives
for nodes 1 MPI Send 4 and node 3 MPI Send 12 to execute earlier. As this procedure is part of a signiﬁcant
phase of the MG application, a reduction in this communication will be applied every time this patterns re-appears.
This repetitive behavior represented by fundamental phases of the entire application can lead to situations where
speciﬁc traﬃc patterns reappear. A phase of an application includes one or more communicating patterns, represented by a set of source/destination pairs as shown in Fig. 3 (a). Representative phases from parallel applications
can be extracted by using the PAS2P performance prediction tool [3]. In table 1 we can see a summary of parallel
applications, their representative phases and weights (how many times it is repeated during execution).
2.2. PR-DRB Strategy
Based on the concept of an application phase and its repetitiveness, the PR-DRB strategy will be exposed.
An example of a traﬃc pattern contained in one phase is shown in Fig. 3 (a). Here, one phase is represented
by a set of sources and all its destination nodes (Dx in Fig. 3 (a)). In ﬁg. 3 (b), during ﬁrst parallel application
phase, PR-DRB has high latency values at the beginning (1), because the method is searching alternative paths

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

Fig. 1. Repetitiveness in Parallel Apps.

Fig. 2. NAS MG Pattern (6 of 64 tasks shown)

to keep latency controlled. At the end of phase 1 (2), latency is stable and then, the best solutions encountered
are saved at the source node. Best solutions are identiﬁed when latency curve has reached its highest point and
it starts decreasing, so a good balance of traﬃc has been found and all messages are properly distributed. In
later phases, latency does not reach its highest historical value, because PR-DRB has identiﬁed already analyzed
similar communication patterns (3) and injected new messages through best alternative paths saved earlier (4).
This approach allows PR-DRB to have stable latency values during the whole parallel application execution.
2.3. Justiﬁcation
Based on previous examples of communication patterns repetitiveness, we can say that High Speed Interconnection Networks (HSIN) routing performance depends mostly on the communication pattern used and the
mapping of nodes to processors. PR-DRB tries to improve communication imbalance situations by distributing
communications in a better way. To improve communication performance, hence applications currently running
in the network, a technique capable to dynamically combine adaptive algorithms and communication patterns is
needed, so that routing and congestion control can perform as fast as possible and minimize overhead.
3. Predictive-Distributed Routing Balancing
In [4] we proposed a routing algorithm, the basic PR-DRB, based on the study of communication latency and
repetitive synthetic patterns. We leverage this strategy for designing pattern recognition functionality. However,
the existing strategy suﬀers from following main limitations:

181

182

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

Table 1. Parallel Applications Phases
Parallel Application
Lammps Comb [18] [19]
NAS FT Class A [20]
NAS FT Class B
NAS MG Class S
NAS MG Class A
NAS MG Class B
SMG2000 Semicoarsening Multigrid Solver [21]
SWEEP3D: 3D Discrete Ordinates Neutron Transport [22]

Total Phases
49
6
6
21
25
27
10
80

Relevant Phases
1
5
5
12
11
3
4
5

Weight (# total of phases’ repetitions)
854
9
22
164
185
424
1200
46000

Fig. 3. (a) Traﬃc Pattern in One App. Phase; (b) PR-DRB-Process;

• The original DRB and the predictive module PR-DRB, lack the functionality to work with real applications
• DRB has been extensively evaluated only against synthetic traﬃc patterns [6] [10].
The Application-Aware PR-DRB has now been extended to tackle this limitation. For these reason, only the
relevant portions of it will be explained here.
3.1. PR-DRB Working Scheme
PR-DRB seeks better response time by using cached communication and alternative paths. In Fig. 4 the
normal or standard Packet delivery Process and the proposed model with its four main tasks are shown. These
tasks are: Monitoring, Notiﬁcation, Path Conﬁguration and Path Selection procedures. At the bottom of the ﬁgure,
it is shown where these tasks are done: at source endnode, at network message routing or at destination endnode.
Monitoring includes the tasks of latency values accumulation and contending ﬂows identiﬁcation, performed
at intermediate routers. Notiﬁcation is initiated at destination endnodes. Here, and Acknowledge (ACK) message
with path information is created and sent back to the source. The third task involves the conﬁguration of new
alternative paths (Metapath Conﬁguration) according to latency values, also performed at source nodes. If there
are saved solutions for a congestion situation, the paths are taken from the saved solution database. Otherwise,
new alternative paths are created. Later, the fourth task is accomplished when new messages are injected into the
network. Here, selection procedures distribute messages among the paths conﬁgured in previous task.
3.1.1. Metapath Conﬁguration
PR-DRB deﬁnes a Metapath as a set of possible alternative paths between each source-destination pair. Metapath Conﬁguration deﬁnes how to create alternative paths in order to expand single paths, and when to use them
according to congestion level in the network. Congestion level in the network is used by the routing unit in order
to perform the load distribution. To evaluate this congestion level then the Metapath latency concept is introduced.
This latency is deﬁned as the inverse of the inverse aggregate latency sum of every path conforming the Metapath
(MSP). These latencies are produced while a message is traversing along one path from the Metapath. The inverse
of the latency is in fact one path’s capacity. The Metapath latency is shown in equation 1.
L(M p) = (

S
1
−1
i=1 L(MS Pi) )

(1)

183

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188
Interconnection Network

Packet Delivery Process
Source

Path Selection
Build
Message

Multistep Path
Selection

Routing
Decision

free link

Message
Arrival

No

Message
Injection

Metapath
Configuration
Paths
Opening/Closing
procedures

Destination
Yes

Message
Delivery

Enqueue
packet

Read
Path

Write
Path

No

Latency
Accumulation

ACK
Arrival

Source endnode

Latency &
Contending Flows
Information

Monitoring

Current
Paths

Lat >
Threshold

Yes

Notification

Record
Contending
Flows

Message routing

ACK
Injection

ACK
Message

Destination endnode

Fig. 4. PR-DRB Diagram

3.2. PR-DRB Thresholds
In order to identify the proper time when an action must be performed by PR-DRB, thresholds are used , as
shown in Fig. 6 (a). According to latency values, three zones are deﬁned: Low (L), Medium (M) and High (H).
The low latency area represents low congestion situations. The medium latency area represents situations when
congestion is raising, but the network can handle all communications properly. This is the normal working zone.
High latency area represents high congestion in the network. While in low and medium latency zones, PR-DRB
does not open new paths. When latency values identiﬁes a transition between medium to higher zones, PR-DRB
starts opening procedures. These includes the searching of saved solutions or new paths opening procedures if
no solutions are saved so far. When congestion is controlled, latency returns to the middle zone and is a ﬂag that
good paths have been found. Here, path saving procedures are initiated. Finally, when latency values drops back
to the lower zone, path closing procedures are started.
3.3. Path Management
Metapah procedures conﬁgure alternative paths to be used accordingly to latency value and thresholds, as
shown in Fig. 5. If transition is from M (medium) to H (high) latency then it denotes congestion, then new
alternative paths are needed. PR-DRB then looks for an already analyzed congestion situation. If this is the
case, the set of alternative paths is retrieved from the database of saved solutions. If no solutions are found, then
alternative paths opening procedures are initiated. If transition is from H to M, information about contending
ﬂows during congestion situations is updated into the saved paths database. If transition is from M to L, latency
values denotes low congestion, then alternative paths closing procedures are invoked. All these procedures feed
the current paths database.
Later, when a new message is ready, PR-DRB performs the Path Selection. Here, PR-DRB selects which paths
are going to be used from those available in the current paths database. Paths that has lower latency values are
more frequently used. Given a source node with N alternative paths, let’s be Lc i(i : 1..N) the latency recorded by
path Ci. The alternative path Cx will be selected in the following injection according to the probability:
p(Cx) =

(1/LC x)
N
i=1 1/LC i

(2)

Furthermore, paths are selected according to their length. If paths are long in hops, message transmission time
could be high enough and lead to performance degradation, so shortest paths are selected. Bandwidths are calculated as the inverse of latencies received in source node. This information is used to build a probability density
function, and a path is selected according to equation 2.

184

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

Fig. 5. Meta Path Conﬁguration

Fig. 6. (a) Thresholds used; (b) Application Characterization Framework

As shown in Fig. 4, a message is forwarded without any overhead when the output port is free. Otherwise,
packet is queued and latency is simultaneously accumulated until the message is ready to be forwarded again.
PR-DRB is based on the DRB algorithm. DRB has been already proposed as a congestion control for Inﬁniband
[13]. As IBA already has functionalities required by PR-DRB (e.g. monitoring functions at IBA switches, the
congestion control architecture (CCA) has procedures for congestion notiﬁcation and path opening), PR-DRB
integration into the IBA standard is feasible.
4. Systematic Analysis Technique
The analysis of applications communication performance suggests a well deﬁned procedure for estimating the
suitability of a given network architecture/topology for a parallel application. This procedure is based on [23] but
adapted to communication performance in mind.
4.1. Obtain Application and Architecture Information
We ﬁrst identify various application characteristics which aﬀect performance. With network performance
in mind it is useful to measure the communication requirements of the application. The network topology and
routers/switches in question also needs to be carefully analyzed. It is important to take into account factors such
as internal bandwidth available, network speed and latency. In ﬁg. 6 (b) we can see the procedure to get all the information. A trace ﬁle is then obtained from an application execution. Later, each node in the network will read an
input trace ﬁle and will simulate the events (for example MPI Wait, MPI Send, MPI Receive,MPI Broadcast).
Every event has a Compute (t) event, which emulates a serial computation of duration t.
4.2. Determine Communication Characteristics
Based on the application speciﬁcations, we should be able to get a sense of whether the application is communicationbound. One way to do this is by executing the application with the PAS2P tool[3] to identify relevant phases of the
application. Later, only those relevant phases could be executed and analyzed. Other way would be to build a histogram of message sizes. A large number of messages over time, or frequent collective communication operations,
may also indicate that the application will be hindered by network contention on the target machine [23].

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

4.3. Benchmark the Application on the Real Machine
A deeper analysis is possible if access to the machine is available, we can obtain additional and more reliable
information about the application and communications. The capability of an application to overlap communication
with computation and the tendency to create network contention are important factors aﬀecting communication.
Although this can be deduced through actual runs on a certain number of processors on the real machine, PAS2P
has the option of executing the application on a smaller cluster footprint and yet get the desired information.
5. PR-DRB Performance Beneﬁts at Application Level
To evaluate the Application-Aware PR-DRB, a simulation approach was chosen. This section shows the results
with real parallel scientiﬁc applications. In [4], we presented the evaluations with synthetic traﬃc for mesh and fat
tree topologies. We use NAS Parallel Benchmarks [20] and Lammps [18] for our evaluation. Latency and global
application execution time are evaluated in order to assess PR-DRB. Latency is the time elapsed since a packet is
created until it reaches its destination, in seconds. Tests were conducted for 64 nodes under fat tree topology.
5.1. Modeling Environment
PR-DRB operations together with network components were modeled [24] using the standard simulation
and modeling tool OPNET [25]. OPNET provides a Discrete Event Simulator engine and oﬀers a hierarchical
modeling environment with an enhanced C++ language. This allows deﬁning network components behavior by a
Finite State Machine approach (FSM), and it supports detailed speciﬁcation of protocols, resources, applications,
algorithms, and queuing policies. We have assumed virtual Cut-through ﬂow control [26]. Link Bandwidth was
set to 2Gbps, packet size was set to 1024 bits and the size of routers buﬀers was 2MB.
5.2. NAS Parallel Benchmark
For NAS Parallel Benchmarks, we focus on the LU pseudo application and MG kernel, which uses long- and
short-distance communication. We use classes S, A and B problem size for evaluation. Although not included
in the paper, we have not seen performance degradation for rest of the NAS Parallel Benchmarks using DRB
and PR-DRB. Fig. 7 shows average latency map for the fat tree network after the execution of the whole LU
Class A application, for (a) Deterministic, (b) DRB and (c) PR-DRB. Latency surface represents the average
contention latency at buﬀers. We see an improvement of 57% on average at the highest peak in the map, between
the Deterministic and DRB algorithms. We can also see that DRB concentrates all the traﬃc into the routers
closest to the sources (index 0 of Routers x Axis). This is due to alternative paths opening procedures used by
DRB. PR-DRB on the other hand achieves 41% latency reduction compared to DRB and 75% compared to the
Deterministic algorithm. Here we can see that PR-DRB has re applied the best solutions directly and avoided the
contention introduced by DRB previously.

Fig. 7. (a) NAS LU Deterministic; (b) NAS LU DRB, (c) NAS LU PR-DRB

In ﬁg. 8 (a) we can see the global network latency results for the MG benchmark classes S, A and B. For class
S we do not see any improvement, since the contention in the network is negligible. However, for classes A and B
we can see a 65% and 60% in latency reduction respectively, comparing the Deterministic and DRB algorithms.
Even though DRB and PR-DRB shows similar ﬁnal latency values, we can see in ﬁgs. 9 and 10 that contention
latency is reduced by PR-DRB. In 9 (a), between time 1.005 and 1.0125 both DRB and PR-DRB have the same
latency. This represent the phases where PR-DRB is learning or monitoring the patterns currently in the network.

185

186

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

Fig. 8. (a) NAS MG Latency; (b) NAS MG Execution Time

From time 1.0125 until the end of the simulation, PR-DRB has lower latency values. This is caused by the fact that
PR-DRB has applied its best known solution for one or more communication pattern. Now the traﬃc is redirected
to others paths, thus the traﬃc is reduced in this router. In ﬁg. 9 (b), between time 1.0225 and 1.03 we can see
that PR-DRB has higher latency value than DRB, but from 1.03 it keeps latency bounded below DRB’s value. In
this case PR-DRB has applied a solution it considers good, but the traﬃc pattern has changed and now its solution
is not longer needed. Here, PR-DRB detaches from work and lets DRB ﬁnd a good solution for this pattern. Figs.
10 (a) and (b) show similar results for other congested routers in the network. Regarding the execution time, as
shown in ﬁg. 8 (b), DRB and PR-DRB outperform the Deterministic in 8% for class A and 23% for class B.

Fig. 9. (a) NAS MG class-A Router A Contention Latency ; (b) NAS MG class-A Router B Contention Latency

Fig. 10. (a) NAS MG class-B Router A Contention Latency ; (b) NAS MG class-B Router B Contention Latency

5.3. Lammp Molecular Dynamics Application - Latency Map
In the map shown in ﬁg. 11 the average latency with DRB algorithm is reduced by 65% compared to the
Deterministic algorithm. PR-DRB has a similar reduction percentage than DRB. However, PR-DRB has better
global latency values compared to both Deterministic and DRB, as shown in ﬁg. 12 (a). Here, latency is reduced
by PR-DRB on 5% compared to DRB and 36% compared to the Deterministic algorithm. PR-DRB achieves this
improvement by using the best known solution every time the same pattern re-appears in the network. Fig. 12

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

(b) shows the execution time reduction obtained by PR-DRB compared to DRB and Deterministic algorithms. In
this case, 6% and 37% respectively. The improvements achieved, in latency and execution time is caused by using
the best solutions for each representative pattern it ﬁnds. Thus, global latency is slightly reduced by contention
latency reduction in buﬀers, as shown in ﬁg. 13. In ﬁg. 13(b) PR-DRB found 80 diﬀerent contending ﬂows
patterns during the ﬁrst stage of the application. Later, 7 patterns were identiﬁed or repeated again. One of those
patterns was repeated 279 times, and the best solution encountered and saved previously was applied every time.
With this pattern recognition procedure, PR-DRB outperforms DRB and the Deterministic algorithms.

Fig. 11. (a) Lammps Deterministic; (b) Lammp DRB, (c) Lammp PR-DRB

Fig. 12. (a) Lammps Latency; (b) Lammps Execution Time

Fig. 13. (a) Lammps Router A Contention Latency; (b) Lammps Router B Contention Latency;

6. Conclusions and Future Work
We have proposed the Application-Aware Predictive and Distributed Routing Balancing, PR-DRB. This strategy uses alternative paths under congestion situation to reduce latency and increase bandwidth availability, by
considering time as well as traﬃc’s dynamic behavior constraints. Routing algorithms try to adapt the traﬃc load
of parallel applications to network topology. These applications change along time and possess repetitive behavior,
and PR-DRB is capable to learn from it and save information for later use. PR-DRB has been developed to fulﬁll
HSIN design objectives such as all-to-all connection, and low and uniform latency between any pair of nodes
under any message traﬃc load. The proposed method is also in line with current approaches used in commercial

187

188

Carlos N´un˜ ez Castillo et al. / Procedia Computer Science 18 (2013) 179 – 188

interconnects (as InﬁniBand). Our policy allows heavier communication load in the network, or in cost-bounded
data centers it allows using less network components, because they are more eﬃciently handled. The evaluation
performed to validate PR-DRB with real traces from applications, has revealed very good improvements in latency
and execution time. Saturation is reduced allowing the use of the network at higher loads. As future work, we
plan to predict future congestion before it has eﬀectively appeared, based on latency trend analysis.
Acknowledgments
This research has been supported by the MEC-MICINN Spain under contract TIN2007-64974. Furthermore,
we thank OPNET Technologies, Inc. for providing us the OPNET Modeler licenses
References
[1] Inﬁniband, Iba, http://www.inﬁnibandta.org/ (2011).
[2] G. Rodriguez, et al., Exploring pattern-aware routing in gen. fat tree networks, in: ICS ’09: Procs of the 23rd int. conf. on Supercomp.,
ACM, USA, 2009, pp. 276–285.
[3] A. Wong, et al., Parallel application signature, CLUSTER ’09. IEEE Int. Conf. on 1 (2009) 1–4.
[4] C. N. Castillo, et al., Predictive and distributed routing balancing on high-speed cluster networks, in: Proc. of the 2011 23rd Int. Symp.
on Comp. Arch. and HPC, SBAC-PAD ’11, IEEE Comp. Soc., 2011, pp. 72–79.
[5] D. Franco, I. Garces, E. Luque, Distributed routing balancing for interconnection network communication, in: HIPC ’98: Procs of the
Fifth Int. Conf. on High Perf. Comp., IEEE Computer Society, 1998, p. 253.
[6] D. Lugones, et al., Dynamic and distributed multipath routing policy for high-speed cluster networks, in: CCGRID ’09: Procs of the
2009 9th IEEE/ACM Int. Symp. on Cluster Comp. and the Grid, USA, 2009, pp. 396–403.
[7] P. Garcia, et al., Recn-dd: A memory-eﬃcient congestion management technique for advanced switching, Parallel Proc., Int. Conf. on 0
(2006) 23–32.
[8] E. Baydal, et al., A family of mechanisms for congestion control in wormhole networks, IEEE Trans. Parallel Distrib. Syst. 16 (9) (2005)
772–784.
[9] S. Yan, et al., An enhanced congestion control mechanism in inﬁniband networks for high performance computing systems, Adv. Inf.
Networks and App., Int. Conf. on 1 (2006) 845–850.
[10] D. Franco, et al., A new method to make communication latency uniform: distributed routing balancing, in: ICS ’99: Procs of the 13th
int. conf. on Superc., ACM, USA, 1999, pp. 210–219.
[11] A. Singh, et al., Globally adaptive load-balanced routing on tori, IEEE Comput. Archit. Lett. 3 (1) (2004) 2.
[12] C. J. Glass, et al., The turn model for adaptive routing, SIGARCH Comput. Archit. News 20 (2) (1992) 278–287.
[13] D. Lugones, et al., Dynamic routing balancing on inﬁniband networks, in: Journal. of Comp. Science & Tech., 2008, pp. 104–110.
[14] A. Vishnu, et al, Hot-spot avoidance with multi-pathing over inﬁniband: An mpi perspective, in: Cluster Computing and the Grid, 2007.
CCGRID 2007. Seventh IEEE Int. Symp. on, 2007, pp. 479 –486.
[15] K. Barker, A. Benner, R. Hoare, A. Hoisie, A. Jones, D. Kerbyson, D. Li, R. Melhem, R. Rajamony, E. Schenfeld, S. Shao, C. Stunkel,
P. Walker, On the feasibility of optical circuit switching for high performance computing systems, in: Supercomp., 2005. Proc. of the
ACM/IEEE SC 2005 Conf., 2005, p. 16.
[16] T. Sherwood, et al., Basic block distribution analysis to ﬁnd periodic behavior and simulation points in applications, in: PACT ’01: Procs
of the 2001 Int. Conf. on Par. Arch. and Compil. Tech., 2001, pp. 3–14.
[17] J. C. Phillips, et al., Scalable molecular dynamics with namd, Journal of Computational Chemistry 26 (16) (2005) 1781–1802.
[18] S. Plimpton, Fast parallel algorithms for short-range molecular dynamics, JOURNAL OF COMP. PHYSICS 117 (1995) 1–19.
[19] S. Labs., Lammps molecular dynamics simulator, http://lammps.sandia.gov, sandia (January 2012).
[20] D. H. Bailey, et al., The nas parallel benchmarks summary and preliminary results, in: Proc. of the 1991 ACM/IEEE conf. on Supercomp.,
Supercomp. ’91, ACM, 1991, pp. 158–165.
[21] A. Simulation, C. A. Purple, The asci purple benchmark codes, ”https://asc.llnl.gov/computingresources/purple/archive/benchmarks/”,
aSC (May 2001).
[22] L.
A.
N.
Laboratory,
Asci
sweep3d
3-dimensional
discrete
ordinates
neutron
transport
benchmark,
http://wwwc3.lanl.gov/pal/software/sweep3d/, los Alamos National Laboratory (May 1995).
[23] A. Bhatel´e, et al., Understanding application performance via micro-benchmarks on three large supercomputers: Intrepid, ranger and
jaguar, Int. J. High Perform. Comput. Appl. 24 (4) (2010) 411–427.
[24] D. Lugones, et al., Modeling adaptive routing protocols in high speed interconnection networks, OPNETWORK 2008 Conf.
[25] T. OPNET, Opnet modeler accelerating network r&d, http://www.opnet.com, oPNET (June 2008).
[26] J. Duato, et al., Interconnection Networks: An Engineering Approach, M. Kaufmann Pub. Inc., USA, 2002.

