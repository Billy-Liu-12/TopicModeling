Procedia Computer Science
Volume 51, 2015, Pages 2739–2743
ICCS 2015 International Conference On Computational Science

Sequential and Parallel Implementation of GRASP for the
0-1 Multidimensional Knapsack Problem∗
Bianca de Almeida Dantas1 and Edson Norberto C´aceres1
Federal University of Mato Grosso do Sul,
Faculty of Computing,
Campo Grande, Mato Grosso do Sul, Brazil
bianca, edson@facom.ufms.br

Abstract
The knapsack problem is a widely known problem in combinatorial optimization and has been
object of many researches in the last decades. The problem has a great number of variants and
obtaining an exact solution to any of these is not easily accomplished, which motivates the search
for alternative techniques to solve the problem. Among these alternatives, metaheuristics seem
to be suitable on the search for approximate solutions for the problem. In this work we propose
a sequential and a parallel implementation for the multidimensional knapsack problem using
GRASP metaheuristic. The obtained results show that GRASP can lead to good quality results,
even optimal in some instances, and that CUDA may be used to expand the neighborhood search
and as a result may lead to improved quality results.
Keywords: GRASP, 0-1 multidimensional knapsack problem, CUDA

1

Introduction

The knapsack problem (KP) is one of the most known problems of combinatorial optimization.
Informally, given a set of items and a knapsack with a known maximum capacity, we want to
ﬁll the knapsack with the most valuable subset of the items subject to the knapsack capacity.
The 0-1 multidimensional knapsack problem (MKP) is a generalization of KP which can have
more than one constraint and the items can not be partitioned. In this variation, the traditional
approaches to solve KP can not be eﬃciently applied anymore and this motivates the search
for alternative approaches.
Formally, we can deﬁne MKP as, given a set of n items with their respective values and m > 1
constraints, deciding which items should be placed inside the knapsack aiming to maximize its
value without extrapolate any of the constraints. We can formulate the problem using the

∗ Partially

supported by CNPq and CAPES.

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.411

2739

GRASP for 0-1 MKP

Dantas and C´
aceres

Equation 1 [2]:

n

vj xj }, j = 1, ..., n

max{
j=1
n

(1)

rij xj ≤ bi , i = 1, ..., m

subject to:
j=1

where V = {v1 , v2 , ..., vn } is an array containing the item values, B = {b1 , b2 , ..., bm } is an array
with the constraints values and matrix R = {r11 , ..., r1m , ..., rm1 , ..., rmn } stores how much
each constraint is used by each item. A solution to the problem is a conﬁguration of array
X = {x1 , x2 , ..., xn }, which satisﬁes every constraint of array B, where each xi can assume the
values 1 or 0 indicating, respectively, the corresponding item belongs or not to the resulting
knapsack. This solution can not be easily obtained, in fact, this is an N P-hard problem.
Diﬀerent metaheuristics have been applied to the solution of the 0-1 MKP [10], some works
deserve to be highlighted and their results are compared to the ones obtained in our implementations: the genetic algorithm proposed by Chu and Beasley [2], the parallel implementation
based on ant-colony optimization, proposed by Fingler et. al [8] and the neurogenetical algorithm proposed by Deane and Agarwal [5].
In previous works [3, 4] we had already presented sequential and parallel implementations
of genetic algorithms and augmented neural networks to ﬁnd approximated solutions to 0-1
MKP and in this work we propose sequential and parallel GRASP approaches to accomplish
this task. The rest of this text is organized as follows. Section 2 presents the deﬁnition of
GRASP metaheuristic. Section 3 describes our proposed solution. In Section 4 we present the
obtained results compared to other approaches. Section 5 shows our conclusions and ideas for
future works.

2

Greedy Randomized Adaptive Search Procedure

Greedy Randomized Adaptive Search Procedure (GRASP) [9] is a multi-start metaheuristic
that performs a sequence of iterations, each one consisting of two phases: construction and
local search. The construction phase is responsible for building an initial feasible solution
using a greedy strategy and a restricted candidate list (RCL); the local search explores the
neighborhood of this solution until a local minimum (or maximum) is found. The result of the
whole process is the best overall solution. GRASP has been successfully applied to solve several
optimization problems and for further reading on GRASP heuristic we suggest the annotated
GRASP bibliography assembled by Festa and Resende [7].

3

The Proposed Solution

In this section we present our approach to use GRASP to solve the 0-1 MKP. We implemented
a sequential version and a version using GPGPU with CUDA library. The sequential implementation was designed following the basic steps proposed by Resende and Ribeiro [9]; the RCL
is constructed using the quality-based policy. In order to evaluate the quality of the items, we
use the pseudoutility of each item which is computed based on its value and on its demand for
each one of the constraints, as stated in [4, 6].
The RCL will contain the items with higher pseudoutilities values. The pseudocodes of our
GRASP main procedure and of ConstructSolution() are shown in Algorithms 1 and 2, where
the parameter α is used to guide the assembly of the RCL.
2740

GRASP for 0-1 MKP

Dantas and C´
aceres

Algorithm 1: GRASP MKP(maxIterations, α)
1
2
3
4
5
6
7
8
9
10
11

Read Input;
BestSolution ← ∅;
for k ← 1, maxIterations do
Solution ← ∅;
Solution ← ConstructSolution(Solution, α);
Solution ← LocalSearch(Solution, α);
if Solution is better than BestSolution then
BestSolution ← Solution;
end
end
return BestSolution;

Algorithm 2: ConstructSolution(Solution, α)
1
2
3
4
5
6
7
8

repeat
Calculate the pseudoutilities of the items;
Construct RCL and randomly choose one item e from RCL;
if e can be added to Solution then
Solution ← Solution ∪{e};
end
until e can not be added to Solution;
return Solution;

Local search, implemented using the ideas presented in [11], works iteratively aiming to ﬁnd
a better solution, it repeats the process of removing some items from current solution until
any available item can be incorporated to the solution and then a new complete solution is
reconstructed. An auxiliary n-position boolean array (named marked) is used to guide this
process, it stores information that helps to keep track of which was the ﬁrst item removed in
each iteration. The steps of local search, based on [11], are listed in Algorithm 3.
Our CUDA implementation aims to expand the neighborhood search using diﬀerent threads
to iteratively construct diﬀerent initial solutions in parallel and then execute local search in
their own generated solution, also in parallel. This approach can be seen as many parallel
executions of the sequential program; the CPU is used to manage the iterations and to ﬁnd the
best solution achieved at the end of the whole process.

4

Implementation and Comparative Results

The implemented programs were executed using the instances of ORLIB library [1], one of the
most used set of instances in works related to the problem. The ORLIB library is composed of
a set of 270 test instances considering 5, 10 or 30 constraints and 100, 250 or 500 items. The gap
is a key concept to evaluate the quality of the obtained results, it is deﬁned as the percentage
of the diﬀerence between the values of the obtained solution and the best known solution.
Both our programs were executed 30 times for each test instance and their medium gaps and
times were computed, as well as the standard deviations of the obtained gaps. Each execution
of the sequential program consisted of 1000 iterations, while the CUDA version executed 100
iterations. The number of threads blocks were set to 100, except for the instances with 500
2741

GRASP for 0-1 MKP

Dantas and C´
aceres

Algorithm 3: LocalSearch(Solution, α)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18

Initialize array marked;
Copy Solution to CurSol;
while there is any not marked item do
Calculate the pseudoutilities of the items;
repeat
Find the e ∈ CurSol with the smallest pseudoutility and remove it from CurSol;
until all the available items may be added to the solution;
ConstructSolution(CurSol, α);
if CurSol is better than Solution then
Solution ← CurSol;
Update array marked;
end
else
CurSol ← Solution;
First item removed is marked;
end
end
return Solution;

items which used 20 threads blocks. The obtained results with every conﬁguration were less
than 1% inferior to the best known solution values. Only 14 test instances had more than 1%
of medium gap, but these values did not exceed 1.2%.
In order to demonstrate how promising GRASP metaheuristic is to solve the 0-1 MKP, we
compared the obtained results with the ones from Chu and Beasley’s genetic algorithm [2],
Deane and Agarwal’s neurogenetical approach [5] and Fingler’s et al. ant-colony algorithm [8].
Table 1 shows the comparisons of the medium gaps of the test instances grouped by number of
items and Table 2 shows the medium gaps grouped by number of constraints.
Table 1: Comparison of the average gap with the test instances grouped by number of items.
n
GA
Neurogenetical ACO SeqGRASP CudaGRASP
100 1.0744
1.0800
1.0889
0.3017
0.2414
250 0.3744
0.3780
0.8522
0.2343
0.2607
500 0.1800
0.1860
0.5389
0.2074
0.2456

Table 2: Comparison of the average gap with the test instances grouped by number of constraints.
m
GA
ACO SeqGRASP CudaGRASP
5 0.2611 0.2133
0.0817
0.0514
10 0.4622 0.6511
0.1913
0.1593
30 0.9056 1.6156
0.4703
0.5369

By the values shown in Table 1 we can see that GRASP leads to smaller gaps than the
other approaches, except for the instances with 500 items where the resulting gaps are slightly
greater than the obtained by Chu and Beasley’s genetic algorithm and by Deane and Agarwal’s
neurogenetical approach. Analysing the values in Table 2 we see that GRASP outperforms
2742

GRASP for 0-1 MKP

Dantas and C´
aceres

the other approaches, although we could not compare with the results from the neurogenetical
algorithm because these values were not available on the reference work.

5

Conclusion

In this work we presented sequential and GPGPU-based algorithms using GRASP metaheuristic
to solve 0-1 MKP and tested them using the test instances of ORLIB library. The tests results
showed GRASP is a promising alternative, achieving solutions less than 1% inferior to the best
known solutions. When compared to other metaheuristics implementations, such as the ones in
[2], [5] and [8], GRASP also obtained better quality results in almost every test conﬁguration.
The GPGPU algorithm achieved slightly better results than the sequential version, mainly
because it allowed a more eﬀective neighborhood exploration. Nevertheless, this improvement
in quality also led to an increase in execution time.
As future works, we will study and implement other sequential and parallel metaheuristics
to solve 0-1 MKP and compare them to GRASP, specially simulated annealing and variable
neighborhood search (VNS). We will also evaluate how GRASP can be applied to other optimization problems, such as the traveling salesman problem (TSP) and the quadratic assignment
problem (QAP).

References
[1] J. E. Beasley. OR-Library: distributing test problems by electronic mail. Journal of the Operational
Research Society, 41(11):1069–1072, 1990.
[2] P. C. Chu and J. E. Beasley. A genetic algorithm for the multidimensional knapsack problem.
Journal of Heuristics, 4(1):63–86, June 1998.
[3] B. A. Dantas and E. N. C´
aceres. Implementa¸c˜
oes paralelas para o problema da mochila multidimensional usando algoritmos gen´eticos. In Anais do XLVI Simp´
osio Brasileiro de Pesquisa
Operacional, 2014.
[4] B. A. Dantas and E. N. C´
aceres. A parallel implementation to the multidimensional knapsack
problem using augmented neural networks. In Proceedings of the 2014 Latin American Computing
Conference (CLEI), pages 570–578, 2014.
[5] J. Deane and A. Agarwal. Neural, genetic, and neurogenetic approaches for solving the 0-1 multidimensional knapsack problem. International Journal of Management & Information Systems First Quarter 2013, 17(1):43–54, 2013.
[6] J. Deane and Anurag Agarwal. Neural metaheuristics for the multidimensional knapsack problem.
Technical report, 2012.
[7] P. Festa and M. G. C. Resende. An annotated bibliography of GRASP – part ii: Applications.
International Transactions in Operational Research, 16(2):131–172, 2009.
[8] H. Fingler, E. N. C´
aceres, H. Mongelli, and S. W. Song. A CUDA based solution to the multidimensional knapsack problem using the ant colony optimization. Procedia Computer Science,
29(0):84 – 94, 2014. 2014 International Conference on Computational Science.
[9] C. C. Ribeiro M. G. C. Resende. Greedy randomized adaptive search procedures. In Fred Glover
and Gary A. Kochenberger, editors, Handbook of Metaheuristics, pages 219–249. Kluwer, 2002.
[10] M. Varnamkhasti. Overview of the algorithms for solving the multidimensional knapsack problems.
Advanced Studies in Biology, 4(1):37–47, 2012.
[11] D. S. Vianna and M. F. D. Vianna. Local search-based heuristics for the multiobjective multidimensional knapsack problem. In Produ¸ca
˜o, volume 23, pages 478–487. 2013.

2743

