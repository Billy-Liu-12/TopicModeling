Procedia Computer Science
Volume 51, 2015, Pages 834–844
ICCS 2015 International Conference On Computational Science

A Cooperative Coevolutionary Diﬀerential Evolution
Algorithm with Adaptive Subcomponents
Giuseppe A. Trunﬁo
DADU, University of Sassari, Italy
{trunfio}@uniss.it

Abstract
The performance of cooperative co-evolutionary (CC) algorithms for large-scale continuous optimization is signiﬁcantly aﬀected by the adopted decomposition of the search space. According to
the literature, a typical decomposition in case of separable problems consists of adopting equally
sized subcomponents for the whole optimization process (i.e. static decomposition). Such an
approach is also often used for non-separable problems, together with a random-grouping strategy. More advanced methods try to determine the optimal size of subcomponents during the
optimization process using reinforcement-learning techniques. However, the latter approaches
are not always suitable in this case because of the non-stationary and history-dependent nature
of the learning environment. This paper investigates a new CC algorithm, based on Diﬀerential
Evolution, in which several decompositions are applied in parallel during short learning phases.
The experimental results on a set of large-scale optimization problems show that the proposed
method can lead to a reliable estimate of the suitability of each subcomponent size. Moreover,
in some cases it outperforms the best static decomposition.
Keywords: Cooperative Coevolution, Diﬀerential Evolution, Large Scale Optimization, Adaptation

1

Introduction

Cooperative Coevolution (CC) [4] is one of the most successful framework for developing search
algorithms able to eﬀectively address large-scale global optimization (LSGO) problems [2]. In
brief, the CC idea consists of decomposing the original high-dimensional problem into a set
of lower-dimensional subcomponents, which are easier to solve. Typically, each subcomponent
is evolved according to a standard optimization metaheuristic. During the process, the only
cooperation takes place in ﬁtness evaluation, through an exchange of information between
subcomponents.
A major challenge for increasing the search performance of the CC approach, consists of
grouping variables into an optimal set of subcomponents. For fully separable (i.e. without
interacting variables) or fully non-separable LSGO problems, a typical decomposition approach
834

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.209

A Cooperative Coevolutionary Diﬀerential Evolution Algorithm with . . .

Giuseppe A. Trunﬁo

consists of using equally sized subcomponents. In these cases, the common size of subcomponents can be a critical factor in determining the performance of the CC technique. The problem
has been addressed ﬁrst in [11] and, more recently, in [3], where the authors: (i ) showed that
in several cases there exists an optimal value for the size of subcomponents; (ii ) proposed an
adaptive approach based on a reinforcement learning technique for ﬁnding such an optimal
value. Unfortunately, as noted in [3], the non-stationary nature of the problem makes hard the
learning of a suitable size for the subcomponents during the evolutionary search.
This paper presents an alternative approach for eﬀectively adapting the size of subcomponents within a CC algorithm. In the proposed method, the learning phases consist of a
concurrent application of a pool of alternative ‘decomposers’. Such an approach, compared
with the activation of one decomposer at a time proposed in [11, 3], enables a more reliable
comparative evaluation of the candidate decomposers. Moreover, in order to promote a better
exploitation of the available computational resources, the devised technique allows to adopt a
diﬀerent number of individuals in subcomponents with diﬀerent sizes. We show, using a numerical investigation on some typical benchmark functions, that the proposed approach can
outperform the use of the optimal static equal-sized decomposition.
The paper is organized as follows. Section 2 outlines a typical CC optimizer and provides
some background on the most relevant methods dealing with the adaptation of the subcomponent sizes, namely MLCC [11] and MLSoft [3]. In section 3, we describe in detail the proposed
approach and in section 4 we discuss some experimental results on a suite of benchmark functions. Section 5 concludes the paper and outlines possible future work.

2

Related Work

A CC optimization [4] is based on partitioning the d-dimensional set of search directions
G = {1, 2, . . . , d} into k sets G1 . . . Gk . Each group Gi of directions deﬁnes a subcomponent S (i)
in which a standard optimization algorithm is applied. Typically, a separate sub-population
is assigned to each subcomponent generated by the groups Gi . By construction, a candidate
solution in S (i) contains only some elements of the d-dimensional vector required for computing the corresponding ﬁtness function f . For this reason, a common d-dimensional context
vector b is built using a representative individual (e.g. the best individual) provided by each
subcomponent. Then, the candidate solutions are evaluated by complementing them through
the appropriate elements of the context vector. In this framework, the cooperation between
sub-populations emerges because the common vector is used for the ﬁtness evaluation of all
individuals. In the original implementation [4], the d-dimensional problem was decomposed
into d sub-populations (i.e. Gi = {i}). The ﬁtness of each individual was computed by evaluating the d-dimensional vector formed by the individual itself and a selected member (e.g.
the current best) from each of the other subcomponents. Subsequently, it was found that the
CC approach can signiﬁcantly improve the optimizer scalability as the dimensionality of the
problem increases [1].
A major issue with the CC framework is that when interdependent variables are assigned to
diﬀerent subcomponents, the search eﬃciency can decline signiﬁcantly [4, 5, 1]. The interdependency between decision variables [6] is a common condition in real optimization problems and
in the CC literature is referred to as non-separability. In case of non-separable problems, the
CC approach usually adopts equally sized subcomponents and integrates the so called Random
Grouping (RG) technique [11, 10]. RG is a strategy in which the directions of the original search
space are periodically grouped in a random way to determine the subcomponent in which the
cooperative search is carried out.
835

A Cooperative Coevolutionary Diﬀerential Evolution Algorithm with . . .

Giuseppe A. Trunﬁo

each cycle, the performance indexes are converted into probabilities using the Boltzmann ‘soft
t
max’ distribution: [8] pi = eri /c / j=1 erj /c , where c is a suitable constant. The latter should
be set in such a way to associate a high probability of being selected to the best decomposers
(exploitation), still giving some chances to all the available decomposers (exploration). The
above mechanism allows to self-adapt the problem decomposition to the particular objective
problem and also to the evolution stages. In [11], the MLCC adaptation method was tested,
using a RG strategy, on a suite of benchmark functions. The authors found that in some cases
the self-adaptive strategy outperformed the corresponding methods based on the static selection
of dk and on the random selection of the group sizes at each cycle.
Recently, in [3] an improvement of the MLCC adaptive approach was presented, namely the
MLSoft algorithm. In particular, the authors noted that the MLCC adaptive method can be
seen in a perspective of a reinforcement learning (RL) approach [8], where the improvement
of ﬁtness is the reinforcement signal and the actions consist in the choice of the decomposer.
However, instead of selecting actions on the basis of its long-term utility, as typically done in
RL, in the MLCC their immediate reward is used. Thus, in MLSoft the ri value was replaced
with a value function Vi . The latter, which is an estimate of the long term utility associated to
the use of a decomposer, was deﬁned as the arithmetic mean of all rewards ri received by the
decomposer dki during the optimization process. The MLSoft algorithm was tested on eight
fully-separable functions using a rich set of decomposers and diﬀerent values of the parameter c.
According to the results, MLSoft outperformed MLCC. However, the MLSoft algorithm was not
able to outperform the corresponding CC framework with a static and optimal subcomponent
size.

3

A new CC with adaptive subcomponents

In both the MLCC and MLSoft approaches, a decomposer is randomly drawn at each cycle
according to its current probability, which is computed on the basis of its value function. The
latter reﬂects the rewards obtained by the decomposer at the end of the cycles in which it has
been used.
Unfortunately, in such a learning scheme the rewards obtained by the diﬀerent decomposers
may be strongly aﬀected by the state of the environment in which they have operated. This
is because of the expected evolution of the population on the ﬁtness landscape, which can
be signiﬁcantly complex. In other words, an hypothetical agent that has to choose a decomposer operates on a non-stationary and history-dependent environment, for which RL schemes
conceived for Markovian environments are not guaranteed to converge to the optimal policy
(although they can still be used with acceptable results in some cases [8]).
The alternative investigated in this study consists of evaluating the diﬀerent decomposers
under the same conditions. More in detail, during the learning phases, the decomposers of a
predeﬁned set are applied starting from the same state of the search, including the same context
vector. In other words, they are concurrently executed on the same initial environment in order
to estimate their value functions. Clearly, depending on the number of candidate decomposers,
learning with such an approach can have a greater computational cost, when compared with
the methods outlined in section 2. However, according to the results discussed later, very short
learning phases can be eﬀective and it is worth investing a slightly greater computational budget
in a more accurate assessment of the performance of decomposers.
Moreover, in order to achieve a better allocation of the available computational resources,
the proposed approach is devised in such a way to have a suitable number of individuals for
each population associated to the diﬀerent decomposers.
837

A Cooperative Coevolutionary Diﬀerential Evolution Algorithm with . . .

Giuseppe A. Trunﬁo

Algorithm 3: CCAS(objectiveFunction, d, learningLength)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41

V ← { k1 , numInd1 , k2 , numInd2 , . . . , km , numIndm };
pop ← initPopulation(d, maxNumInd );
b ← initContextVector(pop);
f ← objectiveFunction(b);
foreach j, numInd ∈ V do
Gj = {G1 , . . . , Gj } ← randomGrouping(d, j);
bj ← b;
popj ← extractPop(pop, numInd);
(prev)
fj
← f;
f itnessEvaluations ← 0;
selectedDecomposer ← 0;
learnCount ← 0;
q = {qk1 , qk2 , . . . qkm } ← 0;
R = {rk1 , rk2 , . . . rkm } ← 0;
while f itnessEvaluations < maxFE do
if learnCount = learnLen then
learnCount ← −1;
foreach j, numInd ∈ V do
qj ←computeValueFunction(rj );
selectedDecomposer ← decomposerWithMax(q);
bestF itnessDecomposer ← decomposerWithMax(f );
copySearchState(bestF itnessDecomposer, selectedDecomposer);
if learnCount ≥ 0 then
learnCount ← learnCount + 1;
foreach j, numInd ∈ V do
fj , FEj ← optimizeSubcomponents(objectiveFunction, Gj , bj , popj );
f itnessEvaluations ← f itnessEvaluations + FEj ;
(learnCount)
(prev)
(prev)
rj
= (fj
− fj )/(| fj
| ×FEj );
(prev)

fj
← fj ;
Gj = {G1 , . . . , Gj } ← randomGrouping(d, j);
else
j ← selectedDecomposer;
fj , FEj ← optimizeSubcomponents(objectiveFunction, Gj , bj , popj );
f itnessEvaluations ← f itnessEvaluations + FEj ;
if unifRandom(0, 1)< then
learnCount ← 0;
broadcastSearchState(bj , popj );
(prev)

fj
← fj ;
b ← bj ;
Gj = {G1 , . . . , Gj } ← randomGrouping(d, j);
return objectiveFunction(b) and b;

In the present application, the used optimizer is JADE [12], an adaptive Diﬀerential Evolution algorithm [7] in which the parameter adaptation was implemented by evolving the mutation
factors and crossover probabilities based on their historical record of success. According to [12],
838

A Cooperative Coevolutionary Diﬀerential Evolution Algorithm with . . .

Giuseppe A. Trunﬁo

JADE showed a very good optimization performance on a standard suite of benchmark functions, compared to other classic and adaptive evolutionary optimization algorithms. It is worth
noting that JADE can optionally use an external archive to store some explored candidate
solutions in order to ﬁnd new promising directions. However, the JADE version developed for
this study does not include such a technique.
The proposed strategy is outlined in Algorithm 3, labelled as CCAS (Cooperative Coevolution with Adaptive Subcomponents). In the latter, we have omitted possible optimizations
for the sake of clarity. Also, note that Algorithm 3 uses the function optimizeSubcomponents
described in Algorithm 2. First, a set V is initialised with the available decomposers, each
represented by a tuple kj , numIndj , where kj is the number of subcomponents and numIndj
is the corresponding number of individuals. Then, a population composed of the maximum
number of individuals among the numIndj is initialized, together with the context vector b.
At lines 5-9, for each decomposer: (i ) we create the groups of coordinates Gi according to the
RG technique; (ii ) we create a ‘local’ copy of the context vector; (iii ) we initialize a local copy
of the population accounting for the actual number of individuals allowed for the decomposer
(function extractPop).
The CC optimizer can be in two diﬀerent states, namely learning (learnCount ≥ 0) and
non-learning (learnCount < 0). Both phases keep carrying out the optimization process.
However, while in the learning phase all the available decomposers are concurrently applied,
in the non-learning one, only the best decomposer is actually used. The duration learnLen of
each learning phase is expressed in cycles. At the ﬁrst cycle, the search is put in learning mode
(see line 12). In the latter, as shown in lines 23-30, all the decomposers are used independently
and a reward rj is computed for each of them as follows:
(prev)

rj =

fj

(prev)

|fj

(cur)

− fj

(1)

| × FEj

where FEj is the last number of objective function evaluations performed by the j-th decomposer. The rationale behind Eq. (1) is to account not only for the progress in ﬁtness but also
for the cost of such a progress.
At the end of the learning phase (lines 17-22), all the rewards obtained by each decomposer
during the learnLen cycles are used for the computation of a value function qj (lines 18-19).
The MLSoft approach, consisting of the average of all the collected rj , can be used to such
purpose. However, currently we adopt a value function designed in such a way to weigh less
the rewards obtained more far away in time:
learnLen

qj =
i=1

(i)

rj
1 + α (learnLen − i)

(2)

where α is a constant value (we use α = 0.5 in the current implementation). After the computation of all qj , the algorithm selects for the subsequent optimization phase the decomposer
with the highest value function (line 20).
However, given the form of the reward function in Eq. (1), which accounts for the eﬃciency
in using the evaluations of objective function, the selected decomposer is not always the one
with the better ﬁtness value. Thus, at line 22, the function copySearchState(from, to) is used to
transmit the current ‘best’ population, including the context vector, to the decomposer that will
be used in the next phase. To this purpose, if the recipient has a lower number of individuals,
then the worst ones are discarded. Also, if the selected decomposer requires a greater number
of individuals, function copySearchState(from, to) does not overwrite its best individuals. Such
839

A Cooperative Coevolutionary Diﬀerential Evolution Algorithm with . . .

Giuseppe A. Trunﬁo

whole search. In many test cases, some decomposers led very early to stagnation. For example,
this was the case of dk = 200 and dk = 500 for function f3 . Also, in the case of f4 all the
decomposers except dk = 2 led to premature convergence. Overall, from Fig. 1 it is clear
that the size and number of individuals of the involved subcomponents can be a key factor in
determining the convergence of a CC algorithm.
In order to perform a preliminary empirical evaluation of the proposed CCAS algorithm,
we executed 25 independent runs on the same test functions listed in Table 1 and with same
number of individuals shown in Table 2. As above, we used 5 JADE iterations per cycle for
all subcomponents. The learning durations were set to 3 cycles. We investigated two diﬀerent
values of the resuming probability , namely 0.01 and 0.05. In general, a low value of helps
to avoid spending too many computational resources on learning. On the other hand, a higher
value of allows exploring the suitability of diﬀerent decomposers during the search process,
whch can be a successful strategy for some functions.
In addition, we have implemented our version of the MLSoft strategy [3], with JADE as
optimizer. To ensure a fair comparison, we used the same JADE parameters of CCAS. Moreover,
for the MLSoft ‘softmax’ distribution we used c = 0.5. The latter value was also used in [3]
where it provided the best results on the tested functions. Also the MLSoft was executed 25
times on the test functions listed in Table 1.
The average achieved results are shown in Table 4, where they are also compared with
the best results obtained using the static decomposition. In this case, the MWW test (with
signiﬁcance 0.05) was used to compare each result of CCAS with the corresponding result of
MLSoft. In Table 4, we marked in bold the best results, when the diﬀerence was statistically
signiﬁcant. As can be seen, CCAS with = 0.05 outperformed MLSoft with c = 0.5 in seven
out of nine cases. In the remaining two cases, the results provided by CCAS were statistically
equivalent to those of MLSoft. However, a more signiﬁcant and extensive comparison between
CCAS and MLSoft would require testing a variety of parameters for both algorithms, and will
be object of a future work.
It is also interesting to compare the results of CCAS, obtained with = 0.05, with the
results provided by the best static decomposer. Also in this case, we have conducted a MWW
statistical test (with signiﬁcance 0.05) which showed that the proposed technique was always
able to achieve a better or equivalent result. The fact that CCAS could improve the best static
decomposer for functions f2 and f9 , was mainly due to its ability to switch to a diﬀerent and
more eﬃcient arrangement of subcomponents during the search. However, we should also investigate in this case the role played by the diﬀerent number of individuals of the subcomponents
during the transitions between the diﬀerent phases of the algorithm.

5

Conclusions and future work

According to the numerical results, the proposed approach can eﬀectively adapt the size of
subcomponents during the CC search. In some cases, among the tested functions, the adaptive
strategy was able to signiﬁcantly outperform the best static decomposer. The results are thus
encouraging, and the method deserves to be investigated more thoroughly, especially using a
more extended suite of benchmark functions.
There are also some more speciﬁc aspects that will be the subject of further study and
experimentations.
A ﬁrst investigation will concern the reward function, which is currently computed using
the ﬁtness improvement in the last cycle and the corresponding number of function evaluations.
According to numerical experiments that we have carried out, taking into account the cost of
843

A Cooperative Coevolutionary Diﬀerential Evolution Algorithm with . . .

Giuseppe A. Trunﬁo

the improvements is usually beneﬁcial. In fact, diﬀerent decomposers have a diﬀerent cost per
cycle and this should not be neglected given that, usually, the budget of evaluations of the
function is limited. However, in some cases such a reward function can overestimate the value
of a decomposer with a low number of individuals when, especially at the beginning of the
process, it provides large improvements of the ﬁtness.
Another aspect to be investigated concerns the reactivation of learning during the optimization process. There are alternatives to the random resuming that deserve to be studied. A
simple approach is to resume exploring the diﬀerent decomposers only in case of stagnation.
However, according to some preliminary results, sometimes waiting for a complete search stagnation leads to a signiﬁcant waste of computational resources. In other cases, the stagnation is
just temporary and the convergence process resumes after a certain number of cycles.
As a ﬁnal consideration, it should be noted that the computational cost of the concurrent
learning phase proposed in this study is signiﬁcantly aﬀected by the number of arrangements
of subcomponents being tested. To mitigate such a problem, a suitable variant of the proposed
approach could be to gradually narrow the set of candidate decomposers, admitting to the
concurrent learning only its most promising elements.

References
[1] Yong Liu, Xin Yao, and Qiangfu Zhao. Scaling up fast evolutionary programming with cooperative
coevolution. In In Proceedings of the 2001 Congress on Evolutionary Computation, Seoul, Korea,
pages 1101–1108, 2001.
[2] Sedigheh Mahdavi, Mohammad Ebrahim Shiri, and Shahryar Rahnamayan. Metaheuristics in
large-scale global continues optimization: A survey. Information Sciences, 295(0):407 – 428, 2015.
[3] Mohammad Nabi Omidvar, Y. Mei, and Xiaodong Li. Eﬀective decomposition of large-scale
separable continuous functions for cooperative co-evolutionary algorithms. In Proceedings of the
IEEE Congress on Evolutionary Computatio. IEEE, 2014.
[4] Mitchell A. Potter and Kenneth A. De Jong. A cooperative coevolutionary approach to function
optimization. In Proceedings of the International Conference on Evolutionary Computation. The
Third Conference on Parallel Problem Solving from Nature: Parallel Problem Solving from Nature,
PPSN III, pages 249–257. Springer-Verlag, 1994.
[5] Mitchell A. Potter and Kenneth A. De Jong. Cooperative coevolution: An architecture for evolving
coadapted subcomponents. Evolutionary Computation, 8(1):1–29, 2000.
[6] Ralf Salomon. Reevaluating genetic algorithm performance under coordinate rotation of benchmark functions - a survey of some theoretical and practical aspects of genetic algorithms. BioSystems, 39:263–278, 1995.
[7] Rainer Storn and Kenneth Price. Diﬀerential evolution a simple and eﬃcient heuristic for global
optimization over continuous spaces. Journal of Global Optimization, 11(4):341–359, 1997.
[8] Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. MIT Press,
1998.
[9] K. Tang, X. Yao, P. Suganthan, C. MacNish, Y. Chen, C. Chen, and Z. Yang. Benchmark functions
for the CEC’ 2008 special session and competition on large scale global optimization.
[10] Zhenyu Yang, Ke Tang, and Xin Yao. Large scale evolutionary optimization using cooperative
coevolution. Information Sciences, 178(15):2985–2999, 2008.
[11] Zhenyu Yang, Ke Tang, and Xin Yao. Multilevel cooperative coevolution for large scale optimization. In IEEE Congress on Evolutionary Computation, pages 1663–1670. IEEE, 2008.
[12] Jingqiao Zhang and Arthur C. Sanderson. Jade: Adaptive diﬀerential evolution with optional
external archive. IEEE Trans. Evolutionary Computation, 13(5):945–958, 2009.

844

