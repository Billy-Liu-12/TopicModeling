Procedia Computer Science
Volume 51, 2015, Pages 2317–2326
ICCS 2015 International Conference On Computational Science

Computational uncertainty management for coastal
flood prevention system
Anna V. Kalyuzhnaya1and Alexander V. Boukhanovsky 1
1

ITMO University, St. Petersburg, Russian Federation
kalyuzhnaya.ann@gmail.com, avb_mail@mail.ru

Abstract
Multivariate and progressive uncertainty is the main factor of accuracy in simulation systems. It can be
a critical issue for systems that forecast and prevent extreme events and related risks. To deal with this
problem, computational uncertainty management strategies should be used. This paper aims to
demonstrate an adaptation of the computational uncertainty management strategy in the framework of
a system for prediction and prevention of such natural disasters as coastal floods. The main goal of the
chosen strategy is to highlight the most significant ways of uncertainty propagation and to collocate
blocks of action with procedures for reduction or evaluation of uncertainty in a way that catches the
major part of model error. Blocks of action involve several procedures: calibration of models, data
assimilation, ensemble forecasts, and various techniques for residual uncertainty evaluation (including
risk evaluation). The strategy described in this paper was tested and proved based on a case study of
the coastal flood prevention system in St. Petersburg.
Keywords: Uncertainty management, Flood prevention, Extreme metocean events forecasting

1 Introduction
Uncertainty is a common notion, in a general sense it means doubt in the quality of information
received, but in scientific practice this term is usually associated with numerical quantity of the notion
itself. Uncertainty could be defined as the measure of belief1 to information associated with
inaccuracies of input data and boundary conditions, adequacy of mathematical models, and
extrapolation of process in time (forecast effect).
Nowadays there are many scientific papers discussing problems around classification, numerical
estimation, and reduction of uncertainty. For example, classification of uncertainty is discussed in
papers [1, 2]. Multivariate uncertainty is the main factor of accuracy in simulation systems and
consists of numerous mathematical models. In the context of system theory, a mathematical model
could be described as a system consisting of components: input and output data, initial state,
parameters and structure. Each component can be associated with a source of uncertainty sharing the
same name [3].
1

In terms of stochastic analysis approach

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.397

2317

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

Input data can be represented by simulation results or observed data. In the first case it contains all
types of uncertainty in mathematical models. In the second case uncertainty is induced by instrumental
errors or errors in the interpolation or/and extrapolation of measured data.
Model structure is one of the uncertainty sources due to the fact that the models are an imperfect
description of reality, and they maintain approximations and simplifications. This type could be
defined as the residual uncertainty over the usage of absolutely accurate input data and optimal
calibration of the models’ parameters. It should be noted that decomposition of the structural
uncertainty in the system and the separate description of contributions of lower level models is
possible only for models with a “clear” modular structure, which provides an opportunity to assess and
control uncertainty at each step and perform separate calibrations for each of the modules.
Model parameters, as well as a model structure, contain uncertainty since they represent properties
of the real system in an approximate form. The main source of the uncertainty turns out to be a lack of
information, which is used for parameter evaluation and causes the indirect evaluation of these
parameters in the process of calibration [4].
Initial and boundary conditions are usually the results of simulation or indirectly restored
observations. In predictive systems the initial condition for the next iteration is the result of the
previous iteration. This means that the initial condition contains the uncertainty, which is typical for
the whole simulation system. Boundary conditions in modern models are seldom the result of direct
observation; moreover they are often replaced by the result of calculations of more global spatial
coverage models.
Output data, which identify the quality of the simulation, is analyzed with the actual data of the
resulting models’ variable state. As the measure of the models’ quality is considered to be the
deviation of its results from nature, it is necessary to take into account the uncertainty, which is
contained within the measures (instrumental errors and spatial variability of the measured value)
Generally, uncertainty can be subdivided into approximative uncertainty and instrumental
inaccuracy. Approximative uncertainty is induced by an incompleteness of scientific knowledge about
a simulated object or simplifications in a model due to complications in analytical solution or high
demands in resource intensity. A significant property of this type of uncertainty is constancy in time
due to the constancy of parameters and mathematical expressions in classical models. Today modern
science focuses on simulated reality (atmosphere circulation models, fields of reanalysis), which is
why approximative uncertainty penetrates all stages of simulation. Another type of uncertainty is
instrumental inaccuracy and errors because in most of cases, a comparison of simulation results and
measurements of target variables provides a criterion of model quality (in terms of adequacy,
accuracy, success rate, etc.). Inaccuracies and errors in measured data lead to incorrect conclusions
about model quality [5].
Uncertainty analysis is based on methods of estimating the confidence level for input data,
parameters, and model structure. An important stage of uncertainty analysis is a defining the
assessment end point. If the assessment end point is a distribution of stochastic variable, the
uncertainty represents inherent variability and can be classified as aleatory or type-A uncertainty. If
the end point of risk assessment is a fixed quantity (deterministic), the uncertainty connected with it
represents an interval with the true state of the system within certain limits. It results from incomplete
knowledge about each part of the prediction system and depends on our ability to describe it. This type
of uncertainty is named epistemic or type-B uncertainty [6, 7].
So, in terms of stochastic approach uncertainty can be described through the probability
distribution function of the target variable. In stochastic models, uncertainty sources can be
represented as stochastic variables. A deterministic variable can be transformed into a stochastic one
by adding a stochastic term to it. In this case the stochastic term represents an error in the estimation of
the true value of the variable and conforms to the uncertainty of type B. If the result of simulation is a
probability distribution of a random variable than it represents variability and conforms to the
uncertainty of type A. But parameters of probability distribution could be underestimated and hold an

2318

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

error or type-B uncertainty. Therefore type-A uncertainty is associated with type-B uncertainty as
variability and uncertainty. Uncertainty usually represents a confidence interval around variability
distribution. In other words, for uncertainty distribution can be formed around parameters or quintiles
of variability distribution [5].
In multi-model simulation systems there are many sources of uncertainty (heterogeneous input data
and models, lack of observed data for calibration and assimilation, etc.) and all of them can be hardly
estimated. Moreover, uncertainty tends to propagate and increases with the dataflow from one part of a
system to another.
Progressive uncertainty can be a critical issue for systems aimed to forecast and prevent extreme
events and related risks. The coastal Flood Warning System (FWS) in St. Petersburg can be analyzed
as an example of a system for forecasting and prevention of natural disaster. Coastal floods have
always been and still remain a serious threat for many coastal regions worldwide. They cause colossal
damage by affecting major port cities which are usually important economic centers and cannot be
fenced from the sea by levee. Saint-Petersburg is common example of such centers. Floods in SaintPetersburg are result of the superposition of storm surge in the eastern part of the Gulf of Finland,
seiche, and meteorologically induced water level disturbances that originate in the western and central
Baltic Sea. As a long wave propagates in the Gulf of Finland its height increases due to the
shallowness of the eastern narrow part of the Gulf. The wind also intensifies the flood wave leading to
fast level rising in Saint-Petersburg. Nowadays, special complexes are developed to protect high
populated coastal cities from economic and cultural losses caused by floods. The Saint-Petersburg
Flood Protection Barrier (FPB) is one of them. It separates the Neva Bay from the Gulf of Finland and
consists of series of dams which are equipped with floodgates for ship passage and water exchange
[8]. The Flood Warning Systems (FWS) was developed to support the management of the barrier
system in cases of flood danger. Its main objective is to predict water level rising in the Gulf of
Finland and calculate possible scenarios for flood prevention to help the Decision Making Group to
reach a decision about the barrier gates maneuvering plan [9].

2 Basic concepts
In order to solve tasks connected with coastal flood prevention a set of models and data sources
must be used. Some of them run in operational loop (in FWS) but some of them are on a research
stage (testing). The principal scheme for coastal floods prevention system is represented on Figure 1.
Main types of used models and external data sources are in Table 1.
Model type
Atmospheric models

Atmospheric forcing
models

Sea wave models
Sea dynamics models

Description
Numerical weather prediction or reanalysis can be used in the form of data sets from
external sources or results of model running inside of the system. In particular, data is
represented by pressure and wind fields in the given area across scales ranging from
several meters to thousands of kilometers. In the case study several sources of
atmospheric forecasts are used: GFS [10], HIRLAM [11], WRF [12], ERA
(reanalysis) [13], NCEP/NCAR (reanalysis) [14].
Models for parameterization of energy transfer from wind to sea surface through
tangential force parameter in hydrodynamic models. In the case study two variants of
atmospheric forcing models are used: linear expression for wind drag coefficient and
Wind-Over-Wave-Coupling theory (WOWC) [15].
Modern sea wave models are represented by third-generation spectral models. In the
case study SWAN model [16] is used.
Numerical hydrodynamic models for sea level and currents forecasts. In the case

2319

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

study several variants are used: two-dimensional model BSM (property of barrier
authority), three-dimensional model Balt-P (Russian central metofice), threedimensional model NEMO [17].
Model for generating
The model for generating an optimal plan is based on multiobjective optimization
gates maneuvering
with non-linear restrictions. Water level forecasts and local hydrometeorological
plans
conditions are used as input data. In the case study the algorithm developed by ITMO
University is used.
Model for risk
The model for risk evaluation is based on an ensemble of water level forecasts taking
evaluation
into account residual uncertainty. in the case study the algorithm developed by ITMO
University is used.
Table 1: Types of models and external data used for the task of coastal floods prevention (with case study
examples)

Figure 1. Scheme for uncertainty propagation in flood prediction system.
The scheme in Figure 1 demonstrates strong interrelations among data sources and models from
Table 1. As a result, source of uncertainty in one part of system can influence on simulation results in
other parts of system. Sources of uncertainty in such system (Fig. 1) can be connected with various
factors. The most significant of them must be noted: extrapolation effect of forecasts (in time);
selection of one variant from a set of alternative data and models; adequacy of forecasting model (in
its structure); instrumental inaccuracy of measurements; adequacy of assignment between simulated
and observed process (in space, in time, etc.).
The task of uncertainty management consists of minimizing of systematic error, minimizing the
removable part of random error, and evaluating the residual part of uncertainty. This could be reached
using one of two strategies: (1) to reduce or evaluate every source of uncertainty; (2) to determine the
most significant ways for uncertainty propagation and to allocate blocks with procedures for reducing
and evaluating these ways. The principal scheme of flood prevention system (Fig. 1) highlights the
three most significant ways: (1) uncertainty induced by atmospheric forecasts, (2) uncertainty induced
by hydrological models, (3) uncertainty induced by the interaction between atmospheric forecasts and
hydrological models taking into account sea surface processes.

2320

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

Also, Figure 1 represents blocks of action with procedures for reduction or evaluation of
uncertainty in such a way as to catch the major part of model error. Blocks of action involve several
procedures: calibration of models, data assimilation, ensemble forecasts, and various techniques for
residual uncertainty evaluation (including risk evaluation). This paper emphasizes the problem of
uncertainty reduction, which is why here, and further on, methods and procedures aimed at improving
the quality of simulation results are highlighted.
The model calibration method is used to reduce the overall uncertainty of a model (regardless of
the sources). The classical calibration procedure supposes the selection of optimal parameters, which
minimizes the objective function value of output variables. It should be noted that the calibration of
parameters can be optimal only in a model with optimal structure. Moreover it is important property
that the parameters are uncorrelated. When models with complex structure are calibrated, the
parameter to which the model is most sensitive is usually chosen. The Figure 1 demonstrates the block
of calibration models of the atmospheric forcing. The given mechanism is based on the calibration of
forcing models’ parameters, which define the relationship with meteorological characteristics (i.e. the
coefficient of friction of the wind), based on the task of hydrological models configuration.
Data assimilation can be defined as a method of dynamic correction of the mathematical model and
its results with usage of the available measured data. Despite the considerable amount of research in
this area and the existing methods, scientific data assimilation problem is not a trivial procedure.
Finding the optimal solution to the problem of data assimilation depends on many factors, including
subject specific benchmarks and features of the numerical scheme of the mathematical model.
Techniques of data assimilation in the model can be classified in accordance with the basic elements in
the model, similar to the sources of uncertainty. Thus, in the following parts of the model these
methods of assimilation could be used: input data, initial state and boundary condition, models’
parameters, and output data. The Figure 1 shows the blocks of assimilation in atmospheric models, the
model of sea waves and the model of flows and sea level. Section 3 of this paper is devoted to the
problem of data assimilation.
The ensemble forecasting approach allows identifying the sensitivity of the result of simulation for
the uncertainty of input data, state variables of the model or the models’ parameters. It is often used
for the numerical evaluation of the uncertainty in simulation results. The term “ensemble forecast”
involves constructing based on the Monte Carlo method (using one model and varying the input or
model parameters for a given probability distribution) or combining the results obtained from different
sources using different models. The uncertainty introduced into the simulation result via parameters
can be estimated using the ensemble of parameters, whereas the remaining elements of the model are
not changed. The problem of sensitivity and uncertainty evaluation can be referred to block for
residual uncertainty analysis in the Figure 1. Block, which implements the procedure of a multi-model
ensemble (Fig. 1) allows to take into account the uncertainty introduced by the model itself, by its
structure and parameters. Traditionally, the procedure of multi-model ensemble prediction is
formulated in terms of the model of vector random variable, when the resulting forecast is a linear
combination of elements of statistical ensembles with correction assigning the optimal weighting
coefficient. This approach is widely used to predict weather events of a complex nature, for instance,
those which have several significant sources of uncertainty and describe several models. Section 4 of
this paper is devoted to the ensemble forecast method.

3 Multistage data assimilation method
The data assimilation (DA) procedure is an essential part of modern systems for metocean events
forecasting. DA helps to reduce the uncertainty in deterministic forecasts that is expressed in terms of

2321

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

deviation from observed values. Historically, DA techniques were extensively developed mostly on
the basis of atmospheric and ocean modeling systems. Among the most popular DA techniques are
optimal interpolation, 3D-Var, 4D-Var, ensemble and steady state Kalman filtration. The 3D-Var
method provides optimal estimation at a particular time step, and has to be iterated over time. This
technique was upgraded to 4D-Var in order to take into account information about the process
dynamics over the entire time window [17]. Kalman filter is the most popular data assimilation
technique. Its popularity is due to the simplicity of its implementation and its robustness relative to the
misspecification of error sources [19].
The multistage DA method was designed for joint procedures for correcting sea dynamic, sea
waves, and meteorological data (Fig. 2). Corrected atmospheric forecasts are fed to the sea waves
model, and sea dynamics model. The sea waves model results (fields of wave parameters) are
corrected by a data assimilation block, and passed to sea dynamics model (by means of forcing
model). At the final stage of DA, level and current observations occur.

Figure 2. Data assimilation scheme for coastal flood prevention system
Multiscale variability of sea level is a key factor for coastal floods generation. That’s why the
stochastic model of uncertainty could be written with respect to sea level field ] ( x, y, t ) and
associated with field of sea currents W( x, y, z, t ) :
] ( x, y, t ) X ( x, y)  H ( x, y, t )  h( x, y, t )  H ( x, y, t ),
(1)
W( x, y, z, t ) Wz ( x, y, z )  V( x, y, z, t )  v( x, y, z, t )  η( x, y, z, t ).
Here X , Wz - climatic fields of sea level and currents (long-time annual average), H , V - longperiod component of sea dynamics (with time scale more than 2-4 days), h, v - synoptic-period

2322

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

component of sea dynamics (according cyclones life period 2-4 days), H , η - local small-scale
perturbations connected with sub-grid effects.
Usually, sea dynamics models for coastal flood prediction reproduce only the synoptic component
of level and currents variability h, v . In the bounds of this time scale the spectrum of model error
corresponds with the spectrum of white noise that means randomness of error. Therefore, it becomes
possible to use standard procedures of DA (first of all procedures based on Kalman filtering). For time
range X  H , Wz  V , the model error spectrum cannot be described as white noise that requires an
additional procedure. So, for multiscale process DA can be written as:
­H t H t 1  K (Yt  H t 1 )
,
(2)
®
¯ht ht 1  K (C (Yt  H t )  ht 1 )
based on solution of system for Kalman filter equations:
f
­
°ht 0ht 1  G f
.
(3)
®
f
°
¯Yt Cht  G o
In expressions 2 and 3, H t is a long-period component of sea level (that is not reproduced by
model), ht is a synoptic-period component of sea level (reproduced by model); K – Kalman gain, M
G ,G
– operator of model action, C – observations operator, f o - forecast and observation errors, index f
– forecast, index a – analysis (forecast field after correction). Yt ^y1, y2 ,...,yn ` represents a vector of
observations in control points.
In tasks connected with the prediction of extreme natural events, there are usually control points of
high importance. Forecasts at these points are involved in the decision making process (gates
maneuvering, evacuation, etc.). Therefore, there is a need to assimilate observations data directly at
control points. Dissemination of assimilation results to the whole grid is performed by using an
optimal interpolation model (formula 4). DA of sea currents v t could be made indirectly in the form
of a vector regression model (formula 4). Summarizing all the above mentioned aspects, DA in sea
dynamics model can be written in a form of system:

­ht f 0hta1
° a
f
f
°°ht ht  K (C (Yt  ht )  ht )
m
® a
f
a
f
°htk htk  ¦i 1 Aik (hti  hti )
° a
m
f
a
f
°¯ v tk v tk  ¦i 1 B ik (hti  hti )

(4)

DA in the atmospheric and sea wave model is based on similar principles, taking into account
typical time scales and spatial variability of simulated processes.

4 Ensemble forecast
Ensemble forecast is another method for uncertainty management. A sample is designed on three
forecasting levels (atmosphere, sea wave, and sea dynamics) by applying alternative models, data
sources and various sets of model options (Fig. 3).
The principal ensemble model can be written in terms of a vector random variable ([ , W( z))
model that takes into account long-period and synoptic components of sea dynamics. But for

2323

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

implementation it is handier to write the model in a form of linear dynamical system separately for
level and currents in each point (x,y):

~
h (t 0 ,W )

n

Wi

¦ ³ A (W  s)h
i

i

f

(t 0 , s)ds

i 1 f

~
v ( z , t 0 ,W )

n1 W i

¦ ³ W (W  s, z)v
j

f
j

( z, t 0 , s)ds 

j 1 f

n2 W i

¦ ³U

(5)
k (W

 s, z )hkf (t 0 , s)ds.

k 1 f

Figure 3. Principal scheme for ensemble sample design
Here Ai (x), U k (x), W j (x) - transfer functions. Model (5) provides an opportunity to forecast with
start time t 0 and horizon W . Expression for the currents ensemble forecast (in model 5) is subdivided
into two parts n1  n2 n . The first part takes into account forecasts of sea currents (directly), and the
second part involves sea level forecasts (if currents forecasts are not available).
Initial forecasts for the ensemble model (5) may have different horizons, moving window of
history, and could be extracted from different grid points. Usage of forecasts in geographically
distributed points becomes possible because of spatiotemporal dependencies of process (i.e.
correlation).
Identification of transfer functions in model (5) is fulfilled by using relevant observations y(t 0  W )
. For example, an expression for sea level ensemble forecast could be represented in a regression form:

y (J ) (t 0  W )

n

¦¦¦
D
i 1

aij(D ) hijf (t 0 ,W , ( x, y)D ) 

2324

a E y E (t , ( x, y) E )  H ,
¦¦
E
( )
k
k

0

k n 1

j

f
where h - level forecast, y – observations,

m

D, E, J

- various sets of grid points.

(6)

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

So, ensemble model (5-6) is a hybrid model written with respect to spatiotemporal dependencies in
sea level and currents fields.

5 Case study
The outlined uncertainty management strategy was applied to FWS in St. Petersburg. Currently,
blocks of data assimilation for atmosphere, sea wave and sea dynamics models, and block for
ensemble forecast are operating within a life-critical system.
Table 2 represents the efficiency of sequential application of uncertainty reduction methods: data
assimilation and ensemble forecast2. As a result, mean forecast error was reduced to 0 cm and mean
absolute forecast error was reduced by more than 50 %.
Uncertainty reduction strategy results could be also expressed in terms of the efficiency of FWS in
St. Petersburg. This criterion is estimated for low-level storm surges and indicates the relation between
a number of false decisions about gate closure and all decisions. Here false decisions are a result of
forecast with an upward bias that leads to the necessity of gates maneuvering. Table 2 shows that the
efficiency of FWS increased from 47 % to 90 % after uncertainty reduction.
Uncertainty reduction method
Without uncertainty
Data assimilation
Data assimilation
management
and ensemble
forecast
Mean forecast error, cm
-6.8
1,9
0
Mean absolute forecast error, cm
13
7,5
6,1
Efficiency of FWS in St.
47
82
90
Petersburg, %
Table 2: Efficiency of uncertainty management strategy for FWS in St. Petersburg

In section 3 basic principles of data assimilation in models for multiscale metocean processes are
discussed. But in the context of the particular task of flood prevention in St. Petersburg there were
several specific points.
Assimilation of sea level data in control points could be produced in distant grid points (when the
control point is out of grid boundaries). In St. Petersburg the control point “Gorny institute” is situated
in the Neva River and is not covered by several models (i.e. BSM). For this case extending
assimilation procedure is used, and it allows to take into account a variability of mean sea level (X in
formula 1 notation). Another feature is the method of DA in a sea wave model on a nested grid
(around flood barrier structures). Because of the small size of the region and the strong spatiotemporal
dependencies of the process, DA is performed as a dynamic correction of boundary conditions.
Ensemble forecast model (6) in St. Petersburg achieves the best result for combination forecasts in
eastern part of the Gulf of Finland and observed data in the western part of the Baltic Sea (in the
Danish straights). The usage of forecasts in the Neva Bay area helps to improve ensemble quality for
lead times 0 – 30 hours, but observations usage in distant points makes it possible to improve
ensemble quality for lead times more than 30 hours.

6 Conclusions
This paper outlines the problem of computational uncertainty management in task of coastal flood
prevention. The uncertainty management strategy consists of determining significant ways of
uncertainty propagation and collocating blocks of action to reduce or evaluate uncertainty. The main
2

Based on results of usage within FWS of St. Petersburg in 2013-2014 years

2325

Computational uncertainty management for coastal ﬂood prevention system

A.Kalyuzhnaya et.al.

methods of uncertainty management involve model calibration, data assimilation, ensemble forecast,
and evaluation of residual uncertainty and related risks. In a multi-model simulation system, data
assimilation could be represented as a multistage method joining data assimilation blocks for various
connected models. The ensemble forecast method is represented as a hybrid model, allowing for use of
forecasted and observed data in geographically distributed points.
The results of the announced strategy could be expressed in terms of the efficiency of FWS in St.
Petersburg. It is clear that efficiency of FWS increased from 47 % to 90 % after applying the
uncertainty management strategy.
This paper is supported by Russian Scientific Foundation, grant #14-11-00823. The research is
performed in Advanced Computing Lab (ITMO University), which is created in the frame of 220
Decree of Russian Government, contract #11.G34.31.0019.

References
[1] Morgan M.G., Small M. (1992). Uncertainty: a guide to dealing with uncertainty in
quantitative risk and policy analysis. Cambridge University Press.
[2] Finkel A.M. (1990). Confronting Uncertainty in Risk Management: A Guide for Decisionmakers: a Report. Center for Risk Management, Resources for the Future.
[3] Liu Y., Gupta H.V. (2007). Uncertainty in hydrologic modeling: Toward an integrated data
assimilation framework. Water Resources Research, 43(7).
[4] Costa R., Kristbergsson K. (2009). Predictive modeling and risk assessment. Springer.
[5] Verdonck F. et al. (2001). Probabilistic environmental risk assessment. Med. Fac. Landbouw
Univ. Gent, 66, 13–19.
[6] H. Apel et al. (2004). Flood risk assessment and associated uncertainty. Natural Hazards and
Earth System Science, 4(2), 295-308.
[7] F. O. Hoffma, J. S. Hammonds. (1994). Propagation of Uncertainty in Risk Assessments: The
Need to Distinguish Between Uncertainty Due to Lack of Knowledge and Uncertainty Due to
Variability. Risk Analysis, 14(5), 707-712.
[8] Saint Petersburg Flood Prevention Facility Complex. http://dambaspb.ru (in Russian).
[9] Boukhanovsky A. et al. (2012) Urgent computing for operational storm surge forecasting in
Saint-Petersburg: in: Proceedings of the InternationalConference on Computational Science, ICCS
2012.
[10] Global Forecast System (http://www.emc.ncep.noaa.gov/GFS/)
[11] HIRLAM (http://www.hirlam.org/).
[12] Michalakes J. (2004). The Weather Research and Forecasting Model: software architecture
and performance. in: Proceedings of 11th ECMWF Workshop on the use of High Performance
Computing in Meteorology. Reading, UK.
[13] ERA-Interim <http://www.ecmwf.int/en/research/climate-reanalysis/era-interim>
[14]NCEP/NCAR Reanalysis < http://www.esrl.noaa.gov/psd/data/reanalysis/reanalysis.shtml>
[15]Makin V.K., Kudryavtsev V.N., Mastenbroek C. Drag of the sea surface. Boundary-Layer
Meteorology, 73(1), 159–182.
[16] SWAN (http://swanmodel.sourceforge.net/)
[17] NEMO model <http://www.nemo-ocean.eu/>
[18] Bouttier, F. (1999) Data assimilation concepts and methods. Meteorological training course
lecture series. ECMWF.
[19] Madsen, H. and Ca˜nizares, R. (1999) Comparison of extended and ensemble Kalman fitlers
for data assimilation in coastal area modelling. International Journal for Numerical Methods in
Fluids, 31(6), 961-981.

2326

