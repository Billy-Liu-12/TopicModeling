Procedia Computer Science
Volume 51, 2015, Pages 1323–1332
ICCS 2015 International Conference On Computational Science

Application of GRAPE9-MPX for high precision
calculation in particle physics and performance results
Hiroshi Daisaka1 , Naohito Nakasato2 , Tadashi Ishikawa3 , and Fukuko Yuasa3
1

3

Hitotsubashi University
2
University of Aizu
High Energy Accelerator Research Organization

Abstract
There are scientiﬁc applications which require calculations with high precision such as Feynman
loop integrals and orbital integrations. These calculations also need to be accelerated. We have
been developing dedicated accelerator systems which consist of processing elements (PE) for
high precision arithmetic operations and a programing interface. GRAPE9-MPX is our latest
system with multiple Field Programmable Gate Array (FPGA) boards on which our developed
PEs are implemented. We present the performance results for GRAPE9-MPX extended to have
up to 16 FPGA boards for quadruple, hexuple, and octuple precision calculation. The achieved
performance for a Feynman loop integral with 12 FPGA boards is 26.5 Gﬂops for quadruple
precision, 13.2 Gﬂops for hexuple precision, and 6.36 Gﬂops for octuple precision. We show
that our hardware implementation is 80 - 200 times faster than software implementations. We
also give analysis of the performance results.
Keywords: Feynman loop integral, high-precision arithmetic, accelerator, GRAPE

1

Introduction

Requirement of numerical calculations and simulations with higher precision is growing. This is,
of course, to obtain rather precise results than those obtained by double precision calculation.
In addition, it has been reported that there is a beneﬁt given by higher precision calculation.
For certain iterative algorithms exhibiting weak convergence, the number of iteration can be
greatly reduced when using higher precision. This leads to a possibility that the execution time
for calculation of convergence becomes short [1].
In particle physics, one of the cases requiring high precision calculation is the numerical
evaluation of multiloop Feynman integrals, in which calculations with precision higher than
double precision are required to obtain stable results due to the divergent nature of the loop
integrals [2]. It seems problematic that it is not clear how high precision is required to obtain an
appropriate solution for loop integrals, i.e., it is not clear how wide the mantissa and exponent
should be. It depends probably on the divergent nature of loop integrals we wish to evaluate.
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.317

1323

Application of GRAPE9-MPX

H. Daisaka et al.

It is likely that we have to calculate loop integrals with not only quadruple but also hexuple
and octuple precision arithmetic.
Even if we use double precision arithmetic, evaluation of a multiloop integral is computationally intensive. This is because a precise evaluation of the integrand is needed at each of a
huge number of multi-dimensional integration points, and we need to treat a wide variety of
multiloop integrals. Therefore, it is not realistic to use software implementations like, for example, MPFR [3], from the viewpoint of computational time, because software implementations
of high precision arithmetic is not eﬀective in general.
In order to accelerate such a calculation with high precision, we have been developing a
series of accelerator boards, named as GRAPE-MPs , which were connected to a host computer
[4] [5] [6] . In the developments, we have designed GRAPE-Multi-Precision (MP) processor
which consisted of a number of processing elements (PE) and memory components with dedicated circuits for quadruple, hexuple, and octuple precision arithmetic. We implemented this
processor on a structured ASIC (Application Speciﬁc Integrated Circuit) [4] and on an FPGA
board with a control processor [5] [6]. Our latest system is GRAPE9-MPX, which consists of
multiple FPGA boards, enabling us to implement more PEs in the system. For the system
with 4 FPGA boards, Motoki et al. [6] presented the performance measurements by calculating
Feynman loop integrals, mainly focused on the case of quadruple precision. In this paper, we
present the performance measurements for GRAPE9-MPX with up to 12 FPGA boards, including the cases of hexuple and octuple precision in addition to the case of quadruple precision.
Also, we give analysis of the performance measurements.
Previous studies showed less scalability in the performance results when varying the number
of FPGA boards [5] [6]. This is due to the inﬂuence of overhead of data transfer between FPGA
boards and a host computer. Since it is expected that the situation becomes worse with more
FPGA boards, it is signiﬁcant to optimize I/O interface in order to improve the scalability.
This paper is organized as follows. In next section, we brieﬂy explain the requirement of
high precision in a multiloop integral. In section 3, we overview GRAPE9-MPX, focusing on
the update. We brieﬂy explain Feynman loop integral used for the performance measurement
and show the results in section 4. The last section is devoted to the summary.

2

Example of necessity of 15-bit exponent

The integral for an N -dimensional scalar Feynman diagram with L loops and N internal lines
can be represented in Feynman parameter space as
I=

Γ(N − dL
2 )
(−1)N
dL/2
(4π)

1 N
0 j=1

dxj δ(1 −

xi )

C N −d(L+1)/2
.
(D − iεC)N −dL/2

(1)

Here the functions C and D are polynomials of Feynman parameters, {xi }, determined by the
topology of the corresponding Feynman diagram [7] and d is a space-time dimension. The term
iεC in the denominator prevents the integral from diverging when the denominator vanishes in
the interior of the domain. We proposed Direct Computation Method (shortly DCM) [8] for the
numerical evaluation of loop integrals. It is a fully numerical method and is a combination of
a numerical multi-dimensional integration and an extrapolation. In this method, it is essential
to get a very precise result by the numerical integration.
Let us consider the integral below as an example,
I(η) =
1324

1
0

1−x1

dx1

0

dx2

1
, η > 0.
(x1 x2 )1−η

(2)

Application of GRAPE9-MPX

H. Daisaka et al.

Table 2.1: Numerical results in double precision with 11-bit exponent. xmin = 0.1491668 ×
10−153 corresponds to the square root of the smallest positive number representable with 11-bit
exponent, and Neval = 347 and h = 0.03132.
4
5
6
7

η = 2−
0.0625
0.03125
0.015625
0.0078125

η2 × I
0.9941263
0.9984387
0.9923926
0.8832410

|η 2 × (I − Ianalytic )|
0.3371749 × 10−9
0.2608374 × 10−4
0.7217638 × 10−2
0.1166713 × 100

It corresponds to one-loop vertex integral (N = 3, L = 1 in Eq.(1)) with massless internal
lines taking d = 4 + 2η, where η is a dimensional regularization parameter in a quantum ﬁeld
theory. When x1 = x2 = 0, it has an endpoint singularity. In DCM, we evaluate Eq.(2)
with several ﬁxed ηs in order to get the sequence of I(η) and then extrapolate the sequence
to the limit of η → 0 to get the coeﬃcients of the expansion numerically. Analytically Eq.(2)
2
(1+η)
can be integrated as Ianalytic (η) = η12 ΓΓ(1+2η)
and expanded into a Laurent series in η as

2
+ Cη−1
1 + C0 + . . ., where Ck is a coeﬃcient. In DCM, we evaluate the integration, η × I,
for ﬁxed ηs, by Double Exponential Formula (shortly DE) [9] numerically and extrapolate the
results to get the coeﬃcient of the ﬁrst term. DE is based on the variable transformation as
1
∞
x = φ(t) = 1/2[1 + tanh((π/2)sinh(t))] for the integral 0 f (x)dx = −∞ f (φ(t)))φ (t)dt and
C−2
η2

N

+
f (φ(kh)))φ (kh), where Neval = N− + N+ + 1 is a
the trapezoidal rule as IhNeval = h k=−N
−
number of the evaluation and h is a mesh size . It is well known that DE has an advantage on
the endpoint singularity.

In Table2.1 we present the error, η 2 ×(I −Ianalytic ), where I is evaluated in double precision
with 11-bit exponent by DE. The numerical error depends on xmin , because the contribution
from the endpoint part, 0 to xmin , is not evaluated. For a ﬁxed xmin , the non-evaluated
contribution is increasing with the decreasing η as Δ ∼ xηmin . In Fig.2.1, the behavior of
errors are plotted. The error such as −2.61 × 10−5 for η = 2−5 comes from the lack of the
evaluation of the endpoint part in the numerical integration due to the limitation of the length
of the exponent. In order to see the behavior of errors regarding to the length of the exponent
bit, we plot the contribution from the endpoint part estimated by the minimum abscissa,
xmin = φ(tmin ), and present it in Fig.2.1 for this example. In double precision arithmetic
with 11-bit exponent, only the rectangular light blue area in Fig.2.1 can be computed and the
minimum error becomes about 2−31 with xmin = 2−511 for η = 2−4 . However, in quadruple
precision with 15-bit exponent, the computable area is extended to the whole area and the
minimum error becomes 2−64 with xmin = 2−8191 for η = 2−7 . In DCM we need the precise
numerical results for Eq.(2) with errors below 2−31 even for η smaller than 2−5 to get the precise
result after extrapolation in the limit of η → 0. Using 15-bit exponent we can evaluate the
integration for the smaller xmin and the smaller η. This example clearly shows that the length
of the exponent plays an important role in the numerical integration of loop integrals with an
endpoint singularity.
1325

Application of GRAPE9-MPX
0

-20

H. Daisaka et al.

4

η=(1/2)
5
η=(1/2) 6
η=(1/2)7
η=(1/2)

log2(Δ)

-40

-60

-80

-100

-8000

-7000

-6000

-5000

-4000

log2xmin

-3000

-2000

-1000

0

Figure 2.1: Relative errors of Eq.(2) from xmin = 2−256 to 2−8191 , with double precision calculation (11-bit exponent) (ﬁlled markers) and quadruple precision calculation (15-bit exponent)
(open markers). Calculations with double precision (11-bit exponent) is allowed in the area of
rectangle (light blue).

3

Overview of GRAPE9-MPX

GRAPE9-MPX system is our latest system of an accelerator with multiple FPGA boards connected to a host computer, on which the MP processor we have been developing is implemented [4] [5] [6]. The MP processor contains PEs which form an SIMD processor. Each
PE has a ﬂoating-point multiply unit and an add unit for quadruple, hexuple, and octuple
precision (hereafter MP4, MP6, and MP8) which can perform an operation in every clock cycle. One of the suitable applications for our system is an interaction type calculation such as
nj
fi = j=1
f (Xi , Yj ) where f is a function with variables Xi and Yi belonging to array variables X and Y . The system includes not only the hardware but also the Goose compiler which
provides a simple programming interface. This compiler allows us to use GRAPE9-MPX by
putting the directive like OpenMP into an application program written by C/C++. For details,
see Daisaka et al. [4] and Nakasato et al. [5].
One of the features of GRAPE9-MPX hardware is that the system consists of multiple FPGA
boards by using PCI Express extender boards (G9MG from KFCR [10]). Figure 3.1 shows a
schematic diagram of the basic system and a picture of the current GRAPE9-MPX system. For
the FPGA board, we used Altera ArriaV board which has logic resources enough to implement
more than 10 PEs. Table 3.1 summarizes our current implementation and performance of MP4,
MP6, and MP8 per board. The peak performance of MP4 with 12 boards is 79.2 Gﬂops.
In order to increase the performance and improve the eﬃciency when the number of FPGA
boards increases, we have improved the GRAPE9-MPX system as follows. One way is to
use two G9MG boards which enable us to integrate 16 FPGA boards. Another improvement
is to optimize I/O interface which makes data transfer from each board to a host computer
in parallel. This is realized by utilizing OpenMP. Each thread created by OpenMP handles
1326

Application of GRAPE9-MPX

H. Daisaka et al.

Figure 3.1: Schematic diagram (left) and picture (right) of GRAPE9-MPX.

Logic utilization
Number of PEs
Clock Speed(MHz)
Peak(Gﬂops)

MP4
88%
36
92
6.6

MP6
81%
20
81
3.2

MP8
89%
12
70
1.6

Table 3.1: Logic utilization, number of PEs, clock speed, and the peak performance for MP4,
MP6, and MP8 implemented on ArriaV. Size of memory implemented in ArriaV is 4k words
for instructions and 32k words for data.
each FPGA board, while in our previous implementation, data was transferred from a host
to each FPGA board in a sequential manner. With this optimization, it can be expected to
improve the scalability of the performance especially in the range where data transfer aﬀects
the performance. Note that this is automatically realized by expanding the functions of Goose
compiler, hence we need no change in our application program.

4

Performance results

4.1

Application to Feynman loop integrals

For the performance measurements, we calculated the two-loop crossed box diagram as in [6].
The integral of this diagram can be expressed as
I2loop

1

=

2
0

3

dξ1 dξ2 dξ3 dξ4 dξ5 dξ6 (ξ12 ξ1 ξ2 ξ4 ξ4 )

C
,
D3

(3)

where
C

=

ξ1 (ξ1 + ξ1 ξ4 ξ4 ),

D

=
−

ξ1 ((ξ1 + ξ1 ξ4 ξ4 )
(ξ1 (ξ1 ξ2 ξ2 ξ3 ξ3 + ξ1 ξ4 ξ4 (ξ2 (ξ3 ξ5 ξ6 + ξ3 ξ5 ξ6 ) − ξ2 ξ5 ξ6 ))

+
+

ξ1 ξ2 (ξ1 ξ4 ξ4 (−ξ5 ξ6 + ξ5 ξ6 ) + (ξ1 ξ2 ξ3 + ξ1 ξ4 ξ4 ξ5 ) + (ξ1 ξ2 ξ3 + ξ1 ξ4 ξ4 ξ6 ))
ξ1 ξ4 (ξ1 ξ5 (ξ2 + ξ2 ξ3 )(ξ4 ξ5 + ξ4 ξ6 ) + ξ1 ξ2 ξ3 ξ5 (ξ4 ξ5 + ξ4 ξ6 ) + ξ1 ξ4 ξ4 ξ5 ξ5 )

+

ξ1 ξ4 (ξ1 ξ6 (ξ2 + ξ2 ξ3 )(ξ4 ξ5 + ξ4 ξ6 ) + ξ1 ξ2 ξ3 ξ6 (ξ4 ξ5 + ξ4 ξ6 ) + ξ1 ξ4 ξ4 ξ6 ξ6 ))),

(4)

1327

Speed[Gflops]

Application of GRAPE9-MPX

H. Daisaka et al.

10.0

MP4
MP6
MP8

1.0
101

102

103

104

Nj

Figure 4.1: The measured performance in Gﬂops for MP4 (red squares), MP6 (green circles),
and MP8 (blue triangles) with 12 boards as a function of Nj .

with ξi = 1 − ξi .
Since I2loop is 6-dimensional, we can straightforwardly evaluate the integral with six-nested
loops by the DE scheme. Computation time for the numerical evaluation of the loops depends on
the total number of evaluation points, Ntotal = Π6k=1 Nk , where Nk is the number of evaluation
points in each dimension. In order to take an advantage of the architecture of GRAPE9-MPX,
we adopt a technique called loop fusion, in which we replace the nested 6-dimensional loops
with Ntotal points with 2 loops. In the present work, we replace the outer 3-dimensional loops
with a single loop (i-loop) and the inner 3-dimensional loops with a single loop (j-loop), so that
Ntotal = Ni × Nj where Ni = N1 × N2 × N3 and Nj = N4 × N5 × N6 are the iteration counts
for each loop. In the measurement, we set Ni = 218 and Nj = 2k where k = 4, 5, 6, ..., 13.
Hereafter, we call the maximum problem size for Nj = 213 , in which Ntotal is 231 .
Our programming system generates a compile report listing the number of operations needed
for a given kernel calculation. This report shows that the number of the total arithmetic operation counts for the loop integral Eq. (3) is 91. Then, together with measured computational
time, a number of performance in ﬂops can be evaluated as (91Ni Nj )/(computational time)
ﬂops. Note that the number of the operation counts involving load/store instructions for memory becomes 128.

4.2

Performance in ﬂops

We measured the performance of GRAPE9-MPX with varying number of FPGA boards up to
12. For a host computer, we used a Linux PC (Scientiﬁc Linux 6.5) with Intel Xeon 2687W
(3.4GHz, 8 cores / 16 HT) CPU on ASRock Xtreme11 motherboard (X79 chipset), whose
bandwidth of PCIe is adequate to connect two G9MG boards. For the measurement calculation
with 8 and 12 boards, we carried out 5 runs and took a maximum value of the performance
at each point as the resulting value, because the results for 8 and 12 boards showed large
ﬂuctuation in each run. The ﬂuctuation is probably due to the fact that we used OpenMP
1328

Application of GRAPE9-MPX

H. Daisaka et al.

tmeasure
ti
tgmp
model

T[s]

10-4

10-5

101

102

103

104

Nj

Figure 4.2: Elapsed time with performance model for MP4 with a single board.

under a circumstance where a number of control threads becomes equal to or larger than that
of physical cores of CPU, which often shows an unexpected behavior in performance.
The performance results for MP4, MP6, and MP8 with 12 boards are shown in Fig. 4.1.
The performance becomes maximum at the maximum problem size. The achieved performance
in the maximum problem size is 26.5 Gﬂops for MP4, 13.2 Gﬂops for MP6, and 6.36 Gﬂops
for MP8, respectively. The eﬃciency compared to the peak performance is about 30 % in all
cases which is consistent with that attained in our previous works with Altera StratixIV FPGA
board [5]. In the smaller problem size (Nj < 1000), the performance becomes worse, since the
overhead of data transfer between the host PC and GRAPE9-MPX aﬀects the performance, as
explained in the following section.

4.3

Performance Model

Figure 4.2 shows the measured elapsed time required for calculation per one i-data point (described by tmeasure ) as a function of Nj for a single board, together with the two dominant
components in the elapsed time, ti (the elapsed time required for i-data transfer) and tgmp (the
sum of the elapsed time required for the calculation on GRAPE9-MPX and the time required
for getting back the results to the host), so that tmeasure ∼ ti + tgmp . The other components
related to data transfer such as time required for j-data transfer are negligible compared to that
of i-data transfer, since the amount of j-data is much smaller than that of i-data. Also, the
time to process on the host is negligible. One can see in Fig. 4.2 that tgmp is proportional to Nj
whereas ti is almost constant since the amount of i-data is ﬁxed, so that tmeasure is dominated
by tgmp in larger problem size (Nj > 1000) whereas by ti in smaller Nj . Thus, data transfer
considerably aﬀects the performance when the problem size is small.
In order to understand the behavior of the performance in detail, we construct a performance
model, which can be applied for the performance of the system with multiple boards. Following
previous studies (e.g., [5]), we can describe the elapsed time required for the calculation per
1329

Application of GRAPE9-MPX
10-3

nb=1
nb=4
nb=12
model(1)
model(4)
model(12)

10-3

nb=1
nb=4
nb=12
model(1)
model(4)
model(12)

T[s]

10-4

T[s]

10-4

H. Daisaka et al.

10-5

10-5

10-6
101

10-6
102

103

104

101

Nj

102

103

104

Nj

Figure 4.3: The elapsed time required for the calculation per one i-data point, as a function of
Nj for MP6 (left panel) and MP8 (right panel) varying the number of FPGA boards.

one i-data point as
Tmodel = thost + tkernel + tcomm ,

(5)

where thost , tkernel , and tcomm are the time to process on the host computer, the time required
for execution of the kernel instructions for one i-data point on GRAPE9-MPX, and the time
required for the communication between the host and GRAPE9-MPX, respectively. The time
tkernel can be expressed as a function of the operation clock of PEs (C Hz), a number of PEs
(np ) per board, a number of FPGA boards (nb ), a number of instructions executed in the kernel
(Ninst ), and a number of j-data (Nj ) as,
tkernel ∼

Ninst
Nj
.
×
C
np nb

(6)

Note that Ninst is the number of the instructions actually executed on the GRAPE9-MPX
which contains not only arithmetic operations but also the load and store instructions. For the
Feynman loop integral used here, the number of the instructions becomes 128. The time tcomm
is given as
(7)
tcomm = tj + (ti + tzero + tf )/nb ,
where tj , ti , tzero , and tf are the elapsed time required for j-data transfer, i-data transfer,
sending zero to clear accumulate registers in PE which is required, and getting result from
GRAPE9-MPX. Note that these terms are for a single board and include the time for data
conversion. For simplicity, we used deduced values from Fig. 4.2 as tj = 0 (sec), ti = 3.7 × 10−6
(sec), tzero = 0 (sec), and thost = 2.0 × 10−7 (sec). For tf , we used an empirical value as
tf = 2.0 × 10−6 (sec), because it is diﬃcult to separate tf from tgmp . With those parameters
in addition to the parameters for MP4, np = 36, C = 92MHz, and nb = 1 so that tkernel ∼
3.86 × 10−8 Nj (sec), we present the performance model in Fig. 4.2 as the solid line, showing
that the performance model and the measurements are in good agreement.
In Fig. 4.3, we also plot the elapsed time required for the calculation per one i-data point with
1, 4, 12 boards for MP6 and MP8, with lines given by the performance model. We estimated
tkernel for MP6 and MP8 by using values in Table 3.1, whereas for the other parameters we used
the same values as MP4. Figure 4.3 also shows a good agreement between the measurement
and the performance model, even when we vary the number of boards.
1330

Application of GRAPE9-MPX

time
sign
exponent
mantissa

MP4
7.33
1
15
112

MP6
14.6
1
15
176

H. Daisaka et al.

MP8
27.9
1
15
240

F4
1569.1
1
116.26

F6
2108.7
1
179.38

F8
2226.5
1
242.50

quadmath
1074.7
1
15
112

DD
182.6
1
11
105

QD
1658.8
1
11
211

Table 4.1: Execution time (sec) of the calculation of the loop integral for the maximum size
problem with GRAPE9-MPX and software implementations. F4/F6/F8 denotes the implementation with MPFR in which mantissa is determined by setting 35/54/73-digit in decimal which
corresponds to MP4/MP6/MP8, exponent is not speciﬁed in our program. “quadmath” has
IEEEE754-2008:binary128 compatible format supported on gcc4.6 or later.

It is also apparent in Fig. 4.3 that the speed-up gained by using multiple boards compared
to a single board. The performance increases almost linearly in wider range of Nj when we
use up to 12 boards. In the maximum problem size speed-up gain is 3.97 times faster using 4
boards, and 11.6 times faster using 12 boards. Even in the smallest problem size (Nj = 16),
speed-up gain is 3.66 for 4 boards and 9.3 times faster using 12 boards, which is a signiﬁcant
improvement compared to the results in our previous work [6] in which it was little speed-up
gain for 4 boards. This improvement of the scalability is mainly due to the parallelization of
the data transfer by using OpenMP.

4.4

Comparison to Software Implementations

We also compared the performance of GRAPE9-MPX and software implementations for the twoloop crossed box integral in Eq.(3) in the maximum problem size. For software implementations,
we used MPFR [3], quadmath on gcc, and DD/QD library[11] [12]. In the implementation
of MPFR, we set 35/54/73-digit in decimal which is denoted as F4/F6/F8 corresponding to
MP4/MP6/MP8. For the calculation with software implementations, we used the host computer
of the GRAPE9-MPX, and utilize OpenMP for parallelization with 16 threads.
Table 4.1 lists the execution time of overall calculation of the loop integral for MP4, MP6,
MP8 and the software implementations. Comparison with GRAPE9-MPX and the software
implementations with the same size of mantissa shows that the former is about 100 times faster
than the latter. For examples, MP4 is about 214 times faster than F4, and about 147 times
faster than quadmath. MP6 is about 144 times faster than F6, and MP8 is about 80 times faster
than F8. The diﬀerence in the execution time between F6 and F8 seems not so signiﬁcant. This
is probably related to internal data representation used in MPFR. We also list the execution time
with DD/QD in Table 4.1. Even for DD and QD format which has only 11-bit exponent, MP4
is about 25 times faster than DD, and 226 times faster than QD. Thus, we show the advantage
of GRAPE9-MPX in the performance.

5

Summary

We described the performance of GRAPE9-MPX system consisting of multiple FPGA boards
on which our developed PEs for quadruple, hexuple, and octuple precision arithmetic operations
are implemented. The performance measurements have been made with the following notable
improvements of GRAPE9-MPX system: (a) we expand the maximum number of FPGA boards
from 8 to 16, (b) we have redesigned the software interface in order to enhance data transfer
1331

Application of GRAPE9-MPX

H. Daisaka et al.

to each FPGA board in parallel with the help of OpenMP. The achieved performance for the
two-loop crossed box integral on the system with 12 FPGA boards is 26.5 Gﬂops for MP4, 13.2
Gﬂops for MP6, and 6.36 Gﬂops for MP8. We also show that the scalability in the performance
is signiﬁcantly improved, increasing almost linearly in wider range of the problem size when we
use up to 12 boards. We also constructed a performance model and showed a good agreement
even when we increased the number of FPGA boards. We have shown that our latest system
is 80 - 200 times faster than the software implementations.

Acknowledgment
This work is supported by Grant-in-Aid for Scientiﬁc Research (23540328 and 24540292) of
JSPS, and the Large Scale Simulation Program No. 14/15-06 of KEK.

References
[1] J. Fujimoto, T. Ishikawa, and D. Perret-Gallix, “High precision numerical computations
A case for an HAPPY design,” in ACPP IRG note:ACPP-N-1 KEK-CP-164, 2005.
[Online]. Available: http://emc2.in2p3.fr/cgi-bin/twiki.source/pub/ACAT/PresentationsNotes/
Highprecisionnumericalcomputatio3.pdf
[2] F. Yuasa, E. de Doncker, J. Fujimoto, N. Hamaguchi, T. Ishikawa, and Y. Shimizu, “Precise
Numerical Evaluation of the Scalar One-Loop Integrals with the Infrared Divergence,” in
PoS(ACAT), vol. 087, 2007. [Online]. Available: http://pos.sissa.it/cgi-bin/reader/conf.cgi?
conﬁd=50
[3] L. Fousse, G. Hanrot, V. Lef`evre, P. P´elissier, and P. Zimmermann, “Mpfr: A multiple-precision
binary ﬂoating-point library with correct rounding,” ACM Trans. Math. Softw., vol. 33, no. 2,
Jun. 2007. [Online]. Available: http://doi.acm.org/10.1145/1236463.1236468
[4] H. Daisaka, N. Nakasato, J. Makino, F. Yuasa, and T. Ishikawa, “GRAPE-MP: An SIMD Accelerator Board for Multi-precision Arithmetic,” Procedia Computer Science, vol. 4, pp. 878–887,
2011.
[5] N. Nakasato, H. Daisaka, T. Fukushige, A. Kawai, J. Makino, T. Ishikawa, and F. Yuasa, “GRAPEMPs: Implementation of an SIMD for Quadruple/Hexuple/Octuple-Precision Arithmetic Operation on a Structured ASIC and an FPGA ,” Embedded Multicore Socs (MCSoC), 2012 IEEE 6th
International Symposium on, pp. 75–83, Sept 2012.
[6] S. Motoki, H. Daisaka, N. Nakasato, T. Ishikawa, F. Yuasa, T. Fukushige, A. Kawai, and J. Makino,
“A development of an accelerator board dedicated for multi-precision arithmetic operations its
application to Feynman loop integrals,” in 16th International Workshop on Advanced Computing
Analysis Techniques in Physics Research, accepted, 2014.
[7] N. Nakanishi, Graph Theory and Feynman Integrals. Gordon and Breach, New York, 1971.
[8] E. de Doncker, Y. Shimizu, J. Fujimoto, and F. Yuasa, “Computation of loop integrals using
extrapolation,” Computer Physics Communications, vol. 159, no. 3, pp. 145–156, 2004.
[9] M. Mori, “Discovery of the Double Exponential Transformation and Its Developments,” Publications of the Research Institute for Mathematical Sciences, vol. 41(4), pp. 897–935, 2005.
[10] K & F Computing Research Co., “PCI Express Extender.” [Online]. Available: http://www.kfcr.
jp/grapedr.html
[11] High-Precision Software Directory. [Online]. Available: http://crd-legacy.lbl.gov/∼dhbailey/
mpdist/
[12] Y. Hida, X. Li, and D. Bailey, “Algorithms for Quad-Double Precision Floating Point Arithmetic,”
in Proceedings of the 15th Symposium on Computer Arithmetic, 2001, pp. 155–162.

1332

