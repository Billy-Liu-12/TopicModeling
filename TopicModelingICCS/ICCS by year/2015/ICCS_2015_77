Procedia Computer Science
Volume 51, 2015, Pages 221–230
ICCS 2015 International Conference On Computational Science

A systematic review of heuristics for proﬁle reduction of
symmetric matrices
J´
unior Assis Barreto Bernardes and Sanderson L. Gonzaga de Oliveira
Departamento de Ciˆencia da Computa¸c˜
ao, Universidade Federal de Lavras, Lavras, MG, Brazil
jrassis@posgrad.ufla.br,sanderson@dcc.ufla.br

Abstract
In this work, a systematic review of heuristics for proﬁle reduction of symmetric matrices is
presented. 74 heuristics tested for reduction proﬁle were found. Researchers compared results of
their heuristics with results of other heuristics. In this review, these comparisons were analyzed
and 8 heuristics were identiﬁed as the possible best for the problem. In addition, exchange
methods, a form of local search, were identiﬁed that can beneﬁt heuristics identiﬁed as the best
ones for the task.
Keywords: proﬁle reduction; combinatorial optimization; envelope reduction problem; graph labelling;
sparse matrices; ordering; reordering algorithms; renumbering.

1

Introduction

Resolution of sparse linear systems in the form Ax = b is fundamental in many numerical
simulations in Science and Engineering and is often responsible for most of the computational
cost in these experiments. The resolution of sparse linear systems is associated, for example, in
the application of the ﬁnite element method which is an important tool in numerical simulations.
Proﬁle reduction can beneﬁt the storage cost of linear systems as well as it can reduce
the computational cost of direct and iterative methods to solve linear systems. For example,
the conjugate gradient method [43, 22] is frequently used for numerical solution of large-scale,
symmetric and positive-deﬁnite sparse linear systems. Let the graph G = (V, E), composed
of a set of vertices V and a set of edges E, correspond the n × n coeﬃcient matrix A = [aij ],
with 1 ≤ i, j ≤ n. One can reduce the computational cost of the conjugate gradient method
by locally ordering the vertices in V [11] so that cache hit rates are improved [10, 6]. This
local ordering can be obtained by a heuristic for proﬁle reduction. Proﬁle reduction can also
beneﬁt other iterative methods to solve linear systems, such as the GMRES method [56]. The
proﬁle minimization problem is hard [48]. The proﬁle of A can be deﬁned as prof ile(A) =
n

i=1

i − min (j | aij = 0) . Several heuristics for proﬁle reduction have been proposed since
1≤j<i

the 1960s and no recent review in this subject was found. Gibbs et. al. [18], Everstine [12]
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.231

221

A review of heuristics for proﬁle reduction of symmetric matrices

Bernardes, Gonzaga de Oliveira

and Lim et. al. [47] compared heuristics published until 1976, 1979 and 1993, respectively.
Here, a systematic review of heuristics for proﬁle reduction published from the 1960s to 2014
is presented.
In section 2, details of the systematic review performed are described. Comparisons of
results of heuristics for proﬁle reduction are shown in section 3. In section 4, comparisons
of results of possible best heuristics for proﬁle reduction are presented. Finally, in section 5,
conclusions and future works are addressed.

2

Systematic Review

This present review began in June, 2014, and concerns heuristics for proﬁle reduction. It was
conducted with the support of the Scopus R database. A search was performed in Scopus R
database using the terms: (Topic = “proﬁle” OR Topic = “envelope”) AND (Topic = “reduction” OR Topic = “reducing” OR Topic = “minimization” OR Topic = “minimisation” OR
Topic = “minimizing” OR Topic = “optimization” OR Topic = “optimizing”) AND (Topic =
“sparse matrix” OR Topic = “sparse matrices” OR Topic = “stiﬀness matrix”). These terms
were searched in the title, abstract and keywords of the articles indexed in the database. This
search resulted in 213 articles. Among these articles retrieved, those ones related to heuristics
for proﬁle reduction were selected. The titles and abstracts of the articles found were then
analyzed independently by two reviewers and a third reviewer was not required since both reviewers agreed with the selections made. In addition to the articles that met the eligibility
criteria, other articles were analyzed to support some of the concepts involved in the heuristics
that had been selected.
Next, to have a clear comparison of the papers selected, data were extracted according to
the following headings: authors, year of publication, results and conclusions. Among the 213
articles retrieved, 48 heuristics for proﬁle reduction were selected and are shown in Table 1.
Afterwards, a backward citation tracking was carried out based on the articles found so that
24 other heuristics were identiﬁed. This means that some of authors of the 213 articles cited
other articles in which other heuristics were proposed. These 24 heuristics are listed in Table
2. Naturally, these papers were studied too. In addition, 2 other heuristics for proﬁle reduction
were found in this second-phase backward citation tracking. These 2 heuristics are shown
as the ﬁrst heuristics in Table 2. Simulations and comparisons related to these 74 heuristics
were evaluated. As a result of this analysis, no articles were found that showed simulations
and comparisons in a manner that could suggest that 8 heuristics might be considered to be
surpassed by any other heuristic. In Figure 1, a graphic of the number per year of these 74
heuristics published from 1969 to 2014 is shown.
14
12

Number of heuristics

10
8
6
4
2
0
1969-1975

1976-1980

1981-1985

1986-1990

1991-1995

1996-2000

2001-2005

2006-2010

2011-2014

Figure 1: Number per year of heuristics published from 1969 to 2014, among the 74 heuristics
for proﬁle reduction found in this systematic review.
222

A review of heuristics for proﬁle reduction of symmetric matrices
Article

Heuristic

Year

Gibbs et. al. [17]
Snay [62]

GPS
Snay
GPS-Lewis
GK-Lewis
TSI
MINDEG ARANY
MAXSWING
Sloan
SloanImp
Zeng
Koo-Lee
Luo
MPG
SloanM
GPSM
Gibbs-KingM
PFM-2
SAPR
SFR
Spectral
LWE
Hybrid
NSloan
Sloan-MGPS
Sloan-Spectral
Hybrid-Perm
Hybrid-Vector
Hu-Scott
Weighted Greedy
Exchange Methods
xRCM-GL
xSloan
xSpectral
xHybrid
xHu-Scott
rsSloan
Ossipov
BTIM
KZL
ALCA
Assymmetric-RCM
GGPS
Wang-Guo-Shi
BIMTR
CSS-band
GPHH-RCM
GP
GPHH-Sloan

1976
1976

Lewis [45]
Taniguchi et. al. [64]
Smyth [60]
Sloan [57]
Sloan [58]
Zeng [68]
Koo and Lee [35]
Luo [49]
Medeiros et. al. [50]
Souza and Murray [63]
Hoit et. al. [25]
Lewis [46]
Paulino et. al. [53]
Barnard et. al. [2]
Lai et. al. [41]
Kumfert and Pothen [40]

Reid and Scott [54]
Hu and Scott [26]

Hager [21]

Reid and Scott [55]
Ossipov [51]
Boutora et. al. [5]
Kaveh et al. [33]
Zhou and Ren [69]
Wang et. al. [67]
Boutora et. al. [4]
Kaveh and Sharafi [32]
Koohestani and Poli [36]
Koohestani and Poli [37]
Koohestani and Poli [39]

Bernardes, Gonzaga de Oliveira

1982
1984
1985
1986
1989
1990
1992
1992
1993

Article retrieved
from Scopus R

Heuristic cited

Year

Gibbs et. al.[18]

MDF and CM-PR
cited in [9]

1969

Gibbs et. al.[18]
1993
Gibbs et. al. [17]
1994
1994
1994
1995
1996
1997

1999

Gibbs et. al.[18]
Lewis[45]
Smyth [60]
Lim et. al. [47]
Hoit et. al. [25]
Sloan and Ng [59]
Hoit et. al. [25]

2001

Reid and Scott [54]

2002

Kumfert and Pothen [40]
Lai and Chang [42]
Kaveh et. al. [33]

2002
2005
2007
2007
2009
2009
2011
2012
2012
2012
2014

Kaveh and Sharafi [32]

CM [9]
King [34]
RCM [14]
Levy [44]
Cheng [7]
Collins [8]
Wang [65]
Gibbs-King [16]
Smyth-Arany [61]
RCM-GL [15]
RCM-GL-FL [13]
PFM [23]
Armstrong [1]
PFM-1 [24]
RCM(SGPD) [52]
GPS(SGPD) [52]
GK(SGPD) [52]
Multi-A [3]
Multi-B [3]
Guan-Willians [20]
KavehBondarabady [27]
KS-ACO-King [28]
Sloan-ACO [29]
KS-ACO-FourSteps [30]

1969
1970
1971
1971
1973
1973
1973
1976
1976
1981
1983
1983
1985
1989
1994
1994
1994
1996
1996
1998
2002
2007
2008
2009

Table 2: 26 heuristics found in the backward
citation track in the 213 articles retrieved
from Scopus R database.

Table 1: 48 heuristics found by using
Scopus R database.

3

Comparisons of results presented by heuristics for proﬁle reduction

In this section, carried out by researchers, simulations and comparisons among results of
heuristics are addressed. The Reverse Cuthill-McKee (RCM) method [14], the Gibbs-PooleStockmeyer (GPS) heuristic [17] and the Reverse Cuthill-McKee method with George-Liu algorithm [15] for vertex pseudo-peripheral method (called here as RCM-GL) were employed as
benchmarks, but they were not the only ones used in the evaluations and comparisons performed among the results of the heuristics for proﬁle reduction. The RCM, GPS, and RCM-GL
heuristics reduce proﬁles at a low computational cost. Since they are classic heuristics for proﬁle
reduction, they have been extensively used by researchers to compare results of heuristics in
this context. Details of the evaluations and comparisons are described below.
Naturally, the heuristics authors compared results of their heuristics with results of other
heuristics in their works. Those comparisons made by the authors were studied seeking to
identify heuristics that might have been surpassed by other heuristics. In the ﬁrst column
of Table 3, 37 heuristics for proﬁle reduction are shown. In the second column of Table 3,
it is shown heuristics whose results (proﬁle reduction and computational cost) surpassed the
heuristic shown in the ﬁrst column. These tests have been outlined in publications shown in
223

A review of heuristics for proﬁle reduction of symmetric matrices

Bernardes, Gonzaga de Oliveira

the third column of Table 3. Similarly, in the second column of Table 4, it is listed 16 heuristics
that showed comparable results in proﬁle reduction but with lower computational cost than the
heuristic shown in the ﬁrst column of this table.
Heuristic

Surpassed in proﬁle reduction

Tests in

CM [9]
MDF [9]
CM-PR [9]

RCM [14]

George [14]

Gibbs-King [16] and GPS [17]
CSS-band [32]
GPS [17]
PFM [23]
CM [9], GPS [17]

Gibbs [16]
Kaveh and Sharafi [32]
Gibbs et. al. [17]
Hoit and Wilson [23]
Everstine [12]

GPS [17]

Gibbs et. al. [18]

GPS [17]
GK-Lewis [45]
Koo-Lee [35]
GPS-Lewis [45] and GK-Lewis [45]
Koo-Lee [35]
BTIM [5]
BIMTR [4]
SloanImp [58]
Sloan [57]
SloanImp [58]
NSloan [40]

Gibbs [16]
Lewis [45]
Koo and Lee [35]
Lewis [45]
Koo and Lee [35]
Boutora et. al. [5]
Boutora et. al. [4]
Sloan [58], Sloan and Ng [59], and Lim et. al. [47]
Sloan [57]
Sloan [58] and Sloan and Ng [59]
Boman and Hendrickson [3]

King [34]
RCM [14]
Levy [44]
Cheng [7]
Collins [8]
Wang [65]
Gibbs-Kingv[16]

GPS [17]
GPS-Lewis [45]
GK-Lewis [45]
MINDEG ARANY [60]
MAXSWING [60]
Sloa86 [57]
PFM-1 [24]
Koo-Lee [35]
SloanM [63]
GPSM [63]
Gibbs-KingM [63]
PFM-2 [25]
RCM(SGPD) [52]
GPS(SGPD) [52]
GK(SGPD) [52]
Spectral [2]
Multi-A [3]
Multi-B [3]
Lai [41]
Hybrid [40]
Weighted Greedy [21]
Exchange Methods [21]
xSloan [21]
KS-ACO-King [28]
Sloan-ACO [29]
KS-ACO-FourSteps [30]
KP2012 [37]

RCM-GL [15]

Smyth [60]

SloanImp [58]
NSloan [40]
CSS-band [32]
GPS [17]
SloanImp [58]
Sloan [57]
GPS [17]
Gibbs-King [16]
Gibbs-King [16]
RCM-GL [15]
GPS [17]
Gibbs-King [16]
NSloan [40] and Hybrid [40]

Sloan [57] and Sloan and Ng [59]
Kumfert and Pothen [40]
Kaveh and Sharafi [32]
Hoit and Garcelon [24]
Lim et. al. [47]

NSloan [40]

Boman and Hendrickson [3]

GPS [17]
NSloan [40]

Lai et. al. [41]
Kumfert and Pothen [40]

Souza and Murray [63]
Hoit et. al. [25]
Paulino et. al. [52]
Kumfert and Pothen [40]

Sloan [57]

Hager [21]

rsSloan [55]
King [34]
Sloan [57]

Reid and Scott [55]
Kaveh and Sharafi [28]
Kaveh and Sharafi [31]

CSS-band [32]

Kaveh and Sharafi [32]

Sloan [57]

Koohestani and Poli [37] and Koohestani and Poli [38]

Table 3: Comparisons among heuristics for proﬁle reduction. In the ﬁrst column, 37 heuristics
for proﬁle reduction are shown. These 37 heuristics were surpassed by heuristics shown in the
second column in direct comparisons analyzed in the articles shown in the third column.

Furthermore, 13 other heuristics that were not considered as possible state-of-art heuristics
for proﬁle reduction are commented as follows. The Smyth-Arany’s [61], Luo’s [49], GuanWilliams’ [20], Kaveh-Bondarabady [27], Ossipov’s [51] and KZL [33] heuristics were not compared with other heuristics by their authors. Since their own authors did not compare their
heuristics with any other, we did not consider these heuristics as possible state-of-art heuristics for proﬁle reduction. The Zeng’s [68], ALCA [69], Zhou and Ren’s Asymmetric-RCM [69]
heuristics, and the heuristic of Boutora et al. [4] were proposed for speciﬁc graph cases as trees,
asymmetric matrices and cylindrical meshes. In addition, the Koohestani and Poli’s paper [36],
cited by Koohestani and Poli [39], was not found. Also, the Armstrong’s heuristic [1] and
the Koohestani and Poli’s hyper-heuristic GPHH-Sloan [39] showed impractical computational
costs. Thus, these heuristics were not considered as possible state-of-art heuristics for proﬁle
reduction.
224

A review of heuristics for proﬁle reduction of symmetric matrices
Heuristic

Bernardes, Gonzaga de Oliveira

Surpassed in proﬁle reduction
and/or in computational cost

Tests in

RCM [14]

George [14]
Lewis [46]

Sloan-MGPS [54]

Reid and Scott [54]

PFM [23]
SAPR [46]
Sloan-Spectral [54]
Hybrid-Perm [54]
Hybrid-Vector [54]
SFR [53]
xRCM-GL [21]
xSpectral [21]
xHybrid [55]
xHu-Scott [55]
rsSloan [55]
TSI [64]
BTIM [5]
GGPS [67]
Wang-Guo-Shi [66]
CSS-band [32]

Paulino et. al [53]
Hager [21]
RCM-GL [15]
Reid and Scott [55]

GPS [17]

Taniguchi et. al. [64]
Boutora et. al. [5]
Wang et. al. [67]
Wang et. al. [66]
Kaveh and Sharafi [32]

Table 4: Comparisons among heuristics for proﬁle reduction. In the ﬁrst column, 16 heuristics
for proﬁle reduction are shown. These 16 heuristics were surpassed by heuristics shown in the
second column, that is, these 16 heuristics presented smaller proﬁle reduction and/or higher
computational cost than the heuristics shown in the second column, in indirect comparisons
analyzed in the papers in which the heuristics were proposed and in publications shown in the
third column.

4

Possible best heuristics for proﬁle reduction

Heuristics that have been classiﬁed as being possibly better at proﬁle reduction are addressed
in this section. These heuristics are shown in Table 5. In order to be considered in this section
as one of the possible best alternatives for proﬁle reduction at a reasonable computational cost,
a heuristic must be able to yield results in proﬁle reduction that are signiﬁcantly better than
the results of the RCM, GPS, and RCM-GL heuristics and must have a computational cost that
is not excessively higher in comparison to the RCM, GPS, and RCM-GL heuristics, as shown,
either directly or indirectly, in comparisons made by researchers in their publications.
Heuristic
Snay
RCM-GL
RCM-GL-FL
SloanImp
MPG
NSloan
Sloan-MGPS
Hu-Scott

Article
Snay [62]
George and Liu [15]
Fenves and Law [13]
Sloan [58]
Medeiros et. al. [50]
Kumfert and Pothen [40]
Reid and Scott [54]
Hu and Scott [26]

Year
1976
1981
1983
1989
1993
1997
1999
2001

Table 5: Possible best methods for proﬁle reduction.

Figure 2: An example mesh in solid lines and
its connectivity graph in dashed lines.

Snay [62] compared the results obtained by his heuristic and the RCM heuristic [14]. The
proﬁles obtained by the Snay heuristics were on average 22% smaller than those obtained with
the RCM heuristic. We cannot aﬃrm that the Snay’s heuristic was surpassed by the RCM
heuristic because no information about the computational cost of the Snay’s heuristic was
shown.
The RCM-GL heuristic [15], despite having obtained larger proﬁles than other heuristics
that were compared with it, presents a signiﬁcantly lower runtime compared to execution times
of other heuristics. Therefore, it is considered one of the possible state-of-art heuristic for proﬁle
reduction.
Fenves and Law [13] applied the RCM-GL heuristic [15] in a mesh connectivity graph for
225

A review of heuristics for proﬁle reduction of symmetric matrices

Bernardes, Gonzaga de Oliveira

proﬁle reduction. We called here this implementation as RCM-GL-FL. The mesh connectivity
graph is a graph G = (V , E ) with vertices in V’ representing the mesh polytopes and edges
in E’ represent interfaces between two polytopes (see Figure 2). The authors compared this
implementation with the RCM-GL heuristic itself. The RCM-GL-FL implementation obtained
proﬁles on average 8.2% larger but in a runtime 4.5 times lower in relation to the RCM-GL
heuristic. Thus, this mesh connectivity graph may beneﬁt the RCM-GL heuristic if the mesh
connectivity graph can be obtained quickly. Particularly, this is inherent in ﬁnite volume
discretizations and an example is shown in Gonzaga de Oliveira et al. [19].
Sloan [58] proposed a new implementation of his previous heuristic [57]. The author compared results of the new implementation, called here as SloanImp, with results obtained by
the Armstrong’s heuristic [1], with the RCM-GL [15] and with Gibbs-King [16] heuristics. The
SloanImp implementation [58] obtained proﬁles on average 8.8% smaller compared to the GibbsKing heuristic and 14.8% smaller compared to the RCM-GL heuristic. Regarding to runtime,
Sloan [58] commented that the RCM-GL heuristic was 140% faster than the Gibbs-King heuristic and 50% faster than the SloanImp implementation [58]. Similar results were presented by
Sloan and Ng [59].
Medeiros et. al. [50] proposed a heuristic for proﬁle reduction, called here as MPG. This
heuristic was compared with the RCM-GL heuristic [15], with the GK-Lewis heuristic [45],
with the SloanImp heuristic [58] and with the Armstrong’s heuristic [1]. The MPG heuristic
obtained proﬁles on average 16% smaller in relation to the RCM-GL heuristic, 10.2% smaller in
relation to the GK-Lewis heuristic [45], 1.5% smaller in relation to the SloanImp heuristic, and
8% larger than the Armstrong’s heuristic. With regard to execution time, the MPG heuristic
was on average 1.9 time slower than the RCM-GL heuristic and its computational time was
slightly slower than the SloanImp heuristic.
Kumfert and Pothen [40] proposed the NSloan heuristic and in their experiments, it obtained
proﬁles on average 42.5% smaller in relation to the RCM-GL heuristic [14], 11.2% smaller
compared to the Sloan’s heuristic [57] and 0.5% larger in relation to the results of the Spectral
heuristic [2]. In relation to runtime, the NSloan heuristic was identical to the Sloan’s heuristic
[57] and 5.8 times faster than the Spectral heuristic; however, it was 2.2 times slower than the
RCM heuristic.
Reid and Scott [54] proposed the Sloan-MGPS heuristic that obtained proﬁles smaller than
the Spectral heuristic [2]. According to results presented by Reid and Scott [54], the Spectral
heuristic obtained results on average 7.93% larger than the Sloan-MGPS heuristic. It should be
noticed that we considered the Spectral heuristic surpassed because it was on average 5.8 times
slower than the NSloan heuristic although the Spectral heuristic obtained proﬁles on average
only 8.07% larger than the NSloan heuristic. Thus, according to results of the Spectral heuristic
[2] shown by Kumfert and Pothen [40], one can infer that the Sloan-MGPS heuristic reduces
proﬁles considerably. Reid and Scott [54] did not show results regarding to runtime. However,
the execution time of the Sloan-MGPS heuristic, quite possibly, is similar to the runtime of the
Sloan [57] because the Sloan-MGPS heuristic is the Sloan heuristic [57, 58] but with a step for
ﬁnding the pseudo-peripheral vertex based on the GPS-heuristic step for ﬁnding the pseudoperipheral initial vertex. Therefore, since the Sloan-MGPS heuristic reduces proﬁles similarly
to the Spectral heuristic as well as the the Sloan-MGPS heuristic is probably as fast as than
the NSloan heuristic, we listed the Sloan-MGPS heuristic as one of the possible best heuristic
for the task.
Hager [21] proposed the xRCM-GL heuristic, which is the RCM-GL heuristic [15] using
exchange methods for local search. In Hager’s experiments, the xRCM-GL heuristic obtained
proﬁles on average 16.4% smaller in relation to the RCM-GL heuristic and execution times
226

A review of heuristics for proﬁle reduction of symmetric matrices

Bernardes, Gonzaga de Oliveira

were not shown. Moreover, Reid and Scott [55] tested several heuristics for proﬁle reduction.
In their tests, the Hu-Scott [26] and the xHu-Scott [21] heuristics obtained proﬁles on average
16.1% and 20.7% smaller than the Sloan’s heuristic [57], respectively. The xHu-Scott heuristic
[21] is the Hu-Scott heuristic [26] using exchange methods for local search. Reid and Scott
[55] compared results of the Sloan [57], the Hu-Scott [26], and the xHu-Scott [21] heuristics.
On the other hand, Hager [21] compared results of the Sloan [57] and the RCM-GL heuristics.
Thus, indirectly, we compared those results between the Hu-Scott [26], the xHu-Scott [21],
and the RCM-GL heuristics in relation only to proﬁle reduction because computational costs
were not presented in those works. From the Hager’s results [21] with Sloan’s heuristic [57],
the Hu-Scott heuristic [26] and the xHu-Scott heuristic [21] obtained proﬁles on average 39.2%
and 42.7% smaller in relation to the RCM-GL heuristic [15], respectively. Thus, since the HuScott heuristic present computational cost signiﬁcantly slower than the xHu-Scott heuristic,
the Hu-Scott heuristic was listed in Table 5 as one of the possible best algorithm for proﬁle
reduction.
In addition, Reid and Scott [55] extended the adjacent exchange methods previously proposed by Hager [21]. In the results presented by Reid and Scott [55], the Sloan’s heuristic [57]
using the adjacent exchange methods, called here as rsSloan, obtained the same proﬁle reduction in relation to the Sloan’s heuristic [57] using the Hager’s exchange methods [21], called
here as xSloan. Moreover, the rsSloan heuristic was on average 25.3 times faster compared to
the xSloan heuristic. Consequently, the results of all the heuristics listed in Table 5 may be
improved by using the adjacent exchange methods [55].

5

Conclusions

An analysis of comparisons performed by researchers among 74 heuristics for proﬁle reduction
of symmetric matrices was the objective of this systematic review. Possibly, other heuristics
for proﬁle reduction exist; however, it is highly probable that results of the main ones were
considered in this systematic review.
These 74 algorithms are inherently dependent on the instances because they were designed as
heuristics. In spite of this, comparisons and published results of the researchers were analyzed
and considered as correct. Resultantly, eight heuristics were identiﬁed as presenting a large
proﬁle reduction at a very low computational cost, as shown in Table 5. In future studies, these
heuristics shall be implemented in order to compare their results and computational costs. In
addition, the Reid and Scott’s adjacent exchange methods [55] associated to these heuristics
for proﬁle reduction shall also be evaluated.

Acknowledgements
This work was undertaken with the support of the CNPq - Conselho Nacional de Desenvolvimento Cientﬁco e Tecnolgico (National Council for Scientiﬁc and Technological Development)
and FAPEMIG - Fundao de Amparo Pesquisa do Estado de Minas Gerais (Minas Gerais
Research Support Foundation).

References
[1] B. A. Armstrong. Near-minimal matrix proﬁles and wavefronts for testing nodal resequencing
algorithms. International Journal for Numerical Methods in Engineering, 21(10):1785–1790, 1985.

227

A review of heuristics for proﬁle reduction of symmetric matrices

Bernardes, Gonzaga de Oliveira

[2] S. T. Barnard, A. Photen, and H. D. Simon. A spectral algorithm for envelope reduction of sparse
matrices. Numerical Linear Algebra with Aplications, 2(4):317–334, 1995.
[3] E. Boman and B. Hendrickson. A multilevel algorithm for reducing the envelope of sparse matrices.
Technical Report SCCM-96-14, Stanford University, Stanford, USA, 1996.
[4] Y. Boutora, R. Ibtiouen, S. Mezani, N. Takorabet, and A. Rezzoug. A new fast method of proﬁle
and wave-front reduction for cylindrical structures in ﬁnite elements method analysis. Progress In
Electromagnetics Research B, 27:349–363, 2011.
[5] Y. Boutora, N. Takorabet, R. Ibtiouen, and S. Mezani. A new method for minimizing the bandwidth and proﬁle of square matrices for triangular ﬁnite elements mesh. IEEE Transactions on
Magnetics, 43(4):1513–1516, 2007.
[6] D. A. Burgess and M. Giles. Renumbering unstructured grids to improve the perfofmance of codes
on hierarchial memory machines. Advances in Engineering Software, 28(3):189–201, 1997.
[7] K. Y. Cheng. Minimizing the bandwidth of sparse symmetric matrices. Computing, 11(2):103–110,
1973.
[8] R. J. Collins. Bandwidth reducing by automatic renumbering. Internatinal Journal for Numerical
Methods in Engineering, 6(3):345–356, 1973.
[9] E. Cuthill and J. McKee. Reducing the bandwidth of sparse symmetric matrices. In 24th National
Conference, pages 157–172, New York, USA, 1969. ACM.
[10] R. Das, D. J. Mavriplis, J. H. Saltz, S. K. Gupta, and R. Ponnusamy. The design and implementation of a parallel unstructured euler solver using software primitives. Technical Report AD-A249
437, Institute for Computer Applications in Science and Engineering - NASA, Virgina, USA, 1992.
[11] I. S. Duﬀ and G. A. Meurant. The eﬀect of ordering on preconditioned conjugate gradients. BIT,
29(4):635–657, December 1989.
[12] G. C. Everstine. A comparison of three resequencing algorithms for the reduction of matrix proﬁle
and wavefront. International Journal for Numerical Methods in Engineering, 14(6):837–853, 1979.
[13] S. J. Fenves and K. H. Law. A two-step approach to ﬁnite element ordering. International Journal
for Numerical Methods in Engineering, 19(6):891–911, 1983.
[14] A. George. Computer implementation of the ﬁnite element method. PhD thesis, Stanford University, Stanford, USA, 1971.
[15] A. George and J. W. Liu. Computer solution of large sparse positive deﬁnite systems. Prentice-Hall,
Englewood Cliﬀs, 1981.
[16] N. E. Gibbs. Algorithm 509: A hybrid proﬁle reduction algorithm. ACM Transactions on Mathematical Software, 2(4):378–387, December 1976.
[17] N. E. Gibbs, W. G. Poole, and P. K. Stockmeyer. An algorithm for reducing the bandwidth and
proﬁle of a sparse matrix. SIAM Journal on Numerical Analysis, 2(13):236–250, 1976.
[18] N. E. Gibbs, W. G. Poole, and P. K. Stockmeyer. Comparison of several bandwidth and proﬁle
reduction algorithms. ACM Transactions on Mathematical Software, 4(1):322–330, 1976.
[19] S. L. Gonzaga de Oliveira, M. Kischinhevsky, and J. M. R. S. Tavares. Novel graph-based adaptive triangular mesh reﬁnement for ﬁnite-volume discretizations. CMES: Computer Modeling in
Engineering & Sciences, 95(2):119–141, 2013.
[20] Y. Guan and K. L. Williams. Proﬁle minimization on triangulated triangles. Technical report,
Computer Science Department of Western Michigan University, 1998. Technical Report TR/98-02.
[21] W. W. Hager. Minimizing the proﬁle of a symmetric matrix. SIAM Journal on Scientiﬁc Computing, 23(5):1799–1816, 2002.
[22] M. R. Hestenes and E. Stiefel. Methods of conjugate gradients for solving linear systems. Journal
of Research of the National Bureau of Standards, 49(36):409–436, 1952.
[23] M. Hoit and E. L. Wilson. An equation numbering algorithm based on a minimum front criteria.
Computers & Structures, 16(1–4):225–239, 1983.
[24] M. I. Hoit and J. H. Garcelon. Updated proﬁle front minimization algorithm. Computers &

228

A review of heuristics for proﬁle reduction of symmetric matrices

Bernardes, Gonzaga de Oliveira

Structures, 33(3):903–914, 1989.
[25] M. I. Hoit, D. Stoker, and G. R. Consolazio. Neural networks for equation renumbering. Computers
an Structures, 52(5):1011–1021, 1994.
[26] Y. Hu and J. A. Scott. A multilevel algorithm for wavefront reduction. SIAM Journal on Scientiﬁc
Computing, 23(4):1352–1375, 2001.
[27] A. Kaveh and R. Bondarabady. A multi-level ﬁnite element nodal ordering using algebraic graph
theory. Finite Elements in Analysis and Design, 38(3):245–261, 2002.
[28] A. Kaveh and P. Sharaﬁ. A simple ant algorithm for proﬁle optimization of sparse matrix. Asian
Journal of Civil Engineering, 9(1):35–46, 2007.
[29] A. Kaveh and P. Sharaﬁ. Optimal priority functions for proﬁle reduction using ant colony optimization. Finite Elements in Analysis and Design, 44(3):131–138, 2008.
[30] A. Kaveh and P. Sharaﬁ. Nodal ordering for bandwidth reduction using ant system algorithm.
Engineering Computations, 26(3):313–323, 2009.
[31] A. Kaveh and P. Sharaﬁ. Proﬁle reduction for sparse matrices using an ant system. In Proc. of
the 12th Int. Conference on Civil, Structural and Environmental Engineering Computing, 2009.
[32] A. Kaveh and P. Sharaﬁ. Ordering for bandwidth and proﬁle minimization problems via charged
system search algorithm. IJST Transactions of Civil Engineering, 36(2):39–52, 2012.
[33] A. Kaveh, M. Zahedi, and K. Laknegadi. A novel nodal ordering algorithm for proﬁle optimization
by eﬃcient solution of diﬀerential equation. Engineering Computations, 24(6):572–585, 2007.
[34] I. P. King. An automatic reordering scheme for simultaneous equations derived from network
systems. International Journal for Numerical Methods in Engineering, 2(4):523–533, 1970.
[35] B. Koo and B. Lee. An eﬃcient proﬁle reduction algorithm based on the frontal ordering scheme
and the graph theory. Computers e Structures, 44(6):1339–1347, 1992.
[36] B. Koohestani and R. Poli. A genetic programming approach for evolving highly-competitive general algorithms for envelope reduction in sparse matrices. In Proceedings of the 12th International
Conference on Parallel Problem Solving from Nature - Volume Part II, PPSN’12, pages 287–296,
Berlin, Heidelberg, 2012. Springer-Verlag.
[37] B. Koohestani and R. Poli. On the application of genetic programming to the envelope reduction
problem. In 4th Comp. Sc. and Electronic Eng. Conf., pages 53–58, Colchester, UK, 2012. IEEE.
[38] B. Koohestani and R. Poli. Addressing the envelope reduction of sparse matrices using a genetic
programming system. Computational Optimization and Applications, pages 1–26, 2014.
[39] B. Koohestani and R. Poli. Evolving an improved algorithm for envelope reduction using a hyperheuristic approach. IEEE Transactions on Evolutionary Computation, 18(4):543–558, 2014.
[40] G. Kumfert and A. Pothen. Two improved algorithms for envelope and wavefront reduction.
Technical Report NAS1-19480, Institute for Computer Applications in Science and Engineering
NASA Langley Research Center, Hampton, Virginia, 1997.
[41] Y. Lai, V. I. Weingarten, and H. Eshraghi. Matrix proﬁle and wavefront reduction based on the
graph theory and wavefront minimization. Int. J. for Num. Meth. in Eng., 39(7):1137–1159, 1996.
[42] Y. L. Lai and G. Chang. On the proﬁle of the corona of two graphs. Information Processing
Letters, 89(6):287–292, 2004.
[43] C. Lanczos. Solutions of systems of linear equations by minimized iterations. Journal of research
of the National Bureau of Standards, 49(1):33–53, 1952.
[44] R. Levy. Resequencing of the structural stiﬀness matrix to iprove computational eﬃciency. JPL
Quarterly Technical Review, 1(2):61–70, July 1971.
[45] J. G. Lewis. Implementation of the Gibbs-Poole-Stockmeyer algorithms and Gibbs-King algorithms. ACM Transactions on Mathematical Software, 8(2):180–189, 1982.
[46] R. R. Lewis. Simulated annealing for proﬁle and ﬁll reduction of sparse matrices. International
Journal for Numerical Methods in Engineering, 37(6):905–925, 1994.

229

A review of heuristics for proﬁle reduction of symmetric matrices

Bernardes, Gonzaga de Oliveira

[47] I. L. Lim, I. W. Johnston, and S. Choi. A comparison of algortithms for proﬁle reduction of sparse
matrices. Computer and Structures, 57(2):297–302, 1995.
[48] Y. Lin and J. Yuan. Proﬁle minimization problem for matrices and graphs. Acta Mathematicae
Applicatae Sinica, 10(1):107–122, 1994.
[49] J. Luo. Algorithms for reducing the bandwidth and proﬁle of a sparse matrix. Computers and
Structures, 44(3):535–548, 1992.
[50] S. R. P. Medeiros, P. M. Pimenta, and P. Goldenberg. Algorithm for proﬁle and wavefront reduction
of sparse matrices with a symmetric structure. Engineering computations, 10(3):257–266, 1993.
[51] P. P. Ossipov. Simple heuristic algorithm for proﬁle reduction of arbitrary sparse matrix. Applied
Mathematics and Computation, 168(2):848–857, 2005.
[52] G. H. Paulino, I. F. M. Menezes, M. Gattass, and S. Mukherjee. New algorithm for ﬁnding a
pseudoperipheral vertex or the endpoints of a pseudodiameter in a graph. Communications in
Numerical Methods in Engineering, 10(11):913–926, 1994.
[53] G. H. Paulino, I. F. M. Menezes, M. Gattass, and S. Mukherjee. Node and element resequencing
using the laplacian of a ﬁnite element graph: Part i - general concepts and algorithm. International
Journal for Numerical Methods in Engineering, 37(9):1511–1530, 1994.
[54] J. K. Reid and J. A. Scott. Ordering symmetric sparse matrices for small proﬁle and wavefront.
International Journal for Numerical Methods in Engineering, 45(12):1737–1755, 1999.
[55] J. K. Reid and J. A. Scott. Implementing Hager’s exchange methods for matrix proﬁle reduction.
ACM Transactions on Mathematical Software, 28(4):377–391, December 2002.
[56] Y. Saad and M. H. Schultz. GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems. SIAM Journal on Scientiﬁc and Statistical Computing, 7(3):856–869,
July 1986.
[57] S. W. Sloan. An algorithm for proﬁle and wavefront reduction of sparse matrices. International
Journal for Numerical Methods in Engineering, 23(2):239–251, 1986.
[58] S. W. Sloan. A Fortran program for proﬁle and wavefront reduction. International Journal for
Numerical Methods in Engineering, 28(11):2651–2679, 1989.
[59] S. W. Sloan and W. S. Ng. A direct comparison of three algorithms for reducing proﬁle and
wavefront. Computers and Structures, 33(2):411–419, 1989.
[60] W. F. Smyth. Algorithms for the reduction of matrix bandwidth and proﬁle. Journal of Computational and Applied Mathematics, 12–13(C):551–561, 1985.
[61] W. F. Smyth and I. Arany. Another algorithm for reducing bandwidth and proﬁle of a sparse
matrix. In Proc. of U.S. National Computer Conference, pages 987–994, New York, 1976. ACM.
[62] R. A. Snay. Reducing the proﬁle of sparse symmetric matrices. Bull. G´eod., 50(4):341–352, 1976.
[63] L. T. Souza and D. W. Murray. Alternative pseudoperipheral node ﬁnder for resequencing schemes.
International Journal for Numerical Methods in Engineering, 36(19):3351–3379, 1993.
[64] T. Taniguchi, N. Shiraishi, and K. Itoh. Proﬁle minimisation algorithm for sparse matrix. Advances
in Engineering Software, 6(3):156–163, 1984.
[65] P. T. R. Wang. Bandwidth minimization, reducibility, decomposition, and triangularization of
sparse matrices. PhD thesis, Comp. and Inf. Science Research Center, Ohio State Univ., 1973.
[66] Q. Wang, Y. Guo, and X. Shi. An improved algorithm fpr matrix bandwidth and proﬁle reduction
in ﬁnite element analysis. Progress In Electromagnetics Research Letters, 9:29–38, 2009.
[67] Q. Wang, Y.C. Guo, and X.W. Shi. A generalized GPS algorithm for reducing the bandwidth and
proﬁle of a sparse matrix. Progress in Electromagnetics Research, 90:121–136, 2009.
[68] Z. Zeng. An improved algorithm for proﬁle minimisation of sparse systems of equations. Advances
in Engineering Software, 12(4):197–199, 1990.
[69] J. Zhou and Y. Ren. An algorithm for reducing the proﬁle of a sparse asymmetric 0-1 matrix. In
Proceedings of the 2009 WRI World Congress on Software Engineering - Volume 02, WCSE ’09,
pages 234–238, Washington, DC, USA, 2009. IEEE Computer Society.

230

