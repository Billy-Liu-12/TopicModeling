Procedia Computer Science
Volume 51, 2015, Pages 855–864
ICCS 2015 International Conference On Computational Science

The Stochastic Simplex Bisection Algorithm
Christer Samuelsson
German Research Center for Artiﬁcial Intelligence
christer.samuelsson@dfki.de

Abstract
We propose the stochastic simplex bisection algorithm. It randomly selects one from a set
of simplexes, bisects it, and replaces it with its two oﬀspring. The selection probability is
proportional to a score indicating how promising the simplex is to bisect. We generalize intervals
to simplexes, rather than to hyperboxes, as bisection then only requires evaluating the function
in one new point, which is somewhat randomized. Using a set of simplexes that partition the
search space yields completeness and avoids redundancy. We provide an appropriate scale- and
oﬀset-invariant score deﬁnition and add an outer loop for handling hyperboxes. Experiments
show that the algorithm is capable of exploring vast numbers of local optima, over huge ranges,
yet ﬁnding the global one. The ease with which it handles quadratic functions makes it ideal
for non-linear regression: it is here successfully applied to logistic regression. The algorithm
does well, also when the number of function evaluations is severely restricted.
Keywords: Optimization, Stochastic Search, Simplex, Bisection, Hyperbox, Regression

1

Introduction

Stochastic optimization [22], i.e., using randomness to guide search, is currently popular: genetic
algorithms [6], particle swarm optimization [13], and ant-colony optimization [3] are celebrity
approaches. These schemes are not only applied to discrete problems, but also to continuous
ones, especially for objective functions where the gradient and Hessian are not readily available,
e.g., where the function value is only obtainable by expensive simulation. We here propose—for
lack of a more evocative name [20]—the stochastic simplex bisection algorithm. Contrary to
many stochastic optimization schemes, it avoids redundancy, yet retains completeness.
Consider the simple problem where we wish to minimize f (x), which is (strictly) convex on
R. Assume further that we have found x1 < x3 < x5 , where f (x1 ) ≥ f (x3 ) ≤ f (x5 ).
Algorithm for Convex Functions
Choose x2 ∈]x1 , x3 [ and x4 ∈]x3 , x5 [, i.e., choose interior points x2 and x4 .
If f (x2 ) ≤ f (x3 ), recurse on x1 , x2 , x3 . If f (x4 ) ≤ f (x3 ), recurse on x3 , x4 , x5 .
Otherwise, recurse on x2 , x3 , x4 .
To paraphrase: “recurse on the subinterval that has an interior point with a smaller function
value than its end points.” But what happens when the function is not convex? Is there some
other version of this algorithm that works? And how does this generalize to several dimensions?
Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.215

855

The Stochastic Simplex Bisection Algorithm

Samuelsson

In the non-convex case, we cannot in general know how f (x1 ), . . . , f (x5 ) compare. A greedy
algorithm might choose to recurse on x1 , x2 , x3 if f (x2 ) ≤ f (x4 ), but on x3 , x4 , x5 otherwise. Or
it could use some more elaborate criterion to select whether to delve into the subinterval [x1 , x3 ]
or into the subinterval [x3 , x5 ]. We deliberately avoid the overlapping interval [x2 , x4 ]. Let this
criterion take the form of a positive score. Having ﬁrst selected, say, [x1 , x3 ] for bisection, the
greedy algorithm now has three intervals [x1 , x2 ], [x2 , x3 ], [x3 , x5 ], each equipped with a score.
It next proceeds to bisect the interval with the highest score of these three.
This leads us to the recursion point of a set {Ik } of non-overlapping intervals that partition
the original interval I0 , each equipped with a positive score sk . We select the next interval to
bisect randomly with probability proportional to sk , and replace it with its two oﬀspring. This
gives us the core stochastic interval bisection scheme. Remains to determine an appropriate
score for each interval. It is worth pointing out that this is very diﬀerent from the probabilistic
bisection algorithm of [9]. The latter is concerned with search under noisy data observations,
not the use of randomness to guide search.
It is tempting to generalize an interval to an n-dimensional box. Such a hyperbox, however,
has 2n corners. Bisecting it requires computing the function value in half of these corners. We
use hyperboxes for other purposes; a better generalization of an interval is to a hyper-triangle,
aka a simplex, with only n + 1 corners. Bisecting it only requires calculating the function value
in one new point. To avoid some simplex-method problems [2], pp. 237–239, we select the
bisection point at random, approximately in the middle of the longest edge of the simplex.
Assembling these ideas, we arrive at the core stochastic simplex bisection algorithm.
Algorithm
Given a set {Tk } of non-overlapping simplexes that partition the original simplex
T0 , each with a positive score sk .
sk
Select the next simplex Tk to bisect at random with probability
.
k sk
Select a bisection point at random roughly in the middle of the longest edge of Tk .
Replace Tk with its two oﬀspring.
Note that this requires an eﬃcient way of stochastic selection that allows adding and deleting
scored elements. A version of binary trees accomplishes this. This algorithm is complete in the
sense that no portion of the search space is ever discarded, and it avoids redundancy by using
non-overlapping simplexes. These are two common pitfalls of stochastic optimization. The
algorithm still reaps the beneﬁts of stochastic search in exploring more promising areas earlier,
in average, while granting also less promising areas a non-zero chance of being explored.
It is often desirable to start from a hyperbox. For example, constraints often take the form
of bounds on the individual variables of each dimension. We will in fact want to restart the
bisection algorithm repeatedly from a hyperbox created in a previous iteration. We thus use an
outer loop over epochs that maintains a hyperbox, and an inner loop over rounds that performs
stochastic simplex bisection proper. Although partitioning a hyperbox into a set of simplexes
is trivial in two dimensions, it is a challenging task in higher ones, see [10] and [7].

2

Outer Loop: Maintaining a Hyperbox

The investigated algorithm consists of two nested loops. The outer loop over epochs maintains a
hyperbox. Each epoch runs the inner loop over rounds, where each round consists of one simplex
bisection, see Section 3. The hyperbox is modiﬁed after each epoch. If the elapsed epoch had
856

The Stochastic Simplex Bisection Algorithm

Samuelsson

enough best points,1 this is a hyperbox that contains all best points and the very best point
as interior points. Otherwise, the previous hyperbox is doubled in size and re-centered around
the current very best point, which may have changed during the epoch.
A best point is any point found during the second phase of an epoch that is the best this far
in that epoch. The best points thus start over each epoch. The very best point , on the other
hand, is the globally best point found in any round of any epoch.
The ﬁrst phase of each epoch consists of the ﬁrst quarter of its rounds. The rest of its
rounds constitute the second phase. Other choices than one quarter were tested, but found less
eﬀective, albeit one third only marginally so. Typical ﬁgures are 60 epochs of 500 rounds each,
but this can be varied with the search conditions, cf. Section 5. Higher dimensions require more
rounds; fewer function evaluations entail fewer epochs and much fewer rounds.
The outer loop is admittedly somewhat ad-hoc. It captures the idea, that if there has been
non-trivial local improvements, search should focus on these improvements, yet also consider the
globally best point found. It turns out that the simple scheme of updating the lower and higher
bounds of the hyperbox in each dimension, for each new best point, works well in practice.

3

Inner Loop: Bisecting Simplexes

The inner loop over rounds bisects simplexes. Each bisection replaces one simplex with two new
ones. In the ﬁrst phase, the simplexes are processed as a ﬁrst-in-ﬁrst-out queue to create an
initial grid. In the second phase, the next simplex to bisect is selected randomly with probability
sk
k sk
where sk is the score of the kth simplex. Indexing the K simplexes in a binary tree yields
O(log 2 K) time complexity, whereas naively using a list swells this to O(K).
(1)
(n+1)
We now venture to deﬁne the simplex scores sk . Let {Tk = xk , . . . , xk
} be a collection
of n-dimensional simplexes with (dropping the index k for clarity),
¯ =
x

1
n+1

n+1

x(i)

;

n+1

1
n+2

f¯ =

i=1

f (¯
x) +

f x(i)

i=1

¯ is the midpoint and f¯ is the average function value over the corners and the midpoint.
where x
f−

= min f (¯
x), min f x(i)

f

= f− − δ =

δ =

f

← max 0, f − fvb

i

5f − − f¯
4

;

f¯ − f −
4

;

f is a combined measure of the lowest function value f − and an estimate δ of how much it
might potentially decrease, judging by the average value f¯. We make f oﬀset-invariant by
subtracting the lowest function value fvb , in the very best point, then cap it to be at least zero.
s =

l · exp (−λf )

;

l = max x(i) − x(j)
ij

;

λ = λ0 · max 1,

1
fw − fvb

The simplex’s score is l · exp(−λf ), where l is the length of its longest edge. λ is λ0 times the
reciprocal of the diﬀerence between the highest function value fw of the corners of the bounding
1 The

terms best point, very best point, and epoch phases will be deﬁned shortly.

857

The Stochastic Simplex Bisection Algorithm

Samuelsson

box and the lowest function value fvb . This renders the score scale-invariant. λλ0 is capped to
be at least one; λ0 defaults to one. Thus, all simplexes must be rescored whenever a new very
best point is found. As this happens rather seldom, it incurs very little overhead in practice.
Each round only creates two new simplexes: the longest edge of the selected simplex is
bisected. All corners remain the same, save one of the two connected by this edge. Let these
¯ —the new corner—is also randomized:
corners be x(i) and x(j) . The edge bisection point x
¯ = (0.5 + θ)x(i) + (0.5 − θ)x(j)
x

for

θ ∼ U(−α, α)

¯ replaces x(i) in one oﬀspring
An empirically good choice is α = 0.05 (max 10% randomness). x
(j)
simplex and x in the other one. Thus only three new function values need be calculated for
each bisection: f (¯
x ) and the function values of the midpoints of the two new simplexes.

4

Related Work

The proposed algorithm uses a typical stochastic optimization scheme. It maintains a set of
elements, each with a positive score; randomly selects some elements based on the scores; uses
these elements to explore the search space, often creating new elements in the process; and
updates the set of elements and their scores according to the ﬁndings. The scheme is however
here applied to regions of the search space, not to points in it, as in, e.g., [4, 8, 12, 17, 19, 21, 24].
The simplex method [2], Chap. 9, doesn’t actually use simplexes. To create new points,
controlled random search [12] generates random simplexes. These may overlap and are not
guaranteed to cover the search space. Nor are they subdivided. Direct [11] uses hyperboxes
that partition the search space. It avoids the 2n complexity by directional search from their
midpoints, ignoring their corners. Each hyperbox potentially containing the global minimum is
trisected, rather than bisected, along each dimension in turn. There is no randomized selection.

5

Experiments

In a ﬁrst set of experiments, we tested how good our algorithm was at ﬁnding the global
minimum, given suﬃcient search resources. In a second set of experiments, the same set-up
was applied without modiﬁcation to logistic regression. In a third set of experiments, we tested
how well the algorithm did given strict limitations on the number of function evaluations.

5.1

The needle in the haystack

Figure 1 shows the one-dimensional objective function
f (x) =

ln(1 + x2 )
sin( 1 + x2 ) · cos(2x(x + 1)) · √
1 + x2

The algorithm ﬁnds the global minimum, indicated in Figure 1 by the red circle at f (4.54) =
−0.66, two thirds of the time for intervals of length two million, given a budget of 300 000 = 3·105
function evaluations, within a fraction of a second. Success is deﬁned as any argument with a
function value within 10−14 of the minimal value, as this is the rounding error of 1.0 − 1.0. For
this objective function, it limits success to the immediate neighborhood of the global minimum.
We then tested the following n-dimensional extension of the objective function for n = 2.
n

f (x) =

f (x1 , . . . , xn ) =
k=1

858

k

f

xi
i=1

The Stochastic Simplex Bisection Algorithm

Samuelsson



























Figure 1: A one-dimensional objective function

The algorithm found one of the twin global minima (due to symmetry in x and x + y) over 40
percent of the time for boxes with sides of length two million, given a budget of ten million
(107 ) function evaluations, in 16 seconds, see Table 1, row three, column six.
We tested all two-dimensional objective functions of Figure 3 (last page), most of which
emanate from [23]. Function 0 is of our own design and function 20 is due to [16]. All functions
have unique global minima, except function 0, cf. above, and functions 12, 14, and 17, which
have four global minima, due to symmetry in ±x, ±y. Functions 16 and 17 were corrected using
[5]. Success was deﬁned as ﬁnding a point with a function value within 10−14 of the known
global minimal value. Due to rounding errors, this is the strictest reasonable requirement.
In Table 1, the ﬁrst column is the test objective function number. The second through
fourth ones indicate the success rate when searching the range [−80, 120] × [−80, 120] with a
budget of 5 · 104 , 105 , and 106 function evaluations respectively. Since many objective functions
have optima in x = 0, we made the range asymmetric. The ﬁfth and sixth column indicate
the success rate when searching the range [−106 , 106 ] × [−106 , 106 ] with a budget of 106 and
107 function evaluations respectively. For such a large range, randomized bisection avoids the
vicinity of x = 0. The ﬁrst experiment (column two) used 60 epochs with 276 rounds and
the second experiment (column three) used 40 epochs with 832 rounds. The third and fourth
experiments (columns four and ﬁve) used 40 epochs and 8332 rounds, and the ﬁfth experiment
(column six) used 40 epochs and 83332 rounds.
Functions 2–6, 8, 10, and 18 are essentially quadratic, and easily handled, as is function 9,
which is quadratic with some trigonometric ripples. For function 1 it is essential to start close
enough the minimum x = 0, to avoid getting lost on the vast, desolate high plateau of f (x) ≈ 20.
A similar analysis applies to function 11 for x = (π, π)T and f (x) ≈ 0. Objective function 7
is the least successful, and is thus the most interesting. It has a concave, gently sloping valley
that tricks the outer loop of the algorithm into local search away from the global optimum. The
(constrained) minimum of function 13 lies in (512, 414.2319)T , outside [−80, 120] × [−80, 120].
Function 20 shows that increasing the number of rounds does not necessarily help.
Squaring function 7, stretching phase one of each epoch to the ﬁrst third of the rounds,
increasing the minimum number of best points from one to three, redeﬁning success as a deviation from the minimum function value of less than 10−6 , and using 80 epochs and 83332 rounds,
859

The Stochastic Simplex Bisection Algorithm

10−14
rounds
fcn 00
fcn 01
fcn 02
fcn 03
fcn 04
fcn 05
fcn 06
fcn 07
fcn 08
fcn 09
fcn 10
fcn 11
fcn 12
fcn 13
fcn 14
fcn 16
fcn 17
fcn 18
fcn 20

[−80, 120]2
5 · 104 105 106
113 187 341
897 980 997
998 997 999
764 832 959
947 925 993
722 705 950
734 983 998
0
0
0
995 995 999
954 988 996
850 932 999
976 981 999
971 989 994
0
0
0
970 939 970
920 925 964
941 943 975
989 992 997
645 706 499

Samuelsson

[−106 , 106 ]2
106
107
264
415
15
106
1000 1000
390
728
458
568
804
862
993
999
0
0
477
546
957
961
773
924
0
0
336
913
171
511
0
367
820
818
721
747
1000 1000
848
849

20·1665
100
550
990
646
730
692
923
0
962
950
953
939
859
0
635
860
710
959
543

[−80, 120]2
40·832 60·554 80·415
187
200
170
980
969
913
997
1000
999
832
877
907
925
955
968
705
693
703
983
988
993
0
0
0
995
999
1000
988
977
929
932
902
858
981
983
981
989
978
973
0
0
0
939
980
994
925
932
926
943
951
938
992
999
999
706
679
708

160·207
210
931
1000
978
978
803
863
0
1000
970
896
994
984
0
1000
927
955
983
596

Table 1: Success rate in 1000 trials
i.e., 2 · 107 function evaluations, yields a success rate of 75 percent. The algorithm then had no
problem locating the minimum in (−10, 1)T approximately, only with pinpointing it exactly.
The algorithm scales well with the search space, which is 108 times larger for columns ﬁve
and six, doubtlessly due to the simplex scores. The exceptions are the vast, desolate high
plateaus of functions 1 and 11. Note the remarkable improvements for functions 12–14 by an
increase of a mere factor of ten in the number of rounds from column ﬁve to column six.
Columns seven through eleven revisit the second experiment on the range [−80, 120] ×
[−80, 120] with a budget of 105 function evaluations. Column seven used half as many epochs
(20) and twice as many rounds (1665); column ten, conversely, used 80 epochs and 415 rounds.
Column eight repeats column three, with 40 epochs and 832 rounds; column nine used 60
epochs and 554 rounds; and column eleven used 160 epochs and 207 rounds. Moving from
column seven to column eight shows essentially universal improvement. Apart from that, these
results indicate that the epoch/round tradeoﬀ can be tuned for function 3, and possibly for
functions 4,10,14, and 20: any individual diﬀerence of up to 50 trials is attributable to chance.

5.2

Logistic regression

Considering how well the algorithm handles quadratic functions, we applied it to a simple case
of non-linear regression, namely to logistic regression, with and without iterative reweighting.
The task consisted in ﬁtting a sigmoid function to a set of 175 argument-values pairs (xi , yi )
from a cosine-distance classiﬁer used by one of our spoken language processing applications [1].
y
p(x)
860

∼ Bernoulli(p(x))

xi ∈ [0, 1] ; yi ∈ {0, 1}
1
= p(x; θ0 , θ1 ) =
1 + exp(−θ1 x + θ0 )
;

The Stochastic Simplex Bisection Algorithm

Samuelsson


	


	







	







	























Figure 2: Logistic regression with and without iterative reweighting

The corresponding minimization problem is
argmin Δ2 (θ0 , θ1 ) ≡

argmin

θ0 ,θ1

di = di (θ0 , θ1 ) =

θ0 ,θ1

i

w(d2i (θ0 , θ1 )) · d2i (θ0 , θ1 )
2
i w(di (θ0 , θ1 ))

d(xi , yi ; θ0 , θ1 ) ≡ yi − p(xi ; θ0 , θ1 )

Deploying the set-up of our ﬁrst experiment proved faster than starting R or Matlab. To achieve
Student’s t distributions with r degrees of freedom for the data errors di , we use the weights
w(d2i )

1

=
1+

2
1 di
r Δ2

with r = 50, see, e.g., [15], pp. 104–105. This requires iteration over the data points (xi , yi ), as
the weights depend on Δ2 (θ0 , θ1 ), but convergence has been proven geometric and it requires
no extra function evaluation. This yields the steeper curve in Figure 2, which is our preferred
ﬁt. Setting w(d2i ) ≡ 1, which assumes Gaussian distributions for di , yields the other curve.

5.3

Frugal function evaluation

The ﬁnal set of experiments explored the scenario where computing function values comes at a
premium, and restricted the number of function evaluations to a few thousand. The range was
again [−80, 120] × [−80, 120]. As in [5], success was here deﬁned as ﬁnding any argument with
a function value within 10−6 of the known global minimal value.
λ0 was increased from one to ten to prioritize exploitation over exploration. The ﬁrst phase
of each epoch consisted of the ﬁrst ﬁve of its 50 rounds in total, i.e., the ﬁrst tenth, rather than
the ﬁrst quarter. The number of epochs was determined by the budget on function evaluations:
once there were none left, the algorithm terminated.
Function values were reused in two distinct ways. Firstly, bisection points were reused
for other simplexes, whenever bisecting the same edge. Secondly, midpoint function values
were approximated with the closest previously evaluated point, if one was available within a
861

The Stochastic Simplex Bisection Algorithm

Evals
|error| < 10−6 on
Fcn 00 01 02 03 04 05 06 08
1000 1 91 640
0 12 17 97 150
2000 5 700 962 10 248 292 448 582
3000 11 820 986 82 505 638 638 768
4000 22 852 992 180 581 715 733 857

Samuelsson

[−80, 120] × [−80, 120]
09 10 11 12 14
346 184 84 77 64
760 627 355 361 403
845 791 506 560 610
886 807 607 689 641

16
619
707
766
771

17
119
467
665
713

18 20
349 57
837 197
916 294
913 279

Table 2: Success rate in 1000 trials
lm
(Euclidean) distance of 2(n+1)
= lm
6 from the midpoint, where lm is the length of the shortest
1
edge of the simplex. The distance from the base to the midpoint is n+1
of the height.
Table 2 shows the success rate in 1000 trials with hard limits of 1000, 2000, 3000, and
4000 function evaluations in rows three through six, respectively. We omit functions 7 and
13. The former is too hard, the latter has its (constrained) minimum in (512, 414.2319)T ,
outside [−80, 120] × [−80, 120]. For 1000 evaluations (row three), the algorithm is useful only
for functions 2 and 16; for 2000 evaluations, the algorithm works well for about half of the test
functions; and for 3000 and 4000 evaluations, it only has problems with functions 0, 3, and 20.
As a comparison, on a diﬀerent but similar test set, [5] reports success rates for a variety
of algorithms: [4, 8, 11, 12, 14, 17, 18, 19, 21, 24]. The better ones perform in the range 50–60
percent, averaged over the test set; the two best ones, [14] and [4], at 79 and 68 percent.

6

Conclusion

We proposed the stochastic simplex bisection algorithm. It randomly selects one from a set of
simplexes, bisects it, and replaces it with its two oﬀspring. The selection probability is proportional to a score indicating how promising the simplex is to bisect. We generalized intervals to
simplexes, rather than to hyperboxes, as bisection then only requires evaluating the function
in one new point, which is somewhat randomized. Using a set of simplexes that partition the
search space yields completeness and avoids redundancy. We provided an appropriate scaleand oﬀset-invariant score deﬁnition and added an outer loop for handling hyperboxes.
The algorithm thus employs a common stochastic optimization scheme, but unlike other
stochastic approaches, it applies the scheme to search space regions, rather than to individual
points. It diﬀers signiﬁcantly from Direct, which is a non-stochastic region-based approach.
Our experiments showed that the resulting algorithm is capable of ﬁnding a needle in a
haystack, i.e., exploring vast numbers of local optima, over huge ranges, yet ﬁnding the global
one. The outer loop can be mislead into premature local search away from the global optimum,
but this can be countered by adjusting the search parameters. The ease with which it handles
quadratic functions makes it ideal for complicated non-linear regression, of which logistic regression is a simple example to which it was successfully applied. The algorithm does well, also
when the number of function evaluations is severely restricted.

Acknowledgment
The author would like to thank Jan Alexandersson, Dietrich Klakow, and the anonymous reviewers for useful comments on previous versions of this article. This work was funded by
BAULT, a multidisciplinary research community at the University of Helsinki, and METALOGUE, a Seventh Framework Programme collaborative project funded by the European Commission, grant agreement number 611073 (http://www.metalogue.eu).
862

The Stochastic Simplex Bisection Algorithm

Samuelsson

References
[1] J. Alexandersson, M. Aretoulaki, N. Campbell, M. Gardner, A. Girenko, D. Klakow, D. Koryzis,
V. Petukhova, M. Specht, D. Spiliotopoulos, et al. Metalogue: A multiperspective multimodal
dialogue system with metacognitive abilities for highly adaptive and ﬂexible dialogue management.
In Procs. Intelligent Environments, pages 365–368. IEEE, 2014.
[2] Niclas Andr´eassson, Anton Egrafov, and Michael Patriksson. An Introduction to Continuous
Optimization. Studentlitteratur, 2005.
[3] Marco Dorigo, Vittorio Maniezzo, and Alberto Colorni. The ant system: Optimization by a colony
of cooperating agents. IEEE Trans. on Systems, Man, and Cybernetics, 26(1):29–41, 1996.
[4] Qingyun Duan, Soroosh Sorooshian, and Vijai Gupta. Eﬀective and eﬃcient global optimization
for conceptual rainfall-runoﬀ models. Water resources research, 28(4):1015–1031, 1992.
[5] Andrea
Gavana.
Global
optimization
benchmarks
and
AMPGO.
http://inﬁnity77.net/global optimization, 2015. Accessed: 2015-01-09.
[6] David E. Goldberg and John H. Holland. Genetic algorithms and machine learning. Machine
Learning, 3(2-3):95–99, 1988.
[7] Mark Haiman. A simple and relatively eﬃcient triangulation of the n-cube. Discrete & Computational Geometry, 6(1):287–289, 1991.
[8] N. Hansen and S. Kern. Evaluating the CMA evolution strategy on multimodal test functions. In
X. Yao et al., editors, Parallel Problem Solving from Nature VIII, pages 282–291. Springer, 2004.
[9] M. Horstein. Sequential transmission using noiseless feedback. IEEE Trans. Inf. Theor., 9(3):136–
143, September 1963.
[10] Robert B. Hughes and Michael R. Anderson. Simplexity of the cube. Discrete Mathematics,
158(13):99 – 150, 1996.
[11] D. R. Jones, C. D. Perttunen, and B. E. Stuckman. Lipschitzian optimization without the Lipschitz
constant. J. Optim. Theory Appl., 79(1):157–181, October 1993.
[12] P. Kaelo and M. M. Ali. Some variants of the controlled random search algorithm for global
optimization. J. Optim. Theory Appl, 130(2):253–264, 2006.
[13] James Kennedy and Russell Eberhart. Particle swarm optimization, 1995.
[14] Leon Lasdon, Abraham Duarte, Fred Glover, Manuel Laguna, and Rafael Mart´ı. Adaptive memory
programming for constrained global optimization. Comput. Oper. Res., 37(8):1500–1509, 2010.
[15] Riccardo A. Maronna, Douglas Martin, and Victor J. Yohai. Robust Statistics. Wiley, 2008.
[16] Katharine Mullen, David Ardia, David Gil, Donald Windover, and James Cline. DEoptim: An R
package for global optimization by diﬀerential evolution. J. of Stat. Software, 40(6):1–26, 2011.
[17] Kenneth V. Price, Rainer M. Storn, and Jouni A. Lampinen. Diﬀerential Evolution - A Practical
Approach to Global Optimization. Natural Computing. Springer-Verlag, 2006. ISBN 540209506.
[18] A. H. G. Rinnooy Kan and G. T. Timmer. Stochastic global optimization methods. Part 1 and 2.
Math. Program., 39(1):27–78, October 1987.
[19] scipy.
scipy.optimize.anneal.
http://docs.scipy.org/doc/scipy/reference/generated/
scipy.optimize.anneal.html, 2014. Accessed: 2015-01-11.
[20] Kenneth S¨
orensen. Metaheuristics—the metaphor exposed. International Transactions in Operational Research, 22(1):3–18, 2015.
[21] A. Ismael Vaz and Lu´ıs N. Vicente. A particle swarm pattern search method for bound constrained
global optimization. J. of Global Optimization, 39(2):197–219, October 2007.
[22] Mattias Wahde. Biologically Inspired Optimization Algorithms. WIT Press, 2008.
[23] Wikipedia.
Test
functions for optimization.
http://en.wikipedia.org/wiki/
Test functions for optimization.html, 2014. Accessed: 2014-12-14.
[24] Xin-She Yang. Fireﬂy algorithms for multimodal optimization. In Procs. 5th Int.’l Conf. Stochastic
Algorithms: Foundations and Applications, SAGA’09, pages 169–178. Springer-Verlag, 2009.

863

The Stochastic Simplex Bisection Algorithm

Samuelsson

n

f (x) =

f (x1 , . . . , xn ) =

k

(0)

ln(1 + x2 )
f0 (x) = sin( 1 + x2 ) · cos(2x(x + 1)) · √
1 + x2
⎛
⎛
⎞⎞
n
n
1
1
20 ⎝1 − exp ⎝−0.2
x2i ⎠⎠ + e − exp
cos(2πxi )
n i=1
n i=1
n

f (x) =

with

i=1

k=1

f (x) =

xi

f0

f (x1 , . . . , xn ) =

x2i

(1)

(2)

k=1
n−1

f (x) =

f (x1 , . . . , xn ) =

100 · (xi+1 − x2i )2 + (xi − 1)2

(3)

k=1

f (x, y) =
f (x, y) =

(1.5 − x + xy)2 + (2.25 − x + xy 2 )2 + (2.625 − x + xy 3 )2
1 + (x + y + 1)2 (19 − 14x + 3x2 − 14y + 6xy + 3y 2 ) ·

(4)
(5)

· 30 + (2x − 3y)2 (18 − 32x + 12x2 + 48y − 36xy + 27y 2)
f (x, y) =

(x + 2y − 7)2 + (2x + y − 5)2

(6)

f (x, y) =
f (x, y) =

0.01x2 |

100 |y −
+ 0.01|x + 10|
2
2
0.26(x + y ) − 0.48xy

(7)
(8)

f (x, y) =

sin2 (3πx) + (x − 1)2 1 + sin2 (3πy) + (y − 1)2 1 + sin2 (2πx)

(9)

f (x, y) =
f (x, y) =

6

x
+ xy + y 2
6
− cos(x) cos(y) exp −(x − π)2 − (y − π)2

2x2 − 1.05x4 +

f (x, y) =

−0.0001 | sin(x) sin(y)| exp

f (x, y) =

−(y + 47) sin

f (x, y) =

−| sin(x) sin(y)| exp

f (x, y) =
f (x, y) =
f (x) =

100 −

x
+ y + 47
2
for –512 ≤ x, y ≤ 512
1−

(10)
(11)

x2 + y 2
π

− x sin

x2 + y 2
π

sin2 (x2 − y 2 ) − 0.5
1 + 0.001(x2 + y 2 )2
cos2 (sin(x2 − y 2 )) − 0.5
0.5 +
1 + 0.001(x2 + y 2 )2
1
2

n−1

+1

|y + 47 − x|

0.5 +

f (x1 , . . . , xn ) =

0.1

x4i − 16x2i + 5xi

(12)
(13)

(14)
(16)
(17)
(18)

k=1
n

f (x) =

x2i + 10 · (1 − cos 2πxi )

f (x1 , . . . , xn ) =
k=1

Figure 3: List of objective functions
864

(20)

