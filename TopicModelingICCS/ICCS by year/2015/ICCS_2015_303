Procedia Computer Science
Volume 51, 2015, Pages 1188–1197
ICCS 2015 International Conference On Computational Science

Statistical Inversion of Absolute Permeability in
Single-Phase Darcy Flow
Thilo Strauss1 , Xiaolin Fan2 , Shuyu Sun2 , and Tauﬁquar Khan1∗
1

2

Department of Mathematical Sciences, Clemson University, Clemson, USA
Division of Physical Sciences and Engineering, King Abdullah University of Science and Technology
(KAUST), Thuwal, Kingdom of Saudi Arabia

Abstract
In this paper, we formulate the permeability inverse problem in the Bayesian framework using
total variation (TV) and p (0 < p ≤ 2) regularization prior. We use the Markov Chain Monte
Carlo (MCMC) method for sampling the posterior distribution to solve the ill-posed inverse
problem. We present simulations to estimate the distribution for each pixel for the image
reconstruction of the absolute permeability.
Keywords: Statistical inversion, Single-phase Darcy ﬂow, Markov chain Monte Carlo method,
Metropolis-Hastings

1

Introduction

Subsurface ﬂow models in oil reservoir, underground aquifers, carbon dioxide sequestration are
broadly employed to predict the ﬂuid ﬂow in the porous media [20, 5, 17, 16, 18, 19, 7]. Combination of Darcy’s law and continuity equation is mostly used to describe the physics and
dynamics of ﬂuid in the porous media. Within these equations, several parameters should be
given before running the model to obtain the solution. The most important one among them is
the absolute permeability characterizing the penetrating ability for ﬂuid in the porous media.
It is not realistic to measure the value of the absolute permeability in the interior of the porous
media of interest. Therefore researchers use inverse methods to estimate the value of the absolute permeability from the boundary measurements. There exists numerous approaches to solve
the inverse problem for the single-phase Darcy ﬂow for example using Levenberg-Marquardt
[12], iterative Gauss-Newton [1] etc. The above mentioned studies focus on deterministic inversion. An alternative approach, the statistical inversion methods for example in electrical
impedance tomography [14], can shed interesting insights into the reconstructions. In [2] some
results on the uncertainty quantiﬁcation of MCMC based image reconstruction has been investigated. Statistically, the sparsity regularization amounts to enforcing p prior on the expansion
∗ Corresponding

1188

Author

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.291

Statistical Inversion of Absolute Permeability

Strauss, Fan, Sun, and Khan

coeﬃcients in a certain basis similar to the deterministic approach [13]. In this paper, we investigate a statistical approach where we consider both TV and p (1 ≤ p ≤ 2) prior as well
as non-convex p (0 < p < 1) priors. Furthermore, we use a fast algorithm to compute the
solution using a special type of a Metropolis Hasting algorithm.

2

Mathematical Model

The modeling mathematical system consists of continuity equations and Darcy’s law, and
boundary conditions.

2.1

Darcy’s law for incompressible single-phase ﬂow in porous media

Let Ω ⊆ R2 be an open and bounded set with C 1 smooth boundary denoted by ∂Ω. Darcy’s
law relates the Darcy velocity to the driven force including the pressure and gravity by
u = −K∇p, K =

kg
kgρ
=
in Ω
μ
η

(1)

where u, k, μ, ρ, g, η, represents the Darcy velocity, kinematic viscosity of ﬂuid, density of
ﬂuid, gravitational constant and dynamic viscosity of ﬂuid, respectively, and K represents the
absolute permeability. In this paper, we formulate a statistical inverse problem to estimate the
absolute permeability K.

2.2

Mass conservation for incompressible single-phase ﬂow in porous
media

The ﬂuid is assumed to ﬂow continuously, which leads to the mass conservation of ﬂuid and is
described by the following mass conservation equation
∂ρφ
+ ∇ · (ρu) = qm in Ω
∂t

(2)

where qm is mass source term (is positive when the media is injected into ﬂuid) or sink term
(is negative when the ﬂuid is extracted out from the media). In this work, we assume the
ﬂuid to be incompressible here. As a result, Equation (2) leads to the following volumetric
conservation equation
∇ · u = q in Ω

(3)

where q = qρm and ∂Ω = Γ = ΓD ΓN (ΓD ,ΓN stand for the Dirichlet boundary and Neumann
portion of the boundary respectively). The boundary conditions are given as follows:
p =
u·n =

pB on ΓD
uB , on ΓN

(4)
(5)

where pB and uB are the pressure on Dirichlet boundary and the normal component of velocity on Neumann boundary respectively, and n is the outward normal unit vector towards on
boundary.
In the forward model, the unknowns p, u can be solved using Equation (1) - Equation (5)
given the permeability, viscosity, density. In the subsequent section we provide a numerical
algorithm to solve the model.
1189

Statistical Inversion of Absolute Permeability

3

Strauss, Fan, Sun, and Khan

Mixed Finite Element Methods For The Forward Model

Mixed Finite Element (MFE) method is one of many ﬁnite element methods which solves Darcys
law and conservation equation to gain the scalar variable and ﬂux vector simultaneously.
The reason for using MFE method to solve the forward ﬂow model is that MFE can meet
the following three excellent properties: local mass conservation, ﬂux continuity, and the same
convergence order for both the scalar variable and the ﬂux. We ﬁrstly introduce some notations.
Denote (·, ·) the L2 (Ω) inner product over a domain for scalar functions and (L2 (Ω))2 inner
product for vector functions. Let us denote the following spaces by
V

=

L2 (Ω), W = H(div; Ω) = w ∈ (L2 (Ω))2 : ∇ · w ∈ L2 (Ω)

W0

=

0
{w ∈ H(div; Ω), w · n = 0 on ∂Ω} , WN
= {w ∈ H(div; Ω), w · n = 0 on ∂ΩN } .

Using these notations weak formulations for the ﬂow model will be given in the subsections
below followed by the MFE scheme for the ﬂow model.

3.1

Weak formulation

0
The weak formulation is to seek p ∈ V and u ∈ WN
+ E(uB ) such that

K −1 u, w − (∇ · w, p)

=

(∇ · u, v)

=

−

ΓD

0
pB w · nds for all w ∈ WN

(q, v) for all v ∈ V

(6)
(7)

where E(uB ) denotes a velocity extension such that E(uB ) · n = uB on ΓN .

3.2

MFE scheme

Generally, RT (Raviart-Thomas) ﬁnite element space is employed to approach the Darcy velocity. The r-th order RT space for the two-dimensional rectangular element is deﬁned by
Vh (T ) = Pr (T ), Wh (T ) = (x1 Pr (T ), x2 Pr (T )) ⊕ (Pr (T ))2

(8)

where ⊕ stands for the direct sum. r = 0 in our scheme is adopted in here. Accordingly, Wh (T )
is given by
Wh (T ) = {w : w = (aT + bT x1 , cT + bT x2 ), aT , bT , cT ∈ R}

(9)

Restricted to an element T , Pr (T ) is the polynomial space of degree less than or equal to
r. Consequently the MFE method for approximating the weak formulation is to search for
0
= W0 + EuB such that
ph (·, ·) ∈ Vh and uh ∈ WN
K −1 uh , w − (∇ · w, ph )

=

(∇ · uh , v)

=

−

ΓD

pB w · nds for all w ∈ Wh

(qh , v) for all v ∈ Vh

(10)
(11)

MFE formulation causes a saddle point problem for the elliptic equations, the solution strategy
is to use the Mixed-Hybrid algorithms for the pressure equation.
We consider a single rectangular element T . By RT0 space, uh in Equation (11) can be
formulated as
uh =

uT,E wT,E
E∈∂T

1190

(12)

Statistical Inversion of Absolute Permeability

Strauss, Fan, Sun, and Khan

where wT,E is a shape function of RT0 and uT,E is the total ﬂux across an edge E of element
T . Taking wT,E as the test function w, the total ﬂux is computed by
AT UT = pT e − PT E

(13)

UT = A−1
T (pT e − PT E )

(14)

and from Equation (13), we have

where AT = [(AT )E,E ∈∂T ], (AT )E,E ) = T wT,E K −1 wT,E dT , UT = [(UT )E∈∂T ], e = [1]E∈∂T ,
PT,E = [pT,E ]. Hence, the ﬂows uT,E in Equation (13) passing through each edge is computed
through a function of the element pressure average and edge average pressure. For simplicity,
we reformulate the equation
uT,E = aT,E pT −

bT,E,E pT,E

(15)

E ∈∂T

where aT,E = E ∈∂T A−1
, bT,E,E = A−1
.
T
T
E,E
E,E
For the second Equation of (11) and combining Equation (12), we obtain
BT UT = 0

(16)

where BT = (BT )T,E , (BT )T,E = T ∇ · wT,E dT, (wT = 1).
Substituting Equation (14) into Equation (16) gives
−1
BT A−1
T pT e − BT AT PT,E = 0

(17)

−1
BT A−1
pT = (BT A−1
T e)
T PT,E .

(18)

and therefore

The continuity of the ﬂux across the inter-element boundaries, uT,E leads to
uT,E =

T
uN
E,E = T
−uT,E , E ∈ ΓN

(19)

Finally, by using Equations (13), (18), and (19), an algebraic linear system of PE is given as
follows,
A S PE = J

(20)

−1
BT A−1
where AS = DS F − G, D = [aT,E ]NT ,NE , E ∈ ∂T , F = [(BT A−1
T e)
T ]NT , G =
[ E,E∈∂T bT,E,E ]NE ,NE , E ∈ ΓD , and NT and NE represent the number of elements and
the number of edges not on ΓD in the mesh, respectively. J is a vector of size NE from
boundary conditions.

4

The Inverse Problem

In the previous sections we saw how to ﬁnd the measurements Υ = (u·n, p) on the boundary ∂Ω
for a given permeability K in a porous media Ω. The inverse problem is to ﬁnd the permeability
1191

Statistical Inversion of Absolute Permeability

Strauss, Fan, Sun, and Khan

K for given noisy measurements Υδ on the boundary ∂Ω. The natural parameter space for the
inverse problem is
Q = {K ∈ L∞ (Ω)|0 < Kmin ≤ K ≤ Kmax < ∞},

(21)

where Kmin , Kmax > 0 are constants. The inverse problem for the single phase Darcy ﬂow
problem in the deterministic setting for the inﬁnite dimensional case can be formulated as a
minimization problem. For example, a total variation (TV) regularization functional can be
written as follows,
Jα (K) = ||Υ(K) − Υδ ||L2 (Ω) + α||∇K||L1 (Ω) ,

(22)

where Υ(K) represents the solution on the boundary ∂Ω of the forward model and Υδ is the
noisy experimental measurement and α is is a TV regularization parameter. Hence solving the
ˆ = arg minK∈Q Jα (K).
inverse problem with this model would be equivalent of ﬁnding K
δ
ˆ
Note that Υ is a noisy measurement which implies that K won’t be the real absolute permeability of the problem, it is rather the permeability with some kind of noise. This leads
to the statistical inverse problem, which is ﬁnding the posterior density of the absolute permeability K. To simplify notation, we will denote K for the rest of this paper as the ﬁnite
dimensional random variable of the absolute permeability and its concrete values at each pixel.
Further, denote Υδ as the ﬁnite dimensional measurement. For example, the posterior density
corresponding to the previous deterministic example (22) would be
P (K|Υδ ) ∝ exp −

1
||Υ(K) − Υδ ||22 − α||∇K||
2σ 2

1

, for K ∈ Q,

(23)

where σ 2 is the variance of the measurement noise and Q = {K ∈ Rd |0 < K min ≤ K ≤ K max <
∞}. Note that exp[− 2σ1 2 ||Υ(K) − Υδ ||22 ] is proportional to a multivariate normal distribution,
which somehow implies that by using the 2 norm in the data term we assumed that Υδ has
additive independent Gaussian noise. For the rest of this paper we will assume that Υδ has
additive Gaussian noise. Hence, the data term for our problem is proportional to a multivariate
normal density
1
P (Υδ |K) ∝ exp − (Υ(K) − Υδ )T C −1 (Υ(K) − Υδ ) ,
2

(24)

where C is a positive deﬁnite covariance matrix of the measurement noise. Furthermore, we
will use the more general regularization density
P (K) ∝

exp [−αR(K)],
0,

if K ∈ Q,
else,

(25)

where R(K) is a regularization function. Concluding, the general posterior density becomes
P (K|Υδ ) ∝ P (Υδ |K)P (K).

(26)

By deﬁnition, the solution of the statistical inverse problem is the posterior density for the
absolute permeability K, but we are interested in ﬁnding the Bayes estimate E(K|Υδ ). Unfortunately, the posterior density (26) does not have a close form, which makes it impossible
to ﬁnd the Bayes estimate in a direct way. Therefore, we approximate the Bayes estimate via
simulations.
1192

Statistical Inversion of Absolute Permeability

5

Strauss, Fan, Sun, and Khan

The Markov Chain Monte Carlo Method

The idea of the MCMC method is generating a large random sample from the posterior density
P (Υδ |K), with let’s say Y samples, and then approximate the Bayes estimate by the sample
mean, e.g.
E(K|Υδ ) =
Rd

KP (K|Υδ )dK ≈

1
Y

Y

K i,

(27)

i=1

where d is the number of dimensions of K (the number of pixels) and K i represents the ith
random sample of the posterior density (26). Typical algorithms to generate such large random
samples are the Gibbs sampler or the Metropolis Hastings algorithm. In this manuscript we
will use a special type of an adaptive Metropolis algorithm. For detailed description of the
Metropolis Hastings algorithm we recommend [4].
Let our Markov chain be deﬁned on the continuous state space (E, B, M ) where B is a Borel
σ-algebra on E and M the normalized Lebesgue measure on E where Q ⊆ E ⊆ Rd Additionally,
assume ξ(x; A) is a transition kernel for K ∈ E, where A ∈ B. The transition kernel ξ(K; A)
denotes the probability of moving from a current state K to another state in the set A. We
would like to ﬁnd conditions of the transition kernel ξ(·; ·) such that it converges to an invariant
distribution π. Here π represents the distribution of the posterior density P (K|Υδ ). After some
analysis we can see that one transition kernel converging to the invariant distribution π is
q(K, K ∗ )α(K, K ∗ )dK ∗ + 1 −

ξM H (K; A) :=

Rd

A

q(K, K ∗ )α(K, K ∗ )dK ∗ χA (K),

(28)

where χA is the indicator function over the set A, q(K, K ∗ ) is a candidate-generating density,
that is, a density which generates from a current random sample K, a new candidate random
sample K ∗ . For example, q(·, ·) could be a multivariate normal density with mean K. Note
that the acceptance ratio
α(x, y) =

min

P (K ∗ |Υδ )q(K ∗ ,K)
,1
P (K|Υδ )q(K,K ∗ )

1,

,

if P (K|Υδ )q(K, K ∗ ) > 0
otherwise,

(29)

is the probability of accepting a new random sample K ∗ . Note that in case that q(·, ·) is
a symmetric density we have that q(K, K ∗ ) = q(K ∗ , K) which simpliﬁes (29). Concluding,
the idea of the Metropolis Hastings algorithm is to generate new candidates of the absolute
permeability using the proposal density q(·, ·) and then accept them as random sample of the
posterior distribution with probability α(K, K ∗ ).
It is known that the proper choice of the proposal density q(·, ·) for the Metropolis algorithm
is vital to obtain a reasonable result by simulation in a suitable amount of time. This choice is
generally very diﬃcult since the target density is generally unknown [11, 8, 10]. One possible way
of smoothing out this problem is by using an adaptive Metropolis algorithm which is iteratively
updating the proposal density in an appropriate way. The downside of this kind of adaptive
algorithm is that the chain usually becomes non-Markovian which would require to establish
the correct ergodic properties. In other words, typically adaptive algorithms iteratively change
the covariance matrix from the proposal density based on all previous samples of the chain, and
hence P (K n |K 0 , K 1 , ..., K n−1 ) = P (K n |K n−1 ).
One adaptive algorithm, proposed in [10], changes the covariance matrix of the proposal distribution at atomic times in order to maintain the Markov property of the chain. An atomic time
1193

Statistical Inversion of Absolute Permeability

Strauss, Fan, Sun, and Khan

for a continuous state space (E, B, M ) is a set A ∈ B with π(A) > 0 such that K n+1 , K n+2 , ...
is conditionally independent of K 0 , K 1 , ..., K n given that K n ∈ A. Although this method seems
very attractive at the ﬁrst view it is practically very complicated to ﬁnd proper atomic times
for high dimensional problems [10]. Another approach is to adapt the proposal distribution a
ﬁxed amount of times and starting the burn-in time after the last adaptation. This method can
not guarantee obtaining the optimal proposal distribution for the target distribution after the
last adaptation. However, it usually increases the convergence speed considerable respect to
the classical Metropolis-Hastings algorithm while still maintaining all good properties of it after
the Burn-in time. Meaning the pilot adaptive Metropolis algorithm still generates a Markov
chain after the pilot time. Another approach, introduced in [11], is to adapt the covariance
matrix of a normal proposal distribution in every iteration after an initial time t0 in such a
way that the correct ergodic properties of the chain can be established even if the chain is itself
non-Markovian. We will use a special kind of pilot adaptive Metropolis algorithm.
The idea of this algorithm is to train the proposal distribution by changing its covariance
matrix in such a way that the acceptance ratio of the chain after the last adaption is close
by the optimal acceptance ratio ao of the chain. Note that there is no analytical framework
for the choice of such a optimal acceptance ratio ao when the target distribution is unknown.
Therefore, the choice of ao is usually based on the result from [8] that for a normal target and
proposal distribution the optimal acceptance ratio is approximately .45 in the one dimensional
case and .234 when the number of dimension converges to inﬁnite.
Assume we wish to perform M adaptions, one every m iterations, where 1 < mM < B <
B + Y . Here B is the burn in time, meaning the amount of random simples which we consider
to dependent from our starting guess and therefore not real random samples from the posterior
density. Note that Y denotes the desired number of real random samples. Lets ci denote a
variable saving wether or not the ith iteration of Algorithm 1 has been accepted,
ci :=

1,
0,

i-th iteration has been accepted,
else.

(30)

1
¯j = m
The estimator for the acceptance ratio for the j-th proposal distribution is a
i=(j−1)m+1 ci .
Let 0 <
1, where 100 would be the percentage of change per adaption in the covariance
matrix C of the proposal distribution. In other words, the j-th adaption would modify the
current covariance matrix Cj−1 in the following way,
⎧
¯ j > ao ,
⎨ (1 + )Cj−1 , if a
if a
¯ j = ao ,
Cj−1 ,
(31)
Cj = ΞP AM (Cj−1 ) :=
⎩
¯ j < ao .
(1 − )Cj−1 , if a
jm

Informally speaking, the algorithm would modify the covariance matrix in the pilot time mM
in such a way that it comes closer to one which has an optimal acceptance ratio, and then starts
the standard Metropolis Hastings algorithm with the latest state and proposal distribution of
the pilot time. In Algorithm 1 we recapitulate the pilot adaptive Metropolis algorithm with an
arbitrary starting state K 0 ∈ Q and a starting guess for the positive deﬁnite covariance matrix
C0 .
When applying Algorithm 1 it is important to know that the chain only satisﬁes the Markov
property after the last adaption at time mM . Note that the chain will still move towards the
high probability areas of the target distribution during the pilot time, which usually results in
a considerable shorter Burn-in time B > mM comparing to the standard Metropolis Hastings
algorithm.
1194

Statistical Inversion of Absolute Permeability

Strauss, Fan, Sun, and Khan

Algorithm 1 A Pilot Adaptive Metropolis Algorithm.
j = 1;
for i = 1 to B+Y do
if i ≡ 0 mod m and i ≤ mM then
Cj = ΞP AM (Cj−1 );
j++;
end if
Generate K ∗ from qCj (K i−1 , ·) and u from U (0, 1);
if u ≤ α(K i−1 , K ∗ ) then
K i = K ∗;
else
K i = K i−1 ;
end if
end for
Return K 1 , K 2 , ..., K B+Y
We discussed the Metropolis-Hastings algorithm and we saw that it samples properly from
the posterior distribution only after a burn-in time B. Therefore, we are interested in knowing
how long this burn-in phase should be. Unfortunately, there is no theory giving a good estimate
of the burn-in time prior to run the Metropolis-Hastings algorithm. That leaves us to ﬁrst run
the Metropolis-Hastings algorithm and then check wether or not it converged to its stationary
distribution (Invariant distribution). There are several methods to check whether or not the
chain converged, however for all methods have a positive probability to produce give a wrong
answer. Therefore, it is recommended to use more that one diagnostic method. The most
common diagnostic methods in the literature are found in the work of Gelman and Rubin [9, 3],
Geweke [6] and Raftery and Lewis [15].

6

Regularizing Prior Density Selection

Before presenting simulations we need to explain what kind of regularizing function R(·) in (25)
we are using. A common choice for regularization in a deterministic setting is a penalty R(K)
using a p norm with 1 ≤ p ≤ 2. For statistical regularization, there is no need to assume that
R(K) be neither a norm nor a convex function, we only need it to be a continuous function.
Therefore we can write the following more general regularization:
M
s
|K i − K pr
i | ,

R1 (K) :=
i=1

where 0 < s ≤ 2, K is a prior estimate of K. In case that 0 < s < 1 this only deﬁnes a metric
but not a norm. The regularization function R1 would make K smooth and is specially eﬃcient
for reconstructions where the area diﬀerent from the background is small. Another common
choice would be the total variation prior, which is deﬁned as:
pr

R2∗ (K) = ||∇K||L1 (Ω) =

Ω

|∇K|dx.

Let R2 (K) represent the discrete analogue of R2∗ (K), for an exact formulation see [14]. This
prior makes the image of the K smooth.
1195

Statistical Inversion of Absolute Permeability

Strauss, Fan, Sun, and Khan

Figure 1. The Darcy ﬂow is from left to right. The image on the left hand side represents
the true absolute permeability on a 25×25 mesh. The image on the right hand side is a
reconstruction using algorithm 1 with a R1 ( 1 ) regularization on a 5×5 mesh. Note that
||K true −K rec ||L1
≈ 0.023 where K true is the true permeability and K rec is the reconstructed
||K true ||L1
permeability.

7

Preliminary Simulation and Conclusion

Here we simulate measurements of a single phase Darcy ﬂow (going from left to right see
Figure 1) on a 25×25 mesh for the velocity, pressure, and absolute permeability for the forward
problem and then we use algorithm 1, with the posterior density introduced in (26) and a R1
regularization, to reconstruct K on a 5×5 mesh. We note that this is a typical setup to avoid
inverse crimes mainly the data using the forward problem is generated on a diﬀerent mesh than
the mesh used for the inverse problem. In algorithm 1 we use the pilot time mM = 70, 000 with
one adaption every m = 100 iteration, we choose the Burn-in time to be B = 140, 000 and the
total number of real random sample Y = 80, 000. The starting absolute permeability K 0 has
been chosen to be constant. The starting covariance matrix C0 was proportional to a identity
matrix plus an additional covariance of .1 for every neighbor elements of the mesh. The result
of the image reconstruction can be found in Figure 1. For this particular simulation which is
low dimensional with d = 25, the computational time is in the order of minutes, however in
realistic scenario for a permeability with much higher dimension i.e. large d, the inverse problem
gets computationally very intensive. This is one of the drawbacks of the statistical approach
using MCMC based algorithms. We have also used deterministic methods in MATLAB such
as Levenberg-Marquardt or Gauss-Newton for the reconstruction of K and found that the
statistical approach provides a much better image. However, further investigation is required
for a thorough comparison. In the future, we will be performing more simulations for diﬀerent
shapes for K as well as implement the TV penalty term and explore the mixture of TV and
sparsity regularization.
We conclude that statistical inversion approach using Markov Chain Monte Carlo method
using an adaptive Metropolis-Hastings algorithm can be used to regularize the ill-posed inverse
problem of permeability reconstruction in porous media.
1196

Statistical Inversion of Absolute Permeability

Strauss, Fan, Sun, and Khan

References
[1] John Baird and Clint Dawson. The representer method for data assimilation in single-phase darcy
ﬂow in porous media. Computational Geosciences, 9(4):247–271, 2005.
[2] Johnathan M Bardsley. Mcmc-based image reconstruction with uncertainty quantiﬁcation. SIAM
Journal on Scientiﬁc Computing, 34(3):A1316–A1332, 2012.
[3] Stephen P Brooks and Andrew Gelman. General methods for monitoring convergence of iterative
simulations. Journal of computational and graphical statistics, 7(4):434–455, 1998.
[4] Siddhartha Chib and Edward Greenberg. Understanding the metropolis-hastings algorithm. The
American Statistician, 49(4):327–335, 1995.
[5] Clint Dawson, Shuyu Sun, and Mary F. Wheeler. Compatible algorithms for coupled ﬂow and
transport. Computer Methods in Applied Mechanics and Engineering, 193(2326):2565 – 2580, 2004.
[6] Salaheddine El Adlouni, Anne-Catherine Favre, and Bernard Bob´ee. Comparison of methodologies
to assess the convergence of markov chain monte carlo methods. Computational Statistics & Data
Analysis, 50(10):2685–2701, 2006.
[7] Xiaolin Fan, Shuyu Sun, Wei Wei, and Jisheng Kou. Numerical simulation of pollutant transport
in fractured vuggy porous karstic aquifers. Journal of Applied Mathematics, 2011, 2011.
[8] A Gelman, G Roberts, and W Gilks. Eﬃcient metropolis jumping rules. Bayesian statistics,
5:599–608, 1996.
[9] Andrew Gelman and Donald B Rubin. Inference from iterative simulation using multiple sequences.
Statistical science, pages 457–472, 1992.
[10] Walter R Gilks, Gareth O Roberts, and Sujit K Sahu. Adaptive markov chain monte carlo through
regeneration. Journal of the American statistical association, 93(443):1045–1054, 1998.
[11] Heikki Haario, Eero Saksman, and Johanna Tamminen. An adaptive metropolis algorithm.
Bernoulli, pages 223–242, 2001.
[12] Marco A Iglesias and Clint Dawson. The representer method for state and parameter estimation in
single-phase darcy ﬂow. Computer Methods in Applied Mechanics and Engineering, 196(45):4577–
4596, 2007.
[13] Bangti Jin, Tauﬁquar Khan, and Peter Maass. A reconstruction algorithm for electrical impedance
tomography based on sparsity regularization. International Journal for Numerical Methods in
Engineering, 89(3):337–353, 2012.
[14] Jari P Kaipio, Ville Kolehmainen, Erkki Somersalo, and Marko Vauhkonen. Statistical inversion and monte carlo sampling methods in electrical impedance tomography. Inverse problems,
16(5):1487, 2000.
[15] Adrian E Raftery and Steven M Lewis. Implementing mcmc. In Markov chain Monte Carlo in
practice, pages 115–130. Springer, 1996.
[16] Shuyu Sun. Discontinuous galerkin methods for reactive transport in porous media. 2003.
[17] Shuyu Sun and Mary F Wheeler. Discontinuous galerkin methods for coupled ﬂow and reactive
transport problems. Applied Numerical Mathematics, 52(2):273–298, 2005.
[18] Shuyu Sun and Mary F Wheeler. L2 (H 1 ) norm a posteriorierror estimation for discontinuous
galerkin approximations of reactive transport problems. Journal of Scientiﬁc Computing, 22(13):501–530, 2005.
[19] Shuyu Sun and Mary F Wheeler. Anisotropic and dynamic mesh adaptation for discontinuous
galerkin methods applied to reactive transport. Computer methods in applied mechanics and
engineering, 195(25):3382–3405, 2006.
[20] Shuyu Sun and Mary F. Wheeler. Symmetric and nonsymmetric discontinuous galerkin methods
for reactive transport in porous media. SIAM Journal on Numerical Analysis, 43(1):pp. 195–219,
2006.

1197

