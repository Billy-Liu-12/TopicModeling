Procedia Computer Science
Volume 51, 2015, Pages 2754–2758
ICCS 2015 International Conference On Computational Science

Eﬃcient BSP/CGM algorithms for the maximum
subsequence sum and related problems∗
Anderson C. Lima1 , Rodrigo G. Branco1 , Edson N. C´aceres1 ,
Roussian R. A. Gaioso2 , Samuel Ferraz1 , Siang W. Song3 , and Wellington S.
Martins2
1

Federal University of Mato Grosso do Sul, Campo Grande, Mato Grosso do Sul, Brazil
2
Federal University of Goi´
as, Goiˆ
ania, Goi´
as, Brazil
3
University of S˜
ao Paulo, S˜
ao Paulo, S˜
ao Paulo, Brazil

Abstract
Given a sequence of n numbers, with at least one positive value, the maximum subsequence
sum problem consists in ﬁnding the contiguous subsequence with the largest sum or score,
among all derived subsequences of the original sequence. Several scientiﬁc applications have
used algorithms that solve the maximum subsequence sum. Particularly in Computational
Biology, these algorithms can help in the tasks of identiﬁcation of transmembrane domains
and in the search for GC -content regions, a required activity in the operation of pathogenicity
islands location. The sequential algorithm that solves this problem has O n time complexity.
In this work we present BSP/CGM parallel algorithms to solve the maximum subsequence sum
problem and three related problems: the maximum longest subsequence sum, the maximum
shortest subsequence sum and the number of disjoints subsequences of maximum sum. To the
best of our knowledge there are no parallel BSP/CGM algorithms for these related problems.
Our algorithms use p processors and require O n/p parallel time with a constant number
of communication rounds for the algorithm of the maximum subsequence sum and O log p
communication rounds, with O n/p local computation per round, for the algorithm of the
related problems. We implemented the algorithms on a cluster of computers using MPI and on
a machine with GPU using CUDA, both with good speed-ups.
Keywords: Parallel algorithms, multicore, GPU, maximum subsequence sum problem.

1

Introduction

The maximum subsequence sum problem consists in ﬁnding the contiguous subsequence with
the largest sum or score, among all derived subsequences of an original sequence of n numbers,
∗ Authors

2754

thank CNPq, CAPES and FAPEG for ﬁnancial support and NVIDIA for equipment donations.

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.421

Eﬃcient BSP/CGM algorithms

Lima, Cceres, Branco, Gaioso, Ferraz, Song and Martins

with at least one positive number [2]. Solution of this problem arises in many areas of Science. One such area is Computational Biology, where many applications require the solution
of the maximum subsequence sum problem. Among these, the identiﬁcation of transmembrane
domains in protein sequences is an important application and represents one of the important
tasks to understand the structure of a protein or the membrane topology [7]. Another biological
application is ﬁnding regions of DNA that are rich or poor in nucleotides G and C (CG-content).
The GC-content is especially important in the operation of search for pathogenicity islands [5].
The best sequential algorithm for the maximum subsequence sum problem, due to J.
Kadane, has O(n) time complexity [2]. However, despite being a simple and fast algorithm,
it returns little information about the maximum
subsequence sum. The output returns only the
value of the maximum subsequence sum.
Previous works have reported good paralFigure 1: The value 15 is the highest and reprelel solutions for the maximum subsequence sum sents the value of maximum sum of Q.
problem. In particular, for this work, we have
used some ideas from Perumalla and Deo [6] parallel algorithm in our results. This algorithm
generates a series of arrays, whose meanings and calculations can be checked in the original
work [6]. Figure 1 illustrates an example of the output array for this algorithm.
Device
Host
In this work, we revisited the
P1
P2
P3
P4
Pn
maximum subsequence sum problem
. . .
Kernel 1 call
and propose solutions to three related
sm1 sm 2 sm n
problems: the maximum longest subsequence sum, the maximum shortKernel 2 call
. . .
est subsequence sum and the number
of disjoints subsequences of maximum
sm1 sm 2 sm n
sum. To the best of our knowledge
.
.
.
there are no parallel BSP/CGM algo.
.
.
Local computation.
rithms for these three problems. The time
.
.
.
time
Barriers of synchronization.
basis of our solutions involves several
Global communication.
Communication between the CPU and the GPU (Global memory).
variations of preﬁx sum in parallel [4].
Comunnication among treads via shared memory.
Our algorithms use p processors
Threads of different blocks can communicate through shared memory.
with O n/p parallel time and a Figure 2: Abstraction between the BSP/CGM model [3]
constant number of communication and GPGPU
rounds. In order to show the eﬃciency not only in theory but also in practice, the algorithms
were implemented on a cluster of computers using MPI and on a machine with GPU using
CUDA, both with good results. Figure 2 illustrates our suggestion for working on a GPGPU
(General Purpose Graphics Processing Unit) with CUDA using the BSP/CGM model [3] .
This paper is organized as follows: Section 2 presents the background and the related works
to this study. Section 3 presents our proposed BSP/CGM algorithms. The implementations
and results are presented in Section 4. Finally, Section 5 presents the conclusions and possible
future work.
Q

5

10

-20

15

-20

8

4

1

2

-1

PSUM

5

15

-5

10

-10

2

6

7

9

8

SSUM

4

-1

-11

9

-6

14

6

2

1

-1

SMAX

15

15

10

10

9

9

9

9

9

8

PMAX

4

4

4

9

9

14

14

14

14

14

M

15

15

10

15

14

15

15

15

15

14

( Q + Q ) = 15
1
2

( Q + Q + Q +Q ) = 15
6
7
8
9

Q = 15
4

Output Array

M

2

15

15

10

15

14

15

15

15

15

14

Background

Consider a sequence Qn = (q1 , q2 , . . . , qn ) composed of n integers, a subsequence is any contiguous segment (qi , . . . , qj ) of Qn for 1 ≤ i ≤ j ≤ n. The maximum subsequence sum problem
2755

Eﬃcient BSP/CGM algorithms

Lima, Cceres, Branco, Gaioso, Ferraz, Song and Martins

is to determine, among all possible subsequences, the subsequence M = (qi , . . . , qj ) that has the
j
maximum sum ( k=i qk ) [2]. In the sequence represented by Figure 3 there are three disjoints
subsequences of maximum sum. All have sum equal to 15, but with diﬀerent sizes.
For simplicity, without loss of generality, assume the
10
-20
15
-20
8
4
1
2
-1
Q 5
Q =15
(Q + Q ) =15
(Q + Q + Q + Q ) = 15
numbers to be integers. In a given sequence of integers,
B
A
C
as the sequence Q illustrated in Figure 3, there might be
Figure 3: The three subsequences of
more than one maximum subsequence sum. In this con- maximum sum of the sequence Q.
text, at least three new problems arise: the maximum longest subsequence sum, the maximum
shortest subsequence sum and the number of disjoints subsequences of maximum sum.
1

3

4

2

6

7

8

9

Proposed Algorithms

Although there is a BSP/CGM parallel algorithm for the 1D maximum subsequence problem,
we cannot use it to ﬁnd, directly, the shortest/longest maximum subsequences. Using the ideas
of the PRAM algorithm proposed by Perumalla and Deo [6], we devised a new BSP/CGM
parallel algorithm for this problem (see Algorithm 1) such that, using the array output, we
can compute the shortest/longest maximum subsequences and the total number of maximum
subsequences. The algorithms in steps 2, 3 and 4 are variations of the preﬁx sum. [6].
Algorithm 1 Maximum Subsequence Sum
Input: (1) A set of P processors; (2) The number i of each processor pi ∈ P , where 1 ≤ i ≤ P ; (3) Sequence Q of n integers.
Output: (1) Array M[1. . . n] of integers with all disjoints subsequences of maximum sum; (2) The maximum value in M.
PSUM ← Prefix Sum Algorithm(P , Q) in parallel.
SSUM ← Suffix Sum Algorithm(P , Q) in parallel. {Preﬁx sum operation applied on the inverse array Q.}
SMAX ← Suffix Maxima Algorithm(P , PSUM) in parallel. {Propagation of maximum values from the end to the beginning.}
PMAX ← Prefix Maxima Algorithm(P , SSUM) in parallel. {Propagation of maximum values from the beginning to the end.}
Processor p1 sends n/p elements of each array Q, PSUM, SSUM, SMAX and PMAX to each processor pi ∈ P .

1:
2:
3:
4:
5:
6:
7:
8:

Each processor pi obtains the local arrays
LocalMS ← PMAX(n/p)-SSUM(n/p)+Q(n/p)
LocalMP ← SMAX(n/p)-PSUM(n/p)+Q(n/p).
LocalM ← LocalMS(n/p)+LocalMP(n/p)-Q(n/p).
Each processor pi sends the array LocalM to processor p1 , which computes the array M :
M = [LocalMp1 , . . . , LocalMp1
] .
, . . . , LocalMpp , . . . , LocalMpp
1
1
n/p
n/p
Maximum Subsequence Sum ← Maximum Reduction Algorithm (P , M) in parallel .

The second algorithm solves the related problems. For better understanding, we chose to
present the steps of this algorithm through the Figure 4. The starting point is the output of
the Algorithm 1. In particular, our algorithms use p processors and require O n/p parallel
time with a constant number of communication rounds for the algorithm of the maximum
subsequence sum and O log p communication rounds, with O n/p local computation per
round, for the algorithm of the related problems, due to internal list ranking algorithm.
Array M of Algorithm 1
M
Applying Counting
Algorithm
3
Output: Number of
Disjoints Subsequences
of Maximum Sum = 3

BinaryLK

2

0

0

1

0

15 15 10 15 14 15 15 15 15 14

Applying Max Reduction
Algorithm
1

Applying Max Reduction Algorithm
Output: Maximum Subsequence Sum
Binary Conversion
Based on
Maximum Sum (MaxSum = 15)
4

0

0

0

1

1

0

1

0

1

1

1

1

BinaryLK 2

0

Applying List Ranking Algorithm
in Binay Array
BinaryLK

2756

Store the Longest Value = 4.

0
Binary

Figure 4:

Output: Longest Maximum
Subsequence Sum = 4

2

1

0

1

0

4

3

2

1

0

4

4

1

4

4

4

4

Applying Min Reduction
Algorithm 2
Output: Shortest Maximum
Subsequence Sum = 1

Problems that can be solved from the output array M of Algorithm 1

4

4

Eﬃcient BSP/CGM algorithms

4

Lima, Cceres, Branco, Gaioso, Ferraz, Song and Martins

Results

Below we present the results achieved by the developed algorithms. The Figures 5-7 illustrated
the cases of comparison between the versions of algorithms for the general problem of maximum
subsequence sum. The Figure 8 illustrates the case of comparison for the related problems. The
MPI version is based on the parallel BSP/CGM algorithm developed by Alves et al. [1] and
involves data compression. The CUDA versions were built from Algorithm 1.
(Sequential pure (no parallel))
(CUDA)

102

M illiseconds

M illiseconds

102

101

(Sequential pure (no parallel))
(MPI with 16 processors)
(MPI with 32 processors)
(MPI with 64 processors)

101

100
0
0

1

2

Figure 5:

1

2

3

n

3

n

·107

Sequential [2] × Parallel CUDA.

Figure 6:

Sequential [2] × Parallel MPI (three executions:
16,32,64 (processors))

(MPI - 64 processors)
(CUDA)

M illiseconds
100

(Sequential pure (no parallel))
(CUDA-Related)

102
M illiseconds

101

·107

101

100
0
0

1

2
n

Figure 7:
n million(s)
1.048.576
2.097.152
4.194.304
8.388.608
16.777.216
32.554.432

1

2
n

3
·10

3
·107

7

MPI × CUDA

Speedup - Figure 5
6.71709
9.52437
7.53388
7.87658
7.63946
8.10558

Figure 8:

Sequential [2] × Related Problems. We modiﬁed the
sequential algorithm to also solve the related problems.

Speedup - Figure 6
4.29897
5.92933
9.78575
11.32026
12.73724
14.54947

Speedup - Figure 7
2.96873
1.97700
1.49924
1.24511
1.10791
0.98876

Speedup - Figure 8
4.91527
5.53549
5.84987
6.18857
6.32009
6.41110

Table 1:

The values of speedup for the cases described in Figures 5 to 8. Particularly, in the speedup of
Figure 6, we use the best run time (64 processors). We have run the algorithms on two diﬀerent computing systems.
The CUDA algorithms were executed on a machine with 8 GB of RAM, Operating System Linux (Ubuntu 14:04), (R)
Intel Core (TM) processor i5-2430M @ 2.40GHz CPU and an NVIDIA GeForce GTX 680 with 1536 processing cores.
The MPI algorithm was executed on a cluster with 64 nodes, each node consisting of 4 processors Dual-Core AMD
Opteron 2.2 GHz with 1024 KB of cache and 8 GB of memory. All nodes are interconnected via a Foundry SuperX
switch using Gigabit ethernet. This cluster belongs to High Performance Computing Virtual Laboratory (HPCVL) of
Carleton University. We expect that the triggered processes were equally distributed among processors of each node
of the cluster. For equivalent comparisons with the CUDA/MPI algorithms, the sequential algorithms were run on
the cluster environment and on the machine with CPU and GPU. Experiments with diﬀerent sizes of sequences were
performed. For each input sequence, the algorithms were run 10 times and the arithmetic mean of the running times
was computed.

5

Conclusion and Future Work

In this work we propose eﬃcient parallel solutions to the maximum subsequence sum and
three related problems. The related problems are: the maximum longest subsequence sum, the
2757

Eﬃcient BSP/CGM algorithms

Lima, Cceres, Branco, Gaioso, Ferraz, Song and Martins

maximum shortest subsequence sum and the number of disjoints subsequences of maximum
sum. To the best of our knowledge there are no parallel algorithms for these related problems.
Our algorithms use p processors and require O n/p parallel time with a constant number
of communication rounds for the algorithm of the maximum subsequence sum and O log p
communication rounds, with O n/p local computation per round, for the algorithm of the
related problems. The good performance of the parallel algorithms is conﬁrmed by experimental
results. The CUDA version, for the Algorithm 1, presented a speedup of ≈ 9x as compared
to the eﬃcient O(n) sequential algorithm [2]. On the other hand the CUDA version for the
algorithm of related problems, presented a speedup of ≈ 6x as compared with the version of the
sequential algorithm, which solves the same problems. When we compare the MPI version with
the CUDA version, both versions present close running times. Importantly, it was from the
CUDA version of Algorithm 1, that we propose an algorithm for the three related problems. We
also conclude that the BSP/CGM model can be used eﬃciently to design parallel algorithms in
GPGPU/CUDA environments. Besides all the details of this environments, we have mapped
our algorithms into implementations with good speedups, where a single GPGPU got better
performance than a cluster of workstations. Finally, we believe that the speedup of our CUDA
algorithms can be further improved through the use of multiple GPUs.

5.1

Future Work

A possibility of future work consists in computing the k-th maximal longest or shortest subsequence sum. Other work is the implementation of the our BSP/CGM algorithm for the
maximum subsequence sum using a multi GPGPU enviroment. We believe that the parallel
time of this algorithm in an multi GPGPU can decrease considerably.

References
[1] Carlos E. R. Alves, Edson N. C´
aceres, and Siang W. Song. BSP/CGM algorithms for maximum subsequence
and maximum subarray. In Recent Advances in Parallel Virtual Machine and Message Passing Interface,
volume 3241 of Lecture Notes in Computer Science, pages 139–146. Springer Berlin Heidelberg, 2004.
[2] Jon Bentley. Programming pearls: Algorithm design techniques. Commun. ACM, 27(9):865–873, September
1984.
[3] Silvia M. G¨
otz. Communication-Eﬃcient Parallel Algoritms for Minimum Spanning Tree Computation.
PhD thesis, University of Paderborn, May 1998.
[4] Richard E. Ladner and Michael J. Fischer. Parallel preﬁx computation. J. ACM, 27(4):831–838, October
1980.
[5] Sandra L. Marcus, John H. Brumell, Cheryl G. Pfeifer, and B.Brett Finlay. Salmonella pathogenicity islands:
big virulence in small packages. Microbes and Infection, 2(2):145–156, 2000.
[6] Kalyan Perumalla and Narsingh Deo. Parallel algorithms for maximum subsequence and maximum subarray.
Parallel Processing Letters, 5:367–363, 1995.
[7] Walter L. Ruzzo and Martin Tompa. A linear time algorithm for ﬁnding all maximal scoring subsequences.
In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology, pages
234–241, August 1999.

2758

