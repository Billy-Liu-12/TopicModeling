Procedia Computer Science
Volume 51, 2015, Pages 1782–1790
ICCS 2015 International Conference On Computational Science

Monte Carlo method for density reconstruction based on
insuﬃcient data
Aneta Karaivanova, Soﬁya Ivanovska, and Todor Gurov
IICT-BAS, Acad. G. Bonchev St., Bl. 25A, Soﬁa 1113, Bulgaria
(anet,sofia,gurov)@parallel.bas.bg

Abstract
In this work we consider the problem of reconstruction of unknown density based on a given
sample. We present a method for density reconstruction which includes B-spline approximation,
least squares method and Monte Carlo method for computing integrals. The error analysis is
provided. The method is compared numerically with other statistical methods for density
estimation and shows very promising results.
Keywords: Monte Carlo Integration, Insuﬃcient Data, Density Reconstruction, Kernel Density Estimation, Histograms

1

Introduction

Let (x1 , x2 , . . . , xn ) be a set of observed data points assumed to be a sample from an unknown probability density function. Density estimation is the construction of an estimate of
the unknown density function from the observed data. One approach to density estimation
is parametric but we are interested in non-parametric approach in which ”the data will be
allowed to speak for themselves in determining the estimate of f more than would be the case
if were constrained to fall in a given parametric family”, [10]. Density estimates of this kind
were ﬁrst proposed by Fix and Hodges, [2], as a way of freeing discriminant analysis from rigid
distributional assumptions. Since then, density estimation and related ideas have been used
in a variety of contexts. For example, in ﬁnancial mathematics the problem of reconstructing densities arises when estimating the proﬁt and loss distribution of a portfolio and thus
when computing risk measures that summarize distribution. The classical methods for density
estimation are histograms, k ernel density estimation, orthogonal series estimators, maximum
penalized likelihood estimators and others (the ﬁrst two are the most popular). Histograms represent a graphical way of summarizing or describing a data set. A histogram visually conveys
how a data set is distributed and provides information about relative frequencies of observations.
Histograms are easy to create and are computationally feasible. The histogram is informative
but it is not smooth and not sensitive enough toward the local properties of the density. The
kernel method overcomes this disadvantage of the histogram method.
1782

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2015
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2015.05.390

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

In this paper we present a density estimation method based on Monte Carlo integration
which shows better accuracy then the method of histograms and the method of kernel density
estimation in case of insuﬃcient data. The Monte Carlo methods are among the most widely
used numerical methods which are applicable to various problems [3, 8]. Let us brieﬂy remind
the Monte Carlo integration concept [4, 6, 11].
Consider an integral on the unit cube I d = [0, 1]d in d dimensions, I[f ] = I d f (x)dx,
of a Lebesgue integrable function f (x), and note that this integral can be expressed as the
expectation of the function f ,
I[f ] = E[f (x)],
(1)
in which x is a uniformly distributed vector in the unit cube.
An empirical approximation to the expectation (1) is given with
IN [f ] =

1
N

N

f (xn ),

(2)

n=1

if {xn } is a sequence sampled from uniform distribution. Equation (2) is called (crude) Monte
Carlo quadrature formula. The integration error, deﬁned as N [f ] = |I[f ] − IN [f ]|, has a
)
. Besides this, probabilistic,
standard normal distribution, with expectation E[ 2N ] = V ar(f
N
bound for the Monte Carlo integration error, an exact upper bound is given with KoksmaHlawka inequality,
∗
(3)
N [f ] ≤ V [f ]DN ,
∗
in which V[f] is the variation of f in the Hardy-Krause sense and DN
is the discrepancy of the
sequence. Equation (3) is valid for any bounded function and any choice of sequence.
The paper is organized as follows: The ﬁrst section is a short introduction, the second section
describes the density estimation method using Monte Carlo integration; the third section brieﬂy
reminds two very popular methods of non-parametric density estimation (histograms and kernel
density estimation), the forth section presents results from the numerical tests, and the last
section gives some conclusions.

2

Density Estimation using Monte Carlo Integration

Consider the problem of approximation of the unknown density function p(x) deﬁned in [a,b]
by given N realizations {ξi }N
i=1 ∈ [a, b] of the random variable ξ with density p(x). The use of
splines for statistical modeling is proposed in [1] and an overconvergent Monte Carlo method
for density modeling is studied in [8, 11].
Suppose p(x) ∈ C k [a, b] where k ≥ 0 is an integer number. It divides the interval [a, b] into
m subintervals and introduces following set points:
ωm = {a = x0 < x1 < . . . < xm = b},
b−a
; 2k new nodes are added to the set ωm and the result is the set:
m
Tn = {t1 < t2 < . . . < tk+1 = x0 < . . . < xm = tn−k < tn−k+1 < . . . < tn }.

with step h =

Consequently n = 2k + m + 1.
It holds approximation of p(x) with B-splines of k-th degree:
L

p(x) =

ci Bi,k (x),

x ∈ [a, b],

L=n−k−1

i=1

1783

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

with an error O(hk ) where ci , i = 1, . . . , L are the approximate coeﬃcients.
The i-th B-spline of k-th degree with nodes ti , . . . , ti+k+1 is deﬁned as the divided diﬀerence of
truncated power function (t − x)k+ with respect to t in the points ti , . . . , ti+k+1 :
Bi,k (x) = (· − x)k+ [ti , . . . , ti+k+1 ],

i = 1, . . . , L,

where x is ﬁxed point and
(t − x)k ,
0,

(t − x)k+ =

t>x
t ≤ x.

Each spline is represented as a linear combination of truncated power functions. Therefore
Bi,k (x) could be represented as follows:
i+k+1

Bi,k (x) =
s=i

(ts − x)k+
(ts ),
ωi,k

where ωi,k (t) = (t − ti ) . . . (t − ti+k+1 ).
The advantage when we apply splines for approximation of unknown function is the usage
of algebraic polynomials of low degree. In order to obtain the coeﬃcients ci (i = 1, . . . , L), we
apply the least squares method, i.e. we have to minimize:
b

2

L

p(x) −

U=

ci Bi,k (x)

dx,

i=1

a

where U is a function of L variables:
b
2

(p(x) − ϕ(x; c1 , . . . , cL )) dx

U = U (c1 , . . . , cL ) =
a
b
2

p (x) dx − 2

U=
a

b

L

ci (p, Bi,k (x)) +
i=1

2

L

ci Bi,k (x)

dx.

i=1

a

All the partial derivatives of U = U (c1 , . . . , cL ) are continuous. The necessary condition for
the function U = U (c1 , . . . , cL ) to possess a minimum is expressed with the system of linear
algebraic equations:
∂U
∂U
∂U
= 0,
= 0, . . . ,
= 0.
∂c1
∂c2
∂cL
We obtain
⎛
⎞
∂U
= −2(p, Bi,k (x)) + 2
∂ci

b

⎝

L

cj Bj,k (x)⎠ Bi,k (x) dx = 0

j=1

a

L

(Bi,k (x), Bj,k (x))cj = (p(x), Bi,k (x))

i = 1, . . . , n − k − 1,

j=1

where the inner product is deﬁned as
b

(f, g) =

f (x)g(x) dx.
a

1784

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

The unknown approximate coeﬃcients cj is obtained as a solution of the system of L equations. Obviously the functional (p(x), Bi,k (x)) is the mathematical expectation of Bi,k (x) with
a density p(x) ([11]):
b

(p(x), Bi,k (x)) =

p(x)Bi,k (x) dx = EBi,k (ξ),
a

where the random number ξ has a density p(x). The inner product (p(x), Bi,k (x)) is estimated
using Monte Carlo method for calculation of the integrals:
(p(x), Bi,k (x)) ≈

N

1
N

B(ξj ) = θˆN .
j=1

where {ξi }N
i=1 is the given sample.
Thus, the constants cj are computed and we obtain an estimation of the unknown density:
L

qL (x) =

cˆj Bj,k .
j=1

The error of the method consists of two components:
||qp − p||2 ≤ ||p − qL ||2 + ||qL − q||2 = δ12 + δ22 ,

(4)

b

where ||f || = ( a f 2 (x)dx)1/2 , δ12 is the systematic error (due to approximation) and δ22 is the
stochastic error (error of Monte Carlo method). The method is considered good when δ1 is
approximately equal to δ2 .
Let us estimate the stochastic error:
δ22 =

L

b

[
a

(cˆj − cj )Bj,k ]2 dx =

j=1

L

L

(cˆj − cj )(cˆj − cj )ai,j ,
i=1 j=1

where

b

ai,j =

Bi,k (x)Bj,k (x)dx.
a

T
Denote A = {ai,j }L
,j=1 and r = (r1 , r2 , . . . , rL ) , ri = cˆi − ci , i = 1, 2, . . . , L. Consider the error
Ar = (ε1 , . . . , εL )T = ε. Since the matrix A is positive deﬁned, it is possible to express the
expectation of the stochastic error as:

E(Ar, r) = E(ε, A−1 ε) ≤ ||A−1 ||E||ε||2 .
The errors εi , i = 1, . . . , L depend on the Monte Carlo method for approximate calculation of
integrals. For the crude Monte Carlo and sample size N we have error:
rN = c0.5 σ(θ)N −1/2 ,

(5)

where c0.5 ≈ 0.6745 and σ(θ) is the standard deviation.

1785

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

The order of the error can be improved by applying a special Monte Carlo techniques, [1].
For B-splines of degree 2, the order of the error is O(N −3/2 ).
Now we will consider the problem of balancing the systematic and stochastic errors in order
to obtain the step of the mesh on which B-splines are deﬁned. The systematic error is
δ 1 ≤ C 1 hk ,
where h is the step of the mesh. The stochastic error is (for the method, presented in [1], with
k = 2):
δ22 ≤ ||A−1 ||C22 N −3 .
Since for the balancing of errors it is necessary to have C1 h2 = C2 ||A||−1/2 N −3/2 , one can get
the optimal relation between N and h:
N = Ch−2/3k .
For the crude Monte Carlo we have N = Ch−2k .

3

Non-parametric Techniques for Probability Density Estimation

In this section we brieﬂy present two very popular methods for probability density estimation:
histograms and kernel method, (see [7, 9, 10]).

3.1

Histograms

The histograms are the oldest and most widely used non-parametric density estimator. This
is usually formed by dividing the real line into equally sized intervals, often called bins. The
histogram is calculated using a random sample ξ1 , ξ2 , . . . , ξN . At ﬁrst, the origin x0 for the bins
and a bin width h have to be chosen. The bin width h is usually called a smoothing parameter
since it controls the amount of ”smoothing” being applied to the data. Our goal is to estimate
a probability density function, so we have to obtain a function pˆ(x) that is nonnegative and
satisﬁes the following condition:
b

pˆ(x) dx = 1.
a

The one-dimensional histogram estimate pˆHist (x) at a point x is deﬁned with the following
expression:
N
νi
1
=
IS (ξi )
for x ∈ Sj ,
pˆHist (x) =
hN
h N i=1 j
where Sj = [xj , xj+1 ) is the j-th bin (j = 0, . . . , m − 1), νj is the number of observations in the
m−1
j-th bin ( j=0 νj = N ), and ISj (ξi ) is the indicator function for the bin Sj .

3.2

Kernel Density Estimation

The histogram is informative but it is not smooth and not sensitive enough toward the local
properties of the density p(x). The kernel method overcomes this disadvantage of the histogram
method.
1786

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

Let K(x) be a function that satisﬁes the conditions:
b

K(x) ≥ 0,

K(x)dx = 1.
a

Then the kernel density estimator with kernel K(x) is deﬁned by
pˆKer (x) =

1
λN

N

K
i=1

x − ξi
λ

,

where λ is the bandwidth (smoothing parameter, window width).
A range of kernel functions are commonly used: uniform, triangular, biweight, triweight,
Epanechnikov, normal, and others. The Epanechnikov kernel is optimal in a minimum variance
sense, though the loss of eﬃciency is small for the kernels listed previously, [5], and due to its
convenient mathematical properties, the normal kernel is often used K(x) = φ(x), where φ() is
the standard normal density function.

4

Numerical Results

In this section the numerical results from the testing of described methods for probability
density estimation are presented. The results are given as a function of the sample size N and
the step of the mesh h. The sample is obtained using a pseudorandom generator. The absolute
error in every point of mesh is computed.
The described algorithms are tested with diﬀerent sample sizes for two diﬀerent distributions
- exponential and normal. The numerical results in all tables have been computed by using
Matlab.
Table 1: Euclidean norm of the absolute error from exponential density reconstruction with
Monte Carlo method and histogram method. The number of the intervals on the mesh is equal
to 25.
Number of realizations
100
1 000
10 000 100 000
Step of the mesh
0.24658 0.25339 0.37490 0.52569
Monte Carlo method
0.37058 0.08860 0.09599 0.00697
Histogram method
0.31275 0.19913 0.22882 0.27471

Table 2: Euclidean norm of the absolute error from normal density reconstruction with Monte
Carlo method, histogram method and kernel density estimation. The number of the intervals
on the mesh is equal to 50.
Number of realizations
Step of the mesh
Monte Carlo method
Histogram method
Kernel density estimation

100
0.10116
1.19988
0.97351
0.14004

1 000
0.13794
0.16517
0.23475
0.07344

10 000
0.14669
0.04509
0.07545
0.03232

100 000
0.16033
0.01765
0.07355
0.01403

1787

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

Tables 1 and 2 show the error dependence of the sample size and the step of the mesh. When
the sample size increases the probable error decreases correspondingly. According to the nature
of the exponential distribution the step of the mesh increases with the increase of the number
of realizations of the random variable but the Euclidean norm of the error decreases. The
results for normal density reconstruction are similar to the previous but the desired accuracy
is achieved slower.
1.2

1

0.8

p(x)

0.6

0.4

0.2

0

−0.2
0

1

2

3

4

5

6

7

x

Figure 1: Exponential density estimation based on sample size 1000 with Monte Carlo method
and method of histograms.
1.2

1

0.8

p(x)

0.6

0.4

0.2

0

−0.2
0

1

2

3

4

5
x

6

7

8

9

10

Figure 2: Exponential density estimation based on sample size 10000 with Monte Carlo method
and method of histograms.
1788

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

The accuracy of the described Monte Carlo method for reconstruction of densities is compared to other statistical methods as histograms and kernel density estimation. From Table 1
it is clear that Monte Carlo method is more precise than the histogram method. For normal
density reconstruction Monte Carlo method gives accuracy of the same order in comparison
with the used statistical methods.

0.45
0.4
0.35
0.3

p(x)

0.25
0.2
0.15
0.1
0.05
0
−0.05
−4

−3

−2

−1

0
x

1

2

3

4

Figure 3: Normal density estimation based on sample size 1000 with Monte Carlo method and
kernel density estimation.
0.45
0.4
0.35

p(x)

0.3
0.25
0.2
0.15
0.1
0.05
0
−0.05
−4

−3

−2

−1

0

1

2

3

4

Figure 4: Normal density estimation based on sample size 10000 with Monte Carlo method
and kernel density estimation.
1789

Monte Carlo for density reconstruction based on insuﬃcient data Karaivanova, Ivanovska and Gurov

Graphic presentation of the density function is shown in case of exponential distribution of
Figure 1 and 2 and normal distribution of Figure 3 and 4. The true density is represented by
a solid line on Figures. The stars represent the results obtained by using Monte Carlo method.
It is obvious from the ﬁgures that with increasing the number of realizations the reconstructed
values ﬁt better to the corresponding density curve for all considered methods. This clearly
shows that high accuracy can only be obtained by using suﬃciently large samples.

5

Conclusion

In the present paper the Monte Carlo method and non-parametric methods for density reconstruction are considered. Their accuracy in solving the investigated problem is compared.
The obtained results show that the considered algorithm using Monte Carlo method gives the
same accuracy with some advantage in comparison with the other mentioned methods for ﬁxed
number of realizations of a random variable and a ﬁxed step of the mesh. In the same time,
the presented method preserves the well known advantages of Monte Carlo methods: simple
construction,robustness,inherent parallelism,good scaling properties over various HPC systems.

Acknowledgment
This work was supported by the National Science Fund of Bulgaria under Grant DFNI-I02/8.

References
[1] Ivan Dimov and Aneta Karaivanova. Overconvergent Monte Carlo Methods for Density-function
Modelling Using b-Splines., pages 85–93. Singapore: World Scientiﬁc, 1994.
[2] J.L. Fix, E.and Hodges. Discriminatory analysis, nonparametric discrimination: Consistency
properties. Technical Report 4, USAF School of Aviation Medicine, Randolph Field, Texas, 1951.
[3] J.M. Hammersley and D.C. Handscomb. Monte Carlo methods. Methuens Monographs on Applied
Probability and Statistics. London: Methuen & Co. Ltd. New York: John Wiley & Sons Inc. VII,
1964.
[4] Malvin H. Kalos and Paula A. Whitlock. Monte Carlo methods. 2nd revised and enlarged ed.
Hoboken, NJ: John Wiley & Sons, 2nd revised and enlarged ed. edition, 2008.
[5] A. Karaivanova. Statistical Numerical Methods and Simulations. Demetra, Soﬁa, 2012. (In Bulgarian).
[6] Dirk P. Kroese, Thomas Taimre, and Zdravko I. Botev. Handbook of Monte Carlo methods.
Hoboken, NJ: John Wiley & Sons, 2011.
[7] Wendy L. Martinez and Angel R. Martinez. Computational Statistics Handbook with MATLAB.
Boca Raton, FL: Chapman & Hall/ CRC, 2002.
[8] G.A. Mikhailov. New Monte Carlo Methods with estimating Derivatives. Utrecht: VSP, 1995.
[9] J. O. Ramsay and B. W. Silverman. Functional data analysis. 2nd ed. New York, NY: Springer,
2nd ed. edition, 2005.
[10] B.W. Silverman. Density Estimation for Statistics and Data Analysis. Monographs on Statistics
and Applied Probability. London - New York: Chapman and Hall. IX, 1986.
[11] I.M. Sobol’. Numerical Monte-Carlo methods. Moskva: Izdat. ’Nauka’, FizMatLit., 1973.

1790

