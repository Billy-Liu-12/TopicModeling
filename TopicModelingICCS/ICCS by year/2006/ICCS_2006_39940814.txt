Integrative Computational Frameworks for
Multiscale Digital Human Modeling and
Simulation
Richard C. Ward1 , Line C. Pouchard2, and James J. Nutaro1
1

Computational Sciences and Engineering Division, Oak Ridge National Laboratory,
P.O. Box 2008, Bethel Valley Road, Oak Ridge, Tennessee, USA
{wardrc1, nutarojj}@ornl.gov
2
Computer Sciences and Mathematics Division, Oak Ridge National Laboratory,
P.O. Box 2008, Bethel Valley Road, Oak Ridge, Tennessee, USA
pouchardlc@ornl.gov

Abstract. Integrated digital human modeling has seen increased interest over the last decade. We describe two eﬀorts to develop computational
frameworks for digital human modeling and describe the progress toward
understanding the requirements for implementation. Both projects addressed data repository, computational environment, and visualization
of results. But neither environment was a true problem-solving environment in that integration of computations with visualization capabilities
was limited or absent. We detail the development of the computational
environments for each eﬀort and then provide proposals for improving
the integration of the various components of a future “Digital Human”
computational environment.

1

Introduction

Integrated digital human modeling has seen increased interest over the last
decade. Here we report on two eﬀorts; the ﬁrst led by Oak Ridge National Laboratory (ORNL) and a more recent larger eﬀort in which ORNL played a role.
Portions of this research were supported by a grant from the Defense Advanced
Research Projects Agency, executed by the U.S. Army Medical Research and Materiel Command/TATRC Cooperative Agreement, Contract W81XWH-04-2-0012.
Portions of this research were sponsored by the Laboratory Directed Research and
Development Program of Oak Ridge National Laboratory, managed by UT-Battelle,
LLC, for the U. S. Department of Energy under Contract No. DE-AC05-00OR22725.
The submitted manuscript has been authored by the U.S. Department of Energy,
Oﬃce of Science of the Oak Ridge National Laboratory, managed for the U.S. DOE
by UT-Battelle, LLC, under contract No. DE-AC05-00OR22725. Accordingly, the
U.S. Government retains a non-exclusive, royalty-free license to publish or reproduce the published form of this contribution, or allow others to do so, for U.S.
Government purpose.
Approved for Public Release, Distribution Unlimited.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 814–821, 2006.
c Springer-Verlag Berlin Heidelberg 2006

Integrative Computational Frameworks

815

The ﬁrst eﬀort, Virtual Human (VH), culminated in the development of a Webbased, Java client/server environment within which some simple cardiovascular
circuit models and various other compartment models were incorporated. The
second eﬀort, the Defense Advance Research Projects Agency (DARPA)-funded
Virtual Soldier (VS) Project, was a much more substantial eﬀort to address
human modeling and predict the consequences of a soldier being wounded on
the battleﬁeld. A more comprehensive project, this second eﬀort addressed the
development of an integrated data repository, computational environment, and
visualization of results and predictions in a concept referred to as the holographic
medical electronic representation (Holomer) [1].
Both these projects contributed signiﬁcantly to our understanding of how
a computational framework can be built to address virtual human simulation.
However, the degree of integration of various components of the environment
left much to be desired. Neither environment fully integrated computations with
other elements of the environment; continued work must be done to bring the
design of digital human modeling environments in line with present thinking
in Service-Oriented Architecture (SOA) (http://www.service-architecture.com/)
for ﬂexibility of integrating data, computational, and visualization components.
Finally, we describe some concepts that might facilitate full integration and
provide an end-to-end capability for data acquisition, model computation, and
display of results and predictions.

2

Virtual Human

The concept of a VH was developed during 1996-2000. The VH was a ”concept...to combine models and data to build a comprehensive computational capability for simulating the function as well as the structure of the human body
and allow trauma simulations as well as many other applications” [2]. In the fall
of 1999 a workshop was held in Rockville, Maryland under ORNL auspices. The
general interest in the concept and enthusiasm for developing a VH, as well as
discussions in the Architecture breakout group, laid a foundation for subsequent
design and development of a computational framework.
2.1

VH Computational Environment

ORNL then initiated an eﬀort to develop a prototype VH computational environment. We chose to develop a Web-delivered environment using Java Remote
Method Invocation (RMI) with the human anatomical geometry deﬁned using
Virtual Reality Modeling Language (VRML) [9] [8]. The software underlying the
computational environment was derived from a generic client-server simulation
framework [3]. The environment allowed for integration of models written in
diﬀerent programming languages integrated using Java Native Interface (JNI).
Remote steering of the computation was also incorporated into the VH computational environment. The user interface is displayed in Fig. 1, showing windows
with the anatomical geometry, a circuit model for the left side of the heart, and

816

R.C. Ward, L.C. Pouchard, and J.J. Nutaro

Fig. 1. Virtual Human User Interface

the physiological response of that model. The anatomical geometry used here
was a portion of the National Library of Medicine Visible Human male data
converted to VRML format.
2.2

PhysioML

The most signiﬁcant development, however, was to create PhysioML, a physiological Extensible Markup Language (XML) to support model description [9].
PhysioML contains tags to describe the model parameters and variables and
associated units. Initial conditions are also deﬁned and the user can select particular variables which can be altered during the computation (computational
steering). Finally, PhysioML has tags to describe the user interface including
placement of parameters and variables on the interface and graphical representation of the results of the simulation.
Thus, PhysioML incorporates the parameters for the physiological model
equations, control of variables for steering the computation, and tags for display
of the results in the user interface. While other XML languages such as SBML
(http://sbml.org/) and cellML (http://www.cellml.org/) incorporated the ﬁrst
concept, PhysioML is unique in providing a capability to control the interface
display and computational steering. At the moment there is no means to incorporate the model description (functions) in the XML format, although eventually

Integrative Computational Frameworks

817

Table 1. Main XML tags used in PhysioML
Display
panel
image
label

User Interface Deﬁnition
deﬁnes a window panel
URL for screen image
screen display

variable
transfer
box
boxstuﬀ
boxtrigger

Model Deﬁnition
deﬁne variable (name, initial value)
transfer matrix
deﬁne a compartment
image displayed in compartment
threshold for compartment

Model

it is envisioned that this can be accomplished using MathML. For details on
PhysioML and examples see http://www.ornl.gov/~rwd/VH/xmlﬁles.html.

3

Virtual Soldier

The purpose of the DARPA VS Project, started in 2004, was to use physiological
models and data to predict the location of a wound to the heart (left ventricle or
right ventricle) caused by a fragment. The speciﬁc examples modeled included
small fragments wounds to myocardial zones 7 and 12 of the left ventricle with the
medical consequences being either tamponade or exsanguination. While diﬀerent
software was used to implement the computational framework for VS and more
sophisticated models were utilized, many of the concepts for the VS, especially
for the user interface, extrapolate concepts originally developed for the VH.
3.1

The VS Holomer Concept

An important concept developed in the VS Project was that of the Holomer. The
Holomer incoporated both the computational framework, including the data and
properties (molecular, biochemical, cellular, physiologic, organ, tissue and whole
body), computational models, and the display environment. The focus of Phase
I was on the heart, so the anatomy considered in the VS Holomer was restricted
to the heart and surrounding major vessels.
3.2

Computational Framework for Phase I

For Phase I two types of computational modeling were conducted: 1) high-level
integrative physiological (HIP) models (circuit models) and 2) three-dimensional
ﬁnite element (FE) models, including electrophysiology and mechanical motion.
The HIP models were optimized to the physiological characteristics and results
were then passed, via ﬁle transfer, to the FE models.
The results of both types of computations were integrated using a visualization environment based on SCIRun [7]. In addition, visualization using the

818

R.C. Ward, L.C. Pouchard, and J.J. Nutaro

SCIRun environment was linked to the VS Knowledge Base (VSKB), an ontology containing deﬁnitions for anatomical terms (the Foundational Model of
Anatomy) and physiology. The project also developed an XML format for describing the fragment wound. The integration of output using SCIRun was what
was generally referred to as the Holomer.
ORNL and its partner, the Center for Information Technology at the University of South Carolina, developed two components of the VS computational
framework. First, we developed middleware to support the project including Web
services for the data repository, a client to connect to the Web service for the
VSKB, and services and associated client API for the HIP model computations.
The University of Washington developed a Web service for the Foundational
Model of Anatomy [6]. These middleware components, various Web services
for data repository, computations, and ontologies, provide a good infrastructure for a future comprehensive computational framework. Unlike the Phase I
framework, this infrastructure would facilitate launching computations from the
environment.
The second component of the work conducted at ORNL involved the development of a “HotBox” within the SCIRun visualization environment. The
“HotBox” facilitated interaction between the VSKB ontologies (speciﬁcally the
anatomical ontology) and the geometric anatomical models and between the
anatomy and associated physiology (see Fig. 2). The problem was to display

Fig. 2. Virtual Soldier Holomer User Interface

Integrative Computational Frameworks

819

this information in such a way as to capture the three-dimensional (3D) nature
of the human body and to correlate that with extensive information about both
the anatomy and the physiology of the wounded soldier [5]. The VS “HotBox”
succeeded in providing this connectivity.

4

Future

In the future we should begin to see true integrative environments for multiscale
human modeling and simulation. A major challenge is to integrate two very
diﬀerent modeling approaches, one based on discrete information (e.g., stoichiometric biochemical reactions) and one based on continuous, time-dependent simulation (e.g., diﬀerential equation-based systemic organ models). Two concepts
are suggested as potential ways to bridge these diﬀerent modeling approaches.
1. Layering of information. This involves the use of autonomous agents
to enable knowledge discovery in support of modeling and simulations. This
knowledge discovery process can mine what is known about relevant anatomic,
metabolic, or physiological information that impact simulations.
2. Discrete-event simulation (DEVS). Discrete event simulation is being
used to model continuous simulations [4]. Since DEVS by deﬁnition can also
incorporate discrete reaction kinetics, it has the potential to provide the
necessary bridge to bring about integration between these approaches. A
conceptualization of our future vision is contained in Fig. 3.
In the concept vision, the ontological information layers (obtained both by
existing libraries of information and supported by intelligent agent searches)
support a computational layer based on a combination of DEVS and continuous

Fig. 3. Future vision of the Virtual Human or Digital Human Infrastructure

820

R.C. Ward, L.C. Pouchard, and J.J. Nutaro

simulation approaches, which in turn supports the data and user interface layers.
This concept uses capabilities and characteristics developed in the VH and VS
projects.
DEVS has a performance advantage over continuous simulation which can
be understood intuitively as follows. The time advance function determines the
frequency with which state updates are calculated at the spatial grid points. The
time advanced at each grid point is inversely proportional to the magnitude of
the time derivative at that point, and so “regions with slow change will have
large time advances relative to regions that are changing quickly. This causes the
simulation algorithm to focus eﬀort on the changing portion of the solution, with
signiﬁcantly less work being devoted to portions that are changing slowly” [4].
Our suggestion is that DEVS can be used to implement multiscale computations when there is loose coupling between “fast” states and “slow” states of the
model system. DEVS can incorporate both discrete models (such as stoichiometric chemical reactions) and continuous models (organ systems) to provide a
comprehensive computational framework for the Digital Human.

5

Summary

We have presented a brief historical account of development of integrative human
modeling, using the VH Project and the DARPA VS Projects as examples. The
lessons learned from these examples and the successes attained have been discussed.
In addition, we have outlined the diﬃculties faced by these projects in attaining a
truly integrated human modeling and simulation environment. Finally, we have
addressed what we believe to be the future in this eﬀort, the push to attain fullyintegrated, multiscale modeling, incorporating both discrete metabolic reactions
and continuous modeling based on diﬀerential equation models.
We have proposed two diﬀerent capabilities which might overcome some of
these diﬃculties and make possible fully integrative modeling. These are: 1)
layering of information and 2) discrete-event simulation. Each of these
concepts are discussed and their usefulness to human modeling and simulation
outlined. We believe that enormous strides will be made in the coming years
toward fully-integrative human modeling, just as scientists have made similar
strides in climate modeling over the last decade. By breaking down the barriers
between discrete models and continuous models, we believe that the goal of a
truly integrated computational environment for human modeling will be a reality
in the not-too-distant future.

References
1. S. P. Dickson, L. C. Pouchard, R. C. Ward, G. Atkins, M. J. Cole, B. Lorensen,
and A. Ade. Linking Human Anatomy to Knowledgebases: A Visual Front End
for Electronic Medical Records. In Medicine Meets Virtual Reality-13 Conference
Proceedings. IOS Press, 2005.
2. C. Krause. The Virtual Human Project: An Idea Whose Time Has Come? ORNL
Review, 33(1), 2000.

Integrative Computational Frameworks

821

3. C. S. Lindsey, J. S. Tolliver, and T. Lindblad. JavaTech, an Introduction to Scientiﬁc
and Technical Computing with Java. Cambridge University Press, Cambridge, UK,
2005.
4. J. Nutaro. Discrete event simulation of continuous systems. To appear in Handbook
of Dynamic Systems Modeling, 2005.
5. L. C. Pouchard and S. P. Dickson. Ontology-Based Three-Dimensional Modeling
for Human Anatomy. Technical Report ORNL/TM-2004/139, Oak Ridge National
Labortory, 2004.
6. C. Rosse and J. L. V. Mejino. Ontology for bioinformatics: The foundational model
of anatomy. Journal of Biomedical Informatics, 36:478–500, 2003.
7. Scientiﬁc Computing and Imaging Institute (SCI). SCIRun: A Scientiﬁc Computing
Problem Solving Environment, 2002.
8. R. C. Ward, K. L. Kruse, G. O. Allgood, L. M. Hively, K. N. Fischer, N. B. Munro,
and C. E. Easterly. Virtual Human Project. In Proceedings of the SPIE: Visualization of Temporal and Spatial Data for Civilian and Defense Applications, pages
158–167, 2001.
9. R. C. Ward, D. J. Strickler, J. S. Tolliver, and C. E. Easterly. A Java User Interface
for the Virtual Human. In Proceedings of the Joint BMES/EMBS Conference, page
1211, Atlanta, GA, 1999.

