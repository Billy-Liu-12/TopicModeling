Multicriterial Decision-Making in Multiagent
Systems
Petr Tuˇcn´ık1 , Jan Koˇzan´
y2, and Vil´em Srovnal1
1

Department of Measurement and Control
ˇ - Technical University of Ostrava,
VSB
17. listopadu 15, 708 33, Ostrava-Poruba
Czech Republic
petr.tucnik@vsb.cz, vilem.srovnal@vsb.cz
2
Department of Computer Science, FEECS,
ˇ - Technical University of Ostrava,
VSB
17. listopadu 15, 708 33, Ostrava-Poruba
Czech Republic
jan.kozany@vsb.cz

Abstract. The main purpose of this article is to present multi-criteria
decision-making principle as a tool providing the agent with autonomous
decision-making capacity. The advantages and disadvantages of this principle are described on the example of the robot soccer game, together
with the future perspective of this approach. The control system for
robot soccer game is designed with consideration of using a multi-criteria
decision-making. As a quickly changing environment, the robot soccer
game provides an excellent testing ground for such experimental
approach.

1

Introduction

The multi-criteria decision-making (MDM) problem area is laying in the intersection of several branches of science. Today, it is mainly used in the decisionsupport systems. From the point of view of the artiﬁcial intelligence the
possibility of application of the MDM principle for governing the agent actions
autonomously is more interesting. It allows us to implement various methods
of machine learning and leads us to unaccustomed perspective of viewing machine decision-making. Therefore, this text is focusing the autonomous decisionmaking and the area of decision-support will be generally omitted.

2

Basic Terms

Before we try to deal with the explanation of the MDM principle itself, we will
deﬁne the basic notions. Then we will use these deﬁned notions in the means of
following descriptions, deﬁnitions and equations.
The agent is the set X = {A, S, M }, where A = {A1 , . . . , An } is a nonempty
set of actions realized by the actuators, S = {s1 , . . . , sm } is the nonempty set
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part III, LNCS 3993, pp. 711–718, 2006.
c Springer-Verlag Berlin Heidelberg 2006

712

P. Tuˇcn´ık, J. Koˇzan´
y, and V. Srovnal

of scanning functions and M = {w1 , . . . , wk } is the nonempty set of motivational
functions and coeﬃcients that characterizes the goals of the agent and the effectiveness of its actions (through the motivational functions it is possible to
implement machine learning methods).
The actions of the set A are divided into the subsets accordingly to the actuator that is capable of their realization. Motivation value of the speciﬁc actuator
selection is divided between actions that this actuator is capable of. With each
actuator at least one speciﬁc motivational function is assembled, when there is
a large scalability of the possible actuator actions, more motivational functions
may be presented. As a supportive tool we may use the initiatory conditions
or threshold values. The whole functional spectrum of the actuator activity (its
whole extent of activities) has to be covered.
The notion of attribute denotes one (distinguishable) characteristic feature
of the agent’s environment and it is represented numerically. This is important
condition for the successful application of the MDM method.
The universum is the environment described from the agent’s point of view
as a system of sets U , resp. z-nary vector of numbers (attributes), where z ∈ N .
The z-nary vector represents all the attributes in the universum. For the universum, the following equation is valid:
U = UR ∪ UI ∪ X,

(1)

where UR represents real component of the world, UI imaginary component of
the world and X agent itself. The universum may not be considered valid without
the presence of the agent itself, as it is an inseparable part of it. The imaginary
part of the universe may not be omitted either, as it may inﬂuence the decision
making process of the agent. The universum is therefore the sum of all inﬂuences
relevant for the agent during the decision forming process.
The universum-configuration represents z-nary vector of attribute values in
the particular time. The attribute value represents measure of presence of given
characteristic in the environment. The attribute value ﬁts into bordered interval
the endpoints (upper limit and lower limit ) of which are speciﬁed by the sensor
sensitivity and range.
The decision-making situation represents such universum-conﬁguration that
it is necessary to start the decision-making process i.e. the sequence of steps
leading to the selection of the best solution variant of the current situation.
With the notion of the variant we refer to the sequence of one or more actions
from the set A (application of such actions must be possible in the given situation), which is in fact the transition from the starting state of the agent to the
state that corresponds with the motivations of the agent in its decision-making
moment.
In the universum, the area of the agent’s eﬀect P , is deﬁned:
P = U ∩ (A1 ∪ . . . ∪ An ),

(2)

where Ai (i = 0, . . . , n) is the area of the eﬀect of the actuator Ai .
The scanning function sj (a1 , . . . , ap ), in the universum U deﬁned by the
attributes (a1 , . . . , az ), returns scanned values of p-nary vector of attributes

Multicriterial Decision-Making in Multiagent Systems

713

(a1 , . . . , ap ). This vector is scanned by the item sj of the sensor set S. It holds
up for z ≥ p. For the function sj , the following equations are valid:
sj (a1 ), sj (a2 ), . . . , sj (ap ) = sj (a1 , . . . , ap ),

(3)

∀sj ∈ S : Re (sj ) ∈ k, l | − ∞ ≤ k ≤ l ≤ ∞, j = 1, . . . , m,

(4)

∀sj ∈ S : Im(sj ) ∈ 0, 1 , j = 1, . . . , m,

(5)

while during the signal processing, the standard normalization formula
normalized value = (attribute value − k)/(l − k)

(6)

is used. The attribute value is normalized to the interval of 0; 1 and variables
k, l are expressing the lower and upper limit of the sensor scanning range. Concurrently, the following condition has to be fulﬁlled:
s1 (A1 , . . . , Az ) ∪ s2 (A1 , . . . , Az ) ∪ . . . ∪ sm (A1 , . . . , Az ) ⊇ P.

(7)

The agent has to be able to perform sensor scanning at least in the area
of eﬀect ofits actuators. If the condition (7) is not fulﬁlled, the agent is not able
to perform his activities eﬀectively, as it is not able to perceive all changes made
in the environment by its actuators.

3

The Basic Principle

In [5], [1], the wide scale of methods of multi-criteria decision-making may befound. The Fig. 1 shows the steps of the MDM process.

Fig. 1. The MDM process

After initialization and goal acquisition in the phase 0, the agent tries to refresh its environmental data by its sensors – this is the phase 1. The set of initiatory conditions is used for the decision-making situation recognition in the phase
2. It has to provide the agent with the ability to react to unexpected changes
in the environment during its target pursue. Also, it must allow the agent to

714

P. Tuˇcn´ık, J. Koˇzan´
y, and V. Srovnal

change its goal through the decision-making process pertinently, e.g. if the prior
goal is accomplished or unattainable. In the phase 3, the conditions of applicability characterize the boundary that expresses the relevance of using the variant
in the decision-making process. The most important step is the phase 4, where
the convenience appraisal of applicable variants is performed. This step plays
the key part in the decision-making procedure. The following formula is used:
w(inv(norm(avi ))),

convenience =

i = 1, . . . , z,

(8)

i

where v stands for the total number of variants.
The convenience value for the each of assorted variants is obtained. Attributes
avi stand for presumptive values of universum-conﬁguration and the norm function normalizes the value of the attribute and is mentioned above (6). The function inv is important, as it represents reversed value of diﬀerence between real
attribute value and ideal attribute value:
inv(current value) = 1 − (ideal value − current value).

(9)

The optimal variant remains constantly deﬁned by m-nary vector of attributes, where m ≤ z, for the each of the decision-making situations and attributes avi diﬀer for each variant other than the optimal variant. There is a ﬁnal
number of activities that the agent is able to perform. As the inverse values
of diﬀerence between the real and ideal variant are used, in the most ideal case,
the convenience value will be equal to 1, and in the worst case it will be close
to 0. Im(inv) = (0; 1 . The lower open boundary of the interval is useful, because
troubles related to computation with zero (dividing operations) may be avoided.
The function w assigns the importance value (weight) to the each attribute.
The machine learning is realized by proper modiﬁcations of the weight function.
Importance of attributes diﬀers in accordance with the actual state of the agent.
E.g. energetically economical solution would be preferred when the battery is
low, fast solution is preferred when there is a little time left, etc. Precise deﬁnitions of weight functions are presented in [5], [1]. In the phase 5, the variant with
the highest convenience value is selected and its realization is carried out in the
phase 6. During processing of the selected solution, the agent is scanning the environment and if the decision-making situation is recognized, the whole sequence
is repeated. The evaluation function (e.g. reinforced learning functions examples
in [3], [4], [6]) provides the feedback and supports the best variant selection, as
it helps the agent inits goal pursue. Based on the scanned environmental data,
modiﬁcations of the function w are made during the learning process. The agent
is optimizing selection process and gets abetter appreciation of the goal pursue
issues. Function w belongs to the M set (motivational factors of the agent).

4

Attribute Composition and Decomposition

The attributes are a cornerstone of the MDM system. Therefore, their formulation requires presence of the proper tool. It is necessary to provide the MDM

Multicriterial Decision-Making in Multiagent Systems

715

system with the adequate amount of attributes. This is where the composition
and decomposition technique is used. Properly functioning MDM system has
to fulﬁll following condition:
|A| ≥ 1 ∧ |S| ≥ 1 ∧ |M | ≥ 1,

(10)

which expresses the requirement of non-emptiness of the A, S, M sets of the
agent. But the case:
|A| = 1 ∧ |S| = 1,
(11)
is trivial one. As there is only one attribute to assess and only one solution possible, it is not really a MDM system. Therefore, it is better to fulﬁll the following
condition:
|A| ≥ 2 ∧ |S| ≥ 2 ∧ |M | ≥ 1,
(12)
where two attributes are considered and two options are possible. There is only
one evaluating function, but it must be included for it is necessary to provide the
agent with satisfactory feedback. It is not possible to call the system artiﬁcially
intelligent if it has no tendency to rational behavior in its environment. Such
rational aspect may be ensured by implementation of the motivational factor
(goal) to the agent. Therefore, at least one item in the M set of the agent is
required. Many repeats ofcomposition or decomposition brings up disserviceable
results or imbalances and dependencies in the universum structure.

5

Examples

The actual aim of our research is the strategy in a robot control system. The
strategy is a component in a hybrid control architecture of the robot soccer control system [2]. This component has a recognized picture from camera (robots’
and ball’s coordinations) in its input. Then it have to make a correct realtime decision-making that depends on the current situation on the playground.
The output of the strategy component is the set hardware level orders setting
the wheel velocities on each our robot.
We have decided to apply the MDM method to the decision making problem. For successful application of the MDM method it is necessary to provide
the suﬃcient amount of attributes to the decision-making system. The fact is
that the only truly relevant data input are video camera pre-processed images.
The decision-making system has to derive all the necessary data from this input,
so we proposed the system of attributes that is based on the video recognition.
The main set of attributes consists of items such as position of the agent
in the system of coordinates, its speed, heading angle, etc. The auxiliary data
structure is division of the soccer playground into areas, as it is shown at Fig. 2.
Such division provides additional (more detailed) information about the agent
position and is useful for easier situation recognition. Hexagon representation in
Fig. 2 is presented because it is easier to see the limited amount of transitions
between the given positions (areas).

716

P. Tuˇcn´ık, J. Koˇzan´
y, and V. Srovnal

Fig. 2. Divided robot soccer playground and its hexagonal representation

For easier use of the MDM method it is useful to divide strategy component
into several subcomponents in a hierarchical manner. We have adopted a hybrid
control architecture of the robot soccer control system [2]. The hybrid control
architecture with modiﬁed strategy component is shown at Fig. 3.
Preprocess component. This component preprocesses a recognized picture
from camera – it predicts the ball’s and robots’ positions, all attributes
needed for next MDM-based selection of strategies are computed there.
High-level component. Recognition of game situation on the playground and
the application of the MDM-based selection of the team strategy is performed
here.
Medium-level component. At this level the roles are delegated to each agent
for example keeper, defender or attacker and there are delegated instructions
to each robot for example moving, shooting etc.
Low-level component. Each agent has to compute its wheel velocities based
on selected instruction in order to perform.
The cooperation of all layers of the strategy module is necessary to achieve satisfactory results. Such architecture also respects the requirements of multi-agent
approach, as it is not a purely centralized system, but a tool for role delegation and work control. It is possible to apply the MDM principle to the most
decision-making situations; therefore, it allows us to perform the tests of this
method.
The high-level component recognizes the game situation on the playground.
It recognizes whether our team should attack or defend. Attributes are ball’s
and robots’ positions and ball possession plays an important role during the
recognition process. Next step is the selection of actions. One action can be
executed by more than one robot, for example the pass action. If our team

Multicriterial Decision-Making in Multiagent Systems

717

Fig. 3. Divided robot soccer playground and its hexagonal representation

attacks, the actions leading to score have the priority, and if our team is defending
againts oponent’s actions then activities preventing opponent to score a goal
have the priority. Attributes for a MDM based decision-making are based on
the following facts - our team is in attack or not and on the positions of the
robots and the ball. Evaluating functions also have to take the probability of the
successful execution of actions under consideration.
The medium-level component is responsible for delegacy of roles and instructions. The roles during the action are delegated to the robots. If there are several
robots assigned to one action then the robot with the most advantageous position for action execution obtains the role of a leader. Robots with the leader
role are responsible for execution of the action. In the next step robots choose
instructions leading to the successful execution of the action. The robots have
to communicate with each other in order to choose instructions properly. The
next reason for communication is need of the plan collision avoidance. Robots
have to exchange their intentions and the adequate solution is the output of this
communication process.
The low-level component is responsible for driving of our robots. There is no
decision-making at this level. Robots don’t communicate with each other.

6

Conclusion

The MDM principle represents an interesting approach to the complicated problem solving. However the main problem remainings in the proper virtual design
of the environment. The universum of the agent must be represented in the numeric format and presented in a suitable quantity of attributes. Also, the motivations of the agent must be designed appropriately. In spite of these design
problems, the MDM principle represents the versatile tool that is able to process
the large variety of tasks.

718

P. Tuˇcn´ık, J. Koˇzan´
y, and V. Srovnal

Acknowledgment
The work and the contribution were supported by the project from Grant Agency
of Czech Academy of Science - Strategic control of the systems with multiagents,
No. 1ET101940418 (2004-2008).

References
ˇ Praha (1997).
1. Fiala, P., Jablonsk´
y, J., Manas, M.: V´ıcekriteri´
aln´ı rozhodov´
an´ı, VSE
2. Kim, J., Kim, D., Kim, Y., Seow, K.: Soccer Robotics (Springer Tracts in Advanced
Robotics), Springer-Verlag, 2004
3. Kub´ık, A.: Agenty a multiagentov´e syst´emy, Silesian University, Opava (2000).
4. Pfeifer, R., Scheier, C.: Understanding Intelligence. The MIT Press, Cambridge,
Massechusetts, (1999).
5. Ram´ık, J.: V´ıcekriteri´
aln´ı rozhodov´
an´ı – Analytick´
y hierarchick´
y proces (AHP),
Silesian University, Opava (1999).
6. Weiss, G.: Multiagent Systems – A Modern Approach to Distributed Modern Approach to Artificial Intelligence. The MIT Press, Cambridge, Massechusetts, (1999).

