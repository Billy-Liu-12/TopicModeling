Soft Computing Based Range Facial Recognition
Using Eigenface
Yeung-Hak Lee1, Chang-Wook Han1, and Tae-Sun Kim2
1

School of Electrical Engineering and Computer Science, Yeungnam University,
214-1 Dae-dong, Gyongsan, Gyongbuk, 712-749 South Korea
{annaturu, cwhan}@yumail.ac.kr
2
Department of Digital Electronic Engineering, Kyungwoon University,
55 Induk-ri, Sandong-myun, Kumi, Kyungbuk, 730-852 South Korea
tskim@ikw.ac.kr

Abstract. The depth information in the face represents personal features in detail. In particular, the surface curvatures extracted from the face contain the
most important personal facial information. These surface curvature and eigenface, which reduce the data dimensions with less degradation of original information, are collaborated into the proposed 3D face recognition algorithm. The
principal components represent the local facial characteristics without loss for
the information. Recognition for the eigenface referred from the maximum and
minimum curvatures is performed. The normalized facial images are also considered to enhance the recognition rate. To classify the faces, the cascade architectures of fuzzy neural networks, which can guarantee a high recognition rate
as well as parsimonious knowledge base, are considered. Experimental results
on a 46 person data set of 3D images demonstrate the effectiveness of the proposed method.

1 Introduction
Today’s computer environments are changing because of the development of intelligent interface and multimedia. To recognize the user automatically, people have researched various recognition methods using biometric information – fingerprint, face,
iris, voice, vein, etc [1]. In a biometric identification system, the face recognition is a
challenging area of research, next to fingerprinting, because it is a no-touch style. For
visible spectrum imaging, there have been many studies reported in literature [2]. But
the method has been found to be limited in their application. It is influenced by lighting illuminance and encounters difficulties when the face is angled away from the
camera. These factors cause low recognition. To solve these problems a computer
company has developed a 3D face recognition system [2][3]. To obtain a 3D face, this
method uses stereo matching, laser scanner, etc. Stereo matching extracts 3D information from the disparity of 2 pictures which are taken by 2 cameras. Even though it can
extract 3D information from near and far away, it has many difficulties in practical
use because of its low precision. 3D laser scanners extract more accurate depth information about the face, and because it uses a filter and a laser, it has the advantage of
not being influence by the lighting illuminance when it is angled away from the camV.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 862 – 869, 2006.
© Springer-Verlag Berlin Heidelberg 2006

Soft Computing Based Range Facial Recognition Using Eigenface

863

era. A laser scanner can measure the distance, therefore, a 3D face image can be reduced by a scaling effect that is caused by the distance between the face and the camera [4][5].
Broadly speaking the two ways to establish recognition employs the face feature
based approach and the area based approach [5]-[8]. A feature based approach uses
feature vectors which are extracted from within the image as a recognition parameter. An area based approach extracts a special area from the face and recognizes it
using the relationship and minimum sum of squared difference. Face recognition research usually uses 2 dimensional images. Recently, the 3D system becomes
cheaper, smaller and faster to process than it used to be. Thus the use of 3D face
image is now being more readily researched [3][9]-[12]. Many researchers have
used 3D face recognition using differential geometry tools for the computation of
curvature [9]. Hiromi et al. [10] treated 3D shape recognition problem of rigid freeform surfaces. Each face in the input images and model database is represented as
an Extended Gaussian Image (EGI), constructed by mapping principal curvatures
and their directions. Gordon [11] presented a study of face recognition based on
depth and curvature features. To find face specific descriptors, he used the curvatures of the face. Comparison of the two faces was made based on the relationship
between the spacing of the features. Lee and Milios [13] extracted the convex regions of the face by segmenting the range of the images based on the sign of the
mean and Gaussian curvature at each point. For each of these convex regions, the
Extended Gaussian Image (EGI) was extracted and then used to match the facial
features of the two face images.
One of the most successful techniques of face recognition as statistical method is
principal component analysis (PCA), and specifically eigenfaces [14][15]. In this paper, we introduce novel face recognition for eigenfaces using the curvature that well
presenting personal characteristics and reducing dimensional spaces. Moreover, the
normalized facial images are considered to improve the recognition rate.
Neural networks (NNs) have been successfully applied to face recognition problems [16]. However, the complexity of the NNs increases exponentially with the parameter values, i.e. input number, output number, hidden neuron number, etc., and
becomes unmanageable [17]. To overcome this curse of dimensionality, the cascade
architectures of fuzzy neural networks (CAFNNs), constructed by the memetic algorithms (hybrid genetic algorithms) [18], are applied to this problem.

2 Face Normalization
The nose is protruded shape and located in the middle of the face. So it can be used as
the reference point, firstly we tried to find the nose tip using the iterative selection
method, after extraction of the face from the 3D face image [20]. Usually, face recognition systems suffer drastic losses in performance when the face is not correctly oriented. The normalization process proposed here is a sequential procedure that aims to
put the face shapes in a standard spatial position. The processing sequence is panning,
rotation and tilting [21].

864

Y.-H. Lee, C.-W. Han, and T.-S. Kim

3 Surface Curvatures
For each data point on the facial surface, the principal, Gaussian and mean curvatures
are calculated and the signs of those (positive, negative and zero) are used to determine the surface type at every point. The z(x, y) image represents a surface where the
individual Z-values are surface depth information. Here, x and y is the two spatial coordinates. We now closely follow the formalism introduced by Peet and Sahota [19],
and specify any point on the surface by its position vector:

R( x, y) = xi + yj + z ( x, y )k

(1)

The first fundamental form of the surface is the expression for the element of arc
length of curves on the surface which pass through the point under consideration. It is
given by:

I = ds 2 = dR ⋅ dR = Edx 2 + 2 Fdxdy + Gdy 2

(2)

where

∂z ∂z
⎛ ∂z ⎞
E = 1+ ⎜ ⎟ , F =
,
∂x ∂y
⎝ ∂x ⎠
2

⎛ ∂z ⎞
G = 1 + ⎜⎜ ⎟⎟
⎝ ∂y ⎠

2

(3)

The second fundamental form arises from the curvature of these curves at the point of
interest and in the given direction:

II = edx 2 + 2 fdxdy + gdy 2

(4)

where

e=

∂2 z
Δ,
∂x 2

f =

∂2z
Δ,
∂x∂y

g=

∂2 z
Δ
∂y 2

(5)

and

Δ = ( EG − F 2 ) −1 / 2

(6)

Casting the above expression into matrix form with;

⎛ dx ⎞
V = ⎜⎜ ⎟⎟ ,
⎝ dy ⎠

⎛E F⎞
⎟⎟ ,
A = ⎜⎜
⎝F G⎠

⎛e
B = ⎜⎜
⎝f

f⎞
⎟
g ⎟⎠

(7)

the two fundamental forms become:

I = V t AV I = V t BV

(8)

Then the curvature of the surface in the direction defined by V is given by:

k=

V t BV
V t AV

(9)

Soft Computing Based Range Facial Recognition Using Eigenface

865

Extreme values of k are given by the solution to the eigenvalue problem:

( B − kA)V = 0

(10)

or

e − kE

f − kF

f − kF

g − kG

=0

(11)

which gives the following expressions for k1 and k2, the minimum and maximum curvatures, respectively:

k1 = {gE − 2 Ff + Ge − [( gE + Ge − 2 Ff ) 2

− 4(eg − f 2 )( EG − F 2 )]1/ 2 }/ 2( EG − F 2 )

k 2 = {gE − 2 Ff + Ge + [( gE + Ge − 2Ff ) 2

− 4(eg − f 2 )( EG − F 2 )]1/ 2 }/ 2( EG − F 2 )

(12)

(13)

Here we have ignored the directional information related to k1 and k2, and chosen
k2 to be the larger of the two. For the present work, however, this has not been done.
The two quantities, k1 and k2, are invariant under rigid motions of the surface. This is
a desirable property for us since the cell nuclei have no predefined orientation on the
slide (the x – y plane).
The Gaussian curvature K and the mean curvature M is defined by

K = k1k2 , M = (k1k2 ) / 2

(14)

which gives k1 and k2, the minimum and maximum curvatures, respectively. It turns
out that the principal curvatures, k1 and k2, and Gaussian are best suited to the detailed
characterization for the facial surface, as illustrated in Fig. 1. For the simple facet
model of second order polynomial of the form, i.e. a 3 by 3 window implementation
in our range images, the local region around the surface is approximated by a quadric
z ( x, y ) = a00 + a10 x + a01 y + a01 y + a20 x 2 + a02 y 2 + a11 xy

(15)

and the practical calculation of principal and Gaussian curvatures is extremely simple.

4 Eigenface
4.1 Computing Eigenfaces [14]

Consider face images of size N by N, extracted contour line value. These images can
be thought as a vector of dimension N2, or a point in N2 – dimensional space. A set of
images, therefore, corresponds to a set of points in this high dimensional space. Since
facial images are similar in structure, these points will not be randomly distributed,
and therefore can be described by a lower dimensional subspace. Principal component
analysis gives the basis vectors for this subspace. Each basis vector is of length N2,
and is the eigenvector of covariance matrix corresponding to the original face images.

866

Y.-H. Lee, C.-W. Han, and T.-S. Kim

(a)

(b)

(c)

(d)

(e)

(f)

Fig. 1. Six possible surface type according to the sign of principal curvatures for the face surface; (a) concave (pit), (b) convex (peak), (c) convex saddle, (d) concave saddle, (e) minimal
surface, (f) plane

Let Γ1 , Γ2 , …, ΓM be the training set of face images. The average face is defined
by
Ψ=

1
M

M

∑Γ

(16)

n

n =1

Each face differs from the average face by the vector Φi = Γn − Ψ . The covariance
matrix

C=

1
M

M

∑Φ Φ
n =1

n

T
n

(17)

has a dimension of N2 x N2 . Determining the eigenvectors of C for typical size of N
is intractable task. Once the eigenfaces are created, identification becomes a pattern
recognition task. Fortunately, we determine the eigenvectors by solving an M by M
matrix instead.
4.2 Identification

The eigenfaces span an M-dimensional subspace of the original N2 image space. The
M significant eigenvectors are chosen as those with the largest corresponding eigenvalues. A test face image Γ is projected into face space by the following operation:
ω n = u nT (Γ − Ψ) , for n=1, …, M, where un is the eigenvectors for C. The weights ωn
from a vector Ω T = [ω1 ω 2 . . . ω M ' ] which describes the contribution of each eigenface
in representing the input face image. This vector can then be used to fit the test image
to a predefined face class. A simple technique is to use the Euclidian distance ε n = Ω − Ω n , where Ω n describes the nth face class. In this paper, we used the
cascade architectures of fuzzy neural networks to compare with the distance as described next chapter.

5 Cascade Architectures of Fuzzy Neural Networks (CAFNNs)
As originally introduced in [17], the structure of the CAFNNs is the cascade combination of the logic processors (LPs) which consist of fuzzy neurons. The sequence of
relevant input subset and the connections were optimized by memetic algorithms in
[18] to construct parsimonious knowledge base, but accurate one. As illustrated in
[18], the memetic algorithms are more effective than the optimization scenario in

Soft Computing Based Range Facial Recognition Using Eigenface

867

[17]. Therefore, the optimization scenario in [18] will be considered in this approach.
For more details about the CAFNNs and its optimization, please refer to [17][18].
To apply the CAFNNs to classification problems, the output (class) should be
fuzzified as binary. For example, if we assume that there are 5 classes (5 persons) in
the data sets, the number of output crisp set should be 5 that are distributed uniformly.
If the person belongs to the 2nd-class, the Boolean output can be discretized as “0 1 0
0 0”. In this classification problem, the winner-take-all method is used to decide the
class of the testing data set. This means that the testing data are classified as the class
which has the biggest membership degree.

6 Experimental Results
In this study, we used a 3D laser scanner made by a 4D culture to obtain a 3D face
image. First, a laser line beam was used to strip the face for 3 seconds, thereby obtaining a laser profile image, that is, 180 pieces and no glasses. The obtained image size
was extracted by using the extraction algorithm of line of center, which is 640 by 480.
Next, calibration was performed in order to process the height value, resampling and
interpolation. Finally, the 3D face images for this experiment were extracted, at 320
by 320. A database is used to compare the different strategies and is composed of 92
images (two images of 46 persons). Of the two pictures available, the second photos
were taken at a time interval of 30 minutes.
Table 1. The comparison of the recognition rate (%)

k1

k2

Best1

Best5

Best10

Best15

CAFNN( normalized)

64.5

78.4

89.6

95.9

CAFNN

56.2

73.9

85.2

90.5

k-NN

42.9

57.1

66.7

66.7

CAFNN (normalized)

68.1

86.4

90.1

96.3

CAFNN

63.7

80.3

85.8

90.1

k-NN

61.9

78.5

83.3

88.1

From these 3D face images, finding the nose tip point, using contour line threshold
values (for which the fiducial point is nose tip), we extract images around the nose
area. To perform recognition experiments for extracted area we first need to create
two sets of images, i.e. training and testing. For each of the two views, 46 normalexpression images were used as the training set. Training images were used to generate an orthogonal basis, as described in section 3, into which each 3D image in training data set is projected in section 4. Testing images are a set of 3D images extracted
local area we wish to identify.

868

Y.-H. Lee, C.-W. Han, and T.-S. Kim

Once the data sets have been extracted with the aid of eigenface, the development
procedure of the CAFNNs should be followed for the face recognition. The used parameter values are the same as [18]. Since a genetic algorithm is a stochastic optimization method, ten times independent simulations were performed to compare the results with the conventional classification methods, as described in Table 1 and Fig. 2.
In Table 1 and Fig. 2, the results of the CAFNN are averaged over ten times independent simulations, and subsequently compared with the results of the conventional
method (k-nearest neighborhood: k-NN). Also, the normalized facial images were
considered to generate the curvature-based data set. As can be seen from Table 1 and
Fig. 2, the recognition rate is improved by using normalized facial images.
k1

100

90

Recognition rate (%)

90

Recognition rate (%)

k2

100

80

70

60

CAFNN (normalized)
CAFNN
k-NN

50

40

80

70

60

CAFNN (normalized)
CAFNN
k-NN

50

40
0

5

10

Ranked best

15

0

5

10

15

Ranked best

Fig. 2. The recognition results using eigenfaces for each area: (a) k1, (b) k2

7 Conclusions
The surface curvatures extracted from the face contain the most important personal
facial information. We have introduced, in this paper, a new practical implementation
of a person verification system using the local shape of 3D face images based on eigenfaces and CAFNNs. The underlying motivations for our approach originate from
the observation that the curvature of face has different characteristic for each person.
We found the exact nose tip point by using an iterative selection method. The lowdimensional eigenfaces represented were robust for the local area of the face. The
normalized facial images were also considered to improve the recognition rate. To
classify the faces, the CAFNNs were used. The CAFNNs have reduced the dimensionality problem by selecting the most relevant input subspaces too. Experimental
results on a group of face images (92 images) demonstrated that our approach produces excellent recognition results for the local eigenfaces.
From the experimental results, we proved that the process of face recognition may
use low dimension, less parameters, calculations and less same person images (used
only two) than earlier suggested. We consider that there are many future experiments
that could be done to extend this study.

Soft Computing Based Range Facial Recognition Using Eigenface

869

References
1. Jain, L. C., Halici, U., Hayashi, I., Lee, S. B.: Intelligent Biometric Techniques in Fingerprint and Face Recognition. CRC Press (1999)
2. 4D Culture. http://www.4dculture.com
3. Cyberware. http://www.cyberware.com
4. Chellapa, R., et al.: Human and Machine Recognition of Faces: A Survey. UMCP CS-TR3399 (1994)
5. Hallinan, P. L., Gordon, G. G., Yuille, A. L., Giblin, P., Mumford, D.: Two and Three
Dimensional Pattern of the Face. A K Peters Ltd. (1999)
6. Grob, M.: Visual Computing. Springer Verlag (1994)
7. Nikolaidis, A., Pitas, I.: Facial Feature Extraction and Pose Determination. Pattern Recognition 33 (2000) 1783-1791
8. Moghaddam, B., Jebara, T., Pentland, A.: Bayesian Face Recognition. Pattern Recognition
33 (2000) 1771-1782
9. Chua, C. S., Han, F., Ho, Y. K.: 3D Human Face Recognition using Point Signature. Proc.
of the 4th ICAFGR (2000)
10. Tanaka, H. T., Ikeda, M., Chiaki, H.: Curvature-based Face Surface Recognition using
Spherial Correlation. Proc. of the 3rd IEEE Int. Conf. on Automatic Face and Gesture Recognition (1998) 372-377
11. Gordon, G. G.: Face Recognition based on Depth and Curvature Feature. Proc. of the
IEEE Computer Society Conf. on Computer Vision and Pattern Recognition (1992) 808810
12. Chellapa, R., Wilson, C. L., Sirohey, S.: Human and Machine Recognition of Faces: A
survey. Proceedings of the IEEE 83(5) (1995) 705-740
13. Lee, J. C., Milios, E.: Matching Range Image of Human Faces. Proc. of the 3rd Int. Conf.
on Computer Vision (1990) 722-726
14. Turk, M., Pentland, A.: Eigenfaces for Recognition. Journal of Cognitive Neuroscience
3(1) (1991) 71-86
15. Hesher, C., Srivastava, A., Erlebacher, G.: Principal Component Analysis of Range Images for Facial Recognition. Proc. of CISST (2002)
16. Zhao, Z. Q., Huang, D. S., Sun, B. Y.: Human Face Recognition based on Multi-features
using Neural Networks Committee. Pattern Recognition Letters 25 (2004) 1351-1358
17. Pedrycz, W., Reformat, M., Han, C. W.: Cascade Architectures of Fuzzy Neural Networks.
Fuzzy Optimization and Decision Making, 3 (2004) 5-37
18. Han, C. W., Pedrycz, W.: A New Genetic Optimization Method and Its Applications. submitted to International Journal of Approximate Reasoning
19. Peet, F. G., Sahota, T. S.: Surface Curvature as a Measure of Image Texture. IEEE Trans.
PAMI 7(6) (1985) 734-738
20. Lee, Y., Park, G., Shim, J., Yi, T.: Face Recognition from 3D Face Profile using Hausdorff
Distance. Proc. of PRIA-6-2002 (2002)
21. Lee, Y.: 3D Face Recognition using Longitudinal Section and Transection. Proc. of
DICTA-2003 (2003)

