Evolutionary Spatial Games Under Stress
J. Alonso1 , A. Fern´
andez1 , and H. Fort2
1

2

Universidad de la Rep´
ublica, Institute of Physics, Facultad de Ingenier´ıa, Julio
Herrera y Reissig 565, 11300 Montevideo, Uruguay
Universidad de la Rep´
ublica, Institute of Physics, Facultad de Ciencias, Igu´
a 4225,
11400 Montevideo, Uruguay

Abstract. We analyse diﬀerent evolutionary spatial games, in which
the pressure of the environment is taken into account, using binary cellular automata. The agents are unconditional players: at each time step
a given cell cooperates (play C) or defects (play D) against all its neighbours. The pressure of the environment is implemented by requiring a
minimum score Umin , representing indispensable resources (nutrients, energy, revenues, etc.) for an individual to prosper. Therefore a cell, instead
of evolving just by adopting the state of its most successful neighbour,
also takes into account if the ”winner” gets a score above or below Umin .
In the latter case it has a probability of adopting the opposite state. Besides the paradigmatic and widely used Prisoner’s Dilemma (PD), two
other games are analysed: the Hawk-Dove (H-D), popular in biology, and
the Stag Hunt (SH) that recently came into favour in social sciences. The
eﬀect of the environmental stress is particularly dramatic in the case of
the PD: it allows the evolution of cooperation for payoﬀ matrices where
defection was the rule for simple unconditional strategy players. Finally,
we discuss a more sophisticated model version in which the ordinary
evolutionary recipe of copying the most successful neighbour is supplemented with a ”win-stay, lose-shift” criterion. This model variant, for a
restricted region of the parameter space, produces critical scaling laws.

1

Introduction

Cooperation and competition in nature represent two faces of a same coin.
Progress seems to need both: competition promotes eﬃciency at the individual level but cooperation is indispensable to achieve collective goals.
Game theory is a branch of mathematics concerned with the analysis of conﬂict situations. Social dilemma games demonstrated to be a suitable approach
to describe this tension between individual and global interests in social sciences
[1] as well in biology [2].
In social dilemma games each individual (“player”) receives a higher payoﬀ
for a socially defecting choice than for a socially cooperative choice no matter
what the other individuals in society do. But, at the same time, all individuals
would be better oﬀ if all cooperate than if all defect. The most popular of such
games is the Prisoner’s Dilemma (PD) [3]. Imagine two players, each confronting
two choices: cooperate (C) or defect (D), and each makes his choice without
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part III, LNCS 3993, pp. 313–320, 2006.
c Springer-Verlag Berlin Heidelberg 2006

314

J. Alonso, A. Fern´
andez, and H. Fort

knowing what the opponent will do. The possible outcomes are: 1) they can
both cooperate: (C,C) and get the ”reward” for mutual cooperation R, 2) they
can both defect: (D,D) and get the ”punishment” P for mutual defection or 3)
one of them cooperates and the other defects: (C,D); in that case the one who
played C gets the ”sucker’s payoﬀ” S while his opponent gets the ”temptation
to defect” T . Hence we have a 2 × 2 payoﬀ matrix with the payoﬀs obeying the
chain of inequalities T > R > P > S. So independently of what the other player
does, defection D yields a higher payoﬀ than cooperation C: if your opponent
defects, and you cooperate you will end up with the worst payoﬀ. On the other
hand, even if your opponent cooperates, you should defect because in that case
your payoﬀ is T which is higher than R. Nevertheless, playing both D they get
P which is worst than R.
A more interesting situation arises when the game is played repeatedly. In
this iterated Prisoner’s Dilemma (IPD), if players have memory (at least from
the immediately previous contest), there are several strategies that outperform
the dominant one-shot strategy [D,D] and lead to some non-null degree of cooperation. For instance, in the strategic tournaments organised by Axelrod [1],
[4] in the 80s, the winner strategy was ’TIT FOR TAT’ (TFT), which plays C
on the ﬁrst move, and on all subsequent moves copy the choice of its opponent
on the previous move. Afterwards a diﬀerent computer tournament was carried
out by Nowak and Sigmund [6]. In that case the winner strategy was the one
previously named simpleton by Rapoport and Chammah [7] or Pavlov by D. and
V. Kraines [8], because if its action result in a high payoﬀ (T or R) it keeps it,
but otherwise changes it.
On the other hand, territoriality by itself provides an alternative way to escape from iterated evolutionary game dilemmas without resorting to memory
of past encounters conditioning the behaviour, which are conditional strategies
(like TFT, Pavlov, etc.). This was shown by Nowak and May [9] who proposed a
cellular automaton in which agents are binary unconditional strategists, that is:
at each time step a given cell play versus all of their neighbours either C or D.
In the next generation, a given cell adopts the state of the most successful cell of
the neighbourhood (the one that collected the highest score among the cell itself
and its neighbours). The game they considered is a simpliﬁed version of the PD
in which the punishment P and the sucker’s payoﬀ S are equal 1 , implying then a
”weak dilemma” (maximum punishment for mutual defection). Speciﬁcally they
ﬁxed R=1 and P =S=0 and found that the fraction of cooperators c varies from
1 to 0 as the temptation increases from T =1 to T =2. However, a problem with
this simple model is that c drops to zero for ordinary non weak dilemmas in
which all the individuals end playing D.
In the present work we propose a simple extension of the unconditional binary C.A. that allows the evolution of cooperation not just for weak dilemmas
but for ordinary ones, where P and S can be quite diﬀerent. The basic idea is
that individuals need to collect, when playing with their z neighbours, a score
1

Indeed this game is the frontier between the PD and the game known as chicken
(see below).

Evolutionary Spatial Games Under Stress

315

above certain threshold Umin in order to prosper. In an ecosystem Umin represents the minimal resources (nutrients, energy, etc.) for surviving, alternatively,
in markets it may represent the minimum revenues that make investments profitable. Provided the diﬀerence between P and S is suﬃciently large, defecting
individuals are on average the most successful in the ﬁrst rounds. Nevertheless,
if Umin > zP , they perform very poorly when surrounded by an entire neighbourhood of D’s (something that in the real world this may be equivalent to
death). Therefore we include a probability p of adopting the state opposite to
the one of the most successful neighbour when its score is below Umin .
In order to minimise the number of model parameters we use a two-parameter
payoﬀ matrix and we ﬁx the worst payoﬀ X (4) to 0 and the second best X (2) to
1 (for example S = 0 and R = 1 for the PD). We explore a subspace of the space
of parameters {T, P, Umin , p} characterising the PD and measure the asymptotic
(after a transient) fraction of cooperators. Furthermore, changing the rank order
of the 4 payoﬀs we explore two other dilemma games. First, when the damage
from mutual defection in the PD is increased so that it ﬁnally exceeds the damage
suﬀered by being exploited, i.e. T > R > S > P , the new game is called the
chicken or Hawk-Dove (H-D) game [2]. The ’Hawk’ and ’Dove’ allude to the two
alternative behaviours displayed by animals in confrontation: hawks are expected
to ﬁght for a resource and will injure or kill their opponents (i.e. play D), doves,
on the other hand, only bluﬀ and do not engage in ﬁghts to the death (i.e. play
C). This game applies thus to situations such that mutual defection (Hawk vs.
Hawk) is the worst possible outcome for both as it happens in most of animal
contests. Second, a nowadays popular game in social sciences is the Stag Hunt
[10], corresponding to the payoﬀs rank order R > T > P > S i.e. when the
reward for mutual cooperation surpasses the temptation to defect. The name
of the game derives from a metaphor invented by the French philosopher Jean
Jacques Rousseau: Two hunters can either jointly hunt a stag or individually hunt
a rabbit. Hunting stags is quite challenging and requires mutual cooperation. If
either of them hunts a stag alone, the chance of success is minimal. Hunting
stags is most beneﬁcial for society but requires trust among its members.

2

The Model

The individuals (people, ﬁrms, bacteria, etc.) are represented by cells of a twodimensional binary cellular automaton (CA). That is, each cell can take two
possible values 0 or 1 corresponding to unconditional strategies for playing versus
their neighbours: cooperate (C) or defect (D).
In this work we restrict ourselves to a) the von Neumann neighbourhood (z = 4
neighbouring cells: the cell above and below, right and left from a given cell) and
b) the Moore neighbourhood (z = 8 neighbouring cells surrounding a given cell).
Typical grid sizes range from 50 × 50 to 500 × 500. Periodic boundary conditions
are used. The score of a given player is the sum of all the payoﬀs he gets against
each neighbour. The dynamic is synchronous: all the agents update their states
simultaneously at the end of each CA-step.

316

J. Alonso, A. Fern´
andez, and H. Fort

In the CA of Ref. [9] natural selection is implemented very simply: each player
adopts the strategy of the most successful neighbour (who got U msn ). Here, we
consider the following modiﬁed evolutionary rule: If U msn > Umin , then the
player adopts the strategy of the most successful neighbour in the next generation. Otherwise, the player has a small probability p of adopting the opposite
strategy. The rationale for this is that copying the most successful neighbour,
when its payoﬀ doesn’t reach a critical threshold, may not be the most eﬃcient
strategy from an evolutionary point of view.

3

Results

After a transient the system reaches a steady state with a deﬁnite value c for
the fraction of agents playing C. The duration of the transient depends on the
lattice size and the neighbourhood. For instance for a 50 × 50 lattice and z = 8
it last typically between 100 and 200 rounds.
To avoid dependence on the initial conditions, the measures correspond to
averages over an ensemble of 100 systems 2 with arbitrary conditions.
Here, we present results for a subspace of the parameter space: the third best
payoﬀ is ﬁxed to X (3) =0.5. This value is chosen such that in the case of the PD,
a punishment of P =0.5 implies, without any doubt, a non weak dilemma 3 . We
studied several values of the probability parameter and the ones reported here
are always for p = 0.1. The best payoﬀ X (1) is varied between 1 and 2. Finally,
since Umin < zX (3) has no eﬀects and Umin > zX (1) doesn’t make sense (since
no one can reach this threshold), the parameter space reduces to the square
plane X (1) − Umin delimited by 1 ≤ X (1) ≤ 2 and zX (3) ≤ Umin ≤ zX (1) .
3.1

Prisoner’s Dilemma: S=0, P =0.5, R=1 and 1<T≤2

Figs. 1.a and 1.b show c as a function of T and Umin . Basically three regions
can be distinguished in the plots: i) A stepladder region emerges from the right
border Umin = zP . ii) For not too large values of T and Umin there is a high
peak of cooperation, delimited at the left by Umin = zR=z (when all the cells
play C). iii) Finally, beyond Umin =zR=z c reaches a plateau delimited by the
straight line Umin (T )=zT .
To understand the 3 diﬀerent regions it is convenient to consider a small
deviation from the minimum T : T = 1 + . Therefore, for z = 8 and P = 0.5
Table 1 summarises the diﬀerent payoﬀs for a player depending on the number
of C’s and D’s in its neighbourhood.
Let’s start with the peak. For Umin greater than 6, only D’s surrounded by at
least 4 C’s can achieve the minimum Umin , so cooperation grows dramatically.
This corresponds to <
∼ 0.16, (i.e. T <
∼ 1.16). If Umin = 8 then c drops abruptly
since even C agents surrounded entirely by other C’s cannot survive anymore.
2
3

The relative error in these averages is about 7 percent.
Both for z=4 or z=8, P =0.5 leads to c=0 when simulating the model of Ref. [9].

Evolutionary Spatial Games Under Stress

317

Table 1. Score of a player depending on its state C or D and the number of C and D
agents in its z = 8 neighbourhood for T =1+ and P =0.5
8C, 0D 7C, 1D 6C, 2D 5C, 3D 4C, 4D 3C, 5D 2C, 6D 1C, 7D 0C, 8D
C
8
7
6
5
4
3
2
1
0
D 8.0 + 8 7.5 + 7 7.0 + 6 6.5 + 5 6.0 + 4 5.5 + 3 5 + 2 4.5 +
4

Fig. 1. Fraction of cooperators for p = 0.1: (a) z=4 neighbours and (b) z=8 neighbours

The stepladder structure can be easily explained considering the payoﬀ values
for D agents. As long as Umin increases each D agent needs more C agents in its
surroundings in order to achieve this threshold. So cooperation grows with Umin
by steps at the values: Umin =T +7P =4.5+ , Umin =2T +6P =5+2 and so on,
which correspond to straight lines with diﬀerent slopes in the (T, Umin ) plane .
Finally, when Umin > 8T the minimum required is above any agent’s possible
score, then the fraction of agents C one time step further will be given by
c(t + 1) = pfD + (1 − p)fC ,

(1)

where fD (fC ) stands for the fraction of agents whose most successful neighbour is a D (C). As none of the agents achieves the threshold, everyone with
probability p adopts a state opposite to the one adopted by the most successful
neighbour. For relatively small values of p, fC ≈ 0 i.e. fD ≈ 1 and thus from (1)
c ≈ p. This explains why the height of the plateau coincides with p .
3.2

Hawk-Dove: P =0, S=0.5, R=1, 1< T ≤2 and Stag Hunt: S=0,
P =0.5, T =1, 1< R ≤2

Let’s brieﬂy review what happens for these other two games. In Fig. 2.a we
observe a qualitatively similar 3d plot for c in the case of the H-D. There is a
peak in the same place although thicker. On the other hand the SH (see Fig. 2.b)
is a much more cooperative than the PD and the threshold has no drastic eﬀects
except when R is close to 1. In that case, once again, there are some intermediate
values of Umin that optimise c.

318

J. Alonso, A. Fern´
andez, and H. Fort

Fig. 2. Fraction of cooperators c for z=8 & p=0.1.(a) H-D (b) SH.

Fig. 3. c for the PD hybrid variant (p=0.1). (a) z=4 neighbours and (b) z=8 neighbours.

3.3

Hybrid Version: Natural Selection Complemented with a
Pavlovian Criterion

A relevant input for the behaviour update rule is the comparison of the individual’s score with Umin . If it is above Umin then the agent’s behaviour may
be worth keeping even if it is not the most successful neighbour msn. Then we
implement this variant as follows: If the cells’s score is above Umin it copies the
state of the msn with probability p (or equivalently remains in its state with
probability 1 − p). If the cells’s score is below Umin there are two alternatives:
If U msn > Umin (U msn < Umin ) the cell copies the state of the msn (opposite
of the msn) with probability 1 − p or remains in its state with probability p.
Therefore, this variant interpolates between the ordinary evolutionary recipe
of copying the msn and the ”win-stay, lose-shift” criterion analysed in detail by
Herz [11].
The main modiﬁcations in the ”landscape” are shown in Fig. 3. Firstly, a
strong increase in c, for all the parameter space surrounding the peak zone, is
observed. Secondly, most part of the plateau is replaced by steep ”cliﬀs”.

Evolutionary Spatial Games Under Stress

3.4

319

Cluster Structure

Spatial patterns were studied for the three games. The most important result
deals with the cluster structure of C agents. It turns out that the PD hybrid
model variant exhibits power-law scaling for a very reduced region in the plane
T − Umin in the vicinity of the point [T = 1.6, Umin = 7.5] 4 . The corresponding
histogram of size distribution of clusters is shown in Fig. 4 and ﬁts well with a
power law with exponent −1.6357 ± 0.0001. Power laws are the signature of spatial organization of processes into a critical state without any dominating scale.
−1

10

−2

10

−3

10

frequency

−4

10

−5

10

−6

10

−7

10

−8

10

−9

10

0

10

1

10

2

10

3

10

4

10

5

10

cluster size

Fig. 4. Dependence of the number of C clusters with size (in logarithmic scale) for the
PD hybrid variant for T = 1.6, Umin = 7.5 (p = 0.1). (500 × 500 lattice)

4

Discussion

We extended a simple CA model to include, besides space and time (repetition),
the inﬂuence of the environment exerting pressure on individuals to cooperate.
This is done by requiring a minimum score Umin necessary for agents to carry
on vital functions.
This recipe gives rise to cooperation among self-interested individuals from
evolution in diﬀerent dilemma games, involving quite arbitrary payoﬀ matrices.
Since we resort to the simplest possible agents - unconditional strategists without
long term memory - this allows a potential applicability of the model to a wide
variety of contexts from virus (recent experiments indicate that RNA virus may
engage in simple two-player games [12]) to social sciences problems.
It is remarkable that, for moderate values of the best payoﬀ, there is an
intermediate range of values of Umin that produces a jump in the cooperation
for all the three games analysed.
Finally, we introduced and studied a more complex model in which the ordinary evolutionary recipe, of copying the most successful neighbour, is supplemented with a Pavlovian ”win-stay, lose-shift” criterion. Besides leading to global
4

The H-D and SH or the basic PD variant don’t give rise to power-laws.

320

J. Alonso, A. Fern´
andez, and H. Fort

optimisation (a much higher cooperation level), this gives rise to power-laws in
the size distribution of C-agent clusters. This critical scaling was already found
in a diﬀerent study of CA playing the PD game with Pavlovian strategies [13].

References
1. Axelrod, R. in: The Evolution of Cooperation, (Basic Books, New York, 1984);
2. Maynard-Smith, J.: Evolution and the Theory of Games, (Cambridge Univ. Press
1982).
3. Flood, M. : Some Experimental Games, Research Memorandum (RAND), RM-789
(1952).
4. Axelrod, R. and Hamilton, W. D. : The evolution of cooperation. Science 211
(1981) 1390-1396
5. Axelrod, R. : J. of Conﬂict Resolution 24 (1980) 379.
6. Nowak, M.A. and Sigmund, K. : A strategy of win-stay, lose-shift that outperforms
tit for tat in Prisoner’s Dilemma, Nature 364 (1993) 56-59.
7. Rapoport, A. and Chammah, A.M. :, Prisoner’s Dilemma (The University of Michigan Press 1965) pp. 73-74.
8. Kraines, D. and Kraines, V. : Pavlov and the Prisoner’s Dilemma, Theory Decision
26 (1988) 47-79.
9. Nowak, M.A. and May, R. : Evolutionary Games and Spatial Chaos, Nature 359
(1992) 826-28.
10. Skyrms, B. :The Stag Hunt and the Evolution of Social Structure, Cambridge University Press 2004.
11. Herz, A.V.M. : Collective Phenomena in Spatially Extended Evolutionary Games,
J. Theor. Biol. 169 (1994) 65-87.
12. Turner, P.E. and Chao, L. : Prisoners Dilemma in an RNA Virus, Nature 398
(1999) 441-443.
13. Fort, H. and Viola, S. : Spatial patterns and scale freedom in Prisoner’s Dilemma
cellular automata with Pavlovian strategies, J. Stat. Mech. (2005) P01010.

