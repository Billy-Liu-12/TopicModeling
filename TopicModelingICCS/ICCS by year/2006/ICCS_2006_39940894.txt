Patient Modeling Using Mind Mapping Representation
as a part of Nursing Care Plan*
Hye-Young Ahn1, Eunja Yeon2, Eunmi Ham2, and Woojin Paik3,**
1
Dept. of Nursing, Eulji University,
143-5 Yongdoo-dong, Jung-gu, Daejeon, 301-832, Korea
ahanaya@eulji.ac.kr
2
Dept. of Nursing Science
3 Dept of Computer Science, Konkuk University,
322 Danwol-Dong, Chungju-Si, Chungcheongbuk-Do, 380-701, Korea
{eunice, hem2003, wjpaik}@kku.ac.kr

Abstract. Nursing care plan reports are one of the most important documents in
the application of nursing processes. In this paper, we describe how a text discourse analysis and an information extraction system can be used to convert a
traditional nursing care plan into a mind mapping representation. Mind mapping
is a process to allow the nurses to focus on the patients rather than on a disease
process. Mind mapping encourages the nurses to maintain a holistic view of the
patient. A mind mapping representation refers to a visual picture of a patient at
the center with various nursing care related information visually linked to the
patient’s form. Our goal is to develop visually browsable models of the patients
to aid in the nursing process education and also help the nurses focus on the patients in the actual care settings.

1 Motivation: Information Extraction from Nursing Care Plan
According to North American Nursing Diagnosis Association (NANDA), a nursing
diagnosis is defined as a critical judgment about individual, family, or community
responses to actual or potential health problems or life processes. The goal of a nursing diagnosis is to identify health problems of the patient and his/her family. A diagnosis provides a direction for the following nursing care [1]. The nursing care plan as
the repositories of knowledge involved in the overall nursing process, which leads up
to the nursing diagnosis [2].
A complementary approach to the traditional tabular and narrative based nursing
care plan is referred as mind mapping [3]. A mind map is designed to move away
from the linear nature of the traditional nursing plan. A mind map is a graphical representation of the connection between concepts and ides that are related to a patient.
From the patient representation placed in the middle, associated information, such as
nursing diagnosis, expected outcome, suggested interventions, observation summaries, and the evaluation by the nurses, are grouped the linked to the patient. A mind
*
**

This paper was supported by Konkuk University in 2005.
Corresponding author.

V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 894 – 901, 2006.
© Springer-Verlag Berlin Heidelberg 2006

Patient Modeling Using Mind Mapping Representation

895

map is for the nurses to develop a whole patient picture that is comprised of a variety
of information, which are related to the identified patient problems. A mind map is
used to reflect how nurses in practices truly think.
Our text preprocessing program first identifies and extracts the nursing diagnoses,
outcomes, and interventions, which are usually in a table. This process is fairly
straightforward as each component is placed under clear descriptive heading. However, extracting observed information summaries about the patients and the evaluations by the nurses is difficult. The main focus of the research in this paper is about
the extracting the summary and evaluation information in the narrative portion of the
nursing care plans. Our text discourse analysis program classifies each clause in the
narrative portions of the care plan according to eight categories. When the classification is completed, the semantic relation extraction program identifies the summary
and evaluation pairs, which are linked by a causal relation. Then, the causally linked
summary and evaluation pairs will become a part of the mind map visual representation. The mind map will be used as a teaching aid for the novice nurses to learn how
to evaluate and represent the patient conditions.

2 Classifying Clauses in Nursing Care Plan Narratives According
to a Nursing Process Text Discourse Model
A text discourse model specifies the necessary classes of knowledge to be identified
in order to develop the skeletal conceptual structure for a class of entities. Based on a
discourse linguistics observation [4], writers are often influenced by the schema of a
particular text type if they produce texts of that type repeatedly. This means that the
writers consider both specific content they wish to convey and usual structure for that
type of text on the basis of the purpose it is intended to serve.
The existence of such predictable structures in texts is consistent with findings in
cognitive psychology which suggest that human cognitive processes are facilitated by
the ability to ‘chunk’ the vast amount of information encountered in daily life into
larger units of organized data [5]. Based on schema theories, humans recode individual units of perception into increasingly larger units, which will eventually reach at
the level of a schema. It has also been argued that humans possess schema for a wide
range of concepts, events, and situations [6]. In discourse linguistics, this schema
theory was extended to suggest that schema exist for text-types that participate regularly in the shared communication of a particular community of users.
As the text structure of a particular text type is discovered, the text’s discernible
and predictable superstructure is also revealed. Superstructure is defined as the textlevel syntactic organization of semantic content. It can be also referred to as the
global schematic structure or the recognizable template that is filled with different
meaning in each particular example of that text type [7]. Some of the text types for
which schemas or models have been developed with varying degree of details are:
newspaper articles [7, 11], arguments [8], editorials [9], abstracts [10], and legal
texts [12].
To develop a text schema for the narratives in the nursing care plan, we analyzed
randomly selected fifteen nursing care plans as a training data set. The care plans
were a part of a course assignment for the ‘Psychiatric Nursing’ course, which was

896

H.-Y. Ahn et al.

offered at the Department of Nursing Science, Konkuk University in Chungju, Korea.
The course was for Juniors who were majoring in the nursing science. Each student
developed a detailed case study report of one patient while the student was working as
a student intern at a psychiatric warden for four weeks. The nursing care plan was
one section of the case report, which was submitted at the end of the internship period. The case reports were from the course offered in the Fall 2004 semester. All
case reports were mainly written in Korean with English translations for a number of
important concepts. We also used another set of fifteen randomly selected nursing
care plans as a testing data set.
Nursing Care
Plan

Facts

Observed

Monologue by
Patient

Summary

Evaluation

Heard

Question by
Nurse

Answer by
Patient

Other Source

Fig. 1. Nursing Care Plan Text Schema

The nursing care plan text schema is shown in the Figure 1. It is based on the qualitative content analysis of the training data set. At the most general level, there are
three major categories. They are ‘Facts’, ‘Summary’, and ‘Evaluation’. ‘Facts’ refer
to the factual information about the patients. ‘Facts’ major category is further divided
into ‘Observed’ and ‘Heard’ categories according to how the information was collected. ‘Observed’ is for the information directly observed or measured by the nurses.
‘Heard’ is what the nurses heard about the patient. ‘Heard’ category is further divided
into four sub-categories. Four sub-categories are: ‘Monologue by Patient’, ‘Question
by Nurse’, ‘Answer by Patient’, and ‘Other Sources’. ‘Monologue by Patient’ is for
the information, which is based on what the patient said about him/herself without
external inquiry. ‘Question by Nurse’ is somewhat problematic sub-category as it
does not independently convey information about the patient. Nurses ask questions
either to learn a particular aspect about the patient’s condition or to encourage the
patient to continue talk about him/herself. Thus, most of the clauses classified under
this category do not convey substantive information. ‘Answer by Patient’ subcategory is for the information provided by the patient in response to a question by the
attending nurses. Finally, ‘Other Sources’ sub-category refers to the patient information provided by the family members, friends, other nurses, or the physicians.
We decided to code each clause with the discourse categories at the most specific
level. The following shows two paragraphs in two different nursing care plans. These
plans were used as the training data set. Although, all qualitative content analysis and

Patient Modeling Using Mind Mapping Representation

897

computational processing is directly applied to the original Korean text, the example
paragraphs are manually translated into English to help non-Korean to understand the
meaning of the examples. ‘<category name>’ and ‘</category name>’ are used to
show the beginning and end of a clause, which is coded as a particular discourse
category.
Example 1. The example is from a paragraph explaining the insight of a patient HS in
the mental state assessment section.
<monologueByPatient> HS said “I hope my nervousness goes away soon’.
</monologueByPatient> <evaluation> Based on the statement, HS seems to understand about his condition well. </evaluation> <otherSource> As HS voluntarily admitted to the hospital last time, </otherSource> <evaluation> it is believed
that HS is positively thinking about the treatments that HS is receiving.
</evaluation>
Example 2. The example is from a paragraph describing the life when the patient JK
was in teens in the developmental history part.
<questionByNurse> Nurse asked ‘Have you ever had a girl friend?’
</questionByNurse> <answerByPatient> JK said ‘No, I never had a girl friend.’
</answerByPatient> <questionByNurse> Nurse asked ‘Do you have many
friends?’ </questionByNurse> <answerByPatient> JK said ‘No, I do not have
many friends.’ </answerByPatient> <summary> As the patient stated that he
never had a relationship with a female and also did not have many male friends,
</summary> <evaluation> it is likely that JK have been having a difficult interpersonal relationship since he was a teenager. </evaluation>
2.1 Extracting Text Classification Features
While coding the training data, we developed both defining features and properties for
each category. The defining features convey the role and purpose of that category
within the nursing care plan text schema while the properties provide suggestive clues
for the recognition of that category. The manual coding suggested to us that we were
relying on five types of linguistic information during our coding. The data, which
would provide these evidence sources, were then analyzed statistically and translated
into computationally recognizable text characteristics. The five sources of evidences
are described in the following.
Lexical Evidences: This source of evidence is a set of one, two, three word phrases
for each component. The set of lexical evidences for each component was chosen
based on observed frequencies and distributions. Only the words or phrases with sufficient occurrences and statistically skewed observed frequency of occurrences in a
particular component were used.
After all coded training data are processed by the lexical evidence extraction module, the frequency distribution of each piece of lexical evidence is further processed to
generate the probability information. For example, ‘
(English translation: it seems to be)’ occurred three times in the clause coded as ‘Facts’, six times in
the ‘Summary’ clauses, and 15 times in ‘Evaluation’ in the training data set. This

있는 듯 하다

898

H.-Y. Ahn et al.

tells us that the clause should be coded as ‘Facts’ three out of 24 times if the sentence
as an example of three word lexical evidences. In the same
includes
is indicated six out of 24 times as ‘Summary’, and 15 out of
manner,
24 times as ‘Evaluation’. After all one, two, and three-word lexical evidence based
on probability calculation is completed, a series of normalization processes is applied
to weed out unreliable lexical evidences and also to remove other influences such as
likelihood of component occurring. As each clause is processed, the lexical evidences
for the words and phrases in the clause are combined using the Dempster-Shafer Theory of Evidence [13]. At the end of all processing, each clause is assigned with four
numbers ranging from zero to one. One number represents the clause’s probability of
having been correctly coded as ‘Facts’. Other numbers are the probability figures for
‘Summary’, and ‘Evaluation’.

‘있는 듯 하다’
‘있는 듯 하다’

Syntactic Evidences: We utilize two types of syntactic evidences: 1) typical sentence
length as measured in the average number of words per clause for each category and
2) individual part-of-speech distribution based on the output of the part-of-speech
tagging. This evidence helps to recognize those categories, which tend to have a
disproportionate number of their words be of a particular part of speech. For example, ‘Observed’ category clauses tend to have comparatively small number of adjectives.
Tense Evidences: Some components tend to contain verbs of a particular tense more
than verbs of other tenses. For example, ‘Fact’ clauses are almost always in the past
or present perfect tense. The tense evidence is a byproduct of part-of-speech tagging.
Document Structure Evidences: There are two types of document structure evidences. Firstly, nursing care plans have section headings, which are closely aligned
with three major categories. For example, ‘Health related Information’ section rarely
had clauses, which are categorizes as ‘Summary’ or ‘Evaluation’. Thus, we utilized
the heading information as another evidence source. Secondly, we included the relative position of each clause with respect to the source paragraph as another evidence
source.
Order of Component Evidences: This source of evidence replies on the tendency of
categories to occur in a particular, relative order. We calculated the frequency with
which each category followed every other category and the frequency with which
each category preceded every other category. The results are stored in two seven-byseven matrices.
2.2 Text Classification
To assign a basic category label to each clause, each clause in the training data set is
categorized according to the predetermined nursing care plan text schema. The first
text classification task involves manually coding all clauses in a set of training documents in preparation for feeding the automatic system. Each clause is classified as
“in” or “out” of the individual categories as outlined by the category definitions. The
next step is to take these manually classified clauses and process them through the

Patient Modeling Using Mind Mapping Representation

899

trainable text classification system. During this process, it builds a vector of lexical
evidences, syntactic evidences, tense evidences, and document structure evidences.
Multi-level Natural Language Processing outputs are the basis for these textual data
feature representations.

Fig. 2. Mind Map for Patient HS

3 Making a Mind Map Visual Representation
Our goal is to make a mind map of a patient along with all related factual and evaluative information about the patient. The Figure 2 shows a mind map representation
about a patient, who is referred as HS.
For this research, we used PersonalBrain, a commercial off the shelf software from
The Brain Technologies Corp (http://www.thebrain.com/). PersonalBrain is an information visualization system, which enables the users to link information into a network of logical associations. PersonalBrain uses ‘Thoughts’ to refer ‘concepts’ and
‘Links’ to refer ‘relations’. The Figure 2 shows ‘Health Maintenance, Altered’ and
‘Social Isolation’ as the nursing diagnoses for the patient HS. Each nursing diagnosis
is preceded by ‘D’. Nursing Outcome is preceded by ‘O’ and Intervention is preceded
by ‘I’. PersonalBrain truncates the labels of each node in the graph if the label is too
long. The full label is revealed when the user moves the cursor on top of the node.
The user can make any node a central node by double clicking on it. The mind map
represented in PersonalBrain is dynamically repositioned to minimize the overloading
of the visual representation in small screen space. At the top of the mind map, there is
a factual information summary observed by the nurse. “Patient complain about facility’ is preceded by ‘FS’, which stands for ‘factual summary’. ‘E’ is for the evaluative
statement by the nurses.

900

H.-Y. Ahn et al.

4 Implementation and Evaluation
The computational modeling of instantiating a discourse-level model of the nursing
care plan texts and converting the traditional nursing care plan to the mind map visual
representation is an ongoing effort. We developed a prototype system by manually
analyzing fifteen sample care plans and tested our system using fifteen unseen care
plans. The first run and evaluation of the correctly categorizing four basic categories
resulted in 80% of the sentences being correctly identified.
There is no directly comparable nursing care plan text classification system. However, a news text classification system, which assigned sentences into one out of fourteen categories, performed at 72% correct rate in the fully automatic mode and 80%
correct rate with various manual heuristic adjustments [11]. It should be noted that
our text classifier did not utilize the second iteration of incorporating the sentences,
with certainty membership value close to zero, as a part of new training data set. We
believe the addition of this process will improve the correctness of our system.

5 Summary
Although we are clearly in the early stages of developing a patient modeling system
based on the mind map representation scheme through the use of nursing care plan
discourse modeling and information extraction system, we find these results quite
promising and eager to share our premature but empirical results and experiences in
creating an operational system with other researchers.
We expect the resulting mind map to aid both nursing students and practitioners
finding the nursing process examples of making proper nursing diagnosis. They can
review what others have done to learn from the sound decisions and the mistakes.
There are many tasks that we have yet to finish. The major missing task is the usability evaluation of the resulting mind map. We also need to increase the size of test
data set to improve the reliability of the evaluation results.
We have applied the nursing care plan discourse model to the actual care plans by
coding a small set of sample texts. This effort in conjunction other automatic discourse modeling works, we argue that it is possible to extract a particular section of
the texts by utilizing a text type specific discourse model.

References
1. Sparks. S.M. and Taylor, C.M., Nursing Diagnosis Reference Manual 5th Edition, Springhouse, Springhouse, Pennsylvania, 2000.
2. Doenges, M., and Moorehead, M.F., Application of Nursing Process and Nursing Diagnosis: An Interactive Text for Diagnostic Reasoning 4th Edition, F.A. Davis Co., Philadelphia, Pennsylvania, 2003.
3. Mueller, A., Johnston, M. & Bligh, D.: Joining mind mapping and care planning to enhance student critical thinking and achieve holistic nursing care. Nursing Diagnosis
13(1):24-27 (2002).
4. Jones, L.B.: Pragmatic aspects of English text structure. Summer Institute of Linguistics,
Arlington, TX (1983).

Patient Modeling Using Mind Mapping Representation

901

5. Rumelhart, D.: Understanding and summarizing brief stories. In D. LaBerge and S.J.
Samuels (Editors) Basic processes in reading: Perception and comprehension. Hillsdale,
NJ: Lawrence Earlbaum Associates: 265-303. (1977)
6. Rumelhart, D.: Schemata: the building blocks of cognition. In R. Spiro, B. Bruce, & W.
Brewer (Editors) Theoretical issues in reading comprehension: Perspectives from cognitive psychology, linguistics, artificial intelligence and education. Hillsdale, NJ: Lawrence
Earlbaum Associates: 33-8. (1980)
7. van Dijk, T.A.: News analysis: Case studies of international and national news in the
press. Hillsdale, NJ: Lawrence Earlbaum Associates. (1988)
8. Cohen, R.: Analyzing the structure of argumentative discourse. Computational Linguistics,
13. 11-24. (1987)
9. Alvarado, S.J.: Understanding editorial text: A computer model of argument comprehension. Boston, MA: Kluwer Academic Publishers. (1990)
10. Liddy, E.D.: The discourse-level structure of empirical abstracts: An exploratory study. Information Processing and Management 27.1, Tarry Town, NY, Pergamon Press: 55-81.
(1991)
11. Liddy, E.D., McVearry, K.A., Paik, W., Yu, E., and McKenna, M.: Development, Implementation and Testing of a Discourse Model for Newspaper Texts. Proceedings of a Human Language Technology Workshop. Plainsboro, NJ, Morgan Kaufmann Publishers:
159-164. (1993)
12. Paik, W. and Lee, J.: Extracting Legal Propositions from Appellate Decisions with Text
Discourse Analysis Methods. Lecture Notes in Computer Science (LNCS) Vol. 3292,
Springer-Verlag: 621-633. (2004)
13. Pearl, J.: Probabilistic reasoning in intelligent systems: networks of plausible inference,
Morgan Kaufmann Publishers, San Francisco, CA. (1988)

