MVRC Heuristic for Solving the Multi-Choice
Multi-Constraint Knapsack Problem
Maria Chantzara and Miltiades Anagnostou
School of Electrical & Computer Engineering, National Technical University of Athens
9 Heroon Polytechniou Str, 157 73 Zografou, Athens, Greece
{marhantz, miltos}@telecom.ntua.gr

Abstract. This paper presents the heuristic algorithm Maximizing Value per
Resources Consumption (MVRC) that solves the Multi-Choice MultiConstraint Knapsack Problem, a variant of the known NP-hard optimization
problem called Knapsack problem. Starting with an initial solution, the MVRC
performs iterative improvements through exchanging the already picked items
in order to conclude to the optimal solution. Following a three step procedure, it
tries to pick the items with the maximum Value per Aggregate Resources
Consumption. The proposed algorithm has been evaluated in terms of the
quality of the final solution and its run-time performance.

1 Introduction
One of the most studied combinatorial optimization problems is the Knapsack
Problem (KP). Numerous problems of different fields such as capital budgeting, cargo
loading and resource allocation are modeled as a variant of it. Due to the high
applicability of this NP-hard problem, it has been widely studied. The objective of the
original KP is to optimize resource allocation, or more precisely, how to distribute a
fixed amount of resources among several actions in order to obtain maximum payoff.
The 0-1 KP considers a knapsack of specific capacity and a set of items; each of them
has specific weight and value. The objective is to determine which items should be
placed in the knapsack so as to maximize the total value of the items contained in it
without exceeding its capacity. Another variant of the 0-1 KP refers to the case that
there are multiple constraints regarding resources and is called Multi-Dimension or
Multi-Constraint KP (MDKP). Another one is the Multi-Choice KP (MCKP). In this
case the items are divided into groups and the objective is to pick exactly one item of
every group in order to maximize the total value.
A combination of the MDKP and MCKP variants is the Multi-Choice MultiConstraint Knapsack Problem (MMKP). Its formal definition is: There are n groups
of items. Group i contains li items. Each item ij has a particular value vij and weights
rij = (r1ij ,..., rmij ) regarding the m resource constraints: C = (C1, ..., Cm ) . The objective is

to pick exactly one item from each group in order to have maximum total value of the
collected items, subject to the m resource constraints. With decision
variable: xij ∈ {0,1} , the MMKP is formulated as follows. The objective function to be
maximized is the total value of the picked items:
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part I, LNCS 3991, pp. 579 – 587, 2006.
© Springer-Verlag Berlin Heidelberg 2006

580

M. Chantzara and M. Anagnostou
i =n j =li

TotalValue = ∑ ∑ vij xij
i =1 j =1

(1)

The constraints are:
i = n j =li

∑ ∑ rkij xij

i =1 j =1

≤ C k , k = 1,..., m

(2)

j =li

∑ xij = 1, i = 1,..., n
j =1

(3)

This paper presents the heuristic Maximizing Value per Resources Consumption
(MVRC) for solving the MMKP. It is an improvement of the heuristic HEU [1] which
is proved to be one of the best known algorithms in terms of performance (solution
optimality vs. computation time). Starting with an initial solution, MVRC performs
iterative improvements though exchanging the already picked items in order to
conclude to the optimal solution. Unlike HEU that tries to minimize the resources
consumption, MVRC picks the items with the maximum Value per Aggregate
Resources Consumption. Finally, MVRC solves the MMKP instances in less time that
is important for cases that require real-time decision making. We have applied the
proposed heuristic to the MMKP instance referring to the discovery of the
information sources for acquiring data on behalf of the context-aware services.
Regarding this problem, each requested type of info corresponds to a group, and the
available quality levels of the same context data correspond to the items of the group.
The resource constraints refer to the cost and the latency bound for obtaining the data.
The value that needs to be maximized is the expected utility of the picked items. The
formulation of context source discovery as MMKP has been analyzed in [2]. In this
case, the values do not follow monotone feasibility order, since items with higher cost
correspond to higher expected utility, while items with higher response time to lower.
The rest of the paper is organized as follows: the literature review related to
MMKP is reported in Section 2. In Section 3, the proposed heuristic MVRC is
detailed and its worst-case complexity is computed. In Section 4 the evaluation of the
MVRC performance is presented. Finally, Section 5 provides some conclusive
remarks.

2 Related Work
In [3] and recently in [4], reviews of the KPs and literature on methods to solve them
are presented. The proposed exact algorithms for solving the different variants are
based on the “branch-and-bound” approach or dynamic programming techniques, that
are capable of producing optimal solutions but they require much time. Therefore,
heuristics providing near-optimal solutions within low computation time are
developed. We are particularly interested in the literature about the MMKP variant.
The exact algorithm for the MMKP is a branch-and-bound [5] that performs a
complete enumeration keeping the best solution found so far in order to find the
optimal one. If a partial solution cannot improve on the best, it is abandoned.

MVRC Heuristic for Solving the Multi-Choice Multi-Constraint Knapsack Problem

581

However, this approach cannot be applied when the selection should be done
real-time, due to its high complexity and therefore, heuristics are developed.
One of the first heuristics for solving the MMKP is presented in [6]. It uses the
concept of graceful degradation from the most valuable items based on Lagrange
Multipliers. This algorithm fails to find a solution when the resources are extremely
short and the feasible solutions are very few. In [1] the heuristic HEU is detailed. This
approach is based on the concept of “aggregate resources” proposed in [7] that
converts the multiple resource dimensions into only one through penalizing the use of
resources. In fact, it applies a large penalty for a heavily used resource and a small
penalty for a lightly used resource. The proposed method starts from an initial pick of
the least valuable items, finds a feasible solution by exchanging items based on the
Toyoda concept, while it ensures that there is improvement regarding the resources
consumption. It finally upgrades the feasible solution in terms of solution value
through iterative exchanges resulting to another feasible solution. The HEU has been
applied to the QoS management problem, where the QoS levels follow monotone
feasibility order since a QoS level with higher utility requires more resources. In order
to have better solutions for the MMKP instances where some higher-valued items
consume less resources than lower-valued, the authors of [8] have proposed another
method. This one applies a transformation technique to map the multi-dimensional
resource to single dimension and constructs convex hulls to reduce the search space of
solutions. Comparing it with the HEU showed that even though it produces solutions
with significant lower value especially for the correlated data sets, it concludes to the
solution in significant reduced time. As a result, it can be stated that it mostly fits to
cases where run-time performance is of greater interest than the solution quality.
Finally, the authors of [9] propose a set of algorithms for finding the solution of an
MMKP instance. The first one constructs an initial feasible solution through a greedy
approach, the second one improves the quality of the initial solution using a
complementary procedure and the third one searches for the best feasible solution
over a set of neighborhoods according to the “guided local search” method. The
evaluation of the performance of this approach showed that it outperforms the HEU in
terms of the solution quality but for the run-time performance no metrics are given.

3 The MVRC Heuristic Algorithm
Before describing the MVRC heuristic, we introduce some notations. Considering
item ij with value vij and resources usage rij = ( r1ij ,..., rmij ) , we define the Aggregate
Resources Consumption (ARC): ARCij =

r1ij ∗ C1 + ... + rkij ∗ Ck
C12 + ... + Ck2

, and the Value-per unit

v
of ARC (V-ARC): V − ARCij = ij ARC . Assuming that we have the problem’s
ij
solution described by the vector S=(1j1,2j2,…, iji,..,njn), denoting the items picked per
i=n

each group, and resources consumption RS = (R1,R2,…Rk) where R k = ∑ rkij i . If the
i =1

already picked item iji of group i is exchanged by the item ij, the new solution is:
S΄=(1j1,2j2,…,ij,…,njn). The resources consumption becomes RS΄=(R΄1,R΄2,…,R΄k).

582

M. Chantzara and M. Anagnostou

For the new solution S΄, we define the Aggregate Resources Requirements (ARR):
ARRij =

( R΄1 − R1) ∗ R1 + ... + ( R΄k − Rk ) ∗ Rk
R12 + ... + Rk2

(VU-ARR): VU − ARRij =

vij − viji
ARRij

, and the Value Update-per unit of ARR

. For the solution S, we also define the feasibility

factor of each resource k as follows: Fk = Rk C . If Fk ≤ 1 , the resource k is called
k

feasible; otherwise it is infeasible. In the same respect, if Fk ≤ 1 for each k=1,2,…,m,
the solution S is called feasible; otherwise it is called infeasible. Moreover for the
picked items in solution S, we define the feasibility factor of each item iji of group i
for each resource k, as follows: FI kji =

rkiji

Rk

. Finally, the sum of the values of the

i=n

picked items is the solution value: V S = ∑ vij i .
i =1

The MVRC heuristic follows three steps in order to reach the final solution. Given
the MMKP input instance, Step1 produces an initial solution. Step 2 produces a
feasible solution through iteratively exchanging the already picked items. In Step 3
the feasible solution is improved by iteratively picking items with higher values.

INPUT

STEP1:
Initial Solution

STEP2:
Find feasible
solution

STEP3:

Improvement

OUTPUT

Fig. 1. MVRC heuristic

The MVRC steps are described in more detail below:
STEP 1: We find the initial solution by selecting the item with the highest V-ARC of
each group. In case the solution is a feasible Step 3 follows; otherwise Step 2 follows.
STEP 2: In this step, we exchange one of the items of the current solution in order to
find a feasible solution. The decision about the exchange is the outcome of the
following sub-steps. Firstly, the resource with the highest feasibility factor is found
(step 2.1) and in relation to this resource, the picked item with the highest feasibility
factor is determined (step 2.2). Then, we exchange this item with an item of the same
group that has lower V-ARC (step 2.3). In case the solution which has come out of
this exchange remains infeasible, Step 2 is repeated; otherwise, Step 3 follows. If Step
2 fails to find any feasible solution, the algorithm terminates without a solution.
STEP 3: In this step, we exchange one of the items of the current solution with
another of the same group in order to increase the solution value. The criterion is the
maximization of the VU-ARR ratio so that the new solution remains feasible. For
deciding on the item to insert in the knapsack, we identify the following cases.
Having two candidate items, with aggregate resources requirements ARR1 and ARR2
respectively: (i) If both ARR1, ARR 2 ≤ 0, the item that maximizes the solution
upgrade is preferred. (ii) If both ARR1, ARR2 > 0, the one with the maximum VU-

MVRC Heuristic for Solving the Multi-Choice Multi-Constraint Knapsack Problem

583

ARR is preferred. (iii) If ARR1 ≤ 0 and ARR2 >0, the one that maximizes solution
value upgrade is preferred. In case, a new exchange can be performed, Step 3 is
repeated; otherwise, the algorithm terminates and the current solution is the optimal.
In the following, we present the upper bounds of the computational complexity of
the three steps of the MVRC heuristic for the MMKP input instance consisting of n
groups, m resources and l items per group. It is assumed that in each group the items
are arranged in non-decreasing order. In Step 1, for every item the ratio V-ARC is
computed with complexity O(nml). For the sorting of the items according to the VARC ratios we use a simple algorithm with complexity O(nl!). For the feasibility
check the complexity is O(m). Therefore, the complexity of Step 1 is O(nml+ nl!+m).
The step 2.1 requires m comparisons and is O(m). The step 2.2 is O(n). The step 2.3
requires constant time since the items are already ordered. The Step 2 can be repeated
2
at most n(l-1). Thus, the complexity of Step 2 is O(n (l-1)m). In Step 3, computing the
VU-ARR has O(m) complexity, while finding the item to be exchanged may require
n(l-1) computations. Thus, the complexity is O(n(l-1)m). Since the feasible upgrades
2
2
could be n(l-1) at most, the complexity of Step 3 is O(n (l-1) m). Finally, we conclude
2
2
2
that the complexity of the MVRC heuristic is O(nml+ nl!+m+n (l-1)m+n (l-1) m).

4 Evaluation
In order to test the performance of the proposed algorithm, we implemented the
MVRC algorithm along with the HEU and the exhaustive approach. The HEU is one
of the best known heuristics that has been evaluated comparatively to all proposed
approaches of the literature. The exhaustive approach is an exact algorithm that
computes all possible combinations and checks their feasibility in order to find the
optimal one (its complexity is O (ml n )). We applied the three algorithms to instances
of different sizes under the scope to test both the quality of the solution and the runtime performance. The implementation of the algorithms is done in Java 1.4., while
we ran the algorithms on a 1.4 GHz Pentium Fujitsu Siemens Lifebook with 512MB
running Linux. The data sets were generated according to the state-of-the-art pattern
described in [8] that generated both correlated and uncorrelated data sets. Concerning
the correlated data instances, that are harder to solve [10], the value of an item
depends on its weights, while concerning the uncorrelated, the value and the weights
are independent. The metrics measuring the performance of the algorithms are:
1. Percentage (%) optimality of the solution that measures the quality of the
produced solution. Assuming that Vopt is the optimal one and Vi is the one we
wish to compare, the percentage optimality is defined as follows:
%Opt = Vi / Vopt *100

2. Computation time describing the required time to execute the algorithm.
3. Number of updates that are performed till the final solution is found, showing
how quick the algorithm converges to the final solution. Unlike the computation
time, this metric does not depend on the implementation of the algorithm.
We recorded these metrics for all algorithms with the increase in the number of
groups, items per group, resource constraints. For each size of data set, we generated

584

M. Chantzara and M. Anagnostou

10 instances and applied the algorithms to all of them. However, we report the average
of the performance metrics of the 10 test instances of the specific data set size. The
graphs of figures 2-4 depict the % optimality of the solutions for small-sized data sets,
since we are unable to run the exhaustive approach for large-sized data instances due to
memory and computation time requirements. The graphs of figures 5-7 depict the
computation time for the two algorithms to find a solution for large-sized data
instances. Finally, the figures 8-10 depict the number of updates respectively.
100

100
HEU,
correlated

98

MVRC,
correlated

97
96

HEU,
uncorrelated

95

MVRC,
uncorrelated

94
93

99

Optimality (%)

Optimality (%)

99

98

HEU,
correlated

97

MVRC,
correlated

96

HEU,
uncorrelated

95
94

MVRC,
uncorrelated

93
92

92
1

2
3
4
Number of groups (n)

0

5

40

80

120

160

200

240

280

320

Number of items per group (l)

100

Optimality (%)

95

HEU,
correlated

90

MVRC,
correlated

85
80

HEU,
uncorrelated

75

MVRC,
uncorrelated

70
65

Computation time (msec)

Fig. 2. Optimality in relation to the number of Fig. 3. Optimality in relation to the number of
items per group (n=2, m=2)
groups (l=20, m=2)

60
0

2
4
6
8
10
Number of resource constraints (m)

80
70
60

HEU,
correlated

50

MVRC,
correlated

40

HEU,
uncorrelated

30

MVRC,
uncorrelated

20
10
0
0

12

10

20

30

40

50

60

70

80

90

Number of groups (n)

Fig. 4. Optimality in relation to the number of Fig. 5.Computation time in relation to the
number of groups (l=10, m=2)
res. constraints (n=2, l=20)

Computation time (msec)

3000
2500

HEU,
correlated

2000

MVRC,
correlated

1500

HEU,
uncorrelated

1000

MVRC,
uncorrelated

500
0

Computation time (msec)

2500

3500

2000

HEU,
correlated

1500

MVRC,
correlated

1000

HEU,
uncorrelated
MVRC,
uncorrelated

500
0

0

100

200

300

400 500

600

700

800

Number of items per group (l)

900

0

5
10
15
20
25
Number of resource constraints (m)

30

Fig. 6. Computation time in relation to the Fig. 7. Computation time in relation to the
number of items per group (n=10, m=2)
number of resource constraints (n=10, l=500)

MVRC Heuristic for Solving the Multi-Choice Multi-Constraint Knapsack Problem
120

160
HEU,
correlated

140
120

MVRC,
correlated

100

HEU,
uncorrelated

80
60

MVRC,
uncorrelated

40
20
0
0

10

20

30

40

50

60

70

80

Number of groups (n)

90

100

HEU,
correlated

80

MVRC,
correlated

Number of updates

180

Number of updates

585

60

HEU,
uncorrelated

40

MVRC,
uncorrelated

20
0
0

100 200 300 400 500 600 700 800 900
Number of items per group (l)

Number of updates

Fig. 8. Number of updates in relation to the Fig. 9. Number of updates in relation to the
number of items per group (n=10, m=2)
number of groups (l=10, m=2)
2000
1800
1600
1400
1200
1000
800
600
400
200
0

HEU,
correlated
MVRC,
correlated
HEU,
uncorrelated
MVRC,
uncorrelated

0

5
10
15
20
25
Number of resource constraints (m)

30

Fig. 10. Number of updates in relation to the number of resource constraints (n=10, l=500)

Observing the above figures we conclude to the following evaluation results:
 Testing the algorithms with small-sized data instances showed that both algorithms
provide feasible solutions for every case. However, using large-sized input
instances the algorithms showed that MVRC fails to find feasible solutions for
large number of resource constraints. In fact, for n=10, l=500, m=20, the failure
rate is 50% while for m=25, it becomes 70%. For the other large-sized input
instances, no failure is noticed.
 Regarding the quality of the solutions, we conclude that both algorithms produce
solutions with value very close to the one produced by the exhaustive approach.
For the smaller data instances, the increase of the problem size result in the
increase of optimality, while for larger data instances the optimality tends to
stabilize. Regarding the quality of the solutions for large data sets, we observe that
the solutions produced by the two algorithms are quite close.
 It may happen that smaller data sets take longer than larger data sets. This happens
because of the fact that the data sets are produced randomly. If the data set consists
of very few feasible solutions it might take less time to get the final solution.
 The performance for the uncorrelated data sets is better than the correlated ones.
 The MVRC outperforms the HEU in terms of solution optimality. It also performs
less updates till finding the final solution, and requires lower computation time. As
the data sizes increase, the increase rates of computation time and performed
updates get higher for the HEU, while for the MVRC it tends to remain stable. The

586

M. Chantzara and M. Anagnostou

complexity of the HEU is quadratic to the group size and number of groups, while
for the MVRC only the complexity of Step 3 is quadratic to the problem size.
However, for large number of constraints the HEU produces better solutions in
terms of quality but it requires more time.
 For large number of items per group, the computation time of the MVRC is higher
than the HEU. However, this is due to the sorting algorithm with complexity
O(nl!) that is used in Step 1. A sorting algorithm with lower complexity, such as
“Quicksort” [11], can be applied in order to minimize the computation time of the
MVRC.

5 Conclusions
We presented the Maximizing Value per Resources Consumption heuristic algorithm
for solving the MMKP within low time that is important for cases that require realtime decision making. The proposed algorithm has been tested against the HEU and
the exhaustive approach for various sizes of input data. The evaluation results showed
that the MVRC generates high quality solutions within low computation time. As the
input data sizes increase, the increase rate of the computation time remains stable.
However, it falls short in cases of large number of resource constraints. Moreover, in
cases of large number of items per group it requires high computation time, but this
can be improved if we utilize sorting algorithms with lower complexity.

References
1. Khan, S., Kin, F. Li, Manning, E., Akbar, M.: Solving the Knapsack Problem for Adaptive
Multimedia Systems. Studia Informatica (2002), Special Issue on Combinatorial
Problems. Vol. 2. No. 1, pp. 154-174.
2. Chantzara, M., Anagnostou, M.: Evaluation and Selection of Context Information. In
Proceedings of the 2nd International Workshop on Modelling and Retrieval of Context
(MRC 2005), Edinburgh, Scotland, (July 31- August 1 2005). CEUR Workshop
Proceedings, ISSN 1613-0073.
3. Martello, S., Toth, P.: Knapsack Problems: Algorithms and Computer Implementations.
Wiley-Inrescience Series in Discrete Mathematics and Optimization, 1990, John Wiley &
Sons, Chichester, England.
4. Kellerer, H., Pferschy, U., Pisinger, D.: Knapsack Problems. Springer, 2004 ,ISBN: 3540-40286-1, p. 546.
5. Khan, S.: Quality Adaptation in a Multi-Session Adaptive Multimedia System: Model,
Algorithms and Architecture. PhD Thesis, Department of Electronical and Computer
Engineering, University of Victoria, Canada (1998).
6. Moser, M., Jokanovic, D., Shiratori, N.: An Algorithm for the Multidimensional MultipleChoice Knapsack Problem. IECE Trans Fundamentals Electron (1997), Vol.80. pp.
582-589.
7. Toyoda, Y.: A Simplified Algorithm for Obtaining Approximate Solutions to Zero-one
Programming Problems. Management Science (1975), Vol. 21, No. 12, pp. 1417-1427.

MVRC Heuristic for Solving the Multi-Choice Multi-Constraint Knapsack Problem

587

8. Akbar, M., Rahman, M., Kaykobad, M., Manning, E., Shoja, G.: Solving the
Multidimensional Multiple-choice Knapsack Problem by Constructing Convex Hulls.
Computers & Operations Research, Elsevier (May 2006). Vol. 33, No. 5, pp. 1259-1273.
9. Hifi, M., Micrafy, M., Sbihi, A.: Heuristic Algorithms for the Multiple-choice
Multidimensional Knapsack Problem. Journal of the Operational Research Society
(December 2004). Vol. 55, pp. 1323-1332.
10. Pisinger, D.: Where are the hard knapsack problems?. Computers and Operations
Research (September 2005). Vol. 32, No. 9, pp. 2271-2284.
11. Cormen, T., Leiserson, C., Rivest, R., Stein, C.: Introduction to Algorithms. MIT Press
and McGraw-Hill.

