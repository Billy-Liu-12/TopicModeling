Comparing Leja and Krylov Approximations
of Large Scale Matrix Exponentials
L. Bergamaschi1, M. Caliari2 , A. Mart´ınez2 , and M. Vianello2
1

Dept. of Math. Methods and Models, University of Padova
berga@dmsa.unipd.it
2
Dept. of Pure and Appl. Math., University of Padova
{mcaliari, acalomar, marcov}@math.unipd.it

Abstract. We have implemented a numerical code (ReLPM, Real Leja
Points Method) for polynomial interpolation of the matrix exponential
propagators exp (ΔtA) v and ϕ(ΔtA) v, ϕ(z) = (exp (z) − 1)/z. The
ReLPM code is tested and compared with Krylov-based routines, on
large scale sparse matrices arising from the spatial discretization of 2D
and 3D advection-diﬀusion equations.

1

Introduction

The systematic study and application of the so-called “exponential integrators”
began about two decades ago, but has received a strong impulse in recent years;
see, e.g., [5, 7, 8] and references therein. A building-block of exponential integrators is the eﬃcient evaluation of the underlying matrix exponential functions,
like exp (ΔtA) v and ϕ(ΔtA) v, ϕ(z) = (exp (z)− 1)/z (here A ∈ Rn×n , v ∈ Rn ,
and Δt > 0 is a time step). To this respect, most authors regard Krylov-like (cf.
e.g. [7, 14]) as the methods of choice. Nevertheless, an alternative class of polynomial methods has been developed since the beginning (cf., e.g., [6, 15, 13]),
which are based on direct interpolation or approximation of the exponential
functions on the spectrum (or the ﬁeld of values) of the relevant matrix. Despite
of a preprocessing stage needed to get an estimate of some marginal eigenvalues,
the latter are competitive with Krylov-like methods in several instances, namely
on large scale, sparse and in general nonsymmetric matrices, arising from the
spatial discretization of parabolic PDEs; see, e.g., [4, 10, 11].
Among others, the ReLPM (Real Leja Points Method), proposed in [4] and
applied to advection-diﬀusion models in [2], has shown very attractive computational features. It rests on Newton interpolation of the exponential functions
at a sequence of Leja points on the real focal interval of a family of confocal
ellipses in the complex plane. The use of Leja points is suggested by the fact
that they guarantee maximal (and thus superlinear) convergence of the interpolant on every ellipse of the confocal family, and thus superlinear convergence
Work supported by the MIUR PRIN 2003 project “Dynamical systems on matrix
manifolds: numerical methods and applications” (co-ordinator L. Lopez, University
of Bari), by the ex-60% funds of the University of Padova, and by the GNCS-INdAM.
V.N. Alexandrov et al. (Eds.): ICCS 2006, Part IV, LNCS 3994, pp. 685–692, 2006.
c Springer-Verlag Berlin Heidelberg 2006

686

L. Bergamaschi et al.

of the corresponding matrix polynomials to the matrix exponential functions.
This feature is shared also by other set of interpolation points, like e.g. standard Chebyshev points, but diﬀerently from the latter, at the same time Leja
points allow to increase the interpolation degree just by adding new nodes of the
same sequence; see [1, 4] for the scalar and matrix features of interpolation at
Leja points. A key step in the approximation procedure is given by estimating
cheaply a real focal interval, say [a, b], such that the “minimal” ellipse of the
confocal family which contains the spectrum (or the ﬁeld of values) of the matrix is not too “large” (the underlying theoretical notion is that of “capacity” of
a compact complex set). The numerical experience with matrices arising from
stable spatial discretizations of parabolic equations (which are the main target
of the ReLPM code) has shown that good results can be obtained at a very
low cost, simply by intersecting the Gershgorin’s circles of the matrix with the
real axis. Indeed, it is worth stressing that the ReLPM method works well with
“stiﬀ” matrices, whose spectrum (or whose ﬁeld of values) has a projection on
the real axis which is nonpositive and much larger than the projection on the
imaginary axis; cf. [4].
We give now two formulas, which are the basis for practical implementation
of the ReLPM method. The kernel of the ReLPM code is given by interpolation
of ϕ(hλ), for suitable h ≤ Δt, at Leja points of the real focal interval [a, b] =
[c − 2γ, c + 2γ]. Observe that once ϕ(hA)v is computed, then exp (hA)v =
hϕ(hA)v +v. In practice, it is numerically convenient to interpolate the function
ϕ(h(c + γξ)) at Leja points {ξs } of the reference interval [−2, 2] (since it has
capacity equal to 1, cf. [15]). Then, given the corresponding divided diﬀerences
{di } for such a function, the matrix Newton polynomial of degree m is
m

i−1

di Ωi ≈ ϕ(hA) , Ωi =

pm (A) =
i=0

((A − cI)/γ − ξs I) .

(1)

s=0

In general, it is not feasible to interpolate with the original time step Δt, which
has to be fractionized. This happens, for example, when the expected degree
for convergence is too large. The ReLPM code subdivides dynamically Δt into
smaller substeps h = hk , and recovers the required vector ϕ(ΔtA)v according
to the time marching scheme
yk+1 = yk + hk ϕ(hk A)(Ayk + v) , k = 0, 1, . . . , k ∗ ; y0 = 0 ,

(2)

where
hk = Δt. Here we use the fact that Δtϕ(ΔtA)v is the solution at
˙
t = Δt of the diﬀerential system y(t)
= Ay(t) + v, y(0) = 0.

2

The ReLPM Code

In this section we present the pseudo-codes of the three subroutines which compose the ReLPM code. They are displayed in Tables 1–3, and accompanied by
a detailed documentation.

Comparing Leja and Krylov Approximations

687

Table 1. Subroutine ReLPM

1.
2.
3.
4.
5.
6.

input: A, v, Δt, exptype, tol
constants: M = 124, (ξ0 , . . . , ξM ) array of M + 1 Leja points in [−2, 2]
k := 0, ρ := Δt, p := 0, w := v
a, b:=“extrema of the real points in the Gersghorin’s circles of A”
c := (a + b)/2, γ := (b − a)/4, ν := 3γ, h := min {Δt, M/ν}, oldh := 0
repeat
7. if h = oldh then
8. call DIVDIFF(h, c, γ, M, (ξ0 , . . . , ξM ), (d0 , . . . , dM ))
9. oldh := h
10. endif
11. call INTERP(A, w, h, tol, c, γ, M, (ξ0 , . . . , ξM ), (d0 , . . . , dM ), q, err, m)
12. if m > M then h := h/2
13. else
14. ρ := ρ − h, p := p + hq
15. if ρ > 0 then
16. w := Ap, w := w + v, k := k + 1, σ := hγ/m
17. if σ > 1 then h := min {σh, M/γ, ρ}
18. else h := min {h, ρ}
19. endif
20. endif
21. endif
22. until ρ = 0
23. k∗ := k, if exptype = 0 then w := Ap, p := w + v else p := p/Δt endif
24. output: the vector p such that p ≈ exp (ΔtA)v (exptype = 0), or p ≈ ϕ(ΔtA) v,
ϕ(z) = (ez − 1)/z (exptype = 1); the total number of substeps k∗

Comments to Table 1. This is the main subroutine. It accepts a matrix
A ∈ Rn×n , a vector v ∈ Rn , a time step Δt > 0, and the type of exponential
function (exp or ϕ). The output is a vector which approximates the corresponding function of the matrix ΔtA, applied to the vector v. The underlying method
is the time-marching scheme (2), with a dynamical managing of the variable substeps h = hk , and Newton interpolation as in (1) of ϕ(hA) at real Leja points
related to spectral estimates for A.
1.) exptype: type of exponential function (0 for exp, 1 for ϕ); tol: the relative
error tolerated for the result exp(ΔtA)v or ϕ(ΔtA)v.
2.) M : maximum interpolation degree allowed “a priori” in the Newton interpolation of ϕ(hA), h ≤ Δt; (ξ0 , . . . , ξM ) is an array of Leja interpolation points, like
e.g. the Fast Leja points in [1]. It is worth stressing that the default M = 124 is
tuned on spatial discretization matrices of linear advection-diﬀusion models, in
order to guarantee that all the divided diﬀerences computed by the subroutine
DIVDIFF are accurate (see [3]).
3.) Initializations: ρ is the portion of Δt still to be covered; p = y0 and w =
Ay0 + v, cf. (2).

688

L. Bergamaschi et al.

4. - 5.) Approximation of the real focal interval of a “minimal” ellipse which
contains the numerical range of the underlying matrix, and the associated parameters: c is the center and γ the capacity (length/4) of the interval. Hereafter,
h and oldh are the current and the previous (sub)steps. For any given substep
h, theoretical estimates show that superlinear convergence of the matrix interpolation polynomial should start at a degree between hγ and 2hγ, cf. [10, 4],
provided that the capacity of the minimal ellipse above is relatively close to γ.
Convergence at reasonable tolerances of the matrix interpolation polynomial is
expected for a degree lower than hν = 3hγ (the factor 3 is an “empirical” choice,
based on numerical experience). Hence, the input step Δt is possibly reduced in
such a way that [hν] ≤ M (here [·] denotes the integer part).
6. - 22.) Main loop: implements the time marching scheme (2) with dynamical
managing of the substeps h = hk .
7. - 10.) When the current and the previous substeps are diﬀerent the divided
diﬀerences (d0 , . . . , dM ) are (re)computed.
11.) Computes q = pm (A)w ≈ ϕ(hA)w, where w = Ap + v, p ≈ yk .
12. - 21.) If the interpolation process has not converged, the substep is halved
and control returns to point 6, otherwise the current substep has been successful.
14.) The remaining portion ρ of Δt and p are updated: now p ≈ yk+1 .
15. - 20.) If Δt has not been completed, prepares the next substep.
16.) Computes w ≈ Ayk+1 +v; σ is a parameter used to detect fast convergence,
i.e. convergence degree smaller than hγ.
17. - 19.) When the actual convergence degree m is smaller than hγ (fast convergence), the next substep h is increased but in such a way that hγ ≤ M (since
convergence is expected again at a degree lower than hγ).
23.) Now p ≈ yk∗ = Δtϕ(ΔtA)v: computes the right type of matrix exponential
function according to exptype.
Table 2. Subroutine DIVDIFF

1. input: h, c, γ, M , (ξ0 , . . . , ξM )
2. “computes (d0 , . . . , dM ), the divided diﬀerences of ϕ(h(c + γξ)), ξ ∈ [−2, 2], at the
Leja points (ξ0 , . . . , ξM ), by the accurate matrix algorithm in [3]”
3. output: (d0 , . . . , dM )

Comments to Table 2. This subroutine accepts a time step h, two parameters
related to the spectral features of an external matrix A, a maximum interpolation
degree M and a corresponding array of Leja interpolation points. It returns
the divided diﬀerences for the Newton polynomial interpolation of ϕ(hA) up to
degree M . The subroutine is thought to work in double precision.
1.) h: time step; c and γ: see point 4 in the comments to the subroutine ReLPM;
M and (ξ0 , . . . , ξM ): maximum interpolation degree and corresponding Leja interpolation points, see the comment to point 2 of the subroutine ReLPM.

Comparing Leja and Krylov Approximations

689

2.) Computes the M +1 divided diﬀerences in double precision as the ﬁrst column
of ϕ(h(c + γ ΞM )), where ΞM is the (M + 1) × (M + 1) bidiagonal matrix with
the Leja points (ξ0 , . . . , ξM ) on the main diagonal and (1, . . . , 1) on the diagonal
immediately below. The matrix ϕ(h(c + γ ΞM )) is approximated via 16-term
Taylor expansions by the scheme proposed in [3], on the basis of [9]. Diﬀerently
from the standard divided diﬀerences table, this algorithm computes accurately
the divided diﬀerences even when their size goes below machine precision, provided that M is not too large for the given h, c and γ (to avoid the underﬂow of
some intermediate quantities in the computation); see the comment to point 2
of the subroutine ReLPM. A more sophisticated implementation could discard
the possible tail of divided diﬀerences that are not suﬃciently accurate (see [3]).
3.) Given (d0 , . . . , dM ), the Newton interpolation polynomial of degree m ≤ M
m
i−1
for ϕ(hλ) is pm (λ) = i=0 di s=0 ((λ − c)/γ − ξs ), λ ∈ [c − 2γ, c + 2γ].
Table 3. Subroutine INTERP

1.
2.
3.
4.

input: A, w, h, tol, c, γ, M , (ξ0 , . . . , ξM ), (d0 , . . . , dM )
constants: = 5
u := w, q := d0 w, e0 := q 2 , β := w 2 , m := 0
repeat
5. z := (Au)/γ, u := z − (c/γ + ξm )u
6. m := m + 1, em := |dm | u 2
7. q := q + dm u
8. if m ≥ − 1 then err := (em + . . . + em− +1 )/ endif
9. until err ≤ β tol or m ≥ M
10. if err > β tol then m := M + 1 endif
11. output: the vector q = pm (A)w, the estimated error err, and the interpolation
degree m, such that q − ϕ(hA) w 2 ≈ err, with err ≤ w 2 tol when m ≤ M ,
whereas a convergence failure occurred when m > M .

Comments to Table 3. This subroutine tries to compute an approximation
q = pm (A)w ≈ ϕ(hA)w, cf. (1), up to an error (relative to w 2 ) less than a
given tolerance, where A ∈ Rn×n , w ∈ Rn and Δt ≥ h > 0.
1.) (d0 , . . . , dM ) are the divided diﬀerences for the Newton interpolation up to
degree M of the function ϕ(h(c + γξ)) at the Leja points (ξ0 , . . . , ξM ) ⊂ [−2, 2].
2.) : number of consecutive error estimates to be averaged in order to ﬁlter error
oscillations (the default = 5 has shown a good numerical behavior).
3.) Initializations: u = Ω0 w, q = p0 (A)w (cf. (1)).
4. - 9.) Main loop: Newton interpolation of the matrix operator ϕ(hA)w.
5.) Computes the vector ((A − cI)/γ − ξm I)u = Au/γ − (c/γ + ξm )u = Ωm+1 w,
avoiding to shift and scale the matrix.
6. - 7.) Computes em , the norm of the new term in the Newton interpolation,
and the vector q = pm (A)w.

690

L. Bergamaschi et al.

8.) Averages the last values of ei to get the actual interpolation error estimate.
9.) Exits the loop as soon as the estimated error is below the relative tolerance,
or the maximum interpolation degree M has been reached.
10.) Sets the output degree m to a value > M in case that convergence has not
been attained.

3

Numerical Tests and Comparisons

In this section we present some numerical examples, where we have tested the
ReLPM code on large scale matrices arising from spatial discretizations of 2D
and 3D advection-diﬀusion equations. The model problem is
∂u
−
→
= div(D∇u) − ϑ , ∇u , x ∈ Ω , t > 0 ,
∂t

(3)

with initial condition u(x, t) = u0 (x), x ∈ Ω, and mixed Dirichlet and Neumann
boundary conditions on ΓD ∪ ΓN = ∂Ω, Ω ⊂ Rd , d = 2, 3. In (3), D is a
→
−
d × d diﬀusion matrix, and ϑ ∈ Rd a constant velocity ﬁeld. Finite Diﬀerence
(FD) or Finite Elements (FE) discretizations produce a system of ODEs like
˙
y(t)
= Ay(t) + b, y(0) = u0 , where A is large, sparse and nonsymmetric. In the
FE case it is obtained cheaply by left-multiplying the stiﬀness matrix with the
inverse of a diagonal mass matrix, via the mass-lumping technique (cf. [2]).
In all the examples we have computed ϕ(ΔtA)v with v = (1, . . . , 1)t (corresponding to u0 ≡ 1), for two values (Δt)1 and (Δt)2 of the time step Δt,
depending on the speciﬁc matrix. The tests have been performed in double precision by a Fortran version of the ReLPM code, on an IBM Power5 processor
with 1.8Gb of RAM. We also give the comparisons with the PHIPRO Fortran
code by Y. Saad (again in double precision), which is based on Krylov subspace
approximations (cf. [12]). The results are collected in Table 4. We report, for
both methods, the number of substeps (steps), the number of total iterations
(i.e., of matrix-vector products), and the CPU time. In addition, for PHIPRO
we show also the chosen dimension for the Krylov subspace. This is a delicate
choice, for which a simple criterion does not seem to be available; in any case, the
default m = 60 is not suitable in the examples. The tolerances for both methods have been tuned in order to have an error, relative to the “exact” result
of the exponential operator, of about 10−6 in the 2-norm (which is compatible
with the underlying spatial discretization error). It is worth observing that even
using smaller tolerances the performances of both methods would not change
signiﬁcantly, since superlinear convergence has already been reached.
Example 1 (FE-2D). We have taken a 2D equation like (3), with Ω = (0, 1)2 ,
→
−
D = I, ϑ = (60, 60), and homogeneous Dirichlet boundary conditions. We have
adopted a standard Galerkin FE discretization with linear basis functions, on a
uniform mesh with n = 490 000 nodes and 977 202 triangular elements, which
produces a matrix with 3 424 402 nonzeros (average nonzeros per row ≈ 7). Here
(Δt)1 = 0.001 and (Δt)2 = 0.01.

Comparing Leja and Krylov Approximations

691

Table 4. Comparing ReLPM and PHIPRO on the advection-diﬀusion discretization
matrices in Examples 1–4 (the CPU times are in seconds)
Δt

Code
PHIPRO
m = 10
m = 20
(Δt)1 m = 25
m = 30
m = 50
ReLPM
PHIPRO
m = 10
m = 20
(Δt)2 m = 25
m = 30
m = 50
ReLPM

FE-2D
steps iter CPU
126 1386 57.1
40 840 45.5
29 754 43.2
23 713 45.4
13 663 58.4
17 857 27.0
steps iter CPU
868 9548 414.3
287 6027 318.8
190 4940 280.9
149 4619 306.6
73 3723 343.3
131 7720 227.3

FE-3D
steps iter CPU
81 891 59.8
28 588 50.2
21 546 45.2
17 527 48.1
10 510 58.9
12 585 32.0
steps iter CPU
428 4708 302.1
152 3192 242.1
117 3042 250.4
94 2914 268.0
53 2703 301.0
74 4335 231.7

FD-2D
steps iter CPU
54 594 44.2
21 441 43.1
16 416 45.6
13 403 55.4
8 408 67.5
5 392 20.6
steps iter CPU
431 4741 375.4
166 3486 323.4
126 3276 353.2
103 3193 415.6
58 2958 516.6
49 3617 186.3

steps
35
†
†
†
†
3
steps
158
†
†
†
†
16

FD-3D
iter CPU
385 349.3
†
†
†
†
†
†
†
†
234 133.0
iter CPU
1738 1593.2
†
†
†
†
†
†
†
†
1094 633.4

Example 2 (FE-3D). Here we have a 3D advection-dispersion equation, where
→
−
→
−
D is the hydrodynamic dispersion tensor, Dij = αT | ϑ |δij + (αL − αT )ϑi ϑj /| ϑ |,
1 ≤ i, j ≤ d (αL and αT being the longitudinal and transverse dispersivity, respectively). The domain is Ω = [0, 1]×[0.0.5]×[0, 1], discretized by a regular mesh
of n = 161 × 81 × 41 = 524 681 nodes and 3 072 000 tetrahedral elements. The
boundary conditions are homogeneous Dirichlet on ΓD = {0} × [0.2, 0.3] × [0, 1],
whereas homogeneous Neumann conditions are imposed on ΓN = ∂Ω \ ΓD .
→
−
The velocity is ϑ = (1, 0, 0), the transmissivity coeﬃcients are piecewise constant and vary by an order of magnitude depending on the elevation of the domain, αL (x3 ) = αT (x3 ) ∈ {0.0025, 0.025}. The resulting FE matrix has 7 837 641
nonzeros (average per row ≈ 14). Here (Δt)1 = 1 and (Δt)2 = 10.
→
−
Example 3 (FD-2D). Again a 2D model, with Ω = (0, 10)2 , D = I, ϑ =
(100, 100), and homogeneous Dirichlet boundary conditions. We have adopted a
second order central FD discretization on a uniform grid with stepsize 0.01 (n =
1 002 001 nodes), generating a pentadiagonal matrix with 5 006 001 nonzeros.
Here (Δt)1 = 0.01 and (Δt)2 = 0.1.
→
−
Example 4 (FD-3D). Here a 3D equation, with Ω = (0, 1)3 , D = I, ϑ =
(200, 200, 200), and homogeneous Dirichlet boundary conditions. Here we have
adopted a second order central FD discretization on a uniform grid with stepsize
0.005 (n = 8 120 601 nodes), generating an eptadiagonal matrix with 56 601 801
nonzeros. Here (Δt)1 = 10−3 and (Δt)2 = 5.2 × 10−3 .
Comments on the results. First, notice that ReLPM performs better than
PHIPRO in all the tests, even with an optimal choice of the Krylov subspace
dimension (underlined CPU times), in spite of a smaller number of total Krylov
iterations. Indeed, it is worth stressing that ReLPM computes only 1 matrix-

692

L. Bergamaschi et al.

vector product, 2 daxpys, 1 vector scaling and 1 scalar product per iteration
inside INTERP. Moreover, it allocates only the matrix and 6 vectors, whereas
PHIPRO has to allocate, besides the matrix, all the m Krylov subspace generators and 4 vectors (neglecting a matrix and some vectors of dimension m). In
addition, when m increases, PHIPRO decreases the total number of iterations,
but is penalized by the long-term recurrence in the orthogonalization process. For
small m, it is penalized by a larger number of substeps. The diﬀerence in storage
requirements produces remarkable consequences in the last example. There, the
matrix is extremely large, and PHIPRO can work only with m ≤ 10 due to the
memory limitations (1.8Gb), becoming about 2.5 times slower than ReLPM.

References
1. Baglama, J., Calvetti, D., Reichel, L.: Fast Leja points. Electron. Trans. Numer.
Anal. 7 (1998) 124–140
2. Bergamaschi, L., Caliari, M., Vianello, M.: The ReLPM exponential integrator for
FE discretizations of advection-diﬀusion equations. Springer LNCS vol. 3039 - part
IV, 2004 (Proc. of ICCS 2004) 434–442
3. Caliari, M.: Accurate evaluation of divided diﬀerences for polynomial interpolation
of exponential propagators. Draft (2005)
4. Caliari, M., Vianello, M., Bergamaschi, L.: Interpolating discrete advectiondiﬀusion propagators at Leja sequences. J. Comput. Appl. Math. 172 (2004) 79–99
5. Cox, S. M., Matthews, P. C.: Exponential time diﬀerencing for stiﬀ systems. J.
Comput. Phys. 176 (2002) 430–455
6. Druskin, V. L., Knizhnerman, L. A.: Two polynomial methods for calculating functions of symmetric matrices. U.S.S.R. Comput. Math. and Math. Phys. 29 (1989)
112–121
7. Hochbruck, M., Lubich, C., Selhofer, H.: Exponential integrators for large systems
of diﬀerential equations. SIAM J. Sci. Comput. 19 (1998) 1552–1574
8. Hochbruck, M., Ostermann, A.: Exponential Runge-Kutta methods for parabolic
problems. Appl. Numer. Math. 53 (2005) 323–339
9. McCurdy, A., Ng, C., Parlett, B. N.: Accurate Computation of Divided Diﬀerences
of the Exponential Function. Math. Comp. 43 (1984) 501–528
10. Moret, I., Novati, P.: The computation of functions of matrices by truncated Faber
series. Numer. Funct. Anal. Optim. 22 (2001) 697–719
11. Novati, P.: A polynomial method based on Fei´er points for the computation of
functions of unsymmetric matrices. Appl. Numer. Math. 44 (2003) 201–224
12. Saad, Y.: SPARSKIT: a basic tool kit for sparse matrix computations. Dept. of
Computer Science and Engineering, University of Minnesota. Version 2 (2005)
13. Schaefer, M. J.: A polynomial based iterative method for linear parabolic equations.
J. Comput. Appl. Math. 29 (1990) 35–50
14. Sidje, R. B.: Expokit. A software package for computing matrix exponentials. ACM
Trans. Math. Software 24 (1998) 130–156
15. Tal-Ezer, H.: Polynomial approximation of functions of matrices and applications.
J. Sci. Comput. 4 (1989) 25–60

