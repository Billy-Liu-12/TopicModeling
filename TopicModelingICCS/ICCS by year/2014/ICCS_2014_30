Procedia Computer Science
Volume 29, 2014, Pages 1888–1892
ICCS 2014. 14th International Conference on Computational Science

Scalable Stochastic and Hybrid Methods and
Algorithms for Extreme Scale Computing
Vassil Alexandrov1*
1

ICREA-Barcelona Supercomputing Center, Spain.
vassil.alexandrov@bsc.es

Abstract
Novel mathematics and mathematical modelling approaches together with scalable algorith ms are
needed to enable key applicat ions at extreme-scale. This is especially true as HPC systems continue to
At the mo ment computational scientists are at
scale up in compute node and processor core count.
the critical point/threshold of novel mathematics develop ment as well as large -scale algorithm
development and re-design and implementation that will affect most of the application areas. Thus the
paper will focus on the mathematical and algorith mic challenges and approaches towards exascale and
beyond and in particular on stochastic and hybrid methods that in turn lead to scalable scientific
algorith ms with minimal or no global co mmun ication, h iding network and memory latency, have very
high computation/communication overlap, have no synchronization points .
Keywords: Scalable Stochastic and Hybrid M athematical M ethods, M onte Carlo methods and algorithms,
Scalable Algorithms, Extreme Scale Computing

1 Introduction
The need for novel mathematics at exascale is clearly noted in (Dongarra et al 2011, US-OS 2009,
US-DOE 2013). Novel mathemat ics and mathemat ical modelling approaches together with scalable
algorith ms are needed to enable key applications at extreme-scale. This is especially t rue as HPC
systems continue to scale up in co mpute node and processor core count. At the mo ment computational
scientists are at the critical point/threshold of novel mathematics develop ment as well as large -scale
algorith m development and re -design and imp lementation that will affect most of the application
areas. Thus this position paper will focus on the mathematical and algorith mic challenges and
approaches towards exascale and beyond and in particular on stochastic a nd hybrid methods that in
turn lead to scalable scientific algorithms with minimal or no global co mmunicat ion, h iding network
*

ICREA-BSC, C/Jordi Girona 29, 08034 Barcelona, Spain

1888

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.173

Scalable Methods and Algorithms for Extreme Scale Computing

V. Alexandrov

and memo ry latency, have very high co mputation/communication overlap, have no synchronization
points. In order to achieve overall efficient scalability (Alexandrov V. 2013, ScalA 2011), scalability
at all three levels is required:
x
x
x

Mathematical model level
Algorithmic level
System level

Novel mathematical methods with inherent scalability and scalable algorith ms are needed to enable
advanced modelling and simulat ion (US-OS 2009, Dongarra et al 2011) of the climate system, air
pollution, disaster modelling of natural phenomena, energy efficiency as well modelling in bio logy
and drug design. The required advances are driven by the increased complexity of the problems (due
to the coupling of models, for examp le), increased number of equations and variables to be solved as
well as increasing t ime and spacial scales fro m local (nano) to g lobal ones. This increased co mplexity
and coupling of models poses additional requirement into not only solving problems with higher
resolutions but dealing with uncertainties, e.g. quantifying uncertainties in such systems, providing
risk assessment, etc.

2 Advantages of Applying Monte Carlo and Hybrid Methods
Monte Carlo and hybrid (stochastic/deterministic) methods seems to be very attractive as a
possible solution and to tackle the above challenges. For example, the stochastic methods such as
Monte Carlo as well as a the hybrid ones (stochastic/determin istic ones) may be a key in delivering
scalability at mathematical model and algorithmic levels.
These algorithms are naturally resilient and fault tolerant. In fact these algorithms have the
following key properties (Alexandrov V. 2013):
x

Enable minimum communication, achieved through data localization and replication.

x

Increased precision, is achieved by adding extra co mputations using the obtained solution so
far without restart .

x

Fault-Tolerance, is achieved by adding extra computations without restart.

x

They are naturally resilient, resilience is achieved by replacing the part of the lost or incorrect
computations with additional computations without restart.

x

May offer an efficient way to tackle and be able to solve multi-level, mult i-scale proble ms on
large-scale systems.

Fro m point of view o f the upcoming exascale architectures, scientific algorith ms for mult i-petaflop
and exa-flop systems also need to be fau lt tolerant and fault resilient, since the probability of faults
increases with scale. Resilience at the system software and at the algorithmic level is needed as a
crosscutting effort. Finally, with the advent of heterogeneous compute nodes that employ standard
processors as well as GPGPUs, scientific algorith ms need to match these architec tures to extract the
most performance. Th is includes different system-specific levels of parallelis m as well as coscheduling of co mputation. Key scientific applications require defin itely novel mathematical models

1889

Scalable Methods and Algorithms for Extreme Scale Computing

V. Alexandrov

and system software that address the scalability and resilience challenges of current- and futuregeneration extreme-scale HPC systems.

2.1 Data Localization and Communication Avoidance
The complexity of the problems to be solved in terms of mu lti-scale, mu lti-level and mu lti-physics
ones require fundamentally new classes of algorith ms, which have reduced global co mmunication
patterns, be highly fault -tolerant and resilient. These are stochastic and hybrid algorithms for linear
algebra (Alexandrov V. 2013, Slattery et al 2013) , nonlinear solvers, preconditioners (Strassburg J,
Alexandrov V. 2013), eigensolvers, mesh generation ODE’s and PDE’s. These are needed for all the
problems mentioned above to be modelled, simu lated and solved efficiently on large scale systems. In
fact for Solv ing Systems of Linear Algebraic (SLA E) and Matrix Inversion (M I) equations the author
has developed several approaches with efficient data d istribution with minimal co mmunication
(Strassburg J, Alexandrov V. 2013). Once data is localized all the samp ling is done on local for the
processor data. These approaches can be used for also solving PDE’s using stochastic or hybrid
approaches while the function is computed apriori or co mputed locally. These new methods and
algorith ms by design are able to possess the resilience and fault-tolerance properties outlined at the
beginning of Section 2.

2.2 Multi-level, Multi-scale, Multi-physics methods
The approaches applied lead usually to decomposing a global problem into loosely coupled large
set of independent problems (sub-problems). In (Pau li S., Arbenz P. and Schwab C. 2012), for
example, a Mult i-level Monte Carlo method is applied to solve a PDE on a massively parallel system.
The algorith m possess all the scalability properties outlined above. Mult i-level Monte Carlo methods
can also be efficiently used for solving stochastic ODE’s (Giles M 2008) and PDE’s (Cliffe K.A. et al
2011) arising for this class of problems. The above approach allow great flexib ility in terms of
minimizing commun ication and playing with the precision while solving the sub-problems and the
overarching problem.

2.3 Solving Problems with Uncertainty
Many mult i-physics, mult i-scale, mult i-level applications either arise or are related to solving
problems with uncertainty and uncertainty quantification. Uncertainty needs to be tackled in a
systematic way while coupling co mplex models, with mu lti-physics, mu lti-scale applications,
uncertainty needs to be propagated and estimate of uncertainty have to be provided. Uncertainty
quantification methods linking input and output uncertainty in case of large number of variab les are
needed. These require emp loy ment of advanced stochastic and Monte Carlo methods as well as hybrid
methods and algorithms are needed.

2.4 Other Application Areas
Other problems wh ich can be efficiently tackled with Monte Carlo Methods are mu lti -dimensional
integration and unconstrained and constrained optimization, for example. We observe the same
properties, localizat ion of data, minimal co mmun ication, and localization of the function to be
computed (both in case of Integration and Opt imization). In case of g lobal optimizat ion, very
effective part itioning of the do main can be achieved. For examp le, methods such as Monte Carlo

1890

Scalable Methods and Algorithms for Extreme Scale Computing

V. Alexandrov

combined with Nested Part itions method could lead to potentially very efficient parallel
implementations.

3 Conclusions
In this position paper, the advantages of designing stochastic and hybrid methods were outlined.
These methods possess a set of important properties, which make them very suitable for efficient
implementation on extreme scale computing systems:
x

Enable minimum communication, achieved through data localization and replication.

x

Increased precision, is achieved by adding extra co mputations using the obtained solution so
far without restart .

x

Fault-Tolerance, is achieved by adding extra computations without restart.

x

They are naturally resilient, resilience is achieved by replacing the part of the lost or incorrect
computations with additional computations without restart.

In addition, these can be applied to variety of important scientific problems and applications such
as: multi-scale, mu lti-physics methods, solving problems with uncertainties, linear algebra, nonlinear
solvers, preconditioners, eigensolvers, solving ODE’s and PDE’s. So me recent advances has already
shown the efficiency of this approach, but novel scalable stochastic and hybrid mathematical methods
and algorith ms are needed to be designed and developed in order to exp lore fu lly the efficiency of th is
approach.

Acknowledgements
This research work was partially supported by High Performance Co mputing VI project, nu mber
TIN2012-34557, of the Spanish Ministry of Economics and Competitiveness .

References
Alexandrov V. (2013), Towards scalable mathematics and scalable algorithms for extreme scale
computing, Journal of Computational Science, 4(2013)iii–v.
Dongarra et al (2011), The International Exascale Soft ware Project Roadmap, The International
Journal of High Performance Computing Applications, 25(1), pp. 3-60, 2011.
Giles M, (2008), Multilevel Monte Carlo Path Simulation, Operations Research, 56 (3) pp. 607-617.
Cliffe K.A. et all, (2011), Mu ltilevel Monte Carlo Methods and Applications to elliptic PDE’s with
random coefficients, Reprint 1/11, 2011.

1891

Scalable Methods and Algorithms for Extreme Scale Computing

V. Alexandrov

US-OS (2009), Modelling and Simu lation at the Exascale for Energy and the Environ ment, US Office
of Science, 2009.
Pauli S., Arbenz P. and Schwab C. (2012), Intrinsic Fault Tolerance of Mult i-Level Monte Carlo
Methods, Research report No 2012-24, August 2012, ETH, Switzerland
ScalA’11,
Latest
Advances
in
Scalable
http://www.csm.ornl.gov/srt/conferences/Scala/2011/

Algorith ms

for

Large-Scale

Systems,

Slattery S.R. et al, 2013, A Mult iple-set Overlapping-Do main Deco mposed Monte Carlo Synthetic
Acceleration Method for Linear Systems, Joint International conference on supercomputing in Nuclear
Applications and Monte Carlo 2013, Paris, France, 2013.
J. Straßburg, V.N. Alexandrov (2013), “A Monte Carlo Approach to Sparse Appro ximate Inverse
Matrix Co mputations,” Procedia Co mputer Science, Vo lu me 18, 2013, Pages 2307-2316, ISSN 18770509, http://dx.doi.org/10.1016/ j.procs.2013.05.402.

1892

