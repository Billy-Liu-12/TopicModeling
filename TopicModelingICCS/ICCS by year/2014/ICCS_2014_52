Procedia Computer Science
Volume 29, 2014, Pages 534–545
ICCS 2014. 14th International Conference on Computational Science

On Resource Eﬃciency of Workﬂow Schedules
Young Choon Lee, Hyuck Han and Albert Y. Zomaya
The University of Sydney, Sydney, NSW, Australia
{young.lee, albert.zomaya}@sydney.edu.au
Dongduk Women’s University, Korea
hhyuck96@dongduk.ac.kr

Abstract
This paper presents the Maximum Eﬀective Reduction (MER) algorithm, which optimizes the
resource eﬃciency of a workﬂow schedule generated by any particular scheduling algorithm.
The ineﬃciency in resource usage of workﬂow execution/schedule is not only in the number of
resources used, but also the actual amount of “used” resource time, including idle time between
any two task executions sourced from data dependencies. MER trades the minimal makespan
increase for the maximal resource usage reduction by consolidating tasks with the exploitation
of resource ineﬃciency in the original workﬂow schedule. Our evaluation using traces from four
real-world scientiﬁc workﬂow applications shows that the rate of resource usage reduction far
outweighs that of the increase in makespan, i.e., the number of resources used is halved on
average while incurring an increase in makespan of less than 10%.
Keywords: Scientiﬁc Workﬂows, Resource Eﬃciency, Workﬂow Scheduling, Resource Management

1

Introduction

Eﬃcient resource management (resource eﬃciency) is a main operational goal in large-scale
computer systems. Despite various eﬀorts, resource utilization in these systems is usually
below 10% due primarily to resource over-provisioning [7]. In other words, resource capacity
is far greater than that needed by applications. Today, resource capacity is abundant; small
commodity server clusters often consist of dozens of compute nodes, each of which contains
multiple processor cores, and public clouds are both readily available and easily accessible.
Applications in science and engineering are becoming increasingly large-scale and complex.
These applications are often amalgamated in the form of workﬂows (such as Montage [2],
CyberShake [1, 6], Epigenomics [5] and SIPHT [13]) with a large number of composite software
modules and services, often numbering in the hundreds or thousands. Most of these applications
enjoy today’s ample resource capacity for performance as they scale well with the number of
resources (resource capacity). For example, the execution time of a Montage application [2] (an
astronomical image mosaic engine, Figure 1a) with 64 processors is just 23.5 minutes, compared
to 453 minutes with one processor [9]. However, this performance improvement may not be
534

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.048

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya
resource

(a) Structure.

(b) No resource limit.

time

time

resource

(c) Resource limit of 4.

Figure 1: Montage workﬂow and two example schedules.
well justiﬁed when resource eﬃciency is a major concern. The ineﬃciency in resource usage of
workﬂow execution/schedule is not only in the number of resources used, but also the actual
amount of “used” resource time, including idle time between any two task executions sourced
from data dependencies.
In traditional workﬂow scheduling, resource eﬃciency is not explicitly dealt with; rather,
since a ﬁxed number of resources is assumed, performance (completion time or makespan) is
viewed as an implicit indication of resource eﬃciency. However, with the virtually unlimited
resource capacity in today’s multi-core era, resource eﬃciency is a function of both makespan
and resource usage. Unless makespan is ﬁxed, the resource eﬃciency of a workﬂow schedule is
not apparent due to the incompatibility between makespan and resource usage.
In this paper, we address the problem of optimizing the resource eﬃciency of workﬂow
schedule. In particular, we propose Maximum Eﬀective Reduction (MER), a workﬂow schedule optimization algorithm that takes as input a workﬂow schedule generated by an existing
scheduling algorithm. With the allowance of a limited increase in the original makespan, MER
consolidates tasks into a fewer number of resources than that used for the original schedule. To
do this, MER essentially optimizes the trade-oﬀ between makespan increase and resource usage
reduction. This trade-oﬀ is referred to as eﬀective reduction (ER) in this study. ER is a relative
resource eﬃciency metric and is deﬁned as the diﬀerence between the resource usage reduction
and makespan increase in a resulting consolidated schedule as compared to the original output
schedule.
The main novelty of MER lies in its identiﬁcation of “near-optimal”1 trade-oﬀ point between makespan increase and resource usage reduction. The innovation is in its simplicity and
eﬀectiveness proved by evaluation results. In traditional workﬂow scheduling, such identiﬁcation can be interpreted as determining the number of resources to be used (resource limit)
for a particular workﬂow. However, the pre-determination of “right/optimal” resource limit
is nearly impossible as the impact of resource limit on the makespan of resuling schedule is
non-deterministic.
Results from our extensive experiments, using traces from ﬁve real-world scientiﬁc workﬂow
applications, show a signiﬁcant improvement in resource eﬃciency. When our schedule optimization algorithm is applied to an output schedule, the rate of resource usage reduction far
outweighs that of any increase in makespan. Speciﬁcally, resource usage (#resources used) is
reduced by 54% with a corresponding 10% increase in makespan.
1 Here, the optimality is empirically determined with an extensive set of experiments since makespan minimization and resource reduction are conﬂicting objectives.

535

On Resource Eﬃciency of Workﬂow Schedules

(a) SIPHT.

Lee, Han, Zomaya

(b) Epigenomics.

(c) CyberShake.

Figure 2: Scientiﬁc Workﬂows.

The rest of this paper is organized as follows. Section 2 motivates the problem of optimizing
resource eﬃciency of workﬂow schedule. Section 3 formalizes the problem with the description
of application and system models. Section 4 presents the MER algorithm. Section 5 evaluates
our solution and present experimental results. Section 6 reviews related work. Our conclusion
is drawn in Section 7.

2

Motivation

While previous work on workﬂow scheduling has focused on increasing the performance
(makespan) with a limited amount of resources (resource limit), the advent of multi-core processors and cloud computing has brought much attention to resource eﬃciency. Since it is very
diﬃcult, if not impossible, to ﬁnd the optimal resource amount for scheduling a given workﬂow
application, and since current workﬂow scheduling algorithms perform quite well in terms of
makespan, the post-processing of output workﬂow schedules may be a practical approach to
optimizing resource usage.
To illustrate the ineﬃciency in resource usage, we use a simple Montage workﬂow (Figure
1a) and its two example schedules (Figures 1b and 1c). Here, resource usage not only refers to
the number of resources used, but also the actual amount of used resource time, including idle
time as 50% or more of peak power is drawn while CPU is idling [4].
The graph in Figure 1a depicts a Montage workﬂow with vertices for tasks and edges for
data dependences or precedence constraints. As tasks constituting the width are most likely
to run in parallel and get assigned onto diﬀerent resources, the number of resources used for a
workﬂow schedule tends to be heavily aﬀected by the width of the graph if no resource limit
is imposed. Unless many levels in a workﬂow have similar widths, the utilization of resources
allocated to some of those tasks constituting the maximum width is very poor. For example,
the scheduling of dark circled tasks in Figure 1a spans across nine resources, leaving the last
four resources to have poor utilization (Figure 1b). An extreme case of such poor utilization is
a bioinformatics workﬂow shown in Figure 2a.
Limiting the number of resources to be used (resource limit) at the time of scheduling is only
a partial and ad-hoc solution (Figure 1c). Moreover, the eﬀectiveness of such a solution varies
for diﬀerent applications, and even with executions of a particular application with diﬀerent
inputs (e.g., data and/or parameter values). Although the workﬂows in Figures 2b and 2c are
very regular in shape and a good resource limit is expected to be easily set, variations in task
execution times, particularly within the same level, disappoint this expectation.
536

On Resource Eﬃciency of Workﬂow Schedules

3

Lee, Han, Zomaya

Schedule Optimization Problem

A workﬂow application can be represented by a directed acyclic graph (DAG), G = V , E
comprising a set V of tasks, V = {v0 , v1 , ..., vn }, and a set E of edges, each of which connects
two tasks representing their precedence constraint or data dependency. A task is ready to run
if all of its parent tasks have completed their execution and communication. The earliest start
time (EST) of a task vi is then determined by the parent task that completes its communication
at the latest time; however, the actual start time (AST) may diﬀer due to the synchronization
required by its child tasks. AST should be between EST and LST (the latest start time), or
an increase/delay occurs to makespan. Corresponding ﬁnish times are denoted as EFT, AFT
and LFT, respectively. We assume characteristics of a workﬂow, including the composition,
data and computational requirements, are either known or can be obtained using application
proﬁling and performance estimation techniques, e.g., [5, 15].
The target system in this study consists of a set R of homogeneous compute resources, R =
{r0 , r1 , ..., rm }. A resource can be a physical compute node or a virtual machine (particularly
in public clouds). Each resource in R consists of a set of p processing elements or (virtual)
processor cores, i.e., ri = {ri,0 , ri,1 , ..., ri,p }. We assume inter-task communication costs are
negligible (i.e., 0) within a single resource. Resources are assumed to be homogeneous in terms
of their core count, computing power and cost.
Assume a workﬂow schedule S 0 is the output of a scheduling algorithm for a given scientiﬁc
workﬂow G and a set of resources R. The output schedule is an execution plan for tasks in
G with a subset R0 of resources used from R, and it contains a set of 3-tuples. Each 3-tuple
consists of a task vi , a resource rj,k and AST (vi ). A set of tasks scheduled on resource rj,k is
denoted as Vj,k . The total resource time used for resource rj,k is deﬁned as the summation of
execution times of tasks in Vj,k , and is denoted by RT (rj,k ). A schedule can be represented as
a Gantt chart, e.g., Figures 1b and 1c.
The workﬂow schedule optimization problem addressed in this paper is to ﬁnd a
consolidated schedule S ∗ , of an original output schedule S 0 , that maximizes the reduction in
resource usage (i.e., the number of resources used or |R0 |) with the minimal makespan increase.
S 0 is the main input and is generated by any given scheduling algorithm.
As makespan only represents the total resource usage of a particular resource, and resource
utilization with workﬂow execution is not an accurate measure for resource eﬃciency, we adopt
eﬀective resource usage reduction, or eﬀective reduction (ER) for short, which measures how
far resource usage reduction (RU R) outweighs makespan increase (M I), i.e., RU R - M I. More
∗
0
|−|R∗ |)
−ms0 )
formally, ER is deﬁned as (|R |R
− (msms
, where |R∗ | is the number of resources used
0|
0
after consolidation, and ms0 and ms∗ are the makespan of original schedule and that of resulting
consolidated schedule, respectively.

4

Maximum Eﬀective Reduction Algorithm

In this section, we present MER, which optimizes workﬂow schedules in three steps: (1) delay
limit identiﬁcation, (2) task consolidation and (3) resource consolidation.

4.1

Delay Limit Identiﬁcation

Finding the minimum makespan increase for the maximal resource reduction is the key to our
schedule optimization problem. To this end, we devise a simple heuristic called Delay Limit
Identiﬁcation (Algorithm 1). The idea is that resources with a small RT (total resource time
537

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya

Algorithm 1: Delay Limit Identiﬁcation
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

R ← sorted resources of R0 in ascending order by RT
group R by RT
srcnt ← 0
ERmax ← 0
for Ri ∈ (R − R|R | ) do
srcnt ← srcnt + |Ri |
ms ← ms0 + RTi
trcnt ← |R0 | − srcnt
if srcnt > trcnt then
srcnt ← ( srcnt
trcnt − 1) · trcnt
while srcnt > 0 do
ms ← ms + srcnt th RT in R
srcnt ← srcnt − trcnt
0

−ms )
M I ← (msms
0
RU R ← srcnt/|R0 |
ER ← RU R − M I
if ER > ERmax then
ERmax ← ER
dlimit ← M I

used, i.e., few scheduled tasks) are more likely to be easily consolidated with a minimal increase
in makespan.
We incrementally search the original schedule to identify the maximum ER. The incremental
search is based on RT as the increase in makespan due to the consolidation of tasks in a
particular resource is essentially bounded by the total resource time used by those tasks (hence,
the calculation of increased makespan ms in line 7). For this reason, we both sort and group
resources by RT before the search. Resources in each group Ri thus have the same RT.
For each resource group Ri , we incrementally examine the trade-oﬀ (ER) between RUR and
MI taking into account previous resource groups; RUR is calculated based on the cumulative
number of resources (srcnt in line 6) up to the current resource group Ri in the examination.
Resources accounting for srcnt are referred to as source resources while the rest are referred to
as target resources and the number of target resources is denoted by trcnt.
In the meantime, the calculation of MI can be a little complicated when the number of source
resources considered for consolidation (srcnt) is greater than that of target resources (trcnt),
i.e., srcnt > trcnt in line 9. In this case, one or more source resources are consolidated into each
of target resources and the increase in makespan is “pessimistically” estimated. Speciﬁcally,
MI is calculated based on the summation of RT’s (line 12) for the worst case scenario. For
example, when seven source resources are considered for being consolidated into three target
resources, the makespan in the worst case is the summation of RT’s of 7th, 6th and 3rd source
resources as resources in R are sorted in increasing order by RT.
We terminate the delay limit identiﬁcation when we reach the resource with the maximum
RT (the last resource group in R or R|R | ) since the number of resources in R|R | is considered
as the minimum number of resources needed. The MI of maximum ER (ERmax ) is in the end
is set to the delay limit (dlimit ).
538

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya

Algorithm 2: Task Consolidation
1
2
3
4
5
6
7
8
9
10
11
12

R∗ ← R0
S∗ ← S0
for ri∗ ∈ R∗ (from the last resource in S 0 ) do
R ← R∗ − ri∗
∗
for vi,j
∈ Vi∗ do
for rk ∈ R do
∗
AST (vi,j
, rk ) ← FindMinMISlot
∗
if AST (vi,j
, rk ) = ∞ then
∗
∗
insert vi,j
at AST (vi,j
, rk )
∗
update schedule (S )
dlimit ← dlimit − mimin
break

14

if ri∗ is empty then
R∗ ← R∗ − ri∗

4.2

Task Consolidation

13

As resource usage becomes poorer towards the last resource in the schedule (see Figure 1b),
task consolidation starts from the last resource used for the original schedule. For each task
considered for consolidation, our task consolidation algorithm (Algorithms 2 and 3) searches for
the resource on which the increase in makespan after consolidation is expected to be minimal.
The search takes place for all used resources except the one on which the task is currently
scheduled (line 4). In other words, a task on a given resource (ri∗ ) can be consolidated into a
resource used later than ri∗ . For example, two tasks in a resource (ri∗ ) can be consolidated into
∗
) than ri∗ (the left side of ri∗ in the schedule) that
two diﬀerent resources, one used earlier (ri−1
∗
) than ri∗ (the
have not yet been checked for consolidation, and the other one used later (ri+1
right side), whose originally scheduled tasks are most likely partially consolidated.
A task is essentially inserted into a slot in which the increase in makespan is minimal. The
identiﬁcation of such a slot is described in Algorithm 3. A task can be consolidated in either of
the following two ways: (1) the task is inserted into an idle slot without aﬀecting the LSTs of any
other tasks (MI ≤ 0), or (2) the task is inserted by delaying the execution of one or more tasks
(the delay is propagated) beyond their LSTs (MI > 0). While the consolidation in (1) simply
requires rescheduling the target task and updating the schedule information (e.g., AST) of that
task and tasks being pushed down2 if any, that in (2) involves an additional process to deal
with delay propagation. Although handling such delay propagation is complicated, the ultimate
makespan increase due to a particular task consolidation can be calculated relatively easily. For
a given task to be consolidated into a resource, the makespan increase is the maximum of the
delays to LSTs of subsequently scheduled tasks (v next tasks) of the consolidating task on that
resource (line 13). We keep track of the slot in which the consolidation results in the minimum
makespan increase (lines 19-20). The eventual minimum MI (M I min ) is checked if it is within
the delay limit (line 22).
Once a task is consolidated with a makespan increase, the schedule (S ∗ ) needs to be updated
2 The number of tasks pushed down is mostly a small fraction of the total number of tasks since pushed-down
tasks are only on a particular resource.

539

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya

Algorithm 3: Find Minimum Makespan Increase Slot
1
2
3
4
5
6

∗
function FindMinMISlot(vi,j
, rk )
M I min ← ∞
for vk,l ∈ Vk do
calculate AST (v ∗ i, j, rk ) before vk,l
if AST (v ∗ i, j, rk ) > LST (v ∗ i, j, rk ) + dlimit then
break

7
8
9
10
11
12
13
14

dmax ← AST (v ∗ i, j, rk ) − LST (v ∗ i, j, rk )
v cur ← vk,l
v next ← v cur + 1
while v next = ø do
if AF T (v cur , rk ) > AST (v next , rk ) then
dcur ← AF T (v cur , rk ) − LST (v next , rk )
if dcur > dmax then
dmax ← dcur

16

else
break

17

v next ← v cur + 1

15

18
19
20
21
22
23
24
25

max

M I ← dms0
if M I < M I min then
M I min ← M I
AST ∗ ← AST (v ∗ i, j, rk )
if M I min > dlimit then
return ∞
else
return AST ∗

(line 10 in Algorithm 2) to deal with the delay propagation caused by the consolidated task.
Tasks aﬀected (delayed their completion beyond LST) by the consolidation are identiﬁed and
their schedule data are updated. Such an identiﬁcation takes place recursively from successor
tasks of the consolidated task, subsequently scheduled tasks on the same resource of the consolidated task, successor tasks of these subsequently scheduled tasks, and so on. The delay limit
(dlimit ) is then reduced by the current makespan increase (line 11).
If all tasks in a resource are consolidated into other resources (line 13), that resource is
removed from the new resource set.

4.3

Resource Consolidation

After consolidating tasks, we consolidate partly used resources in a best-ﬁt manner (Algorithm
4). In particular, multi-core resources with one or more unused cores (but not all) are considered
for consolidation as these partly-used resources are still regarded as being ineﬃcient in terms
of, for example, energy eﬃciency.
Resources with half or fewer of their cores used (R in line 3) are considered as source
540

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya

Algorithm 4: Resource Consolidation
1
2
3
4
5
6
7
8
9

R ← sorted resources of R∗ in ascending order by #used cores
R ← R − resources fully used
R ← R - resource with #used cores > total#cores
2
for ri ∈ R do
R ← R − ri
for rj ∈ R (from the last resource) do
if #unused cores of rj ≥ #used cores of ri then
consolidate ri into rj
break
if ri is not consolidated then
break

10
11

Table 1: Workﬂow Traces. Each job consists of 20 variants with diﬀerent characteristics.
application
CyberShake
Epigenomics

#workﬂow jobs
220
440

Montage
SIPHT

220
320

#tasks in a job (workﬂow size)
50 and [100, 1000] with an interval of
50, [100, 1000] with an interval of 100
{2000, 3000, 4000, 5000, 6000}
50 and [100, 1000] with an interval of
50, [100, 1000] with an interval of 100
{2000, 3000, 4000, 5000, 6000}

100
and
100
and

resources to be consolidated. Each of these resources (R ) is checked with the rest of partly
used resources (R − ri ) from the last resource in R , which is the sorted list of used resources
in ascending order by the number of used cores. A resource is consolidated as a whole due to
inter-resource communication. We stop resource consolidation as soon as a source resource (ri )
is not consolidated (line 10). Resources later in R than ri have at least the same or more used
cores; and thus, they too are unable to be consolidated.

5

Evaluation

In this section, we evaluate MER in a simulated environment with three diﬀerent scheduling
algorithms and under four diﬀerent workﬂow applications. The scheduling algorithms we use
are Critical Path First (CPF) [12], Dynamic Critical Path (DCP) [10] and Critical-Path-ona-Processor (CPOP) [17]. The workﬂow applications are CyberShake, Epigenomics, Montage
and SIPHT. Workﬂow data was obtained from the Pegasus Workﬂow repository [3] and is
summarized in Table 1.

5.1

Performance of MER

We present results using three performance metrics eventually conversing into eﬀective reduction
(ER): (1) makespan increase (MI), (2) resource usage reduction (RUR) and (3) delay limit
(dlimit ). Note that MI is the actual makespan increase bounded by the estimated MI (dlimit
541

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya

Table 2: Simulation results of MER. ms0 and ms∗ denote the makespan (in seconds) of the
original schedule and that after the consolidation, respectively. |R0 | and |R∗ | denote the number
of resources used in the original schedule and that in the consolidated schedule, respectively.
app.
CyberShake
Epigenomics
Montage

SIPHT

result
ms0 , ms∗ (M I)
|R0 |,|R∗ |(RU R)
dlimit
0
ms , ms∗ (M I)
|R0 |,|R∗ |(RU R)
dlimit
0
ms , ms∗ (M I)
|R0 |,|R∗ |(RU R)
dlimit
0
ms , ms∗ (M I)
|R0 |,|R∗ |(RU R)
dlimit

CPF
566, 681 (20%)
20.9, 9.7 (54%)
24%
20876, 23577(13%)
31.2, 24.4 (22%)
18%
212, 242 (14%)
42.0, 11.2 (73%)
18%
5169, 5170 (≈0%)
117.2, 10.8 (91%)
1%

CPOP
684, 806 (18%)
18.7, 6.5 (65%)
23%
23634, 29703(26%)
40.5, 17.0 (58%)
36%
231, 255 (10%)
41.3, 10.9 (74%)
17%
7256, 7261 (≈0%)
135.5, 10.8 (92%)
1%

DCP
567, 682 (20%)
20.8, 9.5 (54%)
24%
20878, 23083(11%)
30.6, 24.9 (18%)
14%
212, 241 (14%)
42.0, 11.3 (73%)
18%
5169, 5188 (≈0%)
107.3, 11.8 (89%)
2%

identiﬁed by Algorithm 1). Experimental results are averaged and summarized in terms of these
three metrics in Table 2.
Overall, MI is relatively low (≤ 20% and many even close to nil) compared to RUR (mostly
> 50%) except in case of CPOP with Epigenomics. MI values always stay below dlimit . We
have also observed that the actual RUR remains very close to that estimated by Algorithm 1,
i.e., within ≈ 2%. This proves the eﬀectiveness of our heuristic (Algorithm 1).
The most notable results are with SIPHT, leading to a RUR of around 90%, and an average
MI of nearly 0, irrespective of scheduling algorithm. This signiﬁcant gain in ER is sourced
from the unbalanced distribution of tasks in SIPHT workﬂows, in which there are a much
larger number of entry tasks than those in the rest of the workﬂow (see Figure 2a). These
entry tasks are distributed across many resources, causing poor overall resource usage. Since
execution times of these entry tasks account for only a fraction of the makespan (i.e., these are
short tasks), their consolidation minimally impacts MI while reducing RUR to a much greater
degree. In the meantime, due to the regularity in Epigenomics workﬂows (i.e., the structure
and execution times of sibling tasks), the degree of schedule consolidation is smaller than that
of the other three workﬂows.

5.2

Eﬃcacy of Delay Limit Identiﬁcation

The identiﬁcation of the right delay limit plays a crucial role in maximizing ER; thus, we
verify the eﬃcacy of MER in making such an identiﬁcation by comparing ER values of the
experimental best with MER’s. We manually set diﬀerent (makespan) delay limits between 0
and 1 with an interval of 0.1. We also add a delay limit of 0.05 (5%) since the schedules of
some workﬂow applications can be well consolidated without much makespan increase. The
maximum ER value for each workﬂow is identiﬁed and presented in Figure 3 with the ER
value of MER. It seems clear that MER (more precisely, Algorithm 1) is capable of ﬁnding the
minimum delay limit and trading it maximally with resource usage reduction.
542

Effective Reduction (ER)

On Resource Eﬃciency of Workﬂow Schedules
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

experimental best

EFT

CPF

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

MER

CPOP

Lee, Han, Zomaya

DCP

experimental best

EFT

(a) CyberShake
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

experimental best

EFT

CPF

CPOP

(c) Montage

CPF

MER

CPOP

DCP

(b) Epigenomics
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

MER

DCP

experimental best

EFT

CPF

CPOP

MER

DCP

(d) SIPHT

Figure 3: Performance of MER with respect to experimental best.

6

Related Work

In many respects, workﬂow scheduling is similar to the conventional task scheduling problem
and can be seen as coarser-grain task scheduling. Typically, regardless of task granularity, the
assumption is that the number of resources is fewer than the number of tasks in a workﬂow;
thus, resource eﬃciency is a lesser concern. The majority of previous studies on workﬂow
scheduling (e.g., [16, 14, 8, 11]) either minimize makespan within the resource capacity available
or minimize the cost of running workﬂows, particularly in clouds. While the former objective is
achieved using all available resources, the latter is mostly sought with minimal resource usage.
These objectives are conﬂicting and yet, closely related to resource eﬃciency.
The work in [16] adopts multi-dimensional graph partitioning to minimize data transfer. As
many scientiﬁc workﬂows increasingly become data-intensive, such minimization is crucial for
performance. Although the minimization of makespan resulted from reduced data transfer has
an implication that the amount of idle slots within a schedule can be minimized, the application
of this work is very diﬃcult when the number of resources is unlimited as in this study.
Works in [14, 8] exploit the deadline ﬂexibility of scientiﬁc workﬂows to reduce execution
costs. M. Mao and M. Humphrey [14] deal with multiple workﬂows using a load vector to
consolidate tasks to minimize #resources, or instances in Amazon EC2. For a given instance,
once a multiple of hours is being reached and no jobs/tasks are assigned to the instance, it is
released (terminated). The instance acquisition and release are dynamically done to minimize
cost without breaching application deadlines.
Ishakian et al. in [8] propose CloudPack, a workload colocation framework that exploits
543

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya

workload ﬂexibilities—similar to allowable delay (or LST −EST ) in this study—for cost savings.
They adopt a dynamic pricing model to more cost eﬀectively deal with provisioning of user
workloads expressed by DAG.
Our work diﬀers from these works in the resource eﬃciency model. Resource eﬃciency in our
study is optimized based on the actual resource usage rather than the number of resource hours.
Further, our objective function (ER) eﬀectively captures the trade-oﬀ between two conﬂicting
objectives, makespan and resource usage.

7

Conclusion

Resource eﬃciency with today’s ample resource capacity is ever important and, whether it is a
research lab’s multi-core cluster or a public cloud, such as Amazon EC2, it is a core operational
goal in computer systems. In this paper, we have studied the optimization of resource eﬃciency
when running large-scale workﬂows. Our MER algorithm optimizes the resource usage of output
workﬂow schedules with a consideration of the trade-oﬀ between resource usage reduction and
makespan increase. MER essentially exploits the inherent resource ineﬃciency in workﬂow
schedules due to task dependencies—an ineﬃciency that worsens when the resource capacity
of target system surpasses resource requirements of a workﬂow. Our study has revealed that
by allowing a small degree of makespan increase, such exploitation reduces resource usage far
greater than any incurred makespan increase. The resulting improvement in resource eﬃciency
has many implications including cost savings and reduction of energy consumption.

Acknowledgement
Dr. Young Choon Lee would like to acknowledge the support of the Australian Research
Council Discovery Early Career Researcher Award Grant DE140101628. Prof. Albert Zomaya
would like to acknowledge the support of the Australian Research Council Discovery Grant
DP130104591.

References
[1] Cybershake. http://scec.usc.edu/scecpedia/CyberShake, 2013.
[2] Montage: An astronomical image mosaic engine. http://montage.ipac.caltech.edu/, 2013.
[3] Pegasus workﬂow repository.
https://confluence.pegasus.isi.edu/display/pegasus/
WorkflowGenerator, 2013.
[4] Luiz Andr´e Barroso and Urs H¨
olzle. The case for energy-proportional computing. Computer,
40(12):33–37, December 2007.
[5] S. Bharathi, A. Chervenak, E. Deelman, G. Mehta, Mei-Hui Su, and K. Vahi. Characterization
of scientiﬁc workﬂows. In Proceedings of Third Workshop on Workﬂows in Support of Large-Scale
Science (WORKS), pages 1–10. IEEE, November 2008.
[6] Robert Graves, Thomas H. Jordan, Scott Callaghan, Ewa Deelman, Edward Field, Gideon Juve,
Carl Kesselman, Philip Maechling, Gaurang Mehta, Kevin Milner, David Okaya, Patrick Small,
and Karan Vahi. Cybershake: A physics-based seismic hazard model for southern california. Pure
and Applied Geophysics, 168(3-4):367–381, 2010.
[7] Albert Greenberg, James Hamilton, David A Maltz, and Parveen Patel. The cost of a cloud:
research problems in data center networks. ACM SIGCOMM Computer Communication Review,
39(1):68–73, 2008.

544

On Resource Eﬃciency of Workﬂow Schedules

Lee, Han, Zomaya

[8] Vatche Ishakian, Raymond Sweha, Azer Bestavros, and Jonathan Appavoo. Cloudpack* exploiting
workload ﬂexibility through rational pricing. In Proceedings of the 13th International Middleware
Conference, Middleware ’12, pages 374–393, New York, NY, USA, 2012.
[9] Daniel S. Katz, Joseph C. Jacob, G. Bruce Berriman, John Good, Anastasia C. Laity, Ewa Deelman, Carl Kesselman, and Gurmeet Singh. A comparison of two methods for building astronomical
image mosaics on a grid. In Proceedings of the 2005 International Conference on Parallel Processing Workshops, ICPPW ’05, pages 85–94, Washington, DC, USA, 2005. IEEE Computer Society.
[10] Yu-Kwong Kwok and Ishfaq Ahmad. Dynamic critical-path scheduling: An eﬀective technique for
allocating task graphs to multiprocessors. IEEE Transactions on Parallel and Distributed Systems,
7(5):506–521, 1996.
[11] Young Choon Lee, Riky Subrata, and Albert Y. Zomaya. On the performance of a dual-objective
optimization model for workﬂow applications on grid platforms. IEEE Transactions on Parallel
and Distributed Systems, 20(9):1273–1284, September 2009.
[12] Young Choon Lee and Albert Y. Zomaya. Stretch Out and Compact: Workﬂow Scheduling with
Resource Abundance. In Proc. of the Int’l Symposium on Cluster Cloud and the Grid (CCGRID),
2013.
[13] Jonathan Livny, Hidayat Teonadi, Miron Livny, and Matthew K. Waldor. High-Throughput,
Kingdom-Wide Prediction and Annotation of Bacterial Non-Coding RNAs.
PLoS ONE,
3(9):e3197+, September 2008.
[14] Ming Mao and Marty Humphrey. Auto-scaling to minimize cost and meet application deadlines
in cloud workﬂows. In Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis (SC), pages 49:1–49:12, 2011.
[15] G. R. Nudd, D. J. Kerbyson, E. Papaefstathiou, S. C. Perry, J. S. Harper, and D. V. Wilcox.
Pace–a toolset for the performance prediction of parallel and distributed systems. International
Journal of High Performance Computing Applications, 14(3):228–251, August 2000.
[16] Masahiro Tanaka and Osamu Tatebe. Workﬂow scheduling to minimize data movement using
multi-constraint graph partitioning. In Proceedings of the 2012 12th IEEE/ACM International
Symposium on Cluster, Cloud and Grid Computing (CCGRID), pages 65–72, 2012.
[17] Haluk Topcuouglu, Salim Hariri, and Min-you Wu. Performance-eﬀective and low-complexity task
scheduling for heterogeneous computing. IEEE Transactions on Parallel and Distributed Systems,
13(3):260–274, 2002.

545

