Procedia Computer Science
Volume 29, 2014, Pages 2162–2167
ICCS 2014. 14th International Conference on Computational Science

Using Kepler for Tool Integration in Microarray
Analysis Workflows
Zhuohui Gan1, Jennifer C. Stowe1, Ilkay Altintas2, Andrew D. McCulloch1,
Alexander C. Zambon3
1

2

Department of Bioengineering, University of California, San Diego, La Jolla, CA, USA
San Diego Supercomputer Center, University of California, San Diego, La Jolla, CA, USA
3
Departments of Pharmacology, University of California, San Diego, La Jolla, CA, USA
zgan@eng.ucsd.edu, azambon@ucsd.edu

Abstract
Increasing numbers of genomic technologies are leading to massive amounts of genomic data, all of
which requires complex analysis. More and more bioinformatics analysis tools are being developed by
scientist to simplify these analyses. However, different pipelines have been developed using different
software environments. This makes integrations of these diverse bioinformatics tools difficult. Kepler
provides an open source environment to integrate these disparate packages. Using Kepler, we
integrated several external tools including Bioconductor packages, AltAnalyze, a python-based open
source tool, and R-based comparison tool to build an automated workflow to meta-analyze both online
and local microarray data. The automated workflow connects the integrated tools seamlessly, delivers
data flow between the tools smoothly, and hence improves efficiency and accuracy of complex data
analyses. Our workflow exemplifies the usage of Kepler as a scientific workflow platform for
bioinformatics pipelines.
Keywords: Kepler, Workflow, AltAnalyze, Integration, Microarray

1 Introduction
With the development of microarray techniques and associated instruments, more and more
microarray datasets are being produced. Hence, many bioinformatics tools such as Bioconductor and
BASE have been developed to assist in the management and analysis of microarray data [1, 2]. This
makes it possible for scientists to build their own microarray analysis pipeline to analyze their
microarray data. For example, Bioconductor has more than 700 available tools that cover different
analyses (http://www.bioconductor.org/packages/2.13/bioc/). The increase in the available tools
supplies scientists with opportunities to select the proper tools to analyze data produced by different
instruments or for their customized purposes.

2162

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.201

Using Kepler for Tool Integration in Microarray Analysis Workﬂows

Gan et al.

Since multiple steps: data quality control, normalization, and differential gene expression analysis
are involved in microarray analysis, multiple tools are usually required for the entire analysis.
However, the available tools have been developed in different programming languages, such as R,
Python or Perl. Understanding how to combine the different tools and languages and how to deliver
the data generated by the former tool to the latter tool has become a concern. A platform that allows
scientists to combine tools and easily delivery data between tools is needed.
Scientific workflow platforms such as Galaxy, Taverna, Bioclipse, Yabi, and Kepler are available
to develop bioinformatics pipelines [3, 4]. The features of these systems are compared in the
publication [5]. Kepler was selected as the platform to develop our workflows because Kepler has a
convenient graphical interface, a set of internal actors, and built-in R/Python components [4, 6]. The
capacity to extend workflows as well as the support of external packages or tools, such as
Bioconductor, also makes Kepler an ideal platform to develop our workflows (https://keplerproject.org/, http://www.biokepler.org/).
In this paper, we describe how we integrated the desired tools for an automated microarray
analysis workflow in Kepler. To utilize the large number of publicly available microarray datasets, we
have developed a Kepler-based workflow, MAAMD, for Meta-Analyses of online-available
Affymetrix Microarray Data [7]. We have shown that MAAMD not only standardizes microarray
analyses but also improves analysis efficiency [7]. To assist scientists with the analysis of their local
microarray data, we also developed a Kepler-based workflow for meta-analyses of local microarray
data. These two workflows were combined as an integrated microarray analysis workflow that works
for both local data and online data. Several open-source tools such as Bioconductor packages and
AltAnalyze were built into the workflow. The utilization of these available tools avoided repetitive
development and greatly improved development efficiency.

2 Tool Integration in Kepler System for Automated Microarray
Analysis
2.1 A Conceptual View of Microarray Analysis Workflow
The workflow in this study is designed for automated meta-analyses of both online and local
Affymetrix microarray data. Briefly, the user determines their data source and collects the required
information: probesets, names of datasets, details of samples, and data locations into CSV files. This
information becomes the input files for the workflow. Multiple datasets are allowed. The targeted
microarray data listed in the input file is reached by downloading or is present in local storage. The
acquired microarray data files are then re-organized to facilitate the following processes. For each
microarray dataset, data quality of the samples is evaluated, according to which the users can select
samples for following analyses. Secondly, the selected data is grouped according to user designation
of the input files, followed by a comparison selection for differential gene expression. Next, the
selected samples are normalized and meta-analyzed for differential gene expression, microRNA
prediction, transcription factor prediction, potential biomarker identification, and pathway analysis.
The targeted microarray datasets listed in the input file are analyzed one by one. An across-dataset
comparison can be carried out as a functional extension once all targeted datasets have been analyzed.
This across-dataset comparison was designed to compare results of different datasets and hence
identify conserved genes under different experimental conditions or among different species. Figure 1
shows the conceptual design of the workflow. Each green box indicates a Kepler module. The solid
lines and the arrows represent the data flow.

2163

Using Kepler for Tool Integration in Microarray Analysis Workﬂows

Gan et al.

Figure 1. A conceptual view of microarray analysis workflow

2.2 Tools Required by the Workflow
To build our microarray analysis pipeline, several publicly available tools were selected and
embedded into our workflow. Briefly, the function of Bioconductor packages affyQCReport and
arrayQualityMetrics was to evaluate the consistency of data quality for all samples in the same data set
and help the user select proper samples for further analysis. AltAnalyze is a python-based open-source
tool, which was developed for microarray and RNASeq analysis [8, 9]. AltAnalyze allows the metaanalyses of microarray data, including: differential gene expression analysis, pathway analysis, and
clustering. Thus, AltAnalyze was selected as the main functional module of the workflow. We
developed an R-based program to compare the analyzed results from different datasets and assist the
identification of potentially conserved or differentially-expressed genes between datasets. This
program was built into the workflow following microarray meta-analyses. Several R scripts were
developed for file operation, information extraction, and data conversion. These R scripts were
embedded into the workflow and enabled a smooth flow of data. Table 1 summarizes the embedded
tools and their corresponding functions in the workflow.
R

R is used to develop the extended sub-workflow “inter-set comparison”. R
scripts are also used for general file operations and data operations in
modules “Parse Input”, “Data Reorganization”, “Data Selection” and
“Group Selection”.

affyQCReport

affyQCReport is used to load Affymetrix raw data into the workflow. This
tool is embedded in module “Quality Control”.

arrayQualityMetrics

arrayQualityMetrics is used for the comprehensive quality control of
Affymetrix raw data. This tool is embedded in module “Quality Control”.

AltAnalyze

AltAnalyze is a tool for data normalization, differential gene expression
analysis, gene enrichment analysis and pathway analysis. AltAnalyze is
built into the module “Meta Analyses”.

Table 1. List of external tools built into the microarray analysis workflow and their corresponding functions

2.3 The Integration of Tools in Kepler
Integration of Bioconductor Packages. Bioconductor packages are R-based, for which R must be
pre-installed. In this work, Bioconductor packages affyQualityMetrics and affyQCReport are selected
and embedded as R actors in the workflow for quality control and data loading. The functions in these
packages are called by loading the packages as a library of R functions in the corresponding R actors.

2164

Using Kepler for Tool Integration in Microarray Analysis Workﬂows

Gan et al.

Integration of AltAnalyze. AltAnalyze is a Python-based, stand-alone software, which can be
driven by command lines. In this work, AltAnalyze is embedded as an ‘External Execution’ actor.
AltAnalyze
supports
command line, thus we call
AltAnalyze the “External
Execution” actor with a
command line containing
data information, such as:
sample species, groups, the
location where the data is
stored, and the location
where the results need be
stored. The command line is
generated by the workflow.
This further simplifies the
meta-analyses process for the
user.
Extension
of
the
Workflow. To compare the
results
from
different
Figure 2. An Extension of the developed Kepler Workflow
datasets, we developed an Rbased program. This program
was converted into an independent workflow in Kepler for inter-set comparison. This independent
workflow was then added into the microarray meta-analyses workflow as a composite actor by adding
a trigger and assigning its input ports to the corresponding data flow is shown in Figure 2.

2.4 The Implementation of Microarray Analysis Workflow in Kepler
Figure 3 represents the detailed implementation of the designed workflow in Kepler. Briefly, the
user selects the source of data that will lead the data flow to “OnlineData” module or “LocalData”
module. The “OnlineData” module contains the previously-developed Kepler workflow, MAAMD,
which is used to acquire and analyze online microarray data [7]. The “LocalData” module works for
the meta-analyses of local microarray data. Both the “OnlineData” module and the “LocalData”
module contain sub-modules for input parsing, data reorganization, data quality control, data selection,
group and comparison selection, meta-analyses, and interest comparison. Though the major structures
are similar, the input files for online data and local data are different due to different information
requirements. This results in different input file parsing modules and different data flow. Also, the
module for data downloading is removed in the “LocalData” module. The corresponding Kepler
workflow files are available at http://www.biokepler.org/use_cases/maamd-workflow-standardizemeta-analyses-affymetrix-microarray-data.
Previously, we validated MAAMD using online data [7]. The integrated workflow was validated
using the same data. Several Affymetrix Microarray datasets for hypoxic experiments, GSE9400,
GSE12160 [10], GSE14981 [11], and GSE15879 [12], were selected from NCBI Gene Expression
Omnibus (GEO). Proper input files were then prepared and sent to the workflow. The workflow was
first run through “OnlineData” module in which the data was downloaded and analyzed automatically.
The downloaded data was then regarded as local microarray data to validate the “LocalData” module,
which gave similar results [7] and served as a successful validation of the local integrated microarray
workflow. The results showed that the workflow performed smoothly and improved analyses
efficiency compared with manual analyses.

2165

Using Kepler for Tool Integration in Microarray Analysis Workﬂows

Gan et al.

Figure 3. The workflow implementation in Kepler for meta-analyses of Affymetrix data

3 Conclusions and Future Directions
The integration of external tools has decreased the amount of work required for the development of
a bioinformatics pipeline and offered the user the flexibility to easily modify their pipeline. The
success in the development of the integrated workflow for meta-analyses of microarray data suggests
that Kepler is an efficient platform to integrate external tools for bioinformatics analyses.
Though the workflow was developed as an automated workflow, due to the complexity of
bioinformatics data, user interactions are required in some cases. Considering the fact that most endusers are biologists who have limited programming skills, simple user-interfaces such as a classic popup dialog-, file-selection dialog are essential. Though the current workflow conducts analyses
smoothly, the user interactions are not as easy as those on expensive, commercial tools. This may
affect the popularity of the developed workflow to some degree. Thus, in the future, along with the
increase in analyses functions, more user-friendly interactions are also planned.

Acknowledgements
The authors would like to express sincere gratitude to Jianwu Wang for his technical supports and
test works. This project was funded in part by the following NIH grants: 8 P41 GM103426, 5P01HL
HL098053, 1R01HL105242, iDASH-U54 HL108460, UL1TR000100 and American Heart
Association 10SDG2630130.

References
[1]
[2]

2166

Koschmieder A, Zimmermann K, Trissl S, Stoltmann T, Leser U. 2012. Tools for managing and
analyzing microarray data. Brief Bioinform 13:46-60
Dudoit S, Gentleman RC, Quackenbush J. 2003. Open source software for the analysis of
microarray data. BioTechniques Suppl:45-51

Using Kepler for Tool Integration in Microarray Analysis Workﬂows

Gan et al.

[3]

Barker A, Hemert Jv. 2008. Scientific Workflow: A Survey and Research Directions. Proc.
Parallel Processing and Applied Mathematics, Poland, 2007, 4967:746-53: Springer Berlin
Heidelberg
[4] Stropp T, McPhillips T, Ludascher B, Bieda M. 2012. Workflows for microarray data processing
in the Kepler environment. BMC Bioinformatics 13:102
[5] Altintas I, Berkley C, Jaeger E, Jones M, Ludaescher B, Mock S. Kepler: An extensible system
for design and execution of scientific workflows. Proc. Proceedings of 16th International
Conference on Scientific and Statistical Database Management, 2004:423–4
[6] Dinov ID, Torri F, Macciardi F, Petrosyan P, Liu Z. 2011. Applications of the pipeline
environment for visual informatics and genomics computations. BMC Bioinformatics, 12:304
[7] Zhuohui Gan, Jianwu Wang, Nathan Salomonis, Jennifer C. Stowe, Gabriel G. Haddad, Andrew
D. McCulloch, Ilkay Altintas, Alexander C. Zambon. 2014. MAAMD: A Workflow to
Standardize Meta-Analyses and Comparison of Affymetrix Microarray Data. BMC
Bioinformatics,15(1):69
[8] Emig D, Salomonis N, Baumbach J, Lengauer T, Conklin BR, Albrecht M. 2010. AltAnalyze
and DomainGraph: analyzing and visualizing exon expression data. Nucleic Acids Res 38:W755W62
[9] Zambon AC, Gaj S, Ho I, Hanspers K, Vranizan K, et al. 2012. GO-Elite: a flexible solution for
pathway and ontology over-representation. Bioinformatics 28:2209-10
[10] Zhao HW, Zhou D, Nizet V, Haddad GG. 2010. Experimental selection for Drosophila survival
in extremely high O2 environments. Plos One 5:e11701
[11] Azad P, Zhou D, Russo E, Haddad GG. 2009. Distinct mechanisms underlying tolerance to
intermittent and constant hypoxia in Drosophila melanogaster. Plos One 4:e5371
[12] Mosqueira M, Willmann G, Ruohola-Baker H, Khurana TS. 2010. Chronic hypoxia impairs
muscle function in the Drosophila model of Duchenne's muscular dystrophy (DMD). Plos One
5:e13450

2167

