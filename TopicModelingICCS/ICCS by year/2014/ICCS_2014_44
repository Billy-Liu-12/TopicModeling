Procedia Computer Science
Volume 29, 2014, Pages 2515–2520
ICCS 2014. 14th International Conference on Computational Science

Characteristics of Dynamical Phase Transitions
for Noise Intensities
1

2

Muyoung Heo1, Jong-Kil Park2, Kyungsik Kim3*

Department of Physics, Pukyong National University, Busan 609-735, Korea
Department of Environmental Engineering, Inje University, Gimhae 621-749, Korea
3
Department of Physics, Pukyong National University, Busan 608-737, Korea

muyoung@gmail.com, envpjk@inje.ac.kr, kskim@pknu.ac.kr

Abstract
We simulate and analyze dynamical phase transitions in a Boolean neural network
with initial random connections. Since we treat a stochastic evolution by using a noise
intensity, we show from our condition that there exists a critical value for the noise
intensity. The nature of the phase transition are found numerically and analytically in
two connections of probability density function and one random network.

1 Introduction
Boolean neural networks have been described as generic models for the dynamics of complex
systems of interacting entities, such as social and economic networks, neural networks, and gene or
protein interaction networks [1]. Kauffman [2] as a model for gene regulation was introduced and
studied the simplest and most widely neural network models. Derrida and Pomeau [3] have performed
calculations of random automata model by using a Boolean function. Their work has given annealed
approximations and quantitative predictions for distances between iterated configurations.
Boolean networks have been used to describe various models in complex systems such as neural
networks with associative memory [4-5], spin glasses [6-9], dynamics of evolution [10-11], and
cellular automata [12-13]. It is well known that a typical Boolean network consists of a set of binary
elements which are connected among them to indicate a net, and the use of common tools has
revealed a robust parallel between Boolean networks and dynamical systems. Historically, neural
networks have approximated universal and nonlinear functions with arbitrary accuracy [14]. This
approximate method is an important advance for neural networks, because of the huge number of
possible nonlinear patterns for real world problems. Neural networks have been described to be
*

Corresponding author; Tel:+82-51-629-5562; Fax:+82-51-629-5549.

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.235

2515

Characteristics of Dynamical Phase Transitions for Noise Intensities

M. Heo, J.K. Park and K. Kim

effectively in modelling and forecasting nonlinear time series with noise [15]. Until now, many
scientists [16] have made the comparison between the neural network and the traditional method in
time series modelling and forecasting performances.
Furthermore, over the last two decades, the remarkable potential of complex networks to simulate
and analyze the dynamical behavior of complex systems has gradually been an increasing trend in
new fields of research in the social, natural, engineering, and medical sciences. In the network theory,
the small-world and scale-free network models [17,18] have been studied widely in various
applications of the scientific fields. The two network models have played a crucial role in the complex
phenomena [19-21], and of current interest are scale-free networks because it follows the power law
for its degree distribution. Particularly, we now introduce the random neural network to our paper, and
the problem of scale-free neural networks will be appeared in other paper.
Until now, several papers have analyzed the non-equilibrium dynamics of deterministic Boolean
neural networks [22,23] and suggested the existence of a variety of possible collective behaviors such
as synchronized oscillations or chaos [24,25]. The influence of noise on the dynamics of Boolean
networks has been analyzed in several published papers [26,27] as well. Scientists researched on
neural networks have been interested in considering the changes in the dynamical properties of a
deterministic system in the presence of noise. Following this motivation, we study random network
models exhibiting self-organization and analyze its tolerance to the effect of noise. In this paper, we
mainly show from two connections (of probability density function) and one random network that the
system undergoes a dynamical phase transition as its amount of randomness is increased.

2 Theoretical Background
Consider a neural network composed of N elements, each of which can only take the values
σ i = +1 or σ i = −1. Every σ i is randomly connected to any L elements of the network, which define
its set of linkages. The parameter L is the connectivity of the network, and each linkage is weighted by
an independent random variable. The NL connections of a network and its corresponding weights
remain fixed throughout the evolution of the system. In our model, the input function [28] at discrete
time step t is represented in terms of
L

I (ci1 , ci2 ,..., ciL ;σ i1 (t ), σ i2 (t ),..., σ iL (t )) = Sign{∑ cijσ i j (t )} .

(1)

j =1

Here σ i (t ) is connected to any L elements having its set of linkages { σ i (t ) } for j = 1,2,...,L, and each
j
linkage σ i (t ) is weighted by an independent random variable cij . The input function takes the same
j
value as the majority of the linkages, if it corresponds to the majority rule.
Using Eq. (1), we introduce a stochastic evolution rule for σ i (t + 1) with a noise intensity γ such
that
(2)
σ i (t + 1) = I (ci1 , ci2 ,..., ciL ;σ i1 (t ), σ i2 (t ),..., σ ik (t))
with 1 − γ and

σ i (t + 1) = −I (ci , ci ,..., ci ;σ i (t ), σ i (t ),..., σ i (t))
1

2

L

1

2

k

(3)

with γ . In above equation, we can select randomly a varying noise intensity γ between 0 and 1/2. In
the case with γ = 0 , a neural network system at time t + 1 will converge to an ordered state in which
all the σ i (t + 1) are equal.

2516

Characteristics of Dynamical Phase Transitions for Noise Intensities

M. Heo, J.K. Park and K. Kim

Next, we consider that the neural network system undergoes a dynamical phase transition from an
ordered to a disordered state as the noise intensity is increased. In order to define the order parameter
adequately described the degree of alignment of the elements of the network, we introduce a statistical
quantity as
1 N
(4)
σ (t ) = ∑ σ i (t ) ,
N i =1
where | σ (t ) |→ 1 for an ordered system in which all elements take the same value, while | σ (t ) |→ 0
for a disordered system. For systems where the time-average of | σ (t ) | converges, an order parameter
Φ is defined as
1 t
(5)
Φ=
∑ | σ (t ) | ,
t − to t =t0
where t0 can take any arbitrary finite time without changing Φ . From Eq. (5), it is well known [29]
that the phase transition is described by

for γ C − γ  1 , and

Φ = [C (γ C − γ )]1/ 2

(6)

Φ=0

(7)

for γ C < γ .

3 Numerical Calculations and Results

2517

Characteristics of Dynamical Phase Transitions for Noise Intensities

M. Heo, J.K. Park and K. Kim

Figure 1: Values of order parameter
for a number of
links L =7 (circle), 9 (square), and 11 (triangle) in the random
network.

In this paper, the N elements of our neural network can be extended to a larger number, but we
only restrict ourselves to the cases for which the computer simulations are carried out for N = 5 × 103
elements. From random initial conditions, we simulate numerically the evolution of the model for a
neural network with N = 5 × 103 elements and three kinds of connectivities L = 7,9,11 . Next, the
order parameter Φ is obtained by integrating | σ (t ) | from t0 = 1× 103 until t = 1× 104 . We treat three
cases as two connections (of probability density function) and one random network.
We can calculate the results for the case of a network with fixed connection weights cij following
that the probability density function P( x) is equal to 1 if 0 ≤ x ≤ 1 and 0 otherwise. The phase
transitions occur only at γ C = 0.241, 0.264 and 0.285 for L =7, 9, and 11, respectively. The numerical
results find the bifurcation diagram of Φ as a function of the noise intensity for the case with cij = 1,
in which all connection weights are equal. As the input function then becomes the majority rule, the
system undergoes apparently a phase transition with γ C = 0.283 , 0.299 and 0.325 for L =7, 9, and 11.
For γ < γ C , all elements in the system will tend to align either to +1 or to −1. Figure 1 shows Φ as a
function of the noise intensity for the case with cij = 1 in the random network with a number of nodes

N = 5 × 103 and links L =7, 9, 11. The system undergoes a phase transition with γ C = 0.269 (L =7),
0.297 (L=9), and 0.313 (L=11), and the computer-simulation is averaged 100 ensembles in Fig. 1.

4 Codnclusions
We have simulated and analyzed dynamical phase transitions in a Boolean neural network with
initial random connections. We have ascertained the nature of phase transitions numerically and
analytically in two connections and one random network. Due to the randomness and the noise with
initial linkages in the neural network, the statistical properties in the dynamics may not change if the
connection weights or the linkages are either time-independent or if they are randomly re-assigned at
every time step. Through Boolean networks, it means that the annealed and quenched dynamics are
equivalent for our model presented in this paper. In other cases, random energy models used by

2518

Characteristics of Dynamical Phase Transitions for Noise Intensities

M. Heo, J.K. Park and K. Kim

Derrida [30,31] have extended to study spin glasses and the protein folding problems [32]. The
connection between Random energy models and traditional methods of statistical mechanics has been
discussed by Janzen et al. [33] in the context of Levy spin glasses. Until present, there exist a number
of reasons to use the neural network for time series simulation and analysis. If an function has relation
between the inputs and outputs for any forecasting model, then it is very important to identify
accurately this function. All these features have made neural networks useful for time series
modelling and forecasting [34,35] in real world problems. In the future, we will extend our model to
scale-free networks of other scientific fields.
This work was supported by the National Research Foundation of Korea(NRF) Grand funded by
the Korea government (MSIP) (2013-065891), by Center for Atmospheric Sciences and Earthquake
Research (CATER 2012-6110), and by the Ministry of Education, Science and Technology
(2013R1A1A2008558).

References
[1] S. Kauffman, C. Peterson, B. Samuelsson and C. Troein, Proc. Natl. Acad. Sci. 100 (2003)
796.
[2] S. A. Kauffman, J. Theor. Biol. 22 (1969) 437.
[3] B. derrida and Y. Pomeau, Europhys. Lett. 1 (1986) 45.
[4] J. J. Hopfield, Proc. Nat. Acad. Sci. 79 (1982) 2554.
[5] K. Sakai and Y. Miyashita, Nature 354 (1991) 152.
[6] B. Derrida, J. Phys. A 20 (1987) L721.
[7] B. Derrida and H. Flyvbjerg, J. Phys. A 19 (1986) 1003.
[8] M. Mezard, G. Parisi, and M. A. Virasoro, Spin Glass Theory and Beyond, World Scientific,
Singapore, 1987.
[9] D. Petters, Intl. J. Mod. Phys. C 8 (1997) 595.
[10] M. Aldana, V. Dossetti, C. Huepe, V. M. Kenkre and H. Larralde, Phys. Rev. Lett. 98 (2007)
095702.
[11] S. A. Kauffman, The Origins of Order: Self-Organization and Selection in Evolution, Oxford
University Press, Oxford, 1993; C. O. Wilke, Phys. Rep. (2001) 395.
[12] J. A. De Sales, M. L. Martins and D. A. Stariolo, Phys. Rev. E 55 (1997) 3262.
[13] H. Flyvbjerg, Acta Phys. Polo. B 20 (1989) 321.
[14] K. E. Kurten, J. Phys. A 21, L615 (1988); S. Wolfram, Rev. Mod. Phys. 55 (1983) 601.
[15] K. Hornik, Neural Networks 4 (1991) 251.
[16] H. Saxen, Intl. J. Neural Sys. 7 (1996) 195.
[17] N. Kohzadi, M. S. Boyd, B. Kermanshahi and I. kaastra, Neurocomputing 10 (1996) 169.
[18] S.-G. Han and B. J. Kim, J. Korean Phys. Soc. 60 (2012) 655.
[19] D.-S. Lee, S. E. Maeng and J. W. Lee, J. Korean Phys. Soc. 60 (2012) 648.
[20] Y. Kim, W. Choi and S-H. Yook, J. Korean Phys. Soc. 60 (2012) 621.
[21] K.-M. Lee, K.-I. Goh and I.-M. Kim, J. Korean Phys. Soc. 60 (2012) 641.
[22] H. W. Choi, S. E. Maeng and J. W. Lee, J. Korean Phys. Soc. 60 (2012) 657.
[23] B. Cheng and D. M. Titterington, Stat. Sci. 9 (1994) 2.
[24] K. E. Kurten, Phys. Lett. A 129 (1988) 157.
[25] H. D. I. Abarbanel, M. I. Rabinovich, A. Selverston and M. V. Bazhenov, Physics-Uspeki 39
(1996) 337.
[26] L. Wang, E. E. Pichler and J. Ross, Proc. Nat. Acad. Sci. 87 (1990) 9467.
[27] J. D. Farmer, Physica D 42 (1990) 153.
[28] E. N. Miranda and N. Parga, Europhys. Lett. 10 (1989) 293.

2519

Characteristics of Dynamical Phase Transitions for Noise Intensities

M. Heo, J.K. Park and K. Kim

[29] C. Huepe and M. Aldana, J. Stat. Phys. 108 (2002) 527.
[30] M. Aldana and C. Huepe, J. Stat. Phys. 112 (2003) 135.
[31] B. Derrida, Phys. Rev. Lett. 45 (1980) 79.
[32] B. Derrida, Phys. Rev. B 24 (1981) 2613.
[33] J. D. Bryngelson and P. G. Wolynes, Proc. Nat. Acad. Sci. 84 (1987) 7524.
[34] K. Janzen, A. Engel and M. Mezard, Europhys. Lett. 89 (2010) 67002.
[35] Czaplicka, J. A. Hołyst and P. M. A. Sloot, Nature Scientific Reports 3 (2013) 1223.

2520

