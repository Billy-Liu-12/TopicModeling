Procedia Computer Science
Volume 29, 2014, Pages 1745–1755
ICCS 2014. 14th International Conference on Computational Science

Progress towards automated Kepler scientific
workflows for computer-aided drug discovery and
molecular simulations
Pek U. Ieong1,3 , Jesper Sørensen1 , Prasantha L. Vemu1, Celia W. Wong1,
Özlem Demir 1, Nadya P. Williams 2,3 , Jianwu Wang2, Daniel Crawl2,3 , Robert
V. Swift1, Robert D. Malmstrom1,3 , Ilkay Altintas 2,3 and Rommie E. Amaro 1,3*
1

Department of Chemistry and Biochemistry, 2 San Diego Supercomputer Center, 3 National
Biomedical Computation Resource, University of California San Diego, CA, USA
ramaro@ucsd.edu

Abstract
We describe the development of automated workflows that support computed -aided drug discovery
(CA DD) and molecular dynamics (M D) simulat ions and are included as part of the National
Bio medical Co mputation Resource (NBCR). The main workflow co mponents include: file management tasks, ligand force field parameterizat ion, receptor-ligand molecu lar dynamics (M D)
simu lations, job submission, serial and parallel executio n, and monitoring on relevant highperformance co mputing (HPC) resources, receptor structural clustering, virtual screening (VS), and
statistical analyses of the VS results. The workflows aim to standardize simu lation and analysis and
promote best practices within the molecu lar simu lation and CADD co mmunit ies. Each co mponent is
developed as a stand-alone workflow, which should allow for easy integration into larger frameworks
built suiting user needs, while remaining intuitive and easy to extend.
Keywords: Scientific workflows, molecular simulation, ligand parameterization, small molecule docking,
structural clustering, big data reduction, web services, relaxed complex scheme

1 Introduction
Using co mputer simulat ion as an aid in drug d iscovery is not novel, y et the field is somet imes still
considered in its infancy, an opinion that may be due to the relatively co mplicated processes involved
*

Corresponding author: Tel: +1-858-534-9629; Fax: +1-858-534-9645; Email: ramaro@ucsd.edu

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.159

1745

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

and the lack of co mmunity-wide standard procedures. Furthermo re, the continuous development of
new computer arch itectures and software parallelization can result in large amounts of data, upwards
of 1 terabyte for single co mputer-aided drug discovery (CADD) projects. Perhaps as a result of th is
enabling technology, it is co mmon for practitioners to spend more time analy zing the data than
generating it. W ith this in mind, our aim is the develop ment of robust, reusable workflows for
simu lation preparation, job execution, and analysis that simp lify best practices and help the
community make the most of their rich data sets.
To develop automated, standardized protocols, we emp loy Kepler [1], a scientific workflo w
framework. Kepler is a free, open-source software suite designed for analy zing and modeling
scientific data. The Kep ler software simp lifies the creation of executable models (scientific
workflows), even by researchers with little programming backg round [2]. Additionally, it is a platform
for users to share and reuse data, workflows, and components for a wide range of scientific and
engineering applicat ions [3, 4]. Kepler has powerful support to handle new cyber infrastructure
demands (e.g., intelligently handling/brokering access to Extreme Science and Engineering Discovery
Environment (XSEDE) and other simu lation-relevant platforms), and it is particu larly well suited to
handle workflows that cross scales. The flexibility of Kepler makes it an ideal environ ment for sharing
methods among scientists, thus increasing reproducibility and accessibility. Kepler also provides a
provenance framework (e.g. data lineage and the processing history of workflo w runs) that collects
informat ion, which can be v iewed through a mo lecular modelers’ virtual notebook [5]. Th is latter
feature also makes it possible to detail methods, software names and versions, resource specifications
and computational cost in literature reports, in a straight-forward manner similar to the standardized
reporting that exists for small-molecule crystal structures [6].

2 The relaxed complex scheme – main components
Previously, we developed a CADD pipeline schematic called the relaxed co mp lex scheme (RCS),
[7], an end-to-end CADD experiment that incorporates receptor flexibility into virtual screening (VS)
by utilizing mo lecular dynamics (M D) simulat ions. As summarized schematically in Figure 1, the
RCS facilitates all steps of VS, including: (1) generating compound libraries, (2) generating and
selecting receptor structures, (3) performing virtual screens, (4) reevaluating and characterizing
docked poses, and (5) sharing virtual-screening results. While not illustrated in Figure 1, workflo w
results lend themselves to statistical validation, an extension discussed in section 3.7
Building on our earlier RCS efforts that were designed with a specific task in -mind, we are
developing individual, stand-alone workflows that are modular and reusable. Co llectively, they form a
“toolkit” of powerful methods that can be assembled to address a range of challenging VS problems.
In particular, to incorporate protein flexib ility into rational d rug discovery and design, we are
constructing a class of workflows to automate the setup, execution, and evaluation of molecular
dynamics simulations. The workflows can be assembled in novel ways, creating environments where
system-specific M D analysis can be meaningfully conducted, providing extended utility beyond
CADD and the RCS. Each Kep ler-based reusable workflow module is called an “actor” and is built
primarily on an open-source software platform, or on software that is free to academic groups. The
near universal accessibility of the workflows should translate to broad dissemination and use, allo wing
researchers to handle the challenges inherent in (big) data more effectively.
To prevent each workflo w fro m beco ming a “black box”, where appropriate, we are focused on
including metrics or analytics that allo w the user to judge the quality of the output an d make key
scientific decisions. As an examp le, we will focus on providing applicat ions that make conducting and
reporting novel MD analyses standard, routine and reproducible [8].

1746

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

We furthermore plan to build workflows that support data sharing and transportation through cloud
and other distributed platforms that facilitate usage of high-speed networks. The combination of these
functionalities will provide a simp le but powerfu l way to create and share customizable reports among
members of large scientific collaborations.

Figure 1: General workflow for ensemble-based VS experiment. Blue arrows indicate size of data sets (i.e.
increasing or decreasing) at each step; * denotes emerging methods t hat have not yet been tested. (AM D:
accelerated molecular dynamics, GB M D: generalized Born molecular dynamics, RM SD: root -mean-squaredeviation, ZINC – ZINC Is Not Commercial, ACD: Available Chemical Database, NCI: National Cancer
Institute, M M -PB(GB)SA: M olecular M echanics – Poisson-Boltzmann (Generalized Born) Surface Area).

3 CADD workflow – main actors
3.1 File management for ligand parameterization
For organizational purpose, we developed a Kepler composite actor that takes a list of PDB files,
which is a standardized file format containing structural informat ion regarding molecules, and creates
subdirectories using the PDB names. The PDB files are then copied to the corresponding
subdirectories. Subsequently, generated data associated with each PDB is stored consistently,
providing better informat ion control. While this actor is a s mall actor, it provides proper file
management, a crucial component of CADD.

3.2 Ligand Parameterization
An MD simulat ion of a protein-ligand co mplex requires development of ligand force field
parameters. Parameterization can be cumbersome and is commonly a multi -step process handled by a
series of user scripts. To streamline this process, we developed a ligand parameterization co mposite
actor͒ (Figure 2), that follows the “gold standard” Amber protocol, using Antechamber [9] and
Gaussian [10]. Th is actor has been parallelized using Kepler to distribute the workload and can
therefore easily accept a large nu mber of ligands as inputs. For each ligand, Antechamber assigns
force field ato m͒ types, wh ile Gaussian performs a min imization before calculating the electrostatic

1747

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

potential (ESP), both at the HF/ 6-31G* level. Ato mic partial charges are then assigned to reproduce
the ESP using the RESP protocol [11]. The actor will read a directory of ligand PDB files and process
them simu ltaneously. The PDB files will be moved into corresponding subdirectories to ensure that all
output files are well organized along with their inputs when performing the calculations in parallel.
These files and directories are then grouped together for the parameterizat ion step as inputs, and lastly
a distributor actor splits the task into smaller jobs that are executed in parallel. This co mposite
actor͒ subsequently outputs the required FRCMOD and PREPC files containing the force field
parameters, which are reusable and easily shared.

Figure 2: Kepler composite actor for the parameterization of small molecule ligands for M D

3.3 Receptor-ligand molecular dynamics simulations
The binding of a ligand to a receptor is a dynamic event. Small mo lecule co mpounds can assume
many different binding poses, and receptor flexibility may change due to ligand binding. Therefore, it
is important to consider the dynamic behavior of both ligands and receptors during CADD. One
commonly applied method to describe the receptor-ligand dynamics is MD simulat ions of the
complex. The steps to prepare an MD simulat ion can be routine but lengthy, especially when
considering many different receptor-ligand comp lexes. To standardized and automate the process, we
have developed a Kepler co mposite actor that simplifies the preparation of MD simulat ions of these
complexes (see Figure 3). This actor takes the outputs generated from the ligand parameterization
actor as the inputs. Furthermore, it requires a receptor PDB file in order to start the workflow. Once
started, the job will run through three major co mponents, described below, that collectively prepare
and run an MD simulation of the user’s system.

Figure 3: Layout of the Receptor-ligand molecular dynamic simulations actor.

Co mponent I – Vina: Given PDB files of a ligand and a receptor, this module prepares the
prerequisite files and docks the ligand into the receptor using Autodock Vina. The result is a PDB file
that describes the “docked pose” of the ligand, or the conformation of the ligand when bound to the
receptor.
Co mponent II – PDB Modification: By concatenating the docked-pose PDB file to the PDB file of
the receptor, co mponent II first creates a merged ligand-receptor comp lex. Next , the receptor-ligand
complex is assigned Amber force field parameters, and the topology and coordinate files required for
MD are generated. Prior to simu lating system dynamics, a restrained minimization is typically carried
out to remove steric conflicts, wh ich can cause MD prog rams to crash. In a final step, component II
prepares the restraint files required during minimization.

1748

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

Co mponent III – Remote Login: This module of the co mposite actor prepares configuration files
for M D simu lation with NAMD [12] and writes submission scripts for running min imization,
equilibrat ion and production jobs on the XSEDE resource Stampede, located at the Texas Advanced
Co mputing Center (see Figure 4). Future developments will enable users to employ alternate HPC
resources. In order to take advantage of parallel co mputing, the files required fo r MD simu lation that
were generated in earlier steps must be moved to the HPC platform. Co mponent III performs th is
operation, moving the prerequisite files to a user specified directory on a remote HPC resource. Once
the files are transferred, co mponent III executes and monitors min imization jobs on the HPC resource,
generates the files necessary for a restrained MD equilibration, performs the restrained MD
equilibration, and finally executes the production MD simulation.

Figure 4: Breakdown of the remote login composite actor of the receptor-ligand dynamic simulation actor.

3.4 Receptor structural clustering
An MD simulat ion yields a “trajectory,” or a set of coordinates that represent the conformational
states of the protein with or without a bound ligand as it evolves through time typically starting fro m
an experimentally determined structure. With modern HPC resources, these trajectories can consist of
thousands or even millions of conformat ions, which translates into giga- or terabytes of data, making
structural analysis challenging. Fortunately, meaningful dataset reduction methods have been devised
that extract representative conformations, or structures. These structures, are generally d ifferent than
the experimentally determined structure(s), and the active sites display alternative conformations
referred to as cryptic binding pockets [13-15], and can be exploited in subsequent VS.

Figure 5: Gromos receptor structural clustering actor.

Considering the size o f contemporary MD datasets, an effective, integrated platform for studying
protein dynamics will require workflow actors that leverage data reduction software in a single,
cohesive, user-friendly framework. To that end, we developed a modular set of actors that process MD
trajectories by GROM OS cluster analysis [16], a method that categorizes protein conformations based
on structural similarity (see Figure 5). In the first processing step, the Trajectories Listing composite
actor utilizes cpptraj, imp lemented in A mberTools, to concatenate short discontinuous trajectories into
one long continuous trajectory. The PDB Creator and PDB Modifier actors then convert the input
trajectory file to the PDB fo rmat required by Gro macs [17], and also strips solvent molecules and
correct for periodic boundary conditions. The Atom Selection actor p icks out the active site residues a
user has predefined and creates a PDB file containing all the atom indices of the selected residues. The

1749

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

files are then sent to the public NBCR Opal server, wh ich aligns each trajectory conformation to a
common reference and clusters the data using the Gro macs. We are planning to extend this workflo w
to include options for alternative clustering strategies.

3.5 Receptor and ligand preparation for docking
Docking programs, such as the widely used AutoDock [18] and AutoDock Vina (Vina) [19],
provide scientists an estimate of the free energy change that occurs when a ligand binds to a receptor.
Both AutoDock and Vina require PDBQT files that des cribe the coordinates, atomic part ial charges,
and AutoDock atom types of the ligand and the receptor. To streamline the conversion procedure, we
have developed an actor that converts a receptor PDB to PDBQT file, which can be used by both
AutoDock and Vina (see Figure 6). The actor uses the publicly available NBCR Opal server to
perform the conversion, while Kepler mon itors job scheduling and returns the output PDBQT file to
the user’s local machine. In the future, this actor will be extended to convert PDB to PDBQT for the
ligand files as well.

Figure 6: Receptor preparation for VS actor.

3.6 Ensemble based virtual screening
As previously stated, proteins are dynamic, and static crystal structures can offer a poor account of
protein flexibility, part icularly when it is pronounced. In a drug discovery context, th is flexibility is
man ifested in the observance of so-called cryptic binding pockets [13-15], or ligand binding sites that
are absent in a crystal structure but are present during an MD simulat ion. To incorporate these
potential binding sites during VS, it is important to include an ensemble of protein receptor structures
that models the flexib ility of a receptor in solution. Here, we describe an actor that screens large ligand
sets against different receptor conformations using Vina [19] (see Figure 7). Users supply a directory
of receptor PDB files, a directory of ligand PDB files and grid information. Receptor PDB and ligand

Figure 7: Virtual screening actor.

1750

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

PDB files are converted to Vina specific PDBQT files. Every ligand is matched with each receptor
once in the “Mix&Match” module, which organizes the large nu mber of files generated in th is
protocol. The combinations are sent to Vina one by one for VS. Then, users have the option to either
run VS locally or on the NBCR Opal server. This imp lementation has been made using the bioKepler
extension [20]. Moreover, this actor carries out provenance and is able to output information regarding
receptors, ligands, runtime and machines used for each run (data not shown).

3.7 Virtual screening performance statistics
During VS, s mall molecu les are assigned a score e.g. during small mo lecule docking, the score is a
predicted binding affin ity of a small molecu le to a receptor target, and those compounds predicted to
bind more favorably receive a higher rank and are more likely to be experimentally assayed.
Performing VS using an ensemble o f protein conformat ions may benefit the discovery effort, but it
is also computationally demanding and scales linearly with the number of conformations. To improve
computational efficiency, statistical methods can be used to select the ensemble that does the best job
of separating known the binders from the known non-binders in a small, experimentally characterized
compound database. By carefully selecting the best performing ensemble, this protocol has the
potential to reduce the computational expense of screening a much larger database of uncharacterized
compounds.
We have developed an actor (see Figure 8) that incorporates the experimental status of a
compound, i.e. b inder or non-binder, the docking score of the co mpound in each receptor ensemb le
member, and returns the ensemble best able to discriminate known binders fro m known non-binders.
Although there are various VS performance metrics available in the literature [21, 22], the area under
the curve (AUC) of the Receiver Operating Characteristic (ROC) plot [23] is one of the most popular
performance evaluation metrics and is used for our workflow. Part of the AUC’s appeal is how easily
it is interpreted. It represents the probability that a randomly selected binder will have a h igher ran k
than a randomly selected non-binder [24, 25]. Consistent with this interpretation, an AUC value of 0.5
indicates the VS protocol performs randomly, wh ile a value of 1 indicates the protocol ranks all of the
binders ahead of all of the non-binders.

Figure 8: VS statistical performance actor utilizing M atlab

In practice, ensemb le selection is co mplicated by the need to evaluate all possible c o mbinations of
receptor conformations, a combinatorial process described by the binomial coefficient. The workflo w
utilizes a series of Matlab [26] scripts to monitor performance of all possible ensembles of
conformat ions. The scripts requires a comma-separated CSV file, containing ligand identification
numbers, e.g. co mpound IDs in a database, a compound classifier, i.e. a 0 or 1, which labels nonbinders and binders, respectively, and the remaining co lu mns contain the docking scores for each
receptor conformation. The scripts return the AUC value for all possible ensembles of receptor
conformat ions, as well as the 95% confidence intervals, and p-values, wh ich provide indications of the
performance reliability and the statistical significance of the performance of each ensemble.
The calculations in Matlab are designed to utilize the Parallel Co mputing Toolbox in Matlab
(parfor loops), although if the separate license required to use the toolbox is not available, the behavior

1751

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

will default to standard loop iteration. The parallel option is highly recommended particularly for a
large number of receptor structures, as these calculations otherwise become very time consuming.

4 Integrated web-services
The comp lexity of scientific applicat ions needed in CADD often requires access to HPC resources.
To ensure tasks are completed expediently, scalable and transparent support of distributed computing
resources available on both HPC platforms and in the cloud is required of each Kepler workflo w
module. To meet this requirement, we use the Opal toolkit [27], which provides Scientific Soft ware as
a Serv ice (SaaS) using standard and simple web interfaces. For examp le, scientific applications
executed by the workflows are wrapped as SOAP-based web services that allo w for programmatic and
web-based application access, which is useful for a wide variety of applications. The programmat ic
capability allows transparent access of different workflo w co mponents, while the web -based service
access provides a large number of NBCR applications to our affiliates and collaborators.
Using integrated web-services for scientific applications also aids our objective to develop a
modular environ ment of interchangeable, customizable modules that can be used to create complex
scientific workflo ws. As SaaS providers, we handle software installation configuration and upgrade
transparently at the cyber-infrastructure level. With infrastructure complexit ies replaced by an easy -touse interface, the full power of the modular workflow environ ment can be easily applied to pressing
scientific problems.
The scientific applications, wrapped as Opal web services [28], can read ily be deployed across
distributed computing environments to accelerate completion of the scalable co mputations within the
CADD framework. It is easy to access the scientific applications through the Opal web server, which
provides a stable, reliable infrastructure for CA DD and mo lecular simulat ions that can accommodate
large throughput in an extensible, reproducible and reusable manner. This approach will allow flexib le
community resource sharing and, by providing the framework to incorporate ideas fro m a broad
community of users, it will promote convergence toward a set of standardized best practices.

5 Workflow Dissemination
CADD workflows, in addition to other NBCR workflow products, are being made available
though the NBCR website and GitHub [29]. We have enabled the NBCR workflows site to be
searched and filtered easily though keywords describing the workflo ws’ application, actors, program
dependency, and other relevant terms, enabling the user to select the appropriate workflow fo r their
needs. Upon selecting a desired workflow the user is taken to the workflow documentation and
download options. The workflo ws will be distributed through GitHub to provide transparent version
control. The user may either download the workflo w itself, requiring a local installation of Kepler and
dependent programs, or download the workflow as part of a Rock’s Rolls [30] containing dependent
programs. The Rock’s Rolls facilitate the utilization of workflows in HPC environments.

6 Conclusions
We have developed a series of modular actors that can be integrated into a larger CADD
framework, or be used as stand-alone tools. The modules described here are have successfully been
deployed on a number of different projects and are being optimized based on user feedback. These
modules demonstrate the usability of Kepler scientific workflows in CADD with the aim to

1752

Automated workﬂows for drug discovery and molecular simulations

R.E. Amaro et al

standardize simu lation and analysis, and to promote best practices within the mo lecular simulat ion and
CADD co mmunit ies. The workflows demonstrate usability in terms of file -management tasks,
mo lecular simu lation including ligand force field parameterization and management of job submission
and monitoring on relevant HPC resources, as well as VS elements such as receptor structural
clustering, docking and statistical analyses of the VS results. The modules developed here were partly
intended for specific-use cases and will in the future be subdivided into smaller modules t o avoid
redundancy, and to make them amenable to incorporate into other framework uses.
Through our work, we have identified some novel Kep ler capabilit ies that would be useful for the
workflows in our science domain. A Kepler feature to allow fo r easier stitching together of several
modules into a larger framework using a GUI framework would be helpful for more novice users. A
particular function of this feature is for Kepler to check and match module output to subsequent
module input requirements in the larger framewo rk, and flag errors at the transitions, which can later
be handled by the users in the design phase. The user can then quickly address any file format
requirements, either by pulling in another module between the two causing the conflict, or manually
provide/specify missing parameters. Furthermore, the current imp lementation fo r assembling several
modules into a larger framework can be challenging when each module has its own PN or SDF
director, as Kepler does not currently allow the PN actor to exist inside another PN or SDF director.
The current models are available for download on the NBCR website and have been integrated
with NBCR web-services. Our lab is currently developing novel Kepler wo rkflo ws designed for
automation and standardizing of common tasks in CADD and molecu lar simu lation. Additionally, we
are developing domain specific interfaces for all NBCR workflo ws. These interfaces will integrate key
visualizat ion software, workflow modification, workflow execution management, and ele ctronic lab
book functions further optimizing the CADD process. We will solicit user feedback and use it to guide
our efforts, to strengthening an ecosystem that encourages development and distribution of workflo ws
with the simulation and CADD communities.

7 Acknowledgements
The authors would like to thank Leah Krause for fru itful discussions regarding the development of
the workflows. This work is funded in part by a grant from the NVIDIA Foundation, an NIH New
Innovator Award to REA OD-007237. Funding and s upport fro m the Nat ional Bio medical
Co mputation Resource is prov ided through NIH P41 GM 103426. b ioKepler is funded by the Nat ional
Science Foundation (NSF) DBI-1062565 under CI Reuse and Advances in Bio informat ics programs
supported some of the IA, DC and JW. The Alfred Ben zon foundation is thanked for postdoctoral
funding to JS. This work used the Extreme Science and Engineering Discovery Environment
(XSEDE) at San Diego Superco mputer Center (SDSC) and Texas Advanced Computing Center
(TACC) using an allocation to REA with grant nu mber TG-CHE060073N. XSEDE is supported by
NSF grant number OCI-1053575.

References
1.
2.

Altintas, I., et al. Kepler: an extensible system for design and execution of scientific
workflows. in Scientific and Statistical Database Management, 2004. Proceedings. 16th
International Conference on. 2004.
McPhillips, T., et al., Scientific workflow design for mere mortals. Future Generation
Computer Systems, 2009. 25(5): p. 541-551.

1753

Automated workﬂows for drug discovery and molecular simulations

3.
4.
5.
6.

7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.

1754

R.E. Amaro et al

Barseghian, D., et al., Workflows and extensions to the Kepler scientific workflow system to
support environmental sensor data access and analysis. Eco logical Informatics, 2010. 5(1):
p. 42-50.
Astakhov, V., et al., Prototype of Kepler Processing Workflows For Microscopy And
Neuroinformatics. Procedia Computer Science, 2012. 9(0): p. 1595-1603.
Moreau, L., et al., Special Issue: The First Provenance Challenge. Concurrency and
Computation: Practice and Experience, 2008. 20(5): p. 409-418.
Strickland, P.R., M.A. Hoyland, and B. McMahon, Small-molecule crystal structure
publication using CIF, in International Tables for Crystallography Volume G: Definition and
exchange of crystallographic data, S.R. Hall and B. McMahon, Editors. 2005, Springer
Netherlands. p. 557-569.
Amaro, R.E., R. Baron, and J.A. McCammon, An improved relaxed complex scheme for
receptor flexibility in computer-aided drug design. Journal of co mputer-aided mo lecular
design, 2008. 22(9): p. 693-705.
Murdock, S.E., et al., Quality Assurance for Biomolecular Simulations. Journal of Chemical
Theory and Computation, 2006. 2(6): p. 1477-1481.
Wang, J., et al., Automatic atom type and bond type perception in molecular mechanical
calculations. Journal of Molecular Graphics & Modelling, 2006. 25(2): p. 247-260.
Frisch, M.J., et al., Gaussian 2009, Gaussian, Inc.: Wallingford, CT, USA.
Bayly, C.I., et al., A well-behaved electrostatic potential based method using charge
restraints for deriving atomic charges: the RESP model. J. Phys. Chem., 1993. 97(40): p.
10269-10280.
Phillips, J.C., et al., Scalable Molecular Dynamics with NAMD. J. Co mput. Chem., 2005. 26:
p. 1781-1802.
Amaro, R.E., et al., Discovery of drug-like inhibitors of an essential RNA-editing ligase in
Trypanosoma brucei. Proceedings of the National Academy of Sciences of the United States
of America, 2008. 105(45): p. 17278-83.
Amaro, R.E., et al., Remarkable loop flexibility in avian influenza N1 and its implications for
antiviral drug design. J Am Chem Soc, 2007. 129(25): p. 7764-5.
Landon, M.R., et al., Novel druggable hot spots in avian influenza neuraminidase H5N1
revealed by computational solvent mapping of a reduced and representative receptor
ensemble. Chem Biol Drug Des, 2008. 71(2): p. 106-16.
Daura, X., W.F. van Gunsteren, and A.E. Mark, Folding-unfolding thermodynamics of a
beta-heptapeptide from equilibrium simulations. Proteins, 1999. 34(3): p. 269-80.
Pronk, S., et al., GROMACS 4.5: a high-throughput and highly parallel open source
molecular simulation toolkit. Bioinformatics, 2013. 29(7): p. 845-854.
Morris, G.M., et al., AutoDock4 and AutoDockTools4: Automated docking with selective
receptor flexibility. Journal of Computational Chemistry, 2009. 30(16): p. 2785-2791.
Trott, O. and A.J. Olson, AutoDock Vina: improving the speed and accuracy of docking with
a new scoring function, efficient optimization, and multithreading. J Co mput Chem, 2010.
31(2): p. 455-61.
Altintas, I., et al., Challenges and approaches for distributed workflow-driven analysis of
large-scale biological data: vision paper, in Proceedings of the 2012 Joint EDBT/ICDT
Workshops2012, ACM: Berlin, Germany. p. 73-78.
Truchon, J.F. and C.I. Bay ly, Evaluating virtual screening methods: good and bad metrics
for the "early recognition" problem. J Chem Inf Model, 2007. 47(2): p. 488-508.
Zhao, W., et al., A statistical framework to evaluate virtual screening. BMC Bioinfo rmatics,
2009. 10: p. 225.
Fawcett, T., An introduction to ROC analysis. Pattern Recognition Letters, 2006. 27(8): p.
861-874.

Automated workﬂows for drug discovery and molecular simulations

24.
25.
26.
27.
28.
29.
30.

R.E. Amaro et al

Nicholls, A., What Do We Know?: Simple Statistical Techniques that Help , in
Chemoinformatics and Computational Chemical Biology, J. Bajorath, Editor. 2011, Hu mana
Press. p. 531-581.
Jain, A.N., Bias, reporting, and sharing: computational evaluations of docking methods.
Journal of Computer-Aided Molecular Design, 2008. 22(3-4): p. 201-212.
Matlab, 2011, The MathWorks Inc.: Natick, Massachusetts.
Krishnan, S., et al. Design and Evaluation of Opal2: A Toolkit for Scientific Software as a
Service. in Services - I, 2009 World Conference on. 2009.
Krishnan, S., et al. Opal: SimpleWeb Services Wrappers for Scientific Applications. in Web
Services, 2006. ICWS '06. International Conference on. 2006.
Github, 2014: https://github.com.
Bruno, G., et al. Rolls: modifying a standard system installer to support user-customizable
cluster frontend appliances. in Cluster Computing, 2004 IEEE International Conference on .
2004.

1755

