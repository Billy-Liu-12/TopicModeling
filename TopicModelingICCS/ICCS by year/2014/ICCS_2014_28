Procedia Computer Science
Volume 29, 2014, Pages 2003–2012
ICCS 2014. 14th International Conference on Computational Science

Large Scale Read Classification
for Next Generation Sequencing
James M. Hogan1*and Timothy Peut1
1: School of EECS, Queensland University of Technology, Brisbane, Australia.
j.hogan@qut.edu.au, tim@timpeut.com.

Abstract
Next Generation Sequencing (NGS) has revolutionised molecu lar biology, resulting in an exp losion of
data sets and an increasing role in clinical practice. Such applicat ions necessarily require rap id
identification of the organis m as a prelude to annotation and further analysis. NGS data consist of a
substantial number of short sequence reads, given context through downstream assembly and
annotation, a process requiring reads consistent with the assumed species or species group. Highly
accurate results have been obtained for restricted sets using SVM classifiers, but such methods are
difficult to parallelise and success depends on careful attention to feature selection. This work
examines the problem at very large scale, using a mix of synthetic and real data with a view to
determining the overall structure of the problem and the effect iveness of parallel ensemb les of simp ler
classifiers (principally random forests) in addressing the challenges of large scale genomics.
Keywords: Genomics, Next Generation Sequencing, Alignment-free M ethods, M achine Learning

1 Introduction
Over the past decade, successive developments in sequencing technologies have revolutionized
mo lecular b iology, increasing sequencing efficiency as much as 100,000-fold over conventional
Sanger sequencing, the foundation of the early public genome projects. These technologies, known
collectively as Next Generation Sequencing (NGS) approaches [1], have fundamentally changed the
nature of molecular biology, resulting in an explosion in the availability of genomic data sets,
supporting routine sequencing in individual laboratories and, increasingly, as part of clinical practice.
The present work has its origins in clin ical sequencing, and the need to identify rapid ly the species
present from the reads obtained from an NGS sequencing run. These ideas were considered in the
context of bacterial infection, although the approach is more broadly applicab le. Briefly, as described
in [2], a lab may isolate DNA fro m a bacterial colony, and sequence the genome before the species is
known with certainty. Clinical signs and non-molecular diagnostics may offer some insight, but the
*

Author to whom all correspondence should be addressed.

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2014.05.184

2003

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

suspicion needs to be confirmed if species-specific downstream in formatics are to work successfully.
The task is to determine, based on the FASTQ sequence files, whether the whole pro ject is based on
an homogeneous sequence sample, one reflecting a single species. In the alternat ive, the pro ject might
be corrupted, drawn fro m a mix o f species, or reflect a previously unknown species or strain. Other
confounding factors are outlined in the same reference.
The representation adopted in [2], tokenizing each read accord ing to substrings of length k
(kmers) and representing each project as a h igh dimensional count vector, proved extremely
successful as a basis for SVM based discrimination of projects across both divergent and closely
related species, with accuracy, precision and recall all well above 90%. Methods based on kmer
spectra allow consideration of similarity without the need for assembly or align ment, and are robust in
the presence of structural re-arrangement (see for examp le [3]). Ho wever, these results rely on carefu l
and computationally intensive selection from the available set, a set whose dimension grows as Ͷ௞ Ǥ
While the earlier study was very successful as a machine learn ing exercise, and had considerable
utility for the set of species considered, the mo re general problem has not been given significant
attention. In particular, the effects of scale and sequencing noise, and computational methods to
overcome them have not been previously investigated. The data sets in [2] were limited to around 130
projects, and the choices of k to 6,8 and 10, with putative feature sets thus ranging fro m 4096 to
1048576. While feature selection limits the effective dimensionality, SVM train ing remains a nontrivial co mputational burden, and one which gro ws markedly with scale. SVM classification is usually
paralellisable, but attempts to parallelise the training process have proven far less successful, the
constrained quadratic programming problem admitting few obvious decompositions.
In this wo rk we extend the previous study through direct consideration of the scale of the data set
through a mix of data: real (d rawn fro m the Sequence Read Archive [4]) and synthetic (generated by
shattering completed and assembled genomes fro m GenBank through the use of the NCBI A RT
toolset [5]). Given the relat ive co mplexity and sequential structure of SVM training, we seek to use
methods that may be more effectively used in systems which part ition the train ing and classification
problems to take advantage of the available co mputational resources. We consider primarily the
environment provided by the open source Mahout Project [6] and the mu ltiple classifiers provided
through the Naïve Bayes and Random Forests libraries.
This paper is organized as fo llo ws. In section 2, we provide more info rmation on the nature of the
problem and on the data sets utilized in the earlier study, before successively introducing the machine
learning environ ment Mahout and the open source map reduce framework Hadoop wh ich underpins it
(section 2.1) and finally the Random Forest classification method used over the remainder of the paper
(section 2.2). Section 3 is concerned with the data selection and preparation, and our focus is mainly
on the use of ART and additional random substitutions to generate variation in the data set, before
considering the computational demands of data preparation in section 3.1. Sect ion 4 presents the
results of our classification experiments and we conclude in section 5 with discussion and future
extensions.

2 Background
Next Generation Sequencing (NGS) [1] is the name given to a nu mber of DNA sequencing
technologies, all of wh ich build on classical shotgun sequencing. Laboratory sequencing machines
randomly break DNA up into numerous short, independent segments, known as reads. The resulting
data are stored in the industry standard FASTQ format.
The task is to classify whether the entire sequencing project belongs to a part icular organis m, here
chosen to be the important pathogen Staphylococcus aureus. The data used by Hogan et al [2] consist
of 130 unique sequencing projects. These projects include a number of S. aureus projects, other
Staphylococcus strains, and other co mmon bacteria such as E. coli, Streptococcus and Chlamydia. All

2004

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

of the sequencing projects were for prokaryotes, specifically bacteria. These were actual sequencing
projects, such that there was variation between different sequences of the same bacteriu m strain as
well as error introduced in the sequencing process. These projects were manually selected and
obtained from the Sequence Read Archive (SRA, formerly known as the Short Read Archive) [4].
As briefly described above, Hogan et al. [2] used a k-mer representation as the basis of this
classification. A sliding window of length k was used to count the occurrences of each k-mer across
each read. These counts were then accumulated over all the reads in the project and then normalised,
resulting in a feature vector of substantial length for each project. For k=8 and k=10, these feature
vectors were reduced using the Relief [7] feature selection algorith m, as not all features were
significant in classification.
This earlier study used a small but broad set of 130 sequencing projects to train and test a Support
Vector Machine (SVM ) in the R statistical environ ment. Two classes were used for classification STAPH_AUREUS and NOT_STAPH_AUREUS. Precision and recall of above 0.95 was achieved,
and the classifier was able readily to distinguish between different species of Staphylococcus. As
noted above, concerns over the scalability of this approach [8] led us to consider a collection of
simp ler – or at least more simp ly t rainable – classifier elements to allow parallelizat ion. These
techniques are considered in the next section.

2.1 Map-Reduce, Hadoop and Mahout
MapReduce [9] is a distributed co mputing model adapted fro m the map-reduce pattern of
functional programming. Orig inally developed in its present form by Google, the method is designed
to scale with increased data sets and additional hardware, splitting the computation over a set of
equivalent nodes in such a way that the results may be readily assembled into groups and collapsed
into an atomic value. The Apache Mahout project [10] is an environment for machine learn ing which
exploits the map reduce framework provided by the Apache Hadoop [11] pro ject. Nu merous tutorials
exist at the Hadoop project site and elsewhere describing the structure of Map -Reduce problems and
the details of the architecture. Specific issues encountered in a class of geno mics problems are
considered in so me detail in [12]. The crucial issue in the present application is the ‘map -reducability’
of the machine learn ing method under consideration; numerous methods admit a map -reduce
representation in the classification phase, but far fewer can be parallelized in this way in the training
phase.
Mahout exists to produce distributed or scalable machine learning libraries. It builds on top of
Hadoop to provide MapReduce based implementations of common classification, clustering and data
mining algorith ms. Mahout is a work in progress and only has a small nu mber of classification
methods implemented, currently : Logistic Regression, Naive Bayes, Rando m Forest, On line Passive
Aggressive, and Hidden Markov Models. Attempts have been made to imp lement an SVM in Mahout
but no working imp lementations currently exist. SVMs are d ifficult to parallelise and existing parallel
SVM imp lementations are not able to be transformed into a Map Reduceable form [8]. While there are
theoretical MapReduceable SVM models [13], there are at present no working implementations.
In this work we consider only the Mahout Random Forest classifier in detail. Our study included
extensive trials using R based imp lementations of Naïve Bayes, Rando m Forests and Regularised
Random Forest algorith ms over the 130 project data set fro m [2]. While we do not report these results
in detail here, the Naïve Bayes classifier performed poorly relat ive to the others and to the earlier
SVM methods. The Random Forest approach was considered promising, achieving resu lts comparable
to those of the SVM, and the method and these results are described in the next section.

2005

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

2.2 Random Forest Classifiers
Random Forests are ensemble methods which use a number of independent decision trees for
classification. Each tree uses a random selection of features to make a classification decision, and the
Random Forest classifies by selecting the mode of all the decision tree outputs. By using a large
number of decision trees, a Random Forest is able to overcome the problems associated with using a
random selection of features to make a decision.
Decision Trees are well-established classification methods that recursively split a data set into
smaller sets based on the result of a test defined at each branch in the tree [14]. Starting with the root
node, decisions are made until a leaf node is reached, at which point the appropriate label can be
applied to the data point. The problem in the train ing process is to determine which feature to use at
each decision to partition the data points.
A Random Fo rest overcomes this semi-rando m feature selection by constructing a large nu mber of
decision trees, in the hundreds or even thousands. Each tree can be constructed independently, which
makes Rando m Fo rest construction MapReduceable, with the reduction step incorporating an overall
decision on the classification of the examp le data vector. The Mahout imp lementation chooses splits
based on an information gain criterion, but does not regularize the approach to limit ov erfitting. In the
trial studies using the R caret package, we found that RF with regularization outperformed even the
SVM approach - albeit marginally and within the standard error - with precision of 0.95 vs. 0.94. The
simp le RF performance was notably weaker, but it was found that this performance could be made
comparable to RRF through more aggressive feature selection, ultimately yielding results comparable
to the SVM. The 130 projects fro m [2] were split into train and holdout sets consisting of 90 and 40
projects respectively. 10-fold cross-validation was used on the training set to calculate mean accuracy
and standard deviation, while the holdout set was used to calculate holdout accuracy, precision and
recall. Trials using Mahout and k=10 y ielded optimal selection at around 1000 features, as may be
seen in Table 1.
Num
Features
10,000
1,000
100

Mean
Accuracy
0.93
0.93
0.93

Std
Deviation
0.08
0.08
0.09

Holdout
Accuracy
0.93
0.95
0.9

Precision

Recall

0.86
0.94
0.82

1.0
0.94
1.0

Table 1 - Mahout Random Forest with Varying Number of Features

3 Data Sets
In addition to the original 130 SRA sequencing projects from [2], a wide range of examples was
here created using the NCBI A RT tool set. A RT is a set of co mmand line tools that generate synthetic
NGS reads fro m a fu ll DNA sequence. ART generates these reads by simu lating the sequencing
process, and has built-in, vendor specific read error models to reproduce error in the sequencing
process. Single-ended Illu mina reads are supported; as this was the hardware used to sequence the
projects from the earlier, this mode was selected for consistency.
ART's error models are derived fro m large sets of actual sequencing data and represent error in the
sequencing process. ART is unable to reproduce the natural variation between organisms of the same
species; it is only able to emulate sequencing error. For single-ended Illu mina reads, the primary
sequencing error is base substitution. That is, bases are so metimes incorrectly read and substituted for
another base.

2006

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

It is important to note that past a certain point increasing the read coverage does not improve the
classification results. The coverage must be high enough such that the sequencing error introduce d by
ART can be normalised out when counting the k-mers. Fro m experimentation it was found that
coverage of 10 was sufficient. As the k-mer counts are normalised, only the relative frequencies of
each k-mer are considered when performing classification. Once the coverage is high enough for
sequencing error to be normalised out, further increases only increase the time taken to prepare the
data set; they do not improve the classifier performance.
The reference sequences for 20 negative strains and one S. aureus were obtained fro m RefSeq, the
NCBI reference sequence database [15]. With these reference sequences ART can be used to generate
data sets of any size. In Hogan et al. [2], the 70 negative sequencing projects came fro m appro ximately
30 different strains, but it was not possible to obtain reference sequences for all of these 30. Reference
sequences for the more uncommon and obscure strains did not exist in RefSeq. The reference
sequences obtained include mult iple Staphylococcus strains and other common bacteria such as E.
coli, Streptococcus and Chlamydia. The full list of reference sequences is in the supplementary
material at http://eprints.qut.edu.au/69837/.
As noted in the documentation and elsewhere, ART does not simulate variation between different
organisms of the same strain; its error model purely deals with sequencing error. To introduce
variation between organisms, bases were rando mly substituted throughout a generate d project before it
was tokenised and k-mers were counted. This was accomp lished by the following (pseudocode) list
comprehension, which was run for each read in every synthetic project:
[base if rand() >= p else rand_choice("ACGT") for base in read]
That is, there is a p probability that each base will be randomly substituted for another base. A
being substituted for A is here a valid substitution; no switch is forced.. Addit ional substitution was
only performed on projects in the holdout set. Unless otherwise noted, for all runs ART generated
reads of length 75 with a coverage of 10, and the top 1,000 features from Relief were used.

3.1 Computational Considerations
Data preparation was performed on a node in QUT's Big Data Lab. This machine had an Intel
Xeon E5-2609 processor with 8 HyperThreads, each running at 1.2GHz. There was a total of 256GB
of memo ry, with approximately 50GB free at any one time. All data was mounted on a network disk,
and the node used 64bit Red Hat Linux as an Operating System.
As previously outlined, there are four main data preparation stages. Each stage was timed, with the
results and time co mplexity of each stage shown in the table below. 1040 projects were created, with
360 in the training/test set and 680 in the holdout set. The k-mers were collected with k=10, the
previously demonstrated optimal value, and Relief selected the top 1,000 features.
Wall Time Taken
(H:M:S)
0:55:41
1:20:23
0:30:41

ܱሺ݊‫ ݏݐ݆ܿ݁݋ݎ݌̴ ݉ݑ‬ൈ ‫ ݁݃ܽݎ݁ݒ݋̴ܿ ݀ܽ݁ݎ‬ሻ
ܱሺ݊‫ ݏݐ݆ܿ݁݋ݎ݌̴ ݉ݑ‬ൈ ‫ ݁݃ܽݎ݁ݒ݋̴ܿ ݀ܽ݁ݎ‬ሻ
ܱሺ݊‫ ݏݐ݆ܿ݁݋ݎ݌̴݉ݑ‬ൈ ‫ݏ݁ݎݑݐ̴݂݈ܽ݁ܽݐ݋ݐ‬ሻ

Feature Selection

3:14:14

ܱሺ݊‫ ݏݐ݆ܿ݁݋ݎ݌̴݉ݑ‬ൈ ‫ݏ݁ݎݑݐ̴݂݈ܽ݁ܽݐ݋ݐ‬ሻ

Total

6:00:59

ܱሺ݊‫ ݏݐ݆ܿ݁݋ݎ݌̴݉ݑ‬ൈ ‫ ݁݃ܽݎ݁ݒ݋̴ܿ ݀ܽ݁ݎ‬൅
‫ ݁݃ܽݎ݁ݒ݋̴ܿ ݀ܽ݁ݎ‬ൈ ‫ݏ݁ݎݑݐ̴݂ܽ݁ ݈ܽݐ݋ݐ‬ሻ

Stage
Create Reads
Count k-mers
Create CSVs

Time Complexity

Table 1 - Computational S tatistics, Data Preparation

2007

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

The overall time co mplexity o f the data preparation stage is linear in the number of p rojects, the
read coverage, and the total features. This linear time co mplexity is necessary to allow scaling to large
data sets. Polynomial or otherwise super-linear co mplexity would present a large barrier to scaling. It
is important to note also that the total features increases exponentially with k as ݊‫ ݏ݁ݎݑݐ̴݂ܽ݁݉ݑ‬ൌ Ͷ௞ .
The first two stages of data preparation, read creat ion and k-mer counting, are embarrassingly
simp le to parallelise. Each synthetic sequencing project can be created independently, and the k-mers
in each pro ject can be counted independently. These two stages required appro ximately 18 hours of
CPU time, and without this inherent parallelism the data preparation stage would be a significant
barrier to scaling to larger data sets. As the data set grows, the preparation stage can be easily run on
more powerful hard ware. The limit ing factor in this work was the use of the Relief feature selection
algorith m, which while selected for its performance, was nonetheless a sequential implementation. A
parallel version – based on subsetting – is likely necessary for extreme scale studies of this nature.

4 Results
The data preparation process described above was performed to create data sets of various sizes,
primarily to test the computational effects of scaling to large data sets. There was no additional
substitution performed: p=0. An approximate 70/ 30 split was used, as this achieved the best results in
earlier work. 10-fold cross validation was emp loyed on the train set to determine the mean accuracy
and standard deviation of the Random Forest. The Mahout Random Forest randomly selected 31
features for consideration per node, and 500 trees were constructed. Mahout Random Forest was able
to perfectly classify all projects at various data set sizes, albeit trivially as the noise level was zero.
The timings for data preparation are provided above, and the training and classification timings were
trivial in comparison, requiring around 1 minute on commodity hardware.
In the remainder of this section, we will consider the dual effects of noise and scale on
classification performance. The nu mber of projects is held to vary between the base of 130 as in [2]
and a maximu m of 1040 as described above. The essential task in each case remains to distinguish a
chosen species from others in the set, where the difficulty arises from natural sequence diversity –
although as we have seen, this effect is limited – and fro m increasing levels of noise.
Overwhelmingly, we find that a random forest classifier produces very similar results for the problem
regardless of the size of the data sets. In this respect, the only interest lies in the computational
efficiency of the process, and this is considered in the previous section. While some limitations will
inevitably arise at extremes, we have established that the approach can work very effectively for a
very large collection of data, training and testing on 360 p rojects and evaluating performance on a
hold out set of almost 700 projects. In the next sections we will examine the effects of noise and
species class on the effectiveness of the approach.

4.1 Noise
With the classifier shown to work on a triv ially simple problem, it is of interest to determine how
much variat ion between organisms can be present before the classifier breaks down. This is
accomplished by means of additional substitution, i.e. p>0. As above, 10-fold cross validation was
emp loyed on the train set to determine the mean accuracy and standard deviation of the Rando m
Forest. The Mahout Random Forest randomly selected 31 features for consideration per node, and 500
trees were constructed. The results are summarised below.

2008

Large Scale Read Classiﬁcation for Next Generation Sequencing

S ubstitution Rate

0.025
0.05
0.075
0.08
0.085
0.09
0.1
0.11
0.2

Mean
Accuracy

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

S td
Deviation

0
0
0
0
0
0
0
0
0

James Hogan and Timothy Peut

Holdout
Accuracy

1.0
1.0
1.0
0.994
0.938
0.731
0.601
0.512
0.5

Precision

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

Recall

1.0
1.0
1.0
0.988
0.876
0.46
0.22
0.02
0

Table 3 - Mahout Random Forest Results, Additional S ubstitution

As these results show, the classifier starts to break down at 8% addit ional substitution. Its precision
is consistently high, while recall quickly drops to unacceptable levels. That is, the classifier has no
false positives and the false negative rate quickly increased past 8% substitution. Some insight into
this problem may be gained by considering the most common features in th e representations. We note
that the feature counts for S. aureus, are p redominantly higher than the counts for the other negative
organisms, and we can highlight this variation by defining an envelope of the negative counts
‫ܧ‬௝ ൌ ሺ ܰଵ௝ ǡ ܰଶ௝ ǡ ܰଷ௝ ǡ ǥ ǡ ܰ௡௝ ሻ,
where Ej is the jth feature count of the envelope and Nij is the jth feature count of the ith negative
organism.

Figure 1 - Top 100 Features, Negative Envelope, p=0.00 and p=0.08. Note the disruption of separation
with increasing noise levels.

2009

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

A graph of S. aureus, the negative envelope, and the mean of these values is shown on the previous
page at left. As the noise level in the data set is increased, we can see a substantial disruption of this
clean feature-based separation across the species set (right).

4.2 Other Species Targets
With the Random Forest able to successfully classify STAPH_AUREUS and
NOT_ STAPH_AUREUS classes, it is of interest to determine whether the k-mer representation and
Mahout's Random Forest are capable of classifying other organisms. In this case, E_COLI and
NOT_ E_ COLI were used as the positive and negative classes. As above, k=10 was used for k-mer
counting and Relief was used to select the top 1,000 features. 10-fold cross validation was emp loyed
on the training/test set to determine the mean accuracy and standard deviation. 31 features were
randomly selected for consideration per node, and 500 t rees were constructed. The results are
summarised below. As these results show, the classifier is able to successfully classify E. coli
sequencing projects. Its precision is constantly high, while recall quickly drops to unacceptable levels
above p=0.06. Th is behaviour was observed with S. aureus, but it is interesting to note that the
transition occurs at a lower value of p, with classification based on a markedly different feature set.
Substitution
Rate
0.05
0.06
0.065
0.07
0.075
0.08
0.085
0.1
0.2

Mean
Accuracy
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

Std
Deviation
0
0
0
0
0
0
0
0
0

Holdout
Accuracy
1.0
1.0
0.9
0.67
0.55
0.51
0.5
0.5
0.5

Precision
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

Recall
1.0
1.0
0.81
0.34
0.103
0.015
0
0
0

Table 4 - Mahout Random Forest Results, E. coli

Touzain et al. [16] investigated genomic variability at the species level for E. coli, S. aureus and S.
pyogenes. It was found that the main type of variab ility is "microdiversity", the differences in small
DNA segments of 20 to 500 bp in size. The S. aureus genomes contained appro ximately 75%
microdiverse loci, with 1.12% insertions and 4.48% deletions per microdiverse loci. The E. coli
genomes contained approximately 55% microdiverse loci, with 3.99% insertions and 4.69% deletions
per microdiverse loci.
These numbers cannot be directly co mpared to the value of p, but they can be interpreted in the
context of results presented. The Random Fo rest was able to classify successfully actual S. aureus
reads, meaning that the variation observed by Touzain et al. is equivalent to a p value of less than the
S. aureus critical point of 0.08. This strongly suggests that the Random Forest classifier is capable of
classifying actual sequencing projects in addition to these synthetic sequencing proje cts, but further
work is necessary to prove this.

2010

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

Figure 2 - Top 100 Features, Negative Envelope, p=0.00 and p=0.10, this time for E. coli as the positive
class. Note the disruption of separation with increasing noise levels.

5 Conclusions
This work has built on the work completed by Hogan et al. [2] to explore the computational
consequences of scaling read classification to a large data set and introducing substantial levels of
noise and targeting additional organisms. As before, the approach does not require assembly into
contigs or read alignment. Here, the k-mer counts are derived directly fro m the reads themselves, in
contrast to approaches in other domains.
It was found that Random Forests match the classificat ion performance of SVMs when classifying
real sequencing projects using a k-mer representation. To allow rapid scaling to large data sets, the
read simu lator ART was used to generate synthetic sequencing projects from reference genomes.
Relief was used to perform feature selection, with a nu mber of custom Python scripts used to automate
the data set preparation process.
The computational impacts of scaling to large data sets were investigated in detail. It was found
that while the data preparation stage scales linearly, it is by far the most time consuming stage. Data
preparation is predominantly parallelisable, but parallel feature selection will be essential for larger
data sets. Machine Learn ing scales linearly with additional sequencing projects and take s an
insignificant amount of time when compared to data preparation
After showing that the software was capable of handling large data sets, while noting these
limitat ions, variation between organisms was investigated. It was found that Mahout's Random Forest
was able to successfully classify the synthetic projects up to a well-defined substitution limit above
which the classification is rapidly disrupted. These results were observed across a wide range of
synthetic sequences and for two distinct target org anisms, results that augur well for broader
application of the approach. The data set contained multiple Staphylococcus strains along with other
more distant species, showing that the Rando m Forest is capable of making both broad and fine grained classification decisions.

2011

Large Scale Read Classiﬁcation for Next Generation Sequencing

James Hogan and Timothy Peut

Co mputationally, the crit ical contribution lies in the effect ive use of a simp le classifier that may be
trained rap idly in parallel and applied through ‘commod ity’ parallelis m, here Hadoop map -reduce
embedded within the Mahout framework. These studies provide a firm basis for further scaling and
broader application across the bacterial spectrum, and to eukaryotic sequencing .

References
[1] M. L. Met zker, "Sequencing technologies - the next generation," Nature Reviews Genetics, vol.
11, pp. 31-46, 2010.
[2] J. Hogan, P. Holland, A. Ho llo way, R. Pet it and T. Read , " Read Classification for Next
Generation Sequencing," in ESANN, Bruges, 2013.
[3] K. Song, J. Ren, G. Reinert , M. Deng, M.S. Waterman and F. Sun, "New develop ments of
align ment-free sequence comparison: measures, statistics and next-generation sequencing," Briefings
in Bioinformatics, 2013.
[4]NCBI,
"The
Sequence
Read
Archive,"
2014.
[Online].
Availab le:
http://www.ncbi.nlm.nih.gov/sra..
[5] W. Huang, L. Li, J. Myers and G. Marth, "ART: a next -generation sequencing read simu lator,"
Bioinformatics, vol. 28, no. 4, pp. 593-594, 2012.
[6]The Apache Software Foundation., "Apache Mahout," 2013. [On line]. Availab le:
http://mahout.apache.org.
[7] K. Kira and L. Rendell, "A practical approach to feature selection," in Proceedings of the ninth
international workshop on Machine Learning, 1992.
[8] E. Chang, K. Zhu, H. Wang, H. Bai, J. Li, Z. Qiu and H. Cu i, "“PSVM: Parallelizing Support
Vector Machines," in Advances in Neural Information Processing Systems, 2007.
[9] J. Dean and S. Ghemawat, "MapReduce: Simp lified Data Processing on Large Clusters," in
OSDI'04: Sixth Symposium on Operating System Design and Implementation, 2004.
[10] The Apache Soft ware Foundation, "Apache Mahout," 2013. [Online]. Availab le:
http://mahout.apache.org.
[11] The Apache Soft ware Foundation, "Apache Hadoop," 2013. [Online]. Availab le:
http://hadoop.apache.org..
[12] J. Hogan, W. Kelly and F. Newell, "Consensus sigma-70 Pro moter Predict ion using Hadoop," in
9th IEEE International Conference on e-Science, Beijing, 2013.
[13] H. Graf, E. Cosatto, L. Bottou, I. Durdanovic and V. Vapnik , "Parallel support vector machines:
The cascade SVM," in Advances in neural information processing systems, 2004..
[14] M. Friedl and C. Brodley, "Decision tree classificat ion of land cover fro m remotely sensed
data," ” Remote sensing of environment, vol. 61, no. 3, pp. 399-409, 1997.
[15] NCBI, "RefSeq : NCBI Reference Sequence Database," 2013. [On line]. Availab le:
http://www.ncbi.nlm.nih.gov/refseq/.
[16] F. Touzain, E. Denamur, C. Medigue, V. Barbe, M. El Karoui and M. Petit , "Small variable
segments constitute a major mtype of diversity of bacterial geno mes at the species level,"
GenomeBiology, vol. 11, no. 45, 2010.

2012

