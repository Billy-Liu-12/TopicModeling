Procedia Computer Science
Volume 29, 2014, Pages 2360–2369
ICCS 2014. 14th International Conference on Computational Science

A Resource Eﬃcient Big Data Analysis Method for the
Social Sciences: the case of global IP activity
Klaus Ackermann∗ and Simon D. Angus
Department of Economics, Monash University, Melbourne, Australia

Abstract
This paper presents a novel and eﬃcient way of analysing big datasets used in social science
research. We provide and demonstrate a way to deal with such datasets without the need for
high performance distributed computational facilities. Using an Internet census dataset and
with the help of freely available tools and programming libraries, we visualize global IP activity
in a spatial and time dimension. We observe a considerable reduction in storage size of our
dataset coupled with a faster processing time.
Keywords: Big Data, Social Sciences, Internet Census, GIS, Memory Reduction

1

Introduction

Social scientists rely on primary data gathered by experiments and surveys or secondary data
supplied by statistical oﬃces. Recent technological progress has enabled practitioners to utilise
novel, and very large, datasets, often revealing, for the ﬁrst time, information on individual
choices and their preferences. In this study, our aim was to utilize an Internet Census conducted
by [7] as a case study of alternative data source utilisation for the social sciences. The Internet
Census contains regular IP probes of the entire IPv4 IP space in 2012 (251 · 109 observations).
A similar census was conducted by [5] to conduct research on the stability of the Internet. From
a social science perspective, each variation in on-line or oﬀ-line activity is actually a revelation
of an individual’s preference for access to the Internet which can, by data-linking, be associated
with a particular time and geo-spatial location. Whilst an individual measure of the activity
at an IP-Address alone does not provide enough information for useful scientiﬁc conclusions,
in the aggregate over time and space, such measurements reﬂect the cultural habits of Internet
access around the globe, revealing potentially fascinating and important use- and preferencepatterns.
There is a growing number of scientiﬁc publications that make use of alternative data sources.
For instance, [9] use satellite images of night time light intensity to analyse regional favouritism
of political leaders, whilst [10] study the occurrence of key words in documents as a proxy for
∗ Corresponding

2360

Author: klaus.ackermann@monash.edu

Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.220

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

Ackermann and Angus

unobservable social phenomena. In the Economics domain, [12] provides an overview of big
data analysis tools and example applications.
Common to these big-data contributions is that they employ built-for-purpose indexing and
utilize software solutions such as ‘hadoop’ or ‘big table’ which are able to harness distributed
ﬁle systems or distributed fast access storages. However, distributed systems are rarely, if ever,
available to social science research facilities or departments, and so, for the standard social
scientist alternative solutions to handle big data without these resources are needed.
Additionally, even in the realm of big data, the recommended sub-sample approach (e.g. by
[12]) is not always available to the social scientist due to high heterogeneity within the observational dataset. For example, in the present dataset, linked observations on IPstatus are
attached to (time,place) pairs (a common observational feature of interesting social science
data). If one supposes that a social scientist would like to assess the Internet usage for cities
with more than ten thousand citizens over a 24 hour cycle, aggregated monthly, an analysis of
(even) the entire dataset would result in less than 30001 observations by time–location cohort.
Given that, on average, only 10% of the data are positive probes, the social scientist now faces
less than 300 observations per cohort: Varian’s rule [12] of using a 0.1% sub-sample, which was
demonstrated to be an eﬃcient approach for transactional data, is clearly not applicable in this
case.
Hence, the summary challenge for the social scientist is to ﬁnd a method which ideally enables her to analyse an entire ‘big data’, heterogeneous, dataset, with non-distributed hardware
resources commonly available within her institution.
In this work, we describe and demonstrate one such solution to this problem. Speciﬁcally, a
Java program was developed using freely available software to ﬁlter and aggregate the dataset,
executable on a multi-core computer. The source code is available on request. We demonstrate
the method to produce revealed preference Internet activity patterns around major cities in the
time dimension and spatial activity maps for Australia.
We ﬁnd that the method successfully delivers a signiﬁcant reduction in storage space requirements (around 18 times), leading to a similar speed up in processing time. Moreover,
the resultant format is easily convertable to the data types of common tools used by social
scientists, such as Qgis, R, Stata or Matlab.

2

Method

The method we describe in this paper is outlined in Fig. 1 as applied to the IP activity database.
In summary, we start by converting 9 TB of loose text ﬁles to a compact binary format and
then transform the resultant set into a readable format for standard statistical programs in the
social science. Importantly, the method does not require access to a computing cluster with
an extensive support team nor associated skills residing with the social scientist for cluster
job submission and data transfer2 . Finally, all software used in the described method is freely
1 Data presented in [4] suggests that there are 3.1 · 105 cities with more than ten thousand people and if one
aggregates hourly each month than that produces 288 bins in the temporal dimension. Combing the spatial and
time dimension results in roughly 9 · 107 cohorts of interest for analysis. If we assume that the total number
of observations (251 · 109 ) are split uniformly across those bins, we would get less than 3000 observations per
cohort.
2 The hardware facilities we used were 8 cores out of a 32 core AMD Opteron Processor 8356 machine with
2.3 GHz processing speed, using around 20 GB of RAM. This exceeds the standard desktop capacity, though
it was readily available in our institution. An eight core computer with 24GB memory and 512GB SSD disk
storage is well within the aﬀordable range for a social science department and would be more than suﬃcient to
accomplish the reduction we describe.

2361

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

Ackermann and Angus

available.
h5repack

JHDF5

uint32

HDF5

Qgis
Stata

HDF5
(compressed)

R
xargs

Raw Data

...

Social Science Data-sets

Figure 1: Schematic scratch of the method applied

Step 1 - Representation of Information
The ﬁrst decision to be taken is what information is needed and how to encode it in the smallest
way possible when dealing with billions of observations. In the present application, we roughly
follow the data encoding approach as outlined in [11]. The Internet Census data contains
various methods used for scanning such as ICMP, Hostprobe, Synscan and Serviceprobe. The
ﬁrst three enable one to get an activity measure of whether a host is active at a certain point in
time, the last (Serviceprobe) determines the Internet service used on a host. The diﬃculty that
arises is that for 49,478,363,902 observations (for ICMP) each observation can be represented
by a triple: [IP, time (as UNIX time-stamp), on/oﬀ activity]. An IP address is represented by
32 bits and is already in a dense format. The time stamp and the activity can be represented
with fewer bits, especially when only storing the time oﬀset for the period of interest. However,
we leave it to the compression algorithm and use 32 bit unsigned as data-type for each element
to use a standardized method for accessing. Selecting as data type integer 64 bit, due to the
non existence of a unsigned integer type in Java, versus 32 bit would double the ICMP space
requiremens of 552 GB in required storage for ICMP. Furthermore, only information that is
needed has to be saved in a new format. Consequently, we ﬁltered out all IP blocks that are
either private or not assigned as public use in the conversion program by [5]3 and then converted
each observation into an eﬃcient packing within the uint32 datatype.

Step 2 - Parallel processing
The data processing problem is twofold. First, the raw data has to be converted into HDF5
to have a reduced, fast and accessible format and second, the information needed has to be
aggregated and extracted. The HDF5 website [6] list various implementations for program
language support such as C, Python and Java. We tried ﬁrst using the python high level API as
well as the Java version from the HDF5 group. With the python API the usage was straight
forward but we found the processing speed less than acceptable for processing billions of data
points. On the other hand, the provided Java libraries were diﬃcult to integrate, however they
oﬀered suﬃcient performance. The diﬀerence arises from the fact that Python uses a global
3 For

2362

a full list see http://tools.ietf.org/html/rfc5735

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

Ackermann and Angus

interpreter lock for threads, while the latest version of Java has an integrated buﬀer and thread
support. We ﬁnally decided to use JHDF5 ([1]), which is a Java wrapper for easier usage and
lowers the entrance barrier.
The raw data is organized by the ﬁrst part of the IP address from 1.x.x.x onwards. We kept
that order and our program processed each ﬁle individually and converted it to a corresponding
HDF5 ﬁle. We used xargs for parallel processing of our program instead of threads to enable us
the use of a computer cluster later on if required. The reference to the used probing protocol
was also kept persistent.
In the aggregation process we employed a map–reduce approach. First, we processed each
ﬁle and linked the IP address to a geographical location using the MaxMind [8] database from
September 2012 and counted the online/oﬄine IP addresses per hour. After this map process
was ﬁnished we combined the resultant ﬁles to one HDF5 ﬁle.

Step 3 - Compression and Storage
After the selection of a storage mechanism it is important to select an appropriate compression
strategy depending on the resources available. The resource constraint we faced was that we
only had access to 8 cores and storage for 3 TB of data on a single host. The disk throughput
was limited by around 50 MB/s which was too limiting for directly feeding data into 8 cores,
our goal was to use all available cores while not getting constrained by the disk speed. HDF5
provides the possibility to select a vector of data as chunk size for compression. A series of
experiments with the HDF5 tool h5repack resulted in an optimal size of 100000x1 as chunk size
for our data with a gzip compression level of 5. In contrast, without compression, only 2 HDF5
ﬁles could be read from the disk directly without the CPUs waiting, whilst with the selected
tuning feature, 8 processes were possible. Figure 2 reports the reduction achieved, while gaining
ﬂexibility in accessing the data and only a slight loss in processing speed.

3

Results

Using alternative data sources that are not commonly used for the social sciences requires
careful consideration of visualisation methods to communicate the contribution to the scientiﬁc
community. For global data, we believe it is essential to select a test case that is representative
for the spatial and time dimension. First the spatial dimension was ﬁxed and the change
in Internet activity over a 24 hour period for selected major, cities (LA, New York, London,
Moscow, Tokyo, Melbourne) was analysed. Second, the geographical location of Australia
was kept constant and the Internet intensity oﬀ all on-line hosts was recorded. Finally, the
spatial and temporal dimension of Internet activity of the surrounding area of Melbourne was
portrayed.
Temporal Variation in IP use Figure 3 is a normalized plot of percentage of active IP
addresses aggregated over a year per hour. The cities are plotted in respect of their time diﬀerence to UTC time from -8 h (Los Angeles) to +11 h (Melbourne). The data were normalized by
scaling the aggregated values to their respective minimum and maximum level. The plot indicates diﬀerent activity and sleep cycle patterns for diﬀerent locations. It seems that cities which
experience a similar intra-day activity cycle share a similar distance to the equator (e.g. London
and Moscow, or Los Angeles and Melbourne), and have similar peak activity times. A possible
explanation for this connection is that a given latitude implies a given exposure to sunlight,
2363

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

10

9.08 TB

Ackermann and Angus

Serviceprobe

Total Data Size (TB)

ICMP

8

Syncscan
Hostprobe

6
4

3.07 TB

2
0.50 TB

0

1
Raw

2
HDF5

3
HDF5

w/o
after
compression compression

Figure 2: Data Size reduction achieved through conversion to HDF5 (without compression) and
then compressed HDF5 format.

aﬀecting melatonin production as investigated in [13], and therefore potentially inﬂuencing societal, intra-day activity peaks. We simply note this possibility without further comment as a
prompt for further research.
Before normalization Moscow had the highest deviation in reachable Internet Addresses that
might indicate a (historico-) cultural preference for saving resources (i.e. a higher fraction of
users switching oﬀ an internet-connected computer when not using it). Further investigations
are necessary selecting many regions worldwide for diﬀerentiating cultural and geographical
impacts.
Spatial variation in IP use Australia consists of 577 Local Government Areas (LGAs) that
change over time. Each border revision tries to follow the population dynamics for a respective
area. LGAs are therefore a natural bin for analysing Internet intensity over space. Figure 4
presents an intensity plot of active IP addresses, aggregated over a year. Unsurprisingly, areas
of high intensity follow closely coastal areas and regions surrounding the major cities (Perth,
Melbourne, Sydney, Brisbane) where the intensity of economic exchange and production is also
the highest. For the inner areas of Australia only partial measurements were available. Around
50% of the observation needed to be dropped from the study due to the lack of suﬃciently
accurate geographical location mapping.
Combined Temporal–Spatial variation in IP Use In Fig. 5 Greater Melbourne LGAs
are visualized across the spatial and time dimension. In contrast to Fig. 3 where the aggregate
over the whole metropolitan area was visualised, in Fig. 5 for each LGA the deviation from the
2364

11am

New York

London

4.5
4

9pm

3.5
3
2

10pm

2.5

Moscow

Tokyo

10am

Melbourne

0

.5

1

1.5

% Active IPs, by ICMP Probe
(normalised)

5

5.5

Los Angeles

2pm

Ackermann and Angus

7pm

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

0

0

2

4

6

6

8

10 12 14 16 18 20 22 24
UTC

12

Los Angeles
London
Tokyo

18

24

New York
Moskau
Melbourne

UTC

Figure 3: Percent Active IPs, by ICMP Probe (normalised) for six major cities. Coloured
markers and lines give hourly data and LOESS smoothed averages respectively. Grey vertical
bars indicate midday in local time with red dashed lines and times indicating the peak IP
activity in local time.
2365

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

Ackermann and Angus

Figure 4: Spatial Internet intensity plot (2012) by positive host responded to ICMP probes
demarcated by Local Government Areas (LGAs).

mean percentage of active IPs in that LGA was plotted. We conjecture that the ﬁrst peak in
LGA intensity, visible in panel 6 (4am-7am) is caused by outer-suburban commuters starting
up internet-connected devices prior to leaving for the city. Otherwise, LGA intensity appears
to build during the working day, with the most intense activity occurring near to the CBD
during 4-7pm. Night time use is, as expected, lower across all LGAs in and around Melbourne
(panels 4 and 5).

Relevance to the social context Previous studies in the social sciences that researched
the importance of the Internet were limited to statistical analysis based on country level data,
such as [2]. They found a positive economic growth eﬀect of an increased availability of the
Internet, using data from the World Development Indicator database. Applying our approach
such a study could now be undertaken on a provincial level, oﬀering the possibility to present
the disparity between diﬀerential regional development.
Alternatively studies that investigated the relation between voting behaviour based on
broadband availability, such as [3], could be extended to diﬀerent countries by providing a
uniﬁed measure. Furthermore, using our approach to generate regional comparable Internet
activity data helps reduce inactive IP addresses. Parts of the IP address space, acquired by
Internet Service Providers, but not assigned to a customer would otherwise heavily bias the
statistical estimates and result in an infeasible input to social science research.
2366

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

4

Ackermann and Angus

Conclusion

In this work, a method has been described which enables social scientists to make use of
the growing number of big data sources with freely available tools and increasingly available
hardware resources. Importantly, the method does not require the scientist to make use of
distributed computing arrays, nor does it utilise sampling [12], yet it delivers facile compression,
storage and processing performance on the entire dataset.
We have demonstrated the method on a very large (9 TB, 251 billion observation) coupled
IP activity – geo-location dataset. The method resulted in an 18 factor compression of the
memory resources required for processing, with attendant 9× speed-up and greatly reduced
computing hardware requirements. The outcome dataset was successfully processed for use in
standard data visualisation and GIS tools such as R and Qgis respectively.
Finally, we have provided example visualisations of interest to social scientists on Internet
(IP) activity across temporal–, spatial–, and combined spatio-temporal– domains.
This project reports on the ﬁrst step in a larger work in which the authors are engaged,
namely, to produce a high-resolution spatio-temporal Internet usage dataset for the social sciences. We look forward to social scientists of various sub-domains using methods similar to the
one proposed in this work to bring other large, interesting, and valuable datasets to the social
science community.

Acknowledgements
This project was in part supported by the auDA Foundation grant, ‘A new, high spatial-resolution,
dataset on Internet use in Australia’. The authors also acknowledge the help of Philip Chan
and the Massive4 group, Monash University and the Australian Synchrotron.

References
[1] Rinn Bernd. Jhdf5 (hdf5 for java). [online], 2013. https://wiki-bsse.ethz.ch/display/JHDF5,
last viewed December 2013.
[2] Changkyu Choi and Myung Hoon Yi. The eﬀect of the Internet on economic growth: Evidence
from cross-country panel data. Economics Letters, 105(1):39–41, October 2009.
[3] Nina Czernich. Broadband Internet and Political Participation: Evidence for Germany. Kyklos,
65(1):31–52, 2012.
[4] Ethan H Decker, Andrew J Kerkhoﬀ, and Melanie E Moses. Global Patterns of City Size Distributions and Their Fundamental Drivers. PLoS ONE, 2(9):e934, September 2007.
[5] Xun Fan and John Heidemann. Selecting representative ip addresses for internet topology studies. In Proceedings of the ACM Internet Measurement Conference, pages 411–423, Melbourne,
Australia, November 2010. ACM.
[6] Hdf group. [online], 2013. http://www.hdfgroup.org/HDF5/, last viewed December 2013.
[7] Internet census 2012 : Port scanning /0 using insecure embedded devices. [online], 2012. http:
//internetcensus2012.bitbucket.org/paper.html, last viewed December 2013.
[8] MaxMind. Maxmind - ip geolocation and online fraud prevention. [online], 2013. https://www.
maxmind.com, last viewed December 2013.
[9] Hodler R. and Raschky P. Regional favoritism. Quarterly Journal of Economics, 2014, forthcomming.

4 http://massive.org.au.

2367

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

Ackermann and Angus

[10] Albert Saiz and Uri Simonsohn. Proxying for unobservable variables with internet documentfrequency. Journal of the European Economic Association, 11(1):137–165, January 2013.
[11] Khalid Sayood. Introduction to Data Compression. The Morgan Kaufmann Series in Multimedia
Information and Systems. Morgan Kaufmann, Burlington, 2006.
[12] Hal R Varian. Big data: New tricks for econometrics. Working Paper, 2013.
[13] L Wetterberg, T Bratlid, L von Knorring, G Eberhard, and A Yuwiler. A multinational study
of the relationships between nighttime urinary melatonin production, age, gender, body size, and
latitude. European Archives of Psychiatry and Clinical Neuroscience, 249(5):256–262, December
1998.

2368

A Resource Eﬃcient Big Data Analysis Method for the Social Sciences

Ackermann and Angus

4: 10pm-1am

3: 7pm-10pm

5: 1am-4am

6: 4am-7am

2: 4pm-7pm

1: 1pm-4pm
7: 7am-10am
0: 10am-1pm
Figure 5: Percent variation (from the mean) in ICMP activity for Greater Melbourne Local
Government areas over 8 × 3 h temporal periods. Note: intensity scale is non-uniform. In
comparison to Fig. 3 a diﬀerent aggregation level was used only containing the metropolitan
area of Melbourne, whilst here also the outer suburbs are visible.

2369

